<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"3": {"id": 3, "path": "/home/vsts/work/1/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp", "content": "//===- SelectionDAGBuilder.cpp - Selection-DAG building -------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This implements routines for translating from LLVM IR into SelectionDAG IR.\n//\n//===----------------------------------------------------------------------===//\n\n#include \"SelectionDAGBuilder.h\"\n#include \"SDNodeDbgValue.h\"\n#include \"llvm/ADT/APFloat.h\"\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/ADT/BitVector.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallSet.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Triple.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/Analysis/BlockFrequencyInfo.h\"\n#include \"llvm/Analysis/BranchProbabilityInfo.h\"\n#include \"llvm/Analysis/ConstantFolding.h\"\n#include \"llvm/Analysis/EHPersonalities.h\"\n#include \"llvm/Analysis/Loads.h\"\n#include \"llvm/Analysis/MemoryLocation.h\"\n#include \"llvm/Analysis/ProfileSummaryInfo.h\"\n#include \"llvm/Analysis/TargetLibraryInfo.h\"\n#include \"llvm/Analysis/ValueTracking.h\"\n#include \"llvm/Analysis/VectorUtils.h\"\n#include \"llvm/CodeGen/Analysis.h\"\n#include \"llvm/CodeGen/FunctionLoweringInfo.h\"\n#include \"llvm/CodeGen/GCMetadata.h\"\n#include \"llvm/CodeGen/MachineBasicBlock.h\"\n#include \"llvm/CodeGen/MachineFrameInfo.h\"\n#include \"llvm/CodeGen/MachineFunction.h\"\n#include \"llvm/CodeGen/MachineInstr.h\"\n#include \"llvm/CodeGen/MachineInstrBuilder.h\"\n#include \"llvm/CodeGen/MachineJumpTableInfo.h\"\n#include \"llvm/CodeGen/MachineMemOperand.h\"\n#include \"llvm/CodeGen/MachineModuleInfo.h\"\n#include \"llvm/CodeGen/MachineOperand.h\"\n#include \"llvm/CodeGen/MachineRegisterInfo.h\"\n#include \"llvm/CodeGen/RuntimeLibcalls.h\"\n#include \"llvm/CodeGen/SelectionDAG.h\"\n#include \"llvm/CodeGen/SelectionDAGTargetInfo.h\"\n#include \"llvm/CodeGen/StackMaps.h\"\n#include \"llvm/CodeGen/SwiftErrorValueTracking.h\"\n#include \"llvm/CodeGen/TargetFrameLowering.h\"\n#include \"llvm/CodeGen/TargetInstrInfo.h\"\n#include \"llvm/CodeGen/TargetOpcodes.h\"\n#include \"llvm/CodeGen/TargetRegisterInfo.h\"\n#include \"llvm/CodeGen/TargetSubtargetInfo.h\"\n#include \"llvm/CodeGen/WinEHFuncInfo.h\"\n#include \"llvm/IR/Argument.h\"\n#include \"llvm/IR/Attributes.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/CallingConv.h\"\n#include \"llvm/IR/Constant.h\"\n#include \"llvm/IR/ConstantRange.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/DataLayout.h\"\n#include \"llvm/IR/DebugInfoMetadata.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/GetElementPtrTypeIterator.h\"\n#include \"llvm/IR/InlineAsm.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/IntrinsicInst.h\"\n#include \"llvm/IR/Intrinsics.h\"\n#include \"llvm/IR/IntrinsicsAArch64.h\"\n#include \"llvm/IR/IntrinsicsWebAssembly.h\"\n#include \"llvm/IR/LLVMContext.h\"\n#include \"llvm/IR/Metadata.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/Operator.h\"\n#include \"llvm/IR/PatternMatch.h\"\n#include \"llvm/IR/Statepoint.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/IR/User.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/MC/MCContext.h\"\n#include \"llvm/MC/MCSymbol.h\"\n#include \"llvm/Support/AtomicOrdering.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/CommandLine.h\"\n#include \"llvm/Support/Compiler.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Support/MathExtras.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/Target/TargetIntrinsicInfo.h\"\n#include \"llvm/Target/TargetMachine.h\"\n#include \"llvm/Target/TargetOptions.h\"\n#include \"llvm/Transforms/Utils/Local.h\"\n#include <cstddef>\n#include <cstring>\n#include <iterator>\n#include <limits>\n#include <numeric>\n#include <tuple>\n\nusing namespace llvm;\nusing namespace PatternMatch;\nusing namespace SwitchCG;\n\n#define DEBUG_TYPE \"isel\"\n\n/// LimitFloatPrecision - Generate low-precision inline sequences for\n/// some float libcalls (6, 8 or 12 bits).\nstatic unsigned LimitFloatPrecision;\n\nstatic cl::opt<bool>\n    InsertAssertAlign(\"insert-assert-align\", cl::init(true),\n                      cl::desc(\"Insert the experimental `assertalign` node.\"),\n                      cl::ReallyHidden);\n\nstatic cl::opt<unsigned, true>\n    LimitFPPrecision(\"limit-float-precision\",\n                     cl::desc(\"Generate low-precision inline sequences \"\n                              \"for some float libcalls\"),\n                     cl::location(LimitFloatPrecision), cl::Hidden,\n                     cl::init(0));\n\nstatic cl::opt<unsigned> SwitchPeelThreshold(\n    \"switch-peel-threshold\", cl::Hidden, cl::init(66),\n    cl::desc(\"Set the case probability threshold for peeling the case from a \"\n             \"switch statement. A value greater than 100 will void this \"\n             \"optimization\"));\n\n// Limit the width of DAG chains. This is important in general to prevent\n// DAG-based analysis from blowing up. For example, alias analysis and\n// load clustering may not complete in reasonable time. It is difficult to\n// recognize and avoid this situation within each individual analysis, and\n// future analyses are likely to have the same behavior. Limiting DAG width is\n// the safe approach and will be especially important with global DAGs.\n//\n// MaxParallelChains default is arbitrarily high to avoid affecting\n// optimization, but could be lowered to improve compile time. Any ld-ld-st-st\n// sequence over this should have been converted to llvm.memcpy by the\n// frontend. It is easy to induce this behavior with .ll code such as:\n// %buffer = alloca [4096 x i8]\n// %data = load [4096 x i8]* %argPtr\n// store [4096 x i8] %data, [4096 x i8]* %buffer\nstatic const unsigned MaxParallelChains = 64;\n\nstatic SDValue getCopyFromPartsVector(SelectionDAG &DAG, const SDLoc &DL,\n                                      const SDValue *Parts, unsigned NumParts,\n                                      MVT PartVT, EVT ValueVT, const Value *V,\n                                      Optional<CallingConv::ID> CC);\n\n/// getCopyFromParts - Create a value that contains the specified legal parts\n/// combined into the value they represent.  If the parts combine to a type\n/// larger than ValueVT then AssertOp can be used to specify whether the extra\n/// bits are known to be zero (ISD::AssertZext) or sign extended from ValueVT\n/// (ISD::AssertSext).\nstatic SDValue getCopyFromParts(SelectionDAG &DAG, const SDLoc &DL,\n                                const SDValue *Parts, unsigned NumParts,\n                                MVT PartVT, EVT ValueVT, const Value *V,\n                                Optional<CallingConv::ID> CC = None,\n                                Optional<ISD::NodeType> AssertOp = None) {\n  // Let the target assemble the parts if it wants to\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  if (SDValue Val = TLI.joinRegisterPartsIntoValue(DAG, DL, Parts, NumParts,\n                                                   PartVT, ValueVT, CC))\n    return Val;\n\n  if (ValueVT.isVector())\n    return getCopyFromPartsVector(DAG, DL, Parts, NumParts, PartVT, ValueVT, V,\n                                  CC);\n\n  assert(NumParts > 0 && \"No parts to assemble!\");\n  SDValue Val = Parts[0];\n\n  if (NumParts > 1) {\n    // Assemble the value from multiple parts.\n    if (ValueVT.isInteger()) {\n      unsigned PartBits = PartVT.getSizeInBits();\n      unsigned ValueBits = ValueVT.getSizeInBits();\n\n      // Assemble the power of 2 part.\n      unsigned RoundParts =\n          (NumParts & (NumParts - 1)) ? 1 << Log2_32(NumParts) : NumParts;\n      unsigned RoundBits = PartBits * RoundParts;\n      EVT RoundVT = RoundBits == ValueBits ?\n        ValueVT : EVT::getIntegerVT(*DAG.getContext(), RoundBits);\n      SDValue Lo, Hi;\n\n      EVT HalfVT = EVT::getIntegerVT(*DAG.getContext(), RoundBits/2);\n\n      if (RoundParts > 2) {\n        Lo = getCopyFromParts(DAG, DL, Parts, RoundParts / 2,\n                              PartVT, HalfVT, V);\n        Hi = getCopyFromParts(DAG, DL, Parts + RoundParts / 2,\n                              RoundParts / 2, PartVT, HalfVT, V);\n      } else {\n        Lo = DAG.getNode(ISD::BITCAST, DL, HalfVT, Parts[0]);\n        Hi = DAG.getNode(ISD::BITCAST, DL, HalfVT, Parts[1]);\n      }\n\n      if (DAG.getDataLayout().isBigEndian())\n        std::swap(Lo, Hi);\n\n      Val = DAG.getNode(ISD::BUILD_PAIR, DL, RoundVT, Lo, Hi);\n\n      if (RoundParts < NumParts) {\n        // Assemble the trailing non-power-of-2 part.\n        unsigned OddParts = NumParts - RoundParts;\n        EVT OddVT = EVT::getIntegerVT(*DAG.getContext(), OddParts * PartBits);\n        Hi = getCopyFromParts(DAG, DL, Parts + RoundParts, OddParts, PartVT,\n                              OddVT, V, CC);\n\n        // Combine the round and odd parts.\n        Lo = Val;\n        if (DAG.getDataLayout().isBigEndian())\n          std::swap(Lo, Hi);\n        EVT TotalVT = EVT::getIntegerVT(*DAG.getContext(), NumParts * PartBits);\n        Hi = DAG.getNode(ISD::ANY_EXTEND, DL, TotalVT, Hi);\n        Hi =\n            DAG.getNode(ISD::SHL, DL, TotalVT, Hi,\n                        DAG.getConstant(Lo.getValueSizeInBits(), DL,\n                                        TLI.getPointerTy(DAG.getDataLayout())));\n        Lo = DAG.getNode(ISD::ZERO_EXTEND, DL, TotalVT, Lo);\n        Val = DAG.getNode(ISD::OR, DL, TotalVT, Lo, Hi);\n      }\n    } else if (PartVT.isFloatingPoint()) {\n      // FP split into multiple FP parts (for ppcf128)\n      assert(ValueVT == EVT(MVT::ppcf128) && PartVT == MVT::f64 &&\n             \"Unexpected split\");\n      SDValue Lo, Hi;\n      Lo = DAG.getNode(ISD::BITCAST, DL, EVT(MVT::f64), Parts[0]);\n      Hi = DAG.getNode(ISD::BITCAST, DL, EVT(MVT::f64), Parts[1]);\n      if (TLI.hasBigEndianPartOrdering(ValueVT, DAG.getDataLayout()))\n        std::swap(Lo, Hi);\n      Val = DAG.getNode(ISD::BUILD_PAIR, DL, ValueVT, Lo, Hi);\n    } else {\n      // FP split into integer parts (soft fp)\n      assert(ValueVT.isFloatingPoint() && PartVT.isInteger() &&\n             !PartVT.isVector() && \"Unexpected split\");\n      EVT IntVT = EVT::getIntegerVT(*DAG.getContext(), ValueVT.getSizeInBits());\n      Val = getCopyFromParts(DAG, DL, Parts, NumParts, PartVT, IntVT, V, CC);\n    }\n  }\n\n  // There is now one part, held in Val.  Correct it to match ValueVT.\n  // PartEVT is the type of the register class that holds the value.\n  // ValueVT is the type of the inline asm operation.\n  EVT PartEVT = Val.getValueType();\n\n  if (PartEVT == ValueVT)\n    return Val;\n\n  if (PartEVT.isInteger() && ValueVT.isFloatingPoint() &&\n      ValueVT.bitsLT(PartEVT)) {\n    // For an FP value in an integer part, we need to truncate to the right\n    // width first.\n    PartEVT = EVT::getIntegerVT(*DAG.getContext(),  ValueVT.getSizeInBits());\n    Val = DAG.getNode(ISD::TRUNCATE, DL, PartEVT, Val);\n  }\n\n  // Handle types that have the same size.\n  if (PartEVT.getSizeInBits() == ValueVT.getSizeInBits())\n    return DAG.getNode(ISD::BITCAST, DL, ValueVT, Val);\n\n  // Handle types with different sizes.\n  if (PartEVT.isInteger() && ValueVT.isInteger()) {\n    if (ValueVT.bitsLT(PartEVT)) {\n      // For a truncate, see if we have any information to\n      // indicate whether the truncated bits will always be\n      // zero or sign-extension.\n      if (AssertOp.hasValue())\n        Val = DAG.getNode(*AssertOp, DL, PartEVT, Val,\n                          DAG.getValueType(ValueVT));\n      return DAG.getNode(ISD::TRUNCATE, DL, ValueVT, Val);\n    }\n    return DAG.getNode(ISD::ANY_EXTEND, DL, ValueVT, Val);\n  }\n\n  if (PartEVT.isFloatingPoint() && ValueVT.isFloatingPoint()) {\n    // FP_ROUND's are always exact here.\n    if (ValueVT.bitsLT(Val.getValueType()))\n      return DAG.getNode(\n          ISD::FP_ROUND, DL, ValueVT, Val,\n          DAG.getTargetConstant(1, DL, TLI.getPointerTy(DAG.getDataLayout())));\n\n    return DAG.getNode(ISD::FP_EXTEND, DL, ValueVT, Val);\n  }\n\n  // Handle MMX to a narrower integer type by bitcasting MMX to integer and\n  // then truncating.\n  if (PartEVT == MVT::x86mmx && ValueVT.isInteger() &&\n      ValueVT.bitsLT(PartEVT)) {\n    Val = DAG.getNode(ISD::BITCAST, DL, MVT::i64, Val);\n    return DAG.getNode(ISD::TRUNCATE, DL, ValueVT, Val);\n  }\n\n  report_fatal_error(\"Unknown mismatch in getCopyFromParts!\");\n}\n\nstatic void diagnosePossiblyInvalidConstraint(LLVMContext &Ctx, const Value *V,\n                                              const Twine &ErrMsg) {\n  const Instruction *I = dyn_cast_or_null<Instruction>(V);\n  if (!V)\n    return Ctx.emitError(ErrMsg);\n\n  const char *AsmError = \", possible invalid constraint for vector type\";\n  if (const CallInst *CI = dyn_cast<CallInst>(I))\n    if (CI->isInlineAsm())\n      return Ctx.emitError(I, ErrMsg + AsmError);\n\n  return Ctx.emitError(I, ErrMsg);\n}\n\n/// getCopyFromPartsVector - Create a value that contains the specified legal\n/// parts combined into the value they represent.  If the parts combine to a\n/// type larger than ValueVT then AssertOp can be used to specify whether the\n/// extra bits are known to be zero (ISD::AssertZext) or sign extended from\n/// ValueVT (ISD::AssertSext).\nstatic SDValue getCopyFromPartsVector(SelectionDAG &DAG, const SDLoc &DL,\n                                      const SDValue *Parts, unsigned NumParts,\n                                      MVT PartVT, EVT ValueVT, const Value *V,\n                                      Optional<CallingConv::ID> CallConv) {\n  assert(ValueVT.isVector() && \"Not a vector value\");\n  assert(NumParts > 0 && \"No parts to assemble!\");\n  const bool IsABIRegCopy = CallConv.hasValue();\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDValue Val = Parts[0];\n\n  // Handle a multi-element vector.\n  if (NumParts > 1) {\n    EVT IntermediateVT;\n    MVT RegisterVT;\n    unsigned NumIntermediates;\n    unsigned NumRegs;\n\n    if (IsABIRegCopy) {\n      NumRegs = TLI.getVectorTypeBreakdownForCallingConv(\n          *DAG.getContext(), CallConv.getValue(), ValueVT, IntermediateVT,\n          NumIntermediates, RegisterVT);\n    } else {\n      NumRegs =\n          TLI.getVectorTypeBreakdown(*DAG.getContext(), ValueVT, IntermediateVT,\n                                     NumIntermediates, RegisterVT);\n    }\n\n    assert(NumRegs == NumParts && \"Part count doesn't match vector breakdown!\");\n    NumParts = NumRegs; // Silence a compiler warning.\n    assert(RegisterVT == PartVT && \"Part type doesn't match vector breakdown!\");\n    assert(RegisterVT.getSizeInBits() ==\n           Parts[0].getSimpleValueType().getSizeInBits() &&\n           \"Part type sizes don't match!\");\n\n    // Assemble the parts into intermediate operands.\n    SmallVector<SDValue, 8> Ops(NumIntermediates);\n    if (NumIntermediates == NumParts) {\n      // If the register was not expanded, truncate or copy the value,\n      // as appropriate.\n      for (unsigned i = 0; i != NumParts; ++i)\n        Ops[i] = getCopyFromParts(DAG, DL, &Parts[i], 1,\n                                  PartVT, IntermediateVT, V, CallConv);\n    } else if (NumParts > 0) {\n      // If the intermediate type was expanded, build the intermediate\n      // operands from the parts.\n      assert(NumParts % NumIntermediates == 0 &&\n             \"Must expand into a divisible number of parts!\");\n      unsigned Factor = NumParts / NumIntermediates;\n      for (unsigned i = 0; i != NumIntermediates; ++i)\n        Ops[i] = getCopyFromParts(DAG, DL, &Parts[i * Factor], Factor,\n                                  PartVT, IntermediateVT, V, CallConv);\n    }\n\n    // Build a vector with BUILD_VECTOR or CONCAT_VECTORS from the\n    // intermediate operands.\n    EVT BuiltVectorTy =\n        IntermediateVT.isVector()\n            ? EVT::getVectorVT(\n                  *DAG.getContext(), IntermediateVT.getScalarType(),\n                  IntermediateVT.getVectorElementCount() * NumParts)\n            : EVT::getVectorVT(*DAG.getContext(),\n                               IntermediateVT.getScalarType(),\n                               NumIntermediates);\n    Val = DAG.getNode(IntermediateVT.isVector() ? ISD::CONCAT_VECTORS\n                                                : ISD::BUILD_VECTOR,\n                      DL, BuiltVectorTy, Ops);\n  }\n\n  // There is now one part, held in Val.  Correct it to match ValueVT.\n  EVT PartEVT = Val.getValueType();\n\n  if (PartEVT == ValueVT)\n    return Val;\n\n  if (PartEVT.isVector()) {\n    // If the element type of the source/dest vectors are the same, but the\n    // parts vector has more elements than the value vector, then we have a\n    // vector widening case (e.g. <2 x float> -> <4 x float>).  Extract the\n    // elements we want.\n    if (PartEVT.getVectorElementType() == ValueVT.getVectorElementType()) {\n      assert((PartEVT.getVectorElementCount().getKnownMinValue() >\n              ValueVT.getVectorElementCount().getKnownMinValue()) &&\n             (PartEVT.getVectorElementCount().isScalable() ==\n              ValueVT.getVectorElementCount().isScalable()) &&\n             \"Cannot narrow, it would be a lossy transformation\");\n      return DAG.getNode(ISD::EXTRACT_SUBVECTOR, DL, ValueVT, Val,\n                         DAG.getVectorIdxConstant(0, DL));\n    }\n\n    // Vector/Vector bitcast.\n    if (ValueVT.getSizeInBits() == PartEVT.getSizeInBits())\n      return DAG.getNode(ISD::BITCAST, DL, ValueVT, Val);\n\n    assert(PartEVT.getVectorElementCount() == ValueVT.getVectorElementCount() &&\n      \"Cannot handle this kind of promotion\");\n    // Promoted vector extract\n    return DAG.getAnyExtOrTrunc(Val, DL, ValueVT);\n\n  }\n\n  // Trivial bitcast if the types are the same size and the destination\n  // vector type is legal.\n  if (PartEVT.getSizeInBits() == ValueVT.getSizeInBits() &&\n      TLI.isTypeLegal(ValueVT))\n    return DAG.getNode(ISD::BITCAST, DL, ValueVT, Val);\n\n  if (ValueVT.getVectorNumElements() != 1) {\n     // Certain ABIs require that vectors are passed as integers. For vectors\n     // are the same size, this is an obvious bitcast.\n     if (ValueVT.getSizeInBits() == PartEVT.getSizeInBits()) {\n       return DAG.getNode(ISD::BITCAST, DL, ValueVT, Val);\n     } else if (ValueVT.bitsLT(PartEVT)) {\n       // Bitcast Val back the original type and extract the corresponding\n       // vector we want.\n       unsigned Elts = PartEVT.getSizeInBits() / ValueVT.getScalarSizeInBits();\n       EVT WiderVecType = EVT::getVectorVT(*DAG.getContext(),\n                                           ValueVT.getVectorElementType(), Elts);\n       Val = DAG.getBitcast(WiderVecType, Val);\n       return DAG.getNode(ISD::EXTRACT_SUBVECTOR, DL, ValueVT, Val,\n                          DAG.getVectorIdxConstant(0, DL));\n     }\n\n     diagnosePossiblyInvalidConstraint(\n         *DAG.getContext(), V, \"non-trivial scalar-to-vector conversion\");\n     return DAG.getUNDEF(ValueVT);\n  }\n\n  // Handle cases such as i8 -> <1 x i1>\n  EVT ValueSVT = ValueVT.getVectorElementType();\n  if (ValueVT.getVectorNumElements() == 1 && ValueSVT != PartEVT) {\n    if (ValueSVT.getSizeInBits() == PartEVT.getSizeInBits())\n      Val = DAG.getNode(ISD::BITCAST, DL, ValueSVT, Val);\n    else\n      Val = ValueVT.isFloatingPoint()\n                ? DAG.getFPExtendOrRound(Val, DL, ValueSVT)\n                : DAG.getAnyExtOrTrunc(Val, DL, ValueSVT);\n  }\n\n  return DAG.getBuildVector(ValueVT, DL, Val);\n}\n\nstatic void getCopyToPartsVector(SelectionDAG &DAG, const SDLoc &dl,\n                                 SDValue Val, SDValue *Parts, unsigned NumParts,\n                                 MVT PartVT, const Value *V,\n                                 Optional<CallingConv::ID> CallConv);\n\n/// getCopyToParts - Create a series of nodes that contain the specified value\n/// split into legal parts.  If the parts contain more bits than Val, then, for\n/// integers, ExtendKind can be used to specify how to generate the extra bits.\nstatic void getCopyToParts(SelectionDAG &DAG, const SDLoc &DL, SDValue Val,\n                           SDValue *Parts, unsigned NumParts, MVT PartVT,\n                           const Value *V,\n                           Optional<CallingConv::ID> CallConv = None,\n                           ISD::NodeType ExtendKind = ISD::ANY_EXTEND) {\n  // Let the target split the parts if it wants to\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  if (TLI.splitValueIntoRegisterParts(DAG, DL, Val, Parts, NumParts, PartVT,\n                                      CallConv))\n    return;\n  EVT ValueVT = Val.getValueType();\n\n  // Handle the vector case separately.\n  if (ValueVT.isVector())\n    return getCopyToPartsVector(DAG, DL, Val, Parts, NumParts, PartVT, V,\n                                CallConv);\n\n  unsigned PartBits = PartVT.getSizeInBits();\n  unsigned OrigNumParts = NumParts;\n  assert(DAG.getTargetLoweringInfo().isTypeLegal(PartVT) &&\n         \"Copying to an illegal type!\");\n\n  if (NumParts == 0)\n    return;\n\n  assert(!ValueVT.isVector() && \"Vector case handled elsewhere\");\n  EVT PartEVT = PartVT;\n  if (PartEVT == ValueVT) {\n    assert(NumParts == 1 && \"No-op copy with multiple parts!\");\n    Parts[0] = Val;\n    return;\n  }\n\n  if (NumParts * PartBits > ValueVT.getSizeInBits()) {\n    // If the parts cover more bits than the value has, promote the value.\n    if (PartVT.isFloatingPoint() && ValueVT.isFloatingPoint()) {\n      assert(NumParts == 1 && \"Do not know what to promote to!\");\n      Val = DAG.getNode(ISD::FP_EXTEND, DL, PartVT, Val);\n    } else {\n      if (ValueVT.isFloatingPoint()) {\n        // FP values need to be bitcast, then extended if they are being put\n        // into a larger container.\n        ValueVT = EVT::getIntegerVT(*DAG.getContext(),  ValueVT.getSizeInBits());\n        Val = DAG.getNode(ISD::BITCAST, DL, ValueVT, Val);\n      }\n      assert((PartVT.isInteger() || PartVT == MVT::x86mmx) &&\n             ValueVT.isInteger() &&\n             \"Unknown mismatch!\");\n      ValueVT = EVT::getIntegerVT(*DAG.getContext(), NumParts * PartBits);\n      Val = DAG.getNode(ExtendKind, DL, ValueVT, Val);\n      if (PartVT == MVT::x86mmx)\n        Val = DAG.getNode(ISD::BITCAST, DL, PartVT, Val);\n    }\n  } else if (PartBits == ValueVT.getSizeInBits()) {\n    // Different types of the same size.\n    assert(NumParts == 1 && PartEVT != ValueVT);\n    Val = DAG.getNode(ISD::BITCAST, DL, PartVT, Val);\n  } else if (NumParts * PartBits < ValueVT.getSizeInBits()) {\n    // If the parts cover less bits than value has, truncate the value.\n    assert((PartVT.isInteger() || PartVT == MVT::x86mmx) &&\n           ValueVT.isInteger() &&\n           \"Unknown mismatch!\");\n    ValueVT = EVT::getIntegerVT(*DAG.getContext(), NumParts * PartBits);\n    Val = DAG.getNode(ISD::TRUNCATE, DL, ValueVT, Val);\n    if (PartVT == MVT::x86mmx)\n      Val = DAG.getNode(ISD::BITCAST, DL, PartVT, Val);\n  }\n\n  // The value may have changed - recompute ValueVT.\n  ValueVT = Val.getValueType();\n  assert(NumParts * PartBits == ValueVT.getSizeInBits() &&\n         \"Failed to tile the value with PartVT!\");\n\n  if (NumParts == 1) {\n    if (PartEVT != ValueVT) {\n      diagnosePossiblyInvalidConstraint(*DAG.getContext(), V,\n                                        \"scalar-to-vector conversion failed\");\n      Val = DAG.getNode(ISD::BITCAST, DL, PartVT, Val);\n    }\n\n    Parts[0] = Val;\n    return;\n  }\n\n  // Expand the value into multiple parts.\n  if (NumParts & (NumParts - 1)) {\n    // The number of parts is not a power of 2.  Split off and copy the tail.\n    assert(PartVT.isInteger() && ValueVT.isInteger() &&\n           \"Do not know what to expand to!\");\n    unsigned RoundParts = 1 << Log2_32(NumParts);\n    unsigned RoundBits = RoundParts * PartBits;\n    unsigned OddParts = NumParts - RoundParts;\n    SDValue OddVal = DAG.getNode(ISD::SRL, DL, ValueVT, Val,\n      DAG.getShiftAmountConstant(RoundBits, ValueVT, DL, /*LegalTypes*/false));\n\n    getCopyToParts(DAG, DL, OddVal, Parts + RoundParts, OddParts, PartVT, V,\n                   CallConv);\n\n    if (DAG.getDataLayout().isBigEndian())\n      // The odd parts were reversed by getCopyToParts - unreverse them.\n      std::reverse(Parts + RoundParts, Parts + NumParts);\n\n    NumParts = RoundParts;\n    ValueVT = EVT::getIntegerVT(*DAG.getContext(), NumParts * PartBits);\n    Val = DAG.getNode(ISD::TRUNCATE, DL, ValueVT, Val);\n  }\n\n  // The number of parts is a power of 2.  Repeatedly bisect the value using\n  // EXTRACT_ELEMENT.\n  Parts[0] = DAG.getNode(ISD::BITCAST, DL,\n                         EVT::getIntegerVT(*DAG.getContext(),\n                                           ValueVT.getSizeInBits()),\n                         Val);\n\n  for (unsigned StepSize = NumParts; StepSize > 1; StepSize /= 2) {\n    for (unsigned i = 0; i < NumParts; i += StepSize) {\n      unsigned ThisBits = StepSize * PartBits / 2;\n      EVT ThisVT = EVT::getIntegerVT(*DAG.getContext(), ThisBits);\n      SDValue &Part0 = Parts[i];\n      SDValue &Part1 = Parts[i+StepSize/2];\n\n      Part1 = DAG.getNode(ISD::EXTRACT_ELEMENT, DL,\n                          ThisVT, Part0, DAG.getIntPtrConstant(1, DL));\n      Part0 = DAG.getNode(ISD::EXTRACT_ELEMENT, DL,\n                          ThisVT, Part0, DAG.getIntPtrConstant(0, DL));\n\n      if (ThisBits == PartBits && ThisVT != PartVT) {\n        Part0 = DAG.getNode(ISD::BITCAST, DL, PartVT, Part0);\n        Part1 = DAG.getNode(ISD::BITCAST, DL, PartVT, Part1);\n      }\n    }\n  }\n\n  if (DAG.getDataLayout().isBigEndian())\n    std::reverse(Parts, Parts + OrigNumParts);\n}\n\nstatic SDValue widenVectorToPartType(SelectionDAG &DAG,\n                                     SDValue Val, const SDLoc &DL, EVT PartVT) {\n  if (!PartVT.isFixedLengthVector())\n    return SDValue();\n\n  EVT ValueVT = Val.getValueType();\n  unsigned PartNumElts = PartVT.getVectorNumElements();\n  unsigned ValueNumElts = ValueVT.getVectorNumElements();\n  if (PartNumElts > ValueNumElts &&\n      PartVT.getVectorElementType() == ValueVT.getVectorElementType()) {\n    EVT ElementVT = PartVT.getVectorElementType();\n    // Vector widening case, e.g. <2 x float> -> <4 x float>.  Shuffle in\n    // undef elements.\n    SmallVector<SDValue, 16> Ops;\n    DAG.ExtractVectorElements(Val, Ops);\n    SDValue EltUndef = DAG.getUNDEF(ElementVT);\n    for (unsigned i = ValueNumElts, e = PartNumElts; i != e; ++i)\n      Ops.push_back(EltUndef);\n\n    // FIXME: Use CONCAT for 2x -> 4x.\n    return DAG.getBuildVector(PartVT, DL, Ops);\n  }\n\n  return SDValue();\n}\n\n/// getCopyToPartsVector - Create a series of nodes that contain the specified\n/// value split into legal parts.\nstatic void getCopyToPartsVector(SelectionDAG &DAG, const SDLoc &DL,\n                                 SDValue Val, SDValue *Parts, unsigned NumParts,\n                                 MVT PartVT, const Value *V,\n                                 Optional<CallingConv::ID> CallConv) {\n  EVT ValueVT = Val.getValueType();\n  assert(ValueVT.isVector() && \"Not a vector\");\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  const bool IsABIRegCopy = CallConv.hasValue();\n\n  if (NumParts == 1) {\n    EVT PartEVT = PartVT;\n    if (PartEVT == ValueVT) {\n      // Nothing to do.\n    } else if (PartVT.getSizeInBits() == ValueVT.getSizeInBits()) {\n      // Bitconvert vector->vector case.\n      Val = DAG.getNode(ISD::BITCAST, DL, PartVT, Val);\n    } else if (SDValue Widened = widenVectorToPartType(DAG, Val, DL, PartVT)) {\n      Val = Widened;\n    } else if (PartVT.isVector() &&\n               PartEVT.getVectorElementType().bitsGE(\n                   ValueVT.getVectorElementType()) &&\n               PartEVT.getVectorElementCount() ==\n                   ValueVT.getVectorElementCount()) {\n\n      // Promoted vector extract\n      Val = DAG.getAnyExtOrTrunc(Val, DL, PartVT);\n    } else {\n      if (ValueVT.getVectorElementCount().isScalar()) {\n        Val = DAG.getNode(ISD::EXTRACT_VECTOR_ELT, DL, PartVT, Val,\n                          DAG.getVectorIdxConstant(0, DL));\n      } else {\n        uint64_t ValueSize = ValueVT.getFixedSizeInBits();\n        assert(PartVT.getFixedSizeInBits() > ValueSize &&\n               \"lossy conversion of vector to scalar type\");\n        EVT IntermediateType = EVT::getIntegerVT(*DAG.getContext(), ValueSize);\n        Val = DAG.getBitcast(IntermediateType, Val);\n        Val = DAG.getAnyExtOrTrunc(Val, DL, PartVT);\n      }\n    }\n\n    assert(Val.getValueType() == PartVT && \"Unexpected vector part value type\");\n    Parts[0] = Val;\n    return;\n  }\n\n  // Handle a multi-element vector.\n  EVT IntermediateVT;\n  MVT RegisterVT;\n  unsigned NumIntermediates;\n  unsigned NumRegs;\n  if (IsABIRegCopy) {\n    NumRegs = TLI.getVectorTypeBreakdownForCallingConv(\n        *DAG.getContext(), CallConv.getValue(), ValueVT, IntermediateVT,\n        NumIntermediates, RegisterVT);\n  } else {\n    NumRegs =\n        TLI.getVectorTypeBreakdown(*DAG.getContext(), ValueVT, IntermediateVT,\n                                   NumIntermediates, RegisterVT);\n  }\n\n  assert(NumRegs == NumParts && \"Part count doesn't match vector breakdown!\");\n  NumParts = NumRegs; // Silence a compiler warning.\n  assert(RegisterVT == PartVT && \"Part type doesn't match vector breakdown!\");\n\n  assert(IntermediateVT.isScalableVector() == ValueVT.isScalableVector() &&\n         \"Mixing scalable and fixed vectors when copying in parts\");\n\n  Optional<ElementCount> DestEltCnt;\n\n  if (IntermediateVT.isVector())\n    DestEltCnt = IntermediateVT.getVectorElementCount() * NumIntermediates;\n  else\n    DestEltCnt = ElementCount::getFixed(NumIntermediates);\n\n  EVT BuiltVectorTy = EVT::getVectorVT(\n      *DAG.getContext(), IntermediateVT.getScalarType(), DestEltCnt.getValue());\n  if (ValueVT != BuiltVectorTy) {\n    if (SDValue Widened = widenVectorToPartType(DAG, Val, DL, BuiltVectorTy))\n      Val = Widened;\n\n    Val = DAG.getNode(ISD::BITCAST, DL, BuiltVectorTy, Val);\n  }\n\n  // Split the vector into intermediate operands.\n  SmallVector<SDValue, 8> Ops(NumIntermediates);\n  for (unsigned i = 0; i != NumIntermediates; ++i) {\n    if (IntermediateVT.isVector()) {\n      // This does something sensible for scalable vectors - see the\n      // definition of EXTRACT_SUBVECTOR for further details.\n      unsigned IntermediateNumElts = IntermediateVT.getVectorMinNumElements();\n      Ops[i] =\n          DAG.getNode(ISD::EXTRACT_SUBVECTOR, DL, IntermediateVT, Val,\n                      DAG.getVectorIdxConstant(i * IntermediateNumElts, DL));\n    } else {\n      Ops[i] = DAG.getNode(ISD::EXTRACT_VECTOR_ELT, DL, IntermediateVT, Val,\n                           DAG.getVectorIdxConstant(i, DL));\n    }\n  }\n\n  // Split the intermediate operands into legal parts.\n  if (NumParts == NumIntermediates) {\n    // If the register was not expanded, promote or copy the value,\n    // as appropriate.\n    for (unsigned i = 0; i != NumParts; ++i)\n      getCopyToParts(DAG, DL, Ops[i], &Parts[i], 1, PartVT, V, CallConv);\n  } else if (NumParts > 0) {\n    // If the intermediate type was expanded, split each the value into\n    // legal parts.\n    assert(NumIntermediates != 0 && \"division by zero\");\n    assert(NumParts % NumIntermediates == 0 &&\n           \"Must expand into a divisible number of parts!\");\n    unsigned Factor = NumParts / NumIntermediates;\n    for (unsigned i = 0; i != NumIntermediates; ++i)\n      getCopyToParts(DAG, DL, Ops[i], &Parts[i * Factor], Factor, PartVT, V,\n                     CallConv);\n  }\n}\n\nRegsForValue::RegsForValue(const SmallVector<unsigned, 4> &regs, MVT regvt,\n                           EVT valuevt, Optional<CallingConv::ID> CC)\n    : ValueVTs(1, valuevt), RegVTs(1, regvt), Regs(regs),\n      RegCount(1, regs.size()), CallConv(CC) {}\n\nRegsForValue::RegsForValue(LLVMContext &Context, const TargetLowering &TLI,\n                           const DataLayout &DL, unsigned Reg, Type *Ty,\n                           Optional<CallingConv::ID> CC) {\n  ComputeValueVTs(TLI, DL, Ty, ValueVTs);\n\n  CallConv = CC;\n\n  for (EVT ValueVT : ValueVTs) {\n    unsigned NumRegs =\n        isABIMangled()\n            ? TLI.getNumRegistersForCallingConv(Context, CC.getValue(), ValueVT)\n            : TLI.getNumRegisters(Context, ValueVT);\n    MVT RegisterVT =\n        isABIMangled()\n            ? TLI.getRegisterTypeForCallingConv(Context, CC.getValue(), ValueVT)\n            : TLI.getRegisterType(Context, ValueVT);\n    for (unsigned i = 0; i != NumRegs; ++i)\n      Regs.push_back(Reg + i);\n    RegVTs.push_back(RegisterVT);\n    RegCount.push_back(NumRegs);\n    Reg += NumRegs;\n  }\n}\n\nSDValue RegsForValue::getCopyFromRegs(SelectionDAG &DAG,\n                                      FunctionLoweringInfo &FuncInfo,\n                                      const SDLoc &dl, SDValue &Chain,\n                                      SDValue *Flag, const Value *V) const {\n  // A Value with type {} or [0 x %t] needs no registers.\n  if (ValueVTs.empty())\n    return SDValue();\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  // Assemble the legal parts into the final values.\n  SmallVector<SDValue, 4> Values(ValueVTs.size());\n  SmallVector<SDValue, 8> Parts;\n  for (unsigned Value = 0, Part = 0, e = ValueVTs.size(); Value != e; ++Value) {\n    // Copy the legal parts from the registers.\n    EVT ValueVT = ValueVTs[Value];\n    unsigned NumRegs = RegCount[Value];\n    MVT RegisterVT = isABIMangled() ? TLI.getRegisterTypeForCallingConv(\n                                          *DAG.getContext(),\n                                          CallConv.getValue(), RegVTs[Value])\n                                    : RegVTs[Value];\n\n    Parts.resize(NumRegs);\n    for (unsigned i = 0; i != NumRegs; ++i) {\n      SDValue P;\n      if (!Flag) {\n        P = DAG.getCopyFromReg(Chain, dl, Regs[Part+i], RegisterVT);\n      } else {\n        P = DAG.getCopyFromReg(Chain, dl, Regs[Part+i], RegisterVT, *Flag);\n        *Flag = P.getValue(2);\n      }\n\n      Chain = P.getValue(1);\n      Parts[i] = P;\n\n      // If the source register was virtual and if we know something about it,\n      // add an assert node.\n      if (!Register::isVirtualRegister(Regs[Part + i]) ||\n          !RegisterVT.isInteger())\n        continue;\n\n      const FunctionLoweringInfo::LiveOutInfo *LOI =\n        FuncInfo.GetLiveOutRegInfo(Regs[Part+i]);\n      if (!LOI)\n        continue;\n\n      unsigned RegSize = RegisterVT.getScalarSizeInBits();\n      unsigned NumSignBits = LOI->NumSignBits;\n      unsigned NumZeroBits = LOI->Known.countMinLeadingZeros();\n\n      if (NumZeroBits == RegSize) {\n        // The current value is a zero.\n        // Explicitly express that as it would be easier for\n        // optimizations to kick in.\n        Parts[i] = DAG.getConstant(0, dl, RegisterVT);\n        continue;\n      }\n\n      // FIXME: We capture more information than the dag can represent.  For\n      // now, just use the tightest assertzext/assertsext possible.\n      bool isSExt;\n      EVT FromVT(MVT::Other);\n      if (NumZeroBits) {\n        FromVT = EVT::getIntegerVT(*DAG.getContext(), RegSize - NumZeroBits);\n        isSExt = false;\n      } else if (NumSignBits > 1) {\n        FromVT =\n            EVT::getIntegerVT(*DAG.getContext(), RegSize - NumSignBits + 1);\n        isSExt = true;\n      } else {\n        continue;\n      }\n      // Add an assertion node.\n      assert(FromVT != MVT::Other);\n      Parts[i] = DAG.getNode(isSExt ? ISD::AssertSext : ISD::AssertZext, dl,\n                             RegisterVT, P, DAG.getValueType(FromVT));\n    }\n\n    Values[Value] = getCopyFromParts(DAG, dl, Parts.begin(), NumRegs,\n                                     RegisterVT, ValueVT, V, CallConv);\n    Part += NumRegs;\n    Parts.clear();\n  }\n\n  return DAG.getNode(ISD::MERGE_VALUES, dl, DAG.getVTList(ValueVTs), Values);\n}\n\nvoid RegsForValue::getCopyToRegs(SDValue Val, SelectionDAG &DAG,\n                                 const SDLoc &dl, SDValue &Chain, SDValue *Flag,\n                                 const Value *V,\n                                 ISD::NodeType PreferredExtendType) const {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  ISD::NodeType ExtendKind = PreferredExtendType;\n\n  // Get the list of the values's legal parts.\n  unsigned NumRegs = Regs.size();\n  SmallVector<SDValue, 8> Parts(NumRegs);\n  for (unsigned Value = 0, Part = 0, e = ValueVTs.size(); Value != e; ++Value) {\n    unsigned NumParts = RegCount[Value];\n\n    MVT RegisterVT = isABIMangled() ? TLI.getRegisterTypeForCallingConv(\n                                          *DAG.getContext(),\n                                          CallConv.getValue(), RegVTs[Value])\n                                    : RegVTs[Value];\n\n    if (ExtendKind == ISD::ANY_EXTEND && TLI.isZExtFree(Val, RegisterVT))\n      ExtendKind = ISD::ZERO_EXTEND;\n\n    getCopyToParts(DAG, dl, Val.getValue(Val.getResNo() + Value), &Parts[Part],\n                   NumParts, RegisterVT, V, CallConv, ExtendKind);\n    Part += NumParts;\n  }\n\n  // Copy the parts into the registers.\n  SmallVector<SDValue, 8> Chains(NumRegs);\n  for (unsigned i = 0; i != NumRegs; ++i) {\n    SDValue Part;\n    if (!Flag) {\n      Part = DAG.getCopyToReg(Chain, dl, Regs[i], Parts[i]);\n    } else {\n      Part = DAG.getCopyToReg(Chain, dl, Regs[i], Parts[i], *Flag);\n      *Flag = Part.getValue(1);\n    }\n\n    Chains[i] = Part.getValue(0);\n  }\n\n  if (NumRegs == 1 || Flag)\n    // If NumRegs > 1 && Flag is used then the use of the last CopyToReg is\n    // flagged to it. That is the CopyToReg nodes and the user are considered\n    // a single scheduling unit. If we create a TokenFactor and return it as\n    // chain, then the TokenFactor is both a predecessor (operand) of the\n    // user as well as a successor (the TF operands are flagged to the user).\n    // c1, f1 = CopyToReg\n    // c2, f2 = CopyToReg\n    // c3     = TokenFactor c1, c2\n    // ...\n    //        = op c3, ..., f2\n    Chain = Chains[NumRegs-1];\n  else\n    Chain = DAG.getNode(ISD::TokenFactor, dl, MVT::Other, Chains);\n}\n\nvoid RegsForValue::AddInlineAsmOperands(unsigned Code, bool HasMatching,\n                                        unsigned MatchingIdx, const SDLoc &dl,\n                                        SelectionDAG &DAG,\n                                        std::vector<SDValue> &Ops) const {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  unsigned Flag = InlineAsm::getFlagWord(Code, Regs.size());\n  if (HasMatching)\n    Flag = InlineAsm::getFlagWordForMatchingOp(Flag, MatchingIdx);\n  else if (!Regs.empty() && Register::isVirtualRegister(Regs.front())) {\n    // Put the register class of the virtual registers in the flag word.  That\n    // way, later passes can recompute register class constraints for inline\n    // assembly as well as normal instructions.\n    // Don't do this for tied operands that can use the regclass information\n    // from the def.\n    const MachineRegisterInfo &MRI = DAG.getMachineFunction().getRegInfo();\n    const TargetRegisterClass *RC = MRI.getRegClass(Regs.front());\n    Flag = InlineAsm::getFlagWordForRegClass(Flag, RC->getID());\n  }\n\n  SDValue Res = DAG.getTargetConstant(Flag, dl, MVT::i32);\n  Ops.push_back(Res);\n\n  if (Code == InlineAsm::Kind_Clobber) {\n    // Clobbers should always have a 1:1 mapping with registers, and may\n    // reference registers that have illegal (e.g. vector) types. Hence, we\n    // shouldn't try to apply any sort of splitting logic to them.\n    assert(Regs.size() == RegVTs.size() && Regs.size() == ValueVTs.size() &&\n           \"No 1:1 mapping from clobbers to regs?\");\n    Register SP = TLI.getStackPointerRegisterToSaveRestore();\n    (void)SP;\n    for (unsigned I = 0, E = ValueVTs.size(); I != E; ++I) {\n      Ops.push_back(DAG.getRegister(Regs[I], RegVTs[I]));\n      assert(\n          (Regs[I] != SP ||\n           DAG.getMachineFunction().getFrameInfo().hasOpaqueSPAdjustment()) &&\n          \"If we clobbered the stack pointer, MFI should know about it.\");\n    }\n    return;\n  }\n\n  for (unsigned Value = 0, Reg = 0, e = ValueVTs.size(); Value != e; ++Value) {\n    unsigned NumRegs = TLI.getNumRegisters(*DAG.getContext(), ValueVTs[Value]);\n    MVT RegisterVT = RegVTs[Value];\n    for (unsigned i = 0; i != NumRegs; ++i) {\n      assert(Reg < Regs.size() && \"Mismatch in # registers expected\");\n      unsigned TheReg = Regs[Reg++];\n      Ops.push_back(DAG.getRegister(TheReg, RegisterVT));\n    }\n  }\n}\n\nSmallVector<std::pair<unsigned, TypeSize>, 4>\nRegsForValue::getRegsAndSizes() const {\n  SmallVector<std::pair<unsigned, TypeSize>, 4> OutVec;\n  unsigned I = 0;\n  for (auto CountAndVT : zip_first(RegCount, RegVTs)) {\n    unsigned RegCount = std::get<0>(CountAndVT);\n    MVT RegisterVT = std::get<1>(CountAndVT);\n    TypeSize RegisterSize = RegisterVT.getSizeInBits();\n    for (unsigned E = I + RegCount; I != E; ++I)\n      OutVec.push_back(std::make_pair(Regs[I], RegisterSize));\n  }\n  return OutVec;\n}\n\nvoid SelectionDAGBuilder::init(GCFunctionInfo *gfi, AliasAnalysis *aa,\n                               const TargetLibraryInfo *li) {\n  AA = aa;\n  GFI = gfi;\n  LibInfo = li;\n  DL = &DAG.getDataLayout();\n  Context = DAG.getContext();\n  LPadToCallSiteMap.clear();\n  SL->init(DAG.getTargetLoweringInfo(), TM, DAG.getDataLayout());\n}\n\nvoid SelectionDAGBuilder::clear() {\n  NodeMap.clear();\n  UnusedArgNodeMap.clear();\n  PendingLoads.clear();\n  PendingExports.clear();\n  PendingConstrainedFP.clear();\n  PendingConstrainedFPStrict.clear();\n  CurInst = nullptr;\n  HasTailCall = false;\n  SDNodeOrder = LowestSDNodeOrder;\n  StatepointLowering.clear();\n}\n\nvoid SelectionDAGBuilder::clearDanglingDebugInfo() {\n  DanglingDebugInfoMap.clear();\n}\n\n// Update DAG root to include dependencies on Pending chains.\nSDValue SelectionDAGBuilder::updateRoot(SmallVectorImpl<SDValue> &Pending) {\n  SDValue Root = DAG.getRoot();\n\n  if (Pending.empty())\n    return Root;\n\n  // Add current root to PendingChains, unless we already indirectly\n  // depend on it.\n  if (Root.getOpcode() != ISD::EntryToken) {\n    unsigned i = 0, e = Pending.size();\n    for (; i != e; ++i) {\n      assert(Pending[i].getNode()->getNumOperands() > 1);\n      if (Pending[i].getNode()->getOperand(0) == Root)\n        break;  // Don't add the root if we already indirectly depend on it.\n    }\n\n    if (i == e)\n      Pending.push_back(Root);\n  }\n\n  if (Pending.size() == 1)\n    Root = Pending[0];\n  else\n    Root = DAG.getTokenFactor(getCurSDLoc(), Pending);\n\n  DAG.setRoot(Root);\n  Pending.clear();\n  return Root;\n}\n\nSDValue SelectionDAGBuilder::getMemoryRoot() {\n  return updateRoot(PendingLoads);\n}\n\nSDValue SelectionDAGBuilder::getRoot() {\n  // Chain up all pending constrained intrinsics together with all\n  // pending loads, by simply appending them to PendingLoads and\n  // then calling getMemoryRoot().\n  PendingLoads.reserve(PendingLoads.size() +\n                       PendingConstrainedFP.size() +\n                       PendingConstrainedFPStrict.size());\n  PendingLoads.append(PendingConstrainedFP.begin(),\n                      PendingConstrainedFP.end());\n  PendingLoads.append(PendingConstrainedFPStrict.begin(),\n                      PendingConstrainedFPStrict.end());\n  PendingConstrainedFP.clear();\n  PendingConstrainedFPStrict.clear();\n  return getMemoryRoot();\n}\n\nSDValue SelectionDAGBuilder::getControlRoot() {\n  // We need to emit pending fpexcept.strict constrained intrinsics,\n  // so append them to the PendingExports list.\n  PendingExports.append(PendingConstrainedFPStrict.begin(),\n                        PendingConstrainedFPStrict.end());\n  PendingConstrainedFPStrict.clear();\n  return updateRoot(PendingExports);\n}\n\nvoid SelectionDAGBuilder::visit(const Instruction &I) {\n  // Set up outgoing PHI node register values before emitting the terminator.\n  if (I.isTerminator()) {\n    HandlePHINodesInSuccessorBlocks(I.getParent());\n  }\n\n  // Increase the SDNodeOrder if dealing with a non-debug instruction.\n  if (!isa<DbgInfoIntrinsic>(I))\n    ++SDNodeOrder;\n\n  CurInst = &I;\n\n  visit(I.getOpcode(), I);\n\n  if (!I.isTerminator() && !HasTailCall &&\n      !isa<GCStatepointInst>(I)) // statepoints handle their exports internally\n    CopyToExportRegsIfNeeded(&I);\n\n  CurInst = nullptr;\n}\n\nvoid SelectionDAGBuilder::visitPHI(const PHINode &) {\n  llvm_unreachable(\"SelectionDAGBuilder shouldn't visit PHI nodes!\");\n}\n\nvoid SelectionDAGBuilder::visit(unsigned Opcode, const User &I) {\n  // Note: this doesn't use InstVisitor, because it has to work with\n  // ConstantExpr's in addition to instructions.\n  switch (Opcode) {\n  default: llvm_unreachable(\"Unknown instruction type encountered!\");\n    // Build the switch statement using the Instruction.def file.\n#define HANDLE_INST(NUM, OPCODE, CLASS) \\\n    case Instruction::OPCODE: visit##OPCODE((const CLASS&)I); break;\n#include \"llvm/IR/Instruction.def\"\n  }\n}\n\nvoid SelectionDAGBuilder::dropDanglingDebugInfo(const DILocalVariable *Variable,\n                                                const DIExpression *Expr) {\n  auto isMatchingDbgValue = [&](DanglingDebugInfo &DDI) {\n    const DbgValueInst *DI = DDI.getDI();\n    DIVariable *DanglingVariable = DI->getVariable();\n    DIExpression *DanglingExpr = DI->getExpression();\n    if (DanglingVariable == Variable && Expr->fragmentsOverlap(DanglingExpr)) {\n      LLVM_DEBUG(dbgs() << \"Dropping dangling debug info for \" << *DI << \"\\n\");\n      return true;\n    }\n    return false;\n  };\n\n  for (auto &DDIMI : DanglingDebugInfoMap) {\n    DanglingDebugInfoVector &DDIV = DDIMI.second;\n\n    // If debug info is to be dropped, run it through final checks to see\n    // whether it can be salvaged.\n    for (auto &DDI : DDIV)\n      if (isMatchingDbgValue(DDI))\n        salvageUnresolvedDbgValue(DDI);\n\n    erase_if(DDIV, isMatchingDbgValue);\n  }\n}\n\n// resolveDanglingDebugInfo - if we saw an earlier dbg_value referring to V,\n// generate the debug data structures now that we've seen its definition.\nvoid SelectionDAGBuilder::resolveDanglingDebugInfo(const Value *V,\n                                                   SDValue Val) {\n  auto DanglingDbgInfoIt = DanglingDebugInfoMap.find(V);\n  if (DanglingDbgInfoIt == DanglingDebugInfoMap.end())\n    return;\n\n  DanglingDebugInfoVector &DDIV = DanglingDbgInfoIt->second;\n  for (auto &DDI : DDIV) {\n    const DbgValueInst *DI = DDI.getDI();\n    assert(DI && \"Ill-formed DanglingDebugInfo\");\n    DebugLoc dl = DDI.getdl();\n    unsigned ValSDNodeOrder = Val.getNode()->getIROrder();\n    unsigned DbgSDNodeOrder = DDI.getSDNodeOrder();\n    DILocalVariable *Variable = DI->getVariable();\n    DIExpression *Expr = DI->getExpression();\n    assert(Variable->isValidLocationForIntrinsic(dl) &&\n           \"Expected inlined-at fields to agree\");\n    SDDbgValue *SDV;\n    if (Val.getNode()) {\n      // FIXME: I doubt that it is correct to resolve a dangling DbgValue as a\n      // FuncArgumentDbgValue (it would be hoisted to the function entry, and if\n      // we couldn't resolve it directly when examining the DbgValue intrinsic\n      // in the first place we should not be more successful here). Unless we\n      // have some test case that prove this to be correct we should avoid\n      // calling EmitFuncArgumentDbgValue here.\n      if (!EmitFuncArgumentDbgValue(V, Variable, Expr, dl, false, Val)) {\n        LLVM_DEBUG(dbgs() << \"Resolve dangling debug info [order=\"\n                          << DbgSDNodeOrder << \"] for:\\n  \" << *DI << \"\\n\");\n        LLVM_DEBUG(dbgs() << \"  By mapping to:\\n    \"; Val.dump());\n        // Increase the SDNodeOrder for the DbgValue here to make sure it is\n        // inserted after the definition of Val when emitting the instructions\n        // after ISel. An alternative could be to teach\n        // ScheduleDAGSDNodes::EmitSchedule to delay the insertion properly.\n        LLVM_DEBUG(if (ValSDNodeOrder > DbgSDNodeOrder) dbgs()\n                   << \"changing SDNodeOrder from \" << DbgSDNodeOrder << \" to \"\n                   << ValSDNodeOrder << \"\\n\");\n        SDV = getDbgValue(Val, Variable, Expr, dl,\n                          std::max(DbgSDNodeOrder, ValSDNodeOrder));\n        DAG.AddDbgValue(SDV, Val.getNode(), false);\n      } else\n        LLVM_DEBUG(dbgs() << \"Resolved dangling debug info for \" << *DI\n                          << \"in EmitFuncArgumentDbgValue\\n\");\n    } else {\n      LLVM_DEBUG(dbgs() << \"Dropping debug info for \" << *DI << \"\\n\");\n      auto Undef =\n          UndefValue::get(DDI.getDI()->getVariableLocation()->getType());\n      auto SDV =\n          DAG.getConstantDbgValue(Variable, Expr, Undef, dl, DbgSDNodeOrder);\n      DAG.AddDbgValue(SDV, nullptr, false);\n    }\n  }\n  DDIV.clear();\n}\n\nvoid SelectionDAGBuilder::salvageUnresolvedDbgValue(DanglingDebugInfo &DDI) {\n  Value *V = DDI.getDI()->getValue();\n  DILocalVariable *Var = DDI.getDI()->getVariable();\n  DIExpression *Expr = DDI.getDI()->getExpression();\n  DebugLoc DL = DDI.getdl();\n  DebugLoc InstDL = DDI.getDI()->getDebugLoc();\n  unsigned SDOrder = DDI.getSDNodeOrder();\n\n  // Currently we consider only dbg.value intrinsics -- we tell the salvager\n  // that DW_OP_stack_value is desired.\n  assert(isa<DbgValueInst>(DDI.getDI()));\n  bool StackValue = true;\n\n  // Can this Value can be encoded without any further work?\n  if (handleDebugValue(V, Var, Expr, DL, InstDL, SDOrder))\n    return;\n\n  // Attempt to salvage back through as many instructions as possible. Bail if\n  // a non-instruction is seen, such as a constant expression or global\n  // variable. FIXME: Further work could recover those too.\n  while (isa<Instruction>(V)) {\n    Instruction &VAsInst = *cast<Instruction>(V);\n    DIExpression *NewExpr = salvageDebugInfoImpl(VAsInst, Expr, StackValue);\n\n    // If we cannot salvage any further, and haven't yet found a suitable debug\n    // expression, bail out.\n    if (!NewExpr)\n      break;\n\n    // New value and expr now represent this debuginfo.\n    V = VAsInst.getOperand(0);\n    Expr = NewExpr;\n\n    // Some kind of simplification occurred: check whether the operand of the\n    // salvaged debug expression can be encoded in this DAG.\n    if (handleDebugValue(V, Var, Expr, DL, InstDL, SDOrder)) {\n      LLVM_DEBUG(dbgs() << \"Salvaged debug location info for:\\n  \"\n                        << DDI.getDI() << \"\\nBy stripping back to:\\n  \" << V);\n      return;\n    }\n  }\n\n  // This was the final opportunity to salvage this debug information, and it\n  // couldn't be done. Place an undef DBG_VALUE at this location to terminate\n  // any earlier variable location.\n  auto Undef = UndefValue::get(DDI.getDI()->getVariableLocation()->getType());\n  auto SDV = DAG.getConstantDbgValue(Var, Expr, Undef, DL, SDNodeOrder);\n  DAG.AddDbgValue(SDV, nullptr, false);\n\n  LLVM_DEBUG(dbgs() << \"Dropping debug value info for:\\n  \" << DDI.getDI()\n                    << \"\\n\");\n  LLVM_DEBUG(dbgs() << \"  Last seen at:\\n    \" << *DDI.getDI()->getOperand(0)\n                    << \"\\n\");\n}\n\nbool SelectionDAGBuilder::handleDebugValue(const Value *V, DILocalVariable *Var,\n                                           DIExpression *Expr, DebugLoc dl,\n                                           DebugLoc InstDL, unsigned Order) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDDbgValue *SDV;\n  if (isa<ConstantInt>(V) || isa<ConstantFP>(V) || isa<UndefValue>(V) ||\n      isa<ConstantPointerNull>(V)) {\n    SDV = DAG.getConstantDbgValue(Var, Expr, V, dl, SDNodeOrder);\n    DAG.AddDbgValue(SDV, nullptr, false);\n    return true;\n  }\n\n  // If the Value is a frame index, we can create a FrameIndex debug value\n  // without relying on the DAG at all.\n  if (const AllocaInst *AI = dyn_cast<AllocaInst>(V)) {\n    auto SI = FuncInfo.StaticAllocaMap.find(AI);\n    if (SI != FuncInfo.StaticAllocaMap.end()) {\n      auto SDV =\n          DAG.getFrameIndexDbgValue(Var, Expr, SI->second,\n                                    /*IsIndirect*/ false, dl, SDNodeOrder);\n      // Do not attach the SDNodeDbgValue to an SDNode: this variable location\n      // is still available even if the SDNode gets optimized out.\n      DAG.AddDbgValue(SDV, nullptr, false);\n      return true;\n    }\n  }\n\n  // Do not use getValue() in here; we don't want to generate code at\n  // this point if it hasn't been done yet.\n  SDValue N = NodeMap[V];\n  if (!N.getNode() && isa<Argument>(V)) // Check unused arguments map.\n    N = UnusedArgNodeMap[V];\n  if (N.getNode()) {\n    if (EmitFuncArgumentDbgValue(V, Var, Expr, dl, false, N))\n      return true;\n    SDV = getDbgValue(N, Var, Expr, dl, SDNodeOrder);\n    DAG.AddDbgValue(SDV, N.getNode(), false);\n    return true;\n  }\n\n  // Special rules apply for the first dbg.values of parameter variables in a\n  // function. Identify them by the fact they reference Argument Values, that\n  // they're parameters, and they are parameters of the current function. We\n  // need to let them dangle until they get an SDNode.\n  bool IsParamOfFunc = isa<Argument>(V) && Var->isParameter() &&\n                       !InstDL.getInlinedAt();\n  if (!IsParamOfFunc) {\n    // The value is not used in this block yet (or it would have an SDNode).\n    // We still want the value to appear for the user if possible -- if it has\n    // an associated VReg, we can refer to that instead.\n    auto VMI = FuncInfo.ValueMap.find(V);\n    if (VMI != FuncInfo.ValueMap.end()) {\n      unsigned Reg = VMI->second;\n      // If this is a PHI node, it may be split up into several MI PHI nodes\n      // (in FunctionLoweringInfo::set).\n      RegsForValue RFV(V->getContext(), TLI, DAG.getDataLayout(), Reg,\n                       V->getType(), None);\n      if (RFV.occupiesMultipleRegs()) {\n        unsigned Offset = 0;\n        unsigned BitsToDescribe = 0;\n        if (auto VarSize = Var->getSizeInBits())\n          BitsToDescribe = *VarSize;\n        if (auto Fragment = Expr->getFragmentInfo())\n          BitsToDescribe = Fragment->SizeInBits;\n        for (auto RegAndSize : RFV.getRegsAndSizes()) {\n          unsigned RegisterSize = RegAndSize.second;\n          // Bail out if all bits are described already.\n          if (Offset >= BitsToDescribe)\n            break;\n          unsigned FragmentSize = (Offset + RegisterSize > BitsToDescribe)\n              ? BitsToDescribe - Offset\n              : RegisterSize;\n          auto FragmentExpr = DIExpression::createFragmentExpression(\n              Expr, Offset, FragmentSize);\n          if (!FragmentExpr)\n              continue;\n          SDV = DAG.getVRegDbgValue(Var, *FragmentExpr, RegAndSize.first,\n                                    false, dl, SDNodeOrder);\n          DAG.AddDbgValue(SDV, nullptr, false);\n          Offset += RegisterSize;\n        }\n      } else {\n        SDV = DAG.getVRegDbgValue(Var, Expr, Reg, false, dl, SDNodeOrder);\n        DAG.AddDbgValue(SDV, nullptr, false);\n      }\n      return true;\n    }\n  }\n\n  return false;\n}\n\nvoid SelectionDAGBuilder::resolveOrClearDbgInfo() {\n  // Try to fixup any remaining dangling debug info -- and drop it if we can't.\n  for (auto &Pair : DanglingDebugInfoMap)\n    for (auto &DDI : Pair.second)\n      salvageUnresolvedDbgValue(DDI);\n  clearDanglingDebugInfo();\n}\n\n/// getCopyFromRegs - If there was virtual register allocated for the value V\n/// emit CopyFromReg of the specified type Ty. Return empty SDValue() otherwise.\nSDValue SelectionDAGBuilder::getCopyFromRegs(const Value *V, Type *Ty) {\n  DenseMap<const Value *, Register>::iterator It = FuncInfo.ValueMap.find(V);\n  SDValue Result;\n\n  if (It != FuncInfo.ValueMap.end()) {\n    Register InReg = It->second;\n\n    RegsForValue RFV(*DAG.getContext(), DAG.getTargetLoweringInfo(),\n                     DAG.getDataLayout(), InReg, Ty,\n                     None); // This is not an ABI copy.\n    SDValue Chain = DAG.getEntryNode();\n    Result = RFV.getCopyFromRegs(DAG, FuncInfo, getCurSDLoc(), Chain, nullptr,\n                                 V);\n    resolveDanglingDebugInfo(V, Result);\n  }\n\n  return Result;\n}\n\n/// getValue - Return an SDValue for the given Value.\nSDValue SelectionDAGBuilder::getValue(const Value *V) {\n  // If we already have an SDValue for this value, use it. It's important\n  // to do this first, so that we don't create a CopyFromReg if we already\n  // have a regular SDValue.\n  SDValue &N = NodeMap[V];\n  if (N.getNode()) return N;\n\n  // If there's a virtual register allocated and initialized for this\n  // value, use it.\n  if (SDValue copyFromReg = getCopyFromRegs(V, V->getType()))\n    return copyFromReg;\n\n  // Otherwise create a new SDValue and remember it.\n  SDValue Val = getValueImpl(V);\n  NodeMap[V] = Val;\n  resolveDanglingDebugInfo(V, Val);\n  return Val;\n}\n\n/// getNonRegisterValue - Return an SDValue for the given Value, but\n/// don't look in FuncInfo.ValueMap for a virtual register.\nSDValue SelectionDAGBuilder::getNonRegisterValue(const Value *V) {\n  // If we already have an SDValue for this value, use it.\n  SDValue &N = NodeMap[V];\n  if (N.getNode()) {\n    if (isa<ConstantSDNode>(N) || isa<ConstantFPSDNode>(N)) {\n      // Remove the debug location from the node as the node is about to be used\n      // in a location which may differ from the original debug location.  This\n      // is relevant to Constant and ConstantFP nodes because they can appear\n      // as constant expressions inside PHI nodes.\n      N->setDebugLoc(DebugLoc());\n    }\n    return N;\n  }\n\n  // Otherwise create a new SDValue and remember it.\n  SDValue Val = getValueImpl(V);\n  NodeMap[V] = Val;\n  resolveDanglingDebugInfo(V, Val);\n  return Val;\n}\n\n/// getValueImpl - Helper function for getValue and getNonRegisterValue.\n/// Create an SDValue for the given value.\nSDValue SelectionDAGBuilder::getValueImpl(const Value *V) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  if (const Constant *C = dyn_cast<Constant>(V)) {\n    EVT VT = TLI.getValueType(DAG.getDataLayout(), V->getType(), true);\n\n    if (const ConstantInt *CI = dyn_cast<ConstantInt>(C))\n      return DAG.getConstant(*CI, getCurSDLoc(), VT);\n\n    if (const GlobalValue *GV = dyn_cast<GlobalValue>(C))\n      return DAG.getGlobalAddress(GV, getCurSDLoc(), VT);\n\n    if (isa<ConstantPointerNull>(C)) {\n      unsigned AS = V->getType()->getPointerAddressSpace();\n      return DAG.getConstant(0, getCurSDLoc(),\n                             TLI.getPointerTy(DAG.getDataLayout(), AS));\n    }\n\n    if (match(C, m_VScale(DAG.getDataLayout())))\n      return DAG.getVScale(getCurSDLoc(), VT, APInt(VT.getSizeInBits(), 1));\n\n    if (const ConstantFP *CFP = dyn_cast<ConstantFP>(C))\n      return DAG.getConstantFP(*CFP, getCurSDLoc(), VT);\n\n    if (isa<UndefValue>(C) && !V->getType()->isAggregateType())\n      return DAG.getUNDEF(VT);\n\n    if (const ConstantExpr *CE = dyn_cast<ConstantExpr>(C)) {\n      visit(CE->getOpcode(), *CE);\n      SDValue N1 = NodeMap[V];\n      assert(N1.getNode() && \"visit didn't populate the NodeMap!\");\n      return N1;\n    }\n\n    if (isa<ConstantStruct>(C) || isa<ConstantArray>(C)) {\n      SmallVector<SDValue, 4> Constants;\n      for (User::const_op_iterator OI = C->op_begin(), OE = C->op_end();\n           OI != OE; ++OI) {\n        SDNode *Val = getValue(*OI).getNode();\n        // If the operand is an empty aggregate, there are no values.\n        if (!Val) continue;\n        // Add each leaf value from the operand to the Constants list\n        // to form a flattened list of all the values.\n        for (unsigned i = 0, e = Val->getNumValues(); i != e; ++i)\n          Constants.push_back(SDValue(Val, i));\n      }\n\n      return DAG.getMergeValues(Constants, getCurSDLoc());\n    }\n\n    if (const ConstantDataSequential *CDS =\n          dyn_cast<ConstantDataSequential>(C)) {\n      SmallVector<SDValue, 4> Ops;\n      for (unsigned i = 0, e = CDS->getNumElements(); i != e; ++i) {\n        SDNode *Val = getValue(CDS->getElementAsConstant(i)).getNode();\n        // Add each leaf value from the operand to the Constants list\n        // to form a flattened list of all the values.\n        for (unsigned i = 0, e = Val->getNumValues(); i != e; ++i)\n          Ops.push_back(SDValue(Val, i));\n      }\n\n      if (isa<ArrayType>(CDS->getType()))\n        return DAG.getMergeValues(Ops, getCurSDLoc());\n      return NodeMap[V] = DAG.getBuildVector(VT, getCurSDLoc(), Ops);\n    }\n\n    if (C->getType()->isStructTy() || C->getType()->isArrayTy()) {\n      assert((isa<ConstantAggregateZero>(C) || isa<UndefValue>(C)) &&\n             \"Unknown struct or array constant!\");\n\n      SmallVector<EVT, 4> ValueVTs;\n      ComputeValueVTs(TLI, DAG.getDataLayout(), C->getType(), ValueVTs);\n      unsigned NumElts = ValueVTs.size();\n      if (NumElts == 0)\n        return SDValue(); // empty struct\n      SmallVector<SDValue, 4> Constants(NumElts);\n      for (unsigned i = 0; i != NumElts; ++i) {\n        EVT EltVT = ValueVTs[i];\n        if (isa<UndefValue>(C))\n          Constants[i] = DAG.getUNDEF(EltVT);\n        else if (EltVT.isFloatingPoint())\n          Constants[i] = DAG.getConstantFP(0, getCurSDLoc(), EltVT);\n        else\n          Constants[i] = DAG.getConstant(0, getCurSDLoc(), EltVT);\n      }\n\n      return DAG.getMergeValues(Constants, getCurSDLoc());\n    }\n\n    if (const BlockAddress *BA = dyn_cast<BlockAddress>(C))\n      return DAG.getBlockAddress(BA, VT);\n\n    if (const auto *Equiv = dyn_cast<DSOLocalEquivalent>(C))\n      return getValue(Equiv->getGlobalValue());\n\n    VectorType *VecTy = cast<VectorType>(V->getType());\n\n    // Now that we know the number and type of the elements, get that number of\n    // elements into the Ops array based on what kind of constant it is.\n    if (const ConstantVector *CV = dyn_cast<ConstantVector>(C)) {\n      SmallVector<SDValue, 16> Ops;\n      unsigned NumElements = cast<FixedVectorType>(VecTy)->getNumElements();\n      for (unsigned i = 0; i != NumElements; ++i)\n        Ops.push_back(getValue(CV->getOperand(i)));\n\n      return NodeMap[V] = DAG.getBuildVector(VT, getCurSDLoc(), Ops);\n    } else if (isa<ConstantAggregateZero>(C)) {\n      EVT EltVT =\n          TLI.getValueType(DAG.getDataLayout(), VecTy->getElementType());\n\n      SDValue Op;\n      if (EltVT.isFloatingPoint())\n        Op = DAG.getConstantFP(0, getCurSDLoc(), EltVT);\n      else\n        Op = DAG.getConstant(0, getCurSDLoc(), EltVT);\n\n      if (isa<ScalableVectorType>(VecTy))\n        return NodeMap[V] = DAG.getSplatVector(VT, getCurSDLoc(), Op);\n      else {\n        SmallVector<SDValue, 16> Ops;\n        Ops.assign(cast<FixedVectorType>(VecTy)->getNumElements(), Op);\n        return NodeMap[V] = DAG.getBuildVector(VT, getCurSDLoc(), Ops);\n      }\n    }\n    llvm_unreachable(\"Unknown vector constant\");\n  }\n\n  // If this is a static alloca, generate it as the frameindex instead of\n  // computation.\n  if (const AllocaInst *AI = dyn_cast<AllocaInst>(V)) {\n    DenseMap<const AllocaInst*, int>::iterator SI =\n      FuncInfo.StaticAllocaMap.find(AI);\n    if (SI != FuncInfo.StaticAllocaMap.end())\n      return DAG.getFrameIndex(SI->second,\n                               TLI.getFrameIndexTy(DAG.getDataLayout()));\n  }\n\n  // If this is an instruction which fast-isel has deferred, select it now.\n  if (const Instruction *Inst = dyn_cast<Instruction>(V)) {\n    unsigned InReg = FuncInfo.InitializeRegForValue(Inst);\n\n    RegsForValue RFV(*DAG.getContext(), TLI, DAG.getDataLayout(), InReg,\n                     Inst->getType(), None);\n    SDValue Chain = DAG.getEntryNode();\n    return RFV.getCopyFromRegs(DAG, FuncInfo, getCurSDLoc(), Chain, nullptr, V);\n  }\n\n  if (const MetadataAsValue *MD = dyn_cast<MetadataAsValue>(V)) {\n    return DAG.getMDNode(cast<MDNode>(MD->getMetadata()));\n  }\n  llvm_unreachable(\"Can't get register for value!\");\n}\n\nvoid SelectionDAGBuilder::visitCatchPad(const CatchPadInst &I) {\n  auto Pers = classifyEHPersonality(FuncInfo.Fn->getPersonalityFn());\n  bool IsMSVCCXX = Pers == EHPersonality::MSVC_CXX;\n  bool IsCoreCLR = Pers == EHPersonality::CoreCLR;\n  bool IsSEH = isAsynchronousEHPersonality(Pers);\n  MachineBasicBlock *CatchPadMBB = FuncInfo.MBB;\n  if (!IsSEH)\n    CatchPadMBB->setIsEHScopeEntry();\n  // In MSVC C++ and CoreCLR, catchblocks are funclets and need prologues.\n  if (IsMSVCCXX || IsCoreCLR)\n    CatchPadMBB->setIsEHFuncletEntry();\n}\n\nvoid SelectionDAGBuilder::visitCatchRet(const CatchReturnInst &I) {\n  // Update machine-CFG edge.\n  MachineBasicBlock *TargetMBB = FuncInfo.MBBMap[I.getSuccessor()];\n  FuncInfo.MBB->addSuccessor(TargetMBB);\n\n  auto Pers = classifyEHPersonality(FuncInfo.Fn->getPersonalityFn());\n  bool IsSEH = isAsynchronousEHPersonality(Pers);\n  if (IsSEH) {\n    // If this is not a fall-through branch or optimizations are switched off,\n    // emit the branch.\n    if (TargetMBB != NextBlock(FuncInfo.MBB) ||\n        TM.getOptLevel() == CodeGenOpt::None)\n      DAG.setRoot(DAG.getNode(ISD::BR, getCurSDLoc(), MVT::Other,\n                              getControlRoot(), DAG.getBasicBlock(TargetMBB)));\n    return;\n  }\n\n  // Figure out the funclet membership for the catchret's successor.\n  // This will be used by the FuncletLayout pass to determine how to order the\n  // BB's.\n  // A 'catchret' returns to the outer scope's color.\n  Value *ParentPad = I.getCatchSwitchParentPad();\n  const BasicBlock *SuccessorColor;\n  if (isa<ConstantTokenNone>(ParentPad))\n    SuccessorColor = &FuncInfo.Fn->getEntryBlock();\n  else\n    SuccessorColor = cast<Instruction>(ParentPad)->getParent();\n  assert(SuccessorColor && \"No parent funclet for catchret!\");\n  MachineBasicBlock *SuccessorColorMBB = FuncInfo.MBBMap[SuccessorColor];\n  assert(SuccessorColorMBB && \"No MBB for SuccessorColor!\");\n\n  // Create the terminator node.\n  SDValue Ret = DAG.getNode(ISD::CATCHRET, getCurSDLoc(), MVT::Other,\n                            getControlRoot(), DAG.getBasicBlock(TargetMBB),\n                            DAG.getBasicBlock(SuccessorColorMBB));\n  DAG.setRoot(Ret);\n}\n\nvoid SelectionDAGBuilder::visitCleanupPad(const CleanupPadInst &CPI) {\n  // Don't emit any special code for the cleanuppad instruction. It just marks\n  // the start of an EH scope/funclet.\n  FuncInfo.MBB->setIsEHScopeEntry();\n  auto Pers = classifyEHPersonality(FuncInfo.Fn->getPersonalityFn());\n  if (Pers != EHPersonality::Wasm_CXX) {\n    FuncInfo.MBB->setIsEHFuncletEntry();\n    FuncInfo.MBB->setIsCleanupFuncletEntry();\n  }\n}\n\n// In wasm EH, even though a catchpad may not catch an exception if a tag does\n// not match, it is OK to add only the first unwind destination catchpad to the\n// successors, because there will be at least one invoke instruction within the\n// catch scope that points to the next unwind destination, if one exists, so\n// CFGSort cannot mess up with BB sorting order.\n// (All catchpads with 'catch (type)' clauses have a 'llvm.rethrow' intrinsic\n// call within them, and catchpads only consisting of 'catch (...)' have a\n// '__cxa_end_catch' call within them, both of which generate invokes in case\n// the next unwind destination exists, i.e., the next unwind destination is not\n// the caller.)\n//\n// Having at most one EH pad successor is also simpler and helps later\n// transformations.\n//\n// For example,\n// current:\n//   invoke void @foo to ... unwind label %catch.dispatch\n// catch.dispatch:\n//   %0 = catchswitch within ... [label %catch.start] unwind label %next\n// catch.start:\n//   ...\n//   ... in this BB or some other child BB dominated by this BB there will be an\n//   invoke that points to 'next' BB as an unwind destination\n//\n// next: ; We don't need to add this to 'current' BB's successor\n//   ...\nstatic void findWasmUnwindDestinations(\n    FunctionLoweringInfo &FuncInfo, const BasicBlock *EHPadBB,\n    BranchProbability Prob,\n    SmallVectorImpl<std::pair<MachineBasicBlock *, BranchProbability>>\n        &UnwindDests) {\n  while (EHPadBB) {\n    const Instruction *Pad = EHPadBB->getFirstNonPHI();\n    if (isa<CleanupPadInst>(Pad)) {\n      // Stop on cleanup pads.\n      UnwindDests.emplace_back(FuncInfo.MBBMap[EHPadBB], Prob);\n      UnwindDests.back().first->setIsEHScopeEntry();\n      break;\n    } else if (auto *CatchSwitch = dyn_cast<CatchSwitchInst>(Pad)) {\n      // Add the catchpad handlers to the possible destinations. We don't\n      // continue to the unwind destination of the catchswitch for wasm.\n      for (const BasicBlock *CatchPadBB : CatchSwitch->handlers()) {\n        UnwindDests.emplace_back(FuncInfo.MBBMap[CatchPadBB], Prob);\n        UnwindDests.back().first->setIsEHScopeEntry();\n      }\n      break;\n    } else {\n      continue;\n    }\n  }\n}\n\n/// When an invoke or a cleanupret unwinds to the next EH pad, there are\n/// many places it could ultimately go. In the IR, we have a single unwind\n/// destination, but in the machine CFG, we enumerate all the possible blocks.\n/// This function skips over imaginary basic blocks that hold catchswitch\n/// instructions, and finds all the \"real\" machine\n/// basic block destinations. As those destinations may not be successors of\n/// EHPadBB, here we also calculate the edge probability to those destinations.\n/// The passed-in Prob is the edge probability to EHPadBB.\nstatic void findUnwindDestinations(\n    FunctionLoweringInfo &FuncInfo, const BasicBlock *EHPadBB,\n    BranchProbability Prob,\n    SmallVectorImpl<std::pair<MachineBasicBlock *, BranchProbability>>\n        &UnwindDests) {\n  EHPersonality Personality =\n    classifyEHPersonality(FuncInfo.Fn->getPersonalityFn());\n  bool IsMSVCCXX = Personality == EHPersonality::MSVC_CXX;\n  bool IsCoreCLR = Personality == EHPersonality::CoreCLR;\n  bool IsWasmCXX = Personality == EHPersonality::Wasm_CXX;\n  bool IsSEH = isAsynchronousEHPersonality(Personality);\n\n  if (IsWasmCXX) {\n    findWasmUnwindDestinations(FuncInfo, EHPadBB, Prob, UnwindDests);\n    assert(UnwindDests.size() <= 1 &&\n           \"There should be at most one unwind destination for wasm\");\n    return;\n  }\n\n  while (EHPadBB) {\n    const Instruction *Pad = EHPadBB->getFirstNonPHI();\n    BasicBlock *NewEHPadBB = nullptr;\n    if (isa<LandingPadInst>(Pad)) {\n      // Stop on landingpads. They are not funclets.\n      UnwindDests.emplace_back(FuncInfo.MBBMap[EHPadBB], Prob);\n      break;\n    } else if (isa<CleanupPadInst>(Pad)) {\n      // Stop on cleanup pads. Cleanups are always funclet entries for all known\n      // personalities.\n      UnwindDests.emplace_back(FuncInfo.MBBMap[EHPadBB], Prob);\n      UnwindDests.back().first->setIsEHScopeEntry();\n      UnwindDests.back().first->setIsEHFuncletEntry();\n      break;\n    } else if (auto *CatchSwitch = dyn_cast<CatchSwitchInst>(Pad)) {\n      // Add the catchpad handlers to the possible destinations.\n      for (const BasicBlock *CatchPadBB : CatchSwitch->handlers()) {\n        UnwindDests.emplace_back(FuncInfo.MBBMap[CatchPadBB], Prob);\n        // For MSVC++ and the CLR, catchblocks are funclets and need prologues.\n        if (IsMSVCCXX || IsCoreCLR)\n          UnwindDests.back().first->setIsEHFuncletEntry();\n        if (!IsSEH)\n          UnwindDests.back().first->setIsEHScopeEntry();\n      }\n      NewEHPadBB = CatchSwitch->getUnwindDest();\n    } else {\n      continue;\n    }\n\n    BranchProbabilityInfo *BPI = FuncInfo.BPI;\n    if (BPI && NewEHPadBB)\n      Prob *= BPI->getEdgeProbability(EHPadBB, NewEHPadBB);\n    EHPadBB = NewEHPadBB;\n  }\n}\n\nvoid SelectionDAGBuilder::visitCleanupRet(const CleanupReturnInst &I) {\n  // Update successor info.\n  SmallVector<std::pair<MachineBasicBlock *, BranchProbability>, 1> UnwindDests;\n  auto UnwindDest = I.getUnwindDest();\n  BranchProbabilityInfo *BPI = FuncInfo.BPI;\n  BranchProbability UnwindDestProb =\n      (BPI && UnwindDest)\n          ? BPI->getEdgeProbability(FuncInfo.MBB->getBasicBlock(), UnwindDest)\n          : BranchProbability::getZero();\n  findUnwindDestinations(FuncInfo, UnwindDest, UnwindDestProb, UnwindDests);\n  for (auto &UnwindDest : UnwindDests) {\n    UnwindDest.first->setIsEHPad();\n    addSuccessorWithProb(FuncInfo.MBB, UnwindDest.first, UnwindDest.second);\n  }\n  FuncInfo.MBB->normalizeSuccProbs();\n\n  // Create the terminator node.\n  SDValue Ret =\n      DAG.getNode(ISD::CLEANUPRET, getCurSDLoc(), MVT::Other, getControlRoot());\n  DAG.setRoot(Ret);\n}\n\nvoid SelectionDAGBuilder::visitCatchSwitch(const CatchSwitchInst &CSI) {\n  report_fatal_error(\"visitCatchSwitch not yet implemented!\");\n}\n\nvoid SelectionDAGBuilder::visitRet(const ReturnInst &I) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  auto &DL = DAG.getDataLayout();\n  SDValue Chain = getControlRoot();\n  SmallVector<ISD::OutputArg, 8> Outs;\n  SmallVector<SDValue, 8> OutVals;\n\n  // Calls to @llvm.experimental.deoptimize don't generate a return value, so\n  // lower\n  //\n  //   %val = call <ty> @llvm.experimental.deoptimize()\n  //   ret <ty> %val\n  //\n  // differently.\n  if (I.getParent()->getTerminatingDeoptimizeCall()) {\n    LowerDeoptimizingReturn();\n    return;\n  }\n\n  if (!FuncInfo.CanLowerReturn) {\n    unsigned DemoteReg = FuncInfo.DemoteRegister;\n    const Function *F = I.getParent()->getParent();\n\n    // Emit a store of the return value through the virtual register.\n    // Leave Outs empty so that LowerReturn won't try to load return\n    // registers the usual way.\n    SmallVector<EVT, 1> PtrValueVTs;\n    ComputeValueVTs(TLI, DL,\n                    F->getReturnType()->getPointerTo(\n                        DAG.getDataLayout().getAllocaAddrSpace()),\n                    PtrValueVTs);\n\n    SDValue RetPtr = DAG.getCopyFromReg(DAG.getEntryNode(), getCurSDLoc(),\n                                        DemoteReg, PtrValueVTs[0]);\n    SDValue RetOp = getValue(I.getOperand(0));\n\n    SmallVector<EVT, 4> ValueVTs, MemVTs;\n    SmallVector<uint64_t, 4> Offsets;\n    ComputeValueVTs(TLI, DL, I.getOperand(0)->getType(), ValueVTs, &MemVTs,\n                    &Offsets);\n    unsigned NumValues = ValueVTs.size();\n\n    SmallVector<SDValue, 4> Chains(NumValues);\n    Align BaseAlign = DL.getPrefTypeAlign(I.getOperand(0)->getType());\n    for (unsigned i = 0; i != NumValues; ++i) {\n      // An aggregate return value cannot wrap around the address space, so\n      // offsets to its parts don't wrap either.\n      SDValue Ptr = DAG.getObjectPtrOffset(getCurSDLoc(), RetPtr,\n                                           TypeSize::Fixed(Offsets[i]));\n\n      SDValue Val = RetOp.getValue(RetOp.getResNo() + i);\n      if (MemVTs[i] != ValueVTs[i])\n        Val = DAG.getPtrExtOrTrunc(Val, getCurSDLoc(), MemVTs[i]);\n      Chains[i] = DAG.getStore(\n          Chain, getCurSDLoc(), Val,\n          // FIXME: better loc info would be nice.\n          Ptr, MachinePointerInfo::getUnknownStack(DAG.getMachineFunction()),\n          commonAlignment(BaseAlign, Offsets[i]));\n    }\n\n    Chain = DAG.getNode(ISD::TokenFactor, getCurSDLoc(),\n                        MVT::Other, Chains);\n  } else if (I.getNumOperands() != 0) {\n    SmallVector<EVT, 4> ValueVTs;\n    ComputeValueVTs(TLI, DL, I.getOperand(0)->getType(), ValueVTs);\n    unsigned NumValues = ValueVTs.size();\n    if (NumValues) {\n      SDValue RetOp = getValue(I.getOperand(0));\n\n      const Function *F = I.getParent()->getParent();\n\n      bool NeedsRegBlock = TLI.functionArgumentNeedsConsecutiveRegisters(\n          I.getOperand(0)->getType(), F->getCallingConv(),\n          /*IsVarArg*/ false);\n\n      ISD::NodeType ExtendKind = ISD::ANY_EXTEND;\n      if (F->getAttributes().hasAttribute(AttributeList::ReturnIndex,\n                                          Attribute::SExt))\n        ExtendKind = ISD::SIGN_EXTEND;\n      else if (F->getAttributes().hasAttribute(AttributeList::ReturnIndex,\n                                               Attribute::ZExt))\n        ExtendKind = ISD::ZERO_EXTEND;\n\n      LLVMContext &Context = F->getContext();\n      bool RetInReg = F->getAttributes().hasAttribute(\n          AttributeList::ReturnIndex, Attribute::InReg);\n\n      for (unsigned j = 0; j != NumValues; ++j) {\n        EVT VT = ValueVTs[j];\n\n        if (ExtendKind != ISD::ANY_EXTEND && VT.isInteger())\n          VT = TLI.getTypeForExtReturn(Context, VT, ExtendKind);\n\n        CallingConv::ID CC = F->getCallingConv();\n\n        unsigned NumParts = TLI.getNumRegistersForCallingConv(Context, CC, VT);\n        MVT PartVT = TLI.getRegisterTypeForCallingConv(Context, CC, VT);\n        SmallVector<SDValue, 4> Parts(NumParts);\n        getCopyToParts(DAG, getCurSDLoc(),\n                       SDValue(RetOp.getNode(), RetOp.getResNo() + j),\n                       &Parts[0], NumParts, PartVT, &I, CC, ExtendKind);\n\n        // 'inreg' on function refers to return value\n        ISD::ArgFlagsTy Flags = ISD::ArgFlagsTy();\n        if (RetInReg)\n          Flags.setInReg();\n\n        if (I.getOperand(0)->getType()->isPointerTy()) {\n          Flags.setPointer();\n          Flags.setPointerAddrSpace(\n              cast<PointerType>(I.getOperand(0)->getType())->getAddressSpace());\n        }\n\n        if (NeedsRegBlock) {\n          Flags.setInConsecutiveRegs();\n          if (j == NumValues - 1)\n            Flags.setInConsecutiveRegsLast();\n        }\n\n        // Propagate extension type if any\n        if (ExtendKind == ISD::SIGN_EXTEND)\n          Flags.setSExt();\n        else if (ExtendKind == ISD::ZERO_EXTEND)\n          Flags.setZExt();\n\n        for (unsigned i = 0; i < NumParts; ++i) {\n          Outs.push_back(ISD::OutputArg(Flags, Parts[i].getValueType(),\n                                        VT, /*isfixed=*/true, 0, 0));\n          OutVals.push_back(Parts[i]);\n        }\n      }\n    }\n  }\n\n  // Push in swifterror virtual register as the last element of Outs. This makes\n  // sure swifterror virtual register will be returned in the swifterror\n  // physical register.\n  const Function *F = I.getParent()->getParent();\n  if (TLI.supportSwiftError() &&\n      F->getAttributes().hasAttrSomewhere(Attribute::SwiftError)) {\n    assert(SwiftError.getFunctionArg() && \"Need a swift error argument\");\n    ISD::ArgFlagsTy Flags = ISD::ArgFlagsTy();\n    Flags.setSwiftError();\n    Outs.push_back(ISD::OutputArg(Flags, EVT(TLI.getPointerTy(DL)) /*vt*/,\n                                  EVT(TLI.getPointerTy(DL)) /*argvt*/,\n                                  true /*isfixed*/, 1 /*origidx*/,\n                                  0 /*partOffs*/));\n    // Create SDNode for the swifterror virtual register.\n    OutVals.push_back(\n        DAG.getRegister(SwiftError.getOrCreateVRegUseAt(\n                            &I, FuncInfo.MBB, SwiftError.getFunctionArg()),\n                        EVT(TLI.getPointerTy(DL))));\n  }\n\n  bool isVarArg = DAG.getMachineFunction().getFunction().isVarArg();\n  CallingConv::ID CallConv =\n    DAG.getMachineFunction().getFunction().getCallingConv();\n  Chain = DAG.getTargetLoweringInfo().LowerReturn(\n      Chain, CallConv, isVarArg, Outs, OutVals, getCurSDLoc(), DAG);\n\n  // Verify that the target's LowerReturn behaved as expected.\n  assert(Chain.getNode() && Chain.getValueType() == MVT::Other &&\n         \"LowerReturn didn't return a valid chain!\");\n\n  // Update the DAG with the new chain value resulting from return lowering.\n  DAG.setRoot(Chain);\n}\n\n/// CopyToExportRegsIfNeeded - If the given value has virtual registers\n/// created for it, emit nodes to copy the value into the virtual\n/// registers.\nvoid SelectionDAGBuilder::CopyToExportRegsIfNeeded(const Value *V) {\n  // Skip empty types\n  if (V->getType()->isEmptyTy())\n    return;\n\n  DenseMap<const Value *, Register>::iterator VMI = FuncInfo.ValueMap.find(V);\n  if (VMI != FuncInfo.ValueMap.end()) {\n    assert(!V->use_empty() && \"Unused value assigned virtual registers!\");\n    CopyValueToVirtualRegister(V, VMI->second);\n  }\n}\n\n/// ExportFromCurrentBlock - If this condition isn't known to be exported from\n/// the current basic block, add it to ValueMap now so that we'll get a\n/// CopyTo/FromReg.\nvoid SelectionDAGBuilder::ExportFromCurrentBlock(const Value *V) {\n  // No need to export constants.\n  if (!isa<Instruction>(V) && !isa<Argument>(V)) return;\n\n  // Already exported?\n  if (FuncInfo.isExportedInst(V)) return;\n\n  unsigned Reg = FuncInfo.InitializeRegForValue(V);\n  CopyValueToVirtualRegister(V, Reg);\n}\n\nbool SelectionDAGBuilder::isExportableFromCurrentBlock(const Value *V,\n                                                     const BasicBlock *FromBB) {\n  // The operands of the setcc have to be in this block.  We don't know\n  // how to export them from some other block.\n  if (const Instruction *VI = dyn_cast<Instruction>(V)) {\n    // Can export from current BB.\n    if (VI->getParent() == FromBB)\n      return true;\n\n    // Is already exported, noop.\n    return FuncInfo.isExportedInst(V);\n  }\n\n  // If this is an argument, we can export it if the BB is the entry block or\n  // if it is already exported.\n  if (isa<Argument>(V)) {\n    if (FromBB == &FromBB->getParent()->getEntryBlock())\n      return true;\n\n    // Otherwise, can only export this if it is already exported.\n    return FuncInfo.isExportedInst(V);\n  }\n\n  // Otherwise, constants can always be exported.\n  return true;\n}\n\n/// Return branch probability calculated by BranchProbabilityInfo for IR blocks.\nBranchProbability\nSelectionDAGBuilder::getEdgeProbability(const MachineBasicBlock *Src,\n                                        const MachineBasicBlock *Dst) const {\n  BranchProbabilityInfo *BPI = FuncInfo.BPI;\n  const BasicBlock *SrcBB = Src->getBasicBlock();\n  const BasicBlock *DstBB = Dst->getBasicBlock();\n  if (!BPI) {\n    // If BPI is not available, set the default probability as 1 / N, where N is\n    // the number of successors.\n    auto SuccSize = std::max<uint32_t>(succ_size(SrcBB), 1);\n    return BranchProbability(1, SuccSize);\n  }\n  return BPI->getEdgeProbability(SrcBB, DstBB);\n}\n\nvoid SelectionDAGBuilder::addSuccessorWithProb(MachineBasicBlock *Src,\n                                               MachineBasicBlock *Dst,\n                                               BranchProbability Prob) {\n  if (!FuncInfo.BPI)\n    Src->addSuccessorWithoutProb(Dst);\n  else {\n    if (Prob.isUnknown())\n      Prob = getEdgeProbability(Src, Dst);\n    Src->addSuccessor(Dst, Prob);\n  }\n}\n\nstatic bool InBlock(const Value *V, const BasicBlock *BB) {\n  if (const Instruction *I = dyn_cast<Instruction>(V))\n    return I->getParent() == BB;\n  return true;\n}\n\n/// EmitBranchForMergedCondition - Helper method for FindMergedConditions.\n/// This function emits a branch and is used at the leaves of an OR or an\n/// AND operator tree.\nvoid\nSelectionDAGBuilder::EmitBranchForMergedCondition(const Value *Cond,\n                                                  MachineBasicBlock *TBB,\n                                                  MachineBasicBlock *FBB,\n                                                  MachineBasicBlock *CurBB,\n                                                  MachineBasicBlock *SwitchBB,\n                                                  BranchProbability TProb,\n                                                  BranchProbability FProb,\n                                                  bool InvertCond) {\n  const BasicBlock *BB = CurBB->getBasicBlock();\n\n  // If the leaf of the tree is a comparison, merge the condition into\n  // the caseblock.\n  if (const CmpInst *BOp = dyn_cast<CmpInst>(Cond)) {\n    // The operands of the cmp have to be in this block.  We don't know\n    // how to export them from some other block.  If this is the first block\n    // of the sequence, no exporting is needed.\n    if (CurBB == SwitchBB ||\n        (isExportableFromCurrentBlock(BOp->getOperand(0), BB) &&\n         isExportableFromCurrentBlock(BOp->getOperand(1), BB))) {\n      ISD::CondCode Condition;\n      if (const ICmpInst *IC = dyn_cast<ICmpInst>(Cond)) {\n        ICmpInst::Predicate Pred =\n            InvertCond ? IC->getInversePredicate() : IC->getPredicate();\n        Condition = getICmpCondCode(Pred);\n      } else {\n        const FCmpInst *FC = cast<FCmpInst>(Cond);\n        FCmpInst::Predicate Pred =\n            InvertCond ? FC->getInversePredicate() : FC->getPredicate();\n        Condition = getFCmpCondCode(Pred);\n        if (TM.Options.NoNaNsFPMath)\n          Condition = getFCmpCodeWithoutNaN(Condition);\n      }\n\n      CaseBlock CB(Condition, BOp->getOperand(0), BOp->getOperand(1), nullptr,\n                   TBB, FBB, CurBB, getCurSDLoc(), TProb, FProb);\n      SL->SwitchCases.push_back(CB);\n      return;\n    }\n  }\n\n  // Create a CaseBlock record representing this branch.\n  ISD::CondCode Opc = InvertCond ? ISD::SETNE : ISD::SETEQ;\n  CaseBlock CB(Opc, Cond, ConstantInt::getTrue(*DAG.getContext()),\n               nullptr, TBB, FBB, CurBB, getCurSDLoc(), TProb, FProb);\n  SL->SwitchCases.push_back(CB);\n}\n\nvoid SelectionDAGBuilder::FindMergedConditions(const Value *Cond,\n                                               MachineBasicBlock *TBB,\n                                               MachineBasicBlock *FBB,\n                                               MachineBasicBlock *CurBB,\n                                               MachineBasicBlock *SwitchBB,\n                                               Instruction::BinaryOps Opc,\n                                               BranchProbability TProb,\n                                               BranchProbability FProb,\n                                               bool InvertCond) {\n  // Skip over not part of the tree and remember to invert op and operands at\n  // next level.\n  Value *NotCond;\n  if (match(Cond, m_OneUse(m_Not(m_Value(NotCond)))) &&\n      InBlock(NotCond, CurBB->getBasicBlock())) {\n    FindMergedConditions(NotCond, TBB, FBB, CurBB, SwitchBB, Opc, TProb, FProb,\n                         !InvertCond);\n    return;\n  }\n\n  const Instruction *BOp = dyn_cast<Instruction>(Cond);\n  const Value *BOpOp0, *BOpOp1;\n  // Compute the effective opcode for Cond, taking into account whether it needs\n  // to be inverted, e.g.\n  //   and (not (or A, B)), C\n  // gets lowered as\n  //   and (and (not A, not B), C)\n  Instruction::BinaryOps BOpc = (Instruction::BinaryOps)0;\n  if (BOp) {\n    BOpc = match(BOp, m_LogicalAnd(m_Value(BOpOp0), m_Value(BOpOp1)))\n               ? Instruction::And\n               : (match(BOp, m_LogicalOr(m_Value(BOpOp0), m_Value(BOpOp1)))\n                      ? Instruction::Or\n                      : (Instruction::BinaryOps)0);\n    if (InvertCond) {\n      if (BOpc == Instruction::And)\n        BOpc = Instruction::Or;\n      else if (BOpc == Instruction::Or)\n        BOpc = Instruction::And;\n    }\n  }\n\n  // If this node is not part of the or/and tree, emit it as a branch.\n  // Note that all nodes in the tree should have same opcode.\n  bool BOpIsInOrAndTree = BOpc && BOpc == Opc && BOp->hasOneUse();\n  if (!BOpIsInOrAndTree || BOp->getParent() != CurBB->getBasicBlock() ||\n      !InBlock(BOpOp0, CurBB->getBasicBlock()) ||\n      !InBlock(BOpOp1, CurBB->getBasicBlock())) {\n    EmitBranchForMergedCondition(Cond, TBB, FBB, CurBB, SwitchBB,\n                                 TProb, FProb, InvertCond);\n    return;\n  }\n\n  //  Create TmpBB after CurBB.\n  MachineFunction::iterator BBI(CurBB);\n  MachineFunction &MF = DAG.getMachineFunction();\n  MachineBasicBlock *TmpBB = MF.CreateMachineBasicBlock(CurBB->getBasicBlock());\n  CurBB->getParent()->insert(++BBI, TmpBB);\n\n  if (Opc == Instruction::Or) {\n    // Codegen X | Y as:\n    // BB1:\n    //   jmp_if_X TBB\n    //   jmp TmpBB\n    // TmpBB:\n    //   jmp_if_Y TBB\n    //   jmp FBB\n    //\n\n    // We have flexibility in setting Prob for BB1 and Prob for TmpBB.\n    // The requirement is that\n    //   TrueProb for BB1 + (FalseProb for BB1 * TrueProb for TmpBB)\n    //     = TrueProb for original BB.\n    // Assuming the original probabilities are A and B, one choice is to set\n    // BB1's probabilities to A/2 and A/2+B, and set TmpBB's probabilities to\n    // A/(1+B) and 2B/(1+B). This choice assumes that\n    //   TrueProb for BB1 == FalseProb for BB1 * TrueProb for TmpBB.\n    // Another choice is to assume TrueProb for BB1 equals to TrueProb for\n    // TmpBB, but the math is more complicated.\n\n    auto NewTrueProb = TProb / 2;\n    auto NewFalseProb = TProb / 2 + FProb;\n    // Emit the LHS condition.\n    FindMergedConditions(BOpOp0, TBB, TmpBB, CurBB, SwitchBB, Opc, NewTrueProb,\n                         NewFalseProb, InvertCond);\n\n    // Normalize A/2 and B to get A/(1+B) and 2B/(1+B).\n    SmallVector<BranchProbability, 2> Probs{TProb / 2, FProb};\n    BranchProbability::normalizeProbabilities(Probs.begin(), Probs.end());\n    // Emit the RHS condition into TmpBB.\n    FindMergedConditions(BOpOp1, TBB, FBB, TmpBB, SwitchBB, Opc, Probs[0],\n                         Probs[1], InvertCond);\n  } else {\n    assert(Opc == Instruction::And && \"Unknown merge op!\");\n    // Codegen X & Y as:\n    // BB1:\n    //   jmp_if_X TmpBB\n    //   jmp FBB\n    // TmpBB:\n    //   jmp_if_Y TBB\n    //   jmp FBB\n    //\n    //  This requires creation of TmpBB after CurBB.\n\n    // We have flexibility in setting Prob for BB1 and Prob for TmpBB.\n    // The requirement is that\n    //   FalseProb for BB1 + (TrueProb for BB1 * FalseProb for TmpBB)\n    //     = FalseProb for original BB.\n    // Assuming the original probabilities are A and B, one choice is to set\n    // BB1's probabilities to A+B/2 and B/2, and set TmpBB's probabilities to\n    // 2A/(1+A) and B/(1+A). This choice assumes that FalseProb for BB1 ==\n    // TrueProb for BB1 * FalseProb for TmpBB.\n\n    auto NewTrueProb = TProb + FProb / 2;\n    auto NewFalseProb = FProb / 2;\n    // Emit the LHS condition.\n    FindMergedConditions(BOpOp0, TmpBB, FBB, CurBB, SwitchBB, Opc, NewTrueProb,\n                         NewFalseProb, InvertCond);\n\n    // Normalize A and B/2 to get 2A/(1+A) and B/(1+A).\n    SmallVector<BranchProbability, 2> Probs{TProb, FProb / 2};\n    BranchProbability::normalizeProbabilities(Probs.begin(), Probs.end());\n    // Emit the RHS condition into TmpBB.\n    FindMergedConditions(BOpOp1, TBB, FBB, TmpBB, SwitchBB, Opc, Probs[0],\n                         Probs[1], InvertCond);\n  }\n}\n\n/// If the set of cases should be emitted as a series of branches, return true.\n/// If we should emit this as a bunch of and/or'd together conditions, return\n/// false.\nbool\nSelectionDAGBuilder::ShouldEmitAsBranches(const std::vector<CaseBlock> &Cases) {\n  if (Cases.size() != 2) return true;\n\n  // If this is two comparisons of the same values or'd or and'd together, they\n  // will get folded into a single comparison, so don't emit two blocks.\n  if ((Cases[0].CmpLHS == Cases[1].CmpLHS &&\n       Cases[0].CmpRHS == Cases[1].CmpRHS) ||\n      (Cases[0].CmpRHS == Cases[1].CmpLHS &&\n       Cases[0].CmpLHS == Cases[1].CmpRHS)) {\n    return false;\n  }\n\n  // Handle: (X != null) | (Y != null) --> (X|Y) != 0\n  // Handle: (X == null) & (Y == null) --> (X|Y) == 0\n  if (Cases[0].CmpRHS == Cases[1].CmpRHS &&\n      Cases[0].CC == Cases[1].CC &&\n      isa<Constant>(Cases[0].CmpRHS) &&\n      cast<Constant>(Cases[0].CmpRHS)->isNullValue()) {\n    if (Cases[0].CC == ISD::SETEQ && Cases[0].TrueBB == Cases[1].ThisBB)\n      return false;\n    if (Cases[0].CC == ISD::SETNE && Cases[0].FalseBB == Cases[1].ThisBB)\n      return false;\n  }\n\n  return true;\n}\n\nvoid SelectionDAGBuilder::visitBr(const BranchInst &I) {\n  MachineBasicBlock *BrMBB = FuncInfo.MBB;\n\n  // Update machine-CFG edges.\n  MachineBasicBlock *Succ0MBB = FuncInfo.MBBMap[I.getSuccessor(0)];\n\n  if (I.isUnconditional()) {\n    // Update machine-CFG edges.\n    BrMBB->addSuccessor(Succ0MBB);\n\n    // If this is not a fall-through branch or optimizations are switched off,\n    // emit the branch.\n    if (Succ0MBB != NextBlock(BrMBB) || TM.getOptLevel() == CodeGenOpt::None)\n      DAG.setRoot(DAG.getNode(ISD::BR, getCurSDLoc(),\n                              MVT::Other, getControlRoot(),\n                              DAG.getBasicBlock(Succ0MBB)));\n\n    return;\n  }\n\n  // If this condition is one of the special cases we handle, do special stuff\n  // now.\n  const Value *CondVal = I.getCondition();\n  MachineBasicBlock *Succ1MBB = FuncInfo.MBBMap[I.getSuccessor(1)];\n\n  // If this is a series of conditions that are or'd or and'd together, emit\n  // this as a sequence of branches instead of setcc's with and/or operations.\n  // As long as jumps are not expensive (exceptions for multi-use logic ops,\n  // unpredictable branches, and vector extracts because those jumps are likely\n  // expensive for any target), this should improve performance.\n  // For example, instead of something like:\n  //     cmp A, B\n  //     C = seteq\n  //     cmp D, E\n  //     F = setle\n  //     or C, F\n  //     jnz foo\n  // Emit:\n  //     cmp A, B\n  //     je foo\n  //     cmp D, E\n  //     jle foo\n  const Instruction *BOp = dyn_cast<Instruction>(CondVal);\n  if (!DAG.getTargetLoweringInfo().isJumpExpensive() && BOp &&\n      BOp->hasOneUse() && !I.hasMetadata(LLVMContext::MD_unpredictable)) {\n    Value *Vec;\n    const Value *BOp0, *BOp1;\n    Instruction::BinaryOps Opcode = (Instruction::BinaryOps)0;\n    if (match(BOp, m_LogicalAnd(m_Value(BOp0), m_Value(BOp1))))\n      Opcode = Instruction::And;\n    else if (match(BOp, m_LogicalOr(m_Value(BOp0), m_Value(BOp1))))\n      Opcode = Instruction::Or;\n\n    if (Opcode && !(match(BOp0, m_ExtractElt(m_Value(Vec), m_Value())) &&\n                    match(BOp1, m_ExtractElt(m_Specific(Vec), m_Value())))) {\n      FindMergedConditions(BOp, Succ0MBB, Succ1MBB, BrMBB, BrMBB, Opcode,\n                           getEdgeProbability(BrMBB, Succ0MBB),\n                           getEdgeProbability(BrMBB, Succ1MBB),\n                           /*InvertCond=*/false);\n      // If the compares in later blocks need to use values not currently\n      // exported from this block, export them now.  This block should always\n      // be the first entry.\n      assert(SL->SwitchCases[0].ThisBB == BrMBB && \"Unexpected lowering!\");\n\n      // Allow some cases to be rejected.\n      if (ShouldEmitAsBranches(SL->SwitchCases)) {\n        for (unsigned i = 1, e = SL->SwitchCases.size(); i != e; ++i) {\n          ExportFromCurrentBlock(SL->SwitchCases[i].CmpLHS);\n          ExportFromCurrentBlock(SL->SwitchCases[i].CmpRHS);\n        }\n\n        // Emit the branch for this block.\n        visitSwitchCase(SL->SwitchCases[0], BrMBB);\n        SL->SwitchCases.erase(SL->SwitchCases.begin());\n        return;\n      }\n\n      // Okay, we decided not to do this, remove any inserted MBB's and clear\n      // SwitchCases.\n      for (unsigned i = 1, e = SL->SwitchCases.size(); i != e; ++i)\n        FuncInfo.MF->erase(SL->SwitchCases[i].ThisBB);\n\n      SL->SwitchCases.clear();\n    }\n  }\n\n  // Create a CaseBlock record representing this branch.\n  CaseBlock CB(ISD::SETEQ, CondVal, ConstantInt::getTrue(*DAG.getContext()),\n               nullptr, Succ0MBB, Succ1MBB, BrMBB, getCurSDLoc());\n\n  // Use visitSwitchCase to actually insert the fast branch sequence for this\n  // cond branch.\n  visitSwitchCase(CB, BrMBB);\n}\n\n/// visitSwitchCase - Emits the necessary code to represent a single node in\n/// the binary search tree resulting from lowering a switch instruction.\nvoid SelectionDAGBuilder::visitSwitchCase(CaseBlock &CB,\n                                          MachineBasicBlock *SwitchBB) {\n  SDValue Cond;\n  SDValue CondLHS = getValue(CB.CmpLHS);\n  SDLoc dl = CB.DL;\n\n  if (CB.CC == ISD::SETTRUE) {\n    // Branch or fall through to TrueBB.\n    addSuccessorWithProb(SwitchBB, CB.TrueBB, CB.TrueProb);\n    SwitchBB->normalizeSuccProbs();\n    if (CB.TrueBB != NextBlock(SwitchBB)) {\n      DAG.setRoot(DAG.getNode(ISD::BR, dl, MVT::Other, getControlRoot(),\n                              DAG.getBasicBlock(CB.TrueBB)));\n    }\n    return;\n  }\n\n  auto &TLI = DAG.getTargetLoweringInfo();\n  EVT MemVT = TLI.getMemValueType(DAG.getDataLayout(), CB.CmpLHS->getType());\n\n  // Build the setcc now.\n  if (!CB.CmpMHS) {\n    // Fold \"(X == true)\" to X and \"(X == false)\" to !X to\n    // handle common cases produced by branch lowering.\n    if (CB.CmpRHS == ConstantInt::getTrue(*DAG.getContext()) &&\n        CB.CC == ISD::SETEQ)\n      Cond = CondLHS;\n    else if (CB.CmpRHS == ConstantInt::getFalse(*DAG.getContext()) &&\n             CB.CC == ISD::SETEQ) {\n      SDValue True = DAG.getConstant(1, dl, CondLHS.getValueType());\n      Cond = DAG.getNode(ISD::XOR, dl, CondLHS.getValueType(), CondLHS, True);\n    } else {\n      SDValue CondRHS = getValue(CB.CmpRHS);\n\n      // If a pointer's DAG type is larger than its memory type then the DAG\n      // values are zero-extended. This breaks signed comparisons so truncate\n      // back to the underlying type before doing the compare.\n      if (CondLHS.getValueType() != MemVT) {\n        CondLHS = DAG.getPtrExtOrTrunc(CondLHS, getCurSDLoc(), MemVT);\n        CondRHS = DAG.getPtrExtOrTrunc(CondRHS, getCurSDLoc(), MemVT);\n      }\n      Cond = DAG.getSetCC(dl, MVT::i1, CondLHS, CondRHS, CB.CC);\n    }\n  } else {\n    assert(CB.CC == ISD::SETLE && \"Can handle only LE ranges now\");\n\n    const APInt& Low = cast<ConstantInt>(CB.CmpLHS)->getValue();\n    const APInt& High = cast<ConstantInt>(CB.CmpRHS)->getValue();\n\n    SDValue CmpOp = getValue(CB.CmpMHS);\n    EVT VT = CmpOp.getValueType();\n\n    if (cast<ConstantInt>(CB.CmpLHS)->isMinValue(true)) {\n      Cond = DAG.getSetCC(dl, MVT::i1, CmpOp, DAG.getConstant(High, dl, VT),\n                          ISD::SETLE);\n    } else {\n      SDValue SUB = DAG.getNode(ISD::SUB, dl,\n                                VT, CmpOp, DAG.getConstant(Low, dl, VT));\n      Cond = DAG.getSetCC(dl, MVT::i1, SUB,\n                          DAG.getConstant(High-Low, dl, VT), ISD::SETULE);\n    }\n  }\n\n  // Update successor info\n  addSuccessorWithProb(SwitchBB, CB.TrueBB, CB.TrueProb);\n  // TrueBB and FalseBB are always different unless the incoming IR is\n  // degenerate. This only happens when running llc on weird IR.\n  if (CB.TrueBB != CB.FalseBB)\n    addSuccessorWithProb(SwitchBB, CB.FalseBB, CB.FalseProb);\n  SwitchBB->normalizeSuccProbs();\n\n  // If the lhs block is the next block, invert the condition so that we can\n  // fall through to the lhs instead of the rhs block.\n  if (CB.TrueBB == NextBlock(SwitchBB)) {\n    std::swap(CB.TrueBB, CB.FalseBB);\n    SDValue True = DAG.getConstant(1, dl, Cond.getValueType());\n    Cond = DAG.getNode(ISD::XOR, dl, Cond.getValueType(), Cond, True);\n  }\n\n  SDValue BrCond = DAG.getNode(ISD::BRCOND, dl,\n                               MVT::Other, getControlRoot(), Cond,\n                               DAG.getBasicBlock(CB.TrueBB));\n\n  // Insert the false branch. Do this even if it's a fall through branch,\n  // this makes it easier to do DAG optimizations which require inverting\n  // the branch condition.\n  BrCond = DAG.getNode(ISD::BR, dl, MVT::Other, BrCond,\n                       DAG.getBasicBlock(CB.FalseBB));\n\n  DAG.setRoot(BrCond);\n}\n\n/// visitJumpTable - Emit JumpTable node in the current MBB\nvoid SelectionDAGBuilder::visitJumpTable(SwitchCG::JumpTable &JT) {\n  // Emit the code for the jump table\n  assert(JT.Reg != -1U && \"Should lower JT Header first!\");\n  EVT PTy = DAG.getTargetLoweringInfo().getPointerTy(DAG.getDataLayout());\n  SDValue Index = DAG.getCopyFromReg(getControlRoot(), getCurSDLoc(),\n                                     JT.Reg, PTy);\n  SDValue Table = DAG.getJumpTable(JT.JTI, PTy);\n  SDValue BrJumpTable = DAG.getNode(ISD::BR_JT, getCurSDLoc(),\n                                    MVT::Other, Index.getValue(1),\n                                    Table, Index);\n  DAG.setRoot(BrJumpTable);\n}\n\n/// visitJumpTableHeader - This function emits necessary code to produce index\n/// in the JumpTable from switch case.\nvoid SelectionDAGBuilder::visitJumpTableHeader(SwitchCG::JumpTable &JT,\n                                               JumpTableHeader &JTH,\n                                               MachineBasicBlock *SwitchBB) {\n  SDLoc dl = getCurSDLoc();\n\n  // Subtract the lowest switch case value from the value being switched on.\n  SDValue SwitchOp = getValue(JTH.SValue);\n  EVT VT = SwitchOp.getValueType();\n  SDValue Sub = DAG.getNode(ISD::SUB, dl, VT, SwitchOp,\n                            DAG.getConstant(JTH.First, dl, VT));\n\n  // The SDNode we just created, which holds the value being switched on minus\n  // the smallest case value, needs to be copied to a virtual register so it\n  // can be used as an index into the jump table in a subsequent basic block.\n  // This value may be smaller or larger than the target's pointer type, and\n  // therefore require extension or truncating.\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SwitchOp = DAG.getZExtOrTrunc(Sub, dl, TLI.getPointerTy(DAG.getDataLayout()));\n\n  unsigned JumpTableReg =\n      FuncInfo.CreateReg(TLI.getPointerTy(DAG.getDataLayout()));\n  SDValue CopyTo = DAG.getCopyToReg(getControlRoot(), dl,\n                                    JumpTableReg, SwitchOp);\n  JT.Reg = JumpTableReg;\n\n  if (!JTH.OmitRangeCheck) {\n    // Emit the range check for the jump table, and branch to the default block\n    // for the switch statement if the value being switched on exceeds the\n    // largest case in the switch.\n    SDValue CMP = DAG.getSetCC(\n        dl, TLI.getSetCCResultType(DAG.getDataLayout(), *DAG.getContext(),\n                                   Sub.getValueType()),\n        Sub, DAG.getConstant(JTH.Last - JTH.First, dl, VT), ISD::SETUGT);\n\n    SDValue BrCond = DAG.getNode(ISD::BRCOND, dl,\n                                 MVT::Other, CopyTo, CMP,\n                                 DAG.getBasicBlock(JT.Default));\n\n    // Avoid emitting unnecessary branches to the next block.\n    if (JT.MBB != NextBlock(SwitchBB))\n      BrCond = DAG.getNode(ISD::BR, dl, MVT::Other, BrCond,\n                           DAG.getBasicBlock(JT.MBB));\n\n    DAG.setRoot(BrCond);\n  } else {\n    // Avoid emitting unnecessary branches to the next block.\n    if (JT.MBB != NextBlock(SwitchBB))\n      DAG.setRoot(DAG.getNode(ISD::BR, dl, MVT::Other, CopyTo,\n                              DAG.getBasicBlock(JT.MBB)));\n    else\n      DAG.setRoot(CopyTo);\n  }\n}\n\n/// Create a LOAD_STACK_GUARD node, and let it carry the target specific global\n/// variable if there exists one.\nstatic SDValue getLoadStackGuard(SelectionDAG &DAG, const SDLoc &DL,\n                                 SDValue &Chain) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT PtrTy = TLI.getPointerTy(DAG.getDataLayout());\n  EVT PtrMemTy = TLI.getPointerMemTy(DAG.getDataLayout());\n  MachineFunction &MF = DAG.getMachineFunction();\n  Value *Global = TLI.getSDagStackGuard(*MF.getFunction().getParent());\n  MachineSDNode *Node =\n      DAG.getMachineNode(TargetOpcode::LOAD_STACK_GUARD, DL, PtrTy, Chain);\n  if (Global) {\n    MachinePointerInfo MPInfo(Global);\n    auto Flags = MachineMemOperand::MOLoad | MachineMemOperand::MOInvariant |\n                 MachineMemOperand::MODereferenceable;\n    MachineMemOperand *MemRef = MF.getMachineMemOperand(\n        MPInfo, Flags, PtrTy.getSizeInBits() / 8, DAG.getEVTAlign(PtrTy));\n    DAG.setNodeMemRefs(Node, {MemRef});\n  }\n  if (PtrTy != PtrMemTy)\n    return DAG.getPtrExtOrTrunc(SDValue(Node, 0), DL, PtrMemTy);\n  return SDValue(Node, 0);\n}\n\n/// Codegen a new tail for a stack protector check ParentMBB which has had its\n/// tail spliced into a stack protector check success bb.\n///\n/// For a high level explanation of how this fits into the stack protector\n/// generation see the comment on the declaration of class\n/// StackProtectorDescriptor.\nvoid SelectionDAGBuilder::visitSPDescriptorParent(StackProtectorDescriptor &SPD,\n                                                  MachineBasicBlock *ParentBB) {\n\n  // First create the loads to the guard/stack slot for the comparison.\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT PtrTy = TLI.getPointerTy(DAG.getDataLayout());\n  EVT PtrMemTy = TLI.getPointerMemTy(DAG.getDataLayout());\n\n  MachineFrameInfo &MFI = ParentBB->getParent()->getFrameInfo();\n  int FI = MFI.getStackProtectorIndex();\n\n  SDValue Guard;\n  SDLoc dl = getCurSDLoc();\n  SDValue StackSlotPtr = DAG.getFrameIndex(FI, PtrTy);\n  const Module &M = *ParentBB->getParent()->getFunction().getParent();\n  Align Align = DL->getPrefTypeAlign(Type::getInt8PtrTy(M.getContext()));\n\n  // Generate code to load the content of the guard slot.\n  SDValue GuardVal = DAG.getLoad(\n      PtrMemTy, dl, DAG.getEntryNode(), StackSlotPtr,\n      MachinePointerInfo::getFixedStack(DAG.getMachineFunction(), FI), Align,\n      MachineMemOperand::MOVolatile);\n\n  if (TLI.useStackGuardXorFP())\n    GuardVal = TLI.emitStackGuardXorFP(DAG, GuardVal, dl);\n\n  // Retrieve guard check function, nullptr if instrumentation is inlined.\n  if (const Function *GuardCheckFn = TLI.getSSPStackGuardCheck(M)) {\n    // The target provides a guard check function to validate the guard value.\n    // Generate a call to that function with the content of the guard slot as\n    // argument.\n    FunctionType *FnTy = GuardCheckFn->getFunctionType();\n    assert(FnTy->getNumParams() == 1 && \"Invalid function signature\");\n\n    TargetLowering::ArgListTy Args;\n    TargetLowering::ArgListEntry Entry;\n    Entry.Node = GuardVal;\n    Entry.Ty = FnTy->getParamType(0);\n    if (GuardCheckFn->hasAttribute(1, Attribute::AttrKind::InReg))\n      Entry.IsInReg = true;\n    Args.push_back(Entry);\n\n    TargetLowering::CallLoweringInfo CLI(DAG);\n    CLI.setDebugLoc(getCurSDLoc())\n        .setChain(DAG.getEntryNode())\n        .setCallee(GuardCheckFn->getCallingConv(), FnTy->getReturnType(),\n                   getValue(GuardCheckFn), std::move(Args));\n\n    std::pair<SDValue, SDValue> Result = TLI.LowerCallTo(CLI);\n    DAG.setRoot(Result.second);\n    return;\n  }\n\n  // If useLoadStackGuardNode returns true, generate LOAD_STACK_GUARD.\n  // Otherwise, emit a volatile load to retrieve the stack guard value.\n  SDValue Chain = DAG.getEntryNode();\n  if (TLI.useLoadStackGuardNode()) {\n    Guard = getLoadStackGuard(DAG, dl, Chain);\n  } else {\n    const Value *IRGuard = TLI.getSDagStackGuard(M);\n    SDValue GuardPtr = getValue(IRGuard);\n\n    Guard = DAG.getLoad(PtrMemTy, dl, Chain, GuardPtr,\n                        MachinePointerInfo(IRGuard, 0), Align,\n                        MachineMemOperand::MOVolatile);\n  }\n\n  // Perform the comparison via a getsetcc.\n  SDValue Cmp = DAG.getSetCC(dl, TLI.getSetCCResultType(DAG.getDataLayout(),\n                                                        *DAG.getContext(),\n                                                        Guard.getValueType()),\n                             Guard, GuardVal, ISD::SETNE);\n\n  // If the guard/stackslot do not equal, branch to failure MBB.\n  SDValue BrCond = DAG.getNode(ISD::BRCOND, dl,\n                               MVT::Other, GuardVal.getOperand(0),\n                               Cmp, DAG.getBasicBlock(SPD.getFailureMBB()));\n  // Otherwise branch to success MBB.\n  SDValue Br = DAG.getNode(ISD::BR, dl,\n                           MVT::Other, BrCond,\n                           DAG.getBasicBlock(SPD.getSuccessMBB()));\n\n  DAG.setRoot(Br);\n}\n\n/// Codegen the failure basic block for a stack protector check.\n///\n/// A failure stack protector machine basic block consists simply of a call to\n/// __stack_chk_fail().\n///\n/// For a high level explanation of how this fits into the stack protector\n/// generation see the comment on the declaration of class\n/// StackProtectorDescriptor.\nvoid\nSelectionDAGBuilder::visitSPDescriptorFailure(StackProtectorDescriptor &SPD) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  TargetLowering::MakeLibCallOptions CallOptions;\n  CallOptions.setDiscardResult(true);\n  SDValue Chain =\n      TLI.makeLibCall(DAG, RTLIB::STACKPROTECTOR_CHECK_FAIL, MVT::isVoid,\n                      None, CallOptions, getCurSDLoc()).second;\n  // On PS4, the \"return address\" must still be within the calling function,\n  // even if it's at the very end, so emit an explicit TRAP here.\n  // Passing 'true' for doesNotReturn above won't generate the trap for us.\n  if (TM.getTargetTriple().isPS4CPU())\n    Chain = DAG.getNode(ISD::TRAP, getCurSDLoc(), MVT::Other, Chain);\n  // WebAssembly needs an unreachable instruction after a non-returning call,\n  // because the function return type can be different from __stack_chk_fail's\n  // return type (void).\n  if (TM.getTargetTriple().isWasm())\n    Chain = DAG.getNode(ISD::TRAP, getCurSDLoc(), MVT::Other, Chain);\n\n  DAG.setRoot(Chain);\n}\n\n/// visitBitTestHeader - This function emits necessary code to produce value\n/// suitable for \"bit tests\"\nvoid SelectionDAGBuilder::visitBitTestHeader(BitTestBlock &B,\n                                             MachineBasicBlock *SwitchBB) {\n  SDLoc dl = getCurSDLoc();\n\n  // Subtract the minimum value.\n  SDValue SwitchOp = getValue(B.SValue);\n  EVT VT = SwitchOp.getValueType();\n  SDValue RangeSub =\n      DAG.getNode(ISD::SUB, dl, VT, SwitchOp, DAG.getConstant(B.First, dl, VT));\n\n  // Determine the type of the test operands.\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  bool UsePtrType = false;\n  if (!TLI.isTypeLegal(VT)) {\n    UsePtrType = true;\n  } else {\n    for (unsigned i = 0, e = B.Cases.size(); i != e; ++i)\n      if (!isUIntN(VT.getSizeInBits(), B.Cases[i].Mask)) {\n        // Switch table case range are encoded into series of masks.\n        // Just use pointer type, it's guaranteed to fit.\n        UsePtrType = true;\n        break;\n      }\n  }\n  SDValue Sub = RangeSub;\n  if (UsePtrType) {\n    VT = TLI.getPointerTy(DAG.getDataLayout());\n    Sub = DAG.getZExtOrTrunc(Sub, dl, VT);\n  }\n\n  B.RegVT = VT.getSimpleVT();\n  B.Reg = FuncInfo.CreateReg(B.RegVT);\n  SDValue CopyTo = DAG.getCopyToReg(getControlRoot(), dl, B.Reg, Sub);\n\n  MachineBasicBlock* MBB = B.Cases[0].ThisBB;\n\n  if (!B.OmitRangeCheck)\n    addSuccessorWithProb(SwitchBB, B.Default, B.DefaultProb);\n  addSuccessorWithProb(SwitchBB, MBB, B.Prob);\n  SwitchBB->normalizeSuccProbs();\n\n  SDValue Root = CopyTo;\n  if (!B.OmitRangeCheck) {\n    // Conditional branch to the default block.\n    SDValue RangeCmp = DAG.getSetCC(dl,\n        TLI.getSetCCResultType(DAG.getDataLayout(), *DAG.getContext(),\n                               RangeSub.getValueType()),\n        RangeSub, DAG.getConstant(B.Range, dl, RangeSub.getValueType()),\n        ISD::SETUGT);\n\n    Root = DAG.getNode(ISD::BRCOND, dl, MVT::Other, Root, RangeCmp,\n                       DAG.getBasicBlock(B.Default));\n  }\n\n  // Avoid emitting unnecessary branches to the next block.\n  if (MBB != NextBlock(SwitchBB))\n    Root = DAG.getNode(ISD::BR, dl, MVT::Other, Root, DAG.getBasicBlock(MBB));\n\n  DAG.setRoot(Root);\n}\n\n/// visitBitTestCase - this function produces one \"bit test\"\nvoid SelectionDAGBuilder::visitBitTestCase(BitTestBlock &BB,\n                                           MachineBasicBlock* NextMBB,\n                                           BranchProbability BranchProbToNext,\n                                           unsigned Reg,\n                                           BitTestCase &B,\n                                           MachineBasicBlock *SwitchBB) {\n  SDLoc dl = getCurSDLoc();\n  MVT VT = BB.RegVT;\n  SDValue ShiftOp = DAG.getCopyFromReg(getControlRoot(), dl, Reg, VT);\n  SDValue Cmp;\n  unsigned PopCount = countPopulation(B.Mask);\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  if (PopCount == 1) {\n    // Testing for a single bit; just compare the shift count with what it\n    // would need to be to shift a 1 bit in that position.\n    Cmp = DAG.getSetCC(\n        dl, TLI.getSetCCResultType(DAG.getDataLayout(), *DAG.getContext(), VT),\n        ShiftOp, DAG.getConstant(countTrailingZeros(B.Mask), dl, VT),\n        ISD::SETEQ);\n  } else if (PopCount == BB.Range) {\n    // There is only one zero bit in the range, test for it directly.\n    Cmp = DAG.getSetCC(\n        dl, TLI.getSetCCResultType(DAG.getDataLayout(), *DAG.getContext(), VT),\n        ShiftOp, DAG.getConstant(countTrailingOnes(B.Mask), dl, VT),\n        ISD::SETNE);\n  } else {\n    // Make desired shift\n    SDValue SwitchVal = DAG.getNode(ISD::SHL, dl, VT,\n                                    DAG.getConstant(1, dl, VT), ShiftOp);\n\n    // Emit bit tests and jumps\n    SDValue AndOp = DAG.getNode(ISD::AND, dl,\n                                VT, SwitchVal, DAG.getConstant(B.Mask, dl, VT));\n    Cmp = DAG.getSetCC(\n        dl, TLI.getSetCCResultType(DAG.getDataLayout(), *DAG.getContext(), VT),\n        AndOp, DAG.getConstant(0, dl, VT), ISD::SETNE);\n  }\n\n  // The branch probability from SwitchBB to B.TargetBB is B.ExtraProb.\n  addSuccessorWithProb(SwitchBB, B.TargetBB, B.ExtraProb);\n  // The branch probability from SwitchBB to NextMBB is BranchProbToNext.\n  addSuccessorWithProb(SwitchBB, NextMBB, BranchProbToNext);\n  // It is not guaranteed that the sum of B.ExtraProb and BranchProbToNext is\n  // one as they are relative probabilities (and thus work more like weights),\n  // and hence we need to normalize them to let the sum of them become one.\n  SwitchBB->normalizeSuccProbs();\n\n  SDValue BrAnd = DAG.getNode(ISD::BRCOND, dl,\n                              MVT::Other, getControlRoot(),\n                              Cmp, DAG.getBasicBlock(B.TargetBB));\n\n  // Avoid emitting unnecessary branches to the next block.\n  if (NextMBB != NextBlock(SwitchBB))\n    BrAnd = DAG.getNode(ISD::BR, dl, MVT::Other, BrAnd,\n                        DAG.getBasicBlock(NextMBB));\n\n  DAG.setRoot(BrAnd);\n}\n\nvoid SelectionDAGBuilder::visitInvoke(const InvokeInst &I) {\n  MachineBasicBlock *InvokeMBB = FuncInfo.MBB;\n\n  // Retrieve successors. Look through artificial IR level blocks like\n  // catchswitch for successors.\n  MachineBasicBlock *Return = FuncInfo.MBBMap[I.getSuccessor(0)];\n  const BasicBlock *EHPadBB = I.getSuccessor(1);\n\n  // Deopt bundles are lowered in LowerCallSiteWithDeoptBundle, and we don't\n  // have to do anything here to lower funclet bundles.\n  assert(!I.hasOperandBundlesOtherThan({LLVMContext::OB_deopt,\n                                        LLVMContext::OB_gc_transition,\n                                        LLVMContext::OB_gc_live,\n                                        LLVMContext::OB_funclet,\n                                        LLVMContext::OB_cfguardtarget}) &&\n         \"Cannot lower invokes with arbitrary operand bundles yet!\");\n\n  const Value *Callee(I.getCalledOperand());\n  const Function *Fn = dyn_cast<Function>(Callee);\n  if (isa<InlineAsm>(Callee))\n    visitInlineAsm(I);\n  else if (Fn && Fn->isIntrinsic()) {\n    switch (Fn->getIntrinsicID()) {\n    default:\n      llvm_unreachable(\"Cannot invoke this intrinsic\");\n    case Intrinsic::donothing:\n      // Ignore invokes to @llvm.donothing: jump directly to the next BB.\n      break;\n    case Intrinsic::experimental_patchpoint_void:\n    case Intrinsic::experimental_patchpoint_i64:\n      visitPatchpoint(I, EHPadBB);\n      break;\n    case Intrinsic::experimental_gc_statepoint:\n      LowerStatepoint(cast<GCStatepointInst>(I), EHPadBB);\n      break;\n    case Intrinsic::wasm_rethrow: {\n      // This is usually done in visitTargetIntrinsic, but this intrinsic is\n      // special because it can be invoked, so we manually lower it to a DAG\n      // node here.\n      SmallVector<SDValue, 8> Ops;\n      Ops.push_back(getRoot()); // inchain\n      const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n      Ops.push_back(\n          DAG.getTargetConstant(Intrinsic::wasm_rethrow, getCurSDLoc(),\n                                TLI.getPointerTy(DAG.getDataLayout())));\n      SDVTList VTs = DAG.getVTList(ArrayRef<EVT>({MVT::Other})); // outchain\n      DAG.setRoot(DAG.getNode(ISD::INTRINSIC_VOID, getCurSDLoc(), VTs, Ops));\n      break;\n    }\n    }\n  } else if (I.countOperandBundlesOfType(LLVMContext::OB_deopt)) {\n    // Currently we do not lower any intrinsic calls with deopt operand bundles.\n    // Eventually we will support lowering the @llvm.experimental.deoptimize\n    // intrinsic, and right now there are no plans to support other intrinsics\n    // with deopt state.\n    LowerCallSiteWithDeoptBundle(&I, getValue(Callee), EHPadBB);\n  } else {\n    LowerCallTo(I, getValue(Callee), false, EHPadBB);\n  }\n\n  // If the value of the invoke is used outside of its defining block, make it\n  // available as a virtual register.\n  // We already took care of the exported value for the statepoint instruction\n  // during call to the LowerStatepoint.\n  if (!isa<GCStatepointInst>(I)) {\n    CopyToExportRegsIfNeeded(&I);\n  }\n\n  SmallVector<std::pair<MachineBasicBlock *, BranchProbability>, 1> UnwindDests;\n  BranchProbabilityInfo *BPI = FuncInfo.BPI;\n  BranchProbability EHPadBBProb =\n      BPI ? BPI->getEdgeProbability(InvokeMBB->getBasicBlock(), EHPadBB)\n          : BranchProbability::getZero();\n  findUnwindDestinations(FuncInfo, EHPadBB, EHPadBBProb, UnwindDests);\n\n  // Update successor info.\n  addSuccessorWithProb(InvokeMBB, Return);\n  for (auto &UnwindDest : UnwindDests) {\n    UnwindDest.first->setIsEHPad();\n    addSuccessorWithProb(InvokeMBB, UnwindDest.first, UnwindDest.second);\n  }\n  InvokeMBB->normalizeSuccProbs();\n\n  // Drop into normal successor.\n  DAG.setRoot(DAG.getNode(ISD::BR, getCurSDLoc(), MVT::Other, getControlRoot(),\n                          DAG.getBasicBlock(Return)));\n}\n\nvoid SelectionDAGBuilder::visitCallBr(const CallBrInst &I) {\n  MachineBasicBlock *CallBrMBB = FuncInfo.MBB;\n\n  // Deopt bundles are lowered in LowerCallSiteWithDeoptBundle, and we don't\n  // have to do anything here to lower funclet bundles.\n  assert(!I.hasOperandBundlesOtherThan(\n             {LLVMContext::OB_deopt, LLVMContext::OB_funclet}) &&\n         \"Cannot lower callbrs with arbitrary operand bundles yet!\");\n\n  assert(I.isInlineAsm() && \"Only know how to handle inlineasm callbr\");\n  visitInlineAsm(I);\n  CopyToExportRegsIfNeeded(&I);\n\n  // Retrieve successors.\n  MachineBasicBlock *Return = FuncInfo.MBBMap[I.getDefaultDest()];\n\n  // Update successor info.\n  addSuccessorWithProb(CallBrMBB, Return, BranchProbability::getOne());\n  for (unsigned i = 0, e = I.getNumIndirectDests(); i < e; ++i) {\n    MachineBasicBlock *Target = FuncInfo.MBBMap[I.getIndirectDest(i)];\n    addSuccessorWithProb(CallBrMBB, Target, BranchProbability::getZero());\n    Target->setIsInlineAsmBrIndirectTarget();\n  }\n  CallBrMBB->normalizeSuccProbs();\n\n  // Drop into default successor.\n  DAG.setRoot(DAG.getNode(ISD::BR, getCurSDLoc(),\n                          MVT::Other, getControlRoot(),\n                          DAG.getBasicBlock(Return)));\n}\n\nvoid SelectionDAGBuilder::visitResume(const ResumeInst &RI) {\n  llvm_unreachable(\"SelectionDAGBuilder shouldn't visit resume instructions!\");\n}\n\nvoid SelectionDAGBuilder::visitLandingPad(const LandingPadInst &LP) {\n  assert(FuncInfo.MBB->isEHPad() &&\n         \"Call to landingpad not in landing pad!\");\n\n  // If there aren't registers to copy the values into (e.g., during SjLj\n  // exceptions), then don't bother to create these DAG nodes.\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  const Constant *PersonalityFn = FuncInfo.Fn->getPersonalityFn();\n  if (TLI.getExceptionPointerRegister(PersonalityFn) == 0 &&\n      TLI.getExceptionSelectorRegister(PersonalityFn) == 0)\n    return;\n\n  // If landingpad's return type is token type, we don't create DAG nodes\n  // for its exception pointer and selector value. The extraction of exception\n  // pointer or selector value from token type landingpads is not currently\n  // supported.\n  if (LP.getType()->isTokenTy())\n    return;\n\n  SmallVector<EVT, 2> ValueVTs;\n  SDLoc dl = getCurSDLoc();\n  ComputeValueVTs(TLI, DAG.getDataLayout(), LP.getType(), ValueVTs);\n  assert(ValueVTs.size() == 2 && \"Only two-valued landingpads are supported\");\n\n  // Get the two live-in registers as SDValues. The physregs have already been\n  // copied into virtual registers.\n  SDValue Ops[2];\n  if (FuncInfo.ExceptionPointerVirtReg) {\n    Ops[0] = DAG.getZExtOrTrunc(\n        DAG.getCopyFromReg(DAG.getEntryNode(), dl,\n                           FuncInfo.ExceptionPointerVirtReg,\n                           TLI.getPointerTy(DAG.getDataLayout())),\n        dl, ValueVTs[0]);\n  } else {\n    Ops[0] = DAG.getConstant(0, dl, TLI.getPointerTy(DAG.getDataLayout()));\n  }\n  Ops[1] = DAG.getZExtOrTrunc(\n      DAG.getCopyFromReg(DAG.getEntryNode(), dl,\n                         FuncInfo.ExceptionSelectorVirtReg,\n                         TLI.getPointerTy(DAG.getDataLayout())),\n      dl, ValueVTs[1]);\n\n  // Merge into one.\n  SDValue Res = DAG.getNode(ISD::MERGE_VALUES, dl,\n                            DAG.getVTList(ValueVTs), Ops);\n  setValue(&LP, Res);\n}\n\nvoid SelectionDAGBuilder::UpdateSplitBlock(MachineBasicBlock *First,\n                                           MachineBasicBlock *Last) {\n  // Update JTCases.\n  for (unsigned i = 0, e = SL->JTCases.size(); i != e; ++i)\n    if (SL->JTCases[i].first.HeaderBB == First)\n      SL->JTCases[i].first.HeaderBB = Last;\n\n  // Update BitTestCases.\n  for (unsigned i = 0, e = SL->BitTestCases.size(); i != e; ++i)\n    if (SL->BitTestCases[i].Parent == First)\n      SL->BitTestCases[i].Parent = Last;\n}\n\nvoid SelectionDAGBuilder::visitIndirectBr(const IndirectBrInst &I) {\n  MachineBasicBlock *IndirectBrMBB = FuncInfo.MBB;\n\n  // Update machine-CFG edges with unique successors.\n  SmallSet<BasicBlock*, 32> Done;\n  for (unsigned i = 0, e = I.getNumSuccessors(); i != e; ++i) {\n    BasicBlock *BB = I.getSuccessor(i);\n    bool Inserted = Done.insert(BB).second;\n    if (!Inserted)\n        continue;\n\n    MachineBasicBlock *Succ = FuncInfo.MBBMap[BB];\n    addSuccessorWithProb(IndirectBrMBB, Succ);\n  }\n  IndirectBrMBB->normalizeSuccProbs();\n\n  DAG.setRoot(DAG.getNode(ISD::BRIND, getCurSDLoc(),\n                          MVT::Other, getControlRoot(),\n                          getValue(I.getAddress())));\n}\n\nvoid SelectionDAGBuilder::visitUnreachable(const UnreachableInst &I) {\n  if (!DAG.getTarget().Options.TrapUnreachable)\n    return;\n\n  // We may be able to ignore unreachable behind a noreturn call.\n  if (DAG.getTarget().Options.NoTrapAfterNoreturn) {\n    const BasicBlock &BB = *I.getParent();\n    if (&I != &BB.front()) {\n      BasicBlock::const_iterator PredI =\n        std::prev(BasicBlock::const_iterator(&I));\n      if (const CallInst *Call = dyn_cast<CallInst>(&*PredI)) {\n        if (Call->doesNotReturn())\n          return;\n      }\n    }\n  }\n\n  DAG.setRoot(DAG.getNode(ISD::TRAP, getCurSDLoc(), MVT::Other, DAG.getRoot()));\n}\n\nvoid SelectionDAGBuilder::visitUnary(const User &I, unsigned Opcode) {\n  SDNodeFlags Flags;\n\n  SDValue Op = getValue(I.getOperand(0));\n  SDValue UnNodeValue = DAG.getNode(Opcode, getCurSDLoc(), Op.getValueType(),\n                                    Op, Flags);\n  setValue(&I, UnNodeValue);\n}\n\nvoid SelectionDAGBuilder::visitBinary(const User &I, unsigned Opcode) {\n  SDNodeFlags Flags;\n  if (auto *OFBinOp = dyn_cast<OverflowingBinaryOperator>(&I)) {\n    Flags.setNoSignedWrap(OFBinOp->hasNoSignedWrap());\n    Flags.setNoUnsignedWrap(OFBinOp->hasNoUnsignedWrap());\n  }\n  if (auto *ExactOp = dyn_cast<PossiblyExactOperator>(&I))\n    Flags.setExact(ExactOp->isExact());\n  if (auto *FPOp = dyn_cast<FPMathOperator>(&I))\n    Flags.copyFMF(*FPOp);\n\n  SDValue Op1 = getValue(I.getOperand(0));\n  SDValue Op2 = getValue(I.getOperand(1));\n  SDValue BinNodeValue = DAG.getNode(Opcode, getCurSDLoc(), Op1.getValueType(),\n                                     Op1, Op2, Flags);\n  setValue(&I, BinNodeValue);\n}\n\nvoid SelectionDAGBuilder::visitShift(const User &I, unsigned Opcode) {\n  SDValue Op1 = getValue(I.getOperand(0));\n  SDValue Op2 = getValue(I.getOperand(1));\n\n  EVT ShiftTy = DAG.getTargetLoweringInfo().getShiftAmountTy(\n      Op1.getValueType(), DAG.getDataLayout());\n\n  // Coerce the shift amount to the right type if we can.\n  if (!I.getType()->isVectorTy() && Op2.getValueType() != ShiftTy) {\n    unsigned ShiftSize = ShiftTy.getSizeInBits();\n    unsigned Op2Size = Op2.getValueSizeInBits();\n    SDLoc DL = getCurSDLoc();\n\n    // If the operand is smaller than the shift count type, promote it.\n    if (ShiftSize > Op2Size)\n      Op2 = DAG.getNode(ISD::ZERO_EXTEND, DL, ShiftTy, Op2);\n\n    // If the operand is larger than the shift count type but the shift\n    // count type has enough bits to represent any shift value, truncate\n    // it now. This is a common case and it exposes the truncate to\n    // optimization early.\n    else if (ShiftSize >= Log2_32_Ceil(Op2.getValueSizeInBits()))\n      Op2 = DAG.getNode(ISD::TRUNCATE, DL, ShiftTy, Op2);\n    // Otherwise we'll need to temporarily settle for some other convenient\n    // type.  Type legalization will make adjustments once the shiftee is split.\n    else\n      Op2 = DAG.getZExtOrTrunc(Op2, DL, MVT::i32);\n  }\n\n  bool nuw = false;\n  bool nsw = false;\n  bool exact = false;\n\n  if (Opcode == ISD::SRL || Opcode == ISD::SRA || Opcode == ISD::SHL) {\n\n    if (const OverflowingBinaryOperator *OFBinOp =\n            dyn_cast<const OverflowingBinaryOperator>(&I)) {\n      nuw = OFBinOp->hasNoUnsignedWrap();\n      nsw = OFBinOp->hasNoSignedWrap();\n    }\n    if (const PossiblyExactOperator *ExactOp =\n            dyn_cast<const PossiblyExactOperator>(&I))\n      exact = ExactOp->isExact();\n  }\n  SDNodeFlags Flags;\n  Flags.setExact(exact);\n  Flags.setNoSignedWrap(nsw);\n  Flags.setNoUnsignedWrap(nuw);\n  SDValue Res = DAG.getNode(Opcode, getCurSDLoc(), Op1.getValueType(), Op1, Op2,\n                            Flags);\n  setValue(&I, Res);\n}\n\nvoid SelectionDAGBuilder::visitSDiv(const User &I) {\n  SDValue Op1 = getValue(I.getOperand(0));\n  SDValue Op2 = getValue(I.getOperand(1));\n\n  SDNodeFlags Flags;\n  Flags.setExact(isa<PossiblyExactOperator>(&I) &&\n                 cast<PossiblyExactOperator>(&I)->isExact());\n  setValue(&I, DAG.getNode(ISD::SDIV, getCurSDLoc(), Op1.getValueType(), Op1,\n                           Op2, Flags));\n}\n\nvoid SelectionDAGBuilder::visitICmp(const User &I) {\n  ICmpInst::Predicate predicate = ICmpInst::BAD_ICMP_PREDICATE;\n  if (const ICmpInst *IC = dyn_cast<ICmpInst>(&I))\n    predicate = IC->getPredicate();\n  else if (const ConstantExpr *IC = dyn_cast<ConstantExpr>(&I))\n    predicate = ICmpInst::Predicate(IC->getPredicate());\n  SDValue Op1 = getValue(I.getOperand(0));\n  SDValue Op2 = getValue(I.getOperand(1));\n  ISD::CondCode Opcode = getICmpCondCode(predicate);\n\n  auto &TLI = DAG.getTargetLoweringInfo();\n  EVT MemVT =\n      TLI.getMemValueType(DAG.getDataLayout(), I.getOperand(0)->getType());\n\n  // If a pointer's DAG type is larger than its memory type then the DAG values\n  // are zero-extended. This breaks signed comparisons so truncate back to the\n  // underlying type before doing the compare.\n  if (Op1.getValueType() != MemVT) {\n    Op1 = DAG.getPtrExtOrTrunc(Op1, getCurSDLoc(), MemVT);\n    Op2 = DAG.getPtrExtOrTrunc(Op2, getCurSDLoc(), MemVT);\n  }\n\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getSetCC(getCurSDLoc(), DestVT, Op1, Op2, Opcode));\n}\n\nvoid SelectionDAGBuilder::visitFCmp(const User &I) {\n  FCmpInst::Predicate predicate = FCmpInst::BAD_FCMP_PREDICATE;\n  if (const FCmpInst *FC = dyn_cast<FCmpInst>(&I))\n    predicate = FC->getPredicate();\n  else if (const ConstantExpr *FC = dyn_cast<ConstantExpr>(&I))\n    predicate = FCmpInst::Predicate(FC->getPredicate());\n  SDValue Op1 = getValue(I.getOperand(0));\n  SDValue Op2 = getValue(I.getOperand(1));\n\n  ISD::CondCode Condition = getFCmpCondCode(predicate);\n  auto *FPMO = cast<FPMathOperator>(&I);\n  if (FPMO->hasNoNaNs() || TM.Options.NoNaNsFPMath)\n    Condition = getFCmpCodeWithoutNaN(Condition);\n\n  SDNodeFlags Flags;\n  Flags.copyFMF(*FPMO);\n  SelectionDAG::FlagInserter FlagsInserter(DAG, Flags);\n\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getSetCC(getCurSDLoc(), DestVT, Op1, Op2, Condition));\n}\n\n// Check if the condition of the select has one use or two users that are both\n// selects with the same condition.\nstatic bool hasOnlySelectUsers(const Value *Cond) {\n  return llvm::all_of(Cond->users(), [](const Value *V) {\n    return isa<SelectInst>(V);\n  });\n}\n\nvoid SelectionDAGBuilder::visitSelect(const User &I) {\n  SmallVector<EVT, 4> ValueVTs;\n  ComputeValueVTs(DAG.getTargetLoweringInfo(), DAG.getDataLayout(), I.getType(),\n                  ValueVTs);\n  unsigned NumValues = ValueVTs.size();\n  if (NumValues == 0) return;\n\n  SmallVector<SDValue, 4> Values(NumValues);\n  SDValue Cond     = getValue(I.getOperand(0));\n  SDValue LHSVal   = getValue(I.getOperand(1));\n  SDValue RHSVal   = getValue(I.getOperand(2));\n  SmallVector<SDValue, 1> BaseOps(1, Cond);\n  ISD::NodeType OpCode =\n      Cond.getValueType().isVector() ? ISD::VSELECT : ISD::SELECT;\n\n  bool IsUnaryAbs = false;\n  bool Negate = false;\n\n  SDNodeFlags Flags;\n  if (auto *FPOp = dyn_cast<FPMathOperator>(&I))\n    Flags.copyFMF(*FPOp);\n\n  // Min/max matching is only viable if all output VTs are the same.\n  if (is_splat(ValueVTs)) {\n    EVT VT = ValueVTs[0];\n    LLVMContext &Ctx = *DAG.getContext();\n    auto &TLI = DAG.getTargetLoweringInfo();\n\n    // We care about the legality of the operation after it has been type\n    // legalized.\n    while (TLI.getTypeAction(Ctx, VT) != TargetLoweringBase::TypeLegal)\n      VT = TLI.getTypeToTransformTo(Ctx, VT);\n\n    // If the vselect is legal, assume we want to leave this as a vector setcc +\n    // vselect. Otherwise, if this is going to be scalarized, we want to see if\n    // min/max is legal on the scalar type.\n    bool UseScalarMinMax = VT.isVector() &&\n      !TLI.isOperationLegalOrCustom(ISD::VSELECT, VT);\n\n    Value *LHS, *RHS;\n    auto SPR = matchSelectPattern(const_cast<User*>(&I), LHS, RHS);\n    ISD::NodeType Opc = ISD::DELETED_NODE;\n    switch (SPR.Flavor) {\n    case SPF_UMAX:    Opc = ISD::UMAX; break;\n    case SPF_UMIN:    Opc = ISD::UMIN; break;\n    case SPF_SMAX:    Opc = ISD::SMAX; break;\n    case SPF_SMIN:    Opc = ISD::SMIN; break;\n    case SPF_FMINNUM:\n      switch (SPR.NaNBehavior) {\n      case SPNB_NA: llvm_unreachable(\"No NaN behavior for FP op?\");\n      case SPNB_RETURNS_NAN:   Opc = ISD::FMINIMUM; break;\n      case SPNB_RETURNS_OTHER: Opc = ISD::FMINNUM; break;\n      case SPNB_RETURNS_ANY: {\n        if (TLI.isOperationLegalOrCustom(ISD::FMINNUM, VT))\n          Opc = ISD::FMINNUM;\n        else if (TLI.isOperationLegalOrCustom(ISD::FMINIMUM, VT))\n          Opc = ISD::FMINIMUM;\n        else if (UseScalarMinMax)\n          Opc = TLI.isOperationLegalOrCustom(ISD::FMINNUM, VT.getScalarType()) ?\n            ISD::FMINNUM : ISD::FMINIMUM;\n        break;\n      }\n      }\n      break;\n    case SPF_FMAXNUM:\n      switch (SPR.NaNBehavior) {\n      case SPNB_NA: llvm_unreachable(\"No NaN behavior for FP op?\");\n      case SPNB_RETURNS_NAN:   Opc = ISD::FMAXIMUM; break;\n      case SPNB_RETURNS_OTHER: Opc = ISD::FMAXNUM; break;\n      case SPNB_RETURNS_ANY:\n\n        if (TLI.isOperationLegalOrCustom(ISD::FMAXNUM, VT))\n          Opc = ISD::FMAXNUM;\n        else if (TLI.isOperationLegalOrCustom(ISD::FMAXIMUM, VT))\n          Opc = ISD::FMAXIMUM;\n        else if (UseScalarMinMax)\n          Opc = TLI.isOperationLegalOrCustom(ISD::FMAXNUM, VT.getScalarType()) ?\n            ISD::FMAXNUM : ISD::FMAXIMUM;\n        break;\n      }\n      break;\n    case SPF_NABS:\n      Negate = true;\n      LLVM_FALLTHROUGH;\n    case SPF_ABS:\n      IsUnaryAbs = true;\n      Opc = ISD::ABS;\n      break;\n    default: break;\n    }\n\n    if (!IsUnaryAbs && Opc != ISD::DELETED_NODE &&\n        (TLI.isOperationLegalOrCustom(Opc, VT) ||\n         (UseScalarMinMax &&\n          TLI.isOperationLegalOrCustom(Opc, VT.getScalarType()))) &&\n        // If the underlying comparison instruction is used by any other\n        // instruction, the consumed instructions won't be destroyed, so it is\n        // not profitable to convert to a min/max.\n        hasOnlySelectUsers(cast<SelectInst>(I).getCondition())) {\n      OpCode = Opc;\n      LHSVal = getValue(LHS);\n      RHSVal = getValue(RHS);\n      BaseOps.clear();\n    }\n\n    if (IsUnaryAbs) {\n      OpCode = Opc;\n      LHSVal = getValue(LHS);\n      BaseOps.clear();\n    }\n  }\n\n  if (IsUnaryAbs) {\n    for (unsigned i = 0; i != NumValues; ++i) {\n      SDLoc dl = getCurSDLoc();\n      EVT VT = LHSVal.getNode()->getValueType(LHSVal.getResNo() + i);\n      Values[i] =\n          DAG.getNode(OpCode, dl, VT, LHSVal.getValue(LHSVal.getResNo() + i));\n      if (Negate)\n        Values[i] = DAG.getNode(ISD::SUB, dl, VT, DAG.getConstant(0, dl, VT),\n                                Values[i]);\n    }\n  } else {\n    for (unsigned i = 0; i != NumValues; ++i) {\n      SmallVector<SDValue, 3> Ops(BaseOps.begin(), BaseOps.end());\n      Ops.push_back(SDValue(LHSVal.getNode(), LHSVal.getResNo() + i));\n      Ops.push_back(SDValue(RHSVal.getNode(), RHSVal.getResNo() + i));\n      Values[i] = DAG.getNode(\n          OpCode, getCurSDLoc(),\n          LHSVal.getNode()->getValueType(LHSVal.getResNo() + i), Ops, Flags);\n    }\n  }\n\n  setValue(&I, DAG.getNode(ISD::MERGE_VALUES, getCurSDLoc(),\n                           DAG.getVTList(ValueVTs), Values));\n}\n\nvoid SelectionDAGBuilder::visitTrunc(const User &I) {\n  // TruncInst cannot be a no-op cast because sizeof(src) > sizeof(dest).\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::TRUNCATE, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitZExt(const User &I) {\n  // ZExt cannot be a no-op cast because sizeof(src) < sizeof(dest).\n  // ZExt also can't be a cast to bool for same reason. So, nothing much to do\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::ZERO_EXTEND, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitSExt(const User &I) {\n  // SExt cannot be a no-op cast because sizeof(src) < sizeof(dest).\n  // SExt also can't be a cast to bool for same reason. So, nothing much to do\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::SIGN_EXTEND, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitFPTrunc(const User &I) {\n  // FPTrunc is never a no-op cast, no need to check\n  SDValue N = getValue(I.getOperand(0));\n  SDLoc dl = getCurSDLoc();\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT DestVT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n  setValue(&I, DAG.getNode(ISD::FP_ROUND, dl, DestVT, N,\n                           DAG.getTargetConstant(\n                               0, dl, TLI.getPointerTy(DAG.getDataLayout()))));\n}\n\nvoid SelectionDAGBuilder::visitFPExt(const User &I) {\n  // FPExt is never a no-op cast, no need to check\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::FP_EXTEND, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitFPToUI(const User &I) {\n  // FPToUI is never a no-op cast, no need to check\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::FP_TO_UINT, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitFPToSI(const User &I) {\n  // FPToSI is never a no-op cast, no need to check\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::FP_TO_SINT, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitUIToFP(const User &I) {\n  // UIToFP is never a no-op cast, no need to check\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::UINT_TO_FP, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitSIToFP(const User &I) {\n  // SIToFP is never a no-op cast, no need to check\n  SDValue N = getValue(I.getOperand(0));\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  setValue(&I, DAG.getNode(ISD::SINT_TO_FP, getCurSDLoc(), DestVT, N));\n}\n\nvoid SelectionDAGBuilder::visitPtrToInt(const User &I) {\n  // What to do depends on the size of the integer and the size of the pointer.\n  // We can either truncate, zero extend, or no-op, accordingly.\n  SDValue N = getValue(I.getOperand(0));\n  auto &TLI = DAG.getTargetLoweringInfo();\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n  EVT PtrMemVT =\n      TLI.getMemValueType(DAG.getDataLayout(), I.getOperand(0)->getType());\n  N = DAG.getPtrExtOrTrunc(N, getCurSDLoc(), PtrMemVT);\n  N = DAG.getZExtOrTrunc(N, getCurSDLoc(), DestVT);\n  setValue(&I, N);\n}\n\nvoid SelectionDAGBuilder::visitIntToPtr(const User &I) {\n  // What to do depends on the size of the integer and the size of the pointer.\n  // We can either truncate, zero extend, or no-op, accordingly.\n  SDValue N = getValue(I.getOperand(0));\n  auto &TLI = DAG.getTargetLoweringInfo();\n  EVT DestVT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n  EVT PtrMemVT = TLI.getMemValueType(DAG.getDataLayout(), I.getType());\n  N = DAG.getZExtOrTrunc(N, getCurSDLoc(), PtrMemVT);\n  N = DAG.getPtrExtOrTrunc(N, getCurSDLoc(), DestVT);\n  setValue(&I, N);\n}\n\nvoid SelectionDAGBuilder::visitBitCast(const User &I) {\n  SDValue N = getValue(I.getOperand(0));\n  SDLoc dl = getCurSDLoc();\n  EVT DestVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                        I.getType());\n\n  // BitCast assures us that source and destination are the same size so this is\n  // either a BITCAST or a no-op.\n  if (DestVT != N.getValueType())\n    setValue(&I, DAG.getNode(ISD::BITCAST, dl,\n                             DestVT, N)); // convert types.\n  // Check if the original LLVM IR Operand was a ConstantInt, because getValue()\n  // might fold any kind of constant expression to an integer constant and that\n  // is not what we are looking for. Only recognize a bitcast of a genuine\n  // constant integer as an opaque constant.\n  else if(ConstantInt *C = dyn_cast<ConstantInt>(I.getOperand(0)))\n    setValue(&I, DAG.getConstant(C->getValue(), dl, DestVT, /*isTarget=*/false,\n                                 /*isOpaque*/true));\n  else\n    setValue(&I, N);            // noop cast.\n}\n\nvoid SelectionDAGBuilder::visitAddrSpaceCast(const User &I) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  const Value *SV = I.getOperand(0);\n  SDValue N = getValue(SV);\n  EVT DestVT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n\n  unsigned SrcAS = SV->getType()->getPointerAddressSpace();\n  unsigned DestAS = I.getType()->getPointerAddressSpace();\n\n  if (!TM.isNoopAddrSpaceCast(SrcAS, DestAS))\n    N = DAG.getAddrSpaceCast(getCurSDLoc(), DestVT, N, SrcAS, DestAS);\n\n  setValue(&I, N);\n}\n\nvoid SelectionDAGBuilder::visitInsertElement(const User &I) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDValue InVec = getValue(I.getOperand(0));\n  SDValue InVal = getValue(I.getOperand(1));\n  SDValue InIdx = DAG.getSExtOrTrunc(getValue(I.getOperand(2)), getCurSDLoc(),\n                                     TLI.getVectorIdxTy(DAG.getDataLayout()));\n  setValue(&I, DAG.getNode(ISD::INSERT_VECTOR_ELT, getCurSDLoc(),\n                           TLI.getValueType(DAG.getDataLayout(), I.getType()),\n                           InVec, InVal, InIdx));\n}\n\nvoid SelectionDAGBuilder::visitExtractElement(const User &I) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDValue InVec = getValue(I.getOperand(0));\n  SDValue InIdx = DAG.getSExtOrTrunc(getValue(I.getOperand(1)), getCurSDLoc(),\n                                     TLI.getVectorIdxTy(DAG.getDataLayout()));\n  setValue(&I, DAG.getNode(ISD::EXTRACT_VECTOR_ELT, getCurSDLoc(),\n                           TLI.getValueType(DAG.getDataLayout(), I.getType()),\n                           InVec, InIdx));\n}\n\nvoid SelectionDAGBuilder::visitShuffleVector(const User &I) {\n  SDValue Src1 = getValue(I.getOperand(0));\n  SDValue Src2 = getValue(I.getOperand(1));\n  ArrayRef<int> Mask;\n  if (auto *SVI = dyn_cast<ShuffleVectorInst>(&I))\n    Mask = SVI->getShuffleMask();\n  else\n    Mask = cast<ConstantExpr>(I).getShuffleMask();\n  SDLoc DL = getCurSDLoc();\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n  EVT SrcVT = Src1.getValueType();\n\n  if (all_of(Mask, [](int Elem) { return Elem == 0; }) &&\n      VT.isScalableVector()) {\n    // Canonical splat form of first element of first input vector.\n    SDValue FirstElt =\n        DAG.getNode(ISD::EXTRACT_VECTOR_ELT, DL, SrcVT.getScalarType(), Src1,\n                    DAG.getVectorIdxConstant(0, DL));\n    setValue(&I, DAG.getNode(ISD::SPLAT_VECTOR, DL, VT, FirstElt));\n    return;\n  }\n\n  // For now, we only handle splats for scalable vectors.\n  // The DAGCombiner will perform a BUILD_VECTOR -> SPLAT_VECTOR transformation\n  // for targets that support a SPLAT_VECTOR for non-scalable vector types.\n  assert(!VT.isScalableVector() && \"Unsupported scalable vector shuffle\");\n\n  unsigned SrcNumElts = SrcVT.getVectorNumElements();\n  unsigned MaskNumElts = Mask.size();\n\n  if (SrcNumElts == MaskNumElts) {\n    setValue(&I, DAG.getVectorShuffle(VT, DL, Src1, Src2, Mask));\n    return;\n  }\n\n  // Normalize the shuffle vector since mask and vector length don't match.\n  if (SrcNumElts < MaskNumElts) {\n    // Mask is longer than the source vectors. We can use concatenate vector to\n    // make the mask and vectors lengths match.\n\n    if (MaskNumElts % SrcNumElts == 0) {\n      // Mask length is a multiple of the source vector length.\n      // Check if the shuffle is some kind of concatenation of the input\n      // vectors.\n      unsigned NumConcat = MaskNumElts / SrcNumElts;\n      bool IsConcat = true;\n      SmallVector<int, 8> ConcatSrcs(NumConcat, -1);\n      for (unsigned i = 0; i != MaskNumElts; ++i) {\n        int Idx = Mask[i];\n        if (Idx < 0)\n          continue;\n        // Ensure the indices in each SrcVT sized piece are sequential and that\n        // the same source is used for the whole piece.\n        if ((Idx % SrcNumElts != (i % SrcNumElts)) ||\n            (ConcatSrcs[i / SrcNumElts] >= 0 &&\n             ConcatSrcs[i / SrcNumElts] != (int)(Idx / SrcNumElts))) {\n          IsConcat = false;\n          break;\n        }\n        // Remember which source this index came from.\n        ConcatSrcs[i / SrcNumElts] = Idx / SrcNumElts;\n      }\n\n      // The shuffle is concatenating multiple vectors together. Just emit\n      // a CONCAT_VECTORS operation.\n      if (IsConcat) {\n        SmallVector<SDValue, 8> ConcatOps;\n        for (auto Src : ConcatSrcs) {\n          if (Src < 0)\n            ConcatOps.push_back(DAG.getUNDEF(SrcVT));\n          else if (Src == 0)\n            ConcatOps.push_back(Src1);\n          else\n            ConcatOps.push_back(Src2);\n        }\n        setValue(&I, DAG.getNode(ISD::CONCAT_VECTORS, DL, VT, ConcatOps));\n        return;\n      }\n    }\n\n    unsigned PaddedMaskNumElts = alignTo(MaskNumElts, SrcNumElts);\n    unsigned NumConcat = PaddedMaskNumElts / SrcNumElts;\n    EVT PaddedVT = EVT::getVectorVT(*DAG.getContext(), VT.getScalarType(),\n                                    PaddedMaskNumElts);\n\n    // Pad both vectors with undefs to make them the same length as the mask.\n    SDValue UndefVal = DAG.getUNDEF(SrcVT);\n\n    SmallVector<SDValue, 8> MOps1(NumConcat, UndefVal);\n    SmallVector<SDValue, 8> MOps2(NumConcat, UndefVal);\n    MOps1[0] = Src1;\n    MOps2[0] = Src2;\n\n    Src1 = DAG.getNode(ISD::CONCAT_VECTORS, DL, PaddedVT, MOps1);\n    Src2 = DAG.getNode(ISD::CONCAT_VECTORS, DL, PaddedVT, MOps2);\n\n    // Readjust mask for new input vector length.\n    SmallVector<int, 8> MappedOps(PaddedMaskNumElts, -1);\n    for (unsigned i = 0; i != MaskNumElts; ++i) {\n      int Idx = Mask[i];\n      if (Idx >= (int)SrcNumElts)\n        Idx -= SrcNumElts - PaddedMaskNumElts;\n      MappedOps[i] = Idx;\n    }\n\n    SDValue Result = DAG.getVectorShuffle(PaddedVT, DL, Src1, Src2, MappedOps);\n\n    // If the concatenated vector was padded, extract a subvector with the\n    // correct number of elements.\n    if (MaskNumElts != PaddedMaskNumElts)\n      Result = DAG.getNode(ISD::EXTRACT_SUBVECTOR, DL, VT, Result,\n                           DAG.getVectorIdxConstant(0, DL));\n\n    setValue(&I, Result);\n    return;\n  }\n\n  if (SrcNumElts > MaskNumElts) {\n    // Analyze the access pattern of the vector to see if we can extract\n    // two subvectors and do the shuffle.\n    int StartIdx[2] = { -1, -1 };  // StartIdx to extract from\n    bool CanExtract = true;\n    for (int Idx : Mask) {\n      unsigned Input = 0;\n      if (Idx < 0)\n        continue;\n\n      if (Idx >= (int)SrcNumElts) {\n        Input = 1;\n        Idx -= SrcNumElts;\n      }\n\n      // If all the indices come from the same MaskNumElts sized portion of\n      // the sources we can use extract. Also make sure the extract wouldn't\n      // extract past the end of the source.\n      int NewStartIdx = alignDown(Idx, MaskNumElts);\n      if (NewStartIdx + MaskNumElts > SrcNumElts ||\n          (StartIdx[Input] >= 0 && StartIdx[Input] != NewStartIdx))\n        CanExtract = false;\n      // Make sure we always update StartIdx as we use it to track if all\n      // elements are undef.\n      StartIdx[Input] = NewStartIdx;\n    }\n\n    if (StartIdx[0] < 0 && StartIdx[1] < 0) {\n      setValue(&I, DAG.getUNDEF(VT)); // Vectors are not used.\n      return;\n    }\n    if (CanExtract) {\n      // Extract appropriate subvector and generate a vector shuffle\n      for (unsigned Input = 0; Input < 2; ++Input) {\n        SDValue &Src = Input == 0 ? Src1 : Src2;\n        if (StartIdx[Input] < 0)\n          Src = DAG.getUNDEF(VT);\n        else {\n          Src = DAG.getNode(ISD::EXTRACT_SUBVECTOR, DL, VT, Src,\n                            DAG.getVectorIdxConstant(StartIdx[Input], DL));\n        }\n      }\n\n      // Calculate new mask.\n      SmallVector<int, 8> MappedOps(Mask.begin(), Mask.end());\n      for (int &Idx : MappedOps) {\n        if (Idx >= (int)SrcNumElts)\n          Idx -= SrcNumElts + StartIdx[1] - MaskNumElts;\n        else if (Idx >= 0)\n          Idx -= StartIdx[0];\n      }\n\n      setValue(&I, DAG.getVectorShuffle(VT, DL, Src1, Src2, MappedOps));\n      return;\n    }\n  }\n\n  // We can't use either concat vectors or extract subvectors so fall back to\n  // replacing the shuffle with extract and build vector.\n  // to insert and build vector.\n  EVT EltVT = VT.getVectorElementType();\n  SmallVector<SDValue,8> Ops;\n  for (int Idx : Mask) {\n    SDValue Res;\n\n    if (Idx < 0) {\n      Res = DAG.getUNDEF(EltVT);\n    } else {\n      SDValue &Src = Idx < (int)SrcNumElts ? Src1 : Src2;\n      if (Idx >= (int)SrcNumElts) Idx -= SrcNumElts;\n\n      Res = DAG.getNode(ISD::EXTRACT_VECTOR_ELT, DL, EltVT, Src,\n                        DAG.getVectorIdxConstant(Idx, DL));\n    }\n\n    Ops.push_back(Res);\n  }\n\n  setValue(&I, DAG.getBuildVector(VT, DL, Ops));\n}\n\nvoid SelectionDAGBuilder::visitInsertValue(const User &I) {\n  ArrayRef<unsigned> Indices;\n  if (const InsertValueInst *IV = dyn_cast<InsertValueInst>(&I))\n    Indices = IV->getIndices();\n  else\n    Indices = cast<ConstantExpr>(&I)->getIndices();\n\n  const Value *Op0 = I.getOperand(0);\n  const Value *Op1 = I.getOperand(1);\n  Type *AggTy = I.getType();\n  Type *ValTy = Op1->getType();\n  bool IntoUndef = isa<UndefValue>(Op0);\n  bool FromUndef = isa<UndefValue>(Op1);\n\n  unsigned LinearIndex = ComputeLinearIndex(AggTy, Indices);\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SmallVector<EVT, 4> AggValueVTs;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), AggTy, AggValueVTs);\n  SmallVector<EVT, 4> ValValueVTs;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), ValTy, ValValueVTs);\n\n  unsigned NumAggValues = AggValueVTs.size();\n  unsigned NumValValues = ValValueVTs.size();\n  SmallVector<SDValue, 4> Values(NumAggValues);\n\n  // Ignore an insertvalue that produces an empty object\n  if (!NumAggValues) {\n    setValue(&I, DAG.getUNDEF(MVT(MVT::Other)));\n    return;\n  }\n\n  SDValue Agg = getValue(Op0);\n  unsigned i = 0;\n  // Copy the beginning value(s) from the original aggregate.\n  for (; i != LinearIndex; ++i)\n    Values[i] = IntoUndef ? DAG.getUNDEF(AggValueVTs[i]) :\n                SDValue(Agg.getNode(), Agg.getResNo() + i);\n  // Copy values from the inserted value(s).\n  if (NumValValues) {\n    SDValue Val = getValue(Op1);\n    for (; i != LinearIndex + NumValValues; ++i)\n      Values[i] = FromUndef ? DAG.getUNDEF(AggValueVTs[i]) :\n                  SDValue(Val.getNode(), Val.getResNo() + i - LinearIndex);\n  }\n  // Copy remaining value(s) from the original aggregate.\n  for (; i != NumAggValues; ++i)\n    Values[i] = IntoUndef ? DAG.getUNDEF(AggValueVTs[i]) :\n                SDValue(Agg.getNode(), Agg.getResNo() + i);\n\n  setValue(&I, DAG.getNode(ISD::MERGE_VALUES, getCurSDLoc(),\n                           DAG.getVTList(AggValueVTs), Values));\n}\n\nvoid SelectionDAGBuilder::visitExtractValue(const User &I) {\n  ArrayRef<unsigned> Indices;\n  if (const ExtractValueInst *EV = dyn_cast<ExtractValueInst>(&I))\n    Indices = EV->getIndices();\n  else\n    Indices = cast<ConstantExpr>(&I)->getIndices();\n\n  const Value *Op0 = I.getOperand(0);\n  Type *AggTy = Op0->getType();\n  Type *ValTy = I.getType();\n  bool OutOfUndef = isa<UndefValue>(Op0);\n\n  unsigned LinearIndex = ComputeLinearIndex(AggTy, Indices);\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SmallVector<EVT, 4> ValValueVTs;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), ValTy, ValValueVTs);\n\n  unsigned NumValValues = ValValueVTs.size();\n\n  // Ignore a extractvalue that produces an empty object\n  if (!NumValValues) {\n    setValue(&I, DAG.getUNDEF(MVT(MVT::Other)));\n    return;\n  }\n\n  SmallVector<SDValue, 4> Values(NumValValues);\n\n  SDValue Agg = getValue(Op0);\n  // Copy out the selected value(s).\n  for (unsigned i = LinearIndex; i != LinearIndex + NumValValues; ++i)\n    Values[i - LinearIndex] =\n      OutOfUndef ?\n        DAG.getUNDEF(Agg.getNode()->getValueType(Agg.getResNo() + i)) :\n        SDValue(Agg.getNode(), Agg.getResNo() + i);\n\n  setValue(&I, DAG.getNode(ISD::MERGE_VALUES, getCurSDLoc(),\n                           DAG.getVTList(ValValueVTs), Values));\n}\n\nvoid SelectionDAGBuilder::visitGetElementPtr(const User &I) {\n  Value *Op0 = I.getOperand(0);\n  // Note that the pointer operand may be a vector of pointers. Take the scalar\n  // element which holds a pointer.\n  unsigned AS = Op0->getType()->getScalarType()->getPointerAddressSpace();\n  SDValue N = getValue(Op0);\n  SDLoc dl = getCurSDLoc();\n  auto &TLI = DAG.getTargetLoweringInfo();\n\n  // Normalize Vector GEP - all scalar operands should be converted to the\n  // splat vector.\n  bool IsVectorGEP = I.getType()->isVectorTy();\n  ElementCount VectorElementCount =\n      IsVectorGEP ? cast<VectorType>(I.getType())->getElementCount()\n                  : ElementCount::getFixed(0);\n\n  if (IsVectorGEP && !N.getValueType().isVector()) {\n    LLVMContext &Context = *DAG.getContext();\n    EVT VT = EVT::getVectorVT(Context, N.getValueType(), VectorElementCount);\n    if (VectorElementCount.isScalable())\n      N = DAG.getSplatVector(VT, dl, N);\n    else\n      N = DAG.getSplatBuildVector(VT, dl, N);\n  }\n\n  for (gep_type_iterator GTI = gep_type_begin(&I), E = gep_type_end(&I);\n       GTI != E; ++GTI) {\n    const Value *Idx = GTI.getOperand();\n    if (StructType *StTy = GTI.getStructTypeOrNull()) {\n      unsigned Field = cast<Constant>(Idx)->getUniqueInteger().getZExtValue();\n      if (Field) {\n        // N = N + Offset\n        uint64_t Offset = DL->getStructLayout(StTy)->getElementOffset(Field);\n\n        // In an inbounds GEP with an offset that is nonnegative even when\n        // interpreted as signed, assume there is no unsigned overflow.\n        SDNodeFlags Flags;\n        if (int64_t(Offset) >= 0 && cast<GEPOperator>(I).isInBounds())\n          Flags.setNoUnsignedWrap(true);\n\n        N = DAG.getNode(ISD::ADD, dl, N.getValueType(), N,\n                        DAG.getConstant(Offset, dl, N.getValueType()), Flags);\n      }\n    } else {\n      // IdxSize is the width of the arithmetic according to IR semantics.\n      // In SelectionDAG, we may prefer to do arithmetic in a wider bitwidth\n      // (and fix up the result later).\n      unsigned IdxSize = DAG.getDataLayout().getIndexSizeInBits(AS);\n      MVT IdxTy = MVT::getIntegerVT(IdxSize);\n      TypeSize ElementSize = DL->getTypeAllocSize(GTI.getIndexedType());\n      // We intentionally mask away the high bits here; ElementSize may not\n      // fit in IdxTy.\n      APInt ElementMul(IdxSize, ElementSize.getKnownMinSize());\n      bool ElementScalable = ElementSize.isScalable();\n\n      // If this is a scalar constant or a splat vector of constants,\n      // handle it quickly.\n      const auto *C = dyn_cast<Constant>(Idx);\n      if (C && isa<VectorType>(C->getType()))\n        C = C->getSplatValue();\n\n      const auto *CI = dyn_cast_or_null<ConstantInt>(C);\n      if (CI && CI->isZero())\n        continue;\n      if (CI && !ElementScalable) {\n        APInt Offs = ElementMul * CI->getValue().sextOrTrunc(IdxSize);\n        LLVMContext &Context = *DAG.getContext();\n        SDValue OffsVal;\n        if (IsVectorGEP)\n          OffsVal = DAG.getConstant(\n              Offs, dl, EVT::getVectorVT(Context, IdxTy, VectorElementCount));\n        else\n          OffsVal = DAG.getConstant(Offs, dl, IdxTy);\n\n        // In an inbounds GEP with an offset that is nonnegative even when\n        // interpreted as signed, assume there is no unsigned overflow.\n        SDNodeFlags Flags;\n        if (Offs.isNonNegative() && cast<GEPOperator>(I).isInBounds())\n          Flags.setNoUnsignedWrap(true);\n\n        OffsVal = DAG.getSExtOrTrunc(OffsVal, dl, N.getValueType());\n\n        N = DAG.getNode(ISD::ADD, dl, N.getValueType(), N, OffsVal, Flags);\n        continue;\n      }\n\n      // N = N + Idx * ElementMul;\n      SDValue IdxN = getValue(Idx);\n\n      if (!IdxN.getValueType().isVector() && IsVectorGEP) {\n        EVT VT = EVT::getVectorVT(*Context, IdxN.getValueType(),\n                                  VectorElementCount);\n        if (VectorElementCount.isScalable())\n          IdxN = DAG.getSplatVector(VT, dl, IdxN);\n        else\n          IdxN = DAG.getSplatBuildVector(VT, dl, IdxN);\n      }\n\n      // If the index is smaller or larger than intptr_t, truncate or extend\n      // it.\n      IdxN = DAG.getSExtOrTrunc(IdxN, dl, N.getValueType());\n\n      if (ElementScalable) {\n        EVT VScaleTy = N.getValueType().getScalarType();\n        SDValue VScale = DAG.getNode(\n            ISD::VSCALE, dl, VScaleTy,\n            DAG.getConstant(ElementMul.getZExtValue(), dl, VScaleTy));\n        if (IsVectorGEP)\n          VScale = DAG.getSplatVector(N.getValueType(), dl, VScale);\n        IdxN = DAG.getNode(ISD::MUL, dl, N.getValueType(), IdxN, VScale);\n      } else {\n        // If this is a multiply by a power of two, turn it into a shl\n        // immediately.  This is a very common case.\n        if (ElementMul != 1) {\n          if (ElementMul.isPowerOf2()) {\n            unsigned Amt = ElementMul.logBase2();\n            IdxN = DAG.getNode(ISD::SHL, dl,\n                               N.getValueType(), IdxN,\n                               DAG.getConstant(Amt, dl, IdxN.getValueType()));\n          } else {\n            SDValue Scale = DAG.getConstant(ElementMul.getZExtValue(), dl,\n                                            IdxN.getValueType());\n            IdxN = DAG.getNode(ISD::MUL, dl,\n                               N.getValueType(), IdxN, Scale);\n          }\n        }\n      }\n\n      N = DAG.getNode(ISD::ADD, dl,\n                      N.getValueType(), N, IdxN);\n    }\n  }\n\n  MVT PtrTy = TLI.getPointerTy(DAG.getDataLayout(), AS);\n  MVT PtrMemTy = TLI.getPointerMemTy(DAG.getDataLayout(), AS);\n  if (IsVectorGEP) {\n    PtrTy = MVT::getVectorVT(PtrTy, VectorElementCount);\n    PtrMemTy = MVT::getVectorVT(PtrMemTy, VectorElementCount);\n  }\n\n  if (PtrMemTy != PtrTy && !cast<GEPOperator>(I).isInBounds())\n    N = DAG.getPtrExtendInReg(N, dl, PtrMemTy);\n\n  setValue(&I, N);\n}\n\nvoid SelectionDAGBuilder::visitAlloca(const AllocaInst &I) {\n  // If this is a fixed sized alloca in the entry block of the function,\n  // allocate it statically on the stack.\n  if (FuncInfo.StaticAllocaMap.count(&I))\n    return;   // getValue will auto-populate this.\n\n  SDLoc dl = getCurSDLoc();\n  Type *Ty = I.getAllocatedType();\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  auto &DL = DAG.getDataLayout();\n  uint64_t TySize = DL.getTypeAllocSize(Ty);\n  MaybeAlign Alignment = std::max(DL.getPrefTypeAlign(Ty), I.getAlign());\n\n  SDValue AllocSize = getValue(I.getArraySize());\n\n  EVT IntPtr = TLI.getPointerTy(DAG.getDataLayout(), DL.getAllocaAddrSpace());\n  if (AllocSize.getValueType() != IntPtr)\n    AllocSize = DAG.getZExtOrTrunc(AllocSize, dl, IntPtr);\n\n  AllocSize = DAG.getNode(ISD::MUL, dl, IntPtr,\n                          AllocSize,\n                          DAG.getConstant(TySize, dl, IntPtr));\n\n  // Handle alignment.  If the requested alignment is less than or equal to\n  // the stack alignment, ignore it.  If the size is greater than or equal to\n  // the stack alignment, we note this in the DYNAMIC_STACKALLOC node.\n  Align StackAlign = DAG.getSubtarget().getFrameLowering()->getStackAlign();\n  if (*Alignment <= StackAlign)\n    Alignment = None;\n\n  const uint64_t StackAlignMask = StackAlign.value() - 1U;\n  // Round the size of the allocation up to the stack alignment size\n  // by add SA-1 to the size. This doesn't overflow because we're computing\n  // an address inside an alloca.\n  SDNodeFlags Flags;\n  Flags.setNoUnsignedWrap(true);\n  AllocSize = DAG.getNode(ISD::ADD, dl, AllocSize.getValueType(), AllocSize,\n                          DAG.getConstant(StackAlignMask, dl, IntPtr), Flags);\n\n  // Mask out the low bits for alignment purposes.\n  AllocSize = DAG.getNode(ISD::AND, dl, AllocSize.getValueType(), AllocSize,\n                          DAG.getConstant(~StackAlignMask, dl, IntPtr));\n\n  SDValue Ops[] = {\n      getRoot(), AllocSize,\n      DAG.getConstant(Alignment ? Alignment->value() : 0, dl, IntPtr)};\n  SDVTList VTs = DAG.getVTList(AllocSize.getValueType(), MVT::Other);\n  SDValue DSA = DAG.getNode(ISD::DYNAMIC_STACKALLOC, dl, VTs, Ops);\n  setValue(&I, DSA);\n  DAG.setRoot(DSA.getValue(1));\n\n  assert(FuncInfo.MF->getFrameInfo().hasVarSizedObjects());\n}\n\nvoid SelectionDAGBuilder::visitLoad(const LoadInst &I) {\n  if (I.isAtomic())\n    return visitAtomicLoad(I);\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  const Value *SV = I.getOperand(0);\n  if (TLI.supportSwiftError()) {\n    // Swifterror values can come from either a function parameter with\n    // swifterror attribute or an alloca with swifterror attribute.\n    if (const Argument *Arg = dyn_cast<Argument>(SV)) {\n      if (Arg->hasSwiftErrorAttr())\n        return visitLoadFromSwiftError(I);\n    }\n\n    if (const AllocaInst *Alloca = dyn_cast<AllocaInst>(SV)) {\n      if (Alloca->isSwiftError())\n        return visitLoadFromSwiftError(I);\n    }\n  }\n\n  SDValue Ptr = getValue(SV);\n\n  Type *Ty = I.getType();\n  Align Alignment = I.getAlign();\n\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n  const MDNode *Ranges = I.getMetadata(LLVMContext::MD_range);\n\n  SmallVector<EVT, 4> ValueVTs, MemVTs;\n  SmallVector<uint64_t, 4> Offsets;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), Ty, ValueVTs, &MemVTs, &Offsets);\n  unsigned NumValues = ValueVTs.size();\n  if (NumValues == 0)\n    return;\n\n  bool isVolatile = I.isVolatile();\n\n  SDValue Root;\n  bool ConstantMemory = false;\n  if (isVolatile)\n    // Serialize volatile loads with other side effects.\n    Root = getRoot();\n  else if (NumValues > MaxParallelChains)\n    Root = getMemoryRoot();\n  else if (AA &&\n           AA->pointsToConstantMemory(MemoryLocation(\n               SV,\n               LocationSize::precise(DAG.getDataLayout().getTypeStoreSize(Ty)),\n               AAInfo))) {\n    // Do not serialize (non-volatile) loads of constant memory with anything.\n    Root = DAG.getEntryNode();\n    ConstantMemory = true;\n  } else {\n    // Do not serialize non-volatile loads against each other.\n    Root = DAG.getRoot();\n  }\n\n  SDLoc dl = getCurSDLoc();\n\n  if (isVolatile)\n    Root = TLI.prepareVolatileOrAtomicLoad(Root, dl, DAG);\n\n  // An aggregate load cannot wrap around the address space, so offsets to its\n  // parts don't wrap either.\n  SDNodeFlags Flags;\n  Flags.setNoUnsignedWrap(true);\n\n  SmallVector<SDValue, 4> Values(NumValues);\n  SmallVector<SDValue, 4> Chains(std::min(MaxParallelChains, NumValues));\n  EVT PtrVT = Ptr.getValueType();\n\n  MachineMemOperand::Flags MMOFlags\n    = TLI.getLoadMemOperandFlags(I, DAG.getDataLayout());\n\n  unsigned ChainI = 0;\n  for (unsigned i = 0; i != NumValues; ++i, ++ChainI) {\n    // Serializing loads here may result in excessive register pressure, and\n    // TokenFactor places arbitrary choke points on the scheduler. SD scheduling\n    // could recover a bit by hoisting nodes upward in the chain by recognizing\n    // they are side-effect free or do not alias. The optimizer should really\n    // avoid this case by converting large object/array copies to llvm.memcpy\n    // (MaxParallelChains should always remain as failsafe).\n    if (ChainI == MaxParallelChains) {\n      assert(PendingLoads.empty() && \"PendingLoads must be serialized first\");\n      SDValue Chain = DAG.getNode(ISD::TokenFactor, dl, MVT::Other,\n                                  makeArrayRef(Chains.data(), ChainI));\n      Root = Chain;\n      ChainI = 0;\n    }\n    SDValue A = DAG.getNode(ISD::ADD, dl,\n                            PtrVT, Ptr,\n                            DAG.getConstant(Offsets[i], dl, PtrVT),\n                            Flags);\n\n    SDValue L = DAG.getLoad(MemVTs[i], dl, Root, A,\n                            MachinePointerInfo(SV, Offsets[i]), Alignment,\n                            MMOFlags, AAInfo, Ranges);\n    Chains[ChainI] = L.getValue(1);\n\n    if (MemVTs[i] != ValueVTs[i])\n      L = DAG.getZExtOrTrunc(L, dl, ValueVTs[i]);\n\n    Values[i] = L;\n  }\n\n  if (!ConstantMemory) {\n    SDValue Chain = DAG.getNode(ISD::TokenFactor, dl, MVT::Other,\n                                makeArrayRef(Chains.data(), ChainI));\n    if (isVolatile)\n      DAG.setRoot(Chain);\n    else\n      PendingLoads.push_back(Chain);\n  }\n\n  setValue(&I, DAG.getNode(ISD::MERGE_VALUES, dl,\n                           DAG.getVTList(ValueVTs), Values));\n}\n\nvoid SelectionDAGBuilder::visitStoreToSwiftError(const StoreInst &I) {\n  assert(DAG.getTargetLoweringInfo().supportSwiftError() &&\n         \"call visitStoreToSwiftError when backend supports swifterror\");\n\n  SmallVector<EVT, 4> ValueVTs;\n  SmallVector<uint64_t, 4> Offsets;\n  const Value *SrcV = I.getOperand(0);\n  ComputeValueVTs(DAG.getTargetLoweringInfo(), DAG.getDataLayout(),\n                  SrcV->getType(), ValueVTs, &Offsets);\n  assert(ValueVTs.size() == 1 && Offsets[0] == 0 &&\n         \"expect a single EVT for swifterror\");\n\n  SDValue Src = getValue(SrcV);\n  // Create a virtual register, then update the virtual register.\n  Register VReg =\n      SwiftError.getOrCreateVRegDefAt(&I, FuncInfo.MBB, I.getPointerOperand());\n  // Chain, DL, Reg, N or Chain, DL, Reg, N, Glue\n  // Chain can be getRoot or getControlRoot.\n  SDValue CopyNode = DAG.getCopyToReg(getRoot(), getCurSDLoc(), VReg,\n                                      SDValue(Src.getNode(), Src.getResNo()));\n  DAG.setRoot(CopyNode);\n}\n\nvoid SelectionDAGBuilder::visitLoadFromSwiftError(const LoadInst &I) {\n  assert(DAG.getTargetLoweringInfo().supportSwiftError() &&\n         \"call visitLoadFromSwiftError when backend supports swifterror\");\n\n  assert(!I.isVolatile() &&\n         !I.hasMetadata(LLVMContext::MD_nontemporal) &&\n         !I.hasMetadata(LLVMContext::MD_invariant_load) &&\n         \"Support volatile, non temporal, invariant for load_from_swift_error\");\n\n  const Value *SV = I.getOperand(0);\n  Type *Ty = I.getType();\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n  assert(\n      (!AA ||\n       !AA->pointsToConstantMemory(MemoryLocation(\n           SV, LocationSize::precise(DAG.getDataLayout().getTypeStoreSize(Ty)),\n           AAInfo))) &&\n      \"load_from_swift_error should not be constant memory\");\n\n  SmallVector<EVT, 4> ValueVTs;\n  SmallVector<uint64_t, 4> Offsets;\n  ComputeValueVTs(DAG.getTargetLoweringInfo(), DAG.getDataLayout(), Ty,\n                  ValueVTs, &Offsets);\n  assert(ValueVTs.size() == 1 && Offsets[0] == 0 &&\n         \"expect a single EVT for swifterror\");\n\n  // Chain, DL, Reg, VT, Glue or Chain, DL, Reg, VT\n  SDValue L = DAG.getCopyFromReg(\n      getRoot(), getCurSDLoc(),\n      SwiftError.getOrCreateVRegUseAt(&I, FuncInfo.MBB, SV), ValueVTs[0]);\n\n  setValue(&I, L);\n}\n\nvoid SelectionDAGBuilder::visitStore(const StoreInst &I) {\n  if (I.isAtomic())\n    return visitAtomicStore(I);\n\n  const Value *SrcV = I.getOperand(0);\n  const Value *PtrV = I.getOperand(1);\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  if (TLI.supportSwiftError()) {\n    // Swifterror values can come from either a function parameter with\n    // swifterror attribute or an alloca with swifterror attribute.\n    if (const Argument *Arg = dyn_cast<Argument>(PtrV)) {\n      if (Arg->hasSwiftErrorAttr())\n        return visitStoreToSwiftError(I);\n    }\n\n    if (const AllocaInst *Alloca = dyn_cast<AllocaInst>(PtrV)) {\n      if (Alloca->isSwiftError())\n        return visitStoreToSwiftError(I);\n    }\n  }\n\n  SmallVector<EVT, 4> ValueVTs, MemVTs;\n  SmallVector<uint64_t, 4> Offsets;\n  ComputeValueVTs(DAG.getTargetLoweringInfo(), DAG.getDataLayout(),\n                  SrcV->getType(), ValueVTs, &MemVTs, &Offsets);\n  unsigned NumValues = ValueVTs.size();\n  if (NumValues == 0)\n    return;\n\n  // Get the lowered operands. Note that we do this after\n  // checking if NumResults is zero, because with zero results\n  // the operands won't have values in the map.\n  SDValue Src = getValue(SrcV);\n  SDValue Ptr = getValue(PtrV);\n\n  SDValue Root = I.isVolatile() ? getRoot() : getMemoryRoot();\n  SmallVector<SDValue, 4> Chains(std::min(MaxParallelChains, NumValues));\n  SDLoc dl = getCurSDLoc();\n  Align Alignment = I.getAlign();\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n\n  auto MMOFlags = TLI.getStoreMemOperandFlags(I, DAG.getDataLayout());\n\n  // An aggregate load cannot wrap around the address space, so offsets to its\n  // parts don't wrap either.\n  SDNodeFlags Flags;\n  Flags.setNoUnsignedWrap(true);\n\n  unsigned ChainI = 0;\n  for (unsigned i = 0; i != NumValues; ++i, ++ChainI) {\n    // See visitLoad comments.\n    if (ChainI == MaxParallelChains) {\n      SDValue Chain = DAG.getNode(ISD::TokenFactor, dl, MVT::Other,\n                                  makeArrayRef(Chains.data(), ChainI));\n      Root = Chain;\n      ChainI = 0;\n    }\n    SDValue Add =\n        DAG.getMemBasePlusOffset(Ptr, TypeSize::Fixed(Offsets[i]), dl, Flags);\n    SDValue Val = SDValue(Src.getNode(), Src.getResNo() + i);\n    if (MemVTs[i] != ValueVTs[i])\n      Val = DAG.getPtrExtOrTrunc(Val, dl, MemVTs[i]);\n    SDValue St =\n        DAG.getStore(Root, dl, Val, Add, MachinePointerInfo(PtrV, Offsets[i]),\n                     Alignment, MMOFlags, AAInfo);\n    Chains[ChainI] = St;\n  }\n\n  SDValue StoreNode = DAG.getNode(ISD::TokenFactor, dl, MVT::Other,\n                                  makeArrayRef(Chains.data(), ChainI));\n  DAG.setRoot(StoreNode);\n}\n\nvoid SelectionDAGBuilder::visitMaskedStore(const CallInst &I,\n                                           bool IsCompressing) {\n  SDLoc sdl = getCurSDLoc();\n\n  auto getMaskedStoreOps = [&](Value *&Ptr, Value *&Mask, Value *&Src0,\n                               MaybeAlign &Alignment) {\n    // llvm.masked.store.*(Src0, Ptr, alignment, Mask)\n    Src0 = I.getArgOperand(0);\n    Ptr = I.getArgOperand(1);\n    Alignment = cast<ConstantInt>(I.getArgOperand(2))->getMaybeAlignValue();\n    Mask = I.getArgOperand(3);\n  };\n  auto getCompressingStoreOps = [&](Value *&Ptr, Value *&Mask, Value *&Src0,\n                                    MaybeAlign &Alignment) {\n    // llvm.masked.compressstore.*(Src0, Ptr, Mask)\n    Src0 = I.getArgOperand(0);\n    Ptr = I.getArgOperand(1);\n    Mask = I.getArgOperand(2);\n    Alignment = None;\n  };\n\n  Value  *PtrOperand, *MaskOperand, *Src0Operand;\n  MaybeAlign Alignment;\n  if (IsCompressing)\n    getCompressingStoreOps(PtrOperand, MaskOperand, Src0Operand, Alignment);\n  else\n    getMaskedStoreOps(PtrOperand, MaskOperand, Src0Operand, Alignment);\n\n  SDValue Ptr = getValue(PtrOperand);\n  SDValue Src0 = getValue(Src0Operand);\n  SDValue Mask = getValue(MaskOperand);\n  SDValue Offset = DAG.getUNDEF(Ptr.getValueType());\n\n  EVT VT = Src0.getValueType();\n  if (!Alignment)\n    Alignment = DAG.getEVTAlign(VT);\n\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n\n  MachineMemOperand *MMO = DAG.getMachineFunction().getMachineMemOperand(\n      MachinePointerInfo(PtrOperand), MachineMemOperand::MOStore,\n      // TODO: Make MachineMemOperands aware of scalable\n      // vectors.\n      VT.getStoreSize().getKnownMinSize(), *Alignment, AAInfo);\n  SDValue StoreNode =\n      DAG.getMaskedStore(getMemoryRoot(), sdl, Src0, Ptr, Offset, Mask, VT, MMO,\n                         ISD::UNINDEXED, false /* Truncating */, IsCompressing);\n  DAG.setRoot(StoreNode);\n  setValue(&I, StoreNode);\n}\n\n// Get a uniform base for the Gather/Scatter intrinsic.\n// The first argument of the Gather/Scatter intrinsic is a vector of pointers.\n// We try to represent it as a base pointer + vector of indices.\n// Usually, the vector of pointers comes from a 'getelementptr' instruction.\n// The first operand of the GEP may be a single pointer or a vector of pointers\n// Example:\n//   %gep.ptr = getelementptr i32, <8 x i32*> %vptr, <8 x i32> %ind\n//  or\n//   %gep.ptr = getelementptr i32, i32* %ptr,        <8 x i32> %ind\n// %res = call <8 x i32> @llvm.masked.gather.v8i32(<8 x i32*> %gep.ptr, ..\n//\n// When the first GEP operand is a single pointer - it is the uniform base we\n// are looking for. If first operand of the GEP is a splat vector - we\n// extract the splat value and use it as a uniform base.\n// In all other cases the function returns 'false'.\nstatic bool getUniformBase(const Value *Ptr, SDValue &Base, SDValue &Index,\n                           ISD::MemIndexType &IndexType, SDValue &Scale,\n                           SelectionDAGBuilder *SDB, const BasicBlock *CurBB) {\n  SelectionDAG& DAG = SDB->DAG;\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  const DataLayout &DL = DAG.getDataLayout();\n\n  assert(Ptr->getType()->isVectorTy() && \"Uexpected pointer type\");\n\n  // Handle splat constant pointer.\n  if (auto *C = dyn_cast<Constant>(Ptr)) {\n    C = C->getSplatValue();\n    if (!C)\n      return false;\n\n    Base = SDB->getValue(C);\n\n    unsigned NumElts = cast<FixedVectorType>(Ptr->getType())->getNumElements();\n    EVT VT = EVT::getVectorVT(*DAG.getContext(), TLI.getPointerTy(DL), NumElts);\n    Index = DAG.getConstant(0, SDB->getCurSDLoc(), VT);\n    IndexType = ISD::SIGNED_SCALED;\n    Scale = DAG.getTargetConstant(1, SDB->getCurSDLoc(), TLI.getPointerTy(DL));\n    return true;\n  }\n\n  const GetElementPtrInst *GEP = dyn_cast<GetElementPtrInst>(Ptr);\n  if (!GEP || GEP->getParent() != CurBB)\n    return false;\n\n  if (GEP->getNumOperands() != 2)\n    return false;\n\n  const Value *BasePtr = GEP->getPointerOperand();\n  const Value *IndexVal = GEP->getOperand(GEP->getNumOperands() - 1);\n\n  // Make sure the base is scalar and the index is a vector.\n  if (BasePtr->getType()->isVectorTy() || !IndexVal->getType()->isVectorTy())\n    return false;\n\n  Base = SDB->getValue(BasePtr);\n  Index = SDB->getValue(IndexVal);\n  IndexType = ISD::SIGNED_SCALED;\n  Scale = DAG.getTargetConstant(\n              DL.getTypeAllocSize(GEP->getResultElementType()),\n              SDB->getCurSDLoc(), TLI.getPointerTy(DL));\n  return true;\n}\n\nvoid SelectionDAGBuilder::visitMaskedScatter(const CallInst &I) {\n  SDLoc sdl = getCurSDLoc();\n\n  // llvm.masked.scatter.*(Src0, Ptrs, alignment, Mask)\n  const Value *Ptr = I.getArgOperand(1);\n  SDValue Src0 = getValue(I.getArgOperand(0));\n  SDValue Mask = getValue(I.getArgOperand(3));\n  EVT VT = Src0.getValueType();\n  Align Alignment = cast<ConstantInt>(I.getArgOperand(2))\n                        ->getMaybeAlignValue()\n                        .getValueOr(DAG.getEVTAlign(VT));\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n\n  SDValue Base;\n  SDValue Index;\n  ISD::MemIndexType IndexType;\n  SDValue Scale;\n  bool UniformBase = getUniformBase(Ptr, Base, Index, IndexType, Scale, this,\n                                    I.getParent());\n\n  unsigned AS = Ptr->getType()->getScalarType()->getPointerAddressSpace();\n  MachineMemOperand *MMO = DAG.getMachineFunction().getMachineMemOperand(\n      MachinePointerInfo(AS), MachineMemOperand::MOStore,\n      // TODO: Make MachineMemOperands aware of scalable\n      // vectors.\n      MemoryLocation::UnknownSize, Alignment, AAInfo);\n  if (!UniformBase) {\n    Base = DAG.getConstant(0, sdl, TLI.getPointerTy(DAG.getDataLayout()));\n    Index = getValue(Ptr);\n    IndexType = ISD::SIGNED_UNSCALED;\n    Scale = DAG.getTargetConstant(1, sdl, TLI.getPointerTy(DAG.getDataLayout()));\n  }\n\n  EVT IdxVT = Index.getValueType();\n  EVT EltTy = IdxVT.getVectorElementType();\n  if (TLI.shouldExtendGSIndex(IdxVT, EltTy)) {\n    EVT NewIdxVT = IdxVT.changeVectorElementType(EltTy);\n    Index = DAG.getNode(ISD::SIGN_EXTEND, sdl, NewIdxVT, Index);\n  }\n\n  SDValue Ops[] = { getMemoryRoot(), Src0, Mask, Base, Index, Scale };\n  SDValue Scatter = DAG.getMaskedScatter(DAG.getVTList(MVT::Other), VT, sdl,\n                                         Ops, MMO, IndexType, false);\n  DAG.setRoot(Scatter);\n  setValue(&I, Scatter);\n}\n\nvoid SelectionDAGBuilder::visitMaskedLoad(const CallInst &I, bool IsExpanding) {\n  SDLoc sdl = getCurSDLoc();\n\n  auto getMaskedLoadOps = [&](Value *&Ptr, Value *&Mask, Value *&Src0,\n                              MaybeAlign &Alignment) {\n    // @llvm.masked.load.*(Ptr, alignment, Mask, Src0)\n    Ptr = I.getArgOperand(0);\n    Alignment = cast<ConstantInt>(I.getArgOperand(1))->getMaybeAlignValue();\n    Mask = I.getArgOperand(2);\n    Src0 = I.getArgOperand(3);\n  };\n  auto getExpandingLoadOps = [&](Value *&Ptr, Value *&Mask, Value *&Src0,\n                                 MaybeAlign &Alignment) {\n    // @llvm.masked.expandload.*(Ptr, Mask, Src0)\n    Ptr = I.getArgOperand(0);\n    Alignment = None;\n    Mask = I.getArgOperand(1);\n    Src0 = I.getArgOperand(2);\n  };\n\n  Value  *PtrOperand, *MaskOperand, *Src0Operand;\n  MaybeAlign Alignment;\n  if (IsExpanding)\n    getExpandingLoadOps(PtrOperand, MaskOperand, Src0Operand, Alignment);\n  else\n    getMaskedLoadOps(PtrOperand, MaskOperand, Src0Operand, Alignment);\n\n  SDValue Ptr = getValue(PtrOperand);\n  SDValue Src0 = getValue(Src0Operand);\n  SDValue Mask = getValue(MaskOperand);\n  SDValue Offset = DAG.getUNDEF(Ptr.getValueType());\n\n  EVT VT = Src0.getValueType();\n  if (!Alignment)\n    Alignment = DAG.getEVTAlign(VT);\n\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n  const MDNode *Ranges = I.getMetadata(LLVMContext::MD_range);\n\n  // Do not serialize masked loads of constant memory with anything.\n  MemoryLocation ML;\n  if (VT.isScalableVector())\n    ML = MemoryLocation::getAfter(PtrOperand);\n  else\n    ML = MemoryLocation(PtrOperand, LocationSize::precise(\n                           DAG.getDataLayout().getTypeStoreSize(I.getType())),\n                           AAInfo);\n  bool AddToChain = !AA || !AA->pointsToConstantMemory(ML);\n\n  SDValue InChain = AddToChain ? DAG.getRoot() : DAG.getEntryNode();\n\n  MachineMemOperand *MMO = DAG.getMachineFunction().getMachineMemOperand(\n      MachinePointerInfo(PtrOperand), MachineMemOperand::MOLoad,\n      // TODO: Make MachineMemOperands aware of scalable\n      // vectors.\n      VT.getStoreSize().getKnownMinSize(), *Alignment, AAInfo, Ranges);\n\n  SDValue Load =\n      DAG.getMaskedLoad(VT, sdl, InChain, Ptr, Offset, Mask, Src0, VT, MMO,\n                        ISD::UNINDEXED, ISD::NON_EXTLOAD, IsExpanding);\n  if (AddToChain)\n    PendingLoads.push_back(Load.getValue(1));\n  setValue(&I, Load);\n}\n\nvoid SelectionDAGBuilder::visitMaskedGather(const CallInst &I) {\n  SDLoc sdl = getCurSDLoc();\n\n  // @llvm.masked.gather.*(Ptrs, alignment, Mask, Src0)\n  const Value *Ptr = I.getArgOperand(0);\n  SDValue Src0 = getValue(I.getArgOperand(3));\n  SDValue Mask = getValue(I.getArgOperand(2));\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n  Align Alignment = cast<ConstantInt>(I.getArgOperand(1))\n                        ->getMaybeAlignValue()\n                        .getValueOr(DAG.getEVTAlign(VT));\n\n  AAMDNodes AAInfo;\n  I.getAAMetadata(AAInfo);\n  const MDNode *Ranges = I.getMetadata(LLVMContext::MD_range);\n\n  SDValue Root = DAG.getRoot();\n  SDValue Base;\n  SDValue Index;\n  ISD::MemIndexType IndexType;\n  SDValue Scale;\n  bool UniformBase = getUniformBase(Ptr, Base, Index, IndexType, Scale, this,\n                                    I.getParent());\n  unsigned AS = Ptr->getType()->getScalarType()->getPointerAddressSpace();\n  MachineMemOperand *MMO = DAG.getMachineFunction().getMachineMemOperand(\n      MachinePointerInfo(AS), MachineMemOperand::MOLoad,\n      // TODO: Make MachineMemOperands aware of scalable\n      // vectors.\n      MemoryLocation::UnknownSize, Alignment, AAInfo, Ranges);\n\n  if (!UniformBase) {\n    Base = DAG.getConstant(0, sdl, TLI.getPointerTy(DAG.getDataLayout()));\n    Index = getValue(Ptr);\n    IndexType = ISD::SIGNED_UNSCALED;\n    Scale = DAG.getTargetConstant(1, sdl, TLI.getPointerTy(DAG.getDataLayout()));\n  }\n\n  EVT IdxVT = Index.getValueType();\n  EVT EltTy = IdxVT.getVectorElementType();\n  if (TLI.shouldExtendGSIndex(IdxVT, EltTy)) {\n    EVT NewIdxVT = IdxVT.changeVectorElementType(EltTy);\n    Index = DAG.getNode(ISD::SIGN_EXTEND, sdl, NewIdxVT, Index);\n  }\n\n  SDValue Ops[] = { Root, Src0, Mask, Base, Index, Scale };\n  SDValue Gather = DAG.getMaskedGather(DAG.getVTList(VT, MVT::Other), VT, sdl,\n                                       Ops, MMO, IndexType, ISD::NON_EXTLOAD);\n\n  PendingLoads.push_back(Gather.getValue(1));\n  setValue(&I, Gather);\n}\n\nvoid SelectionDAGBuilder::visitAtomicCmpXchg(const AtomicCmpXchgInst &I) {\n  SDLoc dl = getCurSDLoc();\n  AtomicOrdering SuccessOrdering = I.getSuccessOrdering();\n  AtomicOrdering FailureOrdering = I.getFailureOrdering();\n  SyncScope::ID SSID = I.getSyncScopeID();\n\n  SDValue InChain = getRoot();\n\n  MVT MemVT = getValue(I.getCompareOperand()).getSimpleValueType();\n  SDVTList VTs = DAG.getVTList(MemVT, MVT::i1, MVT::Other);\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  auto Flags = TLI.getAtomicMemOperandFlags(I, DAG.getDataLayout());\n\n  MachineFunction &MF = DAG.getMachineFunction();\n  MachineMemOperand *MMO = MF.getMachineMemOperand(\n      MachinePointerInfo(I.getPointerOperand()), Flags, MemVT.getStoreSize(),\n      DAG.getEVTAlign(MemVT), AAMDNodes(), nullptr, SSID, SuccessOrdering,\n      FailureOrdering);\n\n  SDValue L = DAG.getAtomicCmpSwap(ISD::ATOMIC_CMP_SWAP_WITH_SUCCESS,\n                                   dl, MemVT, VTs, InChain,\n                                   getValue(I.getPointerOperand()),\n                                   getValue(I.getCompareOperand()),\n                                   getValue(I.getNewValOperand()), MMO);\n\n  SDValue OutChain = L.getValue(2);\n\n  setValue(&I, L);\n  DAG.setRoot(OutChain);\n}\n\nvoid SelectionDAGBuilder::visitAtomicRMW(const AtomicRMWInst &I) {\n  SDLoc dl = getCurSDLoc();\n  ISD::NodeType NT;\n  switch (I.getOperation()) {\n  default: llvm_unreachable(\"Unknown atomicrmw operation\");\n  case AtomicRMWInst::Xchg: NT = ISD::ATOMIC_SWAP; break;\n  case AtomicRMWInst::Add:  NT = ISD::ATOMIC_LOAD_ADD; break;\n  case AtomicRMWInst::Sub:  NT = ISD::ATOMIC_LOAD_SUB; break;\n  case AtomicRMWInst::And:  NT = ISD::ATOMIC_LOAD_AND; break;\n  case AtomicRMWInst::Nand: NT = ISD::ATOMIC_LOAD_NAND; break;\n  case AtomicRMWInst::Or:   NT = ISD::ATOMIC_LOAD_OR; break;\n  case AtomicRMWInst::Xor:  NT = ISD::ATOMIC_LOAD_XOR; break;\n  case AtomicRMWInst::Max:  NT = ISD::ATOMIC_LOAD_MAX; break;\n  case AtomicRMWInst::Min:  NT = ISD::ATOMIC_LOAD_MIN; break;\n  case AtomicRMWInst::UMax: NT = ISD::ATOMIC_LOAD_UMAX; break;\n  case AtomicRMWInst::UMin: NT = ISD::ATOMIC_LOAD_UMIN; break;\n  case AtomicRMWInst::FAdd: NT = ISD::ATOMIC_LOAD_FADD; break;\n  case AtomicRMWInst::FSub: NT = ISD::ATOMIC_LOAD_FSUB; break;\n  }\n  AtomicOrdering Ordering = I.getOrdering();\n  SyncScope::ID SSID = I.getSyncScopeID();\n\n  SDValue InChain = getRoot();\n\n  auto MemVT = getValue(I.getValOperand()).getSimpleValueType();\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  auto Flags = TLI.getAtomicMemOperandFlags(I, DAG.getDataLayout());\n\n  MachineFunction &MF = DAG.getMachineFunction();\n  MachineMemOperand *MMO = MF.getMachineMemOperand(\n      MachinePointerInfo(I.getPointerOperand()), Flags, MemVT.getStoreSize(),\n      DAG.getEVTAlign(MemVT), AAMDNodes(), nullptr, SSID, Ordering);\n\n  SDValue L =\n    DAG.getAtomic(NT, dl, MemVT, InChain,\n                  getValue(I.getPointerOperand()), getValue(I.getValOperand()),\n                  MMO);\n\n  SDValue OutChain = L.getValue(1);\n\n  setValue(&I, L);\n  DAG.setRoot(OutChain);\n}\n\nvoid SelectionDAGBuilder::visitFence(const FenceInst &I) {\n  SDLoc dl = getCurSDLoc();\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDValue Ops[3];\n  Ops[0] = getRoot();\n  Ops[1] = DAG.getTargetConstant((unsigned)I.getOrdering(), dl,\n                                 TLI.getFenceOperandTy(DAG.getDataLayout()));\n  Ops[2] = DAG.getTargetConstant(I.getSyncScopeID(), dl,\n                                 TLI.getFenceOperandTy(DAG.getDataLayout()));\n  DAG.setRoot(DAG.getNode(ISD::ATOMIC_FENCE, dl, MVT::Other, Ops));\n}\n\nvoid SelectionDAGBuilder::visitAtomicLoad(const LoadInst &I) {\n  SDLoc dl = getCurSDLoc();\n  AtomicOrdering Order = I.getOrdering();\n  SyncScope::ID SSID = I.getSyncScopeID();\n\n  SDValue InChain = getRoot();\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n  EVT MemVT = TLI.getMemValueType(DAG.getDataLayout(), I.getType());\n\n  if (!TLI.supportsUnalignedAtomics() &&\n      I.getAlignment() < MemVT.getSizeInBits() / 8)\n    report_fatal_error(\"Cannot generate unaligned atomic load\");\n\n  auto Flags = TLI.getLoadMemOperandFlags(I, DAG.getDataLayout());\n\n  MachineMemOperand *MMO = DAG.getMachineFunction().getMachineMemOperand(\n      MachinePointerInfo(I.getPointerOperand()), Flags, MemVT.getStoreSize(),\n      I.getAlign(), AAMDNodes(), nullptr, SSID, Order);\n\n  InChain = TLI.prepareVolatileOrAtomicLoad(InChain, dl, DAG);\n\n  SDValue Ptr = getValue(I.getPointerOperand());\n\n  if (TLI.lowerAtomicLoadAsLoadSDNode(I)) {\n    // TODO: Once this is better exercised by tests, it should be merged with\n    // the normal path for loads to prevent future divergence.\n    SDValue L = DAG.getLoad(MemVT, dl, InChain, Ptr, MMO);\n    if (MemVT != VT)\n      L = DAG.getPtrExtOrTrunc(L, dl, VT);\n\n    setValue(&I, L);\n    SDValue OutChain = L.getValue(1);\n    if (!I.isUnordered())\n      DAG.setRoot(OutChain);\n    else\n      PendingLoads.push_back(OutChain);\n    return;\n  }\n\n  SDValue L = DAG.getAtomic(ISD::ATOMIC_LOAD, dl, MemVT, MemVT, InChain,\n                            Ptr, MMO);\n\n  SDValue OutChain = L.getValue(1);\n  if (MemVT != VT)\n    L = DAG.getPtrExtOrTrunc(L, dl, VT);\n\n  setValue(&I, L);\n  DAG.setRoot(OutChain);\n}\n\nvoid SelectionDAGBuilder::visitAtomicStore(const StoreInst &I) {\n  SDLoc dl = getCurSDLoc();\n\n  AtomicOrdering Ordering = I.getOrdering();\n  SyncScope::ID SSID = I.getSyncScopeID();\n\n  SDValue InChain = getRoot();\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  EVT MemVT =\n      TLI.getMemValueType(DAG.getDataLayout(), I.getValueOperand()->getType());\n\n  if (I.getAlignment() < MemVT.getSizeInBits() / 8)\n    report_fatal_error(\"Cannot generate unaligned atomic store\");\n\n  auto Flags = TLI.getStoreMemOperandFlags(I, DAG.getDataLayout());\n\n  MachineFunction &MF = DAG.getMachineFunction();\n  MachineMemOperand *MMO = MF.getMachineMemOperand(\n      MachinePointerInfo(I.getPointerOperand()), Flags, MemVT.getStoreSize(),\n      I.getAlign(), AAMDNodes(), nullptr, SSID, Ordering);\n\n  SDValue Val = getValue(I.getValueOperand());\n  if (Val.getValueType() != MemVT)\n    Val = DAG.getPtrExtOrTrunc(Val, dl, MemVT);\n  SDValue Ptr = getValue(I.getPointerOperand());\n\n  if (TLI.lowerAtomicStoreAsStoreSDNode(I)) {\n    // TODO: Once this is better exercised by tests, it should be merged with\n    // the normal path for stores to prevent future divergence.\n    SDValue S = DAG.getStore(InChain, dl, Val, Ptr, MMO);\n    DAG.setRoot(S);\n    return;\n  }\n  SDValue OutChain = DAG.getAtomic(ISD::ATOMIC_STORE, dl, MemVT, InChain,\n                                   Ptr, Val, MMO);\n\n\n  DAG.setRoot(OutChain);\n}\n\n/// visitTargetIntrinsic - Lower a call of a target intrinsic to an INTRINSIC\n/// node.\nvoid SelectionDAGBuilder::visitTargetIntrinsic(const CallInst &I,\n                                               unsigned Intrinsic) {\n  // Ignore the callsite's attributes. A specific call site may be marked with\n  // readnone, but the lowering code will expect the chain based on the\n  // definition.\n  const Function *F = I.getCalledFunction();\n  bool HasChain = !F->doesNotAccessMemory();\n  bool OnlyLoad = HasChain && F->onlyReadsMemory();\n\n  // Build the operand list.\n  SmallVector<SDValue, 8> Ops;\n  if (HasChain) {  // If this intrinsic has side-effects, chainify it.\n    if (OnlyLoad) {\n      // We don't need to serialize loads against other loads.\n      Ops.push_back(DAG.getRoot());\n    } else {\n      Ops.push_back(getRoot());\n    }\n  }\n\n  // Info is set by getTgtMemInstrinsic\n  TargetLowering::IntrinsicInfo Info;\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  bool IsTgtIntrinsic = TLI.getTgtMemIntrinsic(Info, I,\n                                               DAG.getMachineFunction(),\n                                               Intrinsic);\n\n  // Add the intrinsic ID as an integer operand if it's not a target intrinsic.\n  if (!IsTgtIntrinsic || Info.opc == ISD::INTRINSIC_VOID ||\n      Info.opc == ISD::INTRINSIC_W_CHAIN)\n    Ops.push_back(DAG.getTargetConstant(Intrinsic, getCurSDLoc(),\n                                        TLI.getPointerTy(DAG.getDataLayout())));\n\n  // Add all operands of the call to the operand list.\n  for (unsigned i = 0, e = I.getNumArgOperands(); i != e; ++i) {\n    const Value *Arg = I.getArgOperand(i);\n    if (!I.paramHasAttr(i, Attribute::ImmArg)) {\n      Ops.push_back(getValue(Arg));\n      continue;\n    }\n\n    // Use TargetConstant instead of a regular constant for immarg.\n    EVT VT = TLI.getValueType(*DL, Arg->getType(), true);\n    if (const ConstantInt *CI = dyn_cast<ConstantInt>(Arg)) {\n      assert(CI->getBitWidth() <= 64 &&\n             \"large intrinsic immediates not handled\");\n      Ops.push_back(DAG.getTargetConstant(*CI, SDLoc(), VT));\n    } else {\n      Ops.push_back(\n          DAG.getTargetConstantFP(*cast<ConstantFP>(Arg), SDLoc(), VT));\n    }\n  }\n\n  SmallVector<EVT, 4> ValueVTs;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), I.getType(), ValueVTs);\n\n  if (HasChain)\n    ValueVTs.push_back(MVT::Other);\n\n  SDVTList VTs = DAG.getVTList(ValueVTs);\n\n  // Create the node.\n  SDValue Result;\n  if (IsTgtIntrinsic) {\n    // This is target intrinsic that touches memory\n    AAMDNodes AAInfo;\n    I.getAAMetadata(AAInfo);\n    Result =\n        DAG.getMemIntrinsicNode(Info.opc, getCurSDLoc(), VTs, Ops, Info.memVT,\n                                MachinePointerInfo(Info.ptrVal, Info.offset),\n                                Info.align, Info.flags, Info.size, AAInfo);\n  } else if (!HasChain) {\n    Result = DAG.getNode(ISD::INTRINSIC_WO_CHAIN, getCurSDLoc(), VTs, Ops);\n  } else if (!I.getType()->isVoidTy()) {\n    Result = DAG.getNode(ISD::INTRINSIC_W_CHAIN, getCurSDLoc(), VTs, Ops);\n  } else {\n    Result = DAG.getNode(ISD::INTRINSIC_VOID, getCurSDLoc(), VTs, Ops);\n  }\n\n  if (HasChain) {\n    SDValue Chain = Result.getValue(Result.getNode()->getNumValues()-1);\n    if (OnlyLoad)\n      PendingLoads.push_back(Chain);\n    else\n      DAG.setRoot(Chain);\n  }\n\n  if (!I.getType()->isVoidTy()) {\n    if (VectorType *PTy = dyn_cast<VectorType>(I.getType())) {\n      EVT VT = TLI.getValueType(DAG.getDataLayout(), PTy);\n      Result = DAG.getNode(ISD::BITCAST, getCurSDLoc(), VT, Result);\n    } else\n      Result = lowerRangeToAssertZExt(DAG, I, Result);\n\n    MaybeAlign Alignment = I.getRetAlign();\n    if (!Alignment)\n      Alignment = F->getAttributes().getRetAlignment();\n    // Insert `assertalign` node if there's an alignment.\n    if (InsertAssertAlign && Alignment) {\n      Result =\n          DAG.getAssertAlign(getCurSDLoc(), Result, Alignment.valueOrOne());\n    }\n\n    setValue(&I, Result);\n  }\n}\n\n/// GetSignificand - Get the significand and build it into a floating-point\n/// number with exponent of 1:\n///\n///   Op = (Op & 0x007fffff) | 0x3f800000;\n///\n/// where Op is the hexadecimal representation of floating point value.\nstatic SDValue GetSignificand(SelectionDAG &DAG, SDValue Op, const SDLoc &dl) {\n  SDValue t1 = DAG.getNode(ISD::AND, dl, MVT::i32, Op,\n                           DAG.getConstant(0x007fffff, dl, MVT::i32));\n  SDValue t2 = DAG.getNode(ISD::OR, dl, MVT::i32, t1,\n                           DAG.getConstant(0x3f800000, dl, MVT::i32));\n  return DAG.getNode(ISD::BITCAST, dl, MVT::f32, t2);\n}\n\n/// GetExponent - Get the exponent:\n///\n///   (float)(int)(((Op & 0x7f800000) >> 23) - 127);\n///\n/// where Op is the hexadecimal representation of floating point value.\nstatic SDValue GetExponent(SelectionDAG &DAG, SDValue Op,\n                           const TargetLowering &TLI, const SDLoc &dl) {\n  SDValue t0 = DAG.getNode(ISD::AND, dl, MVT::i32, Op,\n                           DAG.getConstant(0x7f800000, dl, MVT::i32));\n  SDValue t1 = DAG.getNode(\n      ISD::SRL, dl, MVT::i32, t0,\n      DAG.getConstant(23, dl, TLI.getPointerTy(DAG.getDataLayout())));\n  SDValue t2 = DAG.getNode(ISD::SUB, dl, MVT::i32, t1,\n                           DAG.getConstant(127, dl, MVT::i32));\n  return DAG.getNode(ISD::SINT_TO_FP, dl, MVT::f32, t2);\n}\n\n/// getF32Constant - Get 32-bit floating point constant.\nstatic SDValue getF32Constant(SelectionDAG &DAG, unsigned Flt,\n                              const SDLoc &dl) {\n  return DAG.getConstantFP(APFloat(APFloat::IEEEsingle(), APInt(32, Flt)), dl,\n                           MVT::f32);\n}\n\nstatic SDValue getLimitedPrecisionExp2(SDValue t0, const SDLoc &dl,\n                                       SelectionDAG &DAG) {\n  // TODO: What fast-math-flags should be set on the floating-point nodes?\n\n  //   IntegerPartOfX = ((int32_t)(t0);\n  SDValue IntegerPartOfX = DAG.getNode(ISD::FP_TO_SINT, dl, MVT::i32, t0);\n\n  //   FractionalPartOfX = t0 - (float)IntegerPartOfX;\n  SDValue t1 = DAG.getNode(ISD::SINT_TO_FP, dl, MVT::f32, IntegerPartOfX);\n  SDValue X = DAG.getNode(ISD::FSUB, dl, MVT::f32, t0, t1);\n\n  //   IntegerPartOfX <<= 23;\n  IntegerPartOfX = DAG.getNode(\n      ISD::SHL, dl, MVT::i32, IntegerPartOfX,\n      DAG.getConstant(23, dl, DAG.getTargetLoweringInfo().getPointerTy(\n                                  DAG.getDataLayout())));\n\n  SDValue TwoToFractionalPartOfX;\n  if (LimitFloatPrecision <= 6) {\n    // For floating-point precision of 6:\n    //\n    //   TwoToFractionalPartOfX =\n    //     0.997535578f +\n    //       (0.735607626f + 0.252464424f * x) * x;\n    //\n    // error 0.0144103317, which is 6 bits\n    SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                             getF32Constant(DAG, 0x3e814304, dl));\n    SDValue t3 = DAG.getNode(ISD::FADD, dl, MVT::f32, t2,\n                             getF32Constant(DAG, 0x3f3c50c8, dl));\n    SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n    TwoToFractionalPartOfX = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                                         getF32Constant(DAG, 0x3f7f5e7e, dl));\n  } else if (LimitFloatPrecision <= 12) {\n    // For floating-point precision of 12:\n    //\n    //   TwoToFractionalPartOfX =\n    //     0.999892986f +\n    //       (0.696457318f +\n    //         (0.224338339f + 0.792043434e-1f * x) * x) * x;\n    //\n    // error 0.000107046256, which is 13 to 14 bits\n    SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                             getF32Constant(DAG, 0x3da235e3, dl));\n    SDValue t3 = DAG.getNode(ISD::FADD, dl, MVT::f32, t2,\n                             getF32Constant(DAG, 0x3e65b8f3, dl));\n    SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n    SDValue t5 = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                             getF32Constant(DAG, 0x3f324b07, dl));\n    SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n    TwoToFractionalPartOfX = DAG.getNode(ISD::FADD, dl, MVT::f32, t6,\n                                         getF32Constant(DAG, 0x3f7ff8fd, dl));\n  } else { // LimitFloatPrecision <= 18\n    // For floating-point precision of 18:\n    //\n    //   TwoToFractionalPartOfX =\n    //     0.999999982f +\n    //       (0.693148872f +\n    //         (0.240227044f +\n    //           (0.554906021e-1f +\n    //             (0.961591928e-2f +\n    //               (0.136028312e-2f + 0.157059148e-3f *x)*x)*x)*x)*x)*x;\n    // error 2.47208000*10^(-7), which is better than 18 bits\n    SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                             getF32Constant(DAG, 0x3924b03e, dl));\n    SDValue t3 = DAG.getNode(ISD::FADD, dl, MVT::f32, t2,\n                             getF32Constant(DAG, 0x3ab24b87, dl));\n    SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n    SDValue t5 = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                             getF32Constant(DAG, 0x3c1d8c17, dl));\n    SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n    SDValue t7 = DAG.getNode(ISD::FADD, dl, MVT::f32, t6,\n                             getF32Constant(DAG, 0x3d634a1d, dl));\n    SDValue t8 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t7, X);\n    SDValue t9 = DAG.getNode(ISD::FADD, dl, MVT::f32, t8,\n                             getF32Constant(DAG, 0x3e75fe14, dl));\n    SDValue t10 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t9, X);\n    SDValue t11 = DAG.getNode(ISD::FADD, dl, MVT::f32, t10,\n                              getF32Constant(DAG, 0x3f317234, dl));\n    SDValue t12 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t11, X);\n    TwoToFractionalPartOfX = DAG.getNode(ISD::FADD, dl, MVT::f32, t12,\n                                         getF32Constant(DAG, 0x3f800000, dl));\n  }\n\n  // Add the exponent into the result in integer domain.\n  SDValue t13 = DAG.getNode(ISD::BITCAST, dl, MVT::i32, TwoToFractionalPartOfX);\n  return DAG.getNode(ISD::BITCAST, dl, MVT::f32,\n                     DAG.getNode(ISD::ADD, dl, MVT::i32, t13, IntegerPartOfX));\n}\n\n/// expandExp - Lower an exp intrinsic. Handles the special sequences for\n/// limited-precision mode.\nstatic SDValue expandExp(const SDLoc &dl, SDValue Op, SelectionDAG &DAG,\n                         const TargetLowering &TLI, SDNodeFlags Flags) {\n  if (Op.getValueType() == MVT::f32 &&\n      LimitFloatPrecision > 0 && LimitFloatPrecision <= 18) {\n\n    // Put the exponent in the right bit position for later addition to the\n    // final result:\n    //\n    // t0 = Op * log2(e)\n\n    // TODO: What fast-math-flags should be set here?\n    SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, Op,\n                             DAG.getConstantFP(numbers::log2ef, dl, MVT::f32));\n    return getLimitedPrecisionExp2(t0, dl, DAG);\n  }\n\n  // No special expansion.\n  return DAG.getNode(ISD::FEXP, dl, Op.getValueType(), Op, Flags);\n}\n\n/// expandLog - Lower a log intrinsic. Handles the special sequences for\n/// limited-precision mode.\nstatic SDValue expandLog(const SDLoc &dl, SDValue Op, SelectionDAG &DAG,\n                         const TargetLowering &TLI, SDNodeFlags Flags) {\n  // TODO: What fast-math-flags should be set on the floating-point nodes?\n\n  if (Op.getValueType() == MVT::f32 &&\n      LimitFloatPrecision > 0 && LimitFloatPrecision <= 18) {\n    SDValue Op1 = DAG.getNode(ISD::BITCAST, dl, MVT::i32, Op);\n\n    // Scale the exponent by log(2).\n    SDValue Exp = GetExponent(DAG, Op1, TLI, dl);\n    SDValue LogOfExponent =\n        DAG.getNode(ISD::FMUL, dl, MVT::f32, Exp,\n                    DAG.getConstantFP(numbers::ln2f, dl, MVT::f32));\n\n    // Get the significand and build it into a floating-point number with\n    // exponent of 1.\n    SDValue X = GetSignificand(DAG, Op1, dl);\n\n    SDValue LogOfMantissa;\n    if (LimitFloatPrecision <= 6) {\n      // For floating-point precision of 6:\n      //\n      //   LogofMantissa =\n      //     -1.1609546f +\n      //       (1.4034025f - 0.23903021f * x) * x;\n      //\n      // error 0.0034276066, which is better than 8 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbe74c456, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3fb3a2b1, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      LogOfMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                                  getF32Constant(DAG, 0x3f949a29, dl));\n    } else if (LimitFloatPrecision <= 12) {\n      // For floating-point precision of 12:\n      //\n      //   LogOfMantissa =\n      //     -1.7417939f +\n      //       (2.8212026f +\n      //         (-1.4699568f +\n      //           (0.44717955f - 0.56570851e-1f * x) * x) * x) * x;\n      //\n      // error 0.000061011436, which is 14 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbd67b6d6, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3ee4f4b8, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      SDValue t3 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                               getF32Constant(DAG, 0x3fbc278b, dl));\n      SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n      SDValue t5 = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                               getF32Constant(DAG, 0x40348e95, dl));\n      SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n      LogOfMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t6,\n                                  getF32Constant(DAG, 0x3fdef31a, dl));\n    } else { // LimitFloatPrecision <= 18\n      // For floating-point precision of 18:\n      //\n      //   LogOfMantissa =\n      //     -2.1072184f +\n      //       (4.2372794f +\n      //         (-3.7029485f +\n      //           (2.2781945f +\n      //             (-0.87823314f +\n      //               (0.19073739f - 0.17809712e-1f * x) * x) * x) * x) * x)*x;\n      //\n      // error 0.0000023660568, which is better than 18 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbc91e5ac, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3e4350aa, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      SDValue t3 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                               getF32Constant(DAG, 0x3f60d3e3, dl));\n      SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n      SDValue t5 = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                               getF32Constant(DAG, 0x4011cdf0, dl));\n      SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n      SDValue t7 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t6,\n                               getF32Constant(DAG, 0x406cfd1c, dl));\n      SDValue t8 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t7, X);\n      SDValue t9 = DAG.getNode(ISD::FADD, dl, MVT::f32, t8,\n                               getF32Constant(DAG, 0x408797cb, dl));\n      SDValue t10 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t9, X);\n      LogOfMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t10,\n                                  getF32Constant(DAG, 0x4006dcab, dl));\n    }\n\n    return DAG.getNode(ISD::FADD, dl, MVT::f32, LogOfExponent, LogOfMantissa);\n  }\n\n  // No special expansion.\n  return DAG.getNode(ISD::FLOG, dl, Op.getValueType(), Op, Flags);\n}\n\n/// expandLog2 - Lower a log2 intrinsic. Handles the special sequences for\n/// limited-precision mode.\nstatic SDValue expandLog2(const SDLoc &dl, SDValue Op, SelectionDAG &DAG,\n                          const TargetLowering &TLI, SDNodeFlags Flags) {\n  // TODO: What fast-math-flags should be set on the floating-point nodes?\n\n  if (Op.getValueType() == MVT::f32 &&\n      LimitFloatPrecision > 0 && LimitFloatPrecision <= 18) {\n    SDValue Op1 = DAG.getNode(ISD::BITCAST, dl, MVT::i32, Op);\n\n    // Get the exponent.\n    SDValue LogOfExponent = GetExponent(DAG, Op1, TLI, dl);\n\n    // Get the significand and build it into a floating-point number with\n    // exponent of 1.\n    SDValue X = GetSignificand(DAG, Op1, dl);\n\n    // Different possible minimax approximations of significand in\n    // floating-point for various degrees of accuracy over [1,2].\n    SDValue Log2ofMantissa;\n    if (LimitFloatPrecision <= 6) {\n      // For floating-point precision of 6:\n      //\n      //   Log2ofMantissa = -1.6749035f + (2.0246817f - .34484768f * x) * x;\n      //\n      // error 0.0049451742, which is more than 7 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbeb08fe0, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x40019463, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      Log2ofMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                                   getF32Constant(DAG, 0x3fd6633d, dl));\n    } else if (LimitFloatPrecision <= 12) {\n      // For floating-point precision of 12:\n      //\n      //   Log2ofMantissa =\n      //     -2.51285454f +\n      //       (4.07009056f +\n      //         (-2.12067489f +\n      //           (.645142248f - 0.816157886e-1f * x) * x) * x) * x;\n      //\n      // error 0.0000876136000, which is better than 13 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbda7262e, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3f25280b, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      SDValue t3 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                               getF32Constant(DAG, 0x4007b923, dl));\n      SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n      SDValue t5 = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                               getF32Constant(DAG, 0x40823e2f, dl));\n      SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n      Log2ofMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t6,\n                                   getF32Constant(DAG, 0x4020d29c, dl));\n    } else { // LimitFloatPrecision <= 18\n      // For floating-point precision of 18:\n      //\n      //   Log2ofMantissa =\n      //     -3.0400495f +\n      //       (6.1129976f +\n      //         (-5.3420409f +\n      //           (3.2865683f +\n      //             (-1.2669343f +\n      //               (0.27515199f -\n      //                 0.25691327e-1f * x) * x) * x) * x) * x) * x;\n      //\n      // error 0.0000018516, which is better than 18 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbcd2769e, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3e8ce0b9, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      SDValue t3 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                               getF32Constant(DAG, 0x3fa22ae7, dl));\n      SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n      SDValue t5 = DAG.getNode(ISD::FADD, dl, MVT::f32, t4,\n                               getF32Constant(DAG, 0x40525723, dl));\n      SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n      SDValue t7 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t6,\n                               getF32Constant(DAG, 0x40aaf200, dl));\n      SDValue t8 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t7, X);\n      SDValue t9 = DAG.getNode(ISD::FADD, dl, MVT::f32, t8,\n                               getF32Constant(DAG, 0x40c39dad, dl));\n      SDValue t10 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t9, X);\n      Log2ofMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t10,\n                                   getF32Constant(DAG, 0x4042902c, dl));\n    }\n\n    return DAG.getNode(ISD::FADD, dl, MVT::f32, LogOfExponent, Log2ofMantissa);\n  }\n\n  // No special expansion.\n  return DAG.getNode(ISD::FLOG2, dl, Op.getValueType(), Op, Flags);\n}\n\n/// expandLog10 - Lower a log10 intrinsic. Handles the special sequences for\n/// limited-precision mode.\nstatic SDValue expandLog10(const SDLoc &dl, SDValue Op, SelectionDAG &DAG,\n                           const TargetLowering &TLI, SDNodeFlags Flags) {\n  // TODO: What fast-math-flags should be set on the floating-point nodes?\n\n  if (Op.getValueType() == MVT::f32 &&\n      LimitFloatPrecision > 0 && LimitFloatPrecision <= 18) {\n    SDValue Op1 = DAG.getNode(ISD::BITCAST, dl, MVT::i32, Op);\n\n    // Scale the exponent by log10(2) [0.30102999f].\n    SDValue Exp = GetExponent(DAG, Op1, TLI, dl);\n    SDValue LogOfExponent = DAG.getNode(ISD::FMUL, dl, MVT::f32, Exp,\n                                        getF32Constant(DAG, 0x3e9a209a, dl));\n\n    // Get the significand and build it into a floating-point number with\n    // exponent of 1.\n    SDValue X = GetSignificand(DAG, Op1, dl);\n\n    SDValue Log10ofMantissa;\n    if (LimitFloatPrecision <= 6) {\n      // For floating-point precision of 6:\n      //\n      //   Log10ofMantissa =\n      //     -0.50419619f +\n      //       (0.60948995f - 0.10380950f * x) * x;\n      //\n      // error 0.0014886165, which is 6 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0xbdd49a13, dl));\n      SDValue t1 = DAG.getNode(ISD::FADD, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3f1c0789, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      Log10ofMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t2,\n                                    getF32Constant(DAG, 0x3f011300, dl));\n    } else if (LimitFloatPrecision <= 12) {\n      // For floating-point precision of 12:\n      //\n      //   Log10ofMantissa =\n      //     -0.64831180f +\n      //       (0.91751397f +\n      //         (-0.31664806f + 0.47637168e-1f * x) * x) * x;\n      //\n      // error 0.00019228036, which is better than 12 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0x3d431f31, dl));\n      SDValue t1 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3ea21fb2, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      SDValue t3 = DAG.getNode(ISD::FADD, dl, MVT::f32, t2,\n                               getF32Constant(DAG, 0x3f6ae232, dl));\n      SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n      Log10ofMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t4,\n                                    getF32Constant(DAG, 0x3f25f7c3, dl));\n    } else { // LimitFloatPrecision <= 18\n      // For floating-point precision of 18:\n      //\n      //   Log10ofMantissa =\n      //     -0.84299375f +\n      //       (1.5327582f +\n      //         (-1.0688956f +\n      //           (0.49102474f +\n      //             (-0.12539807f + 0.13508273e-1f * x) * x) * x) * x) * x;\n      //\n      // error 0.0000037995730, which is better than 18 bits\n      SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, X,\n                               getF32Constant(DAG, 0x3c5d51ce, dl));\n      SDValue t1 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t0,\n                               getF32Constant(DAG, 0x3e00685a, dl));\n      SDValue t2 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t1, X);\n      SDValue t3 = DAG.getNode(ISD::FADD, dl, MVT::f32, t2,\n                               getF32Constant(DAG, 0x3efb6798, dl));\n      SDValue t4 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t3, X);\n      SDValue t5 = DAG.getNode(ISD::FSUB, dl, MVT::f32, t4,\n                               getF32Constant(DAG, 0x3f88d192, dl));\n      SDValue t6 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t5, X);\n      SDValue t7 = DAG.getNode(ISD::FADD, dl, MVT::f32, t6,\n                               getF32Constant(DAG, 0x3fc4316c, dl));\n      SDValue t8 = DAG.getNode(ISD::FMUL, dl, MVT::f32, t7, X);\n      Log10ofMantissa = DAG.getNode(ISD::FSUB, dl, MVT::f32, t8,\n                                    getF32Constant(DAG, 0x3f57ce70, dl));\n    }\n\n    return DAG.getNode(ISD::FADD, dl, MVT::f32, LogOfExponent, Log10ofMantissa);\n  }\n\n  // No special expansion.\n  return DAG.getNode(ISD::FLOG10, dl, Op.getValueType(), Op, Flags);\n}\n\n/// expandExp2 - Lower an exp2 intrinsic. Handles the special sequences for\n/// limited-precision mode.\nstatic SDValue expandExp2(const SDLoc &dl, SDValue Op, SelectionDAG &DAG,\n                          const TargetLowering &TLI, SDNodeFlags Flags) {\n  if (Op.getValueType() == MVT::f32 &&\n      LimitFloatPrecision > 0 && LimitFloatPrecision <= 18)\n    return getLimitedPrecisionExp2(Op, dl, DAG);\n\n  // No special expansion.\n  return DAG.getNode(ISD::FEXP2, dl, Op.getValueType(), Op, Flags);\n}\n\n/// visitPow - Lower a pow intrinsic. Handles the special sequences for\n/// limited-precision mode with x == 10.0f.\nstatic SDValue expandPow(const SDLoc &dl, SDValue LHS, SDValue RHS,\n                         SelectionDAG &DAG, const TargetLowering &TLI,\n                         SDNodeFlags Flags) {\n  bool IsExp10 = false;\n  if (LHS.getValueType() == MVT::f32 && RHS.getValueType() == MVT::f32 &&\n      LimitFloatPrecision > 0 && LimitFloatPrecision <= 18) {\n    if (ConstantFPSDNode *LHSC = dyn_cast<ConstantFPSDNode>(LHS)) {\n      APFloat Ten(10.0f);\n      IsExp10 = LHSC->isExactlyValue(Ten);\n    }\n  }\n\n  // TODO: What fast-math-flags should be set on the FMUL node?\n  if (IsExp10) {\n    // Put the exponent in the right bit position for later addition to the\n    // final result:\n    //\n    //   #define LOG2OF10 3.3219281f\n    //   t0 = Op * LOG2OF10;\n    SDValue t0 = DAG.getNode(ISD::FMUL, dl, MVT::f32, RHS,\n                             getF32Constant(DAG, 0x40549a78, dl));\n    return getLimitedPrecisionExp2(t0, dl, DAG);\n  }\n\n  // No special expansion.\n  return DAG.getNode(ISD::FPOW, dl, LHS.getValueType(), LHS, RHS, Flags);\n}\n\n/// ExpandPowI - Expand a llvm.powi intrinsic.\nstatic SDValue ExpandPowI(const SDLoc &DL, SDValue LHS, SDValue RHS,\n                          SelectionDAG &DAG) {\n  // If RHS is a constant, we can expand this out to a multiplication tree,\n  // otherwise we end up lowering to a call to __powidf2 (for example).  When\n  // optimizing for size, we only want to do this if the expansion would produce\n  // a small number of multiplies, otherwise we do the full expansion.\n  if (ConstantSDNode *RHSC = dyn_cast<ConstantSDNode>(RHS)) {\n    // Get the exponent as a positive value.\n    unsigned Val = RHSC->getSExtValue();\n    if ((int)Val < 0) Val = -Val;\n\n    // powi(x, 0) -> 1.0\n    if (Val == 0)\n      return DAG.getConstantFP(1.0, DL, LHS.getValueType());\n\n    bool OptForSize = DAG.shouldOptForSize();\n    if (!OptForSize ||\n        // If optimizing for size, don't insert too many multiplies.\n        // This inserts up to 5 multiplies.\n        countPopulation(Val) + Log2_32(Val) < 7) {\n      // We use the simple binary decomposition method to generate the multiply\n      // sequence.  There are more optimal ways to do this (for example,\n      // powi(x,15) generates one more multiply than it should), but this has\n      // the benefit of being both really simple and much better than a libcall.\n      SDValue Res;  // Logically starts equal to 1.0\n      SDValue CurSquare = LHS;\n      // TODO: Intrinsics should have fast-math-flags that propagate to these\n      // nodes.\n      while (Val) {\n        if (Val & 1) {\n          if (Res.getNode())\n            Res = DAG.getNode(ISD::FMUL, DL,Res.getValueType(), Res, CurSquare);\n          else\n            Res = CurSquare;  // 1.0*CurSquare.\n        }\n\n        CurSquare = DAG.getNode(ISD::FMUL, DL, CurSquare.getValueType(),\n                                CurSquare, CurSquare);\n        Val >>= 1;\n      }\n\n      // If the original was negative, invert the result, producing 1/(x*x*x).\n      if (RHSC->getSExtValue() < 0)\n        Res = DAG.getNode(ISD::FDIV, DL, LHS.getValueType(),\n                          DAG.getConstantFP(1.0, DL, LHS.getValueType()), Res);\n      return Res;\n    }\n  }\n\n  // Otherwise, expand to a libcall.\n  return DAG.getNode(ISD::FPOWI, DL, LHS.getValueType(), LHS, RHS);\n}\n\nstatic SDValue expandDivFix(unsigned Opcode, const SDLoc &DL,\n                            SDValue LHS, SDValue RHS, SDValue Scale,\n                            SelectionDAG &DAG, const TargetLowering &TLI) {\n  EVT VT = LHS.getValueType();\n  bool Signed = Opcode == ISD::SDIVFIX || Opcode == ISD::SDIVFIXSAT;\n  bool Saturating = Opcode == ISD::SDIVFIXSAT || Opcode == ISD::UDIVFIXSAT;\n  LLVMContext &Ctx = *DAG.getContext();\n\n  // If the type is legal but the operation isn't, this node might survive all\n  // the way to operation legalization. If we end up there and we do not have\n  // the ability to widen the type (if VT*2 is not legal), we cannot expand the\n  // node.\n\n  // Coax the legalizer into expanding the node during type legalization instead\n  // by bumping the size by one bit. This will force it to Promote, enabling the\n  // early expansion and avoiding the need to expand later.\n\n  // We don't have to do this if Scale is 0; that can always be expanded, unless\n  // it's a saturating signed operation. Those can experience true integer\n  // division overflow, a case which we must avoid.\n\n  // FIXME: We wouldn't have to do this (or any of the early\n  // expansion/promotion) if it was possible to expand a libcall of an\n  // illegal type during operation legalization. But it's not, so things\n  // get a bit hacky.\n  unsigned ScaleInt = cast<ConstantSDNode>(Scale)->getZExtValue();\n  if ((ScaleInt > 0 || (Saturating && Signed)) &&\n      (TLI.isTypeLegal(VT) ||\n       (VT.isVector() && TLI.isTypeLegal(VT.getVectorElementType())))) {\n    TargetLowering::LegalizeAction Action = TLI.getFixedPointOperationAction(\n        Opcode, VT, ScaleInt);\n    if (Action != TargetLowering::Legal && Action != TargetLowering::Custom) {\n      EVT PromVT;\n      if (VT.isScalarInteger())\n        PromVT = EVT::getIntegerVT(Ctx, VT.getSizeInBits() + 1);\n      else if (VT.isVector()) {\n        PromVT = VT.getVectorElementType();\n        PromVT = EVT::getIntegerVT(Ctx, PromVT.getSizeInBits() + 1);\n        PromVT = EVT::getVectorVT(Ctx, PromVT, VT.getVectorElementCount());\n      } else\n        llvm_unreachable(\"Wrong VT for DIVFIX?\");\n      if (Signed) {\n        LHS = DAG.getSExtOrTrunc(LHS, DL, PromVT);\n        RHS = DAG.getSExtOrTrunc(RHS, DL, PromVT);\n      } else {\n        LHS = DAG.getZExtOrTrunc(LHS, DL, PromVT);\n        RHS = DAG.getZExtOrTrunc(RHS, DL, PromVT);\n      }\n      EVT ShiftTy = TLI.getShiftAmountTy(PromVT, DAG.getDataLayout());\n      // For saturating operations, we need to shift up the LHS to get the\n      // proper saturation width, and then shift down again afterwards.\n      if (Saturating)\n        LHS = DAG.getNode(ISD::SHL, DL, PromVT, LHS,\n                          DAG.getConstant(1, DL, ShiftTy));\n      SDValue Res = DAG.getNode(Opcode, DL, PromVT, LHS, RHS, Scale);\n      if (Saturating)\n        Res = DAG.getNode(Signed ? ISD::SRA : ISD::SRL, DL, PromVT, Res,\n                          DAG.getConstant(1, DL, ShiftTy));\n      return DAG.getZExtOrTrunc(Res, DL, VT);\n    }\n  }\n\n  return DAG.getNode(Opcode, DL, VT, LHS, RHS, Scale);\n}\n\n// getUnderlyingArgRegs - Find underlying registers used for a truncated,\n// bitcasted, or split argument. Returns a list of <Register, size in bits>\nstatic void\ngetUnderlyingArgRegs(SmallVectorImpl<std::pair<unsigned, TypeSize>> &Regs,\n                     const SDValue &N) {\n  switch (N.getOpcode()) {\n  case ISD::CopyFromReg: {\n    SDValue Op = N.getOperand(1);\n    Regs.emplace_back(cast<RegisterSDNode>(Op)->getReg(),\n                      Op.getValueType().getSizeInBits());\n    return;\n  }\n  case ISD::BITCAST:\n  case ISD::AssertZext:\n  case ISD::AssertSext:\n  case ISD::TRUNCATE:\n    getUnderlyingArgRegs(Regs, N.getOperand(0));\n    return;\n  case ISD::BUILD_PAIR:\n  case ISD::BUILD_VECTOR:\n  case ISD::CONCAT_VECTORS:\n    for (SDValue Op : N->op_values())\n      getUnderlyingArgRegs(Regs, Op);\n    return;\n  default:\n    return;\n  }\n}\n\n/// If the DbgValueInst is a dbg_value of a function argument, create the\n/// corresponding DBG_VALUE machine instruction for it now.  At the end of\n/// instruction selection, they will be inserted to the entry BB.\nbool SelectionDAGBuilder::EmitFuncArgumentDbgValue(\n    const Value *V, DILocalVariable *Variable, DIExpression *Expr,\n    DILocation *DL, bool IsDbgDeclare, const SDValue &N) {\n  const Argument *Arg = dyn_cast<Argument>(V);\n  if (!Arg)\n    return false;\n\n  if (!IsDbgDeclare) {\n    // ArgDbgValues are hoisted to the beginning of the entry block. So we\n    // should only emit as ArgDbgValue if the dbg.value intrinsic is found in\n    // the entry block.\n    bool IsInEntryBlock = FuncInfo.MBB == &FuncInfo.MF->front();\n    if (!IsInEntryBlock)\n      return false;\n\n    // ArgDbgValues are hoisted to the beginning of the entry block.  So we\n    // should only emit as ArgDbgValue if the dbg.value intrinsic describes a\n    // variable that also is a param.\n    //\n    // Although, if we are at the top of the entry block already, we can still\n    // emit using ArgDbgValue. This might catch some situations when the\n    // dbg.value refers to an argument that isn't used in the entry block, so\n    // any CopyToReg node would be optimized out and the only way to express\n    // this DBG_VALUE is by using the physical reg (or FI) as done in this\n    // method.  ArgDbgValues are hoisted to the beginning of the entry block. So\n    // we should only emit as ArgDbgValue if the Variable is an argument to the\n    // current function, and the dbg.value intrinsic is found in the entry\n    // block.\n    bool VariableIsFunctionInputArg = Variable->isParameter() &&\n        !DL->getInlinedAt();\n    bool IsInPrologue = SDNodeOrder == LowestSDNodeOrder;\n    if (!IsInPrologue && !VariableIsFunctionInputArg)\n      return false;\n\n    // Here we assume that a function argument on IR level only can be used to\n    // describe one input parameter on source level. If we for example have\n    // source code like this\n    //\n    //    struct A { long x, y; };\n    //    void foo(struct A a, long b) {\n    //      ...\n    //      b = a.x;\n    //      ...\n    //    }\n    //\n    // and IR like this\n    //\n    //  define void @foo(i32 %a1, i32 %a2, i32 %b)  {\n    //  entry:\n    //    call void @llvm.dbg.value(metadata i32 %a1, \"a\", DW_OP_LLVM_fragment\n    //    call void @llvm.dbg.value(metadata i32 %a2, \"a\", DW_OP_LLVM_fragment\n    //    call void @llvm.dbg.value(metadata i32 %b, \"b\",\n    //    ...\n    //    call void @llvm.dbg.value(metadata i32 %a1, \"b\"\n    //    ...\n    //\n    // then the last dbg.value is describing a parameter \"b\" using a value that\n    // is an argument. But since we already has used %a1 to describe a parameter\n    // we should not handle that last dbg.value here (that would result in an\n    // incorrect hoisting of the DBG_VALUE to the function entry).\n    // Notice that we allow one dbg.value per IR level argument, to accommodate\n    // for the situation with fragments above.\n    if (VariableIsFunctionInputArg) {\n      unsigned ArgNo = Arg->getArgNo();\n      if (ArgNo >= FuncInfo.DescribedArgs.size())\n        FuncInfo.DescribedArgs.resize(ArgNo + 1, false);\n      else if (!IsInPrologue && FuncInfo.DescribedArgs.test(ArgNo))\n        return false;\n      FuncInfo.DescribedArgs.set(ArgNo);\n    }\n  }\n\n  MachineFunction &MF = DAG.getMachineFunction();\n  const TargetInstrInfo *TII = DAG.getSubtarget().getInstrInfo();\n\n  bool IsIndirect = false;\n  Optional<MachineOperand> Op;\n  // Some arguments' frame index is recorded during argument lowering.\n  int FI = FuncInfo.getArgumentFrameIndex(Arg);\n  if (FI != std::numeric_limits<int>::max())\n    Op = MachineOperand::CreateFI(FI);\n\n  SmallVector<std::pair<unsigned, TypeSize>, 8> ArgRegsAndSizes;\n  if (!Op && N.getNode()) {\n    getUnderlyingArgRegs(ArgRegsAndSizes, N);\n    Register Reg;\n    if (ArgRegsAndSizes.size() == 1)\n      Reg = ArgRegsAndSizes.front().first;\n\n    if (Reg && Reg.isVirtual()) {\n      MachineRegisterInfo &RegInfo = MF.getRegInfo();\n      Register PR = RegInfo.getLiveInPhysReg(Reg);\n      if (PR)\n        Reg = PR;\n    }\n    if (Reg) {\n      Op = MachineOperand::CreateReg(Reg, false);\n      IsIndirect = IsDbgDeclare;\n    }\n  }\n\n  if (!Op && N.getNode()) {\n    // Check if frame index is available.\n    SDValue LCandidate = peekThroughBitcasts(N);\n    if (LoadSDNode *LNode = dyn_cast<LoadSDNode>(LCandidate.getNode()))\n      if (FrameIndexSDNode *FINode =\n          dyn_cast<FrameIndexSDNode>(LNode->getBasePtr().getNode()))\n        Op = MachineOperand::CreateFI(FINode->getIndex());\n  }\n\n  if (!Op) {\n    // Create a DBG_VALUE for each decomposed value in ArgRegs to cover Reg\n    auto splitMultiRegDbgValue = [&](ArrayRef<std::pair<unsigned, TypeSize>>\n                                         SplitRegs) {\n      unsigned Offset = 0;\n      for (auto RegAndSize : SplitRegs) {\n        // If the expression is already a fragment, the current register\n        // offset+size might extend beyond the fragment. In this case, only\n        // the register bits that are inside the fragment are relevant.\n        int RegFragmentSizeInBits = RegAndSize.second;\n        if (auto ExprFragmentInfo = Expr->getFragmentInfo()) {\n          uint64_t ExprFragmentSizeInBits = ExprFragmentInfo->SizeInBits;\n          // The register is entirely outside the expression fragment,\n          // so is irrelevant for debug info.\n          if (Offset >= ExprFragmentSizeInBits)\n            break;\n          // The register is partially outside the expression fragment, only\n          // the low bits within the fragment are relevant for debug info.\n          if (Offset + RegFragmentSizeInBits > ExprFragmentSizeInBits) {\n            RegFragmentSizeInBits = ExprFragmentSizeInBits - Offset;\n          }\n        }\n\n        auto FragmentExpr = DIExpression::createFragmentExpression(\n            Expr, Offset, RegFragmentSizeInBits);\n        Offset += RegAndSize.second;\n        // If a valid fragment expression cannot be created, the variable's\n        // correct value cannot be determined and so it is set as Undef.\n        if (!FragmentExpr) {\n          SDDbgValue *SDV = DAG.getConstantDbgValue(\n              Variable, Expr, UndefValue::get(V->getType()), DL, SDNodeOrder);\n          DAG.AddDbgValue(SDV, nullptr, false);\n          continue;\n        }\n        assert(!IsDbgDeclare && \"DbgDeclare operand is not in memory?\");\n        FuncInfo.ArgDbgValues.push_back(\n          BuildMI(MF, DL, TII->get(TargetOpcode::DBG_VALUE), IsDbgDeclare,\n                  RegAndSize.first, Variable, *FragmentExpr));\n      }\n    };\n\n    // Check if ValueMap has reg number.\n    DenseMap<const Value *, Register>::const_iterator\n      VMI = FuncInfo.ValueMap.find(V);\n    if (VMI != FuncInfo.ValueMap.end()) {\n      const auto &TLI = DAG.getTargetLoweringInfo();\n      RegsForValue RFV(V->getContext(), TLI, DAG.getDataLayout(), VMI->second,\n                       V->getType(), None);\n      if (RFV.occupiesMultipleRegs()) {\n        splitMultiRegDbgValue(RFV.getRegsAndSizes());\n        return true;\n      }\n\n      Op = MachineOperand::CreateReg(VMI->second, false);\n      IsIndirect = IsDbgDeclare;\n    } else if (ArgRegsAndSizes.size() > 1) {\n      // This was split due to the calling convention, and no virtual register\n      // mapping exists for the value.\n      splitMultiRegDbgValue(ArgRegsAndSizes);\n      return true;\n    }\n  }\n\n  if (!Op)\n    return false;\n\n  assert(Variable->isValidLocationForIntrinsic(DL) &&\n         \"Expected inlined-at fields to agree\");\n  IsIndirect = (Op->isReg()) ? IsIndirect : true;\n  FuncInfo.ArgDbgValues.push_back(\n      BuildMI(MF, DL, TII->get(TargetOpcode::DBG_VALUE), IsIndirect,\n              *Op, Variable, Expr));\n\n  return true;\n}\n\n/// Return the appropriate SDDbgValue based on N.\nSDDbgValue *SelectionDAGBuilder::getDbgValue(SDValue N,\n                                             DILocalVariable *Variable,\n                                             DIExpression *Expr,\n                                             const DebugLoc &dl,\n                                             unsigned DbgSDNodeOrder) {\n  if (auto *FISDN = dyn_cast<FrameIndexSDNode>(N.getNode())) {\n    // Construct a FrameIndexDbgValue for FrameIndexSDNodes so we can describe\n    // stack slot locations.\n    //\n    // Consider \"int x = 0; int *px = &x;\". There are two kinds of interesting\n    // debug values here after optimization:\n    //\n    //   dbg.value(i32* %px, !\"int *px\", !DIExpression()), and\n    //   dbg.value(i32* %px, !\"int x\", !DIExpression(DW_OP_deref))\n    //\n    // Both describe the direct values of their associated variables.\n    return DAG.getFrameIndexDbgValue(Variable, Expr, FISDN->getIndex(),\n                                     /*IsIndirect*/ false, dl, DbgSDNodeOrder);\n  }\n  return DAG.getDbgValue(Variable, Expr, N.getNode(), N.getResNo(),\n                         /*IsIndirect*/ false, dl, DbgSDNodeOrder);\n}\n\nstatic unsigned FixedPointIntrinsicToOpcode(unsigned Intrinsic) {\n  switch (Intrinsic) {\n  case Intrinsic::smul_fix:\n    return ISD::SMULFIX;\n  case Intrinsic::umul_fix:\n    return ISD::UMULFIX;\n  case Intrinsic::smul_fix_sat:\n    return ISD::SMULFIXSAT;\n  case Intrinsic::umul_fix_sat:\n    return ISD::UMULFIXSAT;\n  case Intrinsic::sdiv_fix:\n    return ISD::SDIVFIX;\n  case Intrinsic::udiv_fix:\n    return ISD::UDIVFIX;\n  case Intrinsic::sdiv_fix_sat:\n    return ISD::SDIVFIXSAT;\n  case Intrinsic::udiv_fix_sat:\n    return ISD::UDIVFIXSAT;\n  default:\n    llvm_unreachable(\"Unhandled fixed point intrinsic\");\n  }\n}\n\nvoid SelectionDAGBuilder::lowerCallToExternalSymbol(const CallInst &I,\n                                           const char *FunctionName) {\n  assert(FunctionName && \"FunctionName must not be nullptr\");\n  SDValue Callee = DAG.getExternalSymbol(\n      FunctionName,\n      DAG.getTargetLoweringInfo().getPointerTy(DAG.getDataLayout()));\n  LowerCallTo(I, Callee, I.isTailCall());\n}\n\n/// Given a @llvm.call.preallocated.setup, return the corresponding\n/// preallocated call.\nstatic const CallBase *FindPreallocatedCall(const Value *PreallocatedSetup) {\n  assert(cast<CallBase>(PreallocatedSetup)\n                 ->getCalledFunction()\n                 ->getIntrinsicID() == Intrinsic::call_preallocated_setup &&\n         \"expected call_preallocated_setup Value\");\n  for (auto *U : PreallocatedSetup->users()) {\n    auto *UseCall = cast<CallBase>(U);\n    const Function *Fn = UseCall->getCalledFunction();\n    if (!Fn || Fn->getIntrinsicID() != Intrinsic::call_preallocated_arg) {\n      return UseCall;\n    }\n  }\n  llvm_unreachable(\"expected corresponding call to preallocated setup/arg\");\n}\n\n/// Lower the call to the specified intrinsic function.\nvoid SelectionDAGBuilder::visitIntrinsicCall(const CallInst &I,\n                                             unsigned Intrinsic) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDLoc sdl = getCurSDLoc();\n  DebugLoc dl = getCurDebugLoc();\n  SDValue Res;\n\n  SDNodeFlags Flags;\n  if (auto *FPOp = dyn_cast<FPMathOperator>(&I))\n    Flags.copyFMF(*FPOp);\n\n  switch (Intrinsic) {\n  default:\n    // By default, turn this into a target intrinsic node.\n    visitTargetIntrinsic(I, Intrinsic);\n    return;\n  case Intrinsic::vscale: {\n    match(&I, m_VScale(DAG.getDataLayout()));\n    EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    setValue(&I,\n             DAG.getVScale(getCurSDLoc(), VT, APInt(VT.getSizeInBits(), 1)));\n    return;\n  }\n  case Intrinsic::vastart:  visitVAStart(I); return;\n  case Intrinsic::vaend:    visitVAEnd(I); return;\n  case Intrinsic::vacopy:   visitVACopy(I); return;\n  case Intrinsic::returnaddress:\n    setValue(&I, DAG.getNode(ISD::RETURNADDR, sdl,\n                             TLI.getPointerTy(DAG.getDataLayout()),\n                             getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::addressofreturnaddress:\n    setValue(&I, DAG.getNode(ISD::ADDROFRETURNADDR, sdl,\n                             TLI.getPointerTy(DAG.getDataLayout())));\n    return;\n  case Intrinsic::sponentry:\n    setValue(&I, DAG.getNode(ISD::SPONENTRY, sdl,\n                             TLI.getFrameIndexTy(DAG.getDataLayout())));\n    return;\n  case Intrinsic::frameaddress:\n    setValue(&I, DAG.getNode(ISD::FRAMEADDR, sdl,\n                             TLI.getFrameIndexTy(DAG.getDataLayout()),\n                             getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::read_volatile_register:\n  case Intrinsic::read_register: {\n    Value *Reg = I.getArgOperand(0);\n    SDValue Chain = getRoot();\n    SDValue RegName =\n        DAG.getMDNode(cast<MDNode>(cast<MetadataAsValue>(Reg)->getMetadata()));\n    EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    Res = DAG.getNode(ISD::READ_REGISTER, sdl,\n      DAG.getVTList(VT, MVT::Other), Chain, RegName);\n    setValue(&I, Res);\n    DAG.setRoot(Res.getValue(1));\n    return;\n  }\n  case Intrinsic::write_register: {\n    Value *Reg = I.getArgOperand(0);\n    Value *RegValue = I.getArgOperand(1);\n    SDValue Chain = getRoot();\n    SDValue RegName =\n        DAG.getMDNode(cast<MDNode>(cast<MetadataAsValue>(Reg)->getMetadata()));\n    DAG.setRoot(DAG.getNode(ISD::WRITE_REGISTER, sdl, MVT::Other, Chain,\n                            RegName, getValue(RegValue)));\n    return;\n  }\n  case Intrinsic::memcpy: {\n    const auto &MCI = cast<MemCpyInst>(I);\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    SDValue Op3 = getValue(I.getArgOperand(2));\n    // @llvm.memcpy defines 0 and 1 to both mean no alignment.\n    Align DstAlign = MCI.getDestAlign().valueOrOne();\n    Align SrcAlign = MCI.getSourceAlign().valueOrOne();\n    Align Alignment = commonAlignment(DstAlign, SrcAlign);\n    bool isVol = MCI.isVolatile();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    // FIXME: Support passing different dest/src alignments to the memcpy DAG\n    // node.\n    SDValue Root = isVol ? getRoot() : getMemoryRoot();\n    SDValue MC = DAG.getMemcpy(Root, sdl, Op1, Op2, Op3, Alignment, isVol,\n                               /* AlwaysInline */ false, isTC,\n                               MachinePointerInfo(I.getArgOperand(0)),\n                               MachinePointerInfo(I.getArgOperand(1)));\n    updateDAGForMaybeTailCall(MC);\n    return;\n  }\n  case Intrinsic::memcpy_inline: {\n    const auto &MCI = cast<MemCpyInlineInst>(I);\n    SDValue Dst = getValue(I.getArgOperand(0));\n    SDValue Src = getValue(I.getArgOperand(1));\n    SDValue Size = getValue(I.getArgOperand(2));\n    assert(isa<ConstantSDNode>(Size) && \"memcpy_inline needs constant size\");\n    // @llvm.memcpy.inline defines 0 and 1 to both mean no alignment.\n    Align DstAlign = MCI.getDestAlign().valueOrOne();\n    Align SrcAlign = MCI.getSourceAlign().valueOrOne();\n    Align Alignment = commonAlignment(DstAlign, SrcAlign);\n    bool isVol = MCI.isVolatile();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    // FIXME: Support passing different dest/src alignments to the memcpy DAG\n    // node.\n    SDValue MC = DAG.getMemcpy(getRoot(), sdl, Dst, Src, Size, Alignment, isVol,\n                               /* AlwaysInline */ true, isTC,\n                               MachinePointerInfo(I.getArgOperand(0)),\n                               MachinePointerInfo(I.getArgOperand(1)));\n    updateDAGForMaybeTailCall(MC);\n    return;\n  }\n  case Intrinsic::memset: {\n    const auto &MSI = cast<MemSetInst>(I);\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    SDValue Op3 = getValue(I.getArgOperand(2));\n    // @llvm.memset defines 0 and 1 to both mean no alignment.\n    Align Alignment = MSI.getDestAlign().valueOrOne();\n    bool isVol = MSI.isVolatile();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    SDValue Root = isVol ? getRoot() : getMemoryRoot();\n    SDValue MS = DAG.getMemset(Root, sdl, Op1, Op2, Op3, Alignment, isVol, isTC,\n                               MachinePointerInfo(I.getArgOperand(0)));\n    updateDAGForMaybeTailCall(MS);\n    return;\n  }\n  case Intrinsic::memmove: {\n    const auto &MMI = cast<MemMoveInst>(I);\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    SDValue Op3 = getValue(I.getArgOperand(2));\n    // @llvm.memmove defines 0 and 1 to both mean no alignment.\n    Align DstAlign = MMI.getDestAlign().valueOrOne();\n    Align SrcAlign = MMI.getSourceAlign().valueOrOne();\n    Align Alignment = commonAlignment(DstAlign, SrcAlign);\n    bool isVol = MMI.isVolatile();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    // FIXME: Support passing different dest/src alignments to the memmove DAG\n    // node.\n    SDValue Root = isVol ? getRoot() : getMemoryRoot();\n    SDValue MM = DAG.getMemmove(Root, sdl, Op1, Op2, Op3, Alignment, isVol,\n                                isTC, MachinePointerInfo(I.getArgOperand(0)),\n                                MachinePointerInfo(I.getArgOperand(1)));\n    updateDAGForMaybeTailCall(MM);\n    return;\n  }\n  case Intrinsic::memcpy_element_unordered_atomic: {\n    const AtomicMemCpyInst &MI = cast<AtomicMemCpyInst>(I);\n    SDValue Dst = getValue(MI.getRawDest());\n    SDValue Src = getValue(MI.getRawSource());\n    SDValue Length = getValue(MI.getLength());\n\n    unsigned DstAlign = MI.getDestAlignment();\n    unsigned SrcAlign = MI.getSourceAlignment();\n    Type *LengthTy = MI.getLength()->getType();\n    unsigned ElemSz = MI.getElementSizeInBytes();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    SDValue MC = DAG.getAtomicMemcpy(getRoot(), sdl, Dst, DstAlign, Src,\n                                     SrcAlign, Length, LengthTy, ElemSz, isTC,\n                                     MachinePointerInfo(MI.getRawDest()),\n                                     MachinePointerInfo(MI.getRawSource()));\n    updateDAGForMaybeTailCall(MC);\n    return;\n  }\n  case Intrinsic::memmove_element_unordered_atomic: {\n    auto &MI = cast<AtomicMemMoveInst>(I);\n    SDValue Dst = getValue(MI.getRawDest());\n    SDValue Src = getValue(MI.getRawSource());\n    SDValue Length = getValue(MI.getLength());\n\n    unsigned DstAlign = MI.getDestAlignment();\n    unsigned SrcAlign = MI.getSourceAlignment();\n    Type *LengthTy = MI.getLength()->getType();\n    unsigned ElemSz = MI.getElementSizeInBytes();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    SDValue MC = DAG.getAtomicMemmove(getRoot(), sdl, Dst, DstAlign, Src,\n                                      SrcAlign, Length, LengthTy, ElemSz, isTC,\n                                      MachinePointerInfo(MI.getRawDest()),\n                                      MachinePointerInfo(MI.getRawSource()));\n    updateDAGForMaybeTailCall(MC);\n    return;\n  }\n  case Intrinsic::memset_element_unordered_atomic: {\n    auto &MI = cast<AtomicMemSetInst>(I);\n    SDValue Dst = getValue(MI.getRawDest());\n    SDValue Val = getValue(MI.getValue());\n    SDValue Length = getValue(MI.getLength());\n\n    unsigned DstAlign = MI.getDestAlignment();\n    Type *LengthTy = MI.getLength()->getType();\n    unsigned ElemSz = MI.getElementSizeInBytes();\n    bool isTC = I.isTailCall() && isInTailCallPosition(I, DAG.getTarget());\n    SDValue MC = DAG.getAtomicMemset(getRoot(), sdl, Dst, DstAlign, Val, Length,\n                                     LengthTy, ElemSz, isTC,\n                                     MachinePointerInfo(MI.getRawDest()));\n    updateDAGForMaybeTailCall(MC);\n    return;\n  }\n  case Intrinsic::call_preallocated_setup: {\n    const CallBase *PreallocatedCall = FindPreallocatedCall(&I);\n    SDValue SrcValue = DAG.getSrcValue(PreallocatedCall);\n    SDValue Res = DAG.getNode(ISD::PREALLOCATED_SETUP, sdl, MVT::Other,\n                              getRoot(), SrcValue);\n    setValue(&I, Res);\n    DAG.setRoot(Res);\n    return;\n  }\n  case Intrinsic::call_preallocated_arg: {\n    const CallBase *PreallocatedCall = FindPreallocatedCall(I.getOperand(0));\n    SDValue SrcValue = DAG.getSrcValue(PreallocatedCall);\n    SDValue Ops[3];\n    Ops[0] = getRoot();\n    Ops[1] = SrcValue;\n    Ops[2] = DAG.getTargetConstant(*cast<ConstantInt>(I.getArgOperand(1)), sdl,\n                                   MVT::i32); // arg index\n    SDValue Res = DAG.getNode(\n        ISD::PREALLOCATED_ARG, sdl,\n        DAG.getVTList(TLI.getPointerTy(DAG.getDataLayout()), MVT::Other), Ops);\n    setValue(&I, Res);\n    DAG.setRoot(Res.getValue(1));\n    return;\n  }\n  case Intrinsic::dbg_addr:\n  case Intrinsic::dbg_declare: {\n    const auto &DI = cast<DbgVariableIntrinsic>(I);\n    DILocalVariable *Variable = DI.getVariable();\n    DIExpression *Expression = DI.getExpression();\n    dropDanglingDebugInfo(Variable, Expression);\n    assert(Variable && \"Missing variable\");\n    LLVM_DEBUG(dbgs() << \"SelectionDAG visiting debug intrinsic: \" << DI\n                      << \"\\n\");\n    // Check if address has undef value.\n    const Value *Address = DI.getVariableLocation();\n    if (!Address || isa<UndefValue>(Address) ||\n        (Address->use_empty() && !isa<Argument>(Address))) {\n      LLVM_DEBUG(dbgs() << \"Dropping debug info for \" << DI\n                        << \" (bad/undef/unused-arg address)\\n\");\n      return;\n    }\n\n    bool isParameter = Variable->isParameter() || isa<Argument>(Address);\n\n    // Check if this variable can be described by a frame index, typically\n    // either as a static alloca or a byval parameter.\n    int FI = std::numeric_limits<int>::max();\n    if (const auto *AI =\n            dyn_cast<AllocaInst>(Address->stripInBoundsConstantOffsets())) {\n      if (AI->isStaticAlloca()) {\n        auto I = FuncInfo.StaticAllocaMap.find(AI);\n        if (I != FuncInfo.StaticAllocaMap.end())\n          FI = I->second;\n      }\n    } else if (const auto *Arg = dyn_cast<Argument>(\n                   Address->stripInBoundsConstantOffsets())) {\n      FI = FuncInfo.getArgumentFrameIndex(Arg);\n    }\n\n    // llvm.dbg.addr is control dependent and always generates indirect\n    // DBG_VALUE instructions. llvm.dbg.declare is handled as a frame index in\n    // the MachineFunction variable table.\n    if (FI != std::numeric_limits<int>::max()) {\n      if (Intrinsic == Intrinsic::dbg_addr) {\n        SDDbgValue *SDV = DAG.getFrameIndexDbgValue(\n            Variable, Expression, FI, /*IsIndirect*/ true, dl, SDNodeOrder);\n        DAG.AddDbgValue(SDV, getRoot().getNode(), isParameter);\n      } else {\n        LLVM_DEBUG(dbgs() << \"Skipping \" << DI\n                          << \" (variable info stashed in MF side table)\\n\");\n      }\n      return;\n    }\n\n    SDValue &N = NodeMap[Address];\n    if (!N.getNode() && isa<Argument>(Address))\n      // Check unused arguments map.\n      N = UnusedArgNodeMap[Address];\n    SDDbgValue *SDV;\n    if (N.getNode()) {\n      if (const BitCastInst *BCI = dyn_cast<BitCastInst>(Address))\n        Address = BCI->getOperand(0);\n      // Parameters are handled specially.\n      auto FINode = dyn_cast<FrameIndexSDNode>(N.getNode());\n      if (isParameter && FINode) {\n        // Byval parameter. We have a frame index at this point.\n        SDV =\n            DAG.getFrameIndexDbgValue(Variable, Expression, FINode->getIndex(),\n                                      /*IsIndirect*/ true, dl, SDNodeOrder);\n      } else if (isa<Argument>(Address)) {\n        // Address is an argument, so try to emit its dbg value using\n        // virtual register info from the FuncInfo.ValueMap.\n        EmitFuncArgumentDbgValue(Address, Variable, Expression, dl, true, N);\n        return;\n      } else {\n        SDV = DAG.getDbgValue(Variable, Expression, N.getNode(), N.getResNo(),\n                              true, dl, SDNodeOrder);\n      }\n      DAG.AddDbgValue(SDV, N.getNode(), isParameter);\n    } else {\n      // If Address is an argument then try to emit its dbg value using\n      // virtual register info from the FuncInfo.ValueMap.\n      if (!EmitFuncArgumentDbgValue(Address, Variable, Expression, dl, true,\n                                    N)) {\n        LLVM_DEBUG(dbgs() << \"Dropping debug info for \" << DI\n                          << \" (could not emit func-arg dbg_value)\\n\");\n      }\n    }\n    return;\n  }\n  case Intrinsic::dbg_label: {\n    const DbgLabelInst &DI = cast<DbgLabelInst>(I);\n    DILabel *Label = DI.getLabel();\n    assert(Label && \"Missing label\");\n\n    SDDbgLabel *SDV;\n    SDV = DAG.getDbgLabel(Label, dl, SDNodeOrder);\n    DAG.AddDbgLabel(SDV);\n    return;\n  }\n  case Intrinsic::dbg_value: {\n    const DbgValueInst &DI = cast<DbgValueInst>(I);\n    assert(DI.getVariable() && \"Missing variable\");\n\n    DILocalVariable *Variable = DI.getVariable();\n    DIExpression *Expression = DI.getExpression();\n    dropDanglingDebugInfo(Variable, Expression);\n    const Value *V = DI.getValue();\n    if (!V)\n      return;\n\n    if (handleDebugValue(V, Variable, Expression, dl, DI.getDebugLoc(),\n        SDNodeOrder))\n      return;\n\n    // TODO: Dangling debug info will eventually either be resolved or produce\n    // an Undef DBG_VALUE. However in the resolution case, a gap may appear\n    // between the original dbg.value location and its resolved DBG_VALUE, which\n    // we should ideally fill with an extra Undef DBG_VALUE.\n\n    DanglingDebugInfoMap[V].emplace_back(&DI, dl, SDNodeOrder);\n    return;\n  }\n\n  case Intrinsic::eh_typeid_for: {\n    // Find the type id for the given typeinfo.\n    GlobalValue *GV = ExtractTypeInfo(I.getArgOperand(0));\n    unsigned TypeID = DAG.getMachineFunction().getTypeIDFor(GV);\n    Res = DAG.getConstant(TypeID, sdl, MVT::i32);\n    setValue(&I, Res);\n    return;\n  }\n\n  case Intrinsic::eh_return_i32:\n  case Intrinsic::eh_return_i64:\n    DAG.getMachineFunction().setCallsEHReturn(true);\n    DAG.setRoot(DAG.getNode(ISD::EH_RETURN, sdl,\n                            MVT::Other,\n                            getControlRoot(),\n                            getValue(I.getArgOperand(0)),\n                            getValue(I.getArgOperand(1))));\n    return;\n  case Intrinsic::eh_unwind_init:\n    DAG.getMachineFunction().setCallsUnwindInit(true);\n    return;\n  case Intrinsic::eh_dwarf_cfa:\n    setValue(&I, DAG.getNode(ISD::EH_DWARF_CFA, sdl,\n                             TLI.getPointerTy(DAG.getDataLayout()),\n                             getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::eh_sjlj_callsite: {\n    MachineModuleInfo &MMI = DAG.getMachineFunction().getMMI();\n    ConstantInt *CI = dyn_cast<ConstantInt>(I.getArgOperand(0));\n    assert(CI && \"Non-constant call site value in eh.sjlj.callsite!\");\n    assert(MMI.getCurrentCallSite() == 0 && \"Overlapping call sites!\");\n\n    MMI.setCurrentCallSite(CI->getZExtValue());\n    return;\n  }\n  case Intrinsic::eh_sjlj_functioncontext: {\n    // Get and store the index of the function context.\n    MachineFrameInfo &MFI = DAG.getMachineFunction().getFrameInfo();\n    AllocaInst *FnCtx =\n      cast<AllocaInst>(I.getArgOperand(0)->stripPointerCasts());\n    int FI = FuncInfo.StaticAllocaMap[FnCtx];\n    MFI.setFunctionContextIndex(FI);\n    return;\n  }\n  case Intrinsic::eh_sjlj_setjmp: {\n    SDValue Ops[2];\n    Ops[0] = getRoot();\n    Ops[1] = getValue(I.getArgOperand(0));\n    SDValue Op = DAG.getNode(ISD::EH_SJLJ_SETJMP, sdl,\n                             DAG.getVTList(MVT::i32, MVT::Other), Ops);\n    setValue(&I, Op.getValue(0));\n    DAG.setRoot(Op.getValue(1));\n    return;\n  }\n  case Intrinsic::eh_sjlj_longjmp:\n    DAG.setRoot(DAG.getNode(ISD::EH_SJLJ_LONGJMP, sdl, MVT::Other,\n                            getRoot(), getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::eh_sjlj_setup_dispatch:\n    DAG.setRoot(DAG.getNode(ISD::EH_SJLJ_SETUP_DISPATCH, sdl, MVT::Other,\n                            getRoot()));\n    return;\n  case Intrinsic::masked_gather:\n    visitMaskedGather(I);\n    return;\n  case Intrinsic::masked_load:\n    visitMaskedLoad(I);\n    return;\n  case Intrinsic::masked_scatter:\n    visitMaskedScatter(I);\n    return;\n  case Intrinsic::masked_store:\n    visitMaskedStore(I);\n    return;\n  case Intrinsic::masked_expandload:\n    visitMaskedLoad(I, true /* IsExpanding */);\n    return;\n  case Intrinsic::masked_compressstore:\n    visitMaskedStore(I, true /* IsCompressing */);\n    return;\n  case Intrinsic::powi:\n    setValue(&I, ExpandPowI(sdl, getValue(I.getArgOperand(0)),\n                            getValue(I.getArgOperand(1)), DAG));\n    return;\n  case Intrinsic::log:\n    setValue(&I, expandLog(sdl, getValue(I.getArgOperand(0)), DAG, TLI, Flags));\n    return;\n  case Intrinsic::log2:\n    setValue(&I,\n             expandLog2(sdl, getValue(I.getArgOperand(0)), DAG, TLI, Flags));\n    return;\n  case Intrinsic::log10:\n    setValue(&I,\n             expandLog10(sdl, getValue(I.getArgOperand(0)), DAG, TLI, Flags));\n    return;\n  case Intrinsic::exp:\n    setValue(&I, expandExp(sdl, getValue(I.getArgOperand(0)), DAG, TLI, Flags));\n    return;\n  case Intrinsic::exp2:\n    setValue(&I,\n             expandExp2(sdl, getValue(I.getArgOperand(0)), DAG, TLI, Flags));\n    return;\n  case Intrinsic::pow:\n    setValue(&I, expandPow(sdl, getValue(I.getArgOperand(0)),\n                           getValue(I.getArgOperand(1)), DAG, TLI, Flags));\n    return;\n  case Intrinsic::sqrt:\n  case Intrinsic::fabs:\n  case Intrinsic::sin:\n  case Intrinsic::cos:\n  case Intrinsic::floor:\n  case Intrinsic::ceil:\n  case Intrinsic::trunc:\n  case Intrinsic::rint:\n  case Intrinsic::nearbyint:\n  case Intrinsic::round:\n  case Intrinsic::roundeven:\n  case Intrinsic::canonicalize: {\n    unsigned Opcode;\n    switch (Intrinsic) {\n    default: llvm_unreachable(\"Impossible intrinsic\");  // Can't reach here.\n    case Intrinsic::sqrt:      Opcode = ISD::FSQRT;      break;\n    case Intrinsic::fabs:      Opcode = ISD::FABS;       break;\n    case Intrinsic::sin:       Opcode = ISD::FSIN;       break;\n    case Intrinsic::cos:       Opcode = ISD::FCOS;       break;\n    case Intrinsic::floor:     Opcode = ISD::FFLOOR;     break;\n    case Intrinsic::ceil:      Opcode = ISD::FCEIL;      break;\n    case Intrinsic::trunc:     Opcode = ISD::FTRUNC;     break;\n    case Intrinsic::rint:      Opcode = ISD::FRINT;      break;\n    case Intrinsic::nearbyint: Opcode = ISD::FNEARBYINT; break;\n    case Intrinsic::round:     Opcode = ISD::FROUND;     break;\n    case Intrinsic::roundeven: Opcode = ISD::FROUNDEVEN; break;\n    case Intrinsic::canonicalize: Opcode = ISD::FCANONICALIZE; break;\n    }\n\n    setValue(&I, DAG.getNode(Opcode, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0)), Flags));\n    return;\n  }\n  case Intrinsic::lround:\n  case Intrinsic::llround:\n  case Intrinsic::lrint:\n  case Intrinsic::llrint: {\n    unsigned Opcode;\n    switch (Intrinsic) {\n    default: llvm_unreachable(\"Impossible intrinsic\");  // Can't reach here.\n    case Intrinsic::lround:  Opcode = ISD::LROUND;  break;\n    case Intrinsic::llround: Opcode = ISD::LLROUND; break;\n    case Intrinsic::lrint:   Opcode = ISD::LRINT;   break;\n    case Intrinsic::llrint:  Opcode = ISD::LLRINT;  break;\n    }\n\n    EVT RetVT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    setValue(&I, DAG.getNode(Opcode, sdl, RetVT,\n                             getValue(I.getArgOperand(0))));\n    return;\n  }\n  case Intrinsic::minnum:\n    setValue(&I, DAG.getNode(ISD::FMINNUM, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0)),\n                             getValue(I.getArgOperand(1)), Flags));\n    return;\n  case Intrinsic::maxnum:\n    setValue(&I, DAG.getNode(ISD::FMAXNUM, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0)),\n                             getValue(I.getArgOperand(1)), Flags));\n    return;\n  case Intrinsic::minimum:\n    setValue(&I, DAG.getNode(ISD::FMINIMUM, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0)),\n                             getValue(I.getArgOperand(1)), Flags));\n    return;\n  case Intrinsic::maximum:\n    setValue(&I, DAG.getNode(ISD::FMAXIMUM, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0)),\n                             getValue(I.getArgOperand(1)), Flags));\n    return;\n  case Intrinsic::copysign:\n    setValue(&I, DAG.getNode(ISD::FCOPYSIGN, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0)),\n                             getValue(I.getArgOperand(1)), Flags));\n    return;\n  case Intrinsic::fma:\n    setValue(&I, DAG.getNode(\n                     ISD::FMA, sdl, getValue(I.getArgOperand(0)).getValueType(),\n                     getValue(I.getArgOperand(0)), getValue(I.getArgOperand(1)),\n                     getValue(I.getArgOperand(2)), Flags));\n    return;\n#define INSTRUCTION(NAME, NARG, ROUND_MODE, INTRINSIC)                         \\\n  case Intrinsic::INTRINSIC:\n#include \"llvm/IR/ConstrainedOps.def\"\n    visitConstrainedFPIntrinsic(cast<ConstrainedFPIntrinsic>(I));\n    return;\n#define BEGIN_REGISTER_VP_INTRINSIC(VPID, ...) case Intrinsic::VPID:\n#include \"llvm/IR/VPIntrinsics.def\"\n    visitVectorPredicationIntrinsic(cast<VPIntrinsic>(I));\n    return;\n  case Intrinsic::fmuladd: {\n    EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    if (TM.Options.AllowFPOpFusion != FPOpFusion::Strict &&\n        TLI.isFMAFasterThanFMulAndFAdd(DAG.getMachineFunction(), VT)) {\n      setValue(&I, DAG.getNode(ISD::FMA, sdl,\n                               getValue(I.getArgOperand(0)).getValueType(),\n                               getValue(I.getArgOperand(0)),\n                               getValue(I.getArgOperand(1)),\n                               getValue(I.getArgOperand(2)), Flags));\n    } else {\n      // TODO: Intrinsic calls should have fast-math-flags.\n      SDValue Mul = DAG.getNode(\n          ISD::FMUL, sdl, getValue(I.getArgOperand(0)).getValueType(),\n          getValue(I.getArgOperand(0)), getValue(I.getArgOperand(1)), Flags);\n      SDValue Add = DAG.getNode(ISD::FADD, sdl,\n                                getValue(I.getArgOperand(0)).getValueType(),\n                                Mul, getValue(I.getArgOperand(2)), Flags);\n      setValue(&I, Add);\n    }\n    return;\n  }\n  case Intrinsic::convert_to_fp16:\n    setValue(&I, DAG.getNode(ISD::BITCAST, sdl, MVT::i16,\n                             DAG.getNode(ISD::FP_ROUND, sdl, MVT::f16,\n                                         getValue(I.getArgOperand(0)),\n                                         DAG.getTargetConstant(0, sdl,\n                                                               MVT::i32))));\n    return;\n  case Intrinsic::convert_from_fp16:\n    setValue(&I, DAG.getNode(ISD::FP_EXTEND, sdl,\n                             TLI.getValueType(DAG.getDataLayout(), I.getType()),\n                             DAG.getNode(ISD::BITCAST, sdl, MVT::f16,\n                                         getValue(I.getArgOperand(0)))));\n    return;\n  case Intrinsic::fptosi_sat: {\n    EVT Type = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    SDValue SatW = DAG.getConstant(Type.getScalarSizeInBits(), sdl, MVT::i32);\n    setValue(&I, DAG.getNode(ISD::FP_TO_SINT_SAT, sdl, Type,\n                             getValue(I.getArgOperand(0)), SatW));\n    return;\n  }\n  case Intrinsic::fptoui_sat: {\n    EVT Type = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    SDValue SatW = DAG.getConstant(Type.getScalarSizeInBits(), sdl, MVT::i32);\n    setValue(&I, DAG.getNode(ISD::FP_TO_UINT_SAT, sdl, Type,\n                             getValue(I.getArgOperand(0)), SatW));\n    return;\n  }\n  case Intrinsic::set_rounding:\n    Res = DAG.getNode(ISD::SET_ROUNDING, sdl, MVT::Other,\n                      {getRoot(), getValue(I.getArgOperand(0))});\n    setValue(&I, Res);\n    DAG.setRoot(Res.getValue(0));\n    return;\n  case Intrinsic::pcmarker: {\n    SDValue Tmp = getValue(I.getArgOperand(0));\n    DAG.setRoot(DAG.getNode(ISD::PCMARKER, sdl, MVT::Other, getRoot(), Tmp));\n    return;\n  }\n  case Intrinsic::readcyclecounter: {\n    SDValue Op = getRoot();\n    Res = DAG.getNode(ISD::READCYCLECOUNTER, sdl,\n                      DAG.getVTList(MVT::i64, MVT::Other), Op);\n    setValue(&I, Res);\n    DAG.setRoot(Res.getValue(1));\n    return;\n  }\n  case Intrinsic::bitreverse:\n    setValue(&I, DAG.getNode(ISD::BITREVERSE, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::bswap:\n    setValue(&I, DAG.getNode(ISD::BSWAP, sdl,\n                             getValue(I.getArgOperand(0)).getValueType(),\n                             getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::cttz: {\n    SDValue Arg = getValue(I.getArgOperand(0));\n    ConstantInt *CI = cast<ConstantInt>(I.getArgOperand(1));\n    EVT Ty = Arg.getValueType();\n    setValue(&I, DAG.getNode(CI->isZero() ? ISD::CTTZ : ISD::CTTZ_ZERO_UNDEF,\n                             sdl, Ty, Arg));\n    return;\n  }\n  case Intrinsic::ctlz: {\n    SDValue Arg = getValue(I.getArgOperand(0));\n    ConstantInt *CI = cast<ConstantInt>(I.getArgOperand(1));\n    EVT Ty = Arg.getValueType();\n    setValue(&I, DAG.getNode(CI->isZero() ? ISD::CTLZ : ISD::CTLZ_ZERO_UNDEF,\n                             sdl, Ty, Arg));\n    return;\n  }\n  case Intrinsic::ctpop: {\n    SDValue Arg = getValue(I.getArgOperand(0));\n    EVT Ty = Arg.getValueType();\n    setValue(&I, DAG.getNode(ISD::CTPOP, sdl, Ty, Arg));\n    return;\n  }\n  case Intrinsic::fshl:\n  case Intrinsic::fshr: {\n    bool IsFSHL = Intrinsic == Intrinsic::fshl;\n    SDValue X = getValue(I.getArgOperand(0));\n    SDValue Y = getValue(I.getArgOperand(1));\n    SDValue Z = getValue(I.getArgOperand(2));\n    EVT VT = X.getValueType();\n\n    if (X == Y) {\n      auto RotateOpcode = IsFSHL ? ISD::ROTL : ISD::ROTR;\n      setValue(&I, DAG.getNode(RotateOpcode, sdl, VT, X, Z));\n    } else {\n      auto FunnelOpcode = IsFSHL ? ISD::FSHL : ISD::FSHR;\n      setValue(&I, DAG.getNode(FunnelOpcode, sdl, VT, X, Y, Z));\n    }\n    return;\n  }\n  case Intrinsic::sadd_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::SADDSAT, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::uadd_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::UADDSAT, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::ssub_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::SSUBSAT, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::usub_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::USUBSAT, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::sshl_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::SSHLSAT, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::ushl_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::USHLSAT, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::smul_fix:\n  case Intrinsic::umul_fix:\n  case Intrinsic::smul_fix_sat:\n  case Intrinsic::umul_fix_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    SDValue Op3 = getValue(I.getArgOperand(2));\n    setValue(&I, DAG.getNode(FixedPointIntrinsicToOpcode(Intrinsic), sdl,\n                             Op1.getValueType(), Op1, Op2, Op3));\n    return;\n  }\n  case Intrinsic::sdiv_fix:\n  case Intrinsic::udiv_fix:\n  case Intrinsic::sdiv_fix_sat:\n  case Intrinsic::udiv_fix_sat: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    SDValue Op3 = getValue(I.getArgOperand(2));\n    setValue(&I, expandDivFix(FixedPointIntrinsicToOpcode(Intrinsic), sdl,\n                              Op1, Op2, Op3, DAG, TLI));\n    return;\n  }\n  case Intrinsic::smax: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::SMAX, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::smin: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::SMIN, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::umax: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::UMAX, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::umin: {\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n    setValue(&I, DAG.getNode(ISD::UMIN, sdl, Op1.getValueType(), Op1, Op2));\n    return;\n  }\n  case Intrinsic::abs: {\n    // TODO: Preserve \"int min is poison\" arg in SDAG?\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    setValue(&I, DAG.getNode(ISD::ABS, sdl, Op1.getValueType(), Op1));\n    return;\n  }\n  case Intrinsic::stacksave: {\n    SDValue Op = getRoot();\n    EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    Res = DAG.getNode(ISD::STACKSAVE, sdl, DAG.getVTList(VT, MVT::Other), Op);\n    setValue(&I, Res);\n    DAG.setRoot(Res.getValue(1));\n    return;\n  }\n  case Intrinsic::stackrestore:\n    Res = getValue(I.getArgOperand(0));\n    DAG.setRoot(DAG.getNode(ISD::STACKRESTORE, sdl, MVT::Other, getRoot(), Res));\n    return;\n  case Intrinsic::get_dynamic_area_offset: {\n    SDValue Op = getRoot();\n    EVT PtrTy = TLI.getFrameIndexTy(DAG.getDataLayout());\n    EVT ResTy = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    // Result type for @llvm.get.dynamic.area.offset should match PtrTy for\n    // target.\n    if (PtrTy.getFixedSizeInBits() < ResTy.getFixedSizeInBits())\n      report_fatal_error(\"Wrong result type for @llvm.get.dynamic.area.offset\"\n                         \" intrinsic!\");\n    Res = DAG.getNode(ISD::GET_DYNAMIC_AREA_OFFSET, sdl, DAG.getVTList(ResTy),\n                      Op);\n    DAG.setRoot(Op);\n    setValue(&I, Res);\n    return;\n  }\n  case Intrinsic::stackguard: {\n    MachineFunction &MF = DAG.getMachineFunction();\n    const Module &M = *MF.getFunction().getParent();\n    SDValue Chain = getRoot();\n    if (TLI.useLoadStackGuardNode()) {\n      Res = getLoadStackGuard(DAG, sdl, Chain);\n    } else {\n      EVT PtrTy = TLI.getValueType(DAG.getDataLayout(), I.getType());\n      const Value *Global = TLI.getSDagStackGuard(M);\n      Align Align = DL->getPrefTypeAlign(Global->getType());\n      Res = DAG.getLoad(PtrTy, sdl, Chain, getValue(Global),\n                        MachinePointerInfo(Global, 0), Align,\n                        MachineMemOperand::MOVolatile);\n    }\n    if (TLI.useStackGuardXorFP())\n      Res = TLI.emitStackGuardXorFP(DAG, Res, sdl);\n    DAG.setRoot(Chain);\n    setValue(&I, Res);\n    return;\n  }\n  case Intrinsic::stackprotector: {\n    // Emit code into the DAG to store the stack guard onto the stack.\n    MachineFunction &MF = DAG.getMachineFunction();\n    MachineFrameInfo &MFI = MF.getFrameInfo();\n    SDValue Src, Chain = getRoot();\n\n    if (TLI.useLoadStackGuardNode())\n      Src = getLoadStackGuard(DAG, sdl, Chain);\n    else\n      Src = getValue(I.getArgOperand(0));   // The guard's value.\n\n    AllocaInst *Slot = cast<AllocaInst>(I.getArgOperand(1));\n\n    int FI = FuncInfo.StaticAllocaMap[Slot];\n    MFI.setStackProtectorIndex(FI);\n    EVT PtrTy = TLI.getFrameIndexTy(DAG.getDataLayout());\n\n    SDValue FIN = DAG.getFrameIndex(FI, PtrTy);\n\n    // Store the stack protector onto the stack.\n    Res = DAG.getStore(\n        Chain, sdl, Src, FIN,\n        MachinePointerInfo::getFixedStack(DAG.getMachineFunction(), FI),\n        MaybeAlign(), MachineMemOperand::MOVolatile);\n    setValue(&I, Res);\n    DAG.setRoot(Res);\n    return;\n  }\n  case Intrinsic::objectsize:\n    llvm_unreachable(\"llvm.objectsize.* should have been lowered already\");\n\n  case Intrinsic::is_constant:\n    llvm_unreachable(\"llvm.is.constant.* should have been lowered already\");\n\n  case Intrinsic::annotation:\n  case Intrinsic::ptr_annotation:\n  case Intrinsic::launder_invariant_group:\n  case Intrinsic::strip_invariant_group:\n    // Drop the intrinsic, but forward the value\n    setValue(&I, getValue(I.getOperand(0)));\n    return;\n\n  case Intrinsic::assume:\n  case Intrinsic::experimental_noalias_scope_decl:\n  case Intrinsic::var_annotation:\n  case Intrinsic::sideeffect:\n    // Discard annotate attributes, noalias scope declarations, assumptions, and\n    // artificial side-effects.\n    return;\n\n  case Intrinsic::codeview_annotation: {\n    // Emit a label associated with this metadata.\n    MachineFunction &MF = DAG.getMachineFunction();\n    MCSymbol *Label =\n        MF.getMMI().getContext().createTempSymbol(\"annotation\", true);\n    Metadata *MD = cast<MetadataAsValue>(I.getArgOperand(0))->getMetadata();\n    MF.addCodeViewAnnotation(Label, cast<MDNode>(MD));\n    Res = DAG.getLabelNode(ISD::ANNOTATION_LABEL, sdl, getRoot(), Label);\n    DAG.setRoot(Res);\n    return;\n  }\n\n  case Intrinsic::init_trampoline: {\n    const Function *F = cast<Function>(I.getArgOperand(1)->stripPointerCasts());\n\n    SDValue Ops[6];\n    Ops[0] = getRoot();\n    Ops[1] = getValue(I.getArgOperand(0));\n    Ops[2] = getValue(I.getArgOperand(1));\n    Ops[3] = getValue(I.getArgOperand(2));\n    Ops[4] = DAG.getSrcValue(I.getArgOperand(0));\n    Ops[5] = DAG.getSrcValue(F);\n\n    Res = DAG.getNode(ISD::INIT_TRAMPOLINE, sdl, MVT::Other, Ops);\n\n    DAG.setRoot(Res);\n    return;\n  }\n  case Intrinsic::adjust_trampoline:\n    setValue(&I, DAG.getNode(ISD::ADJUST_TRAMPOLINE, sdl,\n                             TLI.getPointerTy(DAG.getDataLayout()),\n                             getValue(I.getArgOperand(0))));\n    return;\n  case Intrinsic::gcroot: {\n    assert(DAG.getMachineFunction().getFunction().hasGC() &&\n           \"only valid in functions with gc specified, enforced by Verifier\");\n    assert(GFI && \"implied by previous\");\n    const Value *Alloca = I.getArgOperand(0)->stripPointerCasts();\n    const Constant *TypeMap = cast<Constant>(I.getArgOperand(1));\n\n    FrameIndexSDNode *FI = cast<FrameIndexSDNode>(getValue(Alloca).getNode());\n    GFI->addStackRoot(FI->getIndex(), TypeMap);\n    return;\n  }\n  case Intrinsic::gcread:\n  case Intrinsic::gcwrite:\n    llvm_unreachable(\"GC failed to lower gcread/gcwrite intrinsics!\");\n  case Intrinsic::flt_rounds:\n    Res = DAG.getNode(ISD::FLT_ROUNDS_, sdl, {MVT::i32, MVT::Other}, getRoot());\n    setValue(&I, Res);\n    DAG.setRoot(Res.getValue(1));\n    return;\n\n  case Intrinsic::expect:\n    // Just replace __builtin_expect(exp, c) with EXP.\n    setValue(&I, getValue(I.getArgOperand(0)));\n    return;\n\n  case Intrinsic::ubsantrap:\n  case Intrinsic::debugtrap:\n  case Intrinsic::trap: {\n    StringRef TrapFuncName =\n        I.getAttributes()\n            .getAttribute(AttributeList::FunctionIndex, \"trap-func-name\")\n            .getValueAsString();\n    if (TrapFuncName.empty()) {\n      switch (Intrinsic) {\n      case Intrinsic::trap:\n        DAG.setRoot(DAG.getNode(ISD::TRAP, sdl, MVT::Other, getRoot()));\n        break;\n      case Intrinsic::debugtrap:\n        DAG.setRoot(DAG.getNode(ISD::DEBUGTRAP, sdl, MVT::Other, getRoot()));\n        break;\n      case Intrinsic::ubsantrap:\n        DAG.setRoot(DAG.getNode(\n            ISD::UBSANTRAP, sdl, MVT::Other, getRoot(),\n            DAG.getTargetConstant(\n                cast<ConstantInt>(I.getArgOperand(0))->getZExtValue(), sdl,\n                MVT::i32)));\n        break;\n      default: llvm_unreachable(\"unknown trap intrinsic\");\n      }\n      return;\n    }\n    TargetLowering::ArgListTy Args;\n    if (Intrinsic == Intrinsic::ubsantrap) {\n      Args.push_back(TargetLoweringBase::ArgListEntry());\n      Args[0].Val = I.getArgOperand(0);\n      Args[0].Node = getValue(Args[0].Val);\n      Args[0].Ty = Args[0].Val->getType();\n    }\n\n    TargetLowering::CallLoweringInfo CLI(DAG);\n    CLI.setDebugLoc(sdl).setChain(getRoot()).setLibCallee(\n        CallingConv::C, I.getType(),\n        DAG.getExternalSymbol(TrapFuncName.data(),\n                              TLI.getPointerTy(DAG.getDataLayout())),\n        std::move(Args));\n\n    std::pair<SDValue, SDValue> Result = TLI.LowerCallTo(CLI);\n    DAG.setRoot(Result.second);\n    return;\n  }\n\n  case Intrinsic::uadd_with_overflow:\n  case Intrinsic::sadd_with_overflow:\n  case Intrinsic::usub_with_overflow:\n  case Intrinsic::ssub_with_overflow:\n  case Intrinsic::umul_with_overflow:\n  case Intrinsic::smul_with_overflow: {\n    ISD::NodeType Op;\n    switch (Intrinsic) {\n    default: llvm_unreachable(\"Impossible intrinsic\");  // Can't reach here.\n    case Intrinsic::uadd_with_overflow: Op = ISD::UADDO; break;\n    case Intrinsic::sadd_with_overflow: Op = ISD::SADDO; break;\n    case Intrinsic::usub_with_overflow: Op = ISD::USUBO; break;\n    case Intrinsic::ssub_with_overflow: Op = ISD::SSUBO; break;\n    case Intrinsic::umul_with_overflow: Op = ISD::UMULO; break;\n    case Intrinsic::smul_with_overflow: Op = ISD::SMULO; break;\n    }\n    SDValue Op1 = getValue(I.getArgOperand(0));\n    SDValue Op2 = getValue(I.getArgOperand(1));\n\n    EVT ResultVT = Op1.getValueType();\n    EVT OverflowVT = MVT::i1;\n    if (ResultVT.isVector())\n      OverflowVT = EVT::getVectorVT(\n          *Context, OverflowVT, ResultVT.getVectorElementCount());\n\n    SDVTList VTs = DAG.getVTList(ResultVT, OverflowVT);\n    setValue(&I, DAG.getNode(Op, sdl, VTs, Op1, Op2));\n    return;\n  }\n  case Intrinsic::prefetch: {\n    SDValue Ops[5];\n    unsigned rw = cast<ConstantInt>(I.getArgOperand(1))->getZExtValue();\n    auto Flags = rw == 0 ? MachineMemOperand::MOLoad :MachineMemOperand::MOStore;\n    Ops[0] = DAG.getRoot();\n    Ops[1] = getValue(I.getArgOperand(0));\n    Ops[2] = getValue(I.getArgOperand(1));\n    Ops[3] = getValue(I.getArgOperand(2));\n    Ops[4] = getValue(I.getArgOperand(3));\n    SDValue Result = DAG.getMemIntrinsicNode(\n        ISD::PREFETCH, sdl, DAG.getVTList(MVT::Other), Ops,\n        EVT::getIntegerVT(*Context, 8), MachinePointerInfo(I.getArgOperand(0)),\n        /* align */ None, Flags);\n\n    // Chain the prefetch in parallell with any pending loads, to stay out of\n    // the way of later optimizations.\n    PendingLoads.push_back(Result);\n    Result = getRoot();\n    DAG.setRoot(Result);\n    return;\n  }\n  case Intrinsic::lifetime_start:\n  case Intrinsic::lifetime_end: {\n    bool IsStart = (Intrinsic == Intrinsic::lifetime_start);\n    // Stack coloring is not enabled in O0, discard region information.\n    if (TM.getOptLevel() == CodeGenOpt::None)\n      return;\n\n    const int64_t ObjectSize =\n        cast<ConstantInt>(I.getArgOperand(0))->getSExtValue();\n    Value *const ObjectPtr = I.getArgOperand(1);\n    SmallVector<const Value *, 4> Allocas;\n    getUnderlyingObjects(ObjectPtr, Allocas);\n\n    for (SmallVectorImpl<const Value*>::iterator Object = Allocas.begin(),\n           E = Allocas.end(); Object != E; ++Object) {\n      const AllocaInst *LifetimeObject = dyn_cast_or_null<AllocaInst>(*Object);\n\n      // Could not find an Alloca.\n      if (!LifetimeObject)\n        continue;\n\n      // First check that the Alloca is static, otherwise it won't have a\n      // valid frame index.\n      auto SI = FuncInfo.StaticAllocaMap.find(LifetimeObject);\n      if (SI == FuncInfo.StaticAllocaMap.end())\n        return;\n\n      const int FrameIndex = SI->second;\n      int64_t Offset;\n      if (GetPointerBaseWithConstantOffset(\n              ObjectPtr, Offset, DAG.getDataLayout()) != LifetimeObject)\n        Offset = -1; // Cannot determine offset from alloca to lifetime object.\n      Res = DAG.getLifetimeNode(IsStart, sdl, getRoot(), FrameIndex, ObjectSize,\n                                Offset);\n      DAG.setRoot(Res);\n    }\n    return;\n  }\n  case Intrinsic::pseudoprobe: {\n    auto Guid = cast<ConstantInt>(I.getArgOperand(0))->getZExtValue();\n    auto Index = cast<ConstantInt>(I.getArgOperand(1))->getZExtValue();\n    auto Attr = cast<ConstantInt>(I.getArgOperand(2))->getZExtValue();\n    Res = DAG.getPseudoProbeNode(sdl, getRoot(), Guid, Index, Attr);\n    DAG.setRoot(Res);\n    return;\n  }\n  case Intrinsic::invariant_start:\n    // Discard region information.\n    setValue(&I, DAG.getUNDEF(TLI.getPointerTy(DAG.getDataLayout())));\n    return;\n  case Intrinsic::invariant_end:\n    // Discard region information.\n    return;\n  case Intrinsic::clear_cache:\n    /// FunctionName may be null.\n    if (const char *FunctionName = TLI.getClearCacheBuiltinName())\n      lowerCallToExternalSymbol(I, FunctionName);\n    return;\n  case Intrinsic::donothing:\n    // ignore\n    return;\n  case Intrinsic::experimental_stackmap:\n    visitStackmap(I);\n    return;\n  case Intrinsic::experimental_patchpoint_void:\n  case Intrinsic::experimental_patchpoint_i64:\n    visitPatchpoint(I);\n    return;\n  case Intrinsic::experimental_gc_statepoint:\n    LowerStatepoint(cast<GCStatepointInst>(I));\n    return;\n  case Intrinsic::experimental_gc_result:\n    visitGCResult(cast<GCResultInst>(I));\n    return;\n  case Intrinsic::experimental_gc_relocate:\n    visitGCRelocate(cast<GCRelocateInst>(I));\n    return;\n  case Intrinsic::instrprof_increment:\n    llvm_unreachable(\"instrprof failed to lower an increment\");\n  case Intrinsic::instrprof_value_profile:\n    llvm_unreachable(\"instrprof failed to lower a value profiling call\");\n  case Intrinsic::localescape: {\n    MachineFunction &MF = DAG.getMachineFunction();\n    const TargetInstrInfo *TII = DAG.getSubtarget().getInstrInfo();\n\n    // Directly emit some LOCAL_ESCAPE machine instrs. Label assignment emission\n    // is the same on all targets.\n    for (unsigned Idx = 0, E = I.getNumArgOperands(); Idx < E; ++Idx) {\n      Value *Arg = I.getArgOperand(Idx)->stripPointerCasts();\n      if (isa<ConstantPointerNull>(Arg))\n        continue; // Skip null pointers. They represent a hole in index space.\n      AllocaInst *Slot = cast<AllocaInst>(Arg);\n      assert(FuncInfo.StaticAllocaMap.count(Slot) &&\n             \"can only escape static allocas\");\n      int FI = FuncInfo.StaticAllocaMap[Slot];\n      MCSymbol *FrameAllocSym =\n          MF.getMMI().getContext().getOrCreateFrameAllocSymbol(\n              GlobalValue::dropLLVMManglingEscape(MF.getName()), Idx);\n      BuildMI(*FuncInfo.MBB, FuncInfo.InsertPt, dl,\n              TII->get(TargetOpcode::LOCAL_ESCAPE))\n          .addSym(FrameAllocSym)\n          .addFrameIndex(FI);\n    }\n\n    return;\n  }\n\n  case Intrinsic::localrecover: {\n    // i8* @llvm.localrecover(i8* %fn, i8* %fp, i32 %idx)\n    MachineFunction &MF = DAG.getMachineFunction();\n\n    // Get the symbol that defines the frame offset.\n    auto *Fn = cast<Function>(I.getArgOperand(0)->stripPointerCasts());\n    auto *Idx = cast<ConstantInt>(I.getArgOperand(2));\n    unsigned IdxVal =\n        unsigned(Idx->getLimitedValue(std::numeric_limits<int>::max()));\n    MCSymbol *FrameAllocSym =\n        MF.getMMI().getContext().getOrCreateFrameAllocSymbol(\n            GlobalValue::dropLLVMManglingEscape(Fn->getName()), IdxVal);\n\n    Value *FP = I.getArgOperand(1);\n    SDValue FPVal = getValue(FP);\n    EVT PtrVT = FPVal.getValueType();\n\n    // Create a MCSymbol for the label to avoid any target lowering\n    // that would make this PC relative.\n    SDValue OffsetSym = DAG.getMCSymbol(FrameAllocSym, PtrVT);\n    SDValue OffsetVal =\n        DAG.getNode(ISD::LOCAL_RECOVER, sdl, PtrVT, OffsetSym);\n\n    // Add the offset to the FP.\n    SDValue Add = DAG.getMemBasePlusOffset(FPVal, OffsetVal, sdl);\n    setValue(&I, Add);\n\n    return;\n  }\n\n  case Intrinsic::eh_exceptionpointer:\n  case Intrinsic::eh_exceptioncode: {\n    // Get the exception pointer vreg, copy from it, and resize it to fit.\n    const auto *CPI = cast<CatchPadInst>(I.getArgOperand(0));\n    MVT PtrVT = TLI.getPointerTy(DAG.getDataLayout());\n    const TargetRegisterClass *PtrRC = TLI.getRegClassFor(PtrVT);\n    unsigned VReg = FuncInfo.getCatchPadExceptionPointerVReg(CPI, PtrRC);\n    SDValue N =\n        DAG.getCopyFromReg(DAG.getEntryNode(), getCurSDLoc(), VReg, PtrVT);\n    if (Intrinsic == Intrinsic::eh_exceptioncode)\n      N = DAG.getZExtOrTrunc(N, getCurSDLoc(), MVT::i32);\n    setValue(&I, N);\n    return;\n  }\n  case Intrinsic::xray_customevent: {\n    // Here we want to make sure that the intrinsic behaves as if it has a\n    // specific calling convention, and only for x86_64.\n    // FIXME: Support other platforms later.\n    const auto &Triple = DAG.getTarget().getTargetTriple();\n    if (Triple.getArch() != Triple::x86_64)\n      return;\n\n    SDLoc DL = getCurSDLoc();\n    SmallVector<SDValue, 8> Ops;\n\n    // We want to say that we always want the arguments in registers.\n    SDValue LogEntryVal = getValue(I.getArgOperand(0));\n    SDValue StrSizeVal = getValue(I.getArgOperand(1));\n    SDVTList NodeTys = DAG.getVTList(MVT::Other, MVT::Glue);\n    SDValue Chain = getRoot();\n    Ops.push_back(LogEntryVal);\n    Ops.push_back(StrSizeVal);\n    Ops.push_back(Chain);\n\n    // We need to enforce the calling convention for the callsite, so that\n    // argument ordering is enforced correctly, and that register allocation can\n    // see that some registers may be assumed clobbered and have to preserve\n    // them across calls to the intrinsic.\n    MachineSDNode *MN = DAG.getMachineNode(TargetOpcode::PATCHABLE_EVENT_CALL,\n                                           DL, NodeTys, Ops);\n    SDValue patchableNode = SDValue(MN, 0);\n    DAG.setRoot(patchableNode);\n    setValue(&I, patchableNode);\n    return;\n  }\n  case Intrinsic::xray_typedevent: {\n    // Here we want to make sure that the intrinsic behaves as if it has a\n    // specific calling convention, and only for x86_64.\n    // FIXME: Support other platforms later.\n    const auto &Triple = DAG.getTarget().getTargetTriple();\n    if (Triple.getArch() != Triple::x86_64)\n      return;\n\n    SDLoc DL = getCurSDLoc();\n    SmallVector<SDValue, 8> Ops;\n\n    // We want to say that we always want the arguments in registers.\n    // It's unclear to me how manipulating the selection DAG here forces callers\n    // to provide arguments in registers instead of on the stack.\n    SDValue LogTypeId = getValue(I.getArgOperand(0));\n    SDValue LogEntryVal = getValue(I.getArgOperand(1));\n    SDValue StrSizeVal = getValue(I.getArgOperand(2));\n    SDVTList NodeTys = DAG.getVTList(MVT::Other, MVT::Glue);\n    SDValue Chain = getRoot();\n    Ops.push_back(LogTypeId);\n    Ops.push_back(LogEntryVal);\n    Ops.push_back(StrSizeVal);\n    Ops.push_back(Chain);\n\n    // We need to enforce the calling convention for the callsite, so that\n    // argument ordering is enforced correctly, and that register allocation can\n    // see that some registers may be assumed clobbered and have to preserve\n    // them across calls to the intrinsic.\n    MachineSDNode *MN = DAG.getMachineNode(\n        TargetOpcode::PATCHABLE_TYPED_EVENT_CALL, DL, NodeTys, Ops);\n    SDValue patchableNode = SDValue(MN, 0);\n    DAG.setRoot(patchableNode);\n    setValue(&I, patchableNode);\n    return;\n  }\n  case Intrinsic::experimental_deoptimize:\n    LowerDeoptimizeCall(&I);\n    return;\n\n  case Intrinsic::vector_reduce_fadd:\n  case Intrinsic::vector_reduce_fmul:\n  case Intrinsic::vector_reduce_add:\n  case Intrinsic::vector_reduce_mul:\n  case Intrinsic::vector_reduce_and:\n  case Intrinsic::vector_reduce_or:\n  case Intrinsic::vector_reduce_xor:\n  case Intrinsic::vector_reduce_smax:\n  case Intrinsic::vector_reduce_smin:\n  case Intrinsic::vector_reduce_umax:\n  case Intrinsic::vector_reduce_umin:\n  case Intrinsic::vector_reduce_fmax:\n  case Intrinsic::vector_reduce_fmin:\n    visitVectorReduce(I, Intrinsic);\n    return;\n\n  case Intrinsic::icall_branch_funnel: {\n    SmallVector<SDValue, 16> Ops;\n    Ops.push_back(getValue(I.getArgOperand(0)));\n\n    int64_t Offset;\n    auto *Base = dyn_cast<GlobalObject>(GetPointerBaseWithConstantOffset(\n        I.getArgOperand(1), Offset, DAG.getDataLayout()));\n    if (!Base)\n      report_fatal_error(\n          \"llvm.icall.branch.funnel operand must be a GlobalValue\");\n    Ops.push_back(DAG.getTargetGlobalAddress(Base, getCurSDLoc(), MVT::i64, 0));\n\n    struct BranchFunnelTarget {\n      int64_t Offset;\n      SDValue Target;\n    };\n    SmallVector<BranchFunnelTarget, 8> Targets;\n\n    for (unsigned Op = 1, N = I.getNumArgOperands(); Op != N; Op += 2) {\n      auto *ElemBase = dyn_cast<GlobalObject>(GetPointerBaseWithConstantOffset(\n          I.getArgOperand(Op), Offset, DAG.getDataLayout()));\n      if (ElemBase != Base)\n        report_fatal_error(\"all llvm.icall.branch.funnel operands must refer \"\n                           \"to the same GlobalValue\");\n\n      SDValue Val = getValue(I.getArgOperand(Op + 1));\n      auto *GA = dyn_cast<GlobalAddressSDNode>(Val);\n      if (!GA)\n        report_fatal_error(\n            \"llvm.icall.branch.funnel operand must be a GlobalValue\");\n      Targets.push_back({Offset, DAG.getTargetGlobalAddress(\n                                     GA->getGlobal(), getCurSDLoc(),\n                                     Val.getValueType(), GA->getOffset())});\n    }\n    llvm::sort(Targets,\n               [](const BranchFunnelTarget &T1, const BranchFunnelTarget &T2) {\n                 return T1.Offset < T2.Offset;\n               });\n\n    for (auto &T : Targets) {\n      Ops.push_back(DAG.getTargetConstant(T.Offset, getCurSDLoc(), MVT::i32));\n      Ops.push_back(T.Target);\n    }\n\n    Ops.push_back(DAG.getRoot()); // Chain\n    SDValue N(DAG.getMachineNode(TargetOpcode::ICALL_BRANCH_FUNNEL,\n                                 getCurSDLoc(), MVT::Other, Ops),\n              0);\n    DAG.setRoot(N);\n    setValue(&I, N);\n    HasTailCall = true;\n    return;\n  }\n\n  case Intrinsic::wasm_landingpad_index:\n    // Information this intrinsic contained has been transferred to\n    // MachineFunction in SelectionDAGISel::PrepareEHLandingPad. We can safely\n    // delete it now.\n    return;\n\n  case Intrinsic::aarch64_settag:\n  case Intrinsic::aarch64_settag_zero: {\n    const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n    bool ZeroMemory = Intrinsic == Intrinsic::aarch64_settag_zero;\n    SDValue Val = TSI.EmitTargetCodeForSetTag(\n        DAG, getCurSDLoc(), getRoot(), getValue(I.getArgOperand(0)),\n        getValue(I.getArgOperand(1)), MachinePointerInfo(I.getArgOperand(0)),\n        ZeroMemory);\n    DAG.setRoot(Val);\n    setValue(&I, Val);\n    return;\n  }\n  case Intrinsic::ptrmask: {\n    SDValue Ptr = getValue(I.getOperand(0));\n    SDValue Const = getValue(I.getOperand(1));\n\n    EVT PtrVT = Ptr.getValueType();\n    setValue(&I, DAG.getNode(ISD::AND, getCurSDLoc(), PtrVT, Ptr,\n                             DAG.getZExtOrTrunc(Const, getCurSDLoc(), PtrVT)));\n    return;\n  }\n  case Intrinsic::get_active_lane_mask: {\n    auto DL = getCurSDLoc();\n    SDValue Index = getValue(I.getOperand(0));\n    SDValue TripCount = getValue(I.getOperand(1));\n    Type *ElementTy = I.getOperand(0)->getType();\n    EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    unsigned VecWidth = VT.getVectorNumElements();\n\n    SmallVector<SDValue, 16> OpsTripCount;\n    SmallVector<SDValue, 16> OpsIndex;\n    SmallVector<SDValue, 16> OpsStepConstants;\n    for (unsigned i = 0; i < VecWidth; i++) {\n      OpsTripCount.push_back(TripCount);\n      OpsIndex.push_back(Index);\n      OpsStepConstants.push_back(\n          DAG.getConstant(i, DL, EVT::getEVT(ElementTy)));\n    }\n\n    EVT CCVT = EVT::getVectorVT(I.getContext(), MVT::i1, VecWidth);\n\n    auto VecTy = EVT::getEVT(FixedVectorType::get(ElementTy, VecWidth));\n    SDValue VectorIndex = DAG.getBuildVector(VecTy, DL, OpsIndex);\n    SDValue VectorStep = DAG.getBuildVector(VecTy, DL, OpsStepConstants);\n    SDValue VectorInduction = DAG.getNode(\n       ISD::UADDO, DL, DAG.getVTList(VecTy, CCVT), VectorIndex, VectorStep);\n    SDValue VectorTripCount = DAG.getBuildVector(VecTy, DL, OpsTripCount);\n    SDValue SetCC = DAG.getSetCC(DL, CCVT, VectorInduction.getValue(0),\n                                 VectorTripCount, ISD::CondCode::SETULT);\n    setValue(&I, DAG.getNode(ISD::AND, DL, CCVT,\n                             DAG.getNOT(DL, VectorInduction.getValue(1), CCVT),\n                             SetCC));\n    return;\n  }\n  case Intrinsic::experimental_vector_insert: {\n    auto DL = getCurSDLoc();\n\n    SDValue Vec = getValue(I.getOperand(0));\n    SDValue SubVec = getValue(I.getOperand(1));\n    SDValue Index = getValue(I.getOperand(2));\n    EVT ResultVT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n    setValue(&I, DAG.getNode(ISD::INSERT_SUBVECTOR, DL, ResultVT, Vec, SubVec,\n                             Index));\n    return;\n  }\n  case Intrinsic::experimental_vector_extract: {\n    auto DL = getCurSDLoc();\n\n    SDValue Vec = getValue(I.getOperand(0));\n    SDValue Index = getValue(I.getOperand(1));\n    EVT ResultVT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n\n    setValue(&I, DAG.getNode(ISD::EXTRACT_SUBVECTOR, DL, ResultVT, Vec, Index));\n    return;\n  }\n  }\n}\n\nvoid SelectionDAGBuilder::visitConstrainedFPIntrinsic(\n    const ConstrainedFPIntrinsic &FPI) {\n  SDLoc sdl = getCurSDLoc();\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SmallVector<EVT, 4> ValueVTs;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), FPI.getType(), ValueVTs);\n  ValueVTs.push_back(MVT::Other); // Out chain\n\n  // We do not need to serialize constrained FP intrinsics against\n  // each other or against (nonvolatile) loads, so they can be\n  // chained like loads.\n  SDValue Chain = DAG.getRoot();\n  SmallVector<SDValue, 4> Opers;\n  Opers.push_back(Chain);\n  if (FPI.isUnaryOp()) {\n    Opers.push_back(getValue(FPI.getArgOperand(0)));\n  } else if (FPI.isTernaryOp()) {\n    Opers.push_back(getValue(FPI.getArgOperand(0)));\n    Opers.push_back(getValue(FPI.getArgOperand(1)));\n    Opers.push_back(getValue(FPI.getArgOperand(2)));\n  } else {\n    Opers.push_back(getValue(FPI.getArgOperand(0)));\n    Opers.push_back(getValue(FPI.getArgOperand(1)));\n  }\n\n  auto pushOutChain = [this](SDValue Result, fp::ExceptionBehavior EB) {\n    assert(Result.getNode()->getNumValues() == 2);\n\n    // Push node to the appropriate list so that future instructions can be\n    // chained up correctly.\n    SDValue OutChain = Result.getValue(1);\n    switch (EB) {\n    case fp::ExceptionBehavior::ebIgnore:\n      // The only reason why ebIgnore nodes still need to be chained is that\n      // they might depend on the current rounding mode, and therefore must\n      // not be moved across instruction that may change that mode.\n      LLVM_FALLTHROUGH;\n    case fp::ExceptionBehavior::ebMayTrap:\n      // These must not be moved across calls or instructions that may change\n      // floating-point exception masks.\n      PendingConstrainedFP.push_back(OutChain);\n      break;\n    case fp::ExceptionBehavior::ebStrict:\n      // These must not be moved across calls or instructions that may change\n      // floating-point exception masks or read floating-point exception flags.\n      // In addition, they cannot be optimized out even if unused.\n      PendingConstrainedFPStrict.push_back(OutChain);\n      break;\n    }\n  };\n\n  SDVTList VTs = DAG.getVTList(ValueVTs);\n  fp::ExceptionBehavior EB = FPI.getExceptionBehavior().getValue();\n\n  SDNodeFlags Flags;\n  if (EB == fp::ExceptionBehavior::ebIgnore)\n    Flags.setNoFPExcept(true);\n\n  if (auto *FPOp = dyn_cast<FPMathOperator>(&FPI))\n    Flags.copyFMF(*FPOp);\n\n  unsigned Opcode;\n  switch (FPI.getIntrinsicID()) {\n  default: llvm_unreachable(\"Impossible intrinsic\");  // Can't reach here.\n#define DAG_INSTRUCTION(NAME, NARG, ROUND_MODE, INTRINSIC, DAGN)               \\\n  case Intrinsic::INTRINSIC:                                                   \\\n    Opcode = ISD::STRICT_##DAGN;                                               \\\n    break;\n#include \"llvm/IR/ConstrainedOps.def\"\n  case Intrinsic::experimental_constrained_fmuladd: {\n    Opcode = ISD::STRICT_FMA;\n    // Break fmuladd into fmul and fadd.\n    if (TM.Options.AllowFPOpFusion == FPOpFusion::Strict ||\n        !TLI.isFMAFasterThanFMulAndFAdd(DAG.getMachineFunction(),\n                                        ValueVTs[0])) {\n      Opers.pop_back();\n      SDValue Mul = DAG.getNode(ISD::STRICT_FMUL, sdl, VTs, Opers, Flags);\n      pushOutChain(Mul, EB);\n      Opcode = ISD::STRICT_FADD;\n      Opers.clear();\n      Opers.push_back(Mul.getValue(1));\n      Opers.push_back(Mul.getValue(0));\n      Opers.push_back(getValue(FPI.getArgOperand(2)));\n    }\n    break;\n  }\n  }\n\n  // A few strict DAG nodes carry additional operands that are not\n  // set up by the default code above.\n  switch (Opcode) {\n  default: break;\n  case ISD::STRICT_FP_ROUND:\n    Opers.push_back(\n        DAG.getTargetConstant(0, sdl, TLI.getPointerTy(DAG.getDataLayout())));\n    break;\n  case ISD::STRICT_FSETCC:\n  case ISD::STRICT_FSETCCS: {\n    auto *FPCmp = dyn_cast<ConstrainedFPCmpIntrinsic>(&FPI);\n    Opers.push_back(DAG.getCondCode(getFCmpCondCode(FPCmp->getPredicate())));\n    break;\n  }\n  }\n\n  SDValue Result = DAG.getNode(Opcode, sdl, VTs, Opers, Flags);\n  pushOutChain(Result, EB);\n\n  SDValue FPResult = Result.getValue(0);\n  setValue(&FPI, FPResult);\n}\n\nstatic unsigned getISDForVPIntrinsic(const VPIntrinsic &VPIntrin) {\n  Optional<unsigned> ResOPC;\n  switch (VPIntrin.getIntrinsicID()) {\n#define BEGIN_REGISTER_VP_INTRINSIC(INTRIN, ...) case Intrinsic::INTRIN:\n#define BEGIN_REGISTER_VP_SDNODE(VPSDID, ...) ResOPC = ISD::VPSDID;\n#define END_REGISTER_VP_INTRINSIC(...) break;\n#include \"llvm/IR/VPIntrinsics.def\"\n  }\n\n  if (!ResOPC.hasValue())\n    llvm_unreachable(\n        \"Inconsistency: no SDNode available for this VPIntrinsic!\");\n\n  return ResOPC.getValue();\n}\n\nvoid SelectionDAGBuilder::visitVectorPredicationIntrinsic(\n    const VPIntrinsic &VPIntrin) {\n  unsigned Opcode = getISDForVPIntrinsic(VPIntrin);\n\n  SmallVector<EVT, 4> ValueVTs;\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  ComputeValueVTs(TLI, DAG.getDataLayout(), VPIntrin.getType(), ValueVTs);\n  SDVTList VTs = DAG.getVTList(ValueVTs);\n\n  // Request operands.\n  SmallVector<SDValue, 7> OpValues;\n  for (int i = 0; i < (int)VPIntrin.getNumArgOperands(); ++i)\n    OpValues.push_back(getValue(VPIntrin.getArgOperand(i)));\n\n  SDLoc DL = getCurSDLoc();\n  SDValue Result = DAG.getNode(Opcode, DL, VTs, OpValues);\n  setValue(&VPIntrin, Result);\n}\n\nstd::pair<SDValue, SDValue>\nSelectionDAGBuilder::lowerInvokable(TargetLowering::CallLoweringInfo &CLI,\n                                    const BasicBlock *EHPadBB) {\n  MachineFunction &MF = DAG.getMachineFunction();\n  MachineModuleInfo &MMI = MF.getMMI();\n  MCSymbol *BeginLabel = nullptr;\n\n  if (EHPadBB) {\n    // Insert a label before the invoke call to mark the try range.  This can be\n    // used to detect deletion of the invoke via the MachineModuleInfo.\n    BeginLabel = MMI.getContext().createTempSymbol();\n\n    // For SjLj, keep track of which landing pads go with which invokes\n    // so as to maintain the ordering of pads in the LSDA.\n    unsigned CallSiteIndex = MMI.getCurrentCallSite();\n    if (CallSiteIndex) {\n      MF.setCallSiteBeginLabel(BeginLabel, CallSiteIndex);\n      LPadToCallSiteMap[FuncInfo.MBBMap[EHPadBB]].push_back(CallSiteIndex);\n\n      // Now that the call site is handled, stop tracking it.\n      MMI.setCurrentCallSite(0);\n    }\n\n    // Both PendingLoads and PendingExports must be flushed here;\n    // this call might not return.\n    (void)getRoot();\n    DAG.setRoot(DAG.getEHLabel(getCurSDLoc(), getControlRoot(), BeginLabel));\n\n    CLI.setChain(getRoot());\n  }\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  std::pair<SDValue, SDValue> Result = TLI.LowerCallTo(CLI);\n\n  assert((CLI.IsTailCall || Result.second.getNode()) &&\n         \"Non-null chain expected with non-tail call!\");\n  assert((Result.second.getNode() || !Result.first.getNode()) &&\n         \"Null value expected with tail call!\");\n\n  if (!Result.second.getNode()) {\n    // As a special case, a null chain means that a tail call has been emitted\n    // and the DAG root is already updated.\n    HasTailCall = true;\n\n    // Since there's no actual continuation from this block, nothing can be\n    // relying on us setting vregs for them.\n    PendingExports.clear();\n  } else {\n    DAG.setRoot(Result.second);\n  }\n\n  if (EHPadBB) {\n    // Insert a label at the end of the invoke call to mark the try range.  This\n    // can be used to detect deletion of the invoke via the MachineModuleInfo.\n    MCSymbol *EndLabel = MMI.getContext().createTempSymbol();\n    DAG.setRoot(DAG.getEHLabel(getCurSDLoc(), getRoot(), EndLabel));\n\n    // Inform MachineModuleInfo of range.\n    auto Pers = classifyEHPersonality(FuncInfo.Fn->getPersonalityFn());\n    // There is a platform (e.g. wasm) that uses funclet style IR but does not\n    // actually use outlined funclets and their LSDA info style.\n    if (MF.hasEHFunclets() && isFuncletEHPersonality(Pers)) {\n      assert(CLI.CB);\n      WinEHFuncInfo *EHInfo = DAG.getMachineFunction().getWinEHFuncInfo();\n      EHInfo->addIPToStateRange(cast<InvokeInst>(CLI.CB), BeginLabel, EndLabel);\n    } else if (!isScopedEHPersonality(Pers)) {\n      MF.addInvoke(FuncInfo.MBBMap[EHPadBB], BeginLabel, EndLabel);\n    }\n  }\n\n  return Result;\n}\n\nvoid SelectionDAGBuilder::LowerCallTo(const CallBase &CB, SDValue Callee,\n                                      bool isTailCall,\n                                      const BasicBlock *EHPadBB) {\n  auto &DL = DAG.getDataLayout();\n  FunctionType *FTy = CB.getFunctionType();\n  Type *RetTy = CB.getType();\n\n  TargetLowering::ArgListTy Args;\n  Args.reserve(CB.arg_size());\n\n  const Value *SwiftErrorVal = nullptr;\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  if (isTailCall) {\n    // Avoid emitting tail calls in functions with the disable-tail-calls\n    // attribute.\n    auto *Caller = CB.getParent()->getParent();\n    if (Caller->getFnAttribute(\"disable-tail-calls\").getValueAsString() ==\n        \"true\")\n      isTailCall = false;\n\n    // We can't tail call inside a function with a swifterror argument. Lowering\n    // does not support this yet. It would have to move into the swifterror\n    // register before the call.\n    if (TLI.supportSwiftError() &&\n        Caller->getAttributes().hasAttrSomewhere(Attribute::SwiftError))\n      isTailCall = false;\n  }\n\n  for (auto I = CB.arg_begin(), E = CB.arg_end(); I != E; ++I) {\n    TargetLowering::ArgListEntry Entry;\n    const Value *V = *I;\n\n    // Skip empty types\n    if (V->getType()->isEmptyTy())\n      continue;\n\n    SDValue ArgNode = getValue(V);\n    Entry.Node = ArgNode; Entry.Ty = V->getType();\n\n    Entry.setAttributes(&CB, I - CB.arg_begin());\n\n    // Use swifterror virtual register as input to the call.\n    if (Entry.IsSwiftError && TLI.supportSwiftError()) {\n      SwiftErrorVal = V;\n      // We find the virtual register for the actual swifterror argument.\n      // Instead of using the Value, we use the virtual register instead.\n      Entry.Node =\n          DAG.getRegister(SwiftError.getOrCreateVRegUseAt(&CB, FuncInfo.MBB, V),\n                          EVT(TLI.getPointerTy(DL)));\n    }\n\n    Args.push_back(Entry);\n\n    // If we have an explicit sret argument that is an Instruction, (i.e., it\n    // might point to function-local memory), we can't meaningfully tail-call.\n    if (Entry.IsSRet && isa<Instruction>(V))\n      isTailCall = false;\n  }\n\n  // If call site has a cfguardtarget operand bundle, create and add an\n  // additional ArgListEntry.\n  if (auto Bundle = CB.getOperandBundle(LLVMContext::OB_cfguardtarget)) {\n    TargetLowering::ArgListEntry Entry;\n    Value *V = Bundle->Inputs[0];\n    SDValue ArgNode = getValue(V);\n    Entry.Node = ArgNode;\n    Entry.Ty = V->getType();\n    Entry.IsCFGuardTarget = true;\n    Args.push_back(Entry);\n  }\n\n  // Check if target-independent constraints permit a tail call here.\n  // Target-dependent constraints are checked within TLI->LowerCallTo.\n  if (isTailCall && !isInTailCallPosition(CB, DAG.getTarget()))\n    isTailCall = false;\n\n  // Disable tail calls if there is an swifterror argument. Targets have not\n  // been updated to support tail calls.\n  if (TLI.supportSwiftError() && SwiftErrorVal)\n    isTailCall = false;\n\n  TargetLowering::CallLoweringInfo CLI(DAG);\n  CLI.setDebugLoc(getCurSDLoc())\n      .setChain(getRoot())\n      .setCallee(RetTy, FTy, Callee, std::move(Args), CB)\n      .setTailCall(isTailCall)\n      .setConvergent(CB.isConvergent())\n      .setIsPreallocated(\n          CB.countOperandBundlesOfType(LLVMContext::OB_preallocated) != 0);\n  std::pair<SDValue, SDValue> Result = lowerInvokable(CLI, EHPadBB);\n\n  if (Result.first.getNode()) {\n    Result.first = lowerRangeToAssertZExt(DAG, CB, Result.first);\n    setValue(&CB, Result.first);\n  }\n\n  // The last element of CLI.InVals has the SDValue for swifterror return.\n  // Here we copy it to a virtual register and update SwiftErrorMap for\n  // book-keeping.\n  if (SwiftErrorVal && TLI.supportSwiftError()) {\n    // Get the last element of InVals.\n    SDValue Src = CLI.InVals.back();\n    Register VReg =\n        SwiftError.getOrCreateVRegDefAt(&CB, FuncInfo.MBB, SwiftErrorVal);\n    SDValue CopyNode = CLI.DAG.getCopyToReg(Result.second, CLI.DL, VReg, Src);\n    DAG.setRoot(CopyNode);\n  }\n}\n\nstatic SDValue getMemCmpLoad(const Value *PtrVal, MVT LoadVT,\n                             SelectionDAGBuilder &Builder) {\n  // Check to see if this load can be trivially constant folded, e.g. if the\n  // input is from a string literal.\n  if (const Constant *LoadInput = dyn_cast<Constant>(PtrVal)) {\n    // Cast pointer to the type we really want to load.\n    Type *LoadTy =\n        Type::getIntNTy(PtrVal->getContext(), LoadVT.getScalarSizeInBits());\n    if (LoadVT.isVector())\n      LoadTy = FixedVectorType::get(LoadTy, LoadVT.getVectorNumElements());\n\n    LoadInput = ConstantExpr::getBitCast(const_cast<Constant *>(LoadInput),\n                                         PointerType::getUnqual(LoadTy));\n\n    if (const Constant *LoadCst = ConstantFoldLoadFromConstPtr(\n            const_cast<Constant *>(LoadInput), LoadTy, *Builder.DL))\n      return Builder.getValue(LoadCst);\n  }\n\n  // Otherwise, we have to emit the load.  If the pointer is to unfoldable but\n  // still constant memory, the input chain can be the entry node.\n  SDValue Root;\n  bool ConstantMemory = false;\n\n  // Do not serialize (non-volatile) loads of constant memory with anything.\n  if (Builder.AA && Builder.AA->pointsToConstantMemory(PtrVal)) {\n    Root = Builder.DAG.getEntryNode();\n    ConstantMemory = true;\n  } else {\n    // Do not serialize non-volatile loads against each other.\n    Root = Builder.DAG.getRoot();\n  }\n\n  SDValue Ptr = Builder.getValue(PtrVal);\n  SDValue LoadVal =\n      Builder.DAG.getLoad(LoadVT, Builder.getCurSDLoc(), Root, Ptr,\n                          MachinePointerInfo(PtrVal), Align(1));\n\n  if (!ConstantMemory)\n    Builder.PendingLoads.push_back(LoadVal.getValue(1));\n  return LoadVal;\n}\n\n/// Record the value for an instruction that produces an integer result,\n/// converting the type where necessary.\nvoid SelectionDAGBuilder::processIntegerCallValue(const Instruction &I,\n                                                  SDValue Value,\n                                                  bool IsSigned) {\n  EVT VT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                    I.getType(), true);\n  if (IsSigned)\n    Value = DAG.getSExtOrTrunc(Value, getCurSDLoc(), VT);\n  else\n    Value = DAG.getZExtOrTrunc(Value, getCurSDLoc(), VT);\n  setValue(&I, Value);\n}\n\n/// See if we can lower a memcmp/bcmp call into an optimized form. If so, return\n/// true and lower it. Otherwise return false, and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitMemCmpBCmpCall(const CallInst &I) {\n  const Value *LHS = I.getArgOperand(0), *RHS = I.getArgOperand(1);\n  const Value *Size = I.getArgOperand(2);\n  const ConstantInt *CSize = dyn_cast<ConstantInt>(Size);\n  if (CSize && CSize->getZExtValue() == 0) {\n    EVT CallVT = DAG.getTargetLoweringInfo().getValueType(DAG.getDataLayout(),\n                                                          I.getType(), true);\n    setValue(&I, DAG.getConstant(0, getCurSDLoc(), CallVT));\n    return true;\n  }\n\n  const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n  std::pair<SDValue, SDValue> Res = TSI.EmitTargetCodeForMemcmp(\n      DAG, getCurSDLoc(), DAG.getRoot(), getValue(LHS), getValue(RHS),\n      getValue(Size), MachinePointerInfo(LHS), MachinePointerInfo(RHS));\n  if (Res.first.getNode()) {\n    processIntegerCallValue(I, Res.first, true);\n    PendingLoads.push_back(Res.second);\n    return true;\n  }\n\n  // memcmp(S1,S2,2) != 0 -> (*(short*)LHS != *(short*)RHS)  != 0\n  // memcmp(S1,S2,4) != 0 -> (*(int*)LHS != *(int*)RHS)  != 0\n  if (!CSize || !isOnlyUsedInZeroEqualityComparison(&I))\n    return false;\n\n  // If the target has a fast compare for the given size, it will return a\n  // preferred load type for that size. Require that the load VT is legal and\n  // that the target supports unaligned loads of that type. Otherwise, return\n  // INVALID.\n  auto hasFastLoadsAndCompare = [&](unsigned NumBits) {\n    const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n    MVT LVT = TLI.hasFastEqualityCompare(NumBits);\n    if (LVT != MVT::INVALID_SIMPLE_VALUE_TYPE) {\n      // TODO: Handle 5 byte compare as 4-byte + 1 byte.\n      // TODO: Handle 8 byte compare on x86-32 as two 32-bit loads.\n      // TODO: Check alignment of src and dest ptrs.\n      unsigned DstAS = LHS->getType()->getPointerAddressSpace();\n      unsigned SrcAS = RHS->getType()->getPointerAddressSpace();\n      if (!TLI.isTypeLegal(LVT) ||\n          !TLI.allowsMisalignedMemoryAccesses(LVT, SrcAS) ||\n          !TLI.allowsMisalignedMemoryAccesses(LVT, DstAS))\n        LVT = MVT::INVALID_SIMPLE_VALUE_TYPE;\n    }\n\n    return LVT;\n  };\n\n  // This turns into unaligned loads. We only do this if the target natively\n  // supports the MVT we'll be loading or if it is small enough (<= 4) that\n  // we'll only produce a small number of byte loads.\n  MVT LoadVT;\n  unsigned NumBitsToCompare = CSize->getZExtValue() * 8;\n  switch (NumBitsToCompare) {\n  default:\n    return false;\n  case 16:\n    LoadVT = MVT::i16;\n    break;\n  case 32:\n    LoadVT = MVT::i32;\n    break;\n  case 64:\n  case 128:\n  case 256:\n    LoadVT = hasFastLoadsAndCompare(NumBitsToCompare);\n    break;\n  }\n\n  if (LoadVT == MVT::INVALID_SIMPLE_VALUE_TYPE)\n    return false;\n\n  SDValue LoadL = getMemCmpLoad(LHS, LoadVT, *this);\n  SDValue LoadR = getMemCmpLoad(RHS, LoadVT, *this);\n\n  // Bitcast to a wide integer type if the loads are vectors.\n  if (LoadVT.isVector()) {\n    EVT CmpVT = EVT::getIntegerVT(LHS->getContext(), LoadVT.getSizeInBits());\n    LoadL = DAG.getBitcast(CmpVT, LoadL);\n    LoadR = DAG.getBitcast(CmpVT, LoadR);\n  }\n\n  SDValue Cmp = DAG.getSetCC(getCurSDLoc(), MVT::i1, LoadL, LoadR, ISD::SETNE);\n  processIntegerCallValue(I, Cmp, false);\n  return true;\n}\n\n/// See if we can lower a memchr call into an optimized form. If so, return\n/// true and lower it. Otherwise return false, and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitMemChrCall(const CallInst &I) {\n  const Value *Src = I.getArgOperand(0);\n  const Value *Char = I.getArgOperand(1);\n  const Value *Length = I.getArgOperand(2);\n\n  const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n  std::pair<SDValue, SDValue> Res =\n    TSI.EmitTargetCodeForMemchr(DAG, getCurSDLoc(), DAG.getRoot(),\n                                getValue(Src), getValue(Char), getValue(Length),\n                                MachinePointerInfo(Src));\n  if (Res.first.getNode()) {\n    setValue(&I, Res.first);\n    PendingLoads.push_back(Res.second);\n    return true;\n  }\n\n  return false;\n}\n\n/// See if we can lower a mempcpy call into an optimized form. If so, return\n/// true and lower it. Otherwise return false, and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitMemPCpyCall(const CallInst &I) {\n  SDValue Dst = getValue(I.getArgOperand(0));\n  SDValue Src = getValue(I.getArgOperand(1));\n  SDValue Size = getValue(I.getArgOperand(2));\n\n  Align DstAlign = DAG.InferPtrAlign(Dst).valueOrOne();\n  Align SrcAlign = DAG.InferPtrAlign(Src).valueOrOne();\n  // DAG::getMemcpy needs Alignment to be defined.\n  Align Alignment = std::min(DstAlign, SrcAlign);\n\n  bool isVol = false;\n  SDLoc sdl = getCurSDLoc();\n\n  // In the mempcpy context we need to pass in a false value for isTailCall\n  // because the return pointer needs to be adjusted by the size of\n  // the copied memory.\n  SDValue Root = isVol ? getRoot() : getMemoryRoot();\n  SDValue MC = DAG.getMemcpy(Root, sdl, Dst, Src, Size, Alignment, isVol, false,\n                             /*isTailCall=*/false,\n                             MachinePointerInfo(I.getArgOperand(0)),\n                             MachinePointerInfo(I.getArgOperand(1)));\n  assert(MC.getNode() != nullptr &&\n         \"** memcpy should not be lowered as TailCall in mempcpy context **\");\n  DAG.setRoot(MC);\n\n  // Check if Size needs to be truncated or extended.\n  Size = DAG.getSExtOrTrunc(Size, sdl, Dst.getValueType());\n\n  // Adjust return pointer to point just past the last dst byte.\n  SDValue DstPlusSize = DAG.getNode(ISD::ADD, sdl, Dst.getValueType(),\n                                    Dst, Size);\n  setValue(&I, DstPlusSize);\n  return true;\n}\n\n/// See if we can lower a strcpy call into an optimized form.  If so, return\n/// true and lower it, otherwise return false and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitStrCpyCall(const CallInst &I, bool isStpcpy) {\n  const Value *Arg0 = I.getArgOperand(0), *Arg1 = I.getArgOperand(1);\n\n  const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n  std::pair<SDValue, SDValue> Res =\n    TSI.EmitTargetCodeForStrcpy(DAG, getCurSDLoc(), getRoot(),\n                                getValue(Arg0), getValue(Arg1),\n                                MachinePointerInfo(Arg0),\n                                MachinePointerInfo(Arg1), isStpcpy);\n  if (Res.first.getNode()) {\n    setValue(&I, Res.first);\n    DAG.setRoot(Res.second);\n    return true;\n  }\n\n  return false;\n}\n\n/// See if we can lower a strcmp call into an optimized form.  If so, return\n/// true and lower it, otherwise return false and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitStrCmpCall(const CallInst &I) {\n  const Value *Arg0 = I.getArgOperand(0), *Arg1 = I.getArgOperand(1);\n\n  const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n  std::pair<SDValue, SDValue> Res =\n    TSI.EmitTargetCodeForStrcmp(DAG, getCurSDLoc(), DAG.getRoot(),\n                                getValue(Arg0), getValue(Arg1),\n                                MachinePointerInfo(Arg0),\n                                MachinePointerInfo(Arg1));\n  if (Res.first.getNode()) {\n    processIntegerCallValue(I, Res.first, true);\n    PendingLoads.push_back(Res.second);\n    return true;\n  }\n\n  return false;\n}\n\n/// See if we can lower a strlen call into an optimized form.  If so, return\n/// true and lower it, otherwise return false and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitStrLenCall(const CallInst &I) {\n  const Value *Arg0 = I.getArgOperand(0);\n\n  const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n  std::pair<SDValue, SDValue> Res =\n    TSI.EmitTargetCodeForStrlen(DAG, getCurSDLoc(), DAG.getRoot(),\n                                getValue(Arg0), MachinePointerInfo(Arg0));\n  if (Res.first.getNode()) {\n    processIntegerCallValue(I, Res.first, false);\n    PendingLoads.push_back(Res.second);\n    return true;\n  }\n\n  return false;\n}\n\n/// See if we can lower a strnlen call into an optimized form.  If so, return\n/// true and lower it, otherwise return false and it will be lowered like a\n/// normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitStrNLenCall(const CallInst &I) {\n  const Value *Arg0 = I.getArgOperand(0), *Arg1 = I.getArgOperand(1);\n\n  const SelectionDAGTargetInfo &TSI = DAG.getSelectionDAGInfo();\n  std::pair<SDValue, SDValue> Res =\n    TSI.EmitTargetCodeForStrnlen(DAG, getCurSDLoc(), DAG.getRoot(),\n                                 getValue(Arg0), getValue(Arg1),\n                                 MachinePointerInfo(Arg0));\n  if (Res.first.getNode()) {\n    processIntegerCallValue(I, Res.first, false);\n    PendingLoads.push_back(Res.second);\n    return true;\n  }\n\n  return false;\n}\n\n/// See if we can lower a unary floating-point operation into an SDNode with\n/// the specified Opcode.  If so, return true and lower it, otherwise return\n/// false and it will be lowered like a normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitUnaryFloatCall(const CallInst &I,\n                                              unsigned Opcode) {\n  // We already checked this call's prototype; verify it doesn't modify errno.\n  if (!I.onlyReadsMemory())\n    return false;\n\n  SDNodeFlags Flags;\n  Flags.copyFMF(cast<FPMathOperator>(I));\n\n  SDValue Tmp = getValue(I.getArgOperand(0));\n  setValue(&I,\n           DAG.getNode(Opcode, getCurSDLoc(), Tmp.getValueType(), Tmp, Flags));\n  return true;\n}\n\n/// See if we can lower a binary floating-point operation into an SDNode with\n/// the specified Opcode. If so, return true and lower it. Otherwise return\n/// false, and it will be lowered like a normal call.\n/// The caller already checked that \\p I calls the appropriate LibFunc with a\n/// correct prototype.\nbool SelectionDAGBuilder::visitBinaryFloatCall(const CallInst &I,\n                                               unsigned Opcode) {\n  // We already checked this call's prototype; verify it doesn't modify errno.\n  if (!I.onlyReadsMemory())\n    return false;\n\n  SDNodeFlags Flags;\n  Flags.copyFMF(cast<FPMathOperator>(I));\n\n  SDValue Tmp0 = getValue(I.getArgOperand(0));\n  SDValue Tmp1 = getValue(I.getArgOperand(1));\n  EVT VT = Tmp0.getValueType();\n  setValue(&I, DAG.getNode(Opcode, getCurSDLoc(), VT, Tmp0, Tmp1, Flags));\n  return true;\n}\n\nvoid SelectionDAGBuilder::visitCall(const CallInst &I) {\n  // Handle inline assembly differently.\n  if (I.isInlineAsm()) {\n    visitInlineAsm(I);\n    return;\n  }\n\n  if (Function *F = I.getCalledFunction()) {\n    if (F->isDeclaration()) {\n      // Is this an LLVM intrinsic or a target-specific intrinsic?\n      unsigned IID = F->getIntrinsicID();\n      if (!IID)\n        if (const TargetIntrinsicInfo *II = TM.getIntrinsicInfo())\n          IID = II->getIntrinsicID(F);\n\n      if (IID) {\n        visitIntrinsicCall(I, IID);\n        return;\n      }\n    }\n\n    // Check for well-known libc/libm calls.  If the function is internal, it\n    // can't be a library call.  Don't do the check if marked as nobuiltin for\n    // some reason or the call site requires strict floating point semantics.\n    LibFunc Func;\n    if (!I.isNoBuiltin() && !I.isStrictFP() && !F->hasLocalLinkage() &&\n        F->hasName() && LibInfo->getLibFunc(*F, Func) &&\n        LibInfo->hasOptimizedCodeGen(Func)) {\n      switch (Func) {\n      default: break;\n      case LibFunc_bcmp:\n        if (visitMemCmpBCmpCall(I))\n          return;\n        break;\n      case LibFunc_copysign:\n      case LibFunc_copysignf:\n      case LibFunc_copysignl:\n        // We already checked this call's prototype; verify it doesn't modify\n        // errno.\n        if (I.onlyReadsMemory()) {\n          SDValue LHS = getValue(I.getArgOperand(0));\n          SDValue RHS = getValue(I.getArgOperand(1));\n          setValue(&I, DAG.getNode(ISD::FCOPYSIGN, getCurSDLoc(),\n                                   LHS.getValueType(), LHS, RHS));\n          return;\n        }\n        break;\n      case LibFunc_fabs:\n      case LibFunc_fabsf:\n      case LibFunc_fabsl:\n        if (visitUnaryFloatCall(I, ISD::FABS))\n          return;\n        break;\n      case LibFunc_fmin:\n      case LibFunc_fminf:\n      case LibFunc_fminl:\n        if (visitBinaryFloatCall(I, ISD::FMINNUM))\n          return;\n        break;\n      case LibFunc_fmax:\n      case LibFunc_fmaxf:\n      case LibFunc_fmaxl:\n        if (visitBinaryFloatCall(I, ISD::FMAXNUM))\n          return;\n        break;\n      case LibFunc_sin:\n      case LibFunc_sinf:\n      case LibFunc_sinl:\n        if (visitUnaryFloatCall(I, ISD::FSIN))\n          return;\n        break;\n      case LibFunc_cos:\n      case LibFunc_cosf:\n      case LibFunc_cosl:\n        if (visitUnaryFloatCall(I, ISD::FCOS))\n          return;\n        break;\n      case LibFunc_sqrt:\n      case LibFunc_sqrtf:\n      case LibFunc_sqrtl:\n      case LibFunc_sqrt_finite:\n      case LibFunc_sqrtf_finite:\n      case LibFunc_sqrtl_finite:\n        if (visitUnaryFloatCall(I, ISD::FSQRT))\n          return;\n        break;\n      case LibFunc_floor:\n      case LibFunc_floorf:\n      case LibFunc_floorl:\n        if (visitUnaryFloatCall(I, ISD::FFLOOR))\n          return;\n        break;\n      case LibFunc_nearbyint:\n      case LibFunc_nearbyintf:\n      case LibFunc_nearbyintl:\n        if (visitUnaryFloatCall(I, ISD::FNEARBYINT))\n          return;\n        break;\n      case LibFunc_ceil:\n      case LibFunc_ceilf:\n      case LibFunc_ceill:\n        if (visitUnaryFloatCall(I, ISD::FCEIL))\n          return;\n        break;\n      case LibFunc_rint:\n      case LibFunc_rintf:\n      case LibFunc_rintl:\n        if (visitUnaryFloatCall(I, ISD::FRINT))\n          return;\n        break;\n      case LibFunc_round:\n      case LibFunc_roundf:\n      case LibFunc_roundl:\n        if (visitUnaryFloatCall(I, ISD::FROUND))\n          return;\n        break;\n      case LibFunc_trunc:\n      case LibFunc_truncf:\n      case LibFunc_truncl:\n        if (visitUnaryFloatCall(I, ISD::FTRUNC))\n          return;\n        break;\n      case LibFunc_log2:\n      case LibFunc_log2f:\n      case LibFunc_log2l:\n        if (visitUnaryFloatCall(I, ISD::FLOG2))\n          return;\n        break;\n      case LibFunc_exp2:\n      case LibFunc_exp2f:\n      case LibFunc_exp2l:\n        if (visitUnaryFloatCall(I, ISD::FEXP2))\n          return;\n        break;\n      case LibFunc_memcmp:\n        if (visitMemCmpBCmpCall(I))\n          return;\n        break;\n      case LibFunc_mempcpy:\n        if (visitMemPCpyCall(I))\n          return;\n        break;\n      case LibFunc_memchr:\n        if (visitMemChrCall(I))\n          return;\n        break;\n      case LibFunc_strcpy:\n        if (visitStrCpyCall(I, false))\n          return;\n        break;\n      case LibFunc_stpcpy:\n        if (visitStrCpyCall(I, true))\n          return;\n        break;\n      case LibFunc_strcmp:\n        if (visitStrCmpCall(I))\n          return;\n        break;\n      case LibFunc_strlen:\n        if (visitStrLenCall(I))\n          return;\n        break;\n      case LibFunc_strnlen:\n        if (visitStrNLenCall(I))\n          return;\n        break;\n      }\n    }\n  }\n\n  // Deopt bundles are lowered in LowerCallSiteWithDeoptBundle, and we don't\n  // have to do anything here to lower funclet bundles.\n  // CFGuardTarget bundles are lowered in LowerCallTo.\n  assert(!I.hasOperandBundlesOtherThan(\n             {LLVMContext::OB_deopt, LLVMContext::OB_funclet,\n              LLVMContext::OB_cfguardtarget, LLVMContext::OB_preallocated}) &&\n         \"Cannot lower calls with arbitrary operand bundles!\");\n\n  SDValue Callee = getValue(I.getCalledOperand());\n\n  if (I.countOperandBundlesOfType(LLVMContext::OB_deopt))\n    LowerCallSiteWithDeoptBundle(&I, Callee, nullptr);\n  else\n    // Check if we can potentially perform a tail call. More detailed checking\n    // is be done within LowerCallTo, after more information about the call is\n    // known.\n    LowerCallTo(I, Callee, I.isTailCall());\n}\n\nnamespace {\n\n/// AsmOperandInfo - This contains information for each constraint that we are\n/// lowering.\nclass SDISelAsmOperandInfo : public TargetLowering::AsmOperandInfo {\npublic:\n  /// CallOperand - If this is the result output operand or a clobber\n  /// this is null, otherwise it is the incoming operand to the CallInst.\n  /// This gets modified as the asm is processed.\n  SDValue CallOperand;\n\n  /// AssignedRegs - If this is a register or register class operand, this\n  /// contains the set of register corresponding to the operand.\n  RegsForValue AssignedRegs;\n\n  explicit SDISelAsmOperandInfo(const TargetLowering::AsmOperandInfo &info)\n    : TargetLowering::AsmOperandInfo(info), CallOperand(nullptr, 0) {\n  }\n\n  /// Whether or not this operand accesses memory\n  bool hasMemory(const TargetLowering &TLI) const {\n    // Indirect operand accesses access memory.\n    if (isIndirect)\n      return true;\n\n    for (const auto &Code : Codes)\n      if (TLI.getConstraintType(Code) == TargetLowering::C_Memory)\n        return true;\n\n    return false;\n  }\n\n  /// getCallOperandValEVT - Return the EVT of the Value* that this operand\n  /// corresponds to.  If there is no Value* for this operand, it returns\n  /// MVT::Other.\n  EVT getCallOperandValEVT(LLVMContext &Context, const TargetLowering &TLI,\n                           const DataLayout &DL) const {\n    if (!CallOperandVal) return MVT::Other;\n\n    if (isa<BasicBlock>(CallOperandVal))\n      return TLI.getProgramPointerTy(DL);\n\n    llvm::Type *OpTy = CallOperandVal->getType();\n\n    // FIXME: code duplicated from TargetLowering::ParseConstraints().\n    // If this is an indirect operand, the operand is a pointer to the\n    // accessed type.\n    if (isIndirect) {\n      PointerType *PtrTy = dyn_cast<PointerType>(OpTy);\n      if (!PtrTy)\n        report_fatal_error(\"Indirect operand for inline asm not a pointer!\");\n      OpTy = PtrTy->getElementType();\n    }\n\n    // Look for vector wrapped in a struct. e.g. { <16 x i8> }.\n    if (StructType *STy = dyn_cast<StructType>(OpTy))\n      if (STy->getNumElements() == 1)\n        OpTy = STy->getElementType(0);\n\n    // If OpTy is not a single value, it may be a struct/union that we\n    // can tile with integers.\n    if (!OpTy->isSingleValueType() && OpTy->isSized()) {\n      unsigned BitSize = DL.getTypeSizeInBits(OpTy);\n      switch (BitSize) {\n      default: break;\n      case 1:\n      case 8:\n      case 16:\n      case 32:\n      case 64:\n      case 128:\n        OpTy = IntegerType::get(Context, BitSize);\n        break;\n      }\n    }\n\n    return TLI.getValueType(DL, OpTy, true);\n  }\n};\n\n\n} // end anonymous namespace\n\n/// Make sure that the output operand \\p OpInfo and its corresponding input\n/// operand \\p MatchingOpInfo have compatible constraint types (otherwise error\n/// out).\nstatic void patchMatchingInput(const SDISelAsmOperandInfo &OpInfo,\n                               SDISelAsmOperandInfo &MatchingOpInfo,\n                               SelectionDAG &DAG) {\n  if (OpInfo.ConstraintVT == MatchingOpInfo.ConstraintVT)\n    return;\n\n  const TargetRegisterInfo *TRI = DAG.getSubtarget().getRegisterInfo();\n  const auto &TLI = DAG.getTargetLoweringInfo();\n\n  std::pair<unsigned, const TargetRegisterClass *> MatchRC =\n      TLI.getRegForInlineAsmConstraint(TRI, OpInfo.ConstraintCode,\n                                       OpInfo.ConstraintVT);\n  std::pair<unsigned, const TargetRegisterClass *> InputRC =\n      TLI.getRegForInlineAsmConstraint(TRI, MatchingOpInfo.ConstraintCode,\n                                       MatchingOpInfo.ConstraintVT);\n  if ((OpInfo.ConstraintVT.isInteger() !=\n       MatchingOpInfo.ConstraintVT.isInteger()) ||\n      (MatchRC.second != InputRC.second)) {\n    // FIXME: error out in a more elegant fashion\n    report_fatal_error(\"Unsupported asm: input constraint\"\n                       \" with a matching output constraint of\"\n                       \" incompatible type!\");\n  }\n  MatchingOpInfo.ConstraintVT = OpInfo.ConstraintVT;\n}\n\n/// Get a direct memory input to behave well as an indirect operand.\n/// This may introduce stores, hence the need for a \\p Chain.\n/// \\return The (possibly updated) chain.\nstatic SDValue getAddressForMemoryInput(SDValue Chain, const SDLoc &Location,\n                                        SDISelAsmOperandInfo &OpInfo,\n                                        SelectionDAG &DAG) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  // If we don't have an indirect input, put it in the constpool if we can,\n  // otherwise spill it to a stack slot.\n  // TODO: This isn't quite right. We need to handle these according to\n  // the addressing mode that the constraint wants. Also, this may take\n  // an additional register for the computation and we don't want that\n  // either.\n\n  // If the operand is a float, integer, or vector constant, spill to a\n  // constant pool entry to get its address.\n  const Value *OpVal = OpInfo.CallOperandVal;\n  if (isa<ConstantFP>(OpVal) || isa<ConstantInt>(OpVal) ||\n      isa<ConstantVector>(OpVal) || isa<ConstantDataVector>(OpVal)) {\n    OpInfo.CallOperand = DAG.getConstantPool(\n        cast<Constant>(OpVal), TLI.getPointerTy(DAG.getDataLayout()));\n    return Chain;\n  }\n\n  // Otherwise, create a stack slot and emit a store to it before the asm.\n  Type *Ty = OpVal->getType();\n  auto &DL = DAG.getDataLayout();\n  uint64_t TySize = DL.getTypeAllocSize(Ty);\n  MachineFunction &MF = DAG.getMachineFunction();\n  int SSFI = MF.getFrameInfo().CreateStackObject(\n      TySize, DL.getPrefTypeAlign(Ty), false);\n  SDValue StackSlot = DAG.getFrameIndex(SSFI, TLI.getFrameIndexTy(DL));\n  Chain = DAG.getTruncStore(Chain, Location, OpInfo.CallOperand, StackSlot,\n                            MachinePointerInfo::getFixedStack(MF, SSFI),\n                            TLI.getMemValueType(DL, Ty));\n  OpInfo.CallOperand = StackSlot;\n\n  return Chain;\n}\n\n/// GetRegistersForValue - Assign registers (virtual or physical) for the\n/// specified operand.  We prefer to assign virtual registers, to allow the\n/// register allocator to handle the assignment process.  However, if the asm\n/// uses features that we can't model on machineinstrs, we have SDISel do the\n/// allocation.  This produces generally horrible, but correct, code.\n///\n///   OpInfo describes the operand\n///   RefOpInfo describes the matching operand if any, the operand otherwise\nstatic void GetRegistersForValue(SelectionDAG &DAG, const SDLoc &DL,\n                                 SDISelAsmOperandInfo &OpInfo,\n                                 SDISelAsmOperandInfo &RefOpInfo) {\n  LLVMContext &Context = *DAG.getContext();\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n\n  MachineFunction &MF = DAG.getMachineFunction();\n  SmallVector<unsigned, 4> Regs;\n  const TargetRegisterInfo &TRI = *MF.getSubtarget().getRegisterInfo();\n\n  // No work to do for memory operations.\n  if (OpInfo.ConstraintType == TargetLowering::C_Memory)\n    return;\n\n  // If this is a constraint for a single physreg, or a constraint for a\n  // register class, find it.\n  unsigned AssignedReg;\n  const TargetRegisterClass *RC;\n  std::tie(AssignedReg, RC) = TLI.getRegForInlineAsmConstraint(\n      &TRI, RefOpInfo.ConstraintCode, RefOpInfo.ConstraintVT);\n  // RC is unset only on failure. Return immediately.\n  if (!RC)\n    return;\n\n  // Get the actual register value type.  This is important, because the user\n  // may have asked for (e.g.) the AX register in i32 type.  We need to\n  // remember that AX is actually i16 to get the right extension.\n  const MVT RegVT = *TRI.legalclasstypes_begin(*RC);\n\n  if (OpInfo.ConstraintVT != MVT::Other) {\n    // If this is an FP operand in an integer register (or visa versa), or more\n    // generally if the operand value disagrees with the register class we plan\n    // to stick it in, fix the operand type.\n    //\n    // If this is an input value, the bitcast to the new type is done now.\n    // Bitcast for output value is done at the end of visitInlineAsm().\n    if ((OpInfo.Type == InlineAsm::isOutput ||\n         OpInfo.Type == InlineAsm::isInput) &&\n        !TRI.isTypeLegalForClass(*RC, OpInfo.ConstraintVT)) {\n      // Try to convert to the first EVT that the reg class contains.  If the\n      // types are identical size, use a bitcast to convert (e.g. two differing\n      // vector types).  Note: output bitcast is done at the end of\n      // visitInlineAsm().\n      if (RegVT.getSizeInBits() == OpInfo.ConstraintVT.getSizeInBits()) {\n        // Exclude indirect inputs while they are unsupported because the code\n        // to perform the load is missing and thus OpInfo.CallOperand still\n        // refers to the input address rather than the pointed-to value.\n        if (OpInfo.Type == InlineAsm::isInput && !OpInfo.isIndirect)\n          OpInfo.CallOperand =\n              DAG.getNode(ISD::BITCAST, DL, RegVT, OpInfo.CallOperand);\n        OpInfo.ConstraintVT = RegVT;\n        // If the operand is an FP value and we want it in integer registers,\n        // use the corresponding integer type. This turns an f64 value into\n        // i64, which can be passed with two i32 values on a 32-bit machine.\n      } else if (RegVT.isInteger() && OpInfo.ConstraintVT.isFloatingPoint()) {\n        MVT VT = MVT::getIntegerVT(OpInfo.ConstraintVT.getSizeInBits());\n        if (OpInfo.Type == InlineAsm::isInput)\n          OpInfo.CallOperand =\n              DAG.getNode(ISD::BITCAST, DL, VT, OpInfo.CallOperand);\n        OpInfo.ConstraintVT = VT;\n      }\n    }\n  }\n\n  // No need to allocate a matching input constraint since the constraint it's\n  // matching to has already been allocated.\n  if (OpInfo.isMatchingInputConstraint())\n    return;\n\n  EVT ValueVT = OpInfo.ConstraintVT;\n  if (OpInfo.ConstraintVT == MVT::Other)\n    ValueVT = RegVT;\n\n  // Initialize NumRegs.\n  unsigned NumRegs = 1;\n  if (OpInfo.ConstraintVT != MVT::Other)\n    NumRegs = TLI.getNumRegisters(Context, OpInfo.ConstraintVT);\n\n  // If this is a constraint for a specific physical register, like {r17},\n  // assign it now.\n\n  // If this associated to a specific register, initialize iterator to correct\n  // place. If virtual, make sure we have enough registers\n\n  // Initialize iterator if necessary\n  TargetRegisterClass::iterator I = RC->begin();\n  MachineRegisterInfo &RegInfo = MF.getRegInfo();\n\n  // Do not check for single registers.\n  if (AssignedReg) {\n      for (; *I != AssignedReg; ++I)\n        assert(I != RC->end() && \"AssignedReg should be member of RC\");\n  }\n\n  for (; NumRegs; --NumRegs, ++I) {\n    assert(I != RC->end() && \"Ran out of registers to allocate!\");\n    Register R = AssignedReg ? Register(*I) : RegInfo.createVirtualRegister(RC);\n    Regs.push_back(R);\n  }\n\n  OpInfo.AssignedRegs = RegsForValue(Regs, RegVT, ValueVT);\n}\n\nstatic unsigned\nfindMatchingInlineAsmOperand(unsigned OperandNo,\n                             const std::vector<SDValue> &AsmNodeOperands) {\n  // Scan until we find the definition we already emitted of this operand.\n  unsigned CurOp = InlineAsm::Op_FirstOperand;\n  for (; OperandNo; --OperandNo) {\n    // Advance to the next operand.\n    unsigned OpFlag =\n        cast<ConstantSDNode>(AsmNodeOperands[CurOp])->getZExtValue();\n    assert((InlineAsm::isRegDefKind(OpFlag) ||\n            InlineAsm::isRegDefEarlyClobberKind(OpFlag) ||\n            InlineAsm::isMemKind(OpFlag)) &&\n           \"Skipped past definitions?\");\n    CurOp += InlineAsm::getNumOperandRegisters(OpFlag) + 1;\n  }\n  return CurOp;\n}\n\nnamespace {\n\nclass ExtraFlags {\n  unsigned Flags = 0;\n\npublic:\n  explicit ExtraFlags(const CallBase &Call) {\n    const InlineAsm *IA = cast<InlineAsm>(Call.getCalledOperand());\n    if (IA->hasSideEffects())\n      Flags |= InlineAsm::Extra_HasSideEffects;\n    if (IA->isAlignStack())\n      Flags |= InlineAsm::Extra_IsAlignStack;\n    if (Call.isConvergent())\n      Flags |= InlineAsm::Extra_IsConvergent;\n    Flags |= IA->getDialect() * InlineAsm::Extra_AsmDialect;\n  }\n\n  void update(const TargetLowering::AsmOperandInfo &OpInfo) {\n    // Ideally, we would only check against memory constraints.  However, the\n    // meaning of an Other constraint can be target-specific and we can't easily\n    // reason about it.  Therefore, be conservative and set MayLoad/MayStore\n    // for Other constraints as well.\n    if (OpInfo.ConstraintType == TargetLowering::C_Memory ||\n        OpInfo.ConstraintType == TargetLowering::C_Other) {\n      if (OpInfo.Type == InlineAsm::isInput)\n        Flags |= InlineAsm::Extra_MayLoad;\n      else if (OpInfo.Type == InlineAsm::isOutput)\n        Flags |= InlineAsm::Extra_MayStore;\n      else if (OpInfo.Type == InlineAsm::isClobber)\n        Flags |= (InlineAsm::Extra_MayLoad | InlineAsm::Extra_MayStore);\n    }\n  }\n\n  unsigned get() const { return Flags; }\n};\n\n} // end anonymous namespace\n\n/// visitInlineAsm - Handle a call to an InlineAsm object.\nvoid SelectionDAGBuilder::visitInlineAsm(const CallBase &Call) {\n  const InlineAsm *IA = cast<InlineAsm>(Call.getCalledOperand());\n\n  /// ConstraintOperands - Information about all of the constraints.\n  SmallVector<SDISelAsmOperandInfo, 16> ConstraintOperands;\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  TargetLowering::AsmOperandInfoVector TargetConstraints = TLI.ParseConstraints(\n      DAG.getDataLayout(), DAG.getSubtarget().getRegisterInfo(), Call);\n\n  // First Pass: Calculate HasSideEffects and ExtraFlags (AlignStack,\n  // AsmDialect, MayLoad, MayStore).\n  bool HasSideEffect = IA->hasSideEffects();\n  ExtraFlags ExtraInfo(Call);\n\n  unsigned ArgNo = 0;   // ArgNo - The argument of the CallInst.\n  unsigned ResNo = 0;   // ResNo - The result number of the next output.\n  unsigned NumMatchingOps = 0;\n  for (auto &T : TargetConstraints) {\n    ConstraintOperands.push_back(SDISelAsmOperandInfo(T));\n    SDISelAsmOperandInfo &OpInfo = ConstraintOperands.back();\n\n    // Compute the value type for each operand.\n    if (OpInfo.Type == InlineAsm::isInput ||\n        (OpInfo.Type == InlineAsm::isOutput && OpInfo.isIndirect)) {\n      OpInfo.CallOperandVal = Call.getArgOperand(ArgNo++);\n\n      // Process the call argument. BasicBlocks are labels, currently appearing\n      // only in asm's.\n      if (isa<CallBrInst>(Call) &&\n          ArgNo - 1 >= (cast<CallBrInst>(&Call)->getNumArgOperands() -\n                        cast<CallBrInst>(&Call)->getNumIndirectDests() -\n                        NumMatchingOps) &&\n          (NumMatchingOps == 0 ||\n           ArgNo - 1 < (cast<CallBrInst>(&Call)->getNumArgOperands() -\n                        NumMatchingOps))) {\n        const auto *BA = cast<BlockAddress>(OpInfo.CallOperandVal);\n        EVT VT = TLI.getValueType(DAG.getDataLayout(), BA->getType(), true);\n        OpInfo.CallOperand = DAG.getTargetBlockAddress(BA, VT);\n      } else if (const auto *BB = dyn_cast<BasicBlock>(OpInfo.CallOperandVal)) {\n        OpInfo.CallOperand = DAG.getBasicBlock(FuncInfo.MBBMap[BB]);\n      } else {\n        OpInfo.CallOperand = getValue(OpInfo.CallOperandVal);\n      }\n\n      EVT VT = OpInfo.getCallOperandValEVT(*DAG.getContext(), TLI,\n                                           DAG.getDataLayout());\n      OpInfo.ConstraintVT = VT.isSimple() ? VT.getSimpleVT() : MVT::Other;\n    } else if (OpInfo.Type == InlineAsm::isOutput && !OpInfo.isIndirect) {\n      // The return value of the call is this value.  As such, there is no\n      // corresponding argument.\n      assert(!Call.getType()->isVoidTy() && \"Bad inline asm!\");\n      if (StructType *STy = dyn_cast<StructType>(Call.getType())) {\n        OpInfo.ConstraintVT = TLI.getSimpleValueType(\n            DAG.getDataLayout(), STy->getElementType(ResNo));\n      } else {\n        assert(ResNo == 0 && \"Asm only has one result!\");\n        OpInfo.ConstraintVT =\n            TLI.getSimpleValueType(DAG.getDataLayout(), Call.getType());\n      }\n      ++ResNo;\n    } else {\n      OpInfo.ConstraintVT = MVT::Other;\n    }\n\n    if (OpInfo.hasMatchingInput())\n      ++NumMatchingOps;\n\n    if (!HasSideEffect)\n      HasSideEffect = OpInfo.hasMemory(TLI);\n\n    // Determine if this InlineAsm MayLoad or MayStore based on the constraints.\n    // FIXME: Could we compute this on OpInfo rather than T?\n\n    // Compute the constraint code and ConstraintType to use.\n    TLI.ComputeConstraintToUse(T, SDValue());\n\n    if (T.ConstraintType == TargetLowering::C_Immediate &&\n        OpInfo.CallOperand && !isa<ConstantSDNode>(OpInfo.CallOperand))\n      // We've delayed emitting a diagnostic like the \"n\" constraint because\n      // inlining could cause an integer showing up.\n      return emitInlineAsmError(Call, \"constraint '\" + Twine(T.ConstraintCode) +\n                                          \"' expects an integer constant \"\n                                          \"expression\");\n\n    ExtraInfo.update(T);\n  }\n\n\n  // We won't need to flush pending loads if this asm doesn't touch\n  // memory and is nonvolatile.\n  SDValue Flag, Chain = (HasSideEffect) ? getRoot() : DAG.getRoot();\n\n  bool IsCallBr = isa<CallBrInst>(Call);\n  if (IsCallBr) {\n    // If this is a callbr we need to flush pending exports since inlineasm_br\n    // is a terminator. We need to do this before nodes are glued to\n    // the inlineasm_br node.\n    Chain = getControlRoot();\n  }\n\n  // Second pass over the constraints: compute which constraint option to use.\n  for (SDISelAsmOperandInfo &OpInfo : ConstraintOperands) {\n    // If this is an output operand with a matching input operand, look up the\n    // matching input. If their types mismatch, e.g. one is an integer, the\n    // other is floating point, or their sizes are different, flag it as an\n    // error.\n    if (OpInfo.hasMatchingInput()) {\n      SDISelAsmOperandInfo &Input = ConstraintOperands[OpInfo.MatchingInput];\n      patchMatchingInput(OpInfo, Input, DAG);\n    }\n\n    // Compute the constraint code and ConstraintType to use.\n    TLI.ComputeConstraintToUse(OpInfo, OpInfo.CallOperand, &DAG);\n\n    if (OpInfo.ConstraintType == TargetLowering::C_Memory &&\n        OpInfo.Type == InlineAsm::isClobber)\n      continue;\n\n    // If this is a memory input, and if the operand is not indirect, do what we\n    // need to provide an address for the memory input.\n    if (OpInfo.ConstraintType == TargetLowering::C_Memory &&\n        !OpInfo.isIndirect) {\n      assert((OpInfo.isMultipleAlternative ||\n              (OpInfo.Type == InlineAsm::isInput)) &&\n             \"Can only indirectify direct input operands!\");\n\n      // Memory operands really want the address of the value.\n      Chain = getAddressForMemoryInput(Chain, getCurSDLoc(), OpInfo, DAG);\n\n      // There is no longer a Value* corresponding to this operand.\n      OpInfo.CallOperandVal = nullptr;\n\n      // It is now an indirect operand.\n      OpInfo.isIndirect = true;\n    }\n\n  }\n\n  // AsmNodeOperands - The operands for the ISD::INLINEASM node.\n  std::vector<SDValue> AsmNodeOperands;\n  AsmNodeOperands.push_back(SDValue());  // reserve space for input chain\n  AsmNodeOperands.push_back(DAG.getTargetExternalSymbol(\n      IA->getAsmString().c_str(), TLI.getProgramPointerTy(DAG.getDataLayout())));\n\n  // If we have a !srcloc metadata node associated with it, we want to attach\n  // this to the ultimately generated inline asm machineinstr.  To do this, we\n  // pass in the third operand as this (potentially null) inline asm MDNode.\n  const MDNode *SrcLoc = Call.getMetadata(\"srcloc\");\n  AsmNodeOperands.push_back(DAG.getMDNode(SrcLoc));\n\n  // Remember the HasSideEffect, AlignStack, AsmDialect, MayLoad and MayStore\n  // bits as operand 3.\n  AsmNodeOperands.push_back(DAG.getTargetConstant(\n      ExtraInfo.get(), getCurSDLoc(), TLI.getPointerTy(DAG.getDataLayout())));\n\n  // Third pass: Loop over operands to prepare DAG-level operands.. As part of\n  // this, assign virtual and physical registers for inputs and otput.\n  for (SDISelAsmOperandInfo &OpInfo : ConstraintOperands) {\n    // Assign Registers.\n    SDISelAsmOperandInfo &RefOpInfo =\n        OpInfo.isMatchingInputConstraint()\n            ? ConstraintOperands[OpInfo.getMatchedOperand()]\n            : OpInfo;\n    GetRegistersForValue(DAG, getCurSDLoc(), OpInfo, RefOpInfo);\n\n    auto DetectWriteToReservedRegister = [&]() {\n      const MachineFunction &MF = DAG.getMachineFunction();\n      const TargetRegisterInfo &TRI = *MF.getSubtarget().getRegisterInfo();\n      for (unsigned Reg : OpInfo.AssignedRegs.Regs) {\n        if (Register::isPhysicalRegister(Reg) &&\n            TRI.isInlineAsmReadOnlyReg(MF, Reg)) {\n          const char *RegName = TRI.getName(Reg);\n          emitInlineAsmError(Call, \"write to reserved register '\" +\n                                       Twine(RegName) + \"'\");\n          return true;\n        }\n      }\n      return false;\n    };\n\n    switch (OpInfo.Type) {\n    case InlineAsm::isOutput:\n      if (OpInfo.ConstraintType == TargetLowering::C_Memory) {\n        unsigned ConstraintID =\n            TLI.getInlineAsmMemConstraint(OpInfo.ConstraintCode);\n        assert(ConstraintID != InlineAsm::Constraint_Unknown &&\n               \"Failed to convert memory constraint code to constraint id.\");\n\n        // Add information to the INLINEASM node to know about this output.\n        unsigned OpFlags = InlineAsm::getFlagWord(InlineAsm::Kind_Mem, 1);\n        OpFlags = InlineAsm::getFlagWordForMem(OpFlags, ConstraintID);\n        AsmNodeOperands.push_back(DAG.getTargetConstant(OpFlags, getCurSDLoc(),\n                                                        MVT::i32));\n        AsmNodeOperands.push_back(OpInfo.CallOperand);\n      } else {\n        // Otherwise, this outputs to a register (directly for C_Register /\n        // C_RegisterClass, and a target-defined fashion for\n        // C_Immediate/C_Other). Find a register that we can use.\n        if (OpInfo.AssignedRegs.Regs.empty()) {\n          emitInlineAsmError(\n              Call, \"couldn't allocate output register for constraint '\" +\n                        Twine(OpInfo.ConstraintCode) + \"'\");\n          return;\n        }\n\n        if (DetectWriteToReservedRegister())\n          return;\n\n        // Add information to the INLINEASM node to know that this register is\n        // set.\n        OpInfo.AssignedRegs.AddInlineAsmOperands(\n            OpInfo.isEarlyClobber ? InlineAsm::Kind_RegDefEarlyClobber\n                                  : InlineAsm::Kind_RegDef,\n            false, 0, getCurSDLoc(), DAG, AsmNodeOperands);\n      }\n      break;\n\n    case InlineAsm::isInput: {\n      SDValue InOperandVal = OpInfo.CallOperand;\n\n      if (OpInfo.isMatchingInputConstraint()) {\n        // If this is required to match an output register we have already set,\n        // just use its register.\n        auto CurOp = findMatchingInlineAsmOperand(OpInfo.getMatchedOperand(),\n                                                  AsmNodeOperands);\n        unsigned OpFlag =\n          cast<ConstantSDNode>(AsmNodeOperands[CurOp])->getZExtValue();\n        if (InlineAsm::isRegDefKind(OpFlag) ||\n            InlineAsm::isRegDefEarlyClobberKind(OpFlag)) {\n          // Add (OpFlag&0xffff)>>3 registers to MatchedRegs.\n          if (OpInfo.isIndirect) {\n            // This happens on gcc/testsuite/gcc.dg/pr8788-1.c\n            emitInlineAsmError(Call, \"inline asm not supported yet: \"\n                                     \"don't know how to handle tied \"\n                                     \"indirect register inputs\");\n            return;\n          }\n\n          MVT RegVT = AsmNodeOperands[CurOp+1].getSimpleValueType();\n          SmallVector<unsigned, 4> Regs;\n\n          if (const TargetRegisterClass *RC = TLI.getRegClassFor(RegVT)) {\n            unsigned NumRegs = InlineAsm::getNumOperandRegisters(OpFlag);\n            MachineRegisterInfo &RegInfo =\n                DAG.getMachineFunction().getRegInfo();\n            for (unsigned i = 0; i != NumRegs; ++i)\n              Regs.push_back(RegInfo.createVirtualRegister(RC));\n          } else {\n            emitInlineAsmError(Call,\n                               \"inline asm error: This value type register \"\n                               \"class is not natively supported!\");\n            return;\n          }\n\n          RegsForValue MatchedRegs(Regs, RegVT, InOperandVal.getValueType());\n\n          SDLoc dl = getCurSDLoc();\n          // Use the produced MatchedRegs object to\n          MatchedRegs.getCopyToRegs(InOperandVal, DAG, dl, Chain, &Flag, &Call);\n          MatchedRegs.AddInlineAsmOperands(InlineAsm::Kind_RegUse,\n                                           true, OpInfo.getMatchedOperand(), dl,\n                                           DAG, AsmNodeOperands);\n          break;\n        }\n\n        assert(InlineAsm::isMemKind(OpFlag) && \"Unknown matching constraint!\");\n        assert(InlineAsm::getNumOperandRegisters(OpFlag) == 1 &&\n               \"Unexpected number of operands\");\n        // Add information to the INLINEASM node to know about this input.\n        // See InlineAsm.h isUseOperandTiedToDef.\n        OpFlag = InlineAsm::convertMemFlagWordToMatchingFlagWord(OpFlag);\n        OpFlag = InlineAsm::getFlagWordForMatchingOp(OpFlag,\n                                                    OpInfo.getMatchedOperand());\n        AsmNodeOperands.push_back(DAG.getTargetConstant(\n            OpFlag, getCurSDLoc(), TLI.getPointerTy(DAG.getDataLayout())));\n        AsmNodeOperands.push_back(AsmNodeOperands[CurOp+1]);\n        break;\n      }\n\n      // Treat indirect 'X' constraint as memory.\n      if (OpInfo.ConstraintType == TargetLowering::C_Other &&\n          OpInfo.isIndirect)\n        OpInfo.ConstraintType = TargetLowering::C_Memory;\n\n      if (OpInfo.ConstraintType == TargetLowering::C_Immediate ||\n          OpInfo.ConstraintType == TargetLowering::C_Other) {\n        std::vector<SDValue> Ops;\n        TLI.LowerAsmOperandForConstraint(InOperandVal, OpInfo.ConstraintCode,\n                                          Ops, DAG);\n        if (Ops.empty()) {\n          if (OpInfo.ConstraintType == TargetLowering::C_Immediate)\n            if (isa<ConstantSDNode>(InOperandVal)) {\n              emitInlineAsmError(Call, \"value out of range for constraint '\" +\n                                           Twine(OpInfo.ConstraintCode) + \"'\");\n              return;\n            }\n\n          emitInlineAsmError(Call,\n                             \"invalid operand for inline asm constraint '\" +\n                                 Twine(OpInfo.ConstraintCode) + \"'\");\n          return;\n        }\n\n        // Add information to the INLINEASM node to know about this input.\n        unsigned ResOpType =\n          InlineAsm::getFlagWord(InlineAsm::Kind_Imm, Ops.size());\n        AsmNodeOperands.push_back(DAG.getTargetConstant(\n            ResOpType, getCurSDLoc(), TLI.getPointerTy(DAG.getDataLayout())));\n        llvm::append_range(AsmNodeOperands, Ops);\n        break;\n      }\n\n      if (OpInfo.ConstraintType == TargetLowering::C_Memory) {\n        assert(OpInfo.isIndirect && \"Operand must be indirect to be a mem!\");\n        assert(InOperandVal.getValueType() ==\n                   TLI.getPointerTy(DAG.getDataLayout()) &&\n               \"Memory operands expect pointer values\");\n\n        unsigned ConstraintID =\n            TLI.getInlineAsmMemConstraint(OpInfo.ConstraintCode);\n        assert(ConstraintID != InlineAsm::Constraint_Unknown &&\n               \"Failed to convert memory constraint code to constraint id.\");\n\n        // Add information to the INLINEASM node to know about this input.\n        unsigned ResOpType = InlineAsm::getFlagWord(InlineAsm::Kind_Mem, 1);\n        ResOpType = InlineAsm::getFlagWordForMem(ResOpType, ConstraintID);\n        AsmNodeOperands.push_back(DAG.getTargetConstant(ResOpType,\n                                                        getCurSDLoc(),\n                                                        MVT::i32));\n        AsmNodeOperands.push_back(InOperandVal);\n        break;\n      }\n\n      assert((OpInfo.ConstraintType == TargetLowering::C_RegisterClass ||\n              OpInfo.ConstraintType == TargetLowering::C_Register) &&\n             \"Unknown constraint type!\");\n\n      // TODO: Support this.\n      if (OpInfo.isIndirect) {\n        emitInlineAsmError(\n            Call, \"Don't know how to handle indirect register inputs yet \"\n                  \"for constraint '\" +\n                      Twine(OpInfo.ConstraintCode) + \"'\");\n        return;\n      }\n\n      // Copy the input into the appropriate registers.\n      if (OpInfo.AssignedRegs.Regs.empty()) {\n        emitInlineAsmError(Call,\n                           \"couldn't allocate input reg for constraint '\" +\n                               Twine(OpInfo.ConstraintCode) + \"'\");\n        return;\n      }\n\n      if (DetectWriteToReservedRegister())\n        return;\n\n      SDLoc dl = getCurSDLoc();\n\n      OpInfo.AssignedRegs.getCopyToRegs(InOperandVal, DAG, dl, Chain, &Flag,\n                                        &Call);\n\n      OpInfo.AssignedRegs.AddInlineAsmOperands(InlineAsm::Kind_RegUse, false, 0,\n                                               dl, DAG, AsmNodeOperands);\n      break;\n    }\n    case InlineAsm::isClobber:\n      // Add the clobbered value to the operand list, so that the register\n      // allocator is aware that the physreg got clobbered.\n      if (!OpInfo.AssignedRegs.Regs.empty())\n        OpInfo.AssignedRegs.AddInlineAsmOperands(InlineAsm::Kind_Clobber,\n                                                 false, 0, getCurSDLoc(), DAG,\n                                                 AsmNodeOperands);\n      break;\n    }\n  }\n\n  // Finish up input operands.  Set the input chain and add the flag last.\n  AsmNodeOperands[InlineAsm::Op_InputChain] = Chain;\n  if (Flag.getNode()) AsmNodeOperands.push_back(Flag);\n\n  unsigned ISDOpc = IsCallBr ? ISD::INLINEASM_BR : ISD::INLINEASM;\n  Chain = DAG.getNode(ISDOpc, getCurSDLoc(),\n                      DAG.getVTList(MVT::Other, MVT::Glue), AsmNodeOperands);\n  Flag = Chain.getValue(1);\n\n  // Do additional work to generate outputs.\n\n  SmallVector<EVT, 1> ResultVTs;\n  SmallVector<SDValue, 1> ResultValues;\n  SmallVector<SDValue, 8> OutChains;\n\n  llvm::Type *CallResultType = Call.getType();\n  ArrayRef<Type *> ResultTypes;\n  if (StructType *StructResult = dyn_cast<StructType>(CallResultType))\n    ResultTypes = StructResult->elements();\n  else if (!CallResultType->isVoidTy())\n    ResultTypes = makeArrayRef(CallResultType);\n\n  auto CurResultType = ResultTypes.begin();\n  auto handleRegAssign = [&](SDValue V) {\n    assert(CurResultType != ResultTypes.end() && \"Unexpected value\");\n    assert((*CurResultType)->isSized() && \"Unexpected unsized type\");\n    EVT ResultVT = TLI.getValueType(DAG.getDataLayout(), *CurResultType);\n    ++CurResultType;\n    // If the type of the inline asm call site return value is different but has\n    // same size as the type of the asm output bitcast it.  One example of this\n    // is for vectors with different width / number of elements.  This can\n    // happen for register classes that can contain multiple different value\n    // types.  The preg or vreg allocated may not have the same VT as was\n    // expected.\n    //\n    // This can also happen for a return value that disagrees with the register\n    // class it is put in, eg. a double in a general-purpose register on a\n    // 32-bit machine.\n    if (ResultVT != V.getValueType() &&\n        ResultVT.getSizeInBits() == V.getValueSizeInBits())\n      V = DAG.getNode(ISD::BITCAST, getCurSDLoc(), ResultVT, V);\n    else if (ResultVT != V.getValueType() && ResultVT.isInteger() &&\n             V.getValueType().isInteger()) {\n      // If a result value was tied to an input value, the computed result\n      // may have a wider width than the expected result.  Extract the\n      // relevant portion.\n      V = DAG.getNode(ISD::TRUNCATE, getCurSDLoc(), ResultVT, V);\n    }\n    assert(ResultVT == V.getValueType() && \"Asm result value mismatch!\");\n    ResultVTs.push_back(ResultVT);\n    ResultValues.push_back(V);\n  };\n\n  // Deal with output operands.\n  for (SDISelAsmOperandInfo &OpInfo : ConstraintOperands) {\n    if (OpInfo.Type == InlineAsm::isOutput) {\n      SDValue Val;\n      // Skip trivial output operands.\n      if (OpInfo.AssignedRegs.Regs.empty())\n        continue;\n\n      switch (OpInfo.ConstraintType) {\n      case TargetLowering::C_Register:\n      case TargetLowering::C_RegisterClass:\n        Val = OpInfo.AssignedRegs.getCopyFromRegs(DAG, FuncInfo, getCurSDLoc(),\n                                                  Chain, &Flag, &Call);\n        break;\n      case TargetLowering::C_Immediate:\n      case TargetLowering::C_Other:\n        Val = TLI.LowerAsmOutputForConstraint(Chain, Flag, getCurSDLoc(),\n                                              OpInfo, DAG);\n        break;\n      case TargetLowering::C_Memory:\n        break; // Already handled.\n      case TargetLowering::C_Unknown:\n        assert(false && \"Unexpected unknown constraint\");\n      }\n\n      // Indirect output manifest as stores. Record output chains.\n      if (OpInfo.isIndirect) {\n        const Value *Ptr = OpInfo.CallOperandVal;\n        assert(Ptr && \"Expected value CallOperandVal for indirect asm operand\");\n        SDValue Store = DAG.getStore(Chain, getCurSDLoc(), Val, getValue(Ptr),\n                                     MachinePointerInfo(Ptr));\n        OutChains.push_back(Store);\n      } else {\n        // generate CopyFromRegs to associated registers.\n        assert(!Call.getType()->isVoidTy() && \"Bad inline asm!\");\n        if (Val.getOpcode() == ISD::MERGE_VALUES) {\n          for (const SDValue &V : Val->op_values())\n            handleRegAssign(V);\n        } else\n          handleRegAssign(Val);\n      }\n    }\n  }\n\n  // Set results.\n  if (!ResultValues.empty()) {\n    assert(CurResultType == ResultTypes.end() &&\n           \"Mismatch in number of ResultTypes\");\n    assert(ResultValues.size() == ResultTypes.size() &&\n           \"Mismatch in number of output operands in asm result\");\n\n    SDValue V = DAG.getNode(ISD::MERGE_VALUES, getCurSDLoc(),\n                            DAG.getVTList(ResultVTs), ResultValues);\n    setValue(&Call, V);\n  }\n\n  // Collect store chains.\n  if (!OutChains.empty())\n    Chain = DAG.getNode(ISD::TokenFactor, getCurSDLoc(), MVT::Other, OutChains);\n\n  // Only Update Root if inline assembly has a memory effect.\n  if (ResultValues.empty() || HasSideEffect || !OutChains.empty() || IsCallBr)\n    DAG.setRoot(Chain);\n}\n\nvoid SelectionDAGBuilder::emitInlineAsmError(const CallBase &Call,\n                                             const Twine &Message) {\n  LLVMContext &Ctx = *DAG.getContext();\n  Ctx.emitError(&Call, Message);\n\n  // Make sure we leave the DAG in a valid state\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SmallVector<EVT, 1> ValueVTs;\n  ComputeValueVTs(TLI, DAG.getDataLayout(), Call.getType(), ValueVTs);\n\n  if (ValueVTs.empty())\n    return;\n\n  SmallVector<SDValue, 1> Ops;\n  for (unsigned i = 0, e = ValueVTs.size(); i != e; ++i)\n    Ops.push_back(DAG.getUNDEF(ValueVTs[i]));\n\n  setValue(&Call, DAG.getMergeValues(Ops, getCurSDLoc()));\n}\n\nvoid SelectionDAGBuilder::visitVAStart(const CallInst &I) {\n  DAG.setRoot(DAG.getNode(ISD::VASTART, getCurSDLoc(),\n                          MVT::Other, getRoot(),\n                          getValue(I.getArgOperand(0)),\n                          DAG.getSrcValue(I.getArgOperand(0))));\n}\n\nvoid SelectionDAGBuilder::visitVAArg(const VAArgInst &I) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  const DataLayout &DL = DAG.getDataLayout();\n  SDValue V = DAG.getVAArg(\n      TLI.getMemValueType(DAG.getDataLayout(), I.getType()), getCurSDLoc(),\n      getRoot(), getValue(I.getOperand(0)), DAG.getSrcValue(I.getOperand(0)),\n      DL.getABITypeAlign(I.getType()).value());\n  DAG.setRoot(V.getValue(1));\n\n  if (I.getType()->isPointerTy())\n    V = DAG.getPtrExtOrTrunc(\n        V, getCurSDLoc(), TLI.getValueType(DAG.getDataLayout(), I.getType()));\n  setValue(&I, V);\n}\n\nvoid SelectionDAGBuilder::visitVAEnd(const CallInst &I) {\n  DAG.setRoot(DAG.getNode(ISD::VAEND, getCurSDLoc(),\n                          MVT::Other, getRoot(),\n                          getValue(I.getArgOperand(0)),\n                          DAG.getSrcValue(I.getArgOperand(0))));\n}\n\nvoid SelectionDAGBuilder::visitVACopy(const CallInst &I) {\n  DAG.setRoot(DAG.getNode(ISD::VACOPY, getCurSDLoc(),\n                          MVT::Other, getRoot(),\n                          getValue(I.getArgOperand(0)),\n                          getValue(I.getArgOperand(1)),\n                          DAG.getSrcValue(I.getArgOperand(0)),\n                          DAG.getSrcValue(I.getArgOperand(1))));\n}\n\nSDValue SelectionDAGBuilder::lowerRangeToAssertZExt(SelectionDAG &DAG,\n                                                    const Instruction &I,\n                                                    SDValue Op) {\n  const MDNode *Range = I.getMetadata(LLVMContext::MD_range);\n  if (!Range)\n    return Op;\n\n  ConstantRange CR = getConstantRangeFromMetadata(*Range);\n  if (CR.isFullSet() || CR.isEmptySet() || CR.isUpperWrapped())\n    return Op;\n\n  APInt Lo = CR.getUnsignedMin();\n  if (!Lo.isMinValue())\n    return Op;\n\n  APInt Hi = CR.getUnsignedMax();\n  unsigned Bits = std::max(Hi.getActiveBits(),\n                           static_cast<unsigned>(IntegerType::MIN_INT_BITS));\n\n  EVT SmallVT = EVT::getIntegerVT(*DAG.getContext(), Bits);\n\n  SDLoc SL = getCurSDLoc();\n\n  SDValue ZExt = DAG.getNode(ISD::AssertZext, SL, Op.getValueType(), Op,\n                             DAG.getValueType(SmallVT));\n  unsigned NumVals = Op.getNode()->getNumValues();\n  if (NumVals == 1)\n    return ZExt;\n\n  SmallVector<SDValue, 4> Ops;\n\n  Ops.push_back(ZExt);\n  for (unsigned I = 1; I != NumVals; ++I)\n    Ops.push_back(Op.getValue(I));\n\n  return DAG.getMergeValues(Ops, SL);\n}\n\n/// Populate a CallLowerinInfo (into \\p CLI) based on the properties of\n/// the call being lowered.\n///\n/// This is a helper for lowering intrinsics that follow a target calling\n/// convention or require stack pointer adjustment. Only a subset of the\n/// intrinsic's operands need to participate in the calling convention.\nvoid SelectionDAGBuilder::populateCallLoweringInfo(\n    TargetLowering::CallLoweringInfo &CLI, const CallBase *Call,\n    unsigned ArgIdx, unsigned NumArgs, SDValue Callee, Type *ReturnTy,\n    bool IsPatchPoint) {\n  TargetLowering::ArgListTy Args;\n  Args.reserve(NumArgs);\n\n  // Populate the argument list.\n  // Attributes for args start at offset 1, after the return attribute.\n  for (unsigned ArgI = ArgIdx, ArgE = ArgIdx + NumArgs;\n       ArgI != ArgE; ++ArgI) {\n    const Value *V = Call->getOperand(ArgI);\n\n    assert(!V->getType()->isEmptyTy() && \"Empty type passed to intrinsic.\");\n\n    TargetLowering::ArgListEntry Entry;\n    Entry.Node = getValue(V);\n    Entry.Ty = V->getType();\n    Entry.setAttributes(Call, ArgI);\n    Args.push_back(Entry);\n  }\n\n  CLI.setDebugLoc(getCurSDLoc())\n      .setChain(getRoot())\n      .setCallee(Call->getCallingConv(), ReturnTy, Callee, std::move(Args))\n      .setDiscardResult(Call->use_empty())\n      .setIsPatchPoint(IsPatchPoint)\n      .setIsPreallocated(\n          Call->countOperandBundlesOfType(LLVMContext::OB_preallocated) != 0);\n}\n\n/// Add a stack map intrinsic call's live variable operands to a stackmap\n/// or patchpoint target node's operand list.\n///\n/// Constants are converted to TargetConstants purely as an optimization to\n/// avoid constant materialization and register allocation.\n///\n/// FrameIndex operands are converted to TargetFrameIndex so that ISEL does not\n/// generate addess computation nodes, and so FinalizeISel can convert the\n/// TargetFrameIndex into a DirectMemRefOp StackMap location. This avoids\n/// address materialization and register allocation, but may also be required\n/// for correctness. If a StackMap (or PatchPoint) intrinsic directly uses an\n/// alloca in the entry block, then the runtime may assume that the alloca's\n/// StackMap location can be read immediately after compilation and that the\n/// location is valid at any point during execution (this is similar to the\n/// assumption made by the llvm.gcroot intrinsic). If the alloca's location were\n/// only available in a register, then the runtime would need to trap when\n/// execution reaches the StackMap in order to read the alloca's location.\nstatic void addStackMapLiveVars(const CallBase &Call, unsigned StartIdx,\n                                const SDLoc &DL, SmallVectorImpl<SDValue> &Ops,\n                                SelectionDAGBuilder &Builder) {\n  for (unsigned i = StartIdx, e = Call.arg_size(); i != e; ++i) {\n    SDValue OpVal = Builder.getValue(Call.getArgOperand(i));\n    if (ConstantSDNode *C = dyn_cast<ConstantSDNode>(OpVal)) {\n      Ops.push_back(\n        Builder.DAG.getTargetConstant(StackMaps::ConstantOp, DL, MVT::i64));\n      Ops.push_back(\n        Builder.DAG.getTargetConstant(C->getSExtValue(), DL, MVT::i64));\n    } else if (FrameIndexSDNode *FI = dyn_cast<FrameIndexSDNode>(OpVal)) {\n      const TargetLowering &TLI = Builder.DAG.getTargetLoweringInfo();\n      Ops.push_back(Builder.DAG.getTargetFrameIndex(\n          FI->getIndex(), TLI.getFrameIndexTy(Builder.DAG.getDataLayout())));\n    } else\n      Ops.push_back(OpVal);\n  }\n}\n\n/// Lower llvm.experimental.stackmap directly to its target opcode.\nvoid SelectionDAGBuilder::visitStackmap(const CallInst &CI) {\n  // void @llvm.experimental.stackmap(i32 <id>, i32 <numShadowBytes>,\n  //                                  [live variables...])\n\n  assert(CI.getType()->isVoidTy() && \"Stackmap cannot return a value.\");\n\n  SDValue Chain, InFlag, Callee, NullPtr;\n  SmallVector<SDValue, 32> Ops;\n\n  SDLoc DL = getCurSDLoc();\n  Callee = getValue(CI.getCalledOperand());\n  NullPtr = DAG.getIntPtrConstant(0, DL, true);\n\n  // The stackmap intrinsic only records the live variables (the arguments\n  // passed to it) and emits NOPS (if requested). Unlike the patchpoint\n  // intrinsic, this won't be lowered to a function call. This means we don't\n  // have to worry about calling conventions and target specific lowering code.\n  // Instead we perform the call lowering right here.\n  //\n  // chain, flag = CALLSEQ_START(chain, 0, 0)\n  // chain, flag = STACKMAP(id, nbytes, ..., chain, flag)\n  // chain, flag = CALLSEQ_END(chain, 0, 0, flag)\n  //\n  Chain = DAG.getCALLSEQ_START(getRoot(), 0, 0, DL);\n  InFlag = Chain.getValue(1);\n\n  // Add the <id> and <numBytes> constants.\n  SDValue IDVal = getValue(CI.getOperand(PatchPointOpers::IDPos));\n  Ops.push_back(DAG.getTargetConstant(\n                  cast<ConstantSDNode>(IDVal)->getZExtValue(), DL, MVT::i64));\n  SDValue NBytesVal = getValue(CI.getOperand(PatchPointOpers::NBytesPos));\n  Ops.push_back(DAG.getTargetConstant(\n                  cast<ConstantSDNode>(NBytesVal)->getZExtValue(), DL,\n                  MVT::i32));\n\n  // Push live variables for the stack map.\n  addStackMapLiveVars(CI, 2, DL, Ops, *this);\n\n  // We are not pushing any register mask info here on the operands list,\n  // because the stackmap doesn't clobber anything.\n\n  // Push the chain and the glue flag.\n  Ops.push_back(Chain);\n  Ops.push_back(InFlag);\n\n  // Create the STACKMAP node.\n  SDVTList NodeTys = DAG.getVTList(MVT::Other, MVT::Glue);\n  SDNode *SM = DAG.getMachineNode(TargetOpcode::STACKMAP, DL, NodeTys, Ops);\n  Chain = SDValue(SM, 0);\n  InFlag = Chain.getValue(1);\n\n  Chain = DAG.getCALLSEQ_END(Chain, NullPtr, NullPtr, InFlag, DL);\n\n  // Stackmaps don't generate values, so nothing goes into the NodeMap.\n\n  // Set the root to the target-lowered call chain.\n  DAG.setRoot(Chain);\n\n  // Inform the Frame Information that we have a stackmap in this function.\n  FuncInfo.MF->getFrameInfo().setHasStackMap();\n}\n\n/// Lower llvm.experimental.patchpoint directly to its target opcode.\nvoid SelectionDAGBuilder::visitPatchpoint(const CallBase &CB,\n                                          const BasicBlock *EHPadBB) {\n  // void|i64 @llvm.experimental.patchpoint.void|i64(i64 <id>,\n  //                                                 i32 <numBytes>,\n  //                                                 i8* <target>,\n  //                                                 i32 <numArgs>,\n  //                                                 [Args...],\n  //                                                 [live variables...])\n\n  CallingConv::ID CC = CB.getCallingConv();\n  bool IsAnyRegCC = CC == CallingConv::AnyReg;\n  bool HasDef = !CB.getType()->isVoidTy();\n  SDLoc dl = getCurSDLoc();\n  SDValue Callee = getValue(CB.getArgOperand(PatchPointOpers::TargetPos));\n\n  // Handle immediate and symbolic callees.\n  if (auto* ConstCallee = dyn_cast<ConstantSDNode>(Callee))\n    Callee = DAG.getIntPtrConstant(ConstCallee->getZExtValue(), dl,\n                                   /*isTarget=*/true);\n  else if (auto* SymbolicCallee = dyn_cast<GlobalAddressSDNode>(Callee))\n    Callee =  DAG.getTargetGlobalAddress(SymbolicCallee->getGlobal(),\n                                         SDLoc(SymbolicCallee),\n                                         SymbolicCallee->getValueType(0));\n\n  // Get the real number of arguments participating in the call <numArgs>\n  SDValue NArgVal = getValue(CB.getArgOperand(PatchPointOpers::NArgPos));\n  unsigned NumArgs = cast<ConstantSDNode>(NArgVal)->getZExtValue();\n\n  // Skip the four meta args: <id>, <numNopBytes>, <target>, <numArgs>\n  // Intrinsics include all meta-operands up to but not including CC.\n  unsigned NumMetaOpers = PatchPointOpers::CCPos;\n  assert(CB.arg_size() >= NumMetaOpers + NumArgs &&\n         \"Not enough arguments provided to the patchpoint intrinsic\");\n\n  // For AnyRegCC the arguments are lowered later on manually.\n  unsigned NumCallArgs = IsAnyRegCC ? 0 : NumArgs;\n  Type *ReturnTy =\n      IsAnyRegCC ? Type::getVoidTy(*DAG.getContext()) : CB.getType();\n\n  TargetLowering::CallLoweringInfo CLI(DAG);\n  populateCallLoweringInfo(CLI, &CB, NumMetaOpers, NumCallArgs, Callee,\n                           ReturnTy, true);\n  std::pair<SDValue, SDValue> Result = lowerInvokable(CLI, EHPadBB);\n\n  SDNode *CallEnd = Result.second.getNode();\n  if (HasDef && (CallEnd->getOpcode() == ISD::CopyFromReg))\n    CallEnd = CallEnd->getOperand(0).getNode();\n\n  /// Get a call instruction from the call sequence chain.\n  /// Tail calls are not allowed.\n  assert(CallEnd->getOpcode() == ISD::CALLSEQ_END &&\n         \"Expected a callseq node.\");\n  SDNode *Call = CallEnd->getOperand(0).getNode();\n  bool HasGlue = Call->getGluedNode();\n\n  // Replace the target specific call node with the patchable intrinsic.\n  SmallVector<SDValue, 8> Ops;\n\n  // Add the <id> and <numBytes> constants.\n  SDValue IDVal = getValue(CB.getArgOperand(PatchPointOpers::IDPos));\n  Ops.push_back(DAG.getTargetConstant(\n                  cast<ConstantSDNode>(IDVal)->getZExtValue(), dl, MVT::i64));\n  SDValue NBytesVal = getValue(CB.getArgOperand(PatchPointOpers::NBytesPos));\n  Ops.push_back(DAG.getTargetConstant(\n                  cast<ConstantSDNode>(NBytesVal)->getZExtValue(), dl,\n                  MVT::i32));\n\n  // Add the callee.\n  Ops.push_back(Callee);\n\n  // Adjust <numArgs> to account for any arguments that have been passed on the\n  // stack instead.\n  // Call Node: Chain, Target, {Args}, RegMask, [Glue]\n  unsigned NumCallRegArgs = Call->getNumOperands() - (HasGlue ? 4 : 3);\n  NumCallRegArgs = IsAnyRegCC ? NumArgs : NumCallRegArgs;\n  Ops.push_back(DAG.getTargetConstant(NumCallRegArgs, dl, MVT::i32));\n\n  // Add the calling convention\n  Ops.push_back(DAG.getTargetConstant((unsigned)CC, dl, MVT::i32));\n\n  // Add the arguments we omitted previously. The register allocator should\n  // place these in any free register.\n  if (IsAnyRegCC)\n    for (unsigned i = NumMetaOpers, e = NumMetaOpers + NumArgs; i != e; ++i)\n      Ops.push_back(getValue(CB.getArgOperand(i)));\n\n  // Push the arguments from the call instruction up to the register mask.\n  SDNode::op_iterator e = HasGlue ? Call->op_end()-2 : Call->op_end()-1;\n  Ops.append(Call->op_begin() + 2, e);\n\n  // Push live variables for the stack map.\n  addStackMapLiveVars(CB, NumMetaOpers + NumArgs, dl, Ops, *this);\n\n  // Push the register mask info.\n  if (HasGlue)\n    Ops.push_back(*(Call->op_end()-2));\n  else\n    Ops.push_back(*(Call->op_end()-1));\n\n  // Push the chain (this is originally the first operand of the call, but\n  // becomes now the last or second to last operand).\n  Ops.push_back(*(Call->op_begin()));\n\n  // Push the glue flag (last operand).\n  if (HasGlue)\n    Ops.push_back(*(Call->op_end()-1));\n\n  SDVTList NodeTys;\n  if (IsAnyRegCC && HasDef) {\n    // Create the return types based on the intrinsic definition\n    const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n    SmallVector<EVT, 3> ValueVTs;\n    ComputeValueVTs(TLI, DAG.getDataLayout(), CB.getType(), ValueVTs);\n    assert(ValueVTs.size() == 1 && \"Expected only one return value type.\");\n\n    // There is always a chain and a glue type at the end\n    ValueVTs.push_back(MVT::Other);\n    ValueVTs.push_back(MVT::Glue);\n    NodeTys = DAG.getVTList(ValueVTs);\n  } else\n    NodeTys = DAG.getVTList(MVT::Other, MVT::Glue);\n\n  // Replace the target specific call node with a PATCHPOINT node.\n  MachineSDNode *MN = DAG.getMachineNode(TargetOpcode::PATCHPOINT,\n                                         dl, NodeTys, Ops);\n\n  // Update the NodeMap.\n  if (HasDef) {\n    if (IsAnyRegCC)\n      setValue(&CB, SDValue(MN, 0));\n    else\n      setValue(&CB, Result.first);\n  }\n\n  // Fixup the consumers of the intrinsic. The chain and glue may be used in the\n  // call sequence. Furthermore the location of the chain and glue can change\n  // when the AnyReg calling convention is used and the intrinsic returns a\n  // value.\n  if (IsAnyRegCC && HasDef) {\n    SDValue From[] = {SDValue(Call, 0), SDValue(Call, 1)};\n    SDValue To[] = {SDValue(MN, 1), SDValue(MN, 2)};\n    DAG.ReplaceAllUsesOfValuesWith(From, To, 2);\n  } else\n    DAG.ReplaceAllUsesWith(Call, MN);\n  DAG.DeleteNode(Call);\n\n  // Inform the Frame Information that we have a patchpoint in this function.\n  FuncInfo.MF->getFrameInfo().setHasPatchPoint();\n}\n\nvoid SelectionDAGBuilder::visitVectorReduce(const CallInst &I,\n                                            unsigned Intrinsic) {\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  SDValue Op1 = getValue(I.getArgOperand(0));\n  SDValue Op2;\n  if (I.getNumArgOperands() > 1)\n    Op2 = getValue(I.getArgOperand(1));\n  SDLoc dl = getCurSDLoc();\n  EVT VT = TLI.getValueType(DAG.getDataLayout(), I.getType());\n  SDValue Res;\n  SDNodeFlags SDFlags;\n  if (auto *FPMO = dyn_cast<FPMathOperator>(&I))\n    SDFlags.copyFMF(*FPMO);\n\n  switch (Intrinsic) {\n  case Intrinsic::vector_reduce_fadd:\n    if (SDFlags.hasAllowReassociation())\n      Res = DAG.getNode(ISD::FADD, dl, VT, Op1,\n                        DAG.getNode(ISD::VECREDUCE_FADD, dl, VT, Op2, SDFlags),\n                        SDFlags);\n    else\n      Res = DAG.getNode(ISD::VECREDUCE_SEQ_FADD, dl, VT, Op1, Op2, SDFlags);\n    break;\n  case Intrinsic::vector_reduce_fmul:\n    if (SDFlags.hasAllowReassociation())\n      Res = DAG.getNode(ISD::FMUL, dl, VT, Op1,\n                        DAG.getNode(ISD::VECREDUCE_FMUL, dl, VT, Op2, SDFlags),\n                        SDFlags);\n    else\n      Res = DAG.getNode(ISD::VECREDUCE_SEQ_FMUL, dl, VT, Op1, Op2, SDFlags);\n    break;\n  case Intrinsic::vector_reduce_add:\n    Res = DAG.getNode(ISD::VECREDUCE_ADD, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_mul:\n    Res = DAG.getNode(ISD::VECREDUCE_MUL, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_and:\n    Res = DAG.getNode(ISD::VECREDUCE_AND, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_or:\n    Res = DAG.getNode(ISD::VECREDUCE_OR, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_xor:\n    Res = DAG.getNode(ISD::VECREDUCE_XOR, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_smax:\n    Res = DAG.getNode(ISD::VECREDUCE_SMAX, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_smin:\n    Res = DAG.getNode(ISD::VECREDUCE_SMIN, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_umax:\n    Res = DAG.getNode(ISD::VECREDUCE_UMAX, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_umin:\n    Res = DAG.getNode(ISD::VECREDUCE_UMIN, dl, VT, Op1);\n    break;\n  case Intrinsic::vector_reduce_fmax:\n    Res = DAG.getNode(ISD::VECREDUCE_FMAX, dl, VT, Op1, SDFlags);\n    break;\n  case Intrinsic::vector_reduce_fmin:\n    Res = DAG.getNode(ISD::VECREDUCE_FMIN, dl, VT, Op1, SDFlags);\n    break;\n  default:\n    llvm_unreachable(\"Unhandled vector reduce intrinsic\");\n  }\n  setValue(&I, Res);\n}\n\n/// Returns an AttributeList representing the attributes applied to the return\n/// value of the given call.\nstatic AttributeList getReturnAttrs(TargetLowering::CallLoweringInfo &CLI) {\n  SmallVector<Attribute::AttrKind, 2> Attrs;\n  if (CLI.RetSExt)\n    Attrs.push_back(Attribute::SExt);\n  if (CLI.RetZExt)\n    Attrs.push_back(Attribute::ZExt);\n  if (CLI.IsInReg)\n    Attrs.push_back(Attribute::InReg);\n\n  return AttributeList::get(CLI.RetTy->getContext(), AttributeList::ReturnIndex,\n                            Attrs);\n}\n\n/// TargetLowering::LowerCallTo - This is the default LowerCallTo\n/// implementation, which just calls LowerCall.\n/// FIXME: When all targets are\n/// migrated to using LowerCall, this hook should be integrated into SDISel.\nstd::pair<SDValue, SDValue>\nTargetLowering::LowerCallTo(TargetLowering::CallLoweringInfo &CLI) const {\n  // Handle the incoming return values from the call.\n  CLI.Ins.clear();\n  Type *OrigRetTy = CLI.RetTy;\n  SmallVector<EVT, 4> RetTys;\n  SmallVector<uint64_t, 4> Offsets;\n  auto &DL = CLI.DAG.getDataLayout();\n  ComputeValueVTs(*this, DL, CLI.RetTy, RetTys, &Offsets);\n\n  if (CLI.IsPostTypeLegalization) {\n    // If we are lowering a libcall after legalization, split the return type.\n    SmallVector<EVT, 4> OldRetTys;\n    SmallVector<uint64_t, 4> OldOffsets;\n    RetTys.swap(OldRetTys);\n    Offsets.swap(OldOffsets);\n\n    for (size_t i = 0, e = OldRetTys.size(); i != e; ++i) {\n      EVT RetVT = OldRetTys[i];\n      uint64_t Offset = OldOffsets[i];\n      MVT RegisterVT = getRegisterType(CLI.RetTy->getContext(), RetVT);\n      unsigned NumRegs = getNumRegisters(CLI.RetTy->getContext(), RetVT);\n      unsigned RegisterVTByteSZ = RegisterVT.getSizeInBits() / 8;\n      RetTys.append(NumRegs, RegisterVT);\n      for (unsigned j = 0; j != NumRegs; ++j)\n        Offsets.push_back(Offset + j * RegisterVTByteSZ);\n    }\n  }\n\n  SmallVector<ISD::OutputArg, 4> Outs;\n  GetReturnInfo(CLI.CallConv, CLI.RetTy, getReturnAttrs(CLI), Outs, *this, DL);\n\n  bool CanLowerReturn =\n      this->CanLowerReturn(CLI.CallConv, CLI.DAG.getMachineFunction(),\n                           CLI.IsVarArg, Outs, CLI.RetTy->getContext());\n\n  SDValue DemoteStackSlot;\n  int DemoteStackIdx = -100;\n  if (!CanLowerReturn) {\n    // FIXME: equivalent assert?\n    // assert(!CS.hasInAllocaArgument() &&\n    //        \"sret demotion is incompatible with inalloca\");\n    uint64_t TySize = DL.getTypeAllocSize(CLI.RetTy);\n    Align Alignment = DL.getPrefTypeAlign(CLI.RetTy);\n    MachineFunction &MF = CLI.DAG.getMachineFunction();\n    DemoteStackIdx =\n        MF.getFrameInfo().CreateStackObject(TySize, Alignment, false);\n    Type *StackSlotPtrType = PointerType::get(CLI.RetTy,\n                                              DL.getAllocaAddrSpace());\n\n    DemoteStackSlot = CLI.DAG.getFrameIndex(DemoteStackIdx, getFrameIndexTy(DL));\n    ArgListEntry Entry;\n    Entry.Node = DemoteStackSlot;\n    Entry.Ty = StackSlotPtrType;\n    Entry.IsSExt = false;\n    Entry.IsZExt = false;\n    Entry.IsInReg = false;\n    Entry.IsSRet = true;\n    Entry.IsNest = false;\n    Entry.IsByVal = false;\n    Entry.IsByRef = false;\n    Entry.IsReturned = false;\n    Entry.IsSwiftSelf = false;\n    Entry.IsSwiftError = false;\n    Entry.IsCFGuardTarget = false;\n    Entry.Alignment = Alignment;\n    CLI.getArgs().insert(CLI.getArgs().begin(), Entry);\n    CLI.NumFixedArgs += 1;\n    CLI.RetTy = Type::getVoidTy(CLI.RetTy->getContext());\n\n    // sret demotion isn't compatible with tail-calls, since the sret argument\n    // points into the callers stack frame.\n    CLI.IsTailCall = false;\n  } else {\n    bool NeedsRegBlock = functionArgumentNeedsConsecutiveRegisters(\n        CLI.RetTy, CLI.CallConv, CLI.IsVarArg);\n    for (unsigned I = 0, E = RetTys.size(); I != E; ++I) {\n      ISD::ArgFlagsTy Flags;\n      if (NeedsRegBlock) {\n        Flags.setInConsecutiveRegs();\n        if (I == RetTys.size() - 1)\n          Flags.setInConsecutiveRegsLast();\n      }\n      EVT VT = RetTys[I];\n      MVT RegisterVT = getRegisterTypeForCallingConv(CLI.RetTy->getContext(),\n                                                     CLI.CallConv, VT);\n      unsigned NumRegs = getNumRegistersForCallingConv(CLI.RetTy->getContext(),\n                                                       CLI.CallConv, VT);\n      for (unsigned i = 0; i != NumRegs; ++i) {\n        ISD::InputArg MyFlags;\n        MyFlags.Flags = Flags;\n        MyFlags.VT = RegisterVT;\n        MyFlags.ArgVT = VT;\n        MyFlags.Used = CLI.IsReturnValueUsed;\n        if (CLI.RetTy->isPointerTy()) {\n          MyFlags.Flags.setPointer();\n          MyFlags.Flags.setPointerAddrSpace(\n              cast<PointerType>(CLI.RetTy)->getAddressSpace());\n        }\n        if (CLI.RetSExt)\n          MyFlags.Flags.setSExt();\n        if (CLI.RetZExt)\n          MyFlags.Flags.setZExt();\n        if (CLI.IsInReg)\n          MyFlags.Flags.setInReg();\n        CLI.Ins.push_back(MyFlags);\n      }\n    }\n  }\n\n  // We push in swifterror return as the last element of CLI.Ins.\n  ArgListTy &Args = CLI.getArgs();\n  if (supportSwiftError()) {\n    for (unsigned i = 0, e = Args.size(); i != e; ++i) {\n      if (Args[i].IsSwiftError) {\n        ISD::InputArg MyFlags;\n        MyFlags.VT = getPointerTy(DL);\n        MyFlags.ArgVT = EVT(getPointerTy(DL));\n        MyFlags.Flags.setSwiftError();\n        CLI.Ins.push_back(MyFlags);\n      }\n    }\n  }\n\n  // Handle all of the outgoing arguments.\n  CLI.Outs.clear();\n  CLI.OutVals.clear();\n  for (unsigned i = 0, e = Args.size(); i != e; ++i) {\n    SmallVector<EVT, 4> ValueVTs;\n    ComputeValueVTs(*this, DL, Args[i].Ty, ValueVTs);\n    // FIXME: Split arguments if CLI.IsPostTypeLegalization\n    Type *FinalType = Args[i].Ty;\n    if (Args[i].IsByVal)\n      FinalType = cast<PointerType>(Args[i].Ty)->getElementType();\n    bool NeedsRegBlock = functionArgumentNeedsConsecutiveRegisters(\n        FinalType, CLI.CallConv, CLI.IsVarArg);\n    for (unsigned Value = 0, NumValues = ValueVTs.size(); Value != NumValues;\n         ++Value) {\n      EVT VT = ValueVTs[Value];\n      Type *ArgTy = VT.getTypeForEVT(CLI.RetTy->getContext());\n      SDValue Op = SDValue(Args[i].Node.getNode(),\n                           Args[i].Node.getResNo() + Value);\n      ISD::ArgFlagsTy Flags;\n\n      // Certain targets (such as MIPS), may have a different ABI alignment\n      // for a type depending on the context. Give the target a chance to\n      // specify the alignment it wants.\n      const Align OriginalAlignment(getABIAlignmentForCallingConv(ArgTy, DL));\n\n      if (Args[i].Ty->isPointerTy()) {\n        Flags.setPointer();\n        Flags.setPointerAddrSpace(\n            cast<PointerType>(Args[i].Ty)->getAddressSpace());\n      }\n      if (Args[i].IsZExt)\n        Flags.setZExt();\n      if (Args[i].IsSExt)\n        Flags.setSExt();\n      if (Args[i].IsInReg) {\n        // If we are using vectorcall calling convention, a structure that is\n        // passed InReg - is surely an HVA\n        if (CLI.CallConv == CallingConv::X86_VectorCall &&\n            isa<StructType>(FinalType)) {\n          // The first value of a structure is marked\n          if (0 == Value)\n            Flags.setHvaStart();\n          Flags.setHva();\n        }\n        // Set InReg Flag\n        Flags.setInReg();\n      }\n      if (Args[i].IsSRet)\n        Flags.setSRet();\n      if (Args[i].IsSwiftSelf)\n        Flags.setSwiftSelf();\n      if (Args[i].IsSwiftError)\n        Flags.setSwiftError();\n      if (Args[i].IsCFGuardTarget)\n        Flags.setCFGuardTarget();\n      if (Args[i].IsByVal)\n        Flags.setByVal();\n      if (Args[i].IsByRef)\n        Flags.setByRef();\n      if (Args[i].IsPreallocated) {\n        Flags.setPreallocated();\n        // Set the byval flag for CCAssignFn callbacks that don't know about\n        // preallocated.  This way we can know how many bytes we should've\n        // allocated and how many bytes a callee cleanup function will pop.  If\n        // we port preallocated to more targets, we'll have to add custom\n        // preallocated handling in the various CC lowering callbacks.\n        Flags.setByVal();\n      }\n      if (Args[i].IsInAlloca) {\n        Flags.setInAlloca();\n        // Set the byval flag for CCAssignFn callbacks that don't know about\n        // inalloca.  This way we can know how many bytes we should've allocated\n        // and how many bytes a callee cleanup function will pop.  If we port\n        // inalloca to more targets, we'll have to add custom inalloca handling\n        // in the various CC lowering callbacks.\n        Flags.setByVal();\n      }\n      if (Args[i].IsByVal || Args[i].IsInAlloca || Args[i].IsPreallocated) {\n        PointerType *Ty = cast<PointerType>(Args[i].Ty);\n        Type *ElementTy = Ty->getElementType();\n\n        unsigned FrameSize = DL.getTypeAllocSize(\n            Args[i].ByValType ? Args[i].ByValType : ElementTy);\n        Flags.setByValSize(FrameSize);\n\n        // info is not there but there are cases it cannot get right.\n        Align FrameAlign;\n        if (auto MA = Args[i].Alignment)\n          FrameAlign = *MA;\n        else\n          FrameAlign = Align(getByValTypeAlignment(ElementTy, DL));\n        Flags.setByValAlign(FrameAlign);\n      }\n      if (Args[i].IsNest)\n        Flags.setNest();\n      if (NeedsRegBlock)\n        Flags.setInConsecutiveRegs();\n      Flags.setOrigAlign(OriginalAlignment);\n\n      MVT PartVT = getRegisterTypeForCallingConv(CLI.RetTy->getContext(),\n                                                 CLI.CallConv, VT);\n      unsigned NumParts = getNumRegistersForCallingConv(CLI.RetTy->getContext(),\n                                                        CLI.CallConv, VT);\n      SmallVector<SDValue, 4> Parts(NumParts);\n      ISD::NodeType ExtendKind = ISD::ANY_EXTEND;\n\n      if (Args[i].IsSExt)\n        ExtendKind = ISD::SIGN_EXTEND;\n      else if (Args[i].IsZExt)\n        ExtendKind = ISD::ZERO_EXTEND;\n\n      // Conservatively only handle 'returned' on non-vectors that can be lowered,\n      // for now.\n      if (Args[i].IsReturned && !Op.getValueType().isVector() &&\n          CanLowerReturn) {\n        assert((CLI.RetTy == Args[i].Ty ||\n                (CLI.RetTy->isPointerTy() && Args[i].Ty->isPointerTy() &&\n                 CLI.RetTy->getPointerAddressSpace() ==\n                     Args[i].Ty->getPointerAddressSpace())) &&\n               RetTys.size() == NumValues && \"unexpected use of 'returned'\");\n        // Before passing 'returned' to the target lowering code, ensure that\n        // either the register MVT and the actual EVT are the same size or that\n        // the return value and argument are extended in the same way; in these\n        // cases it's safe to pass the argument register value unchanged as the\n        // return register value (although it's at the target's option whether\n        // to do so)\n        // TODO: allow code generation to take advantage of partially preserved\n        // registers rather than clobbering the entire register when the\n        // parameter extension method is not compatible with the return\n        // extension method\n        if ((NumParts * PartVT.getSizeInBits() == VT.getSizeInBits()) ||\n            (ExtendKind != ISD::ANY_EXTEND && CLI.RetSExt == Args[i].IsSExt &&\n             CLI.RetZExt == Args[i].IsZExt))\n          Flags.setReturned();\n      }\n\n      getCopyToParts(CLI.DAG, CLI.DL, Op, &Parts[0], NumParts, PartVT, CLI.CB,\n                     CLI.CallConv, ExtendKind);\n\n      for (unsigned j = 0; j != NumParts; ++j) {\n        // if it isn't first piece, alignment must be 1\n        // For scalable vectors the scalable part is currently handled\n        // by individual targets, so we just use the known minimum size here.\n        ISD::OutputArg MyFlags(Flags, Parts[j].getValueType(), VT,\n                    i < CLI.NumFixedArgs, i,\n                    j*Parts[j].getValueType().getStoreSize().getKnownMinSize());\n        if (NumParts > 1 && j == 0)\n          MyFlags.Flags.setSplit();\n        else if (j != 0) {\n          MyFlags.Flags.setOrigAlign(Align(1));\n          if (j == NumParts - 1)\n            MyFlags.Flags.setSplitEnd();\n        }\n\n        CLI.Outs.push_back(MyFlags);\n        CLI.OutVals.push_back(Parts[j]);\n      }\n\n      if (NeedsRegBlock && Value == NumValues - 1)\n        CLI.Outs[CLI.Outs.size() - 1].Flags.setInConsecutiveRegsLast();\n    }\n  }\n\n  SmallVector<SDValue, 4> InVals;\n  CLI.Chain = LowerCall(CLI, InVals);\n\n  // Update CLI.InVals to use outside of this function.\n  CLI.InVals = InVals;\n\n  // Verify that the target's LowerCall behaved as expected.\n  assert(CLI.Chain.getNode() && CLI.Chain.getValueType() == MVT::Other &&\n         \"LowerCall didn't return a valid chain!\");\n  assert((!CLI.IsTailCall || InVals.empty()) &&\n         \"LowerCall emitted a return value for a tail call!\");\n  assert((CLI.IsTailCall || InVals.size() == CLI.Ins.size()) &&\n         \"LowerCall didn't emit the correct number of values!\");\n\n  // For a tail call, the return value is merely live-out and there aren't\n  // any nodes in the DAG representing it. Return a special value to\n  // indicate that a tail call has been emitted and no more Instructions\n  // should be processed in the current block.\n  if (CLI.IsTailCall) {\n    CLI.DAG.setRoot(CLI.Chain);\n    return std::make_pair(SDValue(), SDValue());\n  }\n\n#ifndef NDEBUG\n  for (unsigned i = 0, e = CLI.Ins.size(); i != e; ++i) {\n    assert(InVals[i].getNode() && \"LowerCall emitted a null value!\");\n    assert(EVT(CLI.Ins[i].VT) == InVals[i].getValueType() &&\n           \"LowerCall emitted a value with the wrong type!\");\n  }\n#endif\n\n  SmallVector<SDValue, 4> ReturnValues;\n  if (!CanLowerReturn) {\n    // The instruction result is the result of loading from the\n    // hidden sret parameter.\n    SmallVector<EVT, 1> PVTs;\n    Type *PtrRetTy = OrigRetTy->getPointerTo(DL.getAllocaAddrSpace());\n\n    ComputeValueVTs(*this, DL, PtrRetTy, PVTs);\n    assert(PVTs.size() == 1 && \"Pointers should fit in one register\");\n    EVT PtrVT = PVTs[0];\n\n    unsigned NumValues = RetTys.size();\n    ReturnValues.resize(NumValues);\n    SmallVector<SDValue, 4> Chains(NumValues);\n\n    // An aggregate return value cannot wrap around the address space, so\n    // offsets to its parts don't wrap either.\n    SDNodeFlags Flags;\n    Flags.setNoUnsignedWrap(true);\n\n    MachineFunction &MF = CLI.DAG.getMachineFunction();\n    Align HiddenSRetAlign = MF.getFrameInfo().getObjectAlign(DemoteStackIdx);\n    for (unsigned i = 0; i < NumValues; ++i) {\n      SDValue Add = CLI.DAG.getNode(ISD::ADD, CLI.DL, PtrVT, DemoteStackSlot,\n                                    CLI.DAG.getConstant(Offsets[i], CLI.DL,\n                                                        PtrVT), Flags);\n      SDValue L = CLI.DAG.getLoad(\n          RetTys[i], CLI.DL, CLI.Chain, Add,\n          MachinePointerInfo::getFixedStack(CLI.DAG.getMachineFunction(),\n                                            DemoteStackIdx, Offsets[i]),\n          HiddenSRetAlign);\n      ReturnValues[i] = L;\n      Chains[i] = L.getValue(1);\n    }\n\n    CLI.Chain = CLI.DAG.getNode(ISD::TokenFactor, CLI.DL, MVT::Other, Chains);\n  } else {\n    // Collect the legal value parts into potentially illegal values\n    // that correspond to the original function's return values.\n    Optional<ISD::NodeType> AssertOp;\n    if (CLI.RetSExt)\n      AssertOp = ISD::AssertSext;\n    else if (CLI.RetZExt)\n      AssertOp = ISD::AssertZext;\n    unsigned CurReg = 0;\n    for (unsigned I = 0, E = RetTys.size(); I != E; ++I) {\n      EVT VT = RetTys[I];\n      MVT RegisterVT = getRegisterTypeForCallingConv(CLI.RetTy->getContext(),\n                                                     CLI.CallConv, VT);\n      unsigned NumRegs = getNumRegistersForCallingConv(CLI.RetTy->getContext(),\n                                                       CLI.CallConv, VT);\n\n      ReturnValues.push_back(getCopyFromParts(CLI.DAG, CLI.DL, &InVals[CurReg],\n                                              NumRegs, RegisterVT, VT, nullptr,\n                                              CLI.CallConv, AssertOp));\n      CurReg += NumRegs;\n    }\n\n    // For a function returning void, there is no return value. We can't create\n    // such a node, so we just return a null return value in that case. In\n    // that case, nothing will actually look at the value.\n    if (ReturnValues.empty())\n      return std::make_pair(SDValue(), CLI.Chain);\n  }\n\n  SDValue Res = CLI.DAG.getNode(ISD::MERGE_VALUES, CLI.DL,\n                                CLI.DAG.getVTList(RetTys), ReturnValues);\n  return std::make_pair(Res, CLI.Chain);\n}\n\n/// Places new result values for the node in Results (their number\n/// and types must exactly match those of the original return values of\n/// the node), or leaves Results empty, which indicates that the node is not\n/// to be custom lowered after all.\nvoid TargetLowering::LowerOperationWrapper(SDNode *N,\n                                           SmallVectorImpl<SDValue> &Results,\n                                           SelectionDAG &DAG) const {\n  SDValue Res = LowerOperation(SDValue(N, 0), DAG);\n\n  if (!Res.getNode())\n    return;\n\n  // If the original node has one result, take the return value from\n  // LowerOperation as is. It might not be result number 0.\n  if (N->getNumValues() == 1) {\n    Results.push_back(Res);\n    return;\n  }\n\n  // If the original node has multiple results, then the return node should\n  // have the same number of results.\n  assert((N->getNumValues() == Res->getNumValues()) &&\n      \"Lowering returned the wrong number of results!\");\n\n  // Places new result values base on N result number.\n  for (unsigned I = 0, E = N->getNumValues(); I != E; ++I)\n    Results.push_back(Res.getValue(I));\n}\n\nSDValue TargetLowering::LowerOperation(SDValue Op, SelectionDAG &DAG) const {\n  llvm_unreachable(\"LowerOperation not implemented for this target!\");\n}\n\nvoid\nSelectionDAGBuilder::CopyValueToVirtualRegister(const Value *V, unsigned Reg) {\n  SDValue Op = getNonRegisterValue(V);\n  assert((Op.getOpcode() != ISD::CopyFromReg ||\n          cast<RegisterSDNode>(Op.getOperand(1))->getReg() != Reg) &&\n         \"Copy from a reg to the same reg!\");\n  assert(!Register::isPhysicalRegister(Reg) && \"Is a physreg\");\n\n  const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n  // If this is an InlineAsm we have to match the registers required, not the\n  // notional registers required by the type.\n\n  RegsForValue RFV(V->getContext(), TLI, DAG.getDataLayout(), Reg, V->getType(),\n                   None); // This is not an ABI copy.\n  SDValue Chain = DAG.getEntryNode();\n\n  ISD::NodeType ExtendType = (FuncInfo.PreferredExtendType.find(V) ==\n                              FuncInfo.PreferredExtendType.end())\n                                 ? ISD::ANY_EXTEND\n                                 : FuncInfo.PreferredExtendType[V];\n  RFV.getCopyToRegs(Op, DAG, getCurSDLoc(), Chain, nullptr, V, ExtendType);\n  PendingExports.push_back(Chain);\n}\n\n#include \"llvm/CodeGen/SelectionDAGISel.h\"\n\n/// isOnlyUsedInEntryBlock - If the specified argument is only used in the\n/// entry block, return true.  This includes arguments used by switches, since\n/// the switch may expand into multiple basic blocks.\nstatic bool isOnlyUsedInEntryBlock(const Argument *A, bool FastISel) {\n  // With FastISel active, we may be splitting blocks, so force creation\n  // of virtual registers for all non-dead arguments.\n  if (FastISel)\n    return A->use_empty();\n\n  const BasicBlock &Entry = A->getParent()->front();\n  for (const User *U : A->users())\n    if (cast<Instruction>(U)->getParent() != &Entry || isa<SwitchInst>(U))\n      return false;  // Use not in entry block.\n\n  return true;\n}\n\nusing ArgCopyElisionMapTy =\n    DenseMap<const Argument *,\n             std::pair<const AllocaInst *, const StoreInst *>>;\n\n/// Scan the entry block of the function in FuncInfo for arguments that look\n/// like copies into a local alloca. Record any copied arguments in\n/// ArgCopyElisionCandidates.\nstatic void\nfindArgumentCopyElisionCandidates(const DataLayout &DL,\n                                  FunctionLoweringInfo *FuncInfo,\n                                  ArgCopyElisionMapTy &ArgCopyElisionCandidates) {\n  // Record the state of every static alloca used in the entry block. Argument\n  // allocas are all used in the entry block, so we need approximately as many\n  // entries as we have arguments.\n  enum StaticAllocaInfo { Unknown, Clobbered, Elidable };\n  SmallDenseMap<const AllocaInst *, StaticAllocaInfo, 8> StaticAllocas;\n  unsigned NumArgs = FuncInfo->Fn->arg_size();\n  StaticAllocas.reserve(NumArgs * 2);\n\n  auto GetInfoIfStaticAlloca = [&](const Value *V) -> StaticAllocaInfo * {\n    if (!V)\n      return nullptr;\n    V = V->stripPointerCasts();\n    const auto *AI = dyn_cast<AllocaInst>(V);\n    if (!AI || !AI->isStaticAlloca() || !FuncInfo->StaticAllocaMap.count(AI))\n      return nullptr;\n    auto Iter = StaticAllocas.insert({AI, Unknown});\n    return &Iter.first->second;\n  };\n\n  // Look for stores of arguments to static allocas. Look through bitcasts and\n  // GEPs to handle type coercions, as long as the alloca is fully initialized\n  // by the store. Any non-store use of an alloca escapes it and any subsequent\n  // unanalyzed store might write it.\n  // FIXME: Handle structs initialized with multiple stores.\n  for (const Instruction &I : FuncInfo->Fn->getEntryBlock()) {\n    // Look for stores, and handle non-store uses conservatively.\n    const auto *SI = dyn_cast<StoreInst>(&I);\n    if (!SI) {\n      // We will look through cast uses, so ignore them completely.\n      if (I.isCast())\n        continue;\n      // Ignore debug info intrinsics, they don't escape or store to allocas.\n      if (isa<DbgInfoIntrinsic>(I))\n        continue;\n      // This is an unknown instruction. Assume it escapes or writes to all\n      // static alloca operands.\n      for (const Use &U : I.operands()) {\n        if (StaticAllocaInfo *Info = GetInfoIfStaticAlloca(U))\n          *Info = StaticAllocaInfo::Clobbered;\n      }\n      continue;\n    }\n\n    // If the stored value is a static alloca, mark it as escaped.\n    if (StaticAllocaInfo *Info = GetInfoIfStaticAlloca(SI->getValueOperand()))\n      *Info = StaticAllocaInfo::Clobbered;\n\n    // Check if the destination is a static alloca.\n    const Value *Dst = SI->getPointerOperand()->stripPointerCasts();\n    StaticAllocaInfo *Info = GetInfoIfStaticAlloca(Dst);\n    if (!Info)\n      continue;\n    const AllocaInst *AI = cast<AllocaInst>(Dst);\n\n    // Skip allocas that have been initialized or clobbered.\n    if (*Info != StaticAllocaInfo::Unknown)\n      continue;\n\n    // Check if the stored value is an argument, and that this store fully\n    // initializes the alloca. Don't elide copies from the same argument twice.\n    const Value *Val = SI->getValueOperand()->stripPointerCasts();\n    const auto *Arg = dyn_cast<Argument>(Val);\n    if (!Arg || Arg->hasPassPointeeByValueCopyAttr() ||\n        Arg->getType()->isEmptyTy() ||\n        DL.getTypeStoreSize(Arg->getType()) !=\n            DL.getTypeAllocSize(AI->getAllocatedType()) ||\n        ArgCopyElisionCandidates.count(Arg)) {\n      *Info = StaticAllocaInfo::Clobbered;\n      continue;\n    }\n\n    LLVM_DEBUG(dbgs() << \"Found argument copy elision candidate: \" << *AI\n                      << '\\n');\n\n    // Mark this alloca and store for argument copy elision.\n    *Info = StaticAllocaInfo::Elidable;\n    ArgCopyElisionCandidates.insert({Arg, {AI, SI}});\n\n    // Stop scanning if we've seen all arguments. This will happen early in -O0\n    // builds, which is useful, because -O0 builds have large entry blocks and\n    // many allocas.\n    if (ArgCopyElisionCandidates.size() == NumArgs)\n      break;\n  }\n}\n\n/// Try to elide argument copies from memory into a local alloca. Succeeds if\n/// ArgVal is a load from a suitable fixed stack object.\nstatic void tryToElideArgumentCopy(\n    FunctionLoweringInfo &FuncInfo, SmallVectorImpl<SDValue> &Chains,\n    DenseMap<int, int> &ArgCopyElisionFrameIndexMap,\n    SmallPtrSetImpl<const Instruction *> &ElidedArgCopyInstrs,\n    ArgCopyElisionMapTy &ArgCopyElisionCandidates, const Argument &Arg,\n    SDValue ArgVal, bool &ArgHasUses) {\n  // Check if this is a load from a fixed stack object.\n  auto *LNode = dyn_cast<LoadSDNode>(ArgVal);\n  if (!LNode)\n    return;\n  auto *FINode = dyn_cast<FrameIndexSDNode>(LNode->getBasePtr().getNode());\n  if (!FINode)\n    return;\n\n  // Check that the fixed stack object is the right size and alignment.\n  // Look at the alignment that the user wrote on the alloca instead of looking\n  // at the stack object.\n  auto ArgCopyIter = ArgCopyElisionCandidates.find(&Arg);\n  assert(ArgCopyIter != ArgCopyElisionCandidates.end());\n  const AllocaInst *AI = ArgCopyIter->second.first;\n  int FixedIndex = FINode->getIndex();\n  int &AllocaIndex = FuncInfo.StaticAllocaMap[AI];\n  int OldIndex = AllocaIndex;\n  MachineFrameInfo &MFI = FuncInfo.MF->getFrameInfo();\n  if (MFI.getObjectSize(FixedIndex) != MFI.getObjectSize(OldIndex)) {\n    LLVM_DEBUG(\n        dbgs() << \"  argument copy elision failed due to bad fixed stack \"\n                  \"object size\\n\");\n    return;\n  }\n  Align RequiredAlignment = AI->getAlign();\n  if (MFI.getObjectAlign(FixedIndex) < RequiredAlignment) {\n    LLVM_DEBUG(dbgs() << \"  argument copy elision failed: alignment of alloca \"\n                         \"greater than stack argument alignment (\"\n                      << DebugStr(RequiredAlignment) << \" vs \"\n                      << DebugStr(MFI.getObjectAlign(FixedIndex)) << \")\\n\");\n    return;\n  }\n\n  // Perform the elision. Delete the old stack object and replace its only use\n  // in the variable info map. Mark the stack object as mutable.\n  LLVM_DEBUG({\n    dbgs() << \"Eliding argument copy from \" << Arg << \" to \" << *AI << '\\n'\n           << \"  Replacing frame index \" << OldIndex << \" with \" << FixedIndex\n           << '\\n';\n  });\n  MFI.RemoveStackObject(OldIndex);\n  MFI.setIsImmutableObjectIndex(FixedIndex, false);\n  AllocaIndex = FixedIndex;\n  ArgCopyElisionFrameIndexMap.insert({OldIndex, FixedIndex});\n  Chains.push_back(ArgVal.getValue(1));\n\n  // Avoid emitting code for the store implementing the copy.\n  const StoreInst *SI = ArgCopyIter->second.second;\n  ElidedArgCopyInstrs.insert(SI);\n\n  // Check for uses of the argument again so that we can avoid exporting ArgVal\n  // if it is't used by anything other than the store.\n  for (const Value *U : Arg.users()) {\n    if (U != SI) {\n      ArgHasUses = true;\n      break;\n    }\n  }\n}\n\nvoid SelectionDAGISel::LowerArguments(const Function &F) {\n  SelectionDAG &DAG = SDB->DAG;\n  SDLoc dl = SDB->getCurSDLoc();\n  const DataLayout &DL = DAG.getDataLayout();\n  SmallVector<ISD::InputArg, 16> Ins;\n\n  // In Naked functions we aren't going to save any registers.\n  if (F.hasFnAttribute(Attribute::Naked))\n    return;\n\n  if (!FuncInfo->CanLowerReturn) {\n    // Put in an sret pointer parameter before all the other parameters.\n    SmallVector<EVT, 1> ValueVTs;\n    ComputeValueVTs(*TLI, DAG.getDataLayout(),\n                    F.getReturnType()->getPointerTo(\n                        DAG.getDataLayout().getAllocaAddrSpace()),\n                    ValueVTs);\n\n    // NOTE: Assuming that a pointer will never break down to more than one VT\n    // or one register.\n    ISD::ArgFlagsTy Flags;\n    Flags.setSRet();\n    MVT RegisterVT = TLI->getRegisterType(*DAG.getContext(), ValueVTs[0]);\n    ISD::InputArg RetArg(Flags, RegisterVT, ValueVTs[0], true,\n                         ISD::InputArg::NoArgIndex, 0);\n    Ins.push_back(RetArg);\n  }\n\n  // Look for stores of arguments to static allocas. Mark such arguments with a\n  // flag to ask the target to give us the memory location of that argument if\n  // available.\n  ArgCopyElisionMapTy ArgCopyElisionCandidates;\n  findArgumentCopyElisionCandidates(DL, FuncInfo.get(),\n                                    ArgCopyElisionCandidates);\n\n  // Set up the incoming argument description vector.\n  for (const Argument &Arg : F.args()) {\n    unsigned ArgNo = Arg.getArgNo();\n    SmallVector<EVT, 4> ValueVTs;\n    ComputeValueVTs(*TLI, DAG.getDataLayout(), Arg.getType(), ValueVTs);\n    bool isArgValueUsed = !Arg.use_empty();\n    unsigned PartBase = 0;\n    Type *FinalType = Arg.getType();\n    if (Arg.hasAttribute(Attribute::ByVal))\n      FinalType = Arg.getParamByValType();\n    bool NeedsRegBlock = TLI->functionArgumentNeedsConsecutiveRegisters(\n        FinalType, F.getCallingConv(), F.isVarArg());\n    for (unsigned Value = 0, NumValues = ValueVTs.size();\n         Value != NumValues; ++Value) {\n      EVT VT = ValueVTs[Value];\n      Type *ArgTy = VT.getTypeForEVT(*DAG.getContext());\n      ISD::ArgFlagsTy Flags;\n\n      // Certain targets (such as MIPS), may have a different ABI alignment\n      // for a type depending on the context. Give the target a chance to\n      // specify the alignment it wants.\n      const Align OriginalAlignment(\n          TLI->getABIAlignmentForCallingConv(ArgTy, DL));\n\n      if (Arg.getType()->isPointerTy()) {\n        Flags.setPointer();\n        Flags.setPointerAddrSpace(\n            cast<PointerType>(Arg.getType())->getAddressSpace());\n      }\n      if (Arg.hasAttribute(Attribute::ZExt))\n        Flags.setZExt();\n      if (Arg.hasAttribute(Attribute::SExt))\n        Flags.setSExt();\n      if (Arg.hasAttribute(Attribute::InReg)) {\n        // If we are using vectorcall calling convention, a structure that is\n        // passed InReg - is surely an HVA\n        if (F.getCallingConv() == CallingConv::X86_VectorCall &&\n            isa<StructType>(Arg.getType())) {\n          // The first value of a structure is marked\n          if (0 == Value)\n            Flags.setHvaStart();\n          Flags.setHva();\n        }\n        // Set InReg Flag\n        Flags.setInReg();\n      }\n      if (Arg.hasAttribute(Attribute::StructRet))\n        Flags.setSRet();\n      if (Arg.hasAttribute(Attribute::SwiftSelf))\n        Flags.setSwiftSelf();\n      if (Arg.hasAttribute(Attribute::SwiftError))\n        Flags.setSwiftError();\n      if (Arg.hasAttribute(Attribute::ByVal))\n        Flags.setByVal();\n      if (Arg.hasAttribute(Attribute::ByRef))\n        Flags.setByRef();\n      if (Arg.hasAttribute(Attribute::InAlloca)) {\n        Flags.setInAlloca();\n        // Set the byval flag for CCAssignFn callbacks that don't know about\n        // inalloca.  This way we can know how many bytes we should've allocated\n        // and how many bytes a callee cleanup function will pop.  If we port\n        // inalloca to more targets, we'll have to add custom inalloca handling\n        // in the various CC lowering callbacks.\n        Flags.setByVal();\n      }\n      if (Arg.hasAttribute(Attribute::Preallocated)) {\n        Flags.setPreallocated();\n        // Set the byval flag for CCAssignFn callbacks that don't know about\n        // preallocated.  This way we can know how many bytes we should've\n        // allocated and how many bytes a callee cleanup function will pop.  If\n        // we port preallocated to more targets, we'll have to add custom\n        // preallocated handling in the various CC lowering callbacks.\n        Flags.setByVal();\n      }\n\n      Type *ArgMemTy = nullptr;\n      if (Flags.isByVal() || Flags.isInAlloca() || Flags.isPreallocated() ||\n          Flags.isByRef()) {\n        if (!ArgMemTy)\n          ArgMemTy = Arg.getPointeeInMemoryValueType();\n\n        uint64_t MemSize = DL.getTypeAllocSize(ArgMemTy);\n\n        // For in-memory arguments, size and alignment should be passed from FE.\n        // BE will guess if this info is not there but there are cases it cannot\n        // get right.\n        MaybeAlign MemAlign = Arg.getParamAlign();\n        if (!MemAlign)\n          MemAlign = Align(TLI->getByValTypeAlignment(ArgMemTy, DL));\n\n        if (Flags.isByRef()) {\n          Flags.setByRefSize(MemSize);\n          Flags.setByRefAlign(*MemAlign);\n        } else {\n          Flags.setByValSize(MemSize);\n          Flags.setByValAlign(*MemAlign);\n        }\n      }\n\n      if (Arg.hasAttribute(Attribute::Nest))\n        Flags.setNest();\n      if (NeedsRegBlock)\n        Flags.setInConsecutiveRegs();\n      Flags.setOrigAlign(OriginalAlignment);\n      if (ArgCopyElisionCandidates.count(&Arg))\n        Flags.setCopyElisionCandidate();\n      if (Arg.hasAttribute(Attribute::Returned))\n        Flags.setReturned();\n\n      MVT RegisterVT = TLI->getRegisterTypeForCallingConv(\n          *CurDAG->getContext(), F.getCallingConv(), VT);\n      unsigned NumRegs = TLI->getNumRegistersForCallingConv(\n          *CurDAG->getContext(), F.getCallingConv(), VT);\n      for (unsigned i = 0; i != NumRegs; ++i) {\n        // For scalable vectors, use the minimum size; individual targets\n        // are responsible for handling scalable vector arguments and\n        // return values.\n        ISD::InputArg MyFlags(Flags, RegisterVT, VT, isArgValueUsed,\n                 ArgNo, PartBase+i*RegisterVT.getStoreSize().getKnownMinSize());\n        if (NumRegs > 1 && i == 0)\n          MyFlags.Flags.setSplit();\n        // if it isn't first piece, alignment must be 1\n        else if (i > 0) {\n          MyFlags.Flags.setOrigAlign(Align(1));\n          if (i == NumRegs - 1)\n            MyFlags.Flags.setSplitEnd();\n        }\n        Ins.push_back(MyFlags);\n      }\n      if (NeedsRegBlock && Value == NumValues - 1)\n        Ins[Ins.size() - 1].Flags.setInConsecutiveRegsLast();\n      PartBase += VT.getStoreSize().getKnownMinSize();\n    }\n  }\n\n  // Call the target to set up the argument values.\n  SmallVector<SDValue, 8> InVals;\n  SDValue NewRoot = TLI->LowerFormalArguments(\n      DAG.getRoot(), F.getCallingConv(), F.isVarArg(), Ins, dl, DAG, InVals);\n\n  // Verify that the target's LowerFormalArguments behaved as expected.\n  assert(NewRoot.getNode() && NewRoot.getValueType() == MVT::Other &&\n         \"LowerFormalArguments didn't return a valid chain!\");\n  assert(InVals.size() == Ins.size() &&\n         \"LowerFormalArguments didn't emit the correct number of values!\");\n  LLVM_DEBUG({\n    for (unsigned i = 0, e = Ins.size(); i != e; ++i) {\n      assert(InVals[i].getNode() &&\n             \"LowerFormalArguments emitted a null value!\");\n      assert(EVT(Ins[i].VT) == InVals[i].getValueType() &&\n             \"LowerFormalArguments emitted a value with the wrong type!\");\n    }\n  });\n\n  // Update the DAG with the new chain value resulting from argument lowering.\n  DAG.setRoot(NewRoot);\n\n  // Set up the argument values.\n  unsigned i = 0;\n  if (!FuncInfo->CanLowerReturn) {\n    // Create a virtual register for the sret pointer, and put in a copy\n    // from the sret argument into it.\n    SmallVector<EVT, 1> ValueVTs;\n    ComputeValueVTs(*TLI, DAG.getDataLayout(),\n                    F.getReturnType()->getPointerTo(\n                        DAG.getDataLayout().getAllocaAddrSpace()),\n                    ValueVTs);\n    MVT VT = ValueVTs[0].getSimpleVT();\n    MVT RegVT = TLI->getRegisterType(*CurDAG->getContext(), VT);\n    Optional<ISD::NodeType> AssertOp = None;\n    SDValue ArgValue = getCopyFromParts(DAG, dl, &InVals[0], 1, RegVT, VT,\n                                        nullptr, F.getCallingConv(), AssertOp);\n\n    MachineFunction& MF = SDB->DAG.getMachineFunction();\n    MachineRegisterInfo& RegInfo = MF.getRegInfo();\n    Register SRetReg =\n        RegInfo.createVirtualRegister(TLI->getRegClassFor(RegVT));\n    FuncInfo->DemoteRegister = SRetReg;\n    NewRoot =\n        SDB->DAG.getCopyToReg(NewRoot, SDB->getCurSDLoc(), SRetReg, ArgValue);\n    DAG.setRoot(NewRoot);\n\n    // i indexes lowered arguments.  Bump it past the hidden sret argument.\n    ++i;\n  }\n\n  SmallVector<SDValue, 4> Chains;\n  DenseMap<int, int> ArgCopyElisionFrameIndexMap;\n  for (const Argument &Arg : F.args()) {\n    SmallVector<SDValue, 4> ArgValues;\n    SmallVector<EVT, 4> ValueVTs;\n    ComputeValueVTs(*TLI, DAG.getDataLayout(), Arg.getType(), ValueVTs);\n    unsigned NumValues = ValueVTs.size();\n    if (NumValues == 0)\n      continue;\n\n    bool ArgHasUses = !Arg.use_empty();\n\n    // Elide the copying store if the target loaded this argument from a\n    // suitable fixed stack object.\n    if (Ins[i].Flags.isCopyElisionCandidate()) {\n      tryToElideArgumentCopy(*FuncInfo, Chains, ArgCopyElisionFrameIndexMap,\n                             ElidedArgCopyInstrs, ArgCopyElisionCandidates, Arg,\n                             InVals[i], ArgHasUses);\n    }\n\n    // If this argument is unused then remember its value. It is used to generate\n    // debugging information.\n    bool isSwiftErrorArg =\n        TLI->supportSwiftError() &&\n        Arg.hasAttribute(Attribute::SwiftError);\n    if (!ArgHasUses && !isSwiftErrorArg) {\n      SDB->setUnusedArgValue(&Arg, InVals[i]);\n\n      // Also remember any frame index for use in FastISel.\n      if (FrameIndexSDNode *FI =\n          dyn_cast<FrameIndexSDNode>(InVals[i].getNode()))\n        FuncInfo->setArgumentFrameIndex(&Arg, FI->getIndex());\n    }\n\n    for (unsigned Val = 0; Val != NumValues; ++Val) {\n      EVT VT = ValueVTs[Val];\n      MVT PartVT = TLI->getRegisterTypeForCallingConv(*CurDAG->getContext(),\n                                                      F.getCallingConv(), VT);\n      unsigned NumParts = TLI->getNumRegistersForCallingConv(\n          *CurDAG->getContext(), F.getCallingConv(), VT);\n\n      // Even an apparent 'unused' swifterror argument needs to be returned. So\n      // we do generate a copy for it that can be used on return from the\n      // function.\n      if (ArgHasUses || isSwiftErrorArg) {\n        Optional<ISD::NodeType> AssertOp;\n        if (Arg.hasAttribute(Attribute::SExt))\n          AssertOp = ISD::AssertSext;\n        else if (Arg.hasAttribute(Attribute::ZExt))\n          AssertOp = ISD::AssertZext;\n\n        ArgValues.push_back(getCopyFromParts(DAG, dl, &InVals[i], NumParts,\n                                             PartVT, VT, nullptr,\n                                             F.getCallingConv(), AssertOp));\n      }\n\n      i += NumParts;\n    }\n\n    // We don't need to do anything else for unused arguments.\n    if (ArgValues.empty())\n      continue;\n\n    // Note down frame index.\n    if (FrameIndexSDNode *FI =\n        dyn_cast<FrameIndexSDNode>(ArgValues[0].getNode()))\n      FuncInfo->setArgumentFrameIndex(&Arg, FI->getIndex());\n\n    SDValue Res = DAG.getMergeValues(makeArrayRef(ArgValues.data(), NumValues),\n                                     SDB->getCurSDLoc());\n\n    SDB->setValue(&Arg, Res);\n    if (!TM.Options.EnableFastISel && Res.getOpcode() == ISD::BUILD_PAIR) {\n      // We want to associate the argument with the frame index, among\n      // involved operands, that correspond to the lowest address. The\n      // getCopyFromParts function, called earlier, is swapping the order of\n      // the operands to BUILD_PAIR depending on endianness. The result of\n      // that swapping is that the least significant bits of the argument will\n      // be in the first operand of the BUILD_PAIR node, and the most\n      // significant bits will be in the second operand.\n      unsigned LowAddressOp = DAG.getDataLayout().isBigEndian() ? 1 : 0;\n      if (LoadSDNode *LNode =\n          dyn_cast<LoadSDNode>(Res.getOperand(LowAddressOp).getNode()))\n        if (FrameIndexSDNode *FI =\n            dyn_cast<FrameIndexSDNode>(LNode->getBasePtr().getNode()))\n          FuncInfo->setArgumentFrameIndex(&Arg, FI->getIndex());\n    }\n\n    // Analyses past this point are naive and don't expect an assertion.\n    if (Res.getOpcode() == ISD::AssertZext)\n      Res = Res.getOperand(0);\n\n    // Update the SwiftErrorVRegDefMap.\n    if (Res.getOpcode() == ISD::CopyFromReg && isSwiftErrorArg) {\n      unsigned Reg = cast<RegisterSDNode>(Res.getOperand(1))->getReg();\n      if (Register::isVirtualRegister(Reg))\n        SwiftError->setCurrentVReg(FuncInfo->MBB, SwiftError->getFunctionArg(),\n                                   Reg);\n    }\n\n    // If this argument is live outside of the entry block, insert a copy from\n    // wherever we got it to the vreg that other BB's will reference it as.\n    if (Res.getOpcode() == ISD::CopyFromReg) {\n      // If we can, though, try to skip creating an unnecessary vreg.\n      // FIXME: This isn't very clean... it would be nice to make this more\n      // general.\n      unsigned Reg = cast<RegisterSDNode>(Res.getOperand(1))->getReg();\n      if (Register::isVirtualRegister(Reg)) {\n        FuncInfo->ValueMap[&Arg] = Reg;\n        continue;\n      }\n    }\n    if (!isOnlyUsedInEntryBlock(&Arg, TM.Options.EnableFastISel)) {\n      FuncInfo->InitializeRegForValue(&Arg);\n      SDB->CopyToExportRegsIfNeeded(&Arg);\n    }\n  }\n\n  if (!Chains.empty()) {\n    Chains.push_back(NewRoot);\n    NewRoot = DAG.getNode(ISD::TokenFactor, dl, MVT::Other, Chains);\n  }\n\n  DAG.setRoot(NewRoot);\n\n  assert(i == InVals.size() && \"Argument register count mismatch!\");\n\n  // If any argument copy elisions occurred and we have debug info, update the\n  // stale frame indices used in the dbg.declare variable info table.\n  MachineFunction::VariableDbgInfoMapTy &DbgDeclareInfo = MF->getVariableDbgInfo();\n  if (!DbgDeclareInfo.empty() && !ArgCopyElisionFrameIndexMap.empty()) {\n    for (MachineFunction::VariableDbgInfo &VI : DbgDeclareInfo) {\n      auto I = ArgCopyElisionFrameIndexMap.find(VI.Slot);\n      if (I != ArgCopyElisionFrameIndexMap.end())\n        VI.Slot = I->second;\n    }\n  }\n\n  // Finally, if the target has anything special to do, allow it to do so.\n  emitFunctionEntryCode();\n}\n\n/// Handle PHI nodes in successor blocks.  Emit code into the SelectionDAG to\n/// ensure constants are generated when needed.  Remember the virtual registers\n/// that need to be added to the Machine PHI nodes as input.  We cannot just\n/// directly add them, because expansion might result in multiple MBB's for one\n/// BB.  As such, the start of the BB might correspond to a different MBB than\n/// the end.\nvoid\nSelectionDAGBuilder::HandlePHINodesInSuccessorBlocks(const BasicBlock *LLVMBB) {\n  const Instruction *TI = LLVMBB->getTerminator();\n\n  SmallPtrSet<MachineBasicBlock *, 4> SuccsHandled;\n\n  // Check PHI nodes in successors that expect a value to be available from this\n  // block.\n  for (unsigned succ = 0, e = TI->getNumSuccessors(); succ != e; ++succ) {\n    const BasicBlock *SuccBB = TI->getSuccessor(succ);\n    if (!isa<PHINode>(SuccBB->begin())) continue;\n    MachineBasicBlock *SuccMBB = FuncInfo.MBBMap[SuccBB];\n\n    // If this terminator has multiple identical successors (common for\n    // switches), only handle each succ once.\n    if (!SuccsHandled.insert(SuccMBB).second)\n      continue;\n\n    MachineBasicBlock::iterator MBBI = SuccMBB->begin();\n\n    // At this point we know that there is a 1-1 correspondence between LLVM PHI\n    // nodes and Machine PHI nodes, but the incoming operands have not been\n    // emitted yet.\n    for (const PHINode &PN : SuccBB->phis()) {\n      // Ignore dead phi's.\n      if (PN.use_empty())\n        continue;\n\n      // Skip empty types\n      if (PN.getType()->isEmptyTy())\n        continue;\n\n      unsigned Reg;\n      const Value *PHIOp = PN.getIncomingValueForBlock(LLVMBB);\n\n      if (const Constant *C = dyn_cast<Constant>(PHIOp)) {\n        unsigned &RegOut = ConstantsOut[C];\n        if (RegOut == 0) {\n          RegOut = FuncInfo.CreateRegs(C);\n          CopyValueToVirtualRegister(C, RegOut);\n        }\n        Reg = RegOut;\n      } else {\n        DenseMap<const Value *, Register>::iterator I =\n          FuncInfo.ValueMap.find(PHIOp);\n        if (I != FuncInfo.ValueMap.end())\n          Reg = I->second;\n        else {\n          assert(isa<AllocaInst>(PHIOp) &&\n                 FuncInfo.StaticAllocaMap.count(cast<AllocaInst>(PHIOp)) &&\n                 \"Didn't codegen value into a register!??\");\n          Reg = FuncInfo.CreateRegs(PHIOp);\n          CopyValueToVirtualRegister(PHIOp, Reg);\n        }\n      }\n\n      // Remember that this register needs to added to the machine PHI node as\n      // the input for this MBB.\n      SmallVector<EVT, 4> ValueVTs;\n      const TargetLowering &TLI = DAG.getTargetLoweringInfo();\n      ComputeValueVTs(TLI, DAG.getDataLayout(), PN.getType(), ValueVTs);\n      for (unsigned vti = 0, vte = ValueVTs.size(); vti != vte; ++vti) {\n        EVT VT = ValueVTs[vti];\n        unsigned NumRegisters = TLI.getNumRegisters(*DAG.getContext(), VT);\n        for (unsigned i = 0, e = NumRegisters; i != e; ++i)\n          FuncInfo.PHINodesToUpdate.push_back(\n              std::make_pair(&*MBBI++, Reg + i));\n        Reg += NumRegisters;\n      }\n    }\n  }\n\n  ConstantsOut.clear();\n}\n\n/// Add a successor MBB to ParentMBB< creating a new MachineBB for BB if SuccMBB\n/// is 0.\nMachineBasicBlock *\nSelectionDAGBuilder::StackProtectorDescriptor::\nAddSuccessorMBB(const BasicBlock *BB,\n                MachineBasicBlock *ParentMBB,\n                bool IsLikely,\n                MachineBasicBlock *SuccMBB) {\n  // If SuccBB has not been created yet, create it.\n  if (!SuccMBB) {\n    MachineFunction *MF = ParentMBB->getParent();\n    MachineFunction::iterator BBI(ParentMBB);\n    SuccMBB = MF->CreateMachineBasicBlock(BB);\n    MF->insert(++BBI, SuccMBB);\n  }\n  // Add it as a successor of ParentMBB.\n  ParentMBB->addSuccessor(\n      SuccMBB, BranchProbabilityInfo::getBranchProbStackProtector(IsLikely));\n  return SuccMBB;\n}\n\nMachineBasicBlock *SelectionDAGBuilder::NextBlock(MachineBasicBlock *MBB) {\n  MachineFunction::iterator I(MBB);\n  if (++I == FuncInfo.MF->end())\n    return nullptr;\n  return &*I;\n}\n\n/// During lowering new call nodes can be created (such as memset, etc.).\n/// Those will become new roots of the current DAG, but complications arise\n/// when they are tail calls. In such cases, the call lowering will update\n/// the root, but the builder still needs to know that a tail call has been\n/// lowered in order to avoid generating an additional return.\nvoid SelectionDAGBuilder::updateDAGForMaybeTailCall(SDValue MaybeTC) {\n  // If the node is null, we do have a tail call.\n  if (MaybeTC.getNode() != nullptr)\n    DAG.setRoot(MaybeTC);\n  else\n    HasTailCall = true;\n}\n\nvoid SelectionDAGBuilder::lowerWorkItem(SwitchWorkListItem W, Value *Cond,\n                                        MachineBasicBlock *SwitchMBB,\n                                        MachineBasicBlock *DefaultMBB) {\n  MachineFunction *CurMF = FuncInfo.MF;\n  MachineBasicBlock *NextMBB = nullptr;\n  MachineFunction::iterator BBI(W.MBB);\n  if (++BBI != FuncInfo.MF->end())\n    NextMBB = &*BBI;\n\n  unsigned Size = W.LastCluster - W.FirstCluster + 1;\n\n  BranchProbabilityInfo *BPI = FuncInfo.BPI;\n\n  if (Size == 2 && W.MBB == SwitchMBB) {\n    // If any two of the cases has the same destination, and if one value\n    // is the same as the other, but has one bit unset that the other has set,\n    // use bit manipulation to do two compares at once.  For example:\n    // \"if (X == 6 || X == 4)\" -> \"if ((X|2) == 6)\"\n    // TODO: This could be extended to merge any 2 cases in switches with 3\n    // cases.\n    // TODO: Handle cases where W.CaseBB != SwitchBB.\n    CaseCluster &Small = *W.FirstCluster;\n    CaseCluster &Big = *W.LastCluster;\n\n    if (Small.Low == Small.High && Big.Low == Big.High &&\n        Small.MBB == Big.MBB) {\n      const APInt &SmallValue = Small.Low->getValue();\n      const APInt &BigValue = Big.Low->getValue();\n\n      // Check that there is only one bit different.\n      APInt CommonBit = BigValue ^ SmallValue;\n      if (CommonBit.isPowerOf2()) {\n        SDValue CondLHS = getValue(Cond);\n        EVT VT = CondLHS.getValueType();\n        SDLoc DL = getCurSDLoc();\n\n        SDValue Or = DAG.getNode(ISD::OR, DL, VT, CondLHS,\n                                 DAG.getConstant(CommonBit, DL, VT));\n        SDValue Cond = DAG.getSetCC(\n            DL, MVT::i1, Or, DAG.getConstant(BigValue | SmallValue, DL, VT),\n            ISD::SETEQ);\n\n        // Update successor info.\n        // Both Small and Big will jump to Small.BB, so we sum up the\n        // probabilities.\n        addSuccessorWithProb(SwitchMBB, Small.MBB, Small.Prob + Big.Prob);\n        if (BPI)\n          addSuccessorWithProb(\n              SwitchMBB, DefaultMBB,\n              // The default destination is the first successor in IR.\n              BPI->getEdgeProbability(SwitchMBB->getBasicBlock(), (unsigned)0));\n        else\n          addSuccessorWithProb(SwitchMBB, DefaultMBB);\n\n        // Insert the true branch.\n        SDValue BrCond =\n            DAG.getNode(ISD::BRCOND, DL, MVT::Other, getControlRoot(), Cond,\n                        DAG.getBasicBlock(Small.MBB));\n        // Insert the false branch.\n        BrCond = DAG.getNode(ISD::BR, DL, MVT::Other, BrCond,\n                             DAG.getBasicBlock(DefaultMBB));\n\n        DAG.setRoot(BrCond);\n        return;\n      }\n    }\n  }\n\n  if (TM.getOptLevel() != CodeGenOpt::None) {\n    // Here, we order cases by probability so the most likely case will be\n    // checked first. However, two clusters can have the same probability in\n    // which case their relative ordering is non-deterministic. So we use Low\n    // as a tie-breaker as clusters are guaranteed to never overlap.\n    llvm::sort(W.FirstCluster, W.LastCluster + 1,\n               [](const CaseCluster &a, const CaseCluster &b) {\n      return a.Prob != b.Prob ?\n             a.Prob > b.Prob :\n             a.Low->getValue().slt(b.Low->getValue());\n    });\n\n    // Rearrange the case blocks so that the last one falls through if possible\n    // without changing the order of probabilities.\n    for (CaseClusterIt I = W.LastCluster; I > W.FirstCluster; ) {\n      --I;\n      if (I->Prob > W.LastCluster->Prob)\n        break;\n      if (I->Kind == CC_Range && I->MBB == NextMBB) {\n        std::swap(*I, *W.LastCluster);\n        break;\n      }\n    }\n  }\n\n  // Compute total probability.\n  BranchProbability DefaultProb = W.DefaultProb;\n  BranchProbability UnhandledProbs = DefaultProb;\n  for (CaseClusterIt I = W.FirstCluster; I <= W.LastCluster; ++I)\n    UnhandledProbs += I->Prob;\n\n  MachineBasicBlock *CurMBB = W.MBB;\n  for (CaseClusterIt I = W.FirstCluster, E = W.LastCluster; I <= E; ++I) {\n    bool FallthroughUnreachable = false;\n    MachineBasicBlock *Fallthrough;\n    if (I == W.LastCluster) {\n      // For the last cluster, fall through to the default destination.\n      Fallthrough = DefaultMBB;\n      FallthroughUnreachable = isa<UnreachableInst>(\n          DefaultMBB->getBasicBlock()->getFirstNonPHIOrDbg());\n    } else {\n      Fallthrough = CurMF->CreateMachineBasicBlock(CurMBB->getBasicBlock());\n      CurMF->insert(BBI, Fallthrough);\n      // Put Cond in a virtual register to make it available from the new blocks.\n      ExportFromCurrentBlock(Cond);\n    }\n    UnhandledProbs -= I->Prob;\n\n    switch (I->Kind) {\n      case CC_JumpTable: {\n        // FIXME: Optimize away range check based on pivot comparisons.\n        JumpTableHeader *JTH = &SL->JTCases[I->JTCasesIndex].first;\n        SwitchCG::JumpTable *JT = &SL->JTCases[I->JTCasesIndex].second;\n\n        // The jump block hasn't been inserted yet; insert it here.\n        MachineBasicBlock *JumpMBB = JT->MBB;\n        CurMF->insert(BBI, JumpMBB);\n\n        auto JumpProb = I->Prob;\n        auto FallthroughProb = UnhandledProbs;\n\n        // If the default statement is a target of the jump table, we evenly\n        // distribute the default probability to successors of CurMBB. Also\n        // update the probability on the edge from JumpMBB to Fallthrough.\n        for (MachineBasicBlock::succ_iterator SI = JumpMBB->succ_begin(),\n                                              SE = JumpMBB->succ_end();\n             SI != SE; ++SI) {\n          if (*SI == DefaultMBB) {\n            JumpProb += DefaultProb / 2;\n            FallthroughProb -= DefaultProb / 2;\n            JumpMBB->setSuccProbability(SI, DefaultProb / 2);\n            JumpMBB->normalizeSuccProbs();\n            break;\n          }\n        }\n\n        if (FallthroughUnreachable) {\n          // Skip the range check if the fallthrough block is unreachable.\n          JTH->OmitRangeCheck = true;\n        }\n\n        if (!JTH->OmitRangeCheck)\n          addSuccessorWithProb(CurMBB, Fallthrough, FallthroughProb);\n        addSuccessorWithProb(CurMBB, JumpMBB, JumpProb);\n        CurMBB->normalizeSuccProbs();\n\n        // The jump table header will be inserted in our current block, do the\n        // range check, and fall through to our fallthrough block.\n        JTH->HeaderBB = CurMBB;\n        JT->Default = Fallthrough; // FIXME: Move Default to JumpTableHeader.\n\n        // If we're in the right place, emit the jump table header right now.\n        if (CurMBB == SwitchMBB) {\n          visitJumpTableHeader(*JT, *JTH, SwitchMBB);\n          JTH->Emitted = true;\n        }\n        break;\n      }\n      case CC_BitTests: {\n        // FIXME: Optimize away range check based on pivot comparisons.\n        BitTestBlock *BTB = &SL->BitTestCases[I->BTCasesIndex];\n\n        // The bit test blocks haven't been inserted yet; insert them here.\n        for (BitTestCase &BTC : BTB->Cases)\n          CurMF->insert(BBI, BTC.ThisBB);\n\n        // Fill in fields of the BitTestBlock.\n        BTB->Parent = CurMBB;\n        BTB->Default = Fallthrough;\n\n        BTB->DefaultProb = UnhandledProbs;\n        // If the cases in bit test don't form a contiguous range, we evenly\n        // distribute the probability on the edge to Fallthrough to two\n        // successors of CurMBB.\n        if (!BTB->ContiguousRange) {\n          BTB->Prob += DefaultProb / 2;\n          BTB->DefaultProb -= DefaultProb / 2;\n        }\n\n        if (FallthroughUnreachable) {\n          // Skip the range check if the fallthrough block is unreachable.\n          BTB->OmitRangeCheck = true;\n        }\n\n        // If we're in the right place, emit the bit test header right now.\n        if (CurMBB == SwitchMBB) {\n          visitBitTestHeader(*BTB, SwitchMBB);\n          BTB->Emitted = true;\n        }\n        break;\n      }\n      case CC_Range: {\n        const Value *RHS, *LHS, *MHS;\n        ISD::CondCode CC;\n        if (I->Low == I->High) {\n          // Check Cond == I->Low.\n          CC = ISD::SETEQ;\n          LHS = Cond;\n          RHS=I->Low;\n          MHS = nullptr;\n        } else {\n          // Check I->Low <= Cond <= I->High.\n          CC = ISD::SETLE;\n          LHS = I->Low;\n          MHS = Cond;\n          RHS = I->High;\n        }\n\n        // If Fallthrough is unreachable, fold away the comparison.\n        if (FallthroughUnreachable)\n          CC = ISD::SETTRUE;\n\n        // The false probability is the sum of all unhandled cases.\n        CaseBlock CB(CC, LHS, RHS, MHS, I->MBB, Fallthrough, CurMBB,\n                     getCurSDLoc(), I->Prob, UnhandledProbs);\n\n        if (CurMBB == SwitchMBB)\n          visitSwitchCase(CB, SwitchMBB);\n        else\n          SL->SwitchCases.push_back(CB);\n\n        break;\n      }\n    }\n    CurMBB = Fallthrough;\n  }\n}\n\nunsigned SelectionDAGBuilder::caseClusterRank(const CaseCluster &CC,\n                                              CaseClusterIt First,\n                                              CaseClusterIt Last) {\n  return std::count_if(First, Last + 1, [&](const CaseCluster &X) {\n    if (X.Prob != CC.Prob)\n      return X.Prob > CC.Prob;\n\n    // Ties are broken by comparing the case value.\n    return X.Low->getValue().slt(CC.Low->getValue());\n  });\n}\n\nvoid SelectionDAGBuilder::splitWorkItem(SwitchWorkList &WorkList,\n                                        const SwitchWorkListItem &W,\n                                        Value *Cond,\n                                        MachineBasicBlock *SwitchMBB) {\n  assert(W.FirstCluster->Low->getValue().slt(W.LastCluster->Low->getValue()) &&\n         \"Clusters not sorted?\");\n\n  assert(W.LastCluster - W.FirstCluster + 1 >= 2 && \"Too small to split!\");\n\n  // Balance the tree based on branch probabilities to create a near-optimal (in\n  // terms of search time given key frequency) binary search tree. See e.g. Kurt\n  // Mehlhorn \"Nearly Optimal Binary Search Trees\" (1975).\n  CaseClusterIt LastLeft = W.FirstCluster;\n  CaseClusterIt FirstRight = W.LastCluster;\n  auto LeftProb = LastLeft->Prob + W.DefaultProb / 2;\n  auto RightProb = FirstRight->Prob + W.DefaultProb / 2;\n\n  // Move LastLeft and FirstRight towards each other from opposite directions to\n  // find a partitioning of the clusters which balances the probability on both\n  // sides. If LeftProb and RightProb are equal, alternate which side is\n  // taken to ensure 0-probability nodes are distributed evenly.\n  unsigned I = 0;\n  while (LastLeft + 1 < FirstRight) {\n    if (LeftProb < RightProb || (LeftProb == RightProb && (I & 1)))\n      LeftProb += (++LastLeft)->Prob;\n    else\n      RightProb += (--FirstRight)->Prob;\n    I++;\n  }\n\n  while (true) {\n    // Our binary search tree differs from a typical BST in that ours can have up\n    // to three values in each leaf. The pivot selection above doesn't take that\n    // into account, which means the tree might require more nodes and be less\n    // efficient. We compensate for this here.\n\n    unsigned NumLeft = LastLeft - W.FirstCluster + 1;\n    unsigned NumRight = W.LastCluster - FirstRight + 1;\n\n    if (std::min(NumLeft, NumRight) < 3 && std::max(NumLeft, NumRight) > 3) {\n      // If one side has less than 3 clusters, and the other has more than 3,\n      // consider taking a cluster from the other side.\n\n      if (NumLeft < NumRight) {\n        // Consider moving the first cluster on the right to the left side.\n        CaseCluster &CC = *FirstRight;\n        unsigned RightSideRank = caseClusterRank(CC, FirstRight, W.LastCluster);\n        unsigned LeftSideRank = caseClusterRank(CC, W.FirstCluster, LastLeft);\n        if (LeftSideRank <= RightSideRank) {\n          // Moving the cluster to the left does not demote it.\n          ++LastLeft;\n          ++FirstRight;\n          continue;\n        }\n      } else {\n        assert(NumRight < NumLeft);\n        // Consider moving the last element on the left to the right side.\n        CaseCluster &CC = *LastLeft;\n        unsigned LeftSideRank = caseClusterRank(CC, W.FirstCluster, LastLeft);\n        unsigned RightSideRank = caseClusterRank(CC, FirstRight, W.LastCluster);\n        if (RightSideRank <= LeftSideRank) {\n          // Moving the cluster to the right does not demot it.\n          --LastLeft;\n          --FirstRight;\n          continue;\n        }\n      }\n    }\n    break;\n  }\n\n  assert(LastLeft + 1 == FirstRight);\n  assert(LastLeft >= W.FirstCluster);\n  assert(FirstRight <= W.LastCluster);\n\n  // Use the first element on the right as pivot since we will make less-than\n  // comparisons against it.\n  CaseClusterIt PivotCluster = FirstRight;\n  assert(PivotCluster > W.FirstCluster);\n  assert(PivotCluster <= W.LastCluster);\n\n  CaseClusterIt FirstLeft = W.FirstCluster;\n  CaseClusterIt LastRight = W.LastCluster;\n\n  const ConstantInt *Pivot = PivotCluster->Low;\n\n  // New blocks will be inserted immediately after the current one.\n  MachineFunction::iterator BBI(W.MBB);\n  ++BBI;\n\n  // We will branch to the LHS if Value < Pivot. If LHS is a single cluster,\n  // we can branch to its destination directly if it's squeezed exactly in\n  // between the known lower bound and Pivot - 1.\n  MachineBasicBlock *LeftMBB;\n  if (FirstLeft == LastLeft && FirstLeft->Kind == CC_Range &&\n      FirstLeft->Low == W.GE &&\n      (FirstLeft->High->getValue() + 1LL) == Pivot->getValue()) {\n    LeftMBB = FirstLeft->MBB;\n  } else {\n    LeftMBB = FuncInfo.MF->CreateMachineBasicBlock(W.MBB->getBasicBlock());\n    FuncInfo.MF->insert(BBI, LeftMBB);\n    WorkList.push_back(\n        {LeftMBB, FirstLeft, LastLeft, W.GE, Pivot, W.DefaultProb / 2});\n    // Put Cond in a virtual register to make it available from the new blocks.\n    ExportFromCurrentBlock(Cond);\n  }\n\n  // Similarly, we will branch to the RHS if Value >= Pivot. If RHS is a\n  // single cluster, RHS.Low == Pivot, and we can branch to its destination\n  // directly if RHS.High equals the current upper bound.\n  MachineBasicBlock *RightMBB;\n  if (FirstRight == LastRight && FirstRight->Kind == CC_Range &&\n      W.LT && (FirstRight->High->getValue() + 1ULL) == W.LT->getValue()) {\n    RightMBB = FirstRight->MBB;\n  } else {\n    RightMBB = FuncInfo.MF->CreateMachineBasicBlock(W.MBB->getBasicBlock());\n    FuncInfo.MF->insert(BBI, RightMBB);\n    WorkList.push_back(\n        {RightMBB, FirstRight, LastRight, Pivot, W.LT, W.DefaultProb / 2});\n    // Put Cond in a virtual register to make it available from the new blocks.\n    ExportFromCurrentBlock(Cond);\n  }\n\n  // Create the CaseBlock record that will be used to lower the branch.\n  CaseBlock CB(ISD::SETLT, Cond, Pivot, nullptr, LeftMBB, RightMBB, W.MBB,\n               getCurSDLoc(), LeftProb, RightProb);\n\n  if (W.MBB == SwitchMBB)\n    visitSwitchCase(CB, SwitchMBB);\n  else\n    SL->SwitchCases.push_back(CB);\n}\n\n// Scale CaseProb after peeling a case with the probablity of PeeledCaseProb\n// from the swith statement.\nstatic BranchProbability scaleCaseProbality(BranchProbability CaseProb,\n                                            BranchProbability PeeledCaseProb) {\n  if (PeeledCaseProb == BranchProbability::getOne())\n    return BranchProbability::getZero();\n  BranchProbability SwitchProb = PeeledCaseProb.getCompl();\n\n  uint32_t Numerator = CaseProb.getNumerator();\n  uint32_t Denominator = SwitchProb.scale(CaseProb.getDenominator());\n  return BranchProbability(Numerator, std::max(Numerator, Denominator));\n}\n\n// Try to peel the top probability case if it exceeds the threshold.\n// Return current MachineBasicBlock for the switch statement if the peeling\n// does not occur.\n// If the peeling is performed, return the newly created MachineBasicBlock\n// for the peeled switch statement. Also update Clusters to remove the peeled\n// case. PeeledCaseProb is the BranchProbability for the peeled case.\nMachineBasicBlock *SelectionDAGBuilder::peelDominantCaseCluster(\n    const SwitchInst &SI, CaseClusterVector &Clusters,\n    BranchProbability &PeeledCaseProb) {\n  MachineBasicBlock *SwitchMBB = FuncInfo.MBB;\n  // Don't perform if there is only one cluster or optimizing for size.\n  if (SwitchPeelThreshold > 100 || !FuncInfo.BPI || Clusters.size() < 2 ||\n      TM.getOptLevel() == CodeGenOpt::None ||\n      SwitchMBB->getParent()->getFunction().hasMinSize())\n    return SwitchMBB;\n\n  BranchProbability TopCaseProb = BranchProbability(SwitchPeelThreshold, 100);\n  unsigned PeeledCaseIndex = 0;\n  bool SwitchPeeled = false;\n  for (unsigned Index = 0; Index < Clusters.size(); ++Index) {\n    CaseCluster &CC = Clusters[Index];\n    if (CC.Prob < TopCaseProb)\n      continue;\n    TopCaseProb = CC.Prob;\n    PeeledCaseIndex = Index;\n    SwitchPeeled = true;\n  }\n  if (!SwitchPeeled)\n    return SwitchMBB;\n\n  LLVM_DEBUG(dbgs() << \"Peeled one top case in switch stmt, prob: \"\n                    << TopCaseProb << \"\\n\");\n\n  // Record the MBB for the peeled switch statement.\n  MachineFunction::iterator BBI(SwitchMBB);\n  ++BBI;\n  MachineBasicBlock *PeeledSwitchMBB =\n      FuncInfo.MF->CreateMachineBasicBlock(SwitchMBB->getBasicBlock());\n  FuncInfo.MF->insert(BBI, PeeledSwitchMBB);\n\n  ExportFromCurrentBlock(SI.getCondition());\n  auto PeeledCaseIt = Clusters.begin() + PeeledCaseIndex;\n  SwitchWorkListItem W = {SwitchMBB, PeeledCaseIt, PeeledCaseIt,\n                          nullptr,   nullptr,      TopCaseProb.getCompl()};\n  lowerWorkItem(W, SI.getCondition(), SwitchMBB, PeeledSwitchMBB);\n\n  Clusters.erase(PeeledCaseIt);\n  for (CaseCluster &CC : Clusters) {\n    LLVM_DEBUG(\n        dbgs() << \"Scale the probablity for one cluster, before scaling: \"\n               << CC.Prob << \"\\n\");\n    CC.Prob = scaleCaseProbality(CC.Prob, TopCaseProb);\n    LLVM_DEBUG(dbgs() << \"After scaling: \" << CC.Prob << \"\\n\");\n  }\n  PeeledCaseProb = TopCaseProb;\n  return PeeledSwitchMBB;\n}\n\nvoid SelectionDAGBuilder::visitSwitch(const SwitchInst &SI) {\n  // Extract cases from the switch.\n  BranchProbabilityInfo *BPI = FuncInfo.BPI;\n  CaseClusterVector Clusters;\n  Clusters.reserve(SI.getNumCases());\n  for (auto I : SI.cases()) {\n    MachineBasicBlock *Succ = FuncInfo.MBBMap[I.getCaseSuccessor()];\n    const ConstantInt *CaseVal = I.getCaseValue();\n    BranchProbability Prob =\n        BPI ? BPI->getEdgeProbability(SI.getParent(), I.getSuccessorIndex())\n            : BranchProbability(1, SI.getNumCases() + 1);\n    Clusters.push_back(CaseCluster::range(CaseVal, CaseVal, Succ, Prob));\n  }\n\n  MachineBasicBlock *DefaultMBB = FuncInfo.MBBMap[SI.getDefaultDest()];\n\n  // Cluster adjacent cases with the same destination. We do this at all\n  // optimization levels because it's cheap to do and will make codegen faster\n  // if there are many clusters.\n  sortAndRangeify(Clusters);\n\n  // The branch probablity of the peeled case.\n  BranchProbability PeeledCaseProb = BranchProbability::getZero();\n  MachineBasicBlock *PeeledSwitchMBB =\n      peelDominantCaseCluster(SI, Clusters, PeeledCaseProb);\n\n  // If there is only the default destination, jump there directly.\n  MachineBasicBlock *SwitchMBB = FuncInfo.MBB;\n  if (Clusters.empty()) {\n    assert(PeeledSwitchMBB == SwitchMBB);\n    SwitchMBB->addSuccessor(DefaultMBB);\n    if (DefaultMBB != NextBlock(SwitchMBB)) {\n      DAG.setRoot(DAG.getNode(ISD::BR, getCurSDLoc(), MVT::Other,\n                              getControlRoot(), DAG.getBasicBlock(DefaultMBB)));\n    }\n    return;\n  }\n\n  SL->findJumpTables(Clusters, &SI, DefaultMBB, DAG.getPSI(), DAG.getBFI());\n  SL->findBitTestClusters(Clusters, &SI);\n\n  LLVM_DEBUG({\n    dbgs() << \"Case clusters: \";\n    for (const CaseCluster &C : Clusters) {\n      if (C.Kind == CC_JumpTable)\n        dbgs() << \"JT:\";\n      if (C.Kind == CC_BitTests)\n        dbgs() << \"BT:\";\n\n      C.Low->getValue().print(dbgs(), true);\n      if (C.Low != C.High) {\n        dbgs() << '-';\n        C.High->getValue().print(dbgs(), true);\n      }\n      dbgs() << ' ';\n    }\n    dbgs() << '\\n';\n  });\n\n  assert(!Clusters.empty());\n  SwitchWorkList WorkList;\n  CaseClusterIt First = Clusters.begin();\n  CaseClusterIt Last = Clusters.end() - 1;\n  auto DefaultProb = getEdgeProbability(PeeledSwitchMBB, DefaultMBB);\n  // Scale the branchprobability for DefaultMBB if the peel occurs and\n  // DefaultMBB is not replaced.\n  if (PeeledCaseProb != BranchProbability::getZero() &&\n      DefaultMBB == FuncInfo.MBBMap[SI.getDefaultDest()])\n    DefaultProb = scaleCaseProbality(DefaultProb, PeeledCaseProb);\n  WorkList.push_back(\n      {PeeledSwitchMBB, First, Last, nullptr, nullptr, DefaultProb});\n\n  while (!WorkList.empty()) {\n    SwitchWorkListItem W = WorkList.pop_back_val();\n    unsigned NumClusters = W.LastCluster - W.FirstCluster + 1;\n\n    if (NumClusters > 3 && TM.getOptLevel() != CodeGenOpt::None &&\n        !DefaultMBB->getParent()->getFunction().hasMinSize()) {\n      // For optimized builds, lower large range as a balanced binary tree.\n      splitWorkItem(WorkList, W, SI.getCondition(), SwitchMBB);\n      continue;\n    }\n\n    lowerWorkItem(W, SI.getCondition(), SwitchMBB, DefaultMBB);\n  }\n}\n\nvoid SelectionDAGBuilder::visitFreeze(const FreezeInst &I) {\n  SmallVector<EVT, 4> ValueVTs;\n  ComputeValueVTs(DAG.getTargetLoweringInfo(), DAG.getDataLayout(), I.getType(),\n                  ValueVTs);\n  unsigned NumValues = ValueVTs.size();\n  if (NumValues == 0) return;\n\n  SmallVector<SDValue, 4> Values(NumValues);\n  SDValue Op = getValue(I.getOperand(0));\n\n  for (unsigned i = 0; i != NumValues; ++i)\n    Values[i] = DAG.getNode(ISD::FREEZE, getCurSDLoc(), ValueVTs[i],\n                            SDValue(Op.getNode(), Op.getResNo() + i));\n\n  setValue(&I, DAG.getNode(ISD::MERGE_VALUES, getCurSDLoc(),\n                           DAG.getVTList(ValueVTs), Values));\n}\n"}}, "reports": [{"events": [{"location": {"col": 16, "file": 3, "line": 326}, "message": "the definition seen here"}, {"location": {"col": 16, "file": 3, "line": 154}, "message": "differing parameters are named here: ('CC'), in definition: ('CallConv')"}, {"location": {"col": 16, "file": 3, "line": 154}, "message": "function 'getCopyFromPartsVector' has a definition with different parameter names"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp", "reportHash": "caf0ac527d400fa7b123892a6747566b", "checkerName": "readability-inconsistent-declaration-parameter-name", "reviewStatus": null, "severity": "STYLE"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
