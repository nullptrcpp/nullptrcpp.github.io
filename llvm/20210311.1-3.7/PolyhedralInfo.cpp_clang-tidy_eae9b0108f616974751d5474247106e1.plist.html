<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"25": {"id": 25, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AliasSetTracker.h", "content": "//===- llvm/Analysis/AliasSetTracker.h - Build Alias Sets -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines two classes: AliasSetTracker and AliasSet. These interfaces\n// are used to classify a collection of pointer references into a maximal number\n// of disjoint sets. Each AliasSet object constructed by the AliasSetTracker\n// object refers to memory disjoint from the other sets.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_ALIASSETTRACKER_H\n#define LLVM_ANALYSIS_ALIASSETTRACKER_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/ilist.h\"\n#include \"llvm/ADT/ilist_node.h\"\n#include \"llvm/Analysis/MemoryLocation.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Metadata.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Casting.h\"\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <iterator>\n#include <vector>\n\nnamespace llvm {\n\nclass AAResults;\nclass AliasSetTracker;\nclass BasicBlock;\nclass LoadInst;\nclass Loop;\nclass MemorySSA;\nclass AnyMemSetInst;\nclass AnyMemTransferInst;\nclass raw_ostream;\nclass StoreInst;\nclass VAArgInst;\nclass Value;\n\nenum AliasResult : uint8_t;\n\nclass AliasSet : public ilist_node<AliasSet> {\n  friend class AliasSetTracker;\n\n  class PointerRec {\n    Value *Val;  // The pointer this record corresponds to.\n    PointerRec **PrevInList = nullptr;\n    PointerRec *NextInList = nullptr;\n    AliasSet *AS = nullptr;\n    LocationSize Size = LocationSize::mapEmpty();\n    AAMDNodes AAInfo;\n\n    // Whether the size for this record has been set at all. This makes no\n    // guarantees about the size being known.\n    bool isSizeSet() const { return Size != LocationSize::mapEmpty(); }\n\n  public:\n    PointerRec(Value *V)\n      : Val(V), AAInfo(DenseMapInfo<AAMDNodes>::getEmptyKey()) {}\n\n    Value *getValue() const { return Val; }\n\n    PointerRec *getNext() const { return NextInList; }\n    bool hasAliasSet() const { return AS != nullptr; }\n\n    PointerRec** setPrevInList(PointerRec **PIL) {\n      PrevInList = PIL;\n      return &NextInList;\n    }\n\n    bool updateSizeAndAAInfo(LocationSize NewSize, const AAMDNodes &NewAAInfo) {\n      bool SizeChanged = false;\n      if (NewSize != Size) {\n        LocationSize OldSize = Size;\n        Size = isSizeSet() ? Size.unionWith(NewSize) : NewSize;\n        SizeChanged = OldSize != Size;\n      }\n\n      if (AAInfo == DenseMapInfo<AAMDNodes>::getEmptyKey())\n        // We don't have a AAInfo yet. Set it to NewAAInfo.\n        AAInfo = NewAAInfo;\n      else {\n        AAMDNodes Intersection(AAInfo.intersect(NewAAInfo));\n        SizeChanged |= Intersection != AAInfo;\n        AAInfo = Intersection;\n      }\n      return SizeChanged;\n    }\n\n    LocationSize getSize() const {\n      assert(isSizeSet() && \"Getting an unset size!\");\n      return Size;\n    }\n\n    /// Return the AAInfo, or null if there is no information or conflicting\n    /// information.\n    AAMDNodes getAAInfo() const {\n      // If we have missing or conflicting AAInfo, return null.\n      if (AAInfo == DenseMapInfo<AAMDNodes>::getEmptyKey() ||\n          AAInfo == DenseMapInfo<AAMDNodes>::getTombstoneKey())\n        return AAMDNodes();\n      return AAInfo;\n    }\n\n    AliasSet *getAliasSet(AliasSetTracker &AST) {\n      assert(AS && \"No AliasSet yet!\");\n      if (AS->Forward) {\n        AliasSet *OldAS = AS;\n        AS = OldAS->getForwardedTarget(AST);\n        AS->addRef();\n        OldAS->dropRef(AST);\n      }\n      return AS;\n    }\n\n    void setAliasSet(AliasSet *as) {\n      assert(!AS && \"Already have an alias set!\");\n      AS = as;\n    }\n\n    void eraseFromList() {\n      if (NextInList) NextInList->PrevInList = PrevInList;\n      *PrevInList = NextInList;\n      if (AS->PtrListEnd == &NextInList) {\n        AS->PtrListEnd = PrevInList;\n        assert(*AS->PtrListEnd == nullptr && \"List not terminated right!\");\n      }\n      delete this;\n    }\n  };\n\n  // Doubly linked list of nodes.\n  PointerRec *PtrList = nullptr;\n  PointerRec **PtrListEnd;\n  // Forwarding pointer.\n  AliasSet *Forward = nullptr;\n\n  /// All instructions without a specific address in this alias set.\n  /// In rare cases this vector can have a null'ed out WeakVH\n  /// instances (can happen if some other loop pass deletes an\n  /// instruction in this list).\n  std::vector<WeakVH> UnknownInsts;\n\n  /// Number of nodes pointing to this AliasSet plus the number of AliasSets\n  /// forwarding to it.\n  unsigned RefCount : 27;\n\n  // Signifies that this set should be considered to alias any pointer.\n  // Use when the tracker holding this set is saturated.\n  unsigned AliasAny : 1;\n\n  /// The kinds of access this alias set models.\n  ///\n  /// We keep track of whether this alias set merely refers to the locations of\n  /// memory (and not any particular access), whether it modifies or references\n  /// the memory, or whether it does both. The lattice goes from \"NoAccess\" to\n  /// either RefAccess or ModAccess, then to ModRefAccess as necessary.\n  enum AccessLattice {\n    NoAccess = 0,\n    RefAccess = 1,\n    ModAccess = 2,\n    ModRefAccess = RefAccess | ModAccess\n  };\n  unsigned Access : 2;\n\n  /// The kind of alias relationship between pointers of the set.\n  ///\n  /// These represent conservatively correct alias results between any members\n  /// of the set. We represent these independently of the values of alias\n  /// results in order to pack it into a single bit. Lattice goes from\n  /// MustAlias to MayAlias.\n  enum AliasLattice {\n    SetMustAlias = 0, SetMayAlias = 1\n  };\n  unsigned Alias : 1;\n\n  unsigned SetSize = 0;\n\n  void addRef() { ++RefCount; }\n\n  void dropRef(AliasSetTracker &AST) {\n    assert(RefCount >= 1 && \"Invalid reference count detected!\");\n    if (--RefCount == 0)\n      removeFromTracker(AST);\n  }\n\n  Instruction *getUnknownInst(unsigned i) const {\n    assert(i < UnknownInsts.size());\n    return cast_or_null<Instruction>(UnknownInsts[i]);\n  }\n\npublic:\n  AliasSet(const AliasSet &) = delete;\n  AliasSet &operator=(const AliasSet &) = delete;\n\n  /// Accessors...\n  bool isRef() const { return Access & RefAccess; }\n  bool isMod() const { return Access & ModAccess; }\n  bool isMustAlias() const { return Alias == SetMustAlias; }\n  bool isMayAlias()  const { return Alias == SetMayAlias; }\n\n  /// Return true if this alias set should be ignored as part of the\n  /// AliasSetTracker object.\n  bool isForwardingAliasSet() const { return Forward; }\n\n  /// Merge the specified alias set into this alias set.\n  void mergeSetIn(AliasSet &AS, AliasSetTracker &AST);\n\n  // Alias Set iteration - Allow access to all of the pointers which are part of\n  // this alias set.\n  class iterator;\n  iterator begin() const { return iterator(PtrList); }\n  iterator end()   const { return iterator(); }\n  bool empty() const { return PtrList == nullptr; }\n\n  // Unfortunately, ilist::size() is linear, so we have to add code to keep\n  // track of the list's exact size.\n  unsigned size() { return SetSize; }\n\n  /// If this alias set is known to contain a single instruction and *only* a\n  /// single unique instruction, return it.  Otherwise, return nullptr.\n  Instruction* getUniqueInstruction();\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\n  /// Define an iterator for alias sets... this is just a forward iterator.\n  class iterator : public std::iterator<std::forward_iterator_tag,\n                                        PointerRec, ptrdiff_t> {\n    PointerRec *CurNode;\n\n  public:\n    explicit iterator(PointerRec *CN = nullptr) : CurNode(CN) {}\n\n    bool operator==(const iterator& x) const {\n      return CurNode == x.CurNode;\n    }\n    bool operator!=(const iterator& x) const { return !operator==(x); }\n\n    value_type &operator*() const {\n      assert(CurNode && \"Dereferencing AliasSet.end()!\");\n      return *CurNode;\n    }\n    value_type *operator->() const { return &operator*(); }\n\n    Value *getPointer() const { return CurNode->getValue(); }\n    LocationSize getSize() const { return CurNode->getSize(); }\n    AAMDNodes getAAInfo() const { return CurNode->getAAInfo(); }\n\n    iterator& operator++() {                // Preincrement\n      assert(CurNode && \"Advancing past AliasSet.end()!\");\n      CurNode = CurNode->getNext();\n      return *this;\n    }\n    iterator operator++(int) { // Postincrement\n      iterator tmp = *this; ++*this; return tmp;\n    }\n  };\n\nprivate:\n  // Can only be created by AliasSetTracker.\n  AliasSet()\n      : PtrListEnd(&PtrList), RefCount(0),  AliasAny(false), Access(NoAccess),\n        Alias(SetMustAlias) {}\n\n  PointerRec *getSomePointer() const {\n    return PtrList;\n  }\n\n  /// Return the real alias set this represents. If this has been merged with\n  /// another set and is forwarding, return the ultimate destination set. This\n  /// also implements the union-find collapsing as well.\n  AliasSet *getForwardedTarget(AliasSetTracker &AST) {\n    if (!Forward) return this;\n\n    AliasSet *Dest = Forward->getForwardedTarget(AST);\n    if (Dest != Forward) {\n      Dest->addRef();\n      Forward->dropRef(AST);\n      Forward = Dest;\n    }\n    return Dest;\n  }\n\n  void removeFromTracker(AliasSetTracker &AST);\n\n  void addPointer(AliasSetTracker &AST, PointerRec &Entry, LocationSize Size,\n                  const AAMDNodes &AAInfo, bool KnownMustAlias = false,\n                  bool SkipSizeUpdate = false);\n  void addUnknownInst(Instruction *I, AAResults &AA);\n\n  void removeUnknownInst(AliasSetTracker &AST, Instruction *I) {\n    bool WasEmpty = UnknownInsts.empty();\n    for (size_t i = 0, e = UnknownInsts.size(); i != e; ++i)\n      if (UnknownInsts[i] == I) {\n        UnknownInsts[i] = UnknownInsts.back();\n        UnknownInsts.pop_back();\n        --i; --e;  // Revisit the moved entry.\n      }\n    if (!WasEmpty && UnknownInsts.empty())\n      dropRef(AST);\n  }\n\npublic:\n  /// If the specified pointer \"may\" (or must) alias one of the members in the\n  /// set return the appropriate AliasResult. Otherwise return NoAlias.\n  AliasResult aliasesPointer(const Value *Ptr, LocationSize Size,\n                             const AAMDNodes &AAInfo, AAResults &AA) const;\n  bool aliasesUnknownInst(const Instruction *Inst, AAResults &AA) const;\n};\n\ninline raw_ostream& operator<<(raw_ostream &OS, const AliasSet &AS) {\n  AS.print(OS);\n  return OS;\n}\n\nclass AliasSetTracker {\n  /// A CallbackVH to arrange for AliasSetTracker to be notified whenever a\n  /// Value is deleted.\n  class ASTCallbackVH final : public CallbackVH {\n    AliasSetTracker *AST;\n\n    void deleted() override;\n    void allUsesReplacedWith(Value *) override;\n\n  public:\n    ASTCallbackVH(Value *V, AliasSetTracker *AST = nullptr);\n\n    ASTCallbackVH &operator=(Value *V);\n  };\n  /// Traits to tell DenseMap that tell us how to compare and hash the value\n  /// handle.\n  struct ASTCallbackVHDenseMapInfo : public DenseMapInfo<Value *> {};\n\n  AAResults &AA;\n  MemorySSA *MSSA = nullptr;\n  Loop *L = nullptr;\n  ilist<AliasSet> AliasSets;\n\n  using PointerMapType = DenseMap<ASTCallbackVH, AliasSet::PointerRec *,\n                                  ASTCallbackVHDenseMapInfo>;\n\n  // Map from pointers to their node\n  PointerMapType PointerMap;\n\npublic:\n  /// Create an empty collection of AliasSets, and use the specified alias\n  /// analysis object to disambiguate load and store addresses.\n  explicit AliasSetTracker(AAResults &AA) : AA(AA) {}\n  explicit AliasSetTracker(AAResults &AA, MemorySSA *MSSA, Loop *L)\n      : AA(AA), MSSA(MSSA), L(L) {}\n  ~AliasSetTracker() { clear(); }\n\n  /// These methods are used to add different types of instructions to the alias\n  /// sets. Adding a new instruction can result in one of three actions\n  /// happening:\n  ///\n  ///   1. If the instruction doesn't alias any other sets, create a new set.\n  ///   2. If the instruction aliases exactly one set, add it to the set\n  ///   3. If the instruction aliases multiple sets, merge the sets, and add\n  ///      the instruction to the result.\n  ///\n  /// These methods return true if inserting the instruction resulted in the\n  /// addition of a new alias set (i.e., the pointer did not alias anything).\n  ///\n  void add(Value *Ptr, LocationSize Size, const AAMDNodes &AAInfo); // Add a loc\n  void add(LoadInst *LI);\n  void add(StoreInst *SI);\n  void add(VAArgInst *VAAI);\n  void add(AnyMemSetInst *MSI);\n  void add(AnyMemTransferInst *MTI);\n  void add(Instruction *I);       // Dispatch to one of the other add methods...\n  void add(BasicBlock &BB);       // Add all instructions in basic block\n  void add(const AliasSetTracker &AST); // Add alias relations from another AST\n  void addUnknown(Instruction *I);\n  void addAllInstructionsInLoopUsingMSSA();\n\n  void clear();\n\n  /// Return the alias sets that are active.\n  const ilist<AliasSet> &getAliasSets() const { return AliasSets; }\n\n  /// Return the alias set which contains the specified memory location.  If\n  /// the memory location aliases two or more existing alias sets, will have\n  /// the effect of merging those alias sets before the single resulting alias\n  /// set is returned.\n  AliasSet &getAliasSetFor(const MemoryLocation &MemLoc);\n\n  /// Return the underlying alias analysis object used by this tracker.\n  AAResults &getAliasAnalysis() const { return AA; }\n\n  /// This method is used to remove a pointer value from the AliasSetTracker\n  /// entirely. It should be used when an instruction is deleted from the\n  /// program to update the AST. If you don't use this, you would have dangling\n  /// pointers to deleted instructions.\n  void deleteValue(Value *PtrVal);\n\n  /// This method should be used whenever a preexisting value in the program is\n  /// copied or cloned, introducing a new value.  Note that it is ok for clients\n  /// that use this method to introduce the same value multiple times: if the\n  /// tracker already knows about a value, it will ignore the request.\n  void copyValue(Value *From, Value *To);\n\n  using iterator = ilist<AliasSet>::iterator;\n  using const_iterator = ilist<AliasSet>::const_iterator;\n\n  const_iterator begin() const { return AliasSets.begin(); }\n  const_iterator end()   const { return AliasSets.end(); }\n\n  iterator begin() { return AliasSets.begin(); }\n  iterator end()   { return AliasSets.end(); }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  friend class AliasSet;\n\n  // The total number of pointers contained in all \"may\" alias sets.\n  unsigned TotalMayAliasSetSize = 0;\n\n  // A non-null value signifies this AST is saturated. A saturated AST lumps\n  // all pointers into a single \"May\" set.\n  AliasSet *AliasAnyAS = nullptr;\n\n  void removeAliasSet(AliasSet *AS);\n\n  /// Just like operator[] on the map, except that it creates an entry for the\n  /// pointer if it doesn't already exist.\n  AliasSet::PointerRec &getEntryFor(Value *V) {\n    AliasSet::PointerRec *&Entry = PointerMap[ASTCallbackVH(V, this)];\n    if (!Entry)\n      Entry = new AliasSet::PointerRec(V);\n    return *Entry;\n  }\n\n  AliasSet &addPointer(MemoryLocation Loc, AliasSet::AccessLattice E);\n  AliasSet *mergeAliasSetsForPointer(const Value *Ptr, LocationSize Size,\n                                     const AAMDNodes &AAInfo,\n                                     bool &MustAliasAll);\n\n  /// Merge all alias sets into a single set that is considered to alias any\n  /// pointer.\n  AliasSet &mergeAllAliasSets();\n\n  AliasSet *findAliasSetForUnknownInst(Instruction *Inst);\n};\n\ninline raw_ostream& operator<<(raw_ostream &OS, const AliasSetTracker &AST) {\n  AST.print(OS);\n  return OS;\n}\n\nclass AliasSetsPrinterPass : public PassInfoMixin<AliasSetsPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit AliasSetsPrinterPass(raw_ostream &OS);\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_ALIASSETTRACKER_H\n"}, "26": {"id": 26, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "content": "//===- llvm/Analysis/LoopInfo.h - Natural Loop Calculator -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the LoopInfo class that is used to identify natural loops\n// and determine the loop depth of various nodes of the CFG.  A natural loop\n// has exactly one entry-point, which is called the header. Note that natural\n// loops may actually be several loops that share the same header node.\n//\n// This analysis calculates the nesting structure of loops in a function.  For\n// each natural loop identified, this analysis identifies natural loops\n// contained entirely within the loop and the basic blocks the make up the loop.\n//\n// It can calculate on the fly various bits of information, for example:\n//\n//  * whether there is a preheader for the loop\n//  * the number of back edges to the header\n//  * whether or not a particular block branches out of the loop\n//  * the successor blocks of the loop\n//  * the loop depth\n//  * etc...\n//\n// Note that this analysis specifically identifies *Loops* not cycles or SCCs\n// in the CFG.  There can be strongly connected components in the CFG which\n// this analysis will not recognize and that will not be represented by a Loop\n// instance.  In particular, a Loop might be inside such a non-loop SCC, or a\n// non-loop SCC might contain a sub-SCC which is a Loop.\n//\n// For an overview of terminology used in this API (and thus all of our loop\n// analyses or transforms), see docs/LoopTerminology.rst.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_LOOPINFO_H\n#define LLVM_ANALYSIS_LOOPINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Allocator.h\"\n#include <algorithm>\n#include <utility>\n\nnamespace llvm {\n\nclass DominatorTree;\nclass LoopInfo;\nclass Loop;\nclass InductionDescriptor;\nclass MDNode;\nclass MemorySSAUpdater;\nclass ScalarEvolution;\nclass raw_ostream;\ntemplate <class N, bool IsPostDom> class DominatorTreeBase;\ntemplate <class N, class M> class LoopInfoBase;\ntemplate <class N, class M> class LoopBase;\n\n//===----------------------------------------------------------------------===//\n/// Instances of this class are used to represent loops that are detected in the\n/// flow graph.\n///\ntemplate <class BlockT, class LoopT> class LoopBase {\n  LoopT *ParentLoop;\n  // Loops contained entirely within this one.\n  std::vector<LoopT *> SubLoops;\n\n  // The list of blocks in this loop. First entry is the header node.\n  std::vector<BlockT *> Blocks;\n\n  SmallPtrSet<const BlockT *, 8> DenseBlockSet;\n\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n  /// Indicator that this loop is no longer a valid loop.\n  bool IsInvalid = false;\n#endif\n\n  LoopBase(const LoopBase<BlockT, LoopT> &) = delete;\n  const LoopBase<BlockT, LoopT> &\n  operator=(const LoopBase<BlockT, LoopT> &) = delete;\n\npublic:\n  /// Return the nesting level of this loop.  An outer-most loop has depth 1,\n  /// for consistency with loop depth values used for basic blocks, where depth\n  /// 0 is used for blocks not inside any loops.\n  unsigned getLoopDepth() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    unsigned D = 1;\n    for (const LoopT *CurLoop = ParentLoop; CurLoop;\n         CurLoop = CurLoop->ParentLoop)\n      ++D;\n    return D;\n  }\n  BlockT *getHeader() const { return getBlocks().front(); }\n  /// Return the parent loop if it exists or nullptr for top\n  /// level loops.\n\n  /// A loop is either top-level in a function (that is, it is not\n  /// contained in any other loop) or it is entirely enclosed in\n  /// some other loop.\n  /// If a loop is top-level, it has no parent, otherwise its\n  /// parent is the innermost loop in which it is enclosed.\n  LoopT *getParentLoop() const { return ParentLoop; }\n\n  /// This is a raw interface for bypassing addChildLoop.\n  void setParentLoop(LoopT *L) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    ParentLoop = L;\n  }\n\n  /// Return true if the specified loop is contained within in this loop.\n  bool contains(const LoopT *L) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    if (L == this)\n      return true;\n    if (!L)\n      return false;\n    return contains(L->getParentLoop());\n  }\n\n  /// Return true if the specified basic block is in this loop.\n  bool contains(const BlockT *BB) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return DenseBlockSet.count(BB);\n  }\n\n  /// Return true if the specified instruction is in this loop.\n  template <class InstT> bool contains(const InstT *Inst) const {\n    return contains(Inst->getParent());\n  }\n\n  /// Return the loops contained entirely within this loop.\n  const std::vector<LoopT *> &getSubLoops() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return SubLoops;\n  }\n  std::vector<LoopT *> &getSubLoopsVector() {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return SubLoops;\n  }\n  typedef typename std::vector<LoopT *>::const_iterator iterator;\n  typedef\n      typename std::vector<LoopT *>::const_reverse_iterator reverse_iterator;\n  iterator begin() const { return getSubLoops().begin(); }\n  iterator end() const { return getSubLoops().end(); }\n  reverse_iterator rbegin() const { return getSubLoops().rbegin(); }\n  reverse_iterator rend() const { return getSubLoops().rend(); }\n\n  // LoopInfo does not detect irreducible control flow, just natural\n  // loops. That is, it is possible that there is cyclic control\n  // flow within the \"innermost loop\" or around the \"outermost\n  // loop\".\n\n  /// Return true if the loop does not contain any (natural) loops.\n  bool isInnermost() const { return getSubLoops().empty(); }\n  /// Return true if the loop does not have a parent (natural) loop\n  // (i.e. it is outermost, which is the same as top-level).\n  bool isOutermost() const { return getParentLoop() == nullptr; }\n\n  /// Get a list of the basic blocks which make up this loop.\n  ArrayRef<BlockT *> getBlocks() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return Blocks;\n  }\n  typedef typename ArrayRef<BlockT *>::const_iterator block_iterator;\n  block_iterator block_begin() const { return getBlocks().begin(); }\n  block_iterator block_end() const { return getBlocks().end(); }\n  inline iterator_range<block_iterator> blocks() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return make_range(block_begin(), block_end());\n  }\n\n  /// Get the number of blocks in this loop in constant time.\n  /// Invalidate the loop, indicating that it is no longer a loop.\n  unsigned getNumBlocks() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return Blocks.size();\n  }\n\n  /// Return a direct, mutable handle to the blocks vector so that we can\n  /// mutate it efficiently with techniques like `std::remove`.\n  std::vector<BlockT *> &getBlocksVector() {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return Blocks;\n  }\n  /// Return a direct, mutable handle to the blocks set so that we can\n  /// mutate it efficiently.\n  SmallPtrSetImpl<const BlockT *> &getBlocksSet() {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return DenseBlockSet;\n  }\n\n  /// Return a direct, immutable handle to the blocks set.\n  const SmallPtrSetImpl<const BlockT *> &getBlocksSet() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return DenseBlockSet;\n  }\n\n  /// Return true if this loop is no longer valid.  The only valid use of this\n  /// helper is \"assert(L.isInvalid())\" or equivalent, since IsInvalid is set to\n  /// true by the destructor.  In other words, if this accessor returns true,\n  /// the caller has already triggered UB by calling this accessor; and so it\n  /// can only be called in a context where a return value of true indicates a\n  /// programmer error.\n  bool isInvalid() const {\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    return IsInvalid;\n#else\n    return false;\n#endif\n  }\n\n  /// True if terminator in the block can branch to another block that is\n  /// outside of the current loop. \\p BB must be inside the loop.\n  bool isLoopExiting(const BlockT *BB) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(contains(BB) && \"Exiting block must be part of the loop\");\n    for (const auto *Succ : children<const BlockT *>(BB)) {\n      if (!contains(Succ))\n        return true;\n    }\n    return false;\n  }\n\n  /// Returns true if \\p BB is a loop-latch.\n  /// A latch block is a block that contains a branch back to the header.\n  /// This function is useful when there are multiple latches in a loop\n  /// because \\fn getLoopLatch will return nullptr in that case.\n  bool isLoopLatch(const BlockT *BB) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(contains(BB) && \"block does not belong to the loop\");\n\n    BlockT *Header = getHeader();\n    auto PredBegin = GraphTraits<Inverse<BlockT *>>::child_begin(Header);\n    auto PredEnd = GraphTraits<Inverse<BlockT *>>::child_end(Header);\n    return std::find(PredBegin, PredEnd, BB) != PredEnd;\n  }\n\n  /// Calculate the number of back edges to the loop header.\n  unsigned getNumBackEdges() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    unsigned NumBackEdges = 0;\n    BlockT *H = getHeader();\n\n    for (const auto Pred : children<Inverse<BlockT *>>(H))\n      if (contains(Pred))\n        ++NumBackEdges;\n\n    return NumBackEdges;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // APIs for simple analysis of the loop.\n  //\n  // Note that all of these methods can fail on general loops (ie, there may not\n  // be a preheader, etc).  For best success, the loop simplification and\n  // induction variable canonicalization pass should be used to normalize loops\n  // for easy analysis.  These methods assume canonical loops.\n\n  /// Return all blocks inside the loop that have successors outside of the\n  /// loop. These are the blocks _inside of the current loop_ which branch out.\n  /// The returned list is always unique.\n  void getExitingBlocks(SmallVectorImpl<BlockT *> &ExitingBlocks) const;\n\n  /// If getExitingBlocks would return exactly one block, return that block.\n  /// Otherwise return null.\n  BlockT *getExitingBlock() const;\n\n  /// Return all of the successor blocks of this loop. These are the blocks\n  /// _outside of the current loop_ which are branched to.\n  void getExitBlocks(SmallVectorImpl<BlockT *> &ExitBlocks) const;\n\n  /// If getExitBlocks would return exactly one block, return that block.\n  /// Otherwise return null.\n  BlockT *getExitBlock() const;\n\n  /// Return true if no exit block for the loop has a predecessor that is\n  /// outside the loop.\n  bool hasDedicatedExits() const;\n\n  /// Return all unique successor blocks of this loop.\n  /// These are the blocks _outside of the current loop_ which are branched to.\n  void getUniqueExitBlocks(SmallVectorImpl<BlockT *> &ExitBlocks) const;\n\n  /// Return all unique successor blocks of this loop except successors from\n  /// Latch block are not considered. If the exit comes from Latch has also\n  /// non Latch predecessor in a loop it will be added to ExitBlocks.\n  /// These are the blocks _outside of the current loop_ which are branched to.\n  void getUniqueNonLatchExitBlocks(SmallVectorImpl<BlockT *> &ExitBlocks) const;\n\n  /// If getUniqueExitBlocks would return exactly one block, return that block.\n  /// Otherwise return null.\n  BlockT *getUniqueExitBlock() const;\n\n  /// Return true if this loop does not have any exit blocks.\n  bool hasNoExitBlocks() const;\n\n  /// Edge type.\n  typedef std::pair<BlockT *, BlockT *> Edge;\n\n  /// Return all pairs of (_inside_block_,_outside_block_).\n  void getExitEdges(SmallVectorImpl<Edge> &ExitEdges) const;\n\n  /// If there is a preheader for this loop, return it. A loop has a preheader\n  /// if there is only one edge to the header of the loop from outside of the\n  /// loop. If this is the case, the block branching to the header of the loop\n  /// is the preheader node.\n  ///\n  /// This method returns null if there is no preheader for the loop.\n  BlockT *getLoopPreheader() const;\n\n  /// If the given loop's header has exactly one unique predecessor outside the\n  /// loop, return it. Otherwise return null.\n  ///  This is less strict that the loop \"preheader\" concept, which requires\n  /// the predecessor to have exactly one successor.\n  BlockT *getLoopPredecessor() const;\n\n  /// If there is a single latch block for this loop, return it.\n  /// A latch block is a block that contains a branch back to the header.\n  BlockT *getLoopLatch() const;\n\n  /// Return all loop latch blocks of this loop. A latch block is a block that\n  /// contains a branch back to the header.\n  void getLoopLatches(SmallVectorImpl<BlockT *> &LoopLatches) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    BlockT *H = getHeader();\n    for (const auto Pred : children<Inverse<BlockT *>>(H))\n      if (contains(Pred))\n        LoopLatches.push_back(Pred);\n  }\n\n  /// Return all inner loops in the loop nest rooted by the loop in preorder,\n  /// with siblings in forward program order.\n  template <class Type>\n  static void getInnerLoopsInPreorder(const LoopT &L,\n                                      SmallVectorImpl<Type> &PreOrderLoops) {\n    SmallVector<LoopT *, 4> PreOrderWorklist;\n    PreOrderWorklist.append(L.rbegin(), L.rend());\n\n    while (!PreOrderWorklist.empty()) {\n      LoopT *L = PreOrderWorklist.pop_back_val();\n      // Sub-loops are stored in forward program order, but will process the\n      // worklist backwards so append them in reverse order.\n      PreOrderWorklist.append(L->rbegin(), L->rend());\n      PreOrderLoops.push_back(L);\n    }\n  }\n\n  /// Return all loops in the loop nest rooted by the loop in preorder, with\n  /// siblings in forward program order.\n  SmallVector<const LoopT *, 4> getLoopsInPreorder() const {\n    SmallVector<const LoopT *, 4> PreOrderLoops;\n    const LoopT *CurLoop = static_cast<const LoopT *>(this);\n    PreOrderLoops.push_back(CurLoop);\n    getInnerLoopsInPreorder(*CurLoop, PreOrderLoops);\n    return PreOrderLoops;\n  }\n  SmallVector<LoopT *, 4> getLoopsInPreorder() {\n    SmallVector<LoopT *, 4> PreOrderLoops;\n    LoopT *CurLoop = static_cast<LoopT *>(this);\n    PreOrderLoops.push_back(CurLoop);\n    getInnerLoopsInPreorder(*CurLoop, PreOrderLoops);\n    return PreOrderLoops;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // APIs for updating loop information after changing the CFG\n  //\n\n  /// This method is used by other analyses to update loop information.\n  /// NewBB is set to be a new member of the current loop.\n  /// Because of this, it is added as a member of all parent loops, and is added\n  /// to the specified LoopInfo object as being in the current basic block.  It\n  /// is not valid to replace the loop header with this method.\n  void addBasicBlockToLoop(BlockT *NewBB, LoopInfoBase<BlockT, LoopT> &LI);\n\n  /// This is used when splitting loops up. It replaces the OldChild entry in\n  /// our children list with NewChild, and updates the parent pointer of\n  /// OldChild to be null and the NewChild to be this loop.\n  /// This updates the loop depth of the new child.\n  void replaceChildLoopWith(LoopT *OldChild, LoopT *NewChild);\n\n  /// Add the specified loop to be a child of this loop.\n  /// This updates the loop depth of the new child.\n  void addChildLoop(LoopT *NewChild) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(!NewChild->ParentLoop && \"NewChild already has a parent!\");\n    NewChild->ParentLoop = static_cast<LoopT *>(this);\n    SubLoops.push_back(NewChild);\n  }\n\n  /// This removes the specified child from being a subloop of this loop. The\n  /// loop is not deleted, as it will presumably be inserted into another loop.\n  LoopT *removeChildLoop(iterator I) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(I != SubLoops.end() && \"Cannot remove end iterator!\");\n    LoopT *Child = *I;\n    assert(Child->ParentLoop == this && \"Child is not a child of this loop!\");\n    SubLoops.erase(SubLoops.begin() + (I - begin()));\n    Child->ParentLoop = nullptr;\n    return Child;\n  }\n\n  /// This removes the specified child from being a subloop of this loop. The\n  /// loop is not deleted, as it will presumably be inserted into another loop.\n  LoopT *removeChildLoop(LoopT *Child) {\n    return removeChildLoop(llvm::find(*this, Child));\n  }\n\n  /// This adds a basic block directly to the basic block list.\n  /// This should only be used by transformations that create new loops.  Other\n  /// transformations should use addBasicBlockToLoop.\n  void addBlockEntry(BlockT *BB) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    Blocks.push_back(BB);\n    DenseBlockSet.insert(BB);\n  }\n\n  /// interface to reverse Blocks[from, end of loop] in this loop\n  void reverseBlock(unsigned from) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    std::reverse(Blocks.begin() + from, Blocks.end());\n  }\n\n  /// interface to do reserve() for Blocks\n  void reserveBlocks(unsigned size) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    Blocks.reserve(size);\n  }\n\n  /// This method is used to move BB (which must be part of this loop) to be the\n  /// loop header of the loop (the block that dominates all others).\n  void moveToHeader(BlockT *BB) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    if (Blocks[0] == BB)\n      return;\n    for (unsigned i = 0;; ++i) {\n      assert(i != Blocks.size() && \"Loop does not contain BB!\");\n      if (Blocks[i] == BB) {\n        Blocks[i] = Blocks[0];\n        Blocks[0] = BB;\n        return;\n      }\n    }\n  }\n\n  /// This removes the specified basic block from the current loop, updating the\n  /// Blocks as appropriate. This does not update the mapping in the LoopInfo\n  /// class.\n  void removeBlockFromLoop(BlockT *BB) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    auto I = find(Blocks, BB);\n    assert(I != Blocks.end() && \"N is not in this list!\");\n    Blocks.erase(I);\n\n    DenseBlockSet.erase(BB);\n  }\n\n  /// Verify loop structure\n  void verifyLoop() const;\n\n  /// Verify loop structure of this loop and all nested loops.\n  void verifyLoopNest(DenseSet<const LoopT *> *Loops) const;\n\n  /// Returns true if the loop is annotated parallel.\n  ///\n  /// Derived classes can override this method using static template\n  /// polymorphism.\n  bool isAnnotatedParallel() const { return false; }\n\n  /// Print loop with all the BBs inside it.\n  void print(raw_ostream &OS, unsigned Depth = 0, bool Verbose = false) const;\n\nprotected:\n  friend class LoopInfoBase<BlockT, LoopT>;\n\n  /// This creates an empty loop.\n  LoopBase() : ParentLoop(nullptr) {}\n\n  explicit LoopBase(BlockT *BB) : ParentLoop(nullptr) {\n    Blocks.push_back(BB);\n    DenseBlockSet.insert(BB);\n  }\n\n  // Since loop passes like SCEV are allowed to key analysis results off of\n  // `Loop` pointers, we cannot re-use pointers within a loop pass manager.\n  // This means loop passes should not be `delete` ing `Loop` objects directly\n  // (and risk a later `Loop` allocation re-using the address of a previous one)\n  // but should be using LoopInfo::markAsRemoved, which keeps around the `Loop`\n  // pointer till the end of the lifetime of the `LoopInfo` object.\n  //\n  // To make it easier to follow this rule, we mark the destructor as\n  // non-public.\n  ~LoopBase() {\n    for (auto *SubLoop : SubLoops)\n      SubLoop->~LoopT();\n\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    IsInvalid = true;\n#endif\n    SubLoops.clear();\n    Blocks.clear();\n    DenseBlockSet.clear();\n    ParentLoop = nullptr;\n  }\n};\n\ntemplate <class BlockT, class LoopT>\nraw_ostream &operator<<(raw_ostream &OS, const LoopBase<BlockT, LoopT> &Loop) {\n  Loop.print(OS);\n  return OS;\n}\n\n// Implementation in LoopInfoImpl.h\nextern template class LoopBase<BasicBlock, Loop>;\n\n/// Represents a single loop in the control flow graph.  Note that not all SCCs\n/// in the CFG are necessarily loops.\nclass Loop : public LoopBase<BasicBlock, Loop> {\npublic:\n  /// A range representing the start and end location of a loop.\n  class LocRange {\n    DebugLoc Start;\n    DebugLoc End;\n\n  public:\n    LocRange() {}\n    LocRange(DebugLoc Start) : Start(Start), End(Start) {}\n    LocRange(DebugLoc Start, DebugLoc End)\n        : Start(std::move(Start)), End(std::move(End)) {}\n\n    const DebugLoc &getStart() const { return Start; }\n    const DebugLoc &getEnd() const { return End; }\n\n    /// Check for null.\n    ///\n    explicit operator bool() const { return Start && End; }\n  };\n\n  /// Return true if the specified value is loop invariant.\n  bool isLoopInvariant(const Value *V) const;\n\n  /// Return true if all the operands of the specified instruction are loop\n  /// invariant.\n  bool hasLoopInvariantOperands(const Instruction *I) const;\n\n  /// If the given value is an instruction inside of the loop and it can be\n  /// hoisted, do so to make it trivially loop-invariant.\n  /// Return true if the value after any hoisting is loop invariant. This\n  /// function can be used as a slightly more aggressive replacement for\n  /// isLoopInvariant.\n  ///\n  /// If InsertPt is specified, it is the point to hoist instructions to.\n  /// If null, the terminator of the loop preheader is used.\n  bool makeLoopInvariant(Value *V, bool &Changed,\n                         Instruction *InsertPt = nullptr,\n                         MemorySSAUpdater *MSSAU = nullptr) const;\n\n  /// If the given instruction is inside of the loop and it can be hoisted, do\n  /// so to make it trivially loop-invariant.\n  /// Return true if the instruction after any hoisting is loop invariant. This\n  /// function can be used as a slightly more aggressive replacement for\n  /// isLoopInvariant.\n  ///\n  /// If InsertPt is specified, it is the point to hoist instructions to.\n  /// If null, the terminator of the loop preheader is used.\n  ///\n  bool makeLoopInvariant(Instruction *I, bool &Changed,\n                         Instruction *InsertPt = nullptr,\n                         MemorySSAUpdater *MSSAU = nullptr) const;\n\n  /// Check to see if the loop has a canonical induction variable: an integer\n  /// recurrence that starts at 0 and increments by one each time through the\n  /// loop. If so, return the phi node that corresponds to it.\n  ///\n  /// The IndVarSimplify pass transforms loops to have a canonical induction\n  /// variable.\n  ///\n  PHINode *getCanonicalInductionVariable() const;\n\n  /// Obtain the unique incoming and back edge. Return false if they are\n  /// non-unique or the loop is dead; otherwise, return true.\n  bool getIncomingAndBackEdge(BasicBlock *&Incoming,\n                              BasicBlock *&Backedge) const;\n\n  /// Below are some utilities to get the loop guard, loop bounds and induction\n  /// variable, and to check if a given phinode is an auxiliary induction\n  /// variable, if the loop is guarded, and if the loop is canonical.\n  ///\n  /// Here is an example:\n  /// \\code\n  /// for (int i = lb; i < ub; i+=step)\n  ///   <loop body>\n  /// --- pseudo LLVMIR ---\n  /// beforeloop:\n  ///   guardcmp = (lb < ub)\n  ///   if (guardcmp) goto preheader; else goto afterloop\n  /// preheader:\n  /// loop:\n  ///   i_1 = phi[{lb, preheader}, {i_2, latch}]\n  ///   <loop body>\n  ///   i_2 = i_1 + step\n  /// latch:\n  ///   cmp = (i_2 < ub)\n  ///   if (cmp) goto loop\n  /// exit:\n  /// afterloop:\n  /// \\endcode\n  ///\n  /// - getBounds\n  ///   - getInitialIVValue      --> lb\n  ///   - getStepInst            --> i_2 = i_1 + step\n  ///   - getStepValue           --> step\n  ///   - getFinalIVValue        --> ub\n  ///   - getCanonicalPredicate  --> '<'\n  ///   - getDirection           --> Increasing\n  ///\n  /// - getInductionVariable            --> i_1\n  /// - isAuxiliaryInductionVariable(x) --> true if x == i_1\n  /// - getLoopGuardBranch()\n  ///                 --> `if (guardcmp) goto preheader; else goto afterloop`\n  /// - isGuarded()                     --> true\n  /// - isCanonical                     --> false\n  struct LoopBounds {\n    /// Return the LoopBounds object if\n    /// - the given \\p IndVar is an induction variable\n    /// - the initial value of the induction variable can be found\n    /// - the step instruction of the induction variable can be found\n    /// - the final value of the induction variable can be found\n    ///\n    /// Else None.\n    static Optional<Loop::LoopBounds> getBounds(const Loop &L, PHINode &IndVar,\n                                                ScalarEvolution &SE);\n\n    /// Get the initial value of the loop induction variable.\n    Value &getInitialIVValue() const { return InitialIVValue; }\n\n    /// Get the instruction that updates the loop induction variable.\n    Instruction &getStepInst() const { return StepInst; }\n\n    /// Get the step that the loop induction variable gets updated by in each\n    /// loop iteration. Return nullptr if not found.\n    Value *getStepValue() const { return StepValue; }\n\n    /// Get the final value of the loop induction variable.\n    Value &getFinalIVValue() const { return FinalIVValue; }\n\n    /// Return the canonical predicate for the latch compare instruction, if\n    /// able to be calcuated. Else BAD_ICMP_PREDICATE.\n    ///\n    /// A predicate is considered as canonical if requirements below are all\n    /// satisfied:\n    /// 1. The first successor of the latch branch is the loop header\n    ///    If not, inverse the predicate.\n    /// 2. One of the operands of the latch comparison is StepInst\n    ///    If not, and\n    ///    - if the current calcuated predicate is not ne or eq, flip the\n    ///      predicate.\n    ///    - else if the loop is increasing, return slt\n    ///      (notice that it is safe to change from ne or eq to sign compare)\n    ///    - else if the loop is decreasing, return sgt\n    ///      (notice that it is safe to change from ne or eq to sign compare)\n    ///\n    /// Here is an example when both (1) and (2) are not satisfied:\n    /// \\code\n    /// loop.header:\n    ///  %iv = phi [%initialiv, %loop.preheader], [%inc, %loop.header]\n    ///  %inc = add %iv, %step\n    ///  %cmp = slt %iv, %finaliv\n    ///  br %cmp, %loop.exit, %loop.header\n    /// loop.exit:\n    /// \\endcode\n    /// - The second successor of the latch branch is the loop header instead\n    ///   of the first successor (slt -> sge)\n    /// - The first operand of the latch comparison (%cmp) is the IndVar (%iv)\n    ///   instead of the StepInst (%inc) (sge -> sgt)\n    ///\n    /// The predicate would be sgt if both (1) and (2) are satisfied.\n    /// getCanonicalPredicate() returns sgt for this example.\n    /// Note: The IR is not changed.\n    ICmpInst::Predicate getCanonicalPredicate() const;\n\n    /// An enum for the direction of the loop\n    /// - for (int i = 0; i < ub; ++i)  --> Increasing\n    /// - for (int i = ub; i > 0; --i)  --> Descresing\n    /// - for (int i = x; i != y; i+=z) --> Unknown\n    enum class Direction { Increasing, Decreasing, Unknown };\n\n    /// Get the direction of the loop.\n    Direction getDirection() const;\n\n  private:\n    LoopBounds(const Loop &Loop, Value &I, Instruction &SI, Value *SV, Value &F,\n               ScalarEvolution &SE)\n        : L(Loop), InitialIVValue(I), StepInst(SI), StepValue(SV),\n          FinalIVValue(F), SE(SE) {}\n\n    const Loop &L;\n\n    // The initial value of the loop induction variable\n    Value &InitialIVValue;\n\n    // The instruction that updates the loop induction variable\n    Instruction &StepInst;\n\n    // The value that the loop induction variable gets updated by in each loop\n    // iteration\n    Value *StepValue;\n\n    // The final value of the loop induction variable\n    Value &FinalIVValue;\n\n    ScalarEvolution &SE;\n  };\n\n  /// Return the struct LoopBounds collected if all struct members are found,\n  /// else None.\n  Optional<LoopBounds> getBounds(ScalarEvolution &SE) const;\n\n  /// Return the loop induction variable if found, else return nullptr.\n  /// An instruction is considered as the loop induction variable if\n  /// - it is an induction variable of the loop; and\n  /// - it is used to determine the condition of the branch in the loop latch\n  ///\n  /// Note: the induction variable doesn't need to be canonical, i.e. starts at\n  /// zero and increments by one each time through the loop (but it can be).\n  PHINode *getInductionVariable(ScalarEvolution &SE) const;\n\n  /// Get the loop induction descriptor for the loop induction variable. Return\n  /// true if the loop induction variable is found.\n  bool getInductionDescriptor(ScalarEvolution &SE,\n                              InductionDescriptor &IndDesc) const;\n\n  /// Return true if the given PHINode \\p AuxIndVar is\n  /// - in the loop header\n  /// - not used outside of the loop\n  /// - incremented by a loop invariant step for each loop iteration\n  /// - step instruction opcode should be add or sub\n  /// Note: auxiliary induction variable is not required to be used in the\n  ///       conditional branch in the loop latch. (but it can be)\n  bool isAuxiliaryInductionVariable(PHINode &AuxIndVar,\n                                    ScalarEvolution &SE) const;\n\n  /// Return the loop guard branch, if it exists.\n  ///\n  /// This currently only works on simplified loop, as it requires a preheader\n  /// and a latch to identify the guard. It will work on loops of the form:\n  /// \\code\n  /// GuardBB:\n  ///   br cond1, Preheader, ExitSucc <== GuardBranch\n  /// Preheader:\n  ///   br Header\n  /// Header:\n  ///  ...\n  ///   br Latch\n  /// Latch:\n  ///   br cond2, Header, ExitBlock\n  /// ExitBlock:\n  ///   br ExitSucc\n  /// ExitSucc:\n  /// \\endcode\n  BranchInst *getLoopGuardBranch() const;\n\n  /// Return true iff the loop is\n  /// - in simplify rotated form, and\n  /// - guarded by a loop guard branch.\n  bool isGuarded() const { return (getLoopGuardBranch() != nullptr); }\n\n  /// Return true if the loop is in rotated form.\n  ///\n  /// This does not check if the loop was rotated by loop rotation, instead it\n  /// only checks if the loop is in rotated form (has a valid latch that exists\n  /// the loop).\n  bool isRotatedForm() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    BasicBlock *Latch = getLoopLatch();\n    return Latch && isLoopExiting(Latch);\n  }\n\n  /// Return true if the loop induction variable starts at zero and increments\n  /// by one each time through the loop.\n  bool isCanonical(ScalarEvolution &SE) const;\n\n  /// Return true if the Loop is in LCSSA form.\n  bool isLCSSAForm(const DominatorTree &DT) const;\n\n  /// Return true if this Loop and all inner subloops are in LCSSA form.\n  bool isRecursivelyLCSSAForm(const DominatorTree &DT,\n                              const LoopInfo &LI) const;\n\n  /// Return true if the Loop is in the form that the LoopSimplify form\n  /// transforms loops to, which is sometimes called normal form.\n  bool isLoopSimplifyForm() const;\n\n  /// Return true if the loop body is safe to clone in practice.\n  bool isSafeToClone() const;\n\n  /// Returns true if the loop is annotated parallel.\n  ///\n  /// A parallel loop can be assumed to not contain any dependencies between\n  /// iterations by the compiler. That is, any loop-carried dependency checking\n  /// can be skipped completely when parallelizing the loop on the target\n  /// machine. Thus, if the parallel loop information originates from the\n  /// programmer, e.g. via the OpenMP parallel for pragma, it is the\n  /// programmer's responsibility to ensure there are no loop-carried\n  /// dependencies. The final execution order of the instructions across\n  /// iterations is not guaranteed, thus, the end result might or might not\n  /// implement actual concurrent execution of instructions across multiple\n  /// iterations.\n  bool isAnnotatedParallel() const;\n\n  /// Return the llvm.loop loop id metadata node for this loop if it is present.\n  ///\n  /// If this loop contains the same llvm.loop metadata on each branch to the\n  /// header then the node is returned. If any latch instruction does not\n  /// contain llvm.loop or if multiple latches contain different nodes then\n  /// 0 is returned.\n  MDNode *getLoopID() const;\n  /// Set the llvm.loop loop id metadata for this loop.\n  ///\n  /// The LoopID metadata node will be added to each terminator instruction in\n  /// the loop that branches to the loop header.\n  ///\n  /// The LoopID metadata node should have one or more operands and the first\n  /// operand should be the node itself.\n  void setLoopID(MDNode *LoopID) const;\n\n  /// Add llvm.loop.unroll.disable to this loop's loop id metadata.\n  ///\n  /// Remove existing unroll metadata and add unroll disable metadata to\n  /// indicate the loop has already been unrolled.  This prevents a loop\n  /// from being unrolled more than is directed by a pragma if the loop\n  /// unrolling pass is run more than once (which it generally is).\n  void setLoopAlreadyUnrolled();\n\n  /// Add llvm.loop.mustprogress to this loop's loop id metadata.\n  void setLoopMustProgress();\n\n  void dump() const;\n  void dumpVerbose() const;\n\n  /// Return the debug location of the start of this loop.\n  /// This looks for a BB terminating instruction with a known debug\n  /// location by looking at the preheader and header blocks. If it\n  /// cannot find a terminating instruction with location information,\n  /// it returns an unknown location.\n  DebugLoc getStartLoc() const;\n\n  /// Return the source code span of the loop.\n  LocRange getLocRange() const;\n\n  StringRef getName() const {\n    if (BasicBlock *Header = getHeader())\n      if (Header->hasName())\n        return Header->getName();\n    return \"<unnamed loop>\";\n  }\n\nprivate:\n  Loop() = default;\n\n  friend class LoopInfoBase<BasicBlock, Loop>;\n  friend class LoopBase<BasicBlock, Loop>;\n  explicit Loop(BasicBlock *BB) : LoopBase<BasicBlock, Loop>(BB) {}\n  ~Loop() = default;\n};\n\n//===----------------------------------------------------------------------===//\n/// This class builds and contains all of the top-level loop\n/// structures in the specified function.\n///\n\ntemplate <class BlockT, class LoopT> class LoopInfoBase {\n  // BBMap - Mapping of basic blocks to the inner most loop they occur in\n  DenseMap<const BlockT *, LoopT *> BBMap;\n  std::vector<LoopT *> TopLevelLoops;\n  BumpPtrAllocator LoopAllocator;\n\n  friend class LoopBase<BlockT, LoopT>;\n  friend class LoopInfo;\n\n  void operator=(const LoopInfoBase &) = delete;\n  LoopInfoBase(const LoopInfoBase &) = delete;\n\npublic:\n  LoopInfoBase() {}\n  ~LoopInfoBase() { releaseMemory(); }\n\n  LoopInfoBase(LoopInfoBase &&Arg)\n      : BBMap(std::move(Arg.BBMap)),\n        TopLevelLoops(std::move(Arg.TopLevelLoops)),\n        LoopAllocator(std::move(Arg.LoopAllocator)) {\n    // We have to clear the arguments top level loops as we've taken ownership.\n    Arg.TopLevelLoops.clear();\n  }\n  LoopInfoBase &operator=(LoopInfoBase &&RHS) {\n    BBMap = std::move(RHS.BBMap);\n\n    for (auto *L : TopLevelLoops)\n      L->~LoopT();\n\n    TopLevelLoops = std::move(RHS.TopLevelLoops);\n    LoopAllocator = std::move(RHS.LoopAllocator);\n    RHS.TopLevelLoops.clear();\n    return *this;\n  }\n\n  void releaseMemory() {\n    BBMap.clear();\n\n    for (auto *L : TopLevelLoops)\n      L->~LoopT();\n    TopLevelLoops.clear();\n    LoopAllocator.Reset();\n  }\n\n  template <typename... ArgsTy> LoopT *AllocateLoop(ArgsTy &&... Args) {\n    LoopT *Storage = LoopAllocator.Allocate<LoopT>();\n    return new (Storage) LoopT(std::forward<ArgsTy>(Args)...);\n  }\n\n  /// iterator/begin/end - The interface to the top-level loops in the current\n  /// function.\n  ///\n  typedef typename std::vector<LoopT *>::const_iterator iterator;\n  typedef\n      typename std::vector<LoopT *>::const_reverse_iterator reverse_iterator;\n  iterator begin() const { return TopLevelLoops.begin(); }\n  iterator end() const { return TopLevelLoops.end(); }\n  reverse_iterator rbegin() const { return TopLevelLoops.rbegin(); }\n  reverse_iterator rend() const { return TopLevelLoops.rend(); }\n  bool empty() const { return TopLevelLoops.empty(); }\n\n  /// Return all of the loops in the function in preorder across the loop\n  /// nests, with siblings in forward program order.\n  ///\n  /// Note that because loops form a forest of trees, preorder is equivalent to\n  /// reverse postorder.\n  SmallVector<LoopT *, 4> getLoopsInPreorder();\n\n  /// Return all of the loops in the function in preorder across the loop\n  /// nests, with siblings in *reverse* program order.\n  ///\n  /// Note that because loops form a forest of trees, preorder is equivalent to\n  /// reverse postorder.\n  ///\n  /// Also note that this is *not* a reverse preorder. Only the siblings are in\n  /// reverse program order.\n  SmallVector<LoopT *, 4> getLoopsInReverseSiblingPreorder();\n\n  /// Return the inner most loop that BB lives in. If a basic block is in no\n  /// loop (for example the entry node), null is returned.\n  LoopT *getLoopFor(const BlockT *BB) const { return BBMap.lookup(BB); }\n\n  /// Same as getLoopFor.\n  const LoopT *operator[](const BlockT *BB) const { return getLoopFor(BB); }\n\n  /// Return the loop nesting level of the specified block. A depth of 0 means\n  /// the block is not inside any loop.\n  unsigned getLoopDepth(const BlockT *BB) const {\n    const LoopT *L = getLoopFor(BB);\n    return L ? L->getLoopDepth() : 0;\n  }\n\n  // True if the block is a loop header node\n  bool isLoopHeader(const BlockT *BB) const {\n    const LoopT *L = getLoopFor(BB);\n    return L && L->getHeader() == BB;\n  }\n\n  /// Return the top-level loops.\n  const std::vector<LoopT *> &getTopLevelLoops() const { return TopLevelLoops; }\n\n  /// Return the top-level loops.\n  std::vector<LoopT *> &getTopLevelLoopsVector() { return TopLevelLoops; }\n\n  /// This removes the specified top-level loop from this loop info object.\n  /// The loop is not deleted, as it will presumably be inserted into\n  /// another loop.\n  LoopT *removeLoop(iterator I) {\n    assert(I != end() && \"Cannot remove end iterator!\");\n    LoopT *L = *I;\n    assert(L->isOutermost() && \"Not a top-level loop!\");\n    TopLevelLoops.erase(TopLevelLoops.begin() + (I - begin()));\n    return L;\n  }\n\n  /// Change the top-level loop that contains BB to the specified loop.\n  /// This should be used by transformations that restructure the loop hierarchy\n  /// tree.\n  void changeLoopFor(BlockT *BB, LoopT *L) {\n    if (!L) {\n      BBMap.erase(BB);\n      return;\n    }\n    BBMap[BB] = L;\n  }\n\n  /// Replace the specified loop in the top-level loops list with the indicated\n  /// loop.\n  void changeTopLevelLoop(LoopT *OldLoop, LoopT *NewLoop) {\n    auto I = find(TopLevelLoops, OldLoop);\n    assert(I != TopLevelLoops.end() && \"Old loop not at top level!\");\n    *I = NewLoop;\n    assert(!NewLoop->ParentLoop && !OldLoop->ParentLoop &&\n           \"Loops already embedded into a subloop!\");\n  }\n\n  /// This adds the specified loop to the collection of top-level loops.\n  void addTopLevelLoop(LoopT *New) {\n    assert(New->isOutermost() && \"Loop already in subloop!\");\n    TopLevelLoops.push_back(New);\n  }\n\n  /// This method completely removes BB from all data structures,\n  /// including all of the Loop objects it is nested in and our mapping from\n  /// BasicBlocks to loops.\n  void removeBlock(BlockT *BB) {\n    auto I = BBMap.find(BB);\n    if (I != BBMap.end()) {\n      for (LoopT *L = I->second; L; L = L->getParentLoop())\n        L->removeBlockFromLoop(BB);\n\n      BBMap.erase(I);\n    }\n  }\n\n  // Internals\n\n  static bool isNotAlreadyContainedIn(const LoopT *SubLoop,\n                                      const LoopT *ParentLoop) {\n    if (!SubLoop)\n      return true;\n    if (SubLoop == ParentLoop)\n      return false;\n    return isNotAlreadyContainedIn(SubLoop->getParentLoop(), ParentLoop);\n  }\n\n  /// Create the loop forest using a stable algorithm.\n  void analyze(const DominatorTreeBase<BlockT, false> &DomTree);\n\n  // Debugging\n  void print(raw_ostream &OS) const;\n\n  void verify(const DominatorTreeBase<BlockT, false> &DomTree) const;\n\n  /// Destroy a loop that has been removed from the `LoopInfo` nest.\n  ///\n  /// This runs the destructor of the loop object making it invalid to\n  /// reference afterward. The memory is retained so that the *pointer* to the\n  /// loop remains valid.\n  ///\n  /// The caller is responsible for removing this loop from the loop nest and\n  /// otherwise disconnecting it from the broader `LoopInfo` data structures.\n  /// Callers that don't naturally handle this themselves should probably call\n  /// `erase' instead.\n  void destroy(LoopT *L) {\n    L->~LoopT();\n\n    // Since LoopAllocator is a BumpPtrAllocator, this Deallocate only poisons\n    // \\c L, but the pointer remains valid for non-dereferencing uses.\n    LoopAllocator.Deallocate(L);\n  }\n};\n\n// Implementation in LoopInfoImpl.h\nextern template class LoopInfoBase<BasicBlock, Loop>;\n\nclass LoopInfo : public LoopInfoBase<BasicBlock, Loop> {\n  typedef LoopInfoBase<BasicBlock, Loop> BaseT;\n\n  friend class LoopBase<BasicBlock, Loop>;\n\n  void operator=(const LoopInfo &) = delete;\n  LoopInfo(const LoopInfo &) = delete;\n\npublic:\n  LoopInfo() {}\n  explicit LoopInfo(const DominatorTreeBase<BasicBlock, false> &DomTree);\n\n  LoopInfo(LoopInfo &&Arg) : BaseT(std::move(static_cast<BaseT &>(Arg))) {}\n  LoopInfo &operator=(LoopInfo &&RHS) {\n    BaseT::operator=(std::move(static_cast<BaseT &>(RHS)));\n    return *this;\n  }\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // Most of the public interface is provided via LoopInfoBase.\n\n  /// Update LoopInfo after removing the last backedge from a loop. This updates\n  /// the loop forest and parent loops for each block so that \\c L is no longer\n  /// referenced, but does not actually delete \\c L immediately. The pointer\n  /// will remain valid until this LoopInfo's memory is released.\n  void erase(Loop *L);\n\n  /// Returns true if replacing From with To everywhere is guaranteed to\n  /// preserve LCSSA form.\n  bool replacementPreservesLCSSAForm(Instruction *From, Value *To) {\n    // Preserving LCSSA form is only problematic if the replacing value is an\n    // instruction.\n    Instruction *I = dyn_cast<Instruction>(To);\n    if (!I)\n      return true;\n    // If both instructions are defined in the same basic block then replacement\n    // cannot break LCSSA form.\n    if (I->getParent() == From->getParent())\n      return true;\n    // If the instruction is not defined in a loop then it can safely replace\n    // anything.\n    Loop *ToLoop = getLoopFor(I->getParent());\n    if (!ToLoop)\n      return true;\n    // If the replacing instruction is defined in the same loop as the original\n    // instruction, or in a loop that contains it as an inner loop, then using\n    // it as a replacement will not break LCSSA form.\n    return ToLoop->contains(getLoopFor(From->getParent()));\n  }\n\n  /// Checks if moving a specific instruction can break LCSSA in any loop.\n  ///\n  /// Return true if moving \\p Inst to before \\p NewLoc will break LCSSA,\n  /// assuming that the function containing \\p Inst and \\p NewLoc is currently\n  /// in LCSSA form.\n  bool movementPreservesLCSSAForm(Instruction *Inst, Instruction *NewLoc) {\n    assert(Inst->getFunction() == NewLoc->getFunction() &&\n           \"Can't reason about IPO!\");\n\n    auto *OldBB = Inst->getParent();\n    auto *NewBB = NewLoc->getParent();\n\n    // Movement within the same loop does not break LCSSA (the equality check is\n    // to avoid doing a hashtable lookup in case of intra-block movement).\n    if (OldBB == NewBB)\n      return true;\n\n    auto *OldLoop = getLoopFor(OldBB);\n    auto *NewLoop = getLoopFor(NewBB);\n\n    if (OldLoop == NewLoop)\n      return true;\n\n    // Check if Outer contains Inner; with the null loop counting as the\n    // \"outermost\" loop.\n    auto Contains = [](const Loop *Outer, const Loop *Inner) {\n      return !Outer || Outer->contains(Inner);\n    };\n\n    // To check that the movement of Inst to before NewLoc does not break LCSSA,\n    // we need to check two sets of uses for possible LCSSA violations at\n    // NewLoc: the users of NewInst, and the operands of NewInst.\n\n    // If we know we're hoisting Inst out of an inner loop to an outer loop,\n    // then the uses *of* Inst don't need to be checked.\n\n    if (!Contains(NewLoop, OldLoop)) {\n      for (Use &U : Inst->uses()) {\n        auto *UI = cast<Instruction>(U.getUser());\n        auto *UBB = isa<PHINode>(UI) ? cast<PHINode>(UI)->getIncomingBlock(U)\n                                     : UI->getParent();\n        if (UBB != NewBB && getLoopFor(UBB) != NewLoop)\n          return false;\n      }\n    }\n\n    // If we know we're sinking Inst from an outer loop into an inner loop, then\n    // the *operands* of Inst don't need to be checked.\n\n    if (!Contains(OldLoop, NewLoop)) {\n      // See below on why we can't handle phi nodes here.\n      if (isa<PHINode>(Inst))\n        return false;\n\n      for (Use &U : Inst->operands()) {\n        auto *DefI = dyn_cast<Instruction>(U.get());\n        if (!DefI)\n          return false;\n\n        // This would need adjustment if we allow Inst to be a phi node -- the\n        // new use block won't simply be NewBB.\n\n        auto *DefBlock = DefI->getParent();\n        if (DefBlock != NewBB && getLoopFor(DefBlock) != NewLoop)\n          return false;\n      }\n    }\n\n    return true;\n  }\n};\n\n// Allow clients to walk the list of nested loops...\ntemplate <> struct GraphTraits<const Loop *> {\n  typedef const Loop *NodeRef;\n  typedef LoopInfo::iterator ChildIteratorType;\n\n  static NodeRef getEntryNode(const Loop *L) { return L; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->end(); }\n};\n\ntemplate <> struct GraphTraits<Loop *> {\n  typedef Loop *NodeRef;\n  typedef LoopInfo::iterator ChildIteratorType;\n\n  static NodeRef getEntryNode(Loop *L) { return L; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->end(); }\n};\n\n/// Analysis pass that exposes the \\c LoopInfo for a function.\nclass LoopAnalysis : public AnalysisInfoMixin<LoopAnalysis> {\n  friend AnalysisInfoMixin<LoopAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  typedef LoopInfo Result;\n\n  LoopInfo run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c LoopAnalysis results.\nclass LoopPrinterPass : public PassInfoMixin<LoopPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit LoopPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c LoopAnalysis results.\nstruct LoopVerifierPass : public PassInfoMixin<LoopVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// The legacy pass manager's analysis pass to compute loop information.\nclass LoopInfoWrapperPass : public FunctionPass {\n  LoopInfo LI;\n\npublic:\n  static char ID; // Pass identification, replacement for typeid\n\n  LoopInfoWrapperPass();\n\n  LoopInfo &getLoopInfo() { return LI; }\n  const LoopInfo &getLoopInfo() const { return LI; }\n\n  /// Calculate the natural loop information for a given function.\n  bool runOnFunction(Function &F) override;\n\n  void verifyAnalysis() const override;\n\n  void releaseMemory() override { LI.releaseMemory(); }\n\n  void print(raw_ostream &O, const Module *M = nullptr) const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n/// Function to print a loop's contents as LLVM's text IR assembly.\nvoid printLoop(Loop &L, raw_ostream &OS, const std::string &Banner = \"\");\n\n/// Find and return the loop attribute node for the attribute @p Name in\n/// @p LoopID. Return nullptr if there is no such attribute.\nMDNode *findOptionMDForLoopID(MDNode *LoopID, StringRef Name);\n\n/// Find string metadata for a loop.\n///\n/// Returns the MDNode where the first operand is the metadata's name. The\n/// following operands are the metadata's values. If no metadata with @p Name is\n/// found, return nullptr.\nMDNode *findOptionMDForLoop(const Loop *TheLoop, StringRef Name);\n\n/// Return whether an MDNode might represent an access group.\n///\n/// Access group metadata nodes have to be distinct and empty. Being\n/// always-empty ensures that it never needs to be changed (which -- because\n/// MDNodes are designed immutable -- would require creating a new MDNode). Note\n/// that this is not a sufficient condition: not every distinct and empty NDNode\n/// is representing an access group.\nbool isValidAsAccessGroup(MDNode *AccGroup);\n\n/// Create a new LoopID after the loop has been transformed.\n///\n/// This can be used when no follow-up loop attributes are defined\n/// (llvm::makeFollowupLoopID returning None) to stop transformations to be\n/// applied again.\n///\n/// @param Context        The LLVMContext in which to create the new LoopID.\n/// @param OrigLoopID     The original LoopID; can be nullptr if the original\n///                       loop has no LoopID.\n/// @param RemovePrefixes Remove all loop attributes that have these prefixes.\n///                       Use to remove metadata of the transformation that has\n///                       been applied.\n/// @param AddAttrs       Add these loop attributes to the new LoopID.\n///\n/// @return A new LoopID that can be applied using Loop::setLoopID().\nllvm::MDNode *\nmakePostTransformationMetadata(llvm::LLVMContext &Context, MDNode *OrigLoopID,\n                               llvm::ArrayRef<llvm::StringRef> RemovePrefixes,\n                               llvm::ArrayRef<llvm::MDNode *> AddAttrs);\n\n} // End llvm namespace\n\n#endif\n"}, "27": {"id": 27, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "content": "//===- RegionInfo.h - SESE region analysis ----------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Calculate a program structure tree built out of single entry single exit\n// regions.\n// The basic ideas are taken from \"The Program Structure Tree - Richard Johnson,\n// David Pearson, Keshav Pingali - 1994\", however enriched with ideas from \"The\n// Refined Process Structure Tree - Jussi Vanhatalo, Hagen Voelyer, Jana\n// Koehler - 2009\".\n// The algorithm to calculate these data structures however is completely\n// different, as it takes advantage of existing information already available\n// in (Post)dominace tree and dominance frontier passes. This leads to a simpler\n// and in practice hopefully better performing algorithm. The runtime of the\n// algorithms described in the papers above are both linear in graph size,\n// O(V+E), whereas this algorithm is not, as the dominance frontier information\n// itself is not, but in practice runtime seems to be in the order of magnitude\n// of dominance tree calculation.\n//\n// WARNING: LLVM is generally very concerned about compile time such that\n//          the use of additional analysis passes in the default\n//          optimization sequence is avoided as much as possible.\n//          Specifically, if you do not need the RegionInfo, but dominance\n//          information could be sufficient please base your work only on\n//          the dominator tree. Most passes maintain it, such that using\n//          it has often near zero cost. In contrast RegionInfo is by\n//          default not available, is not maintained by existing\n//          transformations and there is no intention to do so.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_REGIONINFO_H\n#define LLVM_ANALYSIS_REGIONINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DepthFirstIterator.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Config/llvm-config.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <algorithm>\n#include <cassert>\n#include <map>\n#include <memory>\n#include <set>\n#include <string>\n#include <type_traits>\n#include <vector>\n\nnamespace llvm {\n\nclass DominanceFrontier;\nclass Loop;\nclass LoopInfo;\nclass PostDominatorTree;\nclass Region;\ntemplate <class RegionTr> class RegionBase;\nclass RegionInfo;\ntemplate <class RegionTr> class RegionInfoBase;\nclass RegionNode;\n\n// Class to be specialized for different users of RegionInfo\n// (i.e. BasicBlocks or MachineBasicBlocks). This is only to avoid needing to\n// pass around an unreasonable number of template parameters.\ntemplate <class FuncT_>\nstruct RegionTraits {\n  // FuncT\n  // BlockT\n  // RegionT\n  // RegionNodeT\n  // RegionInfoT\n  using BrokenT = typename FuncT_::UnknownRegionTypeError;\n};\n\ntemplate <>\nstruct RegionTraits<Function> {\n  using FuncT = Function;\n  using BlockT = BasicBlock;\n  using RegionT = Region;\n  using RegionNodeT = RegionNode;\n  using RegionInfoT = RegionInfo;\n  using DomTreeT = DominatorTree;\n  using DomTreeNodeT = DomTreeNode;\n  using DomFrontierT = DominanceFrontier;\n  using PostDomTreeT = PostDominatorTree;\n  using InstT = Instruction;\n  using LoopT = Loop;\n  using LoopInfoT = LoopInfo;\n\n  static unsigned getNumSuccessors(BasicBlock *BB) {\n    return BB->getTerminator()->getNumSuccessors();\n  }\n};\n\n/// Marker class to iterate over the elements of a Region in flat mode.\n///\n/// The class is used to either iterate in Flat mode or by not using it to not\n/// iterate in Flat mode.  During a Flat mode iteration all Regions are entered\n/// and the iteration returns every BasicBlock.  If the Flat mode is not\n/// selected for SubRegions just one RegionNode containing the subregion is\n/// returned.\ntemplate <class GraphType>\nclass FlatIt {};\n\n/// A RegionNode represents a subregion or a BasicBlock that is part of a\n/// Region.\ntemplate <class Tr>\nclass RegionNodeBase {\n  friend class RegionBase<Tr>;\n\npublic:\n  using BlockT = typename Tr::BlockT;\n  using RegionT = typename Tr::RegionT;\n\nprivate:\n  /// This is the entry basic block that starts this region node.  If this is a\n  /// BasicBlock RegionNode, then entry is just the basic block, that this\n  /// RegionNode represents.  Otherwise it is the entry of this (Sub)RegionNode.\n  ///\n  /// In the BBtoRegionNode map of the parent of this node, BB will always map\n  /// to this node no matter which kind of node this one is.\n  ///\n  /// The node can hold either a Region or a BasicBlock.\n  /// Use one bit to save, if this RegionNode is a subregion or BasicBlock\n  /// RegionNode.\n  PointerIntPair<BlockT *, 1, bool> entry;\n\n  /// The parent Region of this RegionNode.\n  /// @see getParent()\n  RegionT *parent;\n\nprotected:\n  /// Create a RegionNode.\n  ///\n  /// @param Parent      The parent of this RegionNode.\n  /// @param Entry       The entry BasicBlock of the RegionNode.  If this\n  ///                    RegionNode represents a BasicBlock, this is the\n  ///                    BasicBlock itself.  If it represents a subregion, this\n  ///                    is the entry BasicBlock of the subregion.\n  /// @param isSubRegion If this RegionNode represents a SubRegion.\n  inline RegionNodeBase(RegionT *Parent, BlockT *Entry,\n                        bool isSubRegion = false)\n      : entry(Entry, isSubRegion), parent(Parent) {}\n\npublic:\n  RegionNodeBase(const RegionNodeBase &) = delete;\n  RegionNodeBase &operator=(const RegionNodeBase &) = delete;\n\n  /// Get the parent Region of this RegionNode.\n  ///\n  /// The parent Region is the Region this RegionNode belongs to. If for\n  /// example a BasicBlock is element of two Regions, there exist two\n  /// RegionNodes for this BasicBlock. Each with the getParent() function\n  /// pointing to the Region this RegionNode belongs to.\n  ///\n  /// @return Get the parent Region of this RegionNode.\n  inline RegionT *getParent() const { return parent; }\n\n  /// Get the entry BasicBlock of this RegionNode.\n  ///\n  /// If this RegionNode represents a BasicBlock this is just the BasicBlock\n  /// itself, otherwise we return the entry BasicBlock of the Subregion\n  ///\n  /// @return The entry BasicBlock of this RegionNode.\n  inline BlockT *getEntry() const { return entry.getPointer(); }\n\n  /// Get the content of this RegionNode.\n  ///\n  /// This can be either a BasicBlock or a subregion. Before calling getNodeAs()\n  /// check the type of the content with the isSubRegion() function call.\n  ///\n  /// @return The content of this RegionNode.\n  template <class T> inline T *getNodeAs() const;\n\n  /// Is this RegionNode a subregion?\n  ///\n  /// @return True if it contains a subregion. False if it contains a\n  ///         BasicBlock.\n  inline bool isSubRegion() const { return entry.getInt(); }\n};\n\n//===----------------------------------------------------------------------===//\n/// A single entry single exit Region.\n///\n/// A Region is a connected subgraph of a control flow graph that has exactly\n/// two connections to the remaining graph. It can be used to analyze or\n/// optimize parts of the control flow graph.\n///\n/// A <em> simple Region </em> is connected to the remaining graph by just two\n/// edges. One edge entering the Region and another one leaving the Region.\n///\n/// An <em> extended Region </em> (or just Region) is a subgraph that can be\n/// transform into a simple Region. The transformation is done by adding\n/// BasicBlocks that merge several entry or exit edges so that after the merge\n/// just one entry and one exit edge exists.\n///\n/// The \\e Entry of a Region is the first BasicBlock that is passed after\n/// entering the Region. It is an element of the Region. The entry BasicBlock\n/// dominates all BasicBlocks in the Region.\n///\n/// The \\e Exit of a Region is the first BasicBlock that is passed after\n/// leaving the Region. It is not an element of the Region. The exit BasicBlock,\n/// postdominates all BasicBlocks in the Region.\n///\n/// A <em> canonical Region </em> cannot be constructed by combining smaller\n/// Regions.\n///\n/// Region A is the \\e parent of Region B, if B is completely contained in A.\n///\n/// Two canonical Regions either do not intersect at all or one is\n/// the parent of the other.\n///\n/// The <em> Program Structure Tree</em> is a graph (V, E) where V is the set of\n/// Regions in the control flow graph and E is the \\e parent relation of these\n/// Regions.\n///\n/// Example:\n///\n/// \\verbatim\n/// A simple control flow graph, that contains two regions.\n///\n///        1\n///       / |\n///      2   |\n///     / \\   3\n///    4   5  |\n///    |   |  |\n///    6   7  8\n///     \\  | /\n///      \\ |/       Region A: 1 -> 9 {1,2,3,4,5,6,7,8}\n///        9        Region B: 2 -> 9 {2,4,5,6,7}\n/// \\endverbatim\n///\n/// You can obtain more examples by either calling\n///\n/// <tt> \"opt -regions -analyze anyprogram.ll\" </tt>\n/// or\n/// <tt> \"opt -view-regions-only anyprogram.ll\" </tt>\n///\n/// on any LLVM file you are interested in.\n///\n/// The first call returns a textual representation of the program structure\n/// tree, the second one creates a graphical representation using graphviz.\ntemplate <class Tr>\nclass RegionBase : public RegionNodeBase<Tr> {\n  friend class RegionInfoBase<Tr>;\n\n  using FuncT = typename Tr::FuncT;\n  using BlockT = typename Tr::BlockT;\n  using RegionInfoT = typename Tr::RegionInfoT;\n  using RegionT = typename Tr::RegionT;\n  using RegionNodeT = typename Tr::RegionNodeT;\n  using DomTreeT = typename Tr::DomTreeT;\n  using LoopT = typename Tr::LoopT;\n  using LoopInfoT = typename Tr::LoopInfoT;\n  using InstT = typename Tr::InstT;\n\n  using BlockTraits = GraphTraits<BlockT *>;\n  using InvBlockTraits = GraphTraits<Inverse<BlockT *>>;\n  using SuccIterTy = typename BlockTraits::ChildIteratorType;\n  using PredIterTy = typename InvBlockTraits::ChildIteratorType;\n\n  // Information necessary to manage this Region.\n  RegionInfoT *RI;\n  DomTreeT *DT;\n\n  // The exit BasicBlock of this region.\n  // (The entry BasicBlock is part of RegionNode)\n  BlockT *exit;\n\n  using RegionSet = std::vector<std::unique_ptr<RegionT>>;\n\n  // The subregions of this region.\n  RegionSet children;\n\n  using BBNodeMapT = std::map<BlockT *, std::unique_ptr<RegionNodeT>>;\n\n  // Save the BasicBlock RegionNodes that are element of this Region.\n  mutable BBNodeMapT BBNodeMap;\n\n  /// Check if a BB is in this Region. This check also works\n  /// if the region is incorrectly built. (EXPENSIVE!)\n  void verifyBBInRegion(BlockT *BB) const;\n\n  /// Walk over all the BBs of the region starting from BB and\n  /// verify that all reachable basic blocks are elements of the region.\n  /// (EXPENSIVE!)\n  void verifyWalk(BlockT *BB, std::set<BlockT *> *visitedBB) const;\n\n  /// Verify if the region and its children are valid regions (EXPENSIVE!)\n  void verifyRegionNest() const;\n\npublic:\n  /// Create a new region.\n  ///\n  /// @param Entry  The entry basic block of the region.\n  /// @param Exit   The exit basic block of the region.\n  /// @param RI     The region info object that is managing this region.\n  /// @param DT     The dominator tree of the current function.\n  /// @param Parent The surrounding region or NULL if this is a top level\n  ///               region.\n  RegionBase(BlockT *Entry, BlockT *Exit, RegionInfoT *RI, DomTreeT *DT,\n             RegionT *Parent = nullptr);\n\n  RegionBase(const RegionBase &) = delete;\n  RegionBase &operator=(const RegionBase &) = delete;\n\n  /// Delete the Region and all its subregions.\n  ~RegionBase();\n\n  /// Get the entry BasicBlock of the Region.\n  /// @return The entry BasicBlock of the region.\n  BlockT *getEntry() const {\n    return RegionNodeBase<Tr>::getEntry();\n  }\n\n  /// Replace the entry basic block of the region with the new basic\n  ///        block.\n  ///\n  /// @param BB  The new entry basic block of the region.\n  void replaceEntry(BlockT *BB);\n\n  /// Replace the exit basic block of the region with the new basic\n  ///        block.\n  ///\n  /// @param BB  The new exit basic block of the region.\n  void replaceExit(BlockT *BB);\n\n  /// Recursively replace the entry basic block of the region.\n  ///\n  /// This function replaces the entry basic block with a new basic block. It\n  /// also updates all child regions that have the same entry basic block as\n  /// this region.\n  ///\n  /// @param NewEntry The new entry basic block.\n  void replaceEntryRecursive(BlockT *NewEntry);\n\n  /// Recursively replace the exit basic block of the region.\n  ///\n  /// This function replaces the exit basic block with a new basic block. It\n  /// also updates all child regions that have the same exit basic block as\n  /// this region.\n  ///\n  /// @param NewExit The new exit basic block.\n  void replaceExitRecursive(BlockT *NewExit);\n\n  /// Get the exit BasicBlock of the Region.\n  /// @return The exit BasicBlock of the Region, NULL if this is the TopLevel\n  ///         Region.\n  BlockT *getExit() const { return exit; }\n\n  /// Get the parent of the Region.\n  /// @return The parent of the Region or NULL if this is a top level\n  ///         Region.\n  RegionT *getParent() const {\n    return RegionNodeBase<Tr>::getParent();\n  }\n\n  /// Get the RegionNode representing the current Region.\n  /// @return The RegionNode representing the current Region.\n  RegionNodeT *getNode() const {\n    return const_cast<RegionNodeT *>(\n        reinterpret_cast<const RegionNodeT *>(this));\n  }\n\n  /// Get the nesting level of this Region.\n  ///\n  /// An toplevel Region has depth 0.\n  ///\n  /// @return The depth of the region.\n  unsigned getDepth() const;\n\n  /// Check if a Region is the TopLevel region.\n  ///\n  /// The toplevel region represents the whole function.\n  bool isTopLevelRegion() const { return exit == nullptr; }\n\n  /// Return a new (non-canonical) region, that is obtained by joining\n  ///        this region with its predecessors.\n  ///\n  /// @return A region also starting at getEntry(), but reaching to the next\n  ///         basic block that forms with getEntry() a (non-canonical) region.\n  ///         NULL if such a basic block does not exist.\n  RegionT *getExpandedRegion() const;\n\n  /// Return the first block of this region's single entry edge,\n  ///        if existing.\n  ///\n  /// @return The BasicBlock starting this region's single entry edge,\n  ///         else NULL.\n  BlockT *getEnteringBlock() const;\n\n  /// Return the first block of this region's single exit edge,\n  ///        if existing.\n  ///\n  /// @return The BasicBlock starting this region's single exit edge,\n  ///         else NULL.\n  BlockT *getExitingBlock() const;\n\n  /// Collect all blocks of this region's single exit edge, if existing.\n  ///\n  /// @return True if this region contains all the predecessors of the exit.\n  bool getExitingBlocks(SmallVectorImpl<BlockT *> &Exitings) const;\n\n  /// Is this a simple region?\n  ///\n  /// A region is simple if it has exactly one exit and one entry edge.\n  ///\n  /// @return True if the Region is simple.\n  bool isSimple() const;\n\n  /// Returns the name of the Region.\n  /// @return The Name of the Region.\n  std::string getNameStr() const;\n\n  /// Return the RegionInfo object, that belongs to this Region.\n  RegionInfoT *getRegionInfo() const { return RI; }\n\n  /// PrintStyle - Print region in difference ways.\n  enum PrintStyle { PrintNone, PrintBB, PrintRN };\n\n  /// Print the region.\n  ///\n  /// @param OS The output stream the Region is printed to.\n  /// @param printTree Print also the tree of subregions.\n  /// @param level The indentation level used for printing.\n  void print(raw_ostream &OS, bool printTree = true, unsigned level = 0,\n             PrintStyle Style = PrintNone) const;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print the region to stderr.\n  void dump() const;\n#endif\n\n  /// Check if the region contains a BasicBlock.\n  ///\n  /// @param BB The BasicBlock that might be contained in this Region.\n  /// @return True if the block is contained in the region otherwise false.\n  bool contains(const BlockT *BB) const;\n\n  /// Check if the region contains another region.\n  ///\n  /// @param SubRegion The region that might be contained in this Region.\n  /// @return True if SubRegion is contained in the region otherwise false.\n  bool contains(const RegionT *SubRegion) const {\n    // Toplevel Region.\n    if (!getExit())\n      return true;\n\n    return contains(SubRegion->getEntry()) &&\n           (contains(SubRegion->getExit()) ||\n            SubRegion->getExit() == getExit());\n  }\n\n  /// Check if the region contains an Instruction.\n  ///\n  /// @param Inst The Instruction that might be contained in this region.\n  /// @return True if the Instruction is contained in the region otherwise\n  /// false.\n  bool contains(const InstT *Inst) const { return contains(Inst->getParent()); }\n\n  /// Check if the region contains a loop.\n  ///\n  /// @param L The loop that might be contained in this region.\n  /// @return True if the loop is contained in the region otherwise false.\n  ///         In case a NULL pointer is passed to this function the result\n  ///         is false, except for the region that describes the whole function.\n  ///         In that case true is returned.\n  bool contains(const LoopT *L) const;\n\n  /// Get the outermost loop in the region that contains a loop.\n  ///\n  /// Find for a Loop L the outermost loop OuterL that is a parent loop of L\n  /// and is itself contained in the region.\n  ///\n  /// @param L The loop the lookup is started.\n  /// @return The outermost loop in the region, NULL if such a loop does not\n  ///         exist or if the region describes the whole function.\n  LoopT *outermostLoopInRegion(LoopT *L) const;\n\n  /// Get the outermost loop in the region that contains a basic block.\n  ///\n  /// Find for a basic block BB the outermost loop L that contains BB and is\n  /// itself contained in the region.\n  ///\n  /// @param LI A pointer to a LoopInfo analysis.\n  /// @param BB The basic block surrounded by the loop.\n  /// @return The outermost loop in the region, NULL if such a loop does not\n  ///         exist or if the region describes the whole function.\n  LoopT *outermostLoopInRegion(LoopInfoT *LI, BlockT *BB) const;\n\n  /// Get the subregion that starts at a BasicBlock\n  ///\n  /// @param BB The BasicBlock the subregion should start.\n  /// @return The Subregion if available, otherwise NULL.\n  RegionT *getSubRegionNode(BlockT *BB) const;\n\n  /// Get the RegionNode for a BasicBlock\n  ///\n  /// @param BB The BasicBlock at which the RegionNode should start.\n  /// @return If available, the RegionNode that represents the subregion\n  ///         starting at BB. If no subregion starts at BB, the RegionNode\n  ///         representing BB.\n  RegionNodeT *getNode(BlockT *BB) const;\n\n  /// Get the BasicBlock RegionNode for a BasicBlock\n  ///\n  /// @param BB The BasicBlock for which the RegionNode is requested.\n  /// @return The RegionNode representing the BB.\n  RegionNodeT *getBBNode(BlockT *BB) const;\n\n  /// Add a new subregion to this Region.\n  ///\n  /// @param SubRegion The new subregion that will be added.\n  /// @param moveChildren Move the children of this region, that are also\n  ///                     contained in SubRegion into SubRegion.\n  void addSubRegion(RegionT *SubRegion, bool moveChildren = false);\n\n  /// Remove a subregion from this Region.\n  ///\n  /// The subregion is not deleted, as it will probably be inserted into another\n  /// region.\n  /// @param SubRegion The SubRegion that will be removed.\n  RegionT *removeSubRegion(RegionT *SubRegion);\n\n  /// Move all direct child nodes of this Region to another Region.\n  ///\n  /// @param To The Region the child nodes will be transferred to.\n  void transferChildrenTo(RegionT *To);\n\n  /// Verify if the region is a correct region.\n  ///\n  /// Check if this is a correctly build Region. This is an expensive check, as\n  /// the complete CFG of the Region will be walked.\n  void verifyRegion() const;\n\n  /// Clear the cache for BB RegionNodes.\n  ///\n  /// After calling this function the BasicBlock RegionNodes will be stored at\n  /// different memory locations. RegionNodes obtained before this function is\n  /// called are therefore not comparable to RegionNodes abtained afterwords.\n  void clearNodeCache();\n\n  /// @name Subregion Iterators\n  ///\n  /// These iterators iterator over all subregions of this Region.\n  //@{\n  using iterator = typename RegionSet::iterator;\n  using const_iterator = typename RegionSet::const_iterator;\n\n  iterator begin() { return children.begin(); }\n  iterator end() { return children.end(); }\n\n  const_iterator begin() const { return children.begin(); }\n  const_iterator end() const { return children.end(); }\n  //@}\n\n  /// @name BasicBlock Iterators\n  ///\n  /// These iterators iterate over all BasicBlocks that are contained in this\n  /// Region. The iterator also iterates over BasicBlocks that are elements of\n  /// a subregion of this Region. It is therefore called a flat iterator.\n  //@{\n  template <bool IsConst>\n  class block_iterator_wrapper\n      : public df_iterator<\n            std::conditional_t<IsConst, const BlockT, BlockT> *> {\n    using super =\n        df_iterator<std::conditional_t<IsConst, const BlockT, BlockT> *>;\n\n  public:\n    using Self = block_iterator_wrapper<IsConst>;\n    using value_type = typename super::value_type;\n\n    // Construct the begin iterator.\n    block_iterator_wrapper(value_type Entry, value_type Exit)\n        : super(df_begin(Entry)) {\n      // Mark the exit of the region as visited, so that the children of the\n      // exit and the exit itself, i.e. the block outside the region will never\n      // be visited.\n      super::Visited.insert(Exit);\n    }\n\n    // Construct the end iterator.\n    block_iterator_wrapper() : super(df_end<value_type>((BlockT *)nullptr)) {}\n\n    /*implicit*/ block_iterator_wrapper(super I) : super(I) {}\n\n    // FIXME: Even a const_iterator returns a non-const BasicBlock pointer.\n    //        This was introduced for backwards compatibility, but should\n    //        be removed as soon as all users are fixed.\n    BlockT *operator*() const {\n      return const_cast<BlockT *>(super::operator*());\n    }\n  };\n\n  using block_iterator = block_iterator_wrapper<false>;\n  using const_block_iterator = block_iterator_wrapper<true>;\n\n  block_iterator block_begin() { return block_iterator(getEntry(), getExit()); }\n\n  block_iterator block_end() { return block_iterator(); }\n\n  const_block_iterator block_begin() const {\n    return const_block_iterator(getEntry(), getExit());\n  }\n  const_block_iterator block_end() const { return const_block_iterator(); }\n\n  using block_range = iterator_range<block_iterator>;\n  using const_block_range = iterator_range<const_block_iterator>;\n\n  /// Returns a range view of the basic blocks in the region.\n  inline block_range blocks() {\n    return block_range(block_begin(), block_end());\n  }\n\n  /// Returns a range view of the basic blocks in the region.\n  ///\n  /// This is the 'const' version of the range view.\n  inline const_block_range blocks() const {\n    return const_block_range(block_begin(), block_end());\n  }\n  //@}\n\n  /// @name Element Iterators\n  ///\n  /// These iterators iterate over all BasicBlock and subregion RegionNodes that\n  /// are direct children of this Region. It does not iterate over any\n  /// RegionNodes that are also element of a subregion of this Region.\n  //@{\n  using element_iterator =\n      df_iterator<RegionNodeT *, df_iterator_default_set<RegionNodeT *>, false,\n                  GraphTraits<RegionNodeT *>>;\n\n  using const_element_iterator =\n      df_iterator<const RegionNodeT *,\n                  df_iterator_default_set<const RegionNodeT *>, false,\n                  GraphTraits<const RegionNodeT *>>;\n\n  element_iterator element_begin();\n  element_iterator element_end();\n  iterator_range<element_iterator> elements() {\n    return make_range(element_begin(), element_end());\n  }\n\n  const_element_iterator element_begin() const;\n  const_element_iterator element_end() const;\n  iterator_range<const_element_iterator> elements() const {\n    return make_range(element_begin(), element_end());\n  }\n  //@}\n};\n\n/// Print a RegionNode.\ntemplate <class Tr>\ninline raw_ostream &operator<<(raw_ostream &OS, const RegionNodeBase<Tr> &Node);\n\n//===----------------------------------------------------------------------===//\n/// Analysis that detects all canonical Regions.\n///\n/// The RegionInfo pass detects all canonical regions in a function. The Regions\n/// are connected using the parent relation. This builds a Program Structure\n/// Tree.\ntemplate <class Tr>\nclass RegionInfoBase {\n  friend class RegionInfo;\n  friend class MachineRegionInfo;\n\n  using BlockT = typename Tr::BlockT;\n  using FuncT = typename Tr::FuncT;\n  using RegionT = typename Tr::RegionT;\n  using RegionInfoT = typename Tr::RegionInfoT;\n  using DomTreeT = typename Tr::DomTreeT;\n  using DomTreeNodeT = typename Tr::DomTreeNodeT;\n  using PostDomTreeT = typename Tr::PostDomTreeT;\n  using DomFrontierT = typename Tr::DomFrontierT;\n  using BlockTraits = GraphTraits<BlockT *>;\n  using InvBlockTraits = GraphTraits<Inverse<BlockT *>>;\n  using SuccIterTy = typename BlockTraits::ChildIteratorType;\n  using PredIterTy = typename InvBlockTraits::ChildIteratorType;\n\n  using BBtoBBMap = DenseMap<BlockT *, BlockT *>;\n  using BBtoRegionMap = DenseMap<BlockT *, RegionT *>;\n\n  RegionInfoBase();\n\n  RegionInfoBase(RegionInfoBase &&Arg)\n    : DT(std::move(Arg.DT)), PDT(std::move(Arg.PDT)), DF(std::move(Arg.DF)),\n      TopLevelRegion(std::move(Arg.TopLevelRegion)),\n      BBtoRegion(std::move(Arg.BBtoRegion)) {\n    Arg.wipe();\n  }\n\n  RegionInfoBase &operator=(RegionInfoBase &&RHS) {\n    DT = std::move(RHS.DT);\n    PDT = std::move(RHS.PDT);\n    DF = std::move(RHS.DF);\n    TopLevelRegion = std::move(RHS.TopLevelRegion);\n    BBtoRegion = std::move(RHS.BBtoRegion);\n    RHS.wipe();\n    return *this;\n  }\n\n  virtual ~RegionInfoBase();\n\n  DomTreeT *DT;\n  PostDomTreeT *PDT;\n  DomFrontierT *DF;\n\n  /// The top level region.\n  RegionT *TopLevelRegion = nullptr;\n\n  /// Map every BB to the smallest region, that contains BB.\n  BBtoRegionMap BBtoRegion;\n\nprotected:\n  /// Update refences to a RegionInfoT held by the RegionT managed here\n  ///\n  /// This is a post-move helper. Regions hold references to the owning\n  /// RegionInfo object. After a move these need to be fixed.\n  template<typename TheRegionT>\n  void updateRegionTree(RegionInfoT &RI, TheRegionT *R) {\n    if (!R)\n      return;\n    R->RI = &RI;\n    for (auto &SubR : *R)\n      updateRegionTree(RI, SubR.get());\n  }\n\nprivate:\n  /// Wipe this region tree's state without releasing any resources.\n  ///\n  /// This is essentially a post-move helper only. It leaves the object in an\n  /// assignable and destroyable state, but otherwise invalid.\n  void wipe() {\n    DT = nullptr;\n    PDT = nullptr;\n    DF = nullptr;\n    TopLevelRegion = nullptr;\n    BBtoRegion.clear();\n  }\n\n  // Check whether the entries of BBtoRegion for the BBs of region\n  // SR are correct. Triggers an assertion if not. Calls itself recursively for\n  // subregions.\n  void verifyBBMap(const RegionT *SR) const;\n\n  // Returns true if BB is in the dominance frontier of\n  // entry, because it was inherited from exit. In the other case there is an\n  // edge going from entry to BB without passing exit.\n  bool isCommonDomFrontier(BlockT *BB, BlockT *entry, BlockT *exit) const;\n\n  // Check if entry and exit surround a valid region, based on\n  // dominance tree and dominance frontier.\n  bool isRegion(BlockT *entry, BlockT *exit) const;\n\n  // Saves a shortcut pointing from entry to exit.\n  // This function may extend this shortcut if possible.\n  void insertShortCut(BlockT *entry, BlockT *exit, BBtoBBMap *ShortCut) const;\n\n  // Returns the next BB that postdominates N, while skipping\n  // all post dominators that cannot finish a canonical region.\n  DomTreeNodeT *getNextPostDom(DomTreeNodeT *N, BBtoBBMap *ShortCut) const;\n\n  // A region is trivial, if it contains only one BB.\n  bool isTrivialRegion(BlockT *entry, BlockT *exit) const;\n\n  // Creates a single entry single exit region.\n  RegionT *createRegion(BlockT *entry, BlockT *exit);\n\n  // Detect all regions starting with bb 'entry'.\n  void findRegionsWithEntry(BlockT *entry, BBtoBBMap *ShortCut);\n\n  // Detects regions in F.\n  void scanForRegions(FuncT &F, BBtoBBMap *ShortCut);\n\n  // Get the top most parent with the same entry block.\n  RegionT *getTopMostParent(RegionT *region);\n\n  // Build the region hierarchy after all region detected.\n  void buildRegionsTree(DomTreeNodeT *N, RegionT *region);\n\n  // Update statistic about created regions.\n  virtual void updateStatistics(RegionT *R) = 0;\n\n  // Detect all regions in function and build the region tree.\n  void calculate(FuncT &F);\n\npublic:\n  RegionInfoBase(const RegionInfoBase &) = delete;\n  RegionInfoBase &operator=(const RegionInfoBase &) = delete;\n\n  static bool VerifyRegionInfo;\n  static typename RegionT::PrintStyle printStyle;\n\n  void print(raw_ostream &OS) const;\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  void dump() const;\n#endif\n\n  void releaseMemory();\n\n  /// Get the smallest region that contains a BasicBlock.\n  ///\n  /// @param BB The basic block.\n  /// @return The smallest region, that contains BB or NULL, if there is no\n  /// region containing BB.\n  RegionT *getRegionFor(BlockT *BB) const;\n\n  ///  Set the smallest region that surrounds a basic block.\n  ///\n  /// @param BB The basic block surrounded by a region.\n  /// @param R The smallest region that surrounds BB.\n  void setRegionFor(BlockT *BB, RegionT *R);\n\n  /// A shortcut for getRegionFor().\n  ///\n  /// @param BB The basic block.\n  /// @return The smallest region, that contains BB or NULL, if there is no\n  /// region containing BB.\n  RegionT *operator[](BlockT *BB) const;\n\n  /// Return the exit of the maximal refined region, that starts at a\n  /// BasicBlock.\n  ///\n  /// @param BB The BasicBlock the refined region starts.\n  BlockT *getMaxRegionExit(BlockT *BB) const;\n\n  /// Find the smallest region that contains two regions.\n  ///\n  /// @param A The first region.\n  /// @param B The second region.\n  /// @return The smallest region containing A and B.\n  RegionT *getCommonRegion(RegionT *A, RegionT *B) const;\n\n  /// Find the smallest region that contains two basic blocks.\n  ///\n  /// @param A The first basic block.\n  /// @param B The second basic block.\n  /// @return The smallest region that contains A and B.\n  RegionT *getCommonRegion(BlockT *A, BlockT *B) const {\n    return getCommonRegion(getRegionFor(A), getRegionFor(B));\n  }\n\n  /// Find the smallest region that contains a set of regions.\n  ///\n  /// @param Regions A vector of regions.\n  /// @return The smallest region that contains all regions in Regions.\n  RegionT *getCommonRegion(SmallVectorImpl<RegionT *> &Regions) const;\n\n  /// Find the smallest region that contains a set of basic blocks.\n  ///\n  /// @param BBs A vector of basic blocks.\n  /// @return The smallest region that contains all basic blocks in BBS.\n  RegionT *getCommonRegion(SmallVectorImpl<BlockT *> &BBs) const;\n\n  RegionT *getTopLevelRegion() const { return TopLevelRegion; }\n\n  /// Clear the Node Cache for all Regions.\n  ///\n  /// @see Region::clearNodeCache()\n  void clearNodeCache() {\n    if (TopLevelRegion)\n      TopLevelRegion->clearNodeCache();\n  }\n\n  void verifyAnalysis() const;\n};\n\nclass RegionNode : public RegionNodeBase<RegionTraits<Function>> {\npublic:\n  inline RegionNode(Region *Parent, BasicBlock *Entry, bool isSubRegion = false)\n      : RegionNodeBase<RegionTraits<Function>>(Parent, Entry, isSubRegion) {}\n\n  bool operator==(const Region &RN) const {\n    return this == reinterpret_cast<const RegionNode *>(&RN);\n  }\n};\n\nclass Region : public RegionBase<RegionTraits<Function>> {\npublic:\n  Region(BasicBlock *Entry, BasicBlock *Exit, RegionInfo *RI, DominatorTree *DT,\n         Region *Parent = nullptr);\n  ~Region();\n\n  bool operator==(const RegionNode &RN) const {\n    return &RN == reinterpret_cast<const RegionNode *>(this);\n  }\n};\n\nclass RegionInfo : public RegionInfoBase<RegionTraits<Function>> {\npublic:\n  using Base = RegionInfoBase<RegionTraits<Function>>;\n\n  explicit RegionInfo();\n\n  RegionInfo(RegionInfo &&Arg) : Base(std::move(static_cast<Base &>(Arg))) {\n    updateRegionTree(*this, TopLevelRegion);\n  }\n\n  RegionInfo &operator=(RegionInfo &&RHS) {\n    Base::operator=(std::move(static_cast<Base &>(RHS)));\n    updateRegionTree(*this, TopLevelRegion);\n    return *this;\n  }\n\n  ~RegionInfo() override;\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // updateStatistics - Update statistic about created regions.\n  void updateStatistics(Region *R) final;\n\n  void recalculate(Function &F, DominatorTree *DT, PostDominatorTree *PDT,\n                   DominanceFrontier *DF);\n\n#ifndef NDEBUG\n  /// Opens a viewer to show the GraphViz visualization of the regions.\n  ///\n  /// Useful during debugging as an alternative to dump().\n  void view();\n\n  /// Opens a viewer to show the GraphViz visualization of this region\n  /// without instructions in the BasicBlocks.\n  ///\n  /// Useful during debugging as an alternative to dump().\n  void viewOnly();\n#endif\n};\n\nclass RegionInfoPass : public FunctionPass {\n  RegionInfo RI;\n\npublic:\n  static char ID;\n\n  explicit RegionInfoPass();\n  ~RegionInfoPass() override;\n\n  RegionInfo &getRegionInfo() { return RI; }\n\n  const RegionInfo &getRegionInfo() const { return RI; }\n\n  /// @name FunctionPass interface\n  //@{\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void verifyAnalysis() const override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  void print(raw_ostream &OS, const Module *) const override;\n  void dump() const;\n  //@}\n};\n\n/// Analysis pass that exposes the \\c RegionInfo for a function.\nclass RegionInfoAnalysis : public AnalysisInfoMixin<RegionInfoAnalysis> {\n  friend AnalysisInfoMixin<RegionInfoAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = RegionInfo;\n\n  RegionInfo run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c RegionInfo.\nclass RegionInfoPrinterPass : public PassInfoMixin<RegionInfoPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit RegionInfoPrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c RegionInfo.\nstruct RegionInfoVerifierPass : PassInfoMixin<RegionInfoVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\ntemplate <>\ntemplate <>\ninline BasicBlock *\nRegionNodeBase<RegionTraits<Function>>::getNodeAs<BasicBlock>() const {\n  assert(!isSubRegion() && \"This is not a BasicBlock RegionNode!\");\n  return getEntry();\n}\n\ntemplate <>\ntemplate <>\ninline Region *\nRegionNodeBase<RegionTraits<Function>>::getNodeAs<Region>() const {\n  assert(isSubRegion() && \"This is not a subregion RegionNode!\");\n  auto Unconst = const_cast<RegionNodeBase<RegionTraits<Function>> *>(this);\n  return reinterpret_cast<Region *>(Unconst);\n}\n\ntemplate <class Tr>\ninline raw_ostream &operator<<(raw_ostream &OS,\n                               const RegionNodeBase<Tr> &Node) {\n  using BlockT = typename Tr::BlockT;\n  using RegionT = typename Tr::RegionT;\n\n  if (Node.isSubRegion())\n    return OS << Node.template getNodeAs<RegionT>()->getNameStr();\n  else\n    return OS << Node.template getNodeAs<BlockT>()->getName();\n}\n\nextern template class RegionBase<RegionTraits<Function>>;\nextern template class RegionNodeBase<RegionTraits<Function>>;\nextern template class RegionInfoBase<RegionTraits<Function>>;\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_REGIONINFO_H\n"}, "28": {"id": 28, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionPass.h", "content": "//===- RegionPass.h - RegionPass class --------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the RegionPass class. All region based analysis,\n// optimization and transformation passes are derived from RegionPass.\n// This class is implemented following the some ideas of the LoopPass.h class.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_REGIONPASS_H\n#define LLVM_ANALYSIS_REGIONPASS_H\n\n#include \"llvm/Analysis/RegionInfo.h\"\n#include \"llvm/IR/LegacyPassManagers.h\"\n#include \"llvm/Pass.h\"\n#include <deque>\n\nnamespace llvm {\nclass Function;\nclass RGPassManager;\n\n//===----------------------------------------------------------------------===//\n/// A pass that runs on each Region in a function.\n///\n/// RegionPass is managed by RGPassManager.\nclass RegionPass : public Pass {\npublic:\n  explicit RegionPass(char &pid) : Pass(PT_Region, pid) {}\n\n  //===--------------------------------------------------------------------===//\n  /// @name To be implemented by every RegionPass\n  ///\n  //@{\n  /// Run the pass on a specific Region\n  ///\n  /// Accessing regions not contained in the current region is not allowed.\n  ///\n  /// @param R The region this pass is run on.\n  /// @param RGM The RegionPassManager that manages this Pass.\n  ///\n  /// @return True if the pass modifies this Region.\n  virtual bool runOnRegion(Region *R, RGPassManager &RGM) = 0;\n\n  /// Get a pass to print the LLVM IR in the region.\n  ///\n  /// @param O      The output stream to print the Region.\n  /// @param Banner The banner to separate different printed passes.\n  ///\n  /// @return The pass to print the LLVM IR in the region.\n  Pass *createPrinterPass(raw_ostream &O,\n                          const std::string &Banner) const override;\n\n  using llvm::Pass::doInitialization;\n  using llvm::Pass::doFinalization;\n\n  virtual bool doInitialization(Region *R, RGPassManager &RGM) { return false; }\n  virtual bool doFinalization() { return false; }\n  //@}\n\n  //===--------------------------------------------------------------------===//\n  /// @name PassManager API\n  ///\n  //@{\n  void preparePassManager(PMStack &PMS) override;\n\n  void assignPassManager(PMStack &PMS,\n                         PassManagerType PMT = PMT_RegionPassManager) override;\n\n  PassManagerType getPotentialPassManagerType() const override {\n    return PMT_RegionPassManager;\n  }\n  //@}\n\nprotected:\n  /// Optional passes call this function to check whether the pass should be\n  /// skipped. This is the case when optimization bisect is over the limit.\n  bool skipRegion(Region &R) const;\n};\n\n/// The pass manager to schedule RegionPasses.\nclass RGPassManager : public FunctionPass, public PMDataManager {\n  std::deque<Region*> RQ;\n  RegionInfo *RI;\n  Region *CurrentRegion;\n\npublic:\n  static char ID;\n  explicit RGPassManager();\n\n  /// Execute all of the passes scheduled for execution.\n  ///\n  /// @return True if any of the passes modifies the function.\n  bool runOnFunction(Function &F) override;\n\n  /// Pass Manager itself does not invalidate any analysis info.\n  /// RGPassManager needs RegionInfo.\n  void getAnalysisUsage(AnalysisUsage &Info) const override;\n\n  StringRef getPassName() const override { return \"Region Pass Manager\"; }\n\n  PMDataManager *getAsPMDataManager() override { return this; }\n  Pass *getAsPass() override { return this; }\n\n  /// Print passes managed by this manager.\n  void dumpPassStructure(unsigned Offset) override;\n\n  /// Get passes contained by this manager.\n  Pass *getContainedPass(unsigned N) {\n    assert(N < PassVector.size() && \"Pass number out of range!\");\n    Pass *FP = static_cast<Pass *>(PassVector[N]);\n    return FP;\n  }\n\n  PassManagerType getPassManagerType() const override {\n    return PMT_RegionPassManager;\n  }\n};\n\n} // End llvm namespace\n\n#endif\n"}, "29": {"id": 29, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "content": "//===- llvm/Analysis/ScalarEvolution.h - Scalar Evolution -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// The ScalarEvolution class is an LLVM pass which can be used to analyze and\n// categorize scalar expressions in loops.  It specializes in recognizing\n// general induction variables, representing them with the abstract and opaque\n// SCEV class.  Given this analysis, trip counts of loops and other important\n// properties can be obtained.\n//\n// This analysis is primarily useful for induction variable substitution and\n// strength reduction.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_SCALAREVOLUTION_H\n#define LLVM_ANALYSIS_SCALAREVOLUTION_H\n\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/ADT/Hashing.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/ConstantRange.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/Operator.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/IR/ValueMap.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Allocator.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/Compiler.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstdint>\n#include <memory>\n#include <utility>\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass BasicBlock;\nclass Constant;\nclass ConstantInt;\nclass DataLayout;\nclass DominatorTree;\nclass GEPOperator;\nclass Instruction;\nclass LLVMContext;\nclass Loop;\nclass LoopInfo;\nclass raw_ostream;\nclass ScalarEvolution;\nclass SCEVAddRecExpr;\nclass SCEVUnknown;\nclass StructType;\nclass TargetLibraryInfo;\nclass Type;\nclass Value;\nenum SCEVTypes : unsigned short;\n\n/// This class represents an analyzed expression in the program.  These are\n/// opaque objects that the client is not allowed to do much with directly.\n///\nclass SCEV : public FoldingSetNode {\n  friend struct FoldingSetTrait<SCEV>;\n\n  /// A reference to an Interned FoldingSetNodeID for this node.  The\n  /// ScalarEvolution's BumpPtrAllocator holds the data.\n  FoldingSetNodeIDRef FastID;\n\n  // The SCEV baseclass this node corresponds to\n  const SCEVTypes SCEVType;\n\nprotected:\n  // Estimated complexity of this node's expression tree size.\n  const unsigned short ExpressionSize;\n\n  /// This field is initialized to zero and may be used in subclasses to store\n  /// miscellaneous information.\n  unsigned short SubclassData = 0;\n\npublic:\n  /// NoWrapFlags are bitfield indices into SubclassData.\n  ///\n  /// Add and Mul expressions may have no-unsigned-wrap <NUW> or\n  /// no-signed-wrap <NSW> properties, which are derived from the IR\n  /// operator. NSW is a misnomer that we use to mean no signed overflow or\n  /// underflow.\n  ///\n  /// AddRec expressions may have a no-self-wraparound <NW> property if, in\n  /// the integer domain, abs(step) * max-iteration(loop) <=\n  /// unsigned-max(bitwidth).  This means that the recurrence will never reach\n  /// its start value if the step is non-zero.  Computing the same value on\n  /// each iteration is not considered wrapping, and recurrences with step = 0\n  /// are trivially <NW>.  <NW> is independent of the sign of step and the\n  /// value the add recurrence starts with.\n  ///\n  /// Note that NUW and NSW are also valid properties of a recurrence, and\n  /// either implies NW. For convenience, NW will be set for a recurrence\n  /// whenever either NUW or NSW are set.\n  enum NoWrapFlags {\n    FlagAnyWrap = 0,    // No guarantee.\n    FlagNW = (1 << 0),  // No self-wrap.\n    FlagNUW = (1 << 1), // No unsigned wrap.\n    FlagNSW = (1 << 2), // No signed wrap.\n    NoWrapMask = (1 << 3) - 1\n  };\n\n  explicit SCEV(const FoldingSetNodeIDRef ID, SCEVTypes SCEVTy,\n                unsigned short ExpressionSize)\n      : FastID(ID), SCEVType(SCEVTy), ExpressionSize(ExpressionSize) {}\n  SCEV(const SCEV &) = delete;\n  SCEV &operator=(const SCEV &) = delete;\n\n  SCEVTypes getSCEVType() const { return SCEVType; }\n\n  /// Return the LLVM type of this SCEV expression.\n  Type *getType() const;\n\n  /// Return true if the expression is a constant zero.\n  bool isZero() const;\n\n  /// Return true if the expression is a constant one.\n  bool isOne() const;\n\n  /// Return true if the expression is a constant all-ones value.\n  bool isAllOnesValue() const;\n\n  /// Return true if the specified scev is negated, but not a constant.\n  bool isNonConstantNegative() const;\n\n  // Returns estimated size of the mathematical expression represented by this\n  // SCEV. The rules of its calculation are following:\n  // 1) Size of a SCEV without operands (like constants and SCEVUnknown) is 1;\n  // 2) Size SCEV with operands Op1, Op2, ..., OpN is calculated by formula:\n  //    (1 + Size(Op1) + ... + Size(OpN)).\n  // This value gives us an estimation of time we need to traverse through this\n  // SCEV and all its operands recursively. We may use it to avoid performing\n  // heavy transformations on SCEVs of excessive size for sake of saving the\n  // compilation time.\n  unsigned short getExpressionSize() const {\n    return ExpressionSize;\n  }\n\n  /// Print out the internal representation of this scalar to the specified\n  /// stream.  This should really only be used for debugging purposes.\n  void print(raw_ostream &OS) const;\n\n  /// This method is used for debugging.\n  void dump() const;\n};\n\n// Specialize FoldingSetTrait for SCEV to avoid needing to compute\n// temporary FoldingSetNodeID values.\ntemplate <> struct FoldingSetTrait<SCEV> : DefaultFoldingSetTrait<SCEV> {\n  static void Profile(const SCEV &X, FoldingSetNodeID &ID) { ID = X.FastID; }\n\n  static bool Equals(const SCEV &X, const FoldingSetNodeID &ID, unsigned IDHash,\n                     FoldingSetNodeID &TempID) {\n    return ID == X.FastID;\n  }\n\n  static unsigned ComputeHash(const SCEV &X, FoldingSetNodeID &TempID) {\n    return X.FastID.ComputeHash();\n  }\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const SCEV &S) {\n  S.print(OS);\n  return OS;\n}\n\n/// An object of this class is returned by queries that could not be answered.\n/// For example, if you ask for the number of iterations of a linked-list\n/// traversal loop, you will get one of these.  None of the standard SCEV\n/// operations are valid on this class, it is just a marker.\nstruct SCEVCouldNotCompute : public SCEV {\n  SCEVCouldNotCompute();\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEV *S);\n};\n\n/// This class represents an assumption made using SCEV expressions which can\n/// be checked at run-time.\nclass SCEVPredicate : public FoldingSetNode {\n  friend struct FoldingSetTrait<SCEVPredicate>;\n\n  /// A reference to an Interned FoldingSetNodeID for this node.  The\n  /// ScalarEvolution's BumpPtrAllocator holds the data.\n  FoldingSetNodeIDRef FastID;\n\npublic:\n  enum SCEVPredicateKind { P_Union, P_Equal, P_Wrap };\n\nprotected:\n  SCEVPredicateKind Kind;\n  ~SCEVPredicate() = default;\n  SCEVPredicate(const SCEVPredicate &) = default;\n  SCEVPredicate &operator=(const SCEVPredicate &) = default;\n\npublic:\n  SCEVPredicate(const FoldingSetNodeIDRef ID, SCEVPredicateKind Kind);\n\n  SCEVPredicateKind getKind() const { return Kind; }\n\n  /// Returns the estimated complexity of this predicate.  This is roughly\n  /// measured in the number of run-time checks required.\n  virtual unsigned getComplexity() const { return 1; }\n\n  /// Returns true if the predicate is always true. This means that no\n  /// assumptions were made and nothing needs to be checked at run-time.\n  virtual bool isAlwaysTrue() const = 0;\n\n  /// Returns true if this predicate implies \\p N.\n  virtual bool implies(const SCEVPredicate *N) const = 0;\n\n  /// Prints a textual representation of this predicate with an indentation of\n  /// \\p Depth.\n  virtual void print(raw_ostream &OS, unsigned Depth = 0) const = 0;\n\n  /// Returns the SCEV to which this predicate applies, or nullptr if this is\n  /// a SCEVUnionPredicate.\n  virtual const SCEV *getExpr() const = 0;\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const SCEVPredicate &P) {\n  P.print(OS);\n  return OS;\n}\n\n// Specialize FoldingSetTrait for SCEVPredicate to avoid needing to compute\n// temporary FoldingSetNodeID values.\ntemplate <>\nstruct FoldingSetTrait<SCEVPredicate> : DefaultFoldingSetTrait<SCEVPredicate> {\n  static void Profile(const SCEVPredicate &X, FoldingSetNodeID &ID) {\n    ID = X.FastID;\n  }\n\n  static bool Equals(const SCEVPredicate &X, const FoldingSetNodeID &ID,\n                     unsigned IDHash, FoldingSetNodeID &TempID) {\n    return ID == X.FastID;\n  }\n\n  static unsigned ComputeHash(const SCEVPredicate &X,\n                              FoldingSetNodeID &TempID) {\n    return X.FastID.ComputeHash();\n  }\n};\n\n/// This class represents an assumption that two SCEV expressions are equal,\n/// and this can be checked at run-time.\nclass SCEVEqualPredicate final : public SCEVPredicate {\n  /// We assume that LHS == RHS.\n  const SCEV *LHS;\n  const SCEV *RHS;\n\npublic:\n  SCEVEqualPredicate(const FoldingSetNodeIDRef ID, const SCEV *LHS,\n                     const SCEV *RHS);\n\n  /// Implementation of the SCEVPredicate interface\n  bool implies(const SCEVPredicate *N) const override;\n  void print(raw_ostream &OS, unsigned Depth = 0) const override;\n  bool isAlwaysTrue() const override;\n  const SCEV *getExpr() const override;\n\n  /// Returns the left hand side of the equality.\n  const SCEV *getLHS() const { return LHS; }\n\n  /// Returns the right hand side of the equality.\n  const SCEV *getRHS() const { return RHS; }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEVPredicate *P) {\n    return P->getKind() == P_Equal;\n  }\n};\n\n/// This class represents an assumption made on an AddRec expression. Given an\n/// affine AddRec expression {a,+,b}, we assume that it has the nssw or nusw\n/// flags (defined below) in the first X iterations of the loop, where X is a\n/// SCEV expression returned by getPredicatedBackedgeTakenCount).\n///\n/// Note that this does not imply that X is equal to the backedge taken\n/// count. This means that if we have a nusw predicate for i32 {0,+,1} with a\n/// predicated backedge taken count of X, we only guarantee that {0,+,1} has\n/// nusw in the first X iterations. {0,+,1} may still wrap in the loop if we\n/// have more than X iterations.\nclass SCEVWrapPredicate final : public SCEVPredicate {\npublic:\n  /// Similar to SCEV::NoWrapFlags, but with slightly different semantics\n  /// for FlagNUSW. The increment is considered to be signed, and a + b\n  /// (where b is the increment) is considered to wrap if:\n  ///    zext(a + b) != zext(a) + sext(b)\n  ///\n  /// If Signed is a function that takes an n-bit tuple and maps to the\n  /// integer domain as the tuples value interpreted as twos complement,\n  /// and Unsigned a function that takes an n-bit tuple and maps to the\n  /// integer domain as as the base two value of input tuple, then a + b\n  /// has IncrementNUSW iff:\n  ///\n  /// 0 <= Unsigned(a) + Signed(b) < 2^n\n  ///\n  /// The IncrementNSSW flag has identical semantics with SCEV::FlagNSW.\n  ///\n  /// Note that the IncrementNUSW flag is not commutative: if base + inc\n  /// has IncrementNUSW, then inc + base doesn't neccessarily have this\n  /// property. The reason for this is that this is used for sign/zero\n  /// extending affine AddRec SCEV expressions when a SCEVWrapPredicate is\n  /// assumed. A {base,+,inc} expression is already non-commutative with\n  /// regards to base and inc, since it is interpreted as:\n  ///     (((base + inc) + inc) + inc) ...\n  enum IncrementWrapFlags {\n    IncrementAnyWrap = 0,     // No guarantee.\n    IncrementNUSW = (1 << 0), // No unsigned with signed increment wrap.\n    IncrementNSSW = (1 << 1), // No signed with signed increment wrap\n                              // (equivalent with SCEV::NSW)\n    IncrementNoWrapMask = (1 << 2) - 1\n  };\n\n  /// Convenient IncrementWrapFlags manipulation methods.\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  clearFlags(SCEVWrapPredicate::IncrementWrapFlags Flags,\n             SCEVWrapPredicate::IncrementWrapFlags OffFlags) {\n    assert((Flags & IncrementNoWrapMask) == Flags && \"Invalid flags value!\");\n    assert((OffFlags & IncrementNoWrapMask) == OffFlags &&\n           \"Invalid flags value!\");\n    return (SCEVWrapPredicate::IncrementWrapFlags)(Flags & ~OffFlags);\n  }\n\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  maskFlags(SCEVWrapPredicate::IncrementWrapFlags Flags, int Mask) {\n    assert((Flags & IncrementNoWrapMask) == Flags && \"Invalid flags value!\");\n    assert((Mask & IncrementNoWrapMask) == Mask && \"Invalid mask value!\");\n\n    return (SCEVWrapPredicate::IncrementWrapFlags)(Flags & Mask);\n  }\n\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  setFlags(SCEVWrapPredicate::IncrementWrapFlags Flags,\n           SCEVWrapPredicate::IncrementWrapFlags OnFlags) {\n    assert((Flags & IncrementNoWrapMask) == Flags && \"Invalid flags value!\");\n    assert((OnFlags & IncrementNoWrapMask) == OnFlags &&\n           \"Invalid flags value!\");\n\n    return (SCEVWrapPredicate::IncrementWrapFlags)(Flags | OnFlags);\n  }\n\n  /// Returns the set of SCEVWrapPredicate no wrap flags implied by a\n  /// SCEVAddRecExpr.\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  getImpliedFlags(const SCEVAddRecExpr *AR, ScalarEvolution &SE);\n\nprivate:\n  const SCEVAddRecExpr *AR;\n  IncrementWrapFlags Flags;\n\npublic:\n  explicit SCEVWrapPredicate(const FoldingSetNodeIDRef ID,\n                             const SCEVAddRecExpr *AR,\n                             IncrementWrapFlags Flags);\n\n  /// Returns the set assumed no overflow flags.\n  IncrementWrapFlags getFlags() const { return Flags; }\n\n  /// Implementation of the SCEVPredicate interface\n  const SCEV *getExpr() const override;\n  bool implies(const SCEVPredicate *N) const override;\n  void print(raw_ostream &OS, unsigned Depth = 0) const override;\n  bool isAlwaysTrue() const override;\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEVPredicate *P) {\n    return P->getKind() == P_Wrap;\n  }\n};\n\n/// This class represents a composition of other SCEV predicates, and is the\n/// class that most clients will interact with.  This is equivalent to a\n/// logical \"AND\" of all the predicates in the union.\n///\n/// NB! Unlike other SCEVPredicate sub-classes this class does not live in the\n/// ScalarEvolution::Preds folding set.  This is why the \\c add function is sound.\nclass SCEVUnionPredicate final : public SCEVPredicate {\nprivate:\n  using PredicateMap =\n      DenseMap<const SCEV *, SmallVector<const SCEVPredicate *, 4>>;\n\n  /// Vector with references to all predicates in this union.\n  SmallVector<const SCEVPredicate *, 16> Preds;\n\n  /// Maps SCEVs to predicates for quick look-ups.\n  PredicateMap SCEVToPreds;\n\npublic:\n  SCEVUnionPredicate();\n\n  const SmallVectorImpl<const SCEVPredicate *> &getPredicates() const {\n    return Preds;\n  }\n\n  /// Adds a predicate to this union.\n  void add(const SCEVPredicate *N);\n\n  /// Returns a reference to a vector containing all predicates which apply to\n  /// \\p Expr.\n  ArrayRef<const SCEVPredicate *> getPredicatesForExpr(const SCEV *Expr);\n\n  /// Implementation of the SCEVPredicate interface\n  bool isAlwaysTrue() const override;\n  bool implies(const SCEVPredicate *N) const override;\n  void print(raw_ostream &OS, unsigned Depth) const override;\n  const SCEV *getExpr() const override;\n\n  /// We estimate the complexity of a union predicate as the size number of\n  /// predicates in the union.\n  unsigned getComplexity() const override { return Preds.size(); }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEVPredicate *P) {\n    return P->getKind() == P_Union;\n  }\n};\n\n/// The main scalar evolution driver. Because client code (intentionally)\n/// can't do much with the SCEV objects directly, they must ask this class\n/// for services.\nclass ScalarEvolution {\n  friend class ScalarEvolutionsTest;\n\npublic:\n  /// An enum describing the relationship between a SCEV and a loop.\n  enum LoopDisposition {\n    LoopVariant,   ///< The SCEV is loop-variant (unknown).\n    LoopInvariant, ///< The SCEV is loop-invariant.\n    LoopComputable ///< The SCEV varies predictably with the loop.\n  };\n\n  /// An enum describing the relationship between a SCEV and a basic block.\n  enum BlockDisposition {\n    DoesNotDominateBlock,  ///< The SCEV does not dominate the block.\n    DominatesBlock,        ///< The SCEV dominates the block.\n    ProperlyDominatesBlock ///< The SCEV properly dominates the block.\n  };\n\n  /// Convenient NoWrapFlags manipulation that hides enum casts and is\n  /// visible in the ScalarEvolution name space.\n  LLVM_NODISCARD static SCEV::NoWrapFlags maskFlags(SCEV::NoWrapFlags Flags,\n                                                    int Mask) {\n    return (SCEV::NoWrapFlags)(Flags & Mask);\n  }\n  LLVM_NODISCARD static SCEV::NoWrapFlags setFlags(SCEV::NoWrapFlags Flags,\n                                                   SCEV::NoWrapFlags OnFlags) {\n    return (SCEV::NoWrapFlags)(Flags | OnFlags);\n  }\n  LLVM_NODISCARD static SCEV::NoWrapFlags\n  clearFlags(SCEV::NoWrapFlags Flags, SCEV::NoWrapFlags OffFlags) {\n    return (SCEV::NoWrapFlags)(Flags & ~OffFlags);\n  }\n\n  ScalarEvolution(Function &F, TargetLibraryInfo &TLI, AssumptionCache &AC,\n                  DominatorTree &DT, LoopInfo &LI);\n  ScalarEvolution(ScalarEvolution &&Arg);\n  ~ScalarEvolution();\n\n  LLVMContext &getContext() const { return F.getContext(); }\n\n  /// Test if values of the given type are analyzable within the SCEV\n  /// framework. This primarily includes integer types, and it can optionally\n  /// include pointer types if the ScalarEvolution class has access to\n  /// target-specific information.\n  bool isSCEVable(Type *Ty) const;\n\n  /// Return the size in bits of the specified type, for which isSCEVable must\n  /// return true.\n  uint64_t getTypeSizeInBits(Type *Ty) const;\n\n  /// Return a type with the same bitwidth as the given type and which\n  /// represents how SCEV will treat the given type, for which isSCEVable must\n  /// return true. For pointer types, this is the pointer-sized integer type.\n  Type *getEffectiveSCEVType(Type *Ty) const;\n\n  // Returns a wider type among {Ty1, Ty2}.\n  Type *getWiderType(Type *Ty1, Type *Ty2) const;\n\n  /// Return true if the SCEV is a scAddRecExpr or it contains\n  /// scAddRecExpr. The result will be cached in HasRecMap.\n  bool containsAddRecurrence(const SCEV *S);\n\n  /// Erase Value from ValueExprMap and ExprValueMap.\n  void eraseValueFromMap(Value *V);\n\n  /// Return a SCEV expression for the full generality of the specified\n  /// expression.\n  const SCEV *getSCEV(Value *V);\n\n  const SCEV *getConstant(ConstantInt *V);\n  const SCEV *getConstant(const APInt &Val);\n  const SCEV *getConstant(Type *Ty, uint64_t V, bool isSigned = false);\n  const SCEV *getPtrToIntExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getTruncateExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getZeroExtendExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getSignExtendExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getAnyExtendExpr(const SCEV *Op, Type *Ty);\n  const SCEV *getAddExpr(SmallVectorImpl<const SCEV *> &Ops,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0);\n  const SCEV *getAddExpr(const SCEV *LHS, const SCEV *RHS,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 2> Ops = {LHS, RHS};\n    return getAddExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getAddExpr(const SCEV *Op0, const SCEV *Op1, const SCEV *Op2,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 3> Ops = {Op0, Op1, Op2};\n    return getAddExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getMulExpr(SmallVectorImpl<const SCEV *> &Ops,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0);\n  const SCEV *getMulExpr(const SCEV *LHS, const SCEV *RHS,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 2> Ops = {LHS, RHS};\n    return getMulExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getMulExpr(const SCEV *Op0, const SCEV *Op1, const SCEV *Op2,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 3> Ops = {Op0, Op1, Op2};\n    return getMulExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getUDivExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getUDivExactExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getURemExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getAddRecExpr(const SCEV *Start, const SCEV *Step, const Loop *L,\n                            SCEV::NoWrapFlags Flags);\n  const SCEV *getAddRecExpr(SmallVectorImpl<const SCEV *> &Operands,\n                            const Loop *L, SCEV::NoWrapFlags Flags);\n  const SCEV *getAddRecExpr(const SmallVectorImpl<const SCEV *> &Operands,\n                            const Loop *L, SCEV::NoWrapFlags Flags) {\n    SmallVector<const SCEV *, 4> NewOp(Operands.begin(), Operands.end());\n    return getAddRecExpr(NewOp, L, Flags);\n  }\n\n  /// Checks if \\p SymbolicPHI can be rewritten as an AddRecExpr under some\n  /// Predicates. If successful return these <AddRecExpr, Predicates>;\n  /// The function is intended to be called from PSCEV (the caller will decide\n  /// whether to actually add the predicates and carry out the rewrites).\n  Optional<std::pair<const SCEV *, SmallVector<const SCEVPredicate *, 3>>>\n  createAddRecFromPHIWithCasts(const SCEVUnknown *SymbolicPHI);\n\n  /// Returns an expression for a GEP\n  ///\n  /// \\p GEP The GEP. The indices contained in the GEP itself are ignored,\n  /// instead we use IndexExprs.\n  /// \\p IndexExprs The expressions for the indices.\n  const SCEV *getGEPExpr(GEPOperator *GEP,\n                         const SmallVectorImpl<const SCEV *> &IndexExprs);\n  const SCEV *getAbsExpr(const SCEV *Op, bool IsNSW);\n  const SCEV *getSignumExpr(const SCEV *Op);\n  const SCEV *getMinMaxExpr(SCEVTypes Kind,\n                            SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getSMaxExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getSMaxExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getUMaxExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getUMaxExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getSMinExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getSMinExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getUMinExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getUMinExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getUnknown(Value *V);\n  const SCEV *getCouldNotCompute();\n\n  /// Return a SCEV for the constant 0 of a specific type.\n  const SCEV *getZero(Type *Ty) { return getConstant(Ty, 0); }\n\n  /// Return a SCEV for the constant 1 of a specific type.\n  const SCEV *getOne(Type *Ty) { return getConstant(Ty, 1); }\n\n  /// Return a SCEV for the constant -1 of a specific type.\n  const SCEV *getMinusOne(Type *Ty) {\n    return getConstant(Ty, -1, /*isSigned=*/true);\n  }\n\n  /// Return an expression for sizeof ScalableTy that is type IntTy, where\n  /// ScalableTy is a scalable vector type.\n  const SCEV *getSizeOfScalableVectorExpr(Type *IntTy,\n                                          ScalableVectorType *ScalableTy);\n\n  /// Return an expression for the alloc size of AllocTy that is type IntTy\n  const SCEV *getSizeOfExpr(Type *IntTy, Type *AllocTy);\n\n  /// Return an expression for the store size of StoreTy that is type IntTy\n  const SCEV *getStoreSizeOfExpr(Type *IntTy, Type *StoreTy);\n\n  /// Return an expression for offsetof on the given field with type IntTy\n  const SCEV *getOffsetOfExpr(Type *IntTy, StructType *STy, unsigned FieldNo);\n\n  /// Return the SCEV object corresponding to -V.\n  const SCEV *getNegativeSCEV(const SCEV *V,\n                              SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap);\n\n  /// Return the SCEV object corresponding to ~V.\n  const SCEV *getNotSCEV(const SCEV *V);\n\n  /// Return LHS-RHS.  Minus is represented in SCEV as A+B*-1.\n  const SCEV *getMinusSCEV(const SCEV *LHS, const SCEV *RHS,\n                           SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                           unsigned Depth = 0);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is zero extended.\n  const SCEV *getTruncateOrZeroExtend(const SCEV *V, Type *Ty,\n                                      unsigned Depth = 0);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is sign extended.\n  const SCEV *getTruncateOrSignExtend(const SCEV *V, Type *Ty,\n                                      unsigned Depth = 0);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is zero extended.  The\n  /// conversion must not be narrowing.\n  const SCEV *getNoopOrZeroExtend(const SCEV *V, Type *Ty);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is sign extended.  The\n  /// conversion must not be narrowing.\n  const SCEV *getNoopOrSignExtend(const SCEV *V, Type *Ty);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type. If the type must be extended, it is extended with\n  /// unspecified bits. The conversion must not be narrowing.\n  const SCEV *getNoopOrAnyExtend(const SCEV *V, Type *Ty);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  The conversion must not be widening.\n  const SCEV *getTruncateOrNoop(const SCEV *V, Type *Ty);\n\n  /// Promote the operands to the wider of the types using zero-extension, and\n  /// then perform a umax operation with them.\n  const SCEV *getUMaxFromMismatchedTypes(const SCEV *LHS, const SCEV *RHS);\n\n  /// Promote the operands to the wider of the types using zero-extension, and\n  /// then perform a umin operation with them.\n  const SCEV *getUMinFromMismatchedTypes(const SCEV *LHS, const SCEV *RHS);\n\n  /// Promote the operands to the wider of the types using zero-extension, and\n  /// then perform a umin operation with them. N-ary function.\n  const SCEV *getUMinFromMismatchedTypes(SmallVectorImpl<const SCEV *> &Ops);\n\n  /// Transitively follow the chain of pointer-type operands until reaching a\n  /// SCEV that does not have a single pointer operand. This returns a\n  /// SCEVUnknown pointer for well-formed pointer-type expressions, but corner\n  /// cases do exist.\n  const SCEV *getPointerBase(const SCEV *V);\n\n  /// Return a SCEV expression for the specified value at the specified scope\n  /// in the program.  The L value specifies a loop nest to evaluate the\n  /// expression at, where null is the top-level or a specified loop is\n  /// immediately inside of the loop.\n  ///\n  /// This method can be used to compute the exit value for a variable defined\n  /// in a loop by querying what the value will hold in the parent loop.\n  ///\n  /// In the case that a relevant loop exit value cannot be computed, the\n  /// original value V is returned.\n  const SCEV *getSCEVAtScope(const SCEV *S, const Loop *L);\n\n  /// This is a convenience function which does getSCEVAtScope(getSCEV(V), L).\n  const SCEV *getSCEVAtScope(Value *V, const Loop *L);\n\n  /// Test whether entry to the loop is protected by a conditional between LHS\n  /// and RHS.  This is used to help avoid max expressions in loop trip\n  /// counts, and to eliminate casts.\n  bool isLoopEntryGuardedByCond(const Loop *L, ICmpInst::Predicate Pred,\n                                const SCEV *LHS, const SCEV *RHS);\n\n  /// Test whether entry to the basic block is protected by a conditional\n  /// between LHS and RHS.\n  bool isBasicBlockEntryGuardedByCond(const BasicBlock *BB,\n                                      ICmpInst::Predicate Pred, const SCEV *LHS,\n                                      const SCEV *RHS);\n\n  /// Test whether the backedge of the loop is protected by a conditional\n  /// between LHS and RHS.  This is used to eliminate casts.\n  bool isLoopBackedgeGuardedByCond(const Loop *L, ICmpInst::Predicate Pred,\n                                   const SCEV *LHS, const SCEV *RHS);\n\n  /// Returns the maximum trip count of the loop if it is a single-exit\n  /// loop and we can compute a small maximum for that loop.\n  ///\n  /// Implemented in terms of the \\c getSmallConstantTripCount overload with\n  /// the single exiting block passed to it. See that routine for details.\n  unsigned getSmallConstantTripCount(const Loop *L);\n\n  /// Returns the maximum trip count of this loop as a normal unsigned\n  /// value. Returns 0 if the trip count is unknown or not constant. This\n  /// \"trip count\" assumes that control exits via ExitingBlock. More\n  /// precisely, it is the number of times that control may reach ExitingBlock\n  /// before taking the branch. For loops with multiple exits, it may not be\n  /// the number times that the loop header executes if the loop exits\n  /// prematurely via another branch.\n  unsigned getSmallConstantTripCount(const Loop *L,\n                                     const BasicBlock *ExitingBlock);\n\n  /// Returns the upper bound of the loop trip count as a normal unsigned\n  /// value.\n  /// Returns 0 if the trip count is unknown or not constant.\n  unsigned getSmallConstantMaxTripCount(const Loop *L);\n\n  /// Returns the largest constant divisor of the trip count of the\n  /// loop if it is a single-exit loop and we can compute a small maximum for\n  /// that loop.\n  ///\n  /// Implemented in terms of the \\c getSmallConstantTripMultiple overload with\n  /// the single exiting block passed to it. See that routine for details.\n  unsigned getSmallConstantTripMultiple(const Loop *L);\n\n  /// Returns the largest constant divisor of the trip count of this loop as a\n  /// normal unsigned value, if possible. This means that the actual trip\n  /// count is always a multiple of the returned value (don't forget the trip\n  /// count could very well be zero as well!). As explained in the comments\n  /// for getSmallConstantTripCount, this assumes that control exits the loop\n  /// via ExitingBlock.\n  unsigned getSmallConstantTripMultiple(const Loop *L,\n                                        const BasicBlock *ExitingBlock);\n\n  /// The terms \"backedge taken count\" and \"exit count\" are used\n  /// interchangeably to refer to the number of times the backedge of a loop \n  /// has executed before the loop is exited.\n  enum ExitCountKind {\n    /// An expression exactly describing the number of times the backedge has\n    /// executed when a loop is exited.\n    Exact,\n    /// A constant which provides an upper bound on the exact trip count.\n    ConstantMaximum,\n    /// An expression which provides an upper bound on the exact trip count.\n    SymbolicMaximum,\n  };\n\n  /// Return the number of times the backedge executes before the given exit\n  /// would be taken; if not exactly computable, return SCEVCouldNotCompute. \n  /// For a single exit loop, this value is equivelent to the result of\n  /// getBackedgeTakenCount.  The loop is guaranteed to exit (via *some* exit)\n  /// before the backedge is executed (ExitCount + 1) times.  Note that there\n  /// is no guarantee about *which* exit is taken on the exiting iteration.\n  const SCEV *getExitCount(const Loop *L, const BasicBlock *ExitingBlock,\n                           ExitCountKind Kind = Exact);\n\n  /// If the specified loop has a predictable backedge-taken count, return it,\n  /// otherwise return a SCEVCouldNotCompute object. The backedge-taken count is\n  /// the number of times the loop header will be branched to from within the\n  /// loop, assuming there are no abnormal exists like exception throws. This is\n  /// one less than the trip count of the loop, since it doesn't count the first\n  /// iteration, when the header is branched to from outside the loop.\n  ///\n  /// Note that it is not valid to call this method on a loop without a\n  /// loop-invariant backedge-taken count (see\n  /// hasLoopInvariantBackedgeTakenCount).\n  const SCEV *getBackedgeTakenCount(const Loop *L, ExitCountKind Kind = Exact);\n\n  /// Similar to getBackedgeTakenCount, except it will add a set of\n  /// SCEV predicates to Predicates that are required to be true in order for\n  /// the answer to be correct. Predicates can be checked with run-time\n  /// checks and can be used to perform loop versioning.\n  const SCEV *getPredicatedBackedgeTakenCount(const Loop *L,\n                                              SCEVUnionPredicate &Predicates);\n\n  /// When successful, this returns a SCEVConstant that is greater than or equal\n  /// to (i.e. a \"conservative over-approximation\") of the value returend by\n  /// getBackedgeTakenCount.  If such a value cannot be computed, it returns the\n  /// SCEVCouldNotCompute object.\n  const SCEV *getConstantMaxBackedgeTakenCount(const Loop *L) {\n    return getBackedgeTakenCount(L, ConstantMaximum);\n  }\n\n  /// When successful, this returns a SCEV that is greater than or equal\n  /// to (i.e. a \"conservative over-approximation\") of the value returend by\n  /// getBackedgeTakenCount.  If such a value cannot be computed, it returns the\n  /// SCEVCouldNotCompute object.\n  const SCEV *getSymbolicMaxBackedgeTakenCount(const Loop *L) {\n    return getBackedgeTakenCount(L, SymbolicMaximum);\n  }\n\n  /// Return true if the backedge taken count is either the value returned by\n  /// getConstantMaxBackedgeTakenCount or zero.\n  bool isBackedgeTakenCountMaxOrZero(const Loop *L);\n\n  /// Return true if the specified loop has an analyzable loop-invariant\n  /// backedge-taken count.\n  bool hasLoopInvariantBackedgeTakenCount(const Loop *L);\n\n  // This method should be called by the client when it made any change that\n  // would invalidate SCEV's answers, and the client wants to remove all loop\n  // information held internally by ScalarEvolution. This is intended to be used\n  // when the alternative to forget a loop is too expensive (i.e. large loop\n  // bodies).\n  void forgetAllLoops();\n\n  /// This method should be called by the client when it has changed a loop in\n  /// a way that may effect ScalarEvolution's ability to compute a trip count,\n  /// or if the loop is deleted.  This call is potentially expensive for large\n  /// loop bodies.\n  void forgetLoop(const Loop *L);\n\n  // This method invokes forgetLoop for the outermost loop of the given loop\n  // \\p L, making ScalarEvolution forget about all this subtree. This needs to\n  // be done whenever we make a transform that may affect the parameters of the\n  // outer loop, such as exit counts for branches.\n  void forgetTopmostLoop(const Loop *L);\n\n  /// This method should be called by the client when it has changed a value\n  /// in a way that may effect its value, or which may disconnect it from a\n  /// def-use chain linking it to a loop.\n  void forgetValue(Value *V);\n\n  /// Called when the client has changed the disposition of values in\n  /// this loop.\n  ///\n  /// We don't have a way to invalidate per-loop dispositions. Clear and\n  /// recompute is simpler.\n  void forgetLoopDispositions(const Loop *L);\n\n  /// Determine the minimum number of zero bits that S is guaranteed to end in\n  /// (at every loop iteration).  It is, at the same time, the minimum number\n  /// of times S is divisible by 2.  For example, given {4,+,8} it returns 2.\n  /// If S is guaranteed to be 0, it returns the bitwidth of S.\n  uint32_t GetMinTrailingZeros(const SCEV *S);\n\n  /// Determine the unsigned range for a particular SCEV.\n  /// NOTE: This returns a copy of the reference returned by getRangeRef.\n  ConstantRange getUnsignedRange(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_UNSIGNED);\n  }\n\n  /// Determine the min of the unsigned range for a particular SCEV.\n  APInt getUnsignedRangeMin(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_UNSIGNED).getUnsignedMin();\n  }\n\n  /// Determine the max of the unsigned range for a particular SCEV.\n  APInt getUnsignedRangeMax(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_UNSIGNED).getUnsignedMax();\n  }\n\n  /// Determine the signed range for a particular SCEV.\n  /// NOTE: This returns a copy of the reference returned by getRangeRef.\n  ConstantRange getSignedRange(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_SIGNED);\n  }\n\n  /// Determine the min of the signed range for a particular SCEV.\n  APInt getSignedRangeMin(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_SIGNED).getSignedMin();\n  }\n\n  /// Determine the max of the signed range for a particular SCEV.\n  APInt getSignedRangeMax(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_SIGNED).getSignedMax();\n  }\n\n  /// Test if the given expression is known to be negative.\n  bool isKnownNegative(const SCEV *S);\n\n  /// Test if the given expression is known to be positive.\n  bool isKnownPositive(const SCEV *S);\n\n  /// Test if the given expression is known to be non-negative.\n  bool isKnownNonNegative(const SCEV *S);\n\n  /// Test if the given expression is known to be non-positive.\n  bool isKnownNonPositive(const SCEV *S);\n\n  /// Test if the given expression is known to be non-zero.\n  bool isKnownNonZero(const SCEV *S);\n\n  /// Splits SCEV expression \\p S into two SCEVs. One of them is obtained from\n  /// \\p S by substitution of all AddRec sub-expression related to loop \\p L\n  /// with initial value of that SCEV. The second is obtained from \\p S by\n  /// substitution of all AddRec sub-expressions related to loop \\p L with post\n  /// increment of this AddRec in the loop \\p L. In both cases all other AddRec\n  /// sub-expressions (not related to \\p L) remain the same.\n  /// If the \\p S contains non-invariant unknown SCEV the function returns\n  /// CouldNotCompute SCEV in both values of std::pair.\n  /// For example, for SCEV S={0, +, 1}<L1> + {0, +, 1}<L2> and loop L=L1\n  /// the function returns pair:\n  /// first = {0, +, 1}<L2>\n  /// second = {1, +, 1}<L1> + {0, +, 1}<L2>\n  /// We can see that for the first AddRec sub-expression it was replaced with\n  /// 0 (initial value) for the first element and to {1, +, 1}<L1> (post\n  /// increment value) for the second one. In both cases AddRec expression\n  /// related to L2 remains the same.\n  std::pair<const SCEV *, const SCEV *> SplitIntoInitAndPostInc(const Loop *L,\n                                                                const SCEV *S);\n\n  /// We'd like to check the predicate on every iteration of the most dominated\n  /// loop between loops used in LHS and RHS.\n  /// To do this we use the following list of steps:\n  /// 1. Collect set S all loops on which either LHS or RHS depend.\n  /// 2. If S is non-empty\n  /// a. Let PD be the element of S which is dominated by all other elements.\n  /// b. Let E(LHS) be value of LHS on entry of PD.\n  ///    To get E(LHS), we should just take LHS and replace all AddRecs that are\n  ///    attached to PD on with their entry values.\n  ///    Define E(RHS) in the same way.\n  /// c. Let B(LHS) be value of L on backedge of PD.\n  ///    To get B(LHS), we should just take LHS and replace all AddRecs that are\n  ///    attached to PD on with their backedge values.\n  ///    Define B(RHS) in the same way.\n  /// d. Note that E(LHS) and E(RHS) are automatically available on entry of PD,\n  ///    so we can assert on that.\n  /// e. Return true if isLoopEntryGuardedByCond(Pred, E(LHS), E(RHS)) &&\n  ///                   isLoopBackedgeGuardedByCond(Pred, B(LHS), B(RHS))\n  bool isKnownViaInduction(ICmpInst::Predicate Pred, const SCEV *LHS,\n                           const SCEV *RHS);\n\n  /// Test if the given expression is known to satisfy the condition described\n  /// by Pred, LHS, and RHS.\n  bool isKnownPredicate(ICmpInst::Predicate Pred, const SCEV *LHS,\n                        const SCEV *RHS);\n\n  /// Test if the given expression is known to satisfy the condition described\n  /// by Pred, LHS, and RHS in the given Context.\n  bool isKnownPredicateAt(ICmpInst::Predicate Pred, const SCEV *LHS,\n                        const SCEV *RHS, const Instruction *Context);\n\n  /// Test if the condition described by Pred, LHS, RHS is known to be true on\n  /// every iteration of the loop of the recurrency LHS.\n  bool isKnownOnEveryIteration(ICmpInst::Predicate Pred,\n                               const SCEVAddRecExpr *LHS, const SCEV *RHS);\n\n  /// A predicate is said to be monotonically increasing if may go from being\n  /// false to being true as the loop iterates, but never the other way\n  /// around.  A predicate is said to be monotonically decreasing if may go\n  /// from being true to being false as the loop iterates, but never the other\n  /// way around.\n  enum MonotonicPredicateType {\n    MonotonicallyIncreasing,\n    MonotonicallyDecreasing\n  };\n\n  /// If, for all loop invariant X, the predicate \"LHS `Pred` X\" is\n  /// monotonically increasing or decreasing, returns\n  /// Some(MonotonicallyIncreasing) and Some(MonotonicallyDecreasing)\n  /// respectively. If we could not prove either of these facts, returns None.\n  Optional<MonotonicPredicateType>\n  getMonotonicPredicateType(const SCEVAddRecExpr *LHS,\n                            ICmpInst::Predicate Pred);\n\n  struct LoopInvariantPredicate {\n    ICmpInst::Predicate Pred;\n    const SCEV *LHS;\n    const SCEV *RHS;\n\n    LoopInvariantPredicate(ICmpInst::Predicate Pred, const SCEV *LHS,\n                           const SCEV *RHS)\n        : Pred(Pred), LHS(LHS), RHS(RHS) {}\n  };\n  /// If the result of the predicate LHS `Pred` RHS is loop invariant with\n  /// respect to L, return a LoopInvariantPredicate with LHS and RHS being\n  /// invariants, available at L's entry. Otherwise, return None.\n  Optional<LoopInvariantPredicate>\n  getLoopInvariantPredicate(ICmpInst::Predicate Pred, const SCEV *LHS,\n                            const SCEV *RHS, const Loop *L);\n\n  /// If the result of the predicate LHS `Pred` RHS is loop invariant with\n  /// respect to L at given Context during at least first MaxIter iterations,\n  /// return a LoopInvariantPredicate with LHS and RHS being invariants,\n  /// available at L's entry. Otherwise, return None. The predicate should be\n  /// the loop's exit condition.\n  Optional<LoopInvariantPredicate>\n  getLoopInvariantExitCondDuringFirstIterations(ICmpInst::Predicate Pred,\n                                                const SCEV *LHS,\n                                                const SCEV *RHS, const Loop *L,\n                                                const Instruction *Context,\n                                                const SCEV *MaxIter);\n\n  /// Simplify LHS and RHS in a comparison with predicate Pred. Return true\n  /// iff any changes were made. If the operands are provably equal or\n  /// unequal, LHS and RHS are set to the same value and Pred is set to either\n  /// ICMP_EQ or ICMP_NE.\n  bool SimplifyICmpOperands(ICmpInst::Predicate &Pred, const SCEV *&LHS,\n                            const SCEV *&RHS, unsigned Depth = 0);\n\n  /// Return the \"disposition\" of the given SCEV with respect to the given\n  /// loop.\n  LoopDisposition getLoopDisposition(const SCEV *S, const Loop *L);\n\n  /// Return true if the value of the given SCEV is unchanging in the\n  /// specified loop.\n  bool isLoopInvariant(const SCEV *S, const Loop *L);\n\n  /// Determine if the SCEV can be evaluated at loop's entry. It is true if it\n  /// doesn't depend on a SCEVUnknown of an instruction which is dominated by\n  /// the header of loop L.\n  bool isAvailableAtLoopEntry(const SCEV *S, const Loop *L);\n\n  /// Return true if the given SCEV changes value in a known way in the\n  /// specified loop.  This property being true implies that the value is\n  /// variant in the loop AND that we can emit an expression to compute the\n  /// value of the expression at any particular loop iteration.\n  bool hasComputableLoopEvolution(const SCEV *S, const Loop *L);\n\n  /// Return the \"disposition\" of the given SCEV with respect to the given\n  /// block.\n  BlockDisposition getBlockDisposition(const SCEV *S, const BasicBlock *BB);\n\n  /// Return true if elements that makes up the given SCEV dominate the\n  /// specified basic block.\n  bool dominates(const SCEV *S, const BasicBlock *BB);\n\n  /// Return true if elements that makes up the given SCEV properly dominate\n  /// the specified basic block.\n  bool properlyDominates(const SCEV *S, const BasicBlock *BB);\n\n  /// Test whether the given SCEV has Op as a direct or indirect operand.\n  bool hasOperand(const SCEV *S, const SCEV *Op) const;\n\n  /// Return the size of an element read or written by Inst.\n  const SCEV *getElementSize(Instruction *Inst);\n\n  /// Compute the array dimensions Sizes from the set of Terms extracted from\n  /// the memory access function of this SCEVAddRecExpr (second step of\n  /// delinearization).\n  void findArrayDimensions(SmallVectorImpl<const SCEV *> &Terms,\n                           SmallVectorImpl<const SCEV *> &Sizes,\n                           const SCEV *ElementSize);\n\n  void print(raw_ostream &OS) const;\n  void verify() const;\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\n  /// Collect parametric terms occurring in step expressions (first step of\n  /// delinearization).\n  void collectParametricTerms(const SCEV *Expr,\n                              SmallVectorImpl<const SCEV *> &Terms);\n\n  /// Return in Subscripts the access functions for each dimension in Sizes\n  /// (third step of delinearization).\n  void computeAccessFunctions(const SCEV *Expr,\n                              SmallVectorImpl<const SCEV *> &Subscripts,\n                              SmallVectorImpl<const SCEV *> &Sizes);\n\n  /// Gathers the individual index expressions from a GEP instruction.\n  ///\n  /// This function optimistically assumes the GEP references into a fixed size\n  /// array. If this is actually true, this function returns a list of array\n  /// subscript expressions in \\p Subscripts and a list of integers describing\n  /// the size of the individual array dimensions in \\p Sizes. Both lists have\n  /// either equal length or the size list is one element shorter in case there\n  /// is no known size available for the outermost array dimension. Returns true\n  /// if successful and false otherwise.\n  bool getIndexExpressionsFromGEP(const GetElementPtrInst *GEP,\n                                  SmallVectorImpl<const SCEV *> &Subscripts,\n                                  SmallVectorImpl<int> &Sizes);\n\n  /// Split this SCEVAddRecExpr into two vectors of SCEVs representing the\n  /// subscripts and sizes of an array access.\n  ///\n  /// The delinearization is a 3 step process: the first two steps compute the\n  /// sizes of each subscript and the third step computes the access functions\n  /// for the delinearized array:\n  ///\n  /// 1. Find the terms in the step functions\n  /// 2. Compute the array size\n  /// 3. Compute the access function: divide the SCEV by the array size\n  ///    starting with the innermost dimensions found in step 2. The Quotient\n  ///    is the SCEV to be divided in the next step of the recursion. The\n  ///    Remainder is the subscript of the innermost dimension. Loop over all\n  ///    array dimensions computed in step 2.\n  ///\n  /// To compute a uniform array size for several memory accesses to the same\n  /// object, one can collect in step 1 all the step terms for all the memory\n  /// accesses, and compute in step 2 a unique array shape. This guarantees\n  /// that the array shape will be the same across all memory accesses.\n  ///\n  /// FIXME: We could derive the result of steps 1 and 2 from a description of\n  /// the array shape given in metadata.\n  ///\n  /// Example:\n  ///\n  /// A[][n][m]\n  ///\n  /// for i\n  ///   for j\n  ///     for k\n  ///       A[j+k][2i][5i] =\n  ///\n  /// The initial SCEV:\n  ///\n  /// A[{{{0,+,2*m+5}_i, +, n*m}_j, +, n*m}_k]\n  ///\n  /// 1. Find the different terms in the step functions:\n  /// -> [2*m, 5, n*m, n*m]\n  ///\n  /// 2. Compute the array size: sort and unique them\n  /// -> [n*m, 2*m, 5]\n  /// find the GCD of all the terms = 1\n  /// divide by the GCD and erase constant terms\n  /// -> [n*m, 2*m]\n  /// GCD = m\n  /// divide by GCD -> [n, 2]\n  /// remove constant terms\n  /// -> [n]\n  /// size of the array is A[unknown][n][m]\n  ///\n  /// 3. Compute the access function\n  /// a. Divide {{{0,+,2*m+5}_i, +, n*m}_j, +, n*m}_k by the innermost size m\n  /// Quotient: {{{0,+,2}_i, +, n}_j, +, n}_k\n  /// Remainder: {{{0,+,5}_i, +, 0}_j, +, 0}_k\n  /// The remainder is the subscript of the innermost array dimension: [5i].\n  ///\n  /// b. Divide Quotient: {{{0,+,2}_i, +, n}_j, +, n}_k by next outer size n\n  /// Quotient: {{{0,+,0}_i, +, 1}_j, +, 1}_k\n  /// Remainder: {{{0,+,2}_i, +, 0}_j, +, 0}_k\n  /// The Remainder is the subscript of the next array dimension: [2i].\n  ///\n  /// The subscript of the outermost dimension is the Quotient: [j+k].\n  ///\n  /// Overall, we have: A[][n][m], and the access function: A[j+k][2i][5i].\n  void delinearize(const SCEV *Expr, SmallVectorImpl<const SCEV *> &Subscripts,\n                   SmallVectorImpl<const SCEV *> &Sizes,\n                   const SCEV *ElementSize);\n\n  /// Return the DataLayout associated with the module this SCEV instance is\n  /// operating on.\n  const DataLayout &getDataLayout() const {\n    return F.getParent()->getDataLayout();\n  }\n\n  const SCEVPredicate *getEqualPredicate(const SCEV *LHS, const SCEV *RHS);\n\n  const SCEVPredicate *\n  getWrapPredicate(const SCEVAddRecExpr *AR,\n                   SCEVWrapPredicate::IncrementWrapFlags AddedFlags);\n\n  /// Re-writes the SCEV according to the Predicates in \\p A.\n  const SCEV *rewriteUsingPredicate(const SCEV *S, const Loop *L,\n                                    SCEVUnionPredicate &A);\n  /// Tries to convert the \\p S expression to an AddRec expression,\n  /// adding additional predicates to \\p Preds as required.\n  const SCEVAddRecExpr *convertSCEVToAddRecWithPredicates(\n      const SCEV *S, const Loop *L,\n      SmallPtrSetImpl<const SCEVPredicate *> &Preds);\n\n  /// Compute \\p LHS - \\p RHS and returns the result as an APInt if it is a\n  /// constant, and None if it isn't.\n  ///\n  /// This is intended to be a cheaper version of getMinusSCEV.  We can be\n  /// frugal here since we just bail out of actually constructing and\n  /// canonicalizing an expression in the cases where the result isn't going\n  /// to be a constant.\n  Optional<APInt> computeConstantDifference(const SCEV *LHS, const SCEV *RHS);\n\n  /// Update no-wrap flags of an AddRec. This may drop the cached info about\n  /// this AddRec (such as range info) in case if new flags may potentially\n  /// sharpen it.\n  void setNoWrapFlags(SCEVAddRecExpr *AddRec, SCEV::NoWrapFlags Flags);\n\n  /// Try to apply information from loop guards for \\p L to \\p Expr.\n  const SCEV *applyLoopGuards(const SCEV *Expr, const Loop *L);\n\nprivate:\n  /// A CallbackVH to arrange for ScalarEvolution to be notified whenever a\n  /// Value is deleted.\n  class SCEVCallbackVH final : public CallbackVH {\n    ScalarEvolution *SE;\n\n    void deleted() override;\n    void allUsesReplacedWith(Value *New) override;\n\n  public:\n    SCEVCallbackVH(Value *V, ScalarEvolution *SE = nullptr);\n  };\n\n  friend class SCEVCallbackVH;\n  friend class SCEVExpander;\n  friend class SCEVUnknown;\n\n  /// The function we are analyzing.\n  Function &F;\n\n  /// Does the module have any calls to the llvm.experimental.guard intrinsic\n  /// at all?  If this is false, we avoid doing work that will only help if\n  /// thare are guards present in the IR.\n  bool HasGuards;\n\n  /// The target library information for the target we are targeting.\n  TargetLibraryInfo &TLI;\n\n  /// The tracker for \\@llvm.assume intrinsics in this function.\n  AssumptionCache &AC;\n\n  /// The dominator tree.\n  DominatorTree &DT;\n\n  /// The loop information for the function we are currently analyzing.\n  LoopInfo &LI;\n\n  /// This SCEV is used to represent unknown trip counts and things.\n  std::unique_ptr<SCEVCouldNotCompute> CouldNotCompute;\n\n  /// The type for HasRecMap.\n  using HasRecMapType = DenseMap<const SCEV *, bool>;\n\n  /// This is a cache to record whether a SCEV contains any scAddRecExpr.\n  HasRecMapType HasRecMap;\n\n  /// The type for ExprValueMap.\n  using ValueOffsetPair = std::pair<Value *, ConstantInt *>;\n  using ExprValueMapType = DenseMap<const SCEV *, SetVector<ValueOffsetPair>>;\n\n  /// ExprValueMap -- This map records the original values from which\n  /// the SCEV expr is generated from.\n  ///\n  /// We want to represent the mapping as SCEV -> ValueOffsetPair instead\n  /// of SCEV -> Value:\n  /// Suppose we know S1 expands to V1, and\n  ///  S1 = S2 + C_a\n  ///  S3 = S2 + C_b\n  /// where C_a and C_b are different SCEVConstants. Then we'd like to\n  /// expand S3 as V1 - C_a + C_b instead of expanding S2 literally.\n  /// It is helpful when S2 is a complex SCEV expr.\n  ///\n  /// In order to do that, we represent ExprValueMap as a mapping from\n  /// SCEV to ValueOffsetPair. We will save both S1->{V1, 0} and\n  /// S2->{V1, C_a} into the map when we create SCEV for V1. When S3\n  /// is expanded, it will first expand S2 to V1 - C_a because of\n  /// S2->{V1, C_a} in the map, then expand S3 to V1 - C_a + C_b.\n  ///\n  /// Note: S->{V, Offset} in the ExprValueMap means S can be expanded\n  /// to V - Offset.\n  ExprValueMapType ExprValueMap;\n\n  /// The type for ValueExprMap.\n  using ValueExprMapType =\n      DenseMap<SCEVCallbackVH, const SCEV *, DenseMapInfo<Value *>>;\n\n  /// This is a cache of the values we have analyzed so far.\n  ValueExprMapType ValueExprMap;\n\n  /// Mark predicate values currently being processed by isImpliedCond.\n  SmallPtrSet<const Value *, 6> PendingLoopPredicates;\n\n  /// Mark SCEVUnknown Phis currently being processed by getRangeRef.\n  SmallPtrSet<const PHINode *, 6> PendingPhiRanges;\n\n  // Mark SCEVUnknown Phis currently being processed by isImpliedViaMerge.\n  SmallPtrSet<const PHINode *, 6> PendingMerges;\n\n  /// Set to true by isLoopBackedgeGuardedByCond when we're walking the set of\n  /// conditions dominating the backedge of a loop.\n  bool WalkingBEDominatingConds = false;\n\n  /// Set to true by isKnownPredicateViaSplitting when we're trying to prove a\n  /// predicate by splitting it into a set of independent predicates.\n  bool ProvingSplitPredicate = false;\n\n  /// Memoized values for the GetMinTrailingZeros\n  DenseMap<const SCEV *, uint32_t> MinTrailingZerosCache;\n\n  /// Return the Value set from which the SCEV expr is generated.\n  SetVector<ValueOffsetPair> *getSCEVValues(const SCEV *S);\n\n  /// Private helper method for the GetMinTrailingZeros method\n  uint32_t GetMinTrailingZerosImpl(const SCEV *S);\n\n  /// Information about the number of loop iterations for which a loop exit's\n  /// branch condition evaluates to the not-taken path.  This is a temporary\n  /// pair of exact and max expressions that are eventually summarized in\n  /// ExitNotTakenInfo and BackedgeTakenInfo.\n  struct ExitLimit {\n    const SCEV *ExactNotTaken; // The exit is not taken exactly this many times\n    const SCEV *MaxNotTaken; // The exit is not taken at most this many times\n\n    // Not taken either exactly MaxNotTaken or zero times\n    bool MaxOrZero = false;\n\n    /// A set of predicate guards for this ExitLimit. The result is only valid\n    /// if all of the predicates in \\c Predicates evaluate to 'true' at\n    /// run-time.\n    SmallPtrSet<const SCEVPredicate *, 4> Predicates;\n\n    void addPredicate(const SCEVPredicate *P) {\n      assert(!isa<SCEVUnionPredicate>(P) && \"Only add leaf predicates here!\");\n      Predicates.insert(P);\n    }\n\n    /// Construct either an exact exit limit from a constant, or an unknown\n    /// one from a SCEVCouldNotCompute.  No other types of SCEVs are allowed\n    /// as arguments and asserts enforce that internally.\n    /*implicit*/ ExitLimit(const SCEV *E);\n\n    ExitLimit(\n        const SCEV *E, const SCEV *M, bool MaxOrZero,\n        ArrayRef<const SmallPtrSetImpl<const SCEVPredicate *> *> PredSetList);\n\n    ExitLimit(const SCEV *E, const SCEV *M, bool MaxOrZero,\n              const SmallPtrSetImpl<const SCEVPredicate *> &PredSet);\n\n    ExitLimit(const SCEV *E, const SCEV *M, bool MaxOrZero);\n\n    /// Test whether this ExitLimit contains any computed information, or\n    /// whether it's all SCEVCouldNotCompute values.\n    bool hasAnyInfo() const {\n      return !isa<SCEVCouldNotCompute>(ExactNotTaken) ||\n             !isa<SCEVCouldNotCompute>(MaxNotTaken);\n    }\n\n    bool hasOperand(const SCEV *S) const;\n\n    /// Test whether this ExitLimit contains all information.\n    bool hasFullInfo() const {\n      return !isa<SCEVCouldNotCompute>(ExactNotTaken);\n    }\n  };\n\n  /// Information about the number of times a particular loop exit may be\n  /// reached before exiting the loop.\n  struct ExitNotTakenInfo {\n    PoisoningVH<BasicBlock> ExitingBlock;\n    const SCEV *ExactNotTaken;\n    const SCEV *MaxNotTaken;\n    std::unique_ptr<SCEVUnionPredicate> Predicate;\n\n    explicit ExitNotTakenInfo(PoisoningVH<BasicBlock> ExitingBlock,\n                              const SCEV *ExactNotTaken,\n                              const SCEV *MaxNotTaken,\n                              std::unique_ptr<SCEVUnionPredicate> Predicate)\n      : ExitingBlock(ExitingBlock), ExactNotTaken(ExactNotTaken),\n        MaxNotTaken(ExactNotTaken), Predicate(std::move(Predicate)) {}\n\n    bool hasAlwaysTruePredicate() const {\n      return !Predicate || Predicate->isAlwaysTrue();\n    }\n  };\n\n  /// Information about the backedge-taken count of a loop. This currently\n  /// includes an exact count and a maximum count.\n  ///\n  class BackedgeTakenInfo {\n    /// A list of computable exits and their not-taken counts.  Loops almost\n    /// never have more than one computable exit.\n    SmallVector<ExitNotTakenInfo, 1> ExitNotTaken;\n\n    /// Expression indicating the least constant maximum backedge-taken count of\n    /// the loop that is known, or a SCEVCouldNotCompute. This expression is\n    /// only valid if the redicates associated with all loop exits are true.\n    const SCEV *ConstantMax;\n\n    /// Indicating if \\c ExitNotTaken has an element for every exiting block in\n    /// the loop.\n    bool IsComplete;\n\n    /// Expression indicating the least maximum backedge-taken count of the loop\n    /// that is known, or a SCEVCouldNotCompute. Lazily computed on first query.\n    const SCEV *SymbolicMax = nullptr;\n\n    /// True iff the backedge is taken either exactly Max or zero times.\n    bool MaxOrZero = false;\n\n    bool isComplete() const { return IsComplete; }\n    const SCEV *getConstantMax() const { return ConstantMax; }\n\n  public:\n    BackedgeTakenInfo() : ConstantMax(nullptr), IsComplete(false) {}\n    BackedgeTakenInfo(BackedgeTakenInfo &&) = default;\n    BackedgeTakenInfo &operator=(BackedgeTakenInfo &&) = default;\n\n    using EdgeExitInfo = std::pair<BasicBlock *, ExitLimit>;\n\n    /// Initialize BackedgeTakenInfo from a list of exact exit counts.\n    BackedgeTakenInfo(ArrayRef<EdgeExitInfo> ExitCounts, bool IsComplete,\n                      const SCEV *ConstantMax, bool MaxOrZero);\n\n    /// Test whether this BackedgeTakenInfo contains any computed information,\n    /// or whether it's all SCEVCouldNotCompute values.\n    bool hasAnyInfo() const {\n      return !ExitNotTaken.empty() ||\n             !isa<SCEVCouldNotCompute>(getConstantMax());\n    }\n\n    /// Test whether this BackedgeTakenInfo contains complete information.\n    bool hasFullInfo() const { return isComplete(); }\n\n    /// Return an expression indicating the exact *backedge-taken*\n    /// count of the loop if it is known or SCEVCouldNotCompute\n    /// otherwise.  If execution makes it to the backedge on every\n    /// iteration (i.e. there are no abnormal exists like exception\n    /// throws and thread exits) then this is the number of times the\n    /// loop header will execute minus one.\n    ///\n    /// If the SCEV predicate associated with the answer can be different\n    /// from AlwaysTrue, we must add a (non null) Predicates argument.\n    /// The SCEV predicate associated with the answer will be added to\n    /// Predicates. A run-time check needs to be emitted for the SCEV\n    /// predicate in order for the answer to be valid.\n    ///\n    /// Note that we should always know if we need to pass a predicate\n    /// argument or not from the way the ExitCounts vector was computed.\n    /// If we allowed SCEV predicates to be generated when populating this\n    /// vector, this information can contain them and therefore a\n    /// SCEVPredicate argument should be added to getExact.\n    const SCEV *getExact(const Loop *L, ScalarEvolution *SE,\n                         SCEVUnionPredicate *Predicates = nullptr) const;\n\n    /// Return the number of times this loop exit may fall through to the back\n    /// edge, or SCEVCouldNotCompute. The loop is guaranteed not to exit via\n    /// this block before this number of iterations, but may exit via another\n    /// block.\n    const SCEV *getExact(const BasicBlock *ExitingBlock,\n                         ScalarEvolution *SE) const;\n\n    /// Get the constant max backedge taken count for the loop.\n    const SCEV *getConstantMax(ScalarEvolution *SE) const;\n\n    /// Get the constant max backedge taken count for the particular loop exit.\n    const SCEV *getConstantMax(const BasicBlock *ExitingBlock,\n                               ScalarEvolution *SE) const;\n\n    /// Get the symbolic max backedge taken count for the loop.\n    const SCEV *getSymbolicMax(const Loop *L, ScalarEvolution *SE);\n\n    /// Return true if the number of times this backedge is taken is either the\n    /// value returned by getConstantMax or zero.\n    bool isConstantMaxOrZero(ScalarEvolution *SE) const;\n\n    /// Return true if any backedge taken count expressions refer to the given\n    /// subexpression.\n    bool hasOperand(const SCEV *S, ScalarEvolution *SE) const;\n\n    /// Invalidate this result and free associated memory.\n    void clear();\n  };\n\n  /// Cache the backedge-taken count of the loops for this function as they\n  /// are computed.\n  DenseMap<const Loop *, BackedgeTakenInfo> BackedgeTakenCounts;\n\n  /// Cache the predicated backedge-taken count of the loops for this\n  /// function as they are computed.\n  DenseMap<const Loop *, BackedgeTakenInfo> PredicatedBackedgeTakenCounts;\n\n  /// This map contains entries for all of the PHI instructions that we\n  /// attempt to compute constant evolutions for.  This allows us to avoid\n  /// potentially expensive recomputation of these properties.  An instruction\n  /// maps to null if we are unable to compute its exit value.\n  DenseMap<PHINode *, Constant *> ConstantEvolutionLoopExitValue;\n\n  /// This map contains entries for all the expressions that we attempt to\n  /// compute getSCEVAtScope information for, which can be expensive in\n  /// extreme cases.\n  DenseMap<const SCEV *, SmallVector<std::pair<const Loop *, const SCEV *>, 2>>\n      ValuesAtScopes;\n\n  /// Memoized computeLoopDisposition results.\n  DenseMap<const SCEV *,\n           SmallVector<PointerIntPair<const Loop *, 2, LoopDisposition>, 2>>\n      LoopDispositions;\n\n  struct LoopProperties {\n    /// Set to true if the loop contains no instruction that can have side\n    /// effects (i.e. via throwing an exception, volatile or atomic access).\n    bool HasNoAbnormalExits;\n\n    /// Set to true if the loop contains no instruction that can abnormally exit\n    /// the loop (i.e. via throwing an exception, by terminating the thread\n    /// cleanly or by infinite looping in a called function).  Strictly\n    /// speaking, the last one is not leaving the loop, but is identical to\n    /// leaving the loop for reasoning about undefined behavior.\n    bool HasNoSideEffects;\n  };\n\n  /// Cache for \\c getLoopProperties.\n  DenseMap<const Loop *, LoopProperties> LoopPropertiesCache;\n\n  /// Return a \\c LoopProperties instance for \\p L, creating one if necessary.\n  LoopProperties getLoopProperties(const Loop *L);\n\n  bool loopHasNoSideEffects(const Loop *L) {\n    return getLoopProperties(L).HasNoSideEffects;\n  }\n\n  bool loopHasNoAbnormalExits(const Loop *L) {\n    return getLoopProperties(L).HasNoAbnormalExits;\n  }\n\n  /// Compute a LoopDisposition value.\n  LoopDisposition computeLoopDisposition(const SCEV *S, const Loop *L);\n\n  /// Memoized computeBlockDisposition results.\n  DenseMap<\n      const SCEV *,\n      SmallVector<PointerIntPair<const BasicBlock *, 2, BlockDisposition>, 2>>\n      BlockDispositions;\n\n  /// Compute a BlockDisposition value.\n  BlockDisposition computeBlockDisposition(const SCEV *S, const BasicBlock *BB);\n\n  /// Memoized results from getRange\n  DenseMap<const SCEV *, ConstantRange> UnsignedRanges;\n\n  /// Memoized results from getRange\n  DenseMap<const SCEV *, ConstantRange> SignedRanges;\n\n  /// Used to parameterize getRange\n  enum RangeSignHint { HINT_RANGE_UNSIGNED, HINT_RANGE_SIGNED };\n\n  /// Set the memoized range for the given SCEV.\n  const ConstantRange &setRange(const SCEV *S, RangeSignHint Hint,\n                                ConstantRange CR) {\n    DenseMap<const SCEV *, ConstantRange> &Cache =\n        Hint == HINT_RANGE_UNSIGNED ? UnsignedRanges : SignedRanges;\n\n    auto Pair = Cache.try_emplace(S, std::move(CR));\n    if (!Pair.second)\n      Pair.first->second = std::move(CR);\n    return Pair.first->second;\n  }\n\n  /// Determine the range for a particular SCEV.\n  /// NOTE: This returns a reference to an entry in a cache. It must be\n  /// copied if its needed for longer.\n  const ConstantRange &getRangeRef(const SCEV *S, RangeSignHint Hint);\n\n  /// Determines the range for the affine SCEVAddRecExpr {\\p Start,+,\\p Stop}.\n  /// Helper for \\c getRange.\n  ConstantRange getRangeForAffineAR(const SCEV *Start, const SCEV *Stop,\n                                    const SCEV *MaxBECount, unsigned BitWidth);\n\n  /// Determines the range for the affine non-self-wrapping SCEVAddRecExpr {\\p\n  /// Start,+,\\p Stop}<nw>.\n  ConstantRange getRangeForAffineNoSelfWrappingAR(const SCEVAddRecExpr *AddRec,\n                                                  const SCEV *MaxBECount,\n                                                  unsigned BitWidth,\n                                                  RangeSignHint SignHint);\n\n  /// Try to compute a range for the affine SCEVAddRecExpr {\\p Start,+,\\p\n  /// Stop} by \"factoring out\" a ternary expression from the add recurrence.\n  /// Helper called by \\c getRange.\n  ConstantRange getRangeViaFactoring(const SCEV *Start, const SCEV *Stop,\n                                     const SCEV *MaxBECount, unsigned BitWidth);\n\n  /// We know that there is no SCEV for the specified value.  Analyze the\n  /// expression.\n  const SCEV *createSCEV(Value *V);\n\n  /// Provide the special handling we need to analyze PHI SCEVs.\n  const SCEV *createNodeForPHI(PHINode *PN);\n\n  /// Helper function called from createNodeForPHI.\n  const SCEV *createAddRecFromPHI(PHINode *PN);\n\n  /// A helper function for createAddRecFromPHI to handle simple cases.\n  const SCEV *createSimpleAffineAddRec(PHINode *PN, Value *BEValueV,\n                                            Value *StartValueV);\n\n  /// Helper function called from createNodeForPHI.\n  const SCEV *createNodeFromSelectLikePHI(PHINode *PN);\n\n  /// Provide special handling for a select-like instruction (currently this\n  /// is either a select instruction or a phi node).  \\p I is the instruction\n  /// being processed, and it is assumed equivalent to \"Cond ? TrueVal :\n  /// FalseVal\".\n  const SCEV *createNodeForSelectOrPHI(Instruction *I, Value *Cond,\n                                       Value *TrueVal, Value *FalseVal);\n\n  /// Provide the special handling we need to analyze GEP SCEVs.\n  const SCEV *createNodeForGEP(GEPOperator *GEP);\n\n  /// Implementation code for getSCEVAtScope; called at most once for each\n  /// SCEV+Loop pair.\n  const SCEV *computeSCEVAtScope(const SCEV *S, const Loop *L);\n\n  /// This looks up computed SCEV values for all instructions that depend on\n  /// the given instruction and removes them from the ValueExprMap map if they\n  /// reference SymName. This is used during PHI resolution.\n  void forgetSymbolicName(Instruction *I, const SCEV *SymName);\n\n  /// Return the BackedgeTakenInfo for the given loop, lazily computing new\n  /// values if the loop hasn't been analyzed yet. The returned result is\n  /// guaranteed not to be predicated.\n  BackedgeTakenInfo &getBackedgeTakenInfo(const Loop *L);\n\n  /// Similar to getBackedgeTakenInfo, but will add predicates as required\n  /// with the purpose of returning complete information.\n  const BackedgeTakenInfo &getPredicatedBackedgeTakenInfo(const Loop *L);\n\n  /// Compute the number of times the specified loop will iterate.\n  /// If AllowPredicates is set, we will create new SCEV predicates as\n  /// necessary in order to return an exact answer.\n  BackedgeTakenInfo computeBackedgeTakenCount(const Loop *L,\n                                              bool AllowPredicates = false);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if it exits via the specified block. If AllowPredicates is set,\n  /// this call will try to use a minimal set of SCEV predicates in order to\n  /// return an exact answer.\n  ExitLimit computeExitLimit(const Loop *L, BasicBlock *ExitingBlock,\n                             bool AllowPredicates = false);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if its exit condition were a conditional branch of ExitCond.\n  ///\n  /// \\p ControlsExit is true if ExitCond directly controls the exit\n  /// branch. In this case, we can assume that the loop exits only if the\n  /// condition is true and can infer that failing to meet the condition prior\n  /// to integer wraparound results in undefined behavior.\n  ///\n  /// If \\p AllowPredicates is set, this call will try to use a minimal set of\n  /// SCEV predicates in order to return an exact answer.\n  ExitLimit computeExitLimitFromCond(const Loop *L, Value *ExitCond,\n                                     bool ExitIfTrue, bool ControlsExit,\n                                     bool AllowPredicates = false);\n\n  /// Return a symbolic upper bound for the backedge taken count of the loop.\n  /// This is more general than getConstantMaxBackedgeTakenCount as it returns\n  /// an arbitrary expression as opposed to only constants.\n  const SCEV *computeSymbolicMaxBackedgeTakenCount(const Loop *L);\n\n  // Helper functions for computeExitLimitFromCond to avoid exponential time\n  // complexity.\n\n  class ExitLimitCache {\n    // It may look like we need key on the whole (L, ExitIfTrue, ControlsExit,\n    // AllowPredicates) tuple, but recursive calls to\n    // computeExitLimitFromCondCached from computeExitLimitFromCondImpl only\n    // vary the in \\c ExitCond and \\c ControlsExit parameters.  We remember the\n    // initial values of the other values to assert our assumption.\n    SmallDenseMap<PointerIntPair<Value *, 1>, ExitLimit> TripCountMap;\n\n    const Loop *L;\n    bool ExitIfTrue;\n    bool AllowPredicates;\n\n  public:\n    ExitLimitCache(const Loop *L, bool ExitIfTrue, bool AllowPredicates)\n        : L(L), ExitIfTrue(ExitIfTrue), AllowPredicates(AllowPredicates) {}\n\n    Optional<ExitLimit> find(const Loop *L, Value *ExitCond, bool ExitIfTrue,\n                             bool ControlsExit, bool AllowPredicates);\n\n    void insert(const Loop *L, Value *ExitCond, bool ExitIfTrue,\n                bool ControlsExit, bool AllowPredicates, const ExitLimit &EL);\n  };\n\n  using ExitLimitCacheTy = ExitLimitCache;\n\n  ExitLimit computeExitLimitFromCondCached(ExitLimitCacheTy &Cache,\n                                           const Loop *L, Value *ExitCond,\n                                           bool ExitIfTrue,\n                                           bool ControlsExit,\n                                           bool AllowPredicates);\n  ExitLimit computeExitLimitFromCondImpl(ExitLimitCacheTy &Cache, const Loop *L,\n                                         Value *ExitCond, bool ExitIfTrue,\n                                         bool ControlsExit,\n                                         bool AllowPredicates);\n  Optional<ScalarEvolution::ExitLimit>\n  computeExitLimitFromCondFromBinOp(ExitLimitCacheTy &Cache, const Loop *L,\n                                    Value *ExitCond, bool ExitIfTrue,\n                                    bool ControlsExit, bool AllowPredicates);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if its exit condition were a conditional branch of the ICmpInst\n  /// ExitCond and ExitIfTrue. If AllowPredicates is set, this call will try\n  /// to use a minimal set of SCEV predicates in order to return an exact\n  /// answer.\n  ExitLimit computeExitLimitFromICmp(const Loop *L, ICmpInst *ExitCond,\n                                     bool ExitIfTrue,\n                                     bool IsSubExpr,\n                                     bool AllowPredicates = false);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if its exit condition were a switch with a single exiting case\n  /// to ExitingBB.\n  ExitLimit computeExitLimitFromSingleExitSwitch(const Loop *L,\n                                                 SwitchInst *Switch,\n                                                 BasicBlock *ExitingBB,\n                                                 bool IsSubExpr);\n\n  /// Given an exit condition of 'icmp op load X, cst', try to see if we can\n  /// compute the backedge-taken count.\n  ExitLimit computeLoadConstantCompareExitLimit(LoadInst *LI, Constant *RHS,\n                                                const Loop *L,\n                                                ICmpInst::Predicate p);\n\n  /// Compute the exit limit of a loop that is controlled by a\n  /// \"(IV >> 1) != 0\" type comparison.  We cannot compute the exact trip\n  /// count in these cases (since SCEV has no way of expressing them), but we\n  /// can still sometimes compute an upper bound.\n  ///\n  /// Return an ExitLimit for a loop whose backedge is guarded by `LHS Pred\n  /// RHS`.\n  ExitLimit computeShiftCompareExitLimit(Value *LHS, Value *RHS, const Loop *L,\n                                         ICmpInst::Predicate Pred);\n\n  /// If the loop is known to execute a constant number of times (the\n  /// condition evolves only from constants), try to evaluate a few iterations\n  /// of the loop until we get the exit condition gets a value of ExitWhen\n  /// (true or false).  If we cannot evaluate the exit count of the loop,\n  /// return CouldNotCompute.\n  const SCEV *computeExitCountExhaustively(const Loop *L, Value *Cond,\n                                           bool ExitWhen);\n\n  /// Return the number of times an exit condition comparing the specified\n  /// value to zero will execute.  If not computable, return CouldNotCompute.\n  /// If AllowPredicates is set, this call will try to use a minimal set of\n  /// SCEV predicates in order to return an exact answer.\n  ExitLimit howFarToZero(const SCEV *V, const Loop *L, bool IsSubExpr,\n                         bool AllowPredicates = false);\n\n  /// Return the number of times an exit condition checking the specified\n  /// value for nonzero will execute.  If not computable, return\n  /// CouldNotCompute.\n  ExitLimit howFarToNonZero(const SCEV *V, const Loop *L);\n\n  /// Return the number of times an exit condition containing the specified\n  /// less-than comparison will execute.  If not computable, return\n  /// CouldNotCompute.\n  ///\n  /// \\p isSigned specifies whether the less-than is signed.\n  ///\n  /// \\p ControlsExit is true when the LHS < RHS condition directly controls\n  /// the branch (loops exits only if condition is true). In this case, we can\n  /// use NoWrapFlags to skip overflow checks.\n  ///\n  /// If \\p AllowPredicates is set, this call will try to use a minimal set of\n  /// SCEV predicates in order to return an exact answer.\n  ExitLimit howManyLessThans(const SCEV *LHS, const SCEV *RHS, const Loop *L,\n                             bool isSigned, bool ControlsExit,\n                             bool AllowPredicates = false);\n\n  ExitLimit howManyGreaterThans(const SCEV *LHS, const SCEV *RHS, const Loop *L,\n                                bool isSigned, bool IsSubExpr,\n                                bool AllowPredicates = false);\n\n  /// Return a predecessor of BB (which may not be an immediate predecessor)\n  /// which has exactly one successor from which BB is reachable, or null if\n  /// no such block is found.\n  std::pair<const BasicBlock *, const BasicBlock *>\n  getPredecessorWithUniqueSuccessorForBB(const BasicBlock *BB) const;\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the given FoundCondValue value evaluates to true in given\n  /// Context. If Context is nullptr, then the found predicate is true\n  /// everywhere. LHS and FoundLHS may have different type width.\n  bool isImpliedCond(ICmpInst::Predicate Pred, const SCEV *LHS, const SCEV *RHS,\n                     const Value *FoundCondValue, bool Inverse,\n                     const Instruction *Context = nullptr);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the given FoundCondValue value evaluates to true in given\n  /// Context. If Context is nullptr, then the found predicate is true\n  /// everywhere. LHS and FoundLHS must have same type width.\n  bool isImpliedCondBalancedTypes(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                  const SCEV *RHS,\n                                  ICmpInst::Predicate FoundPred,\n                                  const SCEV *FoundLHS, const SCEV *FoundRHS,\n                                  const Instruction *Context);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by FoundPred, FoundLHS, FoundRHS is\n  /// true in given Context. If Context is nullptr, then the found predicate is\n  /// true everywhere.\n  bool isImpliedCond(ICmpInst::Predicate Pred, const SCEV *LHS, const SCEV *RHS,\n                     ICmpInst::Predicate FoundPred, const SCEV *FoundLHS,\n                     const SCEV *FoundRHS,\n                     const Instruction *Context = nullptr);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true in given Context. If Context is nullptr, then the found predicate is\n  /// true everywhere.\n  bool isImpliedCondOperands(ICmpInst::Predicate Pred, const SCEV *LHS,\n                             const SCEV *RHS, const SCEV *FoundLHS,\n                             const SCEV *FoundRHS,\n                             const Instruction *Context = nullptr);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true. Here LHS is an operation that includes FoundLHS as one of its\n  /// arguments.\n  bool isImpliedViaOperations(ICmpInst::Predicate Pred,\n                              const SCEV *LHS, const SCEV *RHS,\n                              const SCEV *FoundLHS, const SCEV *FoundRHS,\n                              unsigned Depth = 0);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true.\n  /// Use only simple non-recursive types of checks, such as range analysis etc.\n  bool isKnownViaNonRecursiveReasoning(ICmpInst::Predicate Pred,\n                                       const SCEV *LHS, const SCEV *RHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  bool isImpliedCondOperandsHelper(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                   const SCEV *RHS, const SCEV *FoundLHS,\n                                   const SCEV *FoundRHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.  Utility function used by isImpliedCondOperands.  Tries to get\n  /// cases like \"X `sgt` 0 => X - 1 `sgt` -1\".\n  bool isImpliedCondOperandsViaRanges(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                      const SCEV *RHS, const SCEV *FoundLHS,\n                                      const SCEV *FoundRHS);\n\n  /// Return true if the condition denoted by \\p LHS \\p Pred \\p RHS is implied\n  /// by a call to @llvm.experimental.guard in \\p BB.\n  bool isImpliedViaGuard(const BasicBlock *BB, ICmpInst::Predicate Pred,\n                         const SCEV *LHS, const SCEV *RHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  ///\n  /// This routine tries to rule out certain kinds of integer overflow, and\n  /// then tries to reason about arithmetic properties of the predicates.\n  bool isImpliedCondOperandsViaNoOverflow(ICmpInst::Predicate Pred,\n                                          const SCEV *LHS, const SCEV *RHS,\n                                          const SCEV *FoundLHS,\n                                          const SCEV *FoundRHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  ///\n  /// This routine tries to weaken the known condition basing on fact that\n  /// FoundLHS is an AddRec.\n  bool isImpliedCondOperandsViaAddRecStart(ICmpInst::Predicate Pred,\n                                           const SCEV *LHS, const SCEV *RHS,\n                                           const SCEV *FoundLHS,\n                                           const SCEV *FoundRHS,\n                                           const Instruction *Context);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  ///\n  /// This routine tries to figure out predicate for Phis which are SCEVUnknown\n  /// if it is true for every possible incoming value from their respective\n  /// basic blocks.\n  bool isImpliedViaMerge(ICmpInst::Predicate Pred,\n                         const SCEV *LHS, const SCEV *RHS,\n                         const SCEV *FoundLHS, const SCEV *FoundRHS,\n                         unsigned Depth);\n\n  /// If we know that the specified Phi is in the header of its containing\n  /// loop, we know the loop executes a constant number of times, and the PHI\n  /// node is just a recurrence involving constants, fold it.\n  Constant *getConstantEvolutionLoopExitValue(PHINode *PN, const APInt &BEs,\n                                              const Loop *L);\n\n  /// Test if the given expression is known to satisfy the condition described\n  /// by Pred and the known constant ranges of LHS and RHS.\n  bool isKnownPredicateViaConstantRanges(ICmpInst::Predicate Pred,\n                                         const SCEV *LHS, const SCEV *RHS);\n\n  /// Try to prove the condition described by \"LHS Pred RHS\" by ruling out\n  /// integer overflow.\n  ///\n  /// For instance, this will return true for \"A s< (A + C)<nsw>\" if C is\n  /// positive.\n  bool isKnownPredicateViaNoOverflow(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                     const SCEV *RHS);\n\n  /// Try to split Pred LHS RHS into logical conjunctions (and's) and try to\n  /// prove them individually.\n  bool isKnownPredicateViaSplitting(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                    const SCEV *RHS);\n\n  /// Try to match the Expr as \"(L + R)<Flags>\".\n  bool splitBinaryAdd(const SCEV *Expr, const SCEV *&L, const SCEV *&R,\n                      SCEV::NoWrapFlags &Flags);\n\n  /// Drop memoized information computed for S.\n  void forgetMemoizedResults(const SCEV *S);\n\n  /// Return an existing SCEV for V if there is one, otherwise return nullptr.\n  const SCEV *getExistingSCEV(Value *V);\n\n  /// Return false iff given SCEV contains a SCEVUnknown with NULL value-\n  /// pointer.\n  bool checkValidity(const SCEV *S) const;\n\n  /// Return true if `ExtendOpTy`({`Start`,+,`Step`}) can be proved to be\n  /// equal to {`ExtendOpTy`(`Start`),+,`ExtendOpTy`(`Step`)}.  This is\n  /// equivalent to proving no signed (resp. unsigned) wrap in\n  /// {`Start`,+,`Step`} if `ExtendOpTy` is `SCEVSignExtendExpr`\n  /// (resp. `SCEVZeroExtendExpr`).\n  template <typename ExtendOpTy>\n  bool proveNoWrapByVaryingStart(const SCEV *Start, const SCEV *Step,\n                                 const Loop *L);\n\n  /// Try to prove NSW or NUW on \\p AR relying on ConstantRange manipulation.\n  SCEV::NoWrapFlags proveNoWrapViaConstantRanges(const SCEVAddRecExpr *AR);\n\n  /// Try to prove NSW on \\p AR by proving facts about conditions known  on\n  /// entry and backedge.\n  SCEV::NoWrapFlags proveNoSignedWrapViaInduction(const SCEVAddRecExpr *AR);\n\n  /// Try to prove NUW on \\p AR by proving facts about conditions known on\n  /// entry and backedge.\n  SCEV::NoWrapFlags proveNoUnsignedWrapViaInduction(const SCEVAddRecExpr *AR);\n\n  Optional<MonotonicPredicateType>\n  getMonotonicPredicateTypeImpl(const SCEVAddRecExpr *LHS,\n                                ICmpInst::Predicate Pred);\n\n  /// Return SCEV no-wrap flags that can be proven based on reasoning about\n  /// how poison produced from no-wrap flags on this value (e.g. a nuw add)\n  /// would trigger undefined behavior on overflow.\n  SCEV::NoWrapFlags getNoWrapFlagsFromUB(const Value *V);\n\n  /// Return true if the SCEV corresponding to \\p I is never poison.  Proving\n  /// this is more complex than proving that just \\p I is never poison, since\n  /// SCEV commons expressions across control flow, and you can have cases\n  /// like:\n  ///\n  ///   idx0 = a + b;\n  ///   ptr[idx0] = 100;\n  ///   if (<condition>) {\n  ///     idx1 = a +nsw b;\n  ///     ptr[idx1] = 200;\n  ///   }\n  ///\n  /// where the SCEV expression (+ a b) is guaranteed to not be poison (and\n  /// hence not sign-overflow) only if \"<condition>\" is true.  Since both\n  /// `idx0` and `idx1` will be mapped to the same SCEV expression, (+ a b),\n  /// it is not okay to annotate (+ a b) with <nsw> in the above example.\n  bool isSCEVExprNeverPoison(const Instruction *I);\n\n  /// This is like \\c isSCEVExprNeverPoison but it specifically works for\n  /// instructions that will get mapped to SCEV add recurrences.  Return true\n  /// if \\p I will never generate poison under the assumption that \\p I is an\n  /// add recurrence on the loop \\p L.\n  bool isAddRecNeverPoison(const Instruction *I, const Loop *L);\n\n  /// Similar to createAddRecFromPHI, but with the additional flexibility of\n  /// suggesting runtime overflow checks in case casts are encountered.\n  /// If successful, the analysis records that for this loop, \\p SymbolicPHI,\n  /// which is the UnknownSCEV currently representing the PHI, can be rewritten\n  /// into an AddRec, assuming some predicates; The function then returns the\n  /// AddRec and the predicates as a pair, and caches this pair in\n  /// PredicatedSCEVRewrites.\n  /// If the analysis is not successful, a mapping from the \\p SymbolicPHI to\n  /// itself (with no predicates) is recorded, and a nullptr with an empty\n  /// predicates vector is returned as a pair.\n  Optional<std::pair<const SCEV *, SmallVector<const SCEVPredicate *, 3>>>\n  createAddRecFromPHIWithCastsImpl(const SCEVUnknown *SymbolicPHI);\n\n  /// Compute the backedge taken count knowing the interval difference, the\n  /// stride and presence of the equality in the comparison.\n  const SCEV *computeBECount(const SCEV *Delta, const SCEV *Stride,\n                             bool Equality);\n\n  /// Compute the maximum backedge count based on the range of values\n  /// permitted by Start, End, and Stride. This is for loops of the form\n  /// {Start, +, Stride} LT End.\n  ///\n  /// Precondition: the induction variable is known to be positive.  We *don't*\n  /// assert these preconditions so please be careful.\n  const SCEV *computeMaxBECountForLT(const SCEV *Start, const SCEV *Stride,\n                                     const SCEV *End, unsigned BitWidth,\n                                     bool IsSigned);\n\n  /// Verify if an linear IV with positive stride can overflow when in a\n  /// less-than comparison, knowing the invariant term of the comparison,\n  /// the stride and the knowledge of NSW/NUW flags on the recurrence.\n  bool doesIVOverflowOnLT(const SCEV *RHS, const SCEV *Stride, bool IsSigned,\n                          bool NoWrap);\n\n  /// Verify if an linear IV with negative stride can overflow when in a\n  /// greater-than comparison, knowing the invariant term of the comparison,\n  /// the stride and the knowledge of NSW/NUW flags on the recurrence.\n  bool doesIVOverflowOnGT(const SCEV *RHS, const SCEV *Stride, bool IsSigned,\n                          bool NoWrap);\n\n  /// Get add expr already created or create a new one.\n  const SCEV *getOrCreateAddExpr(ArrayRef<const SCEV *> Ops,\n                                 SCEV::NoWrapFlags Flags);\n\n  /// Get mul expr already created or create a new one.\n  const SCEV *getOrCreateMulExpr(ArrayRef<const SCEV *> Ops,\n                                 SCEV::NoWrapFlags Flags);\n\n  // Get addrec expr already created or create a new one.\n  const SCEV *getOrCreateAddRecExpr(ArrayRef<const SCEV *> Ops,\n                                    const Loop *L, SCEV::NoWrapFlags Flags);\n\n  /// Return x if \\p Val is f(x) where f is a 1-1 function.\n  const SCEV *stripInjectiveFunctions(const SCEV *Val) const;\n\n  /// Find all of the loops transitively used in \\p S, and fill \\p LoopsUsed.\n  /// A loop is considered \"used\" by an expression if it contains\n  /// an add rec on said loop.\n  void getUsedLoops(const SCEV *S, SmallPtrSetImpl<const Loop *> &LoopsUsed);\n\n  /// Find all of the loops transitively used in \\p S, and update \\c LoopUsers\n  /// accordingly.\n  void addToLoopUseLists(const SCEV *S);\n\n  /// Try to match the pattern generated by getURemExpr(A, B). If successful,\n  /// Assign A and B to LHS and RHS, respectively.\n  bool matchURem(const SCEV *Expr, const SCEV *&LHS, const SCEV *&RHS);\n\n  /// Look for a SCEV expression with type `SCEVType` and operands `Ops` in\n  /// `UniqueSCEVs`.\n  ///\n  /// The first component of the returned tuple is the SCEV if found and null\n  /// otherwise.  The second component is the `FoldingSetNodeID` that was\n  /// constructed to look up the SCEV and the third component is the insertion\n  /// point.\n  std::tuple<SCEV *, FoldingSetNodeID, void *>\n  findExistingSCEVInCache(SCEVTypes SCEVType, ArrayRef<const SCEV *> Ops);\n\n  FoldingSet<SCEV> UniqueSCEVs;\n  FoldingSet<SCEVPredicate> UniquePreds;\n  BumpPtrAllocator SCEVAllocator;\n\n  /// This maps loops to a list of SCEV expressions that (transitively) use said\n  /// loop.\n  DenseMap<const Loop *, SmallVector<const SCEV *, 4>> LoopUsers;\n\n  /// Cache tentative mappings from UnknownSCEVs in a Loop, to a SCEV expression\n  /// they can be rewritten into under certain predicates.\n  DenseMap<std::pair<const SCEVUnknown *, const Loop *>,\n           std::pair<const SCEV *, SmallVector<const SCEVPredicate *, 3>>>\n      PredicatedSCEVRewrites;\n\n  /// The head of a linked list of all SCEVUnknown values that have been\n  /// allocated. This is used by releaseMemory to locate them all and call\n  /// their destructors.\n  SCEVUnknown *FirstUnknown = nullptr;\n};\n\n/// Analysis pass that exposes the \\c ScalarEvolution for a function.\nclass ScalarEvolutionAnalysis\n    : public AnalysisInfoMixin<ScalarEvolutionAnalysis> {\n  friend AnalysisInfoMixin<ScalarEvolutionAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = ScalarEvolution;\n\n  ScalarEvolution run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c ScalarEvolutionAnalysis results.\nclass ScalarEvolutionVerifierPass\n    : public PassInfoMixin<ScalarEvolutionVerifierPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c ScalarEvolutionAnalysis results.\nclass ScalarEvolutionPrinterPass\n    : public PassInfoMixin<ScalarEvolutionPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit ScalarEvolutionPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass ScalarEvolutionWrapperPass : public FunctionPass {\n  std::unique_ptr<ScalarEvolution> SE;\n\npublic:\n  static char ID;\n\n  ScalarEvolutionWrapperPass();\n\n  ScalarEvolution &getSE() { return *SE; }\n  const ScalarEvolution &getSE() const { return *SE; }\n\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  void print(raw_ostream &OS, const Module * = nullptr) const override;\n  void verifyAnalysis() const override;\n};\n\n/// An interface layer with SCEV used to manage how we see SCEV expressions\n/// for values in the context of existing predicates. We can add new\n/// predicates, but we cannot remove them.\n///\n/// This layer has multiple purposes:\n///   - provides a simple interface for SCEV versioning.\n///   - guarantees that the order of transformations applied on a SCEV\n///     expression for a single Value is consistent across two different\n///     getSCEV calls. This means that, for example, once we've obtained\n///     an AddRec expression for a certain value through expression\n///     rewriting, we will continue to get an AddRec expression for that\n///     Value.\n///   - lowers the number of expression rewrites.\nclass PredicatedScalarEvolution {\npublic:\n  PredicatedScalarEvolution(ScalarEvolution &SE, Loop &L);\n\n  const SCEVUnionPredicate &getUnionPredicate() const;\n\n  /// Returns the SCEV expression of V, in the context of the current SCEV\n  /// predicate.  The order of transformations applied on the expression of V\n  /// returned by ScalarEvolution is guaranteed to be preserved, even when\n  /// adding new predicates.\n  const SCEV *getSCEV(Value *V);\n\n  /// Get the (predicated) backedge count for the analyzed loop.\n  const SCEV *getBackedgeTakenCount();\n\n  /// Adds a new predicate.\n  void addPredicate(const SCEVPredicate &Pred);\n\n  /// Attempts to produce an AddRecExpr for V by adding additional SCEV\n  /// predicates. If we can't transform the expression into an AddRecExpr we\n  /// return nullptr and not add additional SCEV predicates to the current\n  /// context.\n  const SCEVAddRecExpr *getAsAddRec(Value *V);\n\n  /// Proves that V doesn't overflow by adding SCEV predicate.\n  void setNoOverflow(Value *V, SCEVWrapPredicate::IncrementWrapFlags Flags);\n\n  /// Returns true if we've proved that V doesn't wrap by means of a SCEV\n  /// predicate.\n  bool hasNoOverflow(Value *V, SCEVWrapPredicate::IncrementWrapFlags Flags);\n\n  /// Returns the ScalarEvolution analysis used.\n  ScalarEvolution *getSE() const { return &SE; }\n\n  /// We need to explicitly define the copy constructor because of FlagsMap.\n  PredicatedScalarEvolution(const PredicatedScalarEvolution &);\n\n  /// Print the SCEV mappings done by the Predicated Scalar Evolution.\n  /// The printed text is indented by \\p Depth.\n  void print(raw_ostream &OS, unsigned Depth) const;\n\n  /// Check if \\p AR1 and \\p AR2 are equal, while taking into account\n  /// Equal predicates in Preds.\n  bool areAddRecsEqualWithPreds(const SCEVAddRecExpr *AR1,\n                                const SCEVAddRecExpr *AR2) const;\n\nprivate:\n  /// Increments the version number of the predicate.  This needs to be called\n  /// every time the SCEV predicate changes.\n  void updateGeneration();\n\n  /// Holds a SCEV and the version number of the SCEV predicate used to\n  /// perform the rewrite of the expression.\n  using RewriteEntry = std::pair<unsigned, const SCEV *>;\n\n  /// Maps a SCEV to the rewrite result of that SCEV at a certain version\n  /// number. If this number doesn't match the current Generation, we will\n  /// need to do a rewrite. To preserve the transformation order of previous\n  /// rewrites, we will rewrite the previous result instead of the original\n  /// SCEV.\n  DenseMap<const SCEV *, RewriteEntry> RewriteMap;\n\n  /// Records what NoWrap flags we've added to a Value *.\n  ValueMap<Value *, SCEVWrapPredicate::IncrementWrapFlags> FlagsMap;\n\n  /// The ScalarEvolution analysis.\n  ScalarEvolution &SE;\n\n  /// The analyzed Loop.\n  const Loop &L;\n\n  /// The SCEVPredicate that forms our context. We will rewrite all\n  /// expressions assuming that this predicate true.\n  SCEVUnionPredicate Preds;\n\n  /// Marks the version of the SCEV predicate used. When rewriting a SCEV\n  /// expression we mark it with the version of the predicate. We use this to\n  /// figure out if the predicate has changed from the last rewrite of the\n  /// SCEV. If so, we need to perform a new rewrite.\n  unsigned Generation = 0;\n\n  /// The backedge taken count.\n  const SCEV *BackedgeCount = nullptr;\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_SCALAREVOLUTION_H\n"}, "30": {"id": 30, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "content": "//===- llvm/Analysis/ScalarEvolutionExpressions.h - SCEV Exprs --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the classes used to represent and build scalar expressions.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_SCALAREVOLUTIONEXPRESSIONS_H\n#define LLVM_ANALYSIS_SCALAREVOLUTIONEXPRESSIONS_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Analysis/ScalarEvolution.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include <cassert>\n#include <cstddef>\n\nnamespace llvm {\n\nclass APInt;\nclass Constant;\nclass ConstantRange;\nclass Loop;\nclass Type;\n\n  enum SCEVTypes : unsigned short {\n    // These should be ordered in terms of increasing complexity to make the\n    // folders simpler.\n    scConstant, scTruncate, scZeroExtend, scSignExtend, scAddExpr, scMulExpr,\n    scUDivExpr, scAddRecExpr, scUMaxExpr, scSMaxExpr, scUMinExpr, scSMinExpr,\n    scPtrToInt, scUnknown, scCouldNotCompute\n  };\n\n  /// This class represents a constant integer value.\n  class SCEVConstant : public SCEV {\n    friend class ScalarEvolution;\n\n    ConstantInt *V;\n\n    SCEVConstant(const FoldingSetNodeIDRef ID, ConstantInt *v) :\n      SCEV(ID, scConstant, 1), V(v) {}\n\n  public:\n    ConstantInt *getValue() const { return V; }\n    const APInt &getAPInt() const { return getValue()->getValue(); }\n\n    Type *getType() const { return V->getType(); }\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scConstant;\n    }\n  };\n\n  inline unsigned short computeExpressionSize(ArrayRef<const SCEV *> Args) {\n    APInt Size(16, 1);\n    for (auto *Arg : Args)\n      Size = Size.uadd_sat(APInt(16, Arg->getExpressionSize()));\n    return (unsigned short)Size.getZExtValue();\n  }\n\n  /// This is the base class for unary cast operator classes.\n  class SCEVCastExpr : public SCEV {\n  protected:\n    std::array<const SCEV *, 1> Operands;\n    Type *Ty;\n\n    SCEVCastExpr(const FoldingSetNodeIDRef ID, SCEVTypes SCEVTy, const SCEV *op,\n                 Type *ty);\n\n  public:\n    const SCEV *getOperand() const { return Operands[0]; }\n    const SCEV *getOperand(unsigned i) const {\n      assert(i == 0 && \"Operand index out of range!\");\n      return Operands[0];\n    }\n    using op_iterator = std::array<const SCEV *, 1>::const_iterator;\n    using op_range = iterator_range<op_iterator>;\n\n    op_range operands() const {\n      return make_range(Operands.begin(), Operands.end());\n    }\n    size_t getNumOperands() const { return 1; }\n    Type *getType() const { return Ty; }\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scPtrToInt || S->getSCEVType() == scTruncate ||\n             S->getSCEVType() == scZeroExtend ||\n             S->getSCEVType() == scSignExtend;\n    }\n  };\n\n  /// This class represents a cast from a pointer to a pointer-sized integer\n  /// value.\n  class SCEVPtrToIntExpr : public SCEVCastExpr {\n    friend class ScalarEvolution;\n\n    SCEVPtrToIntExpr(const FoldingSetNodeIDRef ID, const SCEV *Op, Type *ITy);\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scPtrToInt;\n    }\n  };\n\n  /// This is the base class for unary integral cast operator classes.\n  class SCEVIntegralCastExpr : public SCEVCastExpr {\n  protected:\n    SCEVIntegralCastExpr(const FoldingSetNodeIDRef ID, SCEVTypes SCEVTy,\n                         const SCEV *op, Type *ty);\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scTruncate ||\n             S->getSCEVType() == scZeroExtend ||\n             S->getSCEVType() == scSignExtend;\n    }\n  };\n\n  /// This class represents a truncation of an integer value to a\n  /// smaller integer value.\n  class SCEVTruncateExpr : public SCEVIntegralCastExpr {\n    friend class ScalarEvolution;\n\n    SCEVTruncateExpr(const FoldingSetNodeIDRef ID,\n                     const SCEV *op, Type *ty);\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scTruncate;\n    }\n  };\n\n  /// This class represents a zero extension of a small integer value\n  /// to a larger integer value.\n  class SCEVZeroExtendExpr : public SCEVIntegralCastExpr {\n    friend class ScalarEvolution;\n\n    SCEVZeroExtendExpr(const FoldingSetNodeIDRef ID,\n                       const SCEV *op, Type *ty);\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scZeroExtend;\n    }\n  };\n\n  /// This class represents a sign extension of a small integer value\n  /// to a larger integer value.\n  class SCEVSignExtendExpr : public SCEVIntegralCastExpr {\n    friend class ScalarEvolution;\n\n    SCEVSignExtendExpr(const FoldingSetNodeIDRef ID,\n                       const SCEV *op, Type *ty);\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scSignExtend;\n    }\n  };\n\n  /// This node is a base class providing common functionality for\n  /// n'ary operators.\n  class SCEVNAryExpr : public SCEV {\n  protected:\n    // Since SCEVs are immutable, ScalarEvolution allocates operand\n    // arrays with its SCEVAllocator, so this class just needs a simple\n    // pointer rather than a more elaborate vector-like data structure.\n    // This also avoids the need for a non-trivial destructor.\n    const SCEV *const *Operands;\n    size_t NumOperands;\n\n    SCEVNAryExpr(const FoldingSetNodeIDRef ID, enum SCEVTypes T,\n                 const SCEV *const *O, size_t N)\n        : SCEV(ID, T, computeExpressionSize(makeArrayRef(O, N))), Operands(O),\n          NumOperands(N) {}\n\n  public:\n    size_t getNumOperands() const { return NumOperands; }\n\n    const SCEV *getOperand(unsigned i) const {\n      assert(i < NumOperands && \"Operand index out of range!\");\n      return Operands[i];\n    }\n\n    using op_iterator = const SCEV *const *;\n    using op_range = iterator_range<op_iterator>;\n\n    op_iterator op_begin() const { return Operands; }\n    op_iterator op_end() const { return Operands + NumOperands; }\n    op_range operands() const {\n      return make_range(op_begin(), op_end());\n    }\n\n    Type *getType() const { return getOperand(0)->getType(); }\n\n    NoWrapFlags getNoWrapFlags(NoWrapFlags Mask = NoWrapMask) const {\n      return (NoWrapFlags)(SubclassData & Mask);\n    }\n\n    bool hasNoUnsignedWrap() const {\n      return getNoWrapFlags(FlagNUW) != FlagAnyWrap;\n    }\n\n    bool hasNoSignedWrap() const {\n      return getNoWrapFlags(FlagNSW) != FlagAnyWrap;\n    }\n\n    bool hasNoSelfWrap() const {\n      return getNoWrapFlags(FlagNW) != FlagAnyWrap;\n    }\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scAddExpr || S->getSCEVType() == scMulExpr ||\n             S->getSCEVType() == scSMaxExpr || S->getSCEVType() == scUMaxExpr ||\n             S->getSCEVType() == scSMinExpr || S->getSCEVType() == scUMinExpr ||\n             S->getSCEVType() == scAddRecExpr;\n    }\n  };\n\n  /// This node is the base class for n'ary commutative operators.\n  class SCEVCommutativeExpr : public SCEVNAryExpr {\n  protected:\n    SCEVCommutativeExpr(const FoldingSetNodeIDRef ID,\n                        enum SCEVTypes T, const SCEV *const *O, size_t N)\n      : SCEVNAryExpr(ID, T, O, N) {}\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scAddExpr || S->getSCEVType() == scMulExpr ||\n             S->getSCEVType() == scSMaxExpr || S->getSCEVType() == scUMaxExpr ||\n             S->getSCEVType() == scSMinExpr || S->getSCEVType() == scUMinExpr;\n    }\n\n    /// Set flags for a non-recurrence without clearing previously set flags.\n    void setNoWrapFlags(NoWrapFlags Flags) {\n      SubclassData |= Flags;\n    }\n  };\n\n  /// This node represents an addition of some number of SCEVs.\n  class SCEVAddExpr : public SCEVCommutativeExpr {\n    friend class ScalarEvolution;\n\n    Type *Ty;\n\n    SCEVAddExpr(const FoldingSetNodeIDRef ID, const SCEV *const *O, size_t N)\n        : SCEVCommutativeExpr(ID, scAddExpr, O, N) {\n      auto *FirstPointerTypedOp = find_if(operands(), [](const SCEV *Op) {\n        return Op->getType()->isPointerTy();\n      });\n      if (FirstPointerTypedOp != operands().end())\n        Ty = (*FirstPointerTypedOp)->getType();\n      else\n        Ty = getOperand(0)->getType();\n    }\n\n  public:\n    Type *getType() const { return Ty; }\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scAddExpr;\n    }\n  };\n\n  /// This node represents multiplication of some number of SCEVs.\n  class SCEVMulExpr : public SCEVCommutativeExpr {\n    friend class ScalarEvolution;\n\n    SCEVMulExpr(const FoldingSetNodeIDRef ID,\n                const SCEV *const *O, size_t N)\n      : SCEVCommutativeExpr(ID, scMulExpr, O, N) {}\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scMulExpr;\n    }\n  };\n\n  /// This class represents a binary unsigned division operation.\n  class SCEVUDivExpr : public SCEV {\n    friend class ScalarEvolution;\n\n    std::array<const SCEV *, 2> Operands;\n\n    SCEVUDivExpr(const FoldingSetNodeIDRef ID, const SCEV *lhs, const SCEV *rhs)\n        : SCEV(ID, scUDivExpr, computeExpressionSize({lhs, rhs})) {\n        Operands[0] = lhs;\n        Operands[1] = rhs;\n      }\n\n  public:\n    const SCEV *getLHS() const { return Operands[0]; }\n    const SCEV *getRHS() const { return Operands[1]; }\n    size_t getNumOperands() const { return 2; }\n    const SCEV *getOperand(unsigned i) const {\n      assert((i == 0 || i == 1) && \"Operand index out of range!\");\n      return i == 0 ? getLHS() : getRHS();\n    }\n\n    using op_iterator = std::array<const SCEV *, 2>::const_iterator;\n    using op_range = iterator_range<op_iterator>;\n    op_range operands() const {\n      return make_range(Operands.begin(), Operands.end());\n    }\n\n    Type *getType() const {\n      // In most cases the types of LHS and RHS will be the same, but in some\n      // crazy cases one or the other may be a pointer. ScalarEvolution doesn't\n      // depend on the type for correctness, but handling types carefully can\n      // avoid extra casts in the SCEVExpander. The LHS is more likely to be\n      // a pointer type than the RHS, so use the RHS' type here.\n      return getRHS()->getType();\n    }\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scUDivExpr;\n    }\n  };\n\n  /// This node represents a polynomial recurrence on the trip count\n  /// of the specified loop.  This is the primary focus of the\n  /// ScalarEvolution framework; all the other SCEV subclasses are\n  /// mostly just supporting infrastructure to allow SCEVAddRecExpr\n  /// expressions to be created and analyzed.\n  ///\n  /// All operands of an AddRec are required to be loop invariant.\n  ///\n  class SCEVAddRecExpr : public SCEVNAryExpr {\n    friend class ScalarEvolution;\n\n    const Loop *L;\n\n    SCEVAddRecExpr(const FoldingSetNodeIDRef ID,\n                   const SCEV *const *O, size_t N, const Loop *l)\n      : SCEVNAryExpr(ID, scAddRecExpr, O, N), L(l) {}\n\n  public:\n    const SCEV *getStart() const { return Operands[0]; }\n    const Loop *getLoop() const { return L; }\n\n    /// Constructs and returns the recurrence indicating how much this\n    /// expression steps by.  If this is a polynomial of degree N, it\n    /// returns a chrec of degree N-1.  We cannot determine whether\n    /// the step recurrence has self-wraparound.\n    const SCEV *getStepRecurrence(ScalarEvolution &SE) const {\n      if (isAffine()) return getOperand(1);\n      return SE.getAddRecExpr(SmallVector<const SCEV *, 3>(op_begin()+1,\n                                                           op_end()),\n                              getLoop(), FlagAnyWrap);\n    }\n\n    /// Return true if this represents an expression A + B*x where A\n    /// and B are loop invariant values.\n    bool isAffine() const {\n      // We know that the start value is invariant.  This expression is thus\n      // affine iff the step is also invariant.\n      return getNumOperands() == 2;\n    }\n\n    /// Return true if this represents an expression A + B*x + C*x^2\n    /// where A, B and C are loop invariant values.  This corresponds\n    /// to an addrec of the form {L,+,M,+,N}\n    bool isQuadratic() const {\n      return getNumOperands() == 3;\n    }\n\n    /// Set flags for a recurrence without clearing any previously set flags.\n    /// For AddRec, either NUW or NSW implies NW. Keep track of this fact here\n    /// to make it easier to propagate flags.\n    void setNoWrapFlags(NoWrapFlags Flags) {\n      if (Flags & (FlagNUW | FlagNSW))\n        Flags = ScalarEvolution::setFlags(Flags, FlagNW);\n      SubclassData |= Flags;\n    }\n\n    /// Return the value of this chain of recurrences at the specified\n    /// iteration number.\n    const SCEV *evaluateAtIteration(const SCEV *It, ScalarEvolution &SE) const;\n\n    /// Return the number of iterations of this loop that produce\n    /// values in the specified constant range.  Another way of\n    /// looking at this is that it returns the first iteration number\n    /// where the value is not in the condition, thus computing the\n    /// exit count.  If the iteration count can't be computed, an\n    /// instance of SCEVCouldNotCompute is returned.\n    const SCEV *getNumIterationsInRange(const ConstantRange &Range,\n                                        ScalarEvolution &SE) const;\n\n    /// Return an expression representing the value of this expression\n    /// one iteration of the loop ahead.\n    const SCEVAddRecExpr *getPostIncExpr(ScalarEvolution &SE) const;\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scAddRecExpr;\n    }\n  };\n\n  /// This node is the base class min/max selections.\n  class SCEVMinMaxExpr : public SCEVCommutativeExpr {\n    friend class ScalarEvolution;\n\n    static bool isMinMaxType(enum SCEVTypes T) {\n      return T == scSMaxExpr || T == scUMaxExpr || T == scSMinExpr ||\n             T == scUMinExpr;\n    }\n\n  protected:\n    /// Note: Constructing subclasses via this constructor is allowed\n    SCEVMinMaxExpr(const FoldingSetNodeIDRef ID, enum SCEVTypes T,\n                   const SCEV *const *O, size_t N)\n        : SCEVCommutativeExpr(ID, T, O, N) {\n      assert(isMinMaxType(T));\n      // Min and max never overflow\n      setNoWrapFlags((NoWrapFlags)(FlagNUW | FlagNSW));\n    }\n\n  public:\n    static bool classof(const SCEV *S) {\n      return isMinMaxType(S->getSCEVType());\n    }\n\n    static enum SCEVTypes negate(enum SCEVTypes T) {\n      switch (T) {\n      case scSMaxExpr:\n        return scSMinExpr;\n      case scSMinExpr:\n        return scSMaxExpr;\n      case scUMaxExpr:\n        return scUMinExpr;\n      case scUMinExpr:\n        return scUMaxExpr;\n      default:\n        llvm_unreachable(\"Not a min or max SCEV type!\");\n      }\n    }\n  };\n\n  /// This class represents a signed maximum selection.\n  class SCEVSMaxExpr : public SCEVMinMaxExpr {\n    friend class ScalarEvolution;\n\n    SCEVSMaxExpr(const FoldingSetNodeIDRef ID, const SCEV *const *O, size_t N)\n        : SCEVMinMaxExpr(ID, scSMaxExpr, O, N) {}\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scSMaxExpr;\n    }\n  };\n\n  /// This class represents an unsigned maximum selection.\n  class SCEVUMaxExpr : public SCEVMinMaxExpr {\n    friend class ScalarEvolution;\n\n    SCEVUMaxExpr(const FoldingSetNodeIDRef ID, const SCEV *const *O, size_t N)\n        : SCEVMinMaxExpr(ID, scUMaxExpr, O, N) {}\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scUMaxExpr;\n    }\n  };\n\n  /// This class represents a signed minimum selection.\n  class SCEVSMinExpr : public SCEVMinMaxExpr {\n    friend class ScalarEvolution;\n\n    SCEVSMinExpr(const FoldingSetNodeIDRef ID, const SCEV *const *O, size_t N)\n        : SCEVMinMaxExpr(ID, scSMinExpr, O, N) {}\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scSMinExpr;\n    }\n  };\n\n  /// This class represents an unsigned minimum selection.\n  class SCEVUMinExpr : public SCEVMinMaxExpr {\n    friend class ScalarEvolution;\n\n    SCEVUMinExpr(const FoldingSetNodeIDRef ID, const SCEV *const *O, size_t N)\n        : SCEVMinMaxExpr(ID, scUMinExpr, O, N) {}\n\n  public:\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scUMinExpr;\n    }\n  };\n\n  /// This means that we are dealing with an entirely unknown SCEV\n  /// value, and only represent it as its LLVM Value.  This is the\n  /// \"bottom\" value for the analysis.\n  class SCEVUnknown final : public SCEV, private CallbackVH {\n    friend class ScalarEvolution;\n\n    /// The parent ScalarEvolution value. This is used to update the\n    /// parent's maps when the value associated with a SCEVUnknown is\n    /// deleted or RAUW'd.\n    ScalarEvolution *SE;\n\n    /// The next pointer in the linked list of all SCEVUnknown\n    /// instances owned by a ScalarEvolution.\n    SCEVUnknown *Next;\n\n    SCEVUnknown(const FoldingSetNodeIDRef ID, Value *V,\n                ScalarEvolution *se, SCEVUnknown *next) :\n      SCEV(ID, scUnknown, 1), CallbackVH(V), SE(se), Next(next) {}\n\n    // Implement CallbackVH.\n    void deleted() override;\n    void allUsesReplacedWith(Value *New) override;\n\n  public:\n    Value *getValue() const { return getValPtr(); }\n\n    /// @{\n    /// Test whether this is a special constant representing a type\n    /// size, alignment, or field offset in a target-independent\n    /// manner, and hasn't happened to have been folded with other\n    /// operations into something unrecognizable. This is mainly only\n    /// useful for pretty-printing and other situations where it isn't\n    /// absolutely required for these to succeed.\n    bool isSizeOf(Type *&AllocTy) const;\n    bool isAlignOf(Type *&AllocTy) const;\n    bool isOffsetOf(Type *&STy, Constant *&FieldNo) const;\n    /// @}\n\n    Type *getType() const { return getValPtr()->getType(); }\n\n    /// Methods for support type inquiry through isa, cast, and dyn_cast:\n    static bool classof(const SCEV *S) {\n      return S->getSCEVType() == scUnknown;\n    }\n  };\n\n  /// This class defines a simple visitor class that may be used for\n  /// various SCEV analysis purposes.\n  template<typename SC, typename RetVal=void>\n  struct SCEVVisitor {\n    RetVal visit(const SCEV *S) {\n      switch (S->getSCEVType()) {\n      case scConstant:\n        return ((SC*)this)->visitConstant((const SCEVConstant*)S);\n      case scPtrToInt:\n        return ((SC *)this)->visitPtrToIntExpr((const SCEVPtrToIntExpr *)S);\n      case scTruncate:\n        return ((SC*)this)->visitTruncateExpr((const SCEVTruncateExpr*)S);\n      case scZeroExtend:\n        return ((SC*)this)->visitZeroExtendExpr((const SCEVZeroExtendExpr*)S);\n      case scSignExtend:\n        return ((SC*)this)->visitSignExtendExpr((const SCEVSignExtendExpr*)S);\n      case scAddExpr:\n        return ((SC*)this)->visitAddExpr((const SCEVAddExpr*)S);\n      case scMulExpr:\n        return ((SC*)this)->visitMulExpr((const SCEVMulExpr*)S);\n      case scUDivExpr:\n        return ((SC*)this)->visitUDivExpr((const SCEVUDivExpr*)S);\n      case scAddRecExpr:\n        return ((SC*)this)->visitAddRecExpr((const SCEVAddRecExpr*)S);\n      case scSMaxExpr:\n        return ((SC*)this)->visitSMaxExpr((const SCEVSMaxExpr*)S);\n      case scUMaxExpr:\n        return ((SC*)this)->visitUMaxExpr((const SCEVUMaxExpr*)S);\n      case scSMinExpr:\n        return ((SC *)this)->visitSMinExpr((const SCEVSMinExpr *)S);\n      case scUMinExpr:\n        return ((SC *)this)->visitUMinExpr((const SCEVUMinExpr *)S);\n      case scUnknown:\n        return ((SC*)this)->visitUnknown((const SCEVUnknown*)S);\n      case scCouldNotCompute:\n        return ((SC*)this)->visitCouldNotCompute((const SCEVCouldNotCompute*)S);\n      }\n      llvm_unreachable(\"Unknown SCEV kind!\");\n    }\n\n    RetVal visitCouldNotCompute(const SCEVCouldNotCompute *S) {\n      llvm_unreachable(\"Invalid use of SCEVCouldNotCompute!\");\n    }\n  };\n\n  /// Visit all nodes in the expression tree using worklist traversal.\n  ///\n  /// Visitor implements:\n  ///   // return true to follow this node.\n  ///   bool follow(const SCEV *S);\n  ///   // return true to terminate the search.\n  ///   bool isDone();\n  template<typename SV>\n  class SCEVTraversal {\n    SV &Visitor;\n    SmallVector<const SCEV *, 8> Worklist;\n    SmallPtrSet<const SCEV *, 8> Visited;\n\n    void push(const SCEV *S) {\n      if (Visited.insert(S).second && Visitor.follow(S))\n        Worklist.push_back(S);\n    }\n\n  public:\n    SCEVTraversal(SV& V): Visitor(V) {}\n\n    void visitAll(const SCEV *Root) {\n      push(Root);\n      while (!Worklist.empty() && !Visitor.isDone()) {\n        const SCEV *S = Worklist.pop_back_val();\n\n        switch (S->getSCEVType()) {\n        case scConstant:\n        case scUnknown:\n          continue;\n        case scPtrToInt:\n        case scTruncate:\n        case scZeroExtend:\n        case scSignExtend:\n          push(cast<SCEVCastExpr>(S)->getOperand());\n          continue;\n        case scAddExpr:\n        case scMulExpr:\n        case scSMaxExpr:\n        case scUMaxExpr:\n        case scSMinExpr:\n        case scUMinExpr:\n        case scAddRecExpr:\n          for (const auto *Op : cast<SCEVNAryExpr>(S)->operands())\n            push(Op);\n          continue;\n        case scUDivExpr: {\n          const SCEVUDivExpr *UDiv = cast<SCEVUDivExpr>(S);\n          push(UDiv->getLHS());\n          push(UDiv->getRHS());\n          continue;\n        }\n        case scCouldNotCompute:\n          llvm_unreachable(\"Attempt to use a SCEVCouldNotCompute object!\");\n        }\n        llvm_unreachable(\"Unknown SCEV kind!\");\n      }\n    }\n  };\n\n  /// Use SCEVTraversal to visit all nodes in the given expression tree.\n  template<typename SV>\n  void visitAll(const SCEV *Root, SV& Visitor) {\n    SCEVTraversal<SV> T(Visitor);\n    T.visitAll(Root);\n  }\n\n  /// Return true if any node in \\p Root satisfies the predicate \\p Pred.\n  template <typename PredTy>\n  bool SCEVExprContains(const SCEV *Root, PredTy Pred) {\n    struct FindClosure {\n      bool Found = false;\n      PredTy Pred;\n\n      FindClosure(PredTy Pred) : Pred(Pred) {}\n\n      bool follow(const SCEV *S) {\n        if (!Pred(S))\n          return true;\n\n        Found = true;\n        return false;\n      }\n\n      bool isDone() const { return Found; }\n    };\n\n    FindClosure FC(Pred);\n    visitAll(Root, FC);\n    return FC.Found;\n  }\n\n  /// This visitor recursively visits a SCEV expression and re-writes it.\n  /// The result from each visit is cached, so it will return the same\n  /// SCEV for the same input.\n  template<typename SC>\n  class SCEVRewriteVisitor : public SCEVVisitor<SC, const SCEV *> {\n  protected:\n    ScalarEvolution &SE;\n    // Memoize the result of each visit so that we only compute once for\n    // the same input SCEV. This is to avoid redundant computations when\n    // a SCEV is referenced by multiple SCEVs. Without memoization, this\n    // visit algorithm would have exponential time complexity in the worst\n    // case, causing the compiler to hang on certain tests.\n    DenseMap<const SCEV *, const SCEV *> RewriteResults;\n\n  public:\n    SCEVRewriteVisitor(ScalarEvolution &SE) : SE(SE) {}\n\n    const SCEV *visit(const SCEV *S) {\n      auto It = RewriteResults.find(S);\n      if (It != RewriteResults.end())\n        return It->second;\n      auto* Visited = SCEVVisitor<SC, const SCEV *>::visit(S);\n      auto Result = RewriteResults.try_emplace(S, Visited);\n      assert(Result.second && \"Should insert a new entry\");\n      return Result.first->second;\n    }\n\n    const SCEV *visitConstant(const SCEVConstant *Constant) {\n      return Constant;\n    }\n\n    const SCEV *visitPtrToIntExpr(const SCEVPtrToIntExpr *Expr) {\n      const SCEV *Operand = ((SC *)this)->visit(Expr->getOperand());\n      return Operand == Expr->getOperand()\n                 ? Expr\n                 : SE.getPtrToIntExpr(Operand, Expr->getType());\n    }\n\n    const SCEV *visitTruncateExpr(const SCEVTruncateExpr *Expr) {\n      const SCEV *Operand = ((SC*)this)->visit(Expr->getOperand());\n      return Operand == Expr->getOperand()\n                 ? Expr\n                 : SE.getTruncateExpr(Operand, Expr->getType());\n    }\n\n    const SCEV *visitZeroExtendExpr(const SCEVZeroExtendExpr *Expr) {\n      const SCEV *Operand = ((SC*)this)->visit(Expr->getOperand());\n      return Operand == Expr->getOperand()\n                 ? Expr\n                 : SE.getZeroExtendExpr(Operand, Expr->getType());\n    }\n\n    const SCEV *visitSignExtendExpr(const SCEVSignExtendExpr *Expr) {\n      const SCEV *Operand = ((SC*)this)->visit(Expr->getOperand());\n      return Operand == Expr->getOperand()\n                 ? Expr\n                 : SE.getSignExtendExpr(Operand, Expr->getType());\n    }\n\n    const SCEV *visitAddExpr(const SCEVAddExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC*)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr : SE.getAddExpr(Operands);\n    }\n\n    const SCEV *visitMulExpr(const SCEVMulExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC*)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr : SE.getMulExpr(Operands);\n    }\n\n    const SCEV *visitUDivExpr(const SCEVUDivExpr *Expr) {\n      auto *LHS = ((SC *)this)->visit(Expr->getLHS());\n      auto *RHS = ((SC *)this)->visit(Expr->getRHS());\n      bool Changed = LHS != Expr->getLHS() || RHS != Expr->getRHS();\n      return !Changed ? Expr : SE.getUDivExpr(LHS, RHS);\n    }\n\n    const SCEV *visitAddRecExpr(const SCEVAddRecExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC*)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr\n                      : SE.getAddRecExpr(Operands, Expr->getLoop(),\n                                         Expr->getNoWrapFlags());\n    }\n\n    const SCEV *visitSMaxExpr(const SCEVSMaxExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC *)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr : SE.getSMaxExpr(Operands);\n    }\n\n    const SCEV *visitUMaxExpr(const SCEVUMaxExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC*)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr : SE.getUMaxExpr(Operands);\n    }\n\n    const SCEV *visitSMinExpr(const SCEVSMinExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC *)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr : SE.getSMinExpr(Operands);\n    }\n\n    const SCEV *visitUMinExpr(const SCEVUMinExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      bool Changed = false;\n      for (auto *Op : Expr->operands()) {\n        Operands.push_back(((SC *)this)->visit(Op));\n        Changed |= Op != Operands.back();\n      }\n      return !Changed ? Expr : SE.getUMinExpr(Operands);\n    }\n\n    const SCEV *visitUnknown(const SCEVUnknown *Expr) {\n      return Expr;\n    }\n\n    const SCEV *visitCouldNotCompute(const SCEVCouldNotCompute *Expr) {\n      return Expr;\n    }\n  };\n\n  using ValueToValueMap = DenseMap<const Value *, Value *>;\n  using ValueToSCEVMapTy = DenseMap<const Value *, const SCEV *>;\n\n  /// The SCEVParameterRewriter takes a scalar evolution expression and updates\n  /// the SCEVUnknown components following the Map (Value -> SCEV).\n  class SCEVParameterRewriter : public SCEVRewriteVisitor<SCEVParameterRewriter> {\n  public:\n    static const SCEV *rewrite(const SCEV *Scev, ScalarEvolution &SE,\n                               ValueToSCEVMapTy &Map) {\n      SCEVParameterRewriter Rewriter(SE, Map);\n      return Rewriter.visit(Scev);\n    }\n\n    SCEVParameterRewriter(ScalarEvolution &SE, ValueToSCEVMapTy &M)\n        : SCEVRewriteVisitor(SE), Map(M) {}\n\n    const SCEV *visitUnknown(const SCEVUnknown *Expr) {\n      auto I = Map.find(Expr->getValue());\n      if (I == Map.end())\n        return Expr;\n      return I->second;\n    }\n\n  private:\n    ValueToSCEVMapTy &Map;\n  };\n\n  using LoopToScevMapT = DenseMap<const Loop *, const SCEV *>;\n\n  /// The SCEVLoopAddRecRewriter takes a scalar evolution expression and applies\n  /// the Map (Loop -> SCEV) to all AddRecExprs.\n  class SCEVLoopAddRecRewriter\n      : public SCEVRewriteVisitor<SCEVLoopAddRecRewriter> {\n  public:\n    SCEVLoopAddRecRewriter(ScalarEvolution &SE, LoopToScevMapT &M)\n        : SCEVRewriteVisitor(SE), Map(M) {}\n\n    static const SCEV *rewrite(const SCEV *Scev, LoopToScevMapT &Map,\n                               ScalarEvolution &SE) {\n      SCEVLoopAddRecRewriter Rewriter(SE, Map);\n      return Rewriter.visit(Scev);\n    }\n\n    const SCEV *visitAddRecExpr(const SCEVAddRecExpr *Expr) {\n      SmallVector<const SCEV *, 2> Operands;\n      for (const SCEV *Op : Expr->operands())\n        Operands.push_back(visit(Op));\n\n      const Loop *L = Expr->getLoop();\n      const SCEV *Res = SE.getAddRecExpr(Operands, L, Expr->getNoWrapFlags());\n\n      if (0 == Map.count(L))\n        return Res;\n\n      const SCEVAddRecExpr *Rec = cast<SCEVAddRecExpr>(Res);\n      return Rec->evaluateAtIteration(Map[L], SE);\n    }\n\n  private:\n    LoopToScevMapT &Map;\n  };\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_SCALAREVOLUTIONEXPRESSIONS_H\n"}, "31": {"id": 31, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h", "content": "//===- TargetTransformInfo.h ------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This pass exposes codegen information to IR-level passes. Every\n/// transformation that uses codegen information is broken into three parts:\n/// 1. The IR-level analysis pass.\n/// 2. The IR-level transformation interface which provides the needed\n///    information.\n/// 3. Codegen-level implementation which uses target-specific hooks.\n///\n/// This file defines #2, which is the interface that IR-level transformations\n/// use for querying the codegen.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_TARGETTRANSFORMINFO_H\n#define LLVM_ANALYSIS_TARGETTRANSFORMINFO_H\n\n#include \"llvm/Analysis/IVDescriptors.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Operator.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/AtomicOrdering.h\"\n#include \"llvm/Support/DataTypes.h\"\n#include \"llvm/Support/InstructionCost.h\"\n#include <functional>\n\nnamespace llvm {\n\nnamespace Intrinsic {\ntypedef unsigned ID;\n}\n\nclass AssumptionCache;\nclass BlockFrequencyInfo;\nclass DominatorTree;\nclass BranchInst;\nclass CallBase;\nclass ExtractElementInst;\nclass Function;\nclass GlobalValue;\nclass InstCombiner;\nclass IntrinsicInst;\nclass LoadInst;\nclass LoopAccessInfo;\nclass Loop;\nclass LoopInfo;\nclass ProfileSummaryInfo;\nclass SCEV;\nclass ScalarEvolution;\nclass StoreInst;\nclass SwitchInst;\nclass TargetLibraryInfo;\nclass Type;\nclass User;\nclass Value;\nstruct KnownBits;\ntemplate <typename T> class Optional;\n\n/// Information about a load/store intrinsic defined by the target.\nstruct MemIntrinsicInfo {\n  /// This is the pointer that the intrinsic is loading from or storing to.\n  /// If this is non-null, then analysis/optimization passes can assume that\n  /// this intrinsic is functionally equivalent to a load/store from this\n  /// pointer.\n  Value *PtrVal = nullptr;\n\n  // Ordering for atomic operations.\n  AtomicOrdering Ordering = AtomicOrdering::NotAtomic;\n\n  // Same Id is set by the target for corresponding load/store intrinsics.\n  unsigned short MatchingId = 0;\n\n  bool ReadMem = false;\n  bool WriteMem = false;\n  bool IsVolatile = false;\n\n  bool isUnordered() const {\n    return (Ordering == AtomicOrdering::NotAtomic ||\n            Ordering == AtomicOrdering::Unordered) &&\n           !IsVolatile;\n  }\n};\n\n/// Attributes of a target dependent hardware loop.\nstruct HardwareLoopInfo {\n  HardwareLoopInfo() = delete;\n  HardwareLoopInfo(Loop *L) : L(L) {}\n  Loop *L = nullptr;\n  BasicBlock *ExitBlock = nullptr;\n  BranchInst *ExitBranch = nullptr;\n  const SCEV *TripCount = nullptr;\n  IntegerType *CountType = nullptr;\n  Value *LoopDecrement = nullptr; // Decrement the loop counter by this\n                                  // value in every iteration.\n  bool IsNestingLegal = false;    // Can a hardware loop be a parent to\n                                  // another hardware loop?\n  bool CounterInReg = false;      // Should loop counter be updated in\n                                  // the loop via a phi?\n  bool PerformEntryTest = false;  // Generate the intrinsic which also performs\n                                  // icmp ne zero on the loop counter value and\n                                  // produces an i1 to guard the loop entry.\n  bool isHardwareLoopCandidate(ScalarEvolution &SE, LoopInfo &LI,\n                               DominatorTree &DT, bool ForceNestedLoop = false,\n                               bool ForceHardwareLoopPHI = false);\n  bool canAnalyze(LoopInfo &LI);\n};\n\nclass IntrinsicCostAttributes {\n  const IntrinsicInst *II = nullptr;\n  Type *RetTy = nullptr;\n  Intrinsic::ID IID;\n  SmallVector<Type *, 4> ParamTys;\n  SmallVector<const Value *, 4> Arguments;\n  FastMathFlags FMF;\n  // If ScalarizationCost is UINT_MAX, the cost of scalarizing the\n  // arguments and the return value will be computed based on types.\n  unsigned ScalarizationCost = std::numeric_limits<unsigned>::max();\n\npublic:\n  IntrinsicCostAttributes(\n      Intrinsic::ID Id, const CallBase &CI,\n      unsigned ScalarizationCost = std::numeric_limits<unsigned>::max());\n\n  IntrinsicCostAttributes(\n      Intrinsic::ID Id, Type *RTy, ArrayRef<Type *> Tys,\n      FastMathFlags Flags = FastMathFlags(), const IntrinsicInst *I = nullptr,\n      unsigned ScalarCost = std::numeric_limits<unsigned>::max());\n\n  IntrinsicCostAttributes(Intrinsic::ID Id, Type *RTy,\n                          ArrayRef<const Value *> Args);\n\n  IntrinsicCostAttributes(\n      Intrinsic::ID Id, Type *RTy, ArrayRef<const Value *> Args,\n      ArrayRef<Type *> Tys, FastMathFlags Flags = FastMathFlags(),\n      const IntrinsicInst *I = nullptr,\n      unsigned ScalarCost = std::numeric_limits<unsigned>::max());\n\n  Intrinsic::ID getID() const { return IID; }\n  const IntrinsicInst *getInst() const { return II; }\n  Type *getReturnType() const { return RetTy; }\n  FastMathFlags getFlags() const { return FMF; }\n  unsigned getScalarizationCost() const { return ScalarizationCost; }\n  const SmallVectorImpl<const Value *> &getArgs() const { return Arguments; }\n  const SmallVectorImpl<Type *> &getArgTypes() const { return ParamTys; }\n\n  bool isTypeBasedOnly() const {\n    return Arguments.empty();\n  }\n\n  bool skipScalarizationCost() const {\n    return ScalarizationCost != std::numeric_limits<unsigned>::max();\n  }\n};\n\nclass TargetTransformInfo;\ntypedef TargetTransformInfo TTI;\n\n/// This pass provides access to the codegen interfaces that are needed\n/// for IR-level transformations.\nclass TargetTransformInfo {\npublic:\n  /// Construct a TTI object using a type implementing the \\c Concept\n  /// API below.\n  ///\n  /// This is used by targets to construct a TTI wrapping their target-specific\n  /// implementation that encodes appropriate costs for their target.\n  template <typename T> TargetTransformInfo(T Impl);\n\n  /// Construct a baseline TTI object using a minimal implementation of\n  /// the \\c Concept API below.\n  ///\n  /// The TTI implementation will reflect the information in the DataLayout\n  /// provided if non-null.\n  explicit TargetTransformInfo(const DataLayout &DL);\n\n  // Provide move semantics.\n  TargetTransformInfo(TargetTransformInfo &&Arg);\n  TargetTransformInfo &operator=(TargetTransformInfo &&RHS);\n\n  // We need to define the destructor out-of-line to define our sub-classes\n  // out-of-line.\n  ~TargetTransformInfo();\n\n  /// Handle the invalidation of this information.\n  ///\n  /// When used as a result of \\c TargetIRAnalysis this method will be called\n  /// when the function this was computed for changes. When it returns false,\n  /// the information is preserved across those changes.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    // FIXME: We should probably in some way ensure that the subtarget\n    // information for a function hasn't changed.\n    return false;\n  }\n\n  /// \\name Generic Target Information\n  /// @{\n\n  /// The kind of cost model.\n  ///\n  /// There are several different cost models that can be customized by the\n  /// target. The normalization of each cost model may be target specific.\n  enum TargetCostKind {\n    TCK_RecipThroughput, ///< Reciprocal throughput.\n    TCK_Latency,         ///< The latency of instruction.\n    TCK_CodeSize,        ///< Instruction code size.\n    TCK_SizeAndLatency   ///< The weighted sum of size and latency.\n  };\n\n  /// Query the cost of a specified instruction.\n  ///\n  /// Clients should use this interface to query the cost of an existing\n  /// instruction. The instruction must have a valid parent (basic block).\n  ///\n  /// Note, this method does not cache the cost calculation and it\n  /// can be expensive in some cases.\n  InstructionCost getInstructionCost(const Instruction *I,\n                                     enum TargetCostKind kind) const {\n    InstructionCost Cost;\n    switch (kind) {\n    case TCK_RecipThroughput:\n      Cost = getInstructionThroughput(I);\n      break;\n    case TCK_Latency:\n      Cost = getInstructionLatency(I);\n      break;\n    case TCK_CodeSize:\n    case TCK_SizeAndLatency:\n      Cost = getUserCost(I, kind);\n      break;\n    }\n    if (Cost == -1)\n      Cost.setInvalid();\n    return Cost;\n  }\n\n  /// Underlying constants for 'cost' values in this interface.\n  ///\n  /// Many APIs in this interface return a cost. This enum defines the\n  /// fundamental values that should be used to interpret (and produce) those\n  /// costs. The costs are returned as an int rather than a member of this\n  /// enumeration because it is expected that the cost of one IR instruction\n  /// may have a multiplicative factor to it or otherwise won't fit directly\n  /// into the enum. Moreover, it is common to sum or average costs which works\n  /// better as simple integral values. Thus this enum only provides constants.\n  /// Also note that the returned costs are signed integers to make it natural\n  /// to add, subtract, and test with zero (a common boundary condition). It is\n  /// not expected that 2^32 is a realistic cost to be modeling at any point.\n  ///\n  /// Note that these costs should usually reflect the intersection of code-size\n  /// cost and execution cost. A free instruction is typically one that folds\n  /// into another instruction. For example, reg-to-reg moves can often be\n  /// skipped by renaming the registers in the CPU, but they still are encoded\n  /// and thus wouldn't be considered 'free' here.\n  enum TargetCostConstants {\n    TCC_Free = 0,     ///< Expected to fold away in lowering.\n    TCC_Basic = 1,    ///< The cost of a typical 'add' instruction.\n    TCC_Expensive = 4 ///< The cost of a 'div' instruction on x86.\n  };\n\n  /// Estimate the cost of a GEP operation when lowered.\n  int getGEPCost(Type *PointeeType, const Value *Ptr,\n                 ArrayRef<const Value *> Operands,\n                 TargetCostKind CostKind = TCK_SizeAndLatency) const;\n\n  /// \\returns A value by which our inlining threshold should be multiplied.\n  /// This is primarily used to bump up the inlining threshold wholesale on\n  /// targets where calls are unusually expensive.\n  ///\n  /// TODO: This is a rather blunt instrument.  Perhaps altering the costs of\n  /// individual classes of instructions would be better.\n  unsigned getInliningThresholdMultiplier() const;\n\n  /// \\returns A value to be added to the inlining threshold.\n  unsigned adjustInliningThreshold(const CallBase *CB) const;\n\n  /// \\returns Vector bonus in percent.\n  ///\n  /// Vector bonuses: We want to more aggressively inline vector-dense kernels\n  /// and apply this bonus based on the percentage of vector instructions. A\n  /// bonus is applied if the vector instructions exceed 50% and half that\n  /// amount is applied if it exceeds 10%. Note that these bonuses are some what\n  /// arbitrary and evolved over time by accident as much as because they are\n  /// principled bonuses.\n  /// FIXME: It would be nice to base the bonus values on something more\n  /// scientific. A target may has no bonus on vector instructions.\n  int getInlinerVectorBonusPercent() const;\n\n  /// \\return the expected cost of a memcpy, which could e.g. depend on the\n  /// source/destination type and alignment and the number of bytes copied.\n  int getMemcpyCost(const Instruction *I) const;\n\n  /// \\return The estimated number of case clusters when lowering \\p 'SI'.\n  /// \\p JTSize Set a jump table size only when \\p SI is suitable for a jump\n  /// table.\n  unsigned getEstimatedNumberOfCaseClusters(const SwitchInst &SI,\n                                            unsigned &JTSize,\n                                            ProfileSummaryInfo *PSI,\n                                            BlockFrequencyInfo *BFI) const;\n\n  /// Estimate the cost of a given IR user when lowered.\n  ///\n  /// This can estimate the cost of either a ConstantExpr or Instruction when\n  /// lowered.\n  ///\n  /// \\p Operands is a list of operands which can be a result of transformations\n  /// of the current operands. The number of the operands on the list must equal\n  /// to the number of the current operands the IR user has. Their order on the\n  /// list must be the same as the order of the current operands the IR user\n  /// has.\n  ///\n  /// The returned cost is defined in terms of \\c TargetCostConstants, see its\n  /// comments for a detailed explanation of the cost values.\n  int getUserCost(const User *U, ArrayRef<const Value *> Operands,\n                  TargetCostKind CostKind) const;\n\n  /// This is a helper function which calls the two-argument getUserCost\n  /// with \\p Operands which are the current operands U has.\n  int getUserCost(const User *U, TargetCostKind CostKind) const {\n    SmallVector<const Value *, 4> Operands(U->operand_values());\n    return getUserCost(U, Operands, CostKind);\n  }\n\n  /// Return true if branch divergence exists.\n  ///\n  /// Branch divergence has a significantly negative impact on GPU performance\n  /// when threads in the same wavefront take different paths due to conditional\n  /// branches.\n  bool hasBranchDivergence() const;\n\n  /// Return true if the target prefers to use GPU divergence analysis to\n  /// replace the legacy version.\n  bool useGPUDivergenceAnalysis() const;\n\n  /// Returns whether V is a source of divergence.\n  ///\n  /// This function provides the target-dependent information for\n  /// the target-independent LegacyDivergenceAnalysis. LegacyDivergenceAnalysis\n  /// first builds the dependency graph, and then runs the reachability\n  /// algorithm starting with the sources of divergence.\n  bool isSourceOfDivergence(const Value *V) const;\n\n  // Returns true for the target specific\n  // set of operations which produce uniform result\n  // even taking non-uniform arguments\n  bool isAlwaysUniform(const Value *V) const;\n\n  /// Returns the address space ID for a target's 'flat' address space. Note\n  /// this is not necessarily the same as addrspace(0), which LLVM sometimes\n  /// refers to as the generic address space. The flat address space is a\n  /// generic address space that can be used access multiple segments of memory\n  /// with different address spaces. Access of a memory location through a\n  /// pointer with this address space is expected to be legal but slower\n  /// compared to the same memory location accessed through a pointer with a\n  /// different address space.\n  //\n  /// This is for targets with different pointer representations which can\n  /// be converted with the addrspacecast instruction. If a pointer is converted\n  /// to this address space, optimizations should attempt to replace the access\n  /// with the source address space.\n  ///\n  /// \\returns ~0u if the target does not have such a flat address space to\n  /// optimize away.\n  unsigned getFlatAddressSpace() const;\n\n  /// Return any intrinsic address operand indexes which may be rewritten if\n  /// they use a flat address space pointer.\n  ///\n  /// \\returns true if the intrinsic was handled.\n  bool collectFlatAddressOperands(SmallVectorImpl<int> &OpIndexes,\n                                  Intrinsic::ID IID) const;\n\n  bool isNoopAddrSpaceCast(unsigned FromAS, unsigned ToAS) const;\n\n  unsigned getAssumedAddrSpace(const Value *V) const;\n\n  /// Rewrite intrinsic call \\p II such that \\p OldV will be replaced with \\p\n  /// NewV, which has a different address space. This should happen for every\n  /// operand index that collectFlatAddressOperands returned for the intrinsic.\n  /// \\returns nullptr if the intrinsic was not handled. Otherwise, returns the\n  /// new value (which may be the original \\p II with modified operands).\n  Value *rewriteIntrinsicWithAddressSpace(IntrinsicInst *II, Value *OldV,\n                                          Value *NewV) const;\n\n  /// Test whether calls to a function lower to actual program function\n  /// calls.\n  ///\n  /// The idea is to test whether the program is likely to require a 'call'\n  /// instruction or equivalent in order to call the given function.\n  ///\n  /// FIXME: It's not clear that this is a good or useful query API. Client's\n  /// should probably move to simpler cost metrics using the above.\n  /// Alternatively, we could split the cost interface into distinct code-size\n  /// and execution-speed costs. This would allow modelling the core of this\n  /// query more accurately as a call is a single small instruction, but\n  /// incurs significant execution cost.\n  bool isLoweredToCall(const Function *F) const;\n\n  struct LSRCost {\n    /// TODO: Some of these could be merged. Also, a lexical ordering\n    /// isn't always optimal.\n    unsigned Insns;\n    unsigned NumRegs;\n    unsigned AddRecCost;\n    unsigned NumIVMuls;\n    unsigned NumBaseAdds;\n    unsigned ImmCost;\n    unsigned SetupCost;\n    unsigned ScaleCost;\n  };\n\n  /// Parameters that control the generic loop unrolling transformation.\n  struct UnrollingPreferences {\n    /// The cost threshold for the unrolled loop. Should be relative to the\n    /// getUserCost values returned by this API, and the expectation is that\n    /// the unrolled loop's instructions when run through that interface should\n    /// not exceed this cost. However, this is only an estimate. Also, specific\n    /// loops may be unrolled even with a cost above this threshold if deemed\n    /// profitable. Set this to UINT_MAX to disable the loop body cost\n    /// restriction.\n    unsigned Threshold;\n    /// If complete unrolling will reduce the cost of the loop, we will boost\n    /// the Threshold by a certain percent to allow more aggressive complete\n    /// unrolling. This value provides the maximum boost percentage that we\n    /// can apply to Threshold (The value should be no less than 100).\n    /// BoostedThreshold = Threshold * min(RolledCost / UnrolledCost,\n    ///                                    MaxPercentThresholdBoost / 100)\n    /// E.g. if complete unrolling reduces the loop execution time by 50%\n    /// then we boost the threshold by the factor of 2x. If unrolling is not\n    /// expected to reduce the running time, then we do not increase the\n    /// threshold.\n    unsigned MaxPercentThresholdBoost;\n    /// The cost threshold for the unrolled loop when optimizing for size (set\n    /// to UINT_MAX to disable).\n    unsigned OptSizeThreshold;\n    /// The cost threshold for the unrolled loop, like Threshold, but used\n    /// for partial/runtime unrolling (set to UINT_MAX to disable).\n    unsigned PartialThreshold;\n    /// The cost threshold for the unrolled loop when optimizing for size, like\n    /// OptSizeThreshold, but used for partial/runtime unrolling (set to\n    /// UINT_MAX to disable).\n    unsigned PartialOptSizeThreshold;\n    /// A forced unrolling factor (the number of concatenated bodies of the\n    /// original loop in the unrolled loop body). When set to 0, the unrolling\n    /// transformation will select an unrolling factor based on the current cost\n    /// threshold and other factors.\n    unsigned Count;\n    /// Default unroll count for loops with run-time trip count.\n    unsigned DefaultUnrollRuntimeCount;\n    // Set the maximum unrolling factor. The unrolling factor may be selected\n    // using the appropriate cost threshold, but may not exceed this number\n    // (set to UINT_MAX to disable). This does not apply in cases where the\n    // loop is being fully unrolled.\n    unsigned MaxCount;\n    /// Set the maximum unrolling factor for full unrolling. Like MaxCount, but\n    /// applies even if full unrolling is selected. This allows a target to fall\n    /// back to Partial unrolling if full unrolling is above FullUnrollMaxCount.\n    unsigned FullUnrollMaxCount;\n    // Represents number of instructions optimized when \"back edge\"\n    // becomes \"fall through\" in unrolled loop.\n    // For now we count a conditional branch on a backedge and a comparison\n    // feeding it.\n    unsigned BEInsns;\n    /// Allow partial unrolling (unrolling of loops to expand the size of the\n    /// loop body, not only to eliminate small constant-trip-count loops).\n    bool Partial;\n    /// Allow runtime unrolling (unrolling of loops to expand the size of the\n    /// loop body even when the number of loop iterations is not known at\n    /// compile time).\n    bool Runtime;\n    /// Allow generation of a loop remainder (extra iterations after unroll).\n    bool AllowRemainder;\n    /// Allow emitting expensive instructions (such as divisions) when computing\n    /// the trip count of a loop for runtime unrolling.\n    bool AllowExpensiveTripCount;\n    /// Apply loop unroll on any kind of loop\n    /// (mainly to loops that fail runtime unrolling).\n    bool Force;\n    /// Allow using trip count upper bound to unroll loops.\n    bool UpperBound;\n    /// Allow unrolling of all the iterations of the runtime loop remainder.\n    bool UnrollRemainder;\n    /// Allow unroll and jam. Used to enable unroll and jam for the target.\n    bool UnrollAndJam;\n    /// Threshold for unroll and jam, for inner loop size. The 'Threshold'\n    /// value above is used during unroll and jam for the outer loop size.\n    /// This value is used in the same manner to limit the size of the inner\n    /// loop.\n    unsigned UnrollAndJamInnerLoopThreshold;\n    /// Don't allow loop unrolling to simulate more than this number of\n    /// iterations when checking full unroll profitability\n    unsigned MaxIterationsCountToAnalyze;\n  };\n\n  /// Get target-customized preferences for the generic loop unrolling\n  /// transformation. The caller will initialize UP with the current\n  /// target-independent defaults.\n  void getUnrollingPreferences(Loop *L, ScalarEvolution &,\n                               UnrollingPreferences &UP) const;\n\n  /// Query the target whether it would be profitable to convert the given loop\n  /// into a hardware loop.\n  bool isHardwareLoopProfitable(Loop *L, ScalarEvolution &SE,\n                                AssumptionCache &AC, TargetLibraryInfo *LibInfo,\n                                HardwareLoopInfo &HWLoopInfo) const;\n\n  /// Query the target whether it would be prefered to create a predicated\n  /// vector loop, which can avoid the need to emit a scalar epilogue loop.\n  bool preferPredicateOverEpilogue(Loop *L, LoopInfo *LI, ScalarEvolution &SE,\n                                   AssumptionCache &AC, TargetLibraryInfo *TLI,\n                                   DominatorTree *DT,\n                                   const LoopAccessInfo *LAI) const;\n\n  /// Query the target whether lowering of the llvm.get.active.lane.mask\n  /// intrinsic is supported.\n  bool emitGetActiveLaneMask() const;\n\n  // Parameters that control the loop peeling transformation\n  struct PeelingPreferences {\n    /// A forced peeling factor (the number of bodied of the original loop\n    /// that should be peeled off before the loop body). When set to 0, the\n    /// a peeling factor based on profile information and other factors.\n    unsigned PeelCount;\n    /// Allow peeling off loop iterations.\n    bool AllowPeeling;\n    /// Allow peeling off loop iterations for loop nests.\n    bool AllowLoopNestsPeeling;\n    /// Allow peeling basing on profile. Uses to enable peeling off all\n    /// iterations basing on provided profile.\n    /// If the value is true the peeling cost model can decide to peel only\n    /// some iterations and in this case it will set this to false.\n    bool PeelProfiledIterations;\n  };\n\n  /// Get target-customized preferences for the generic loop peeling\n  /// transformation. The caller will initialize \\p PP with the current\n  /// target-independent defaults with information from \\p L and \\p SE.\n  void getPeelingPreferences(Loop *L, ScalarEvolution &SE,\n                             PeelingPreferences &PP) const;\n\n  /// Targets can implement their own combinations for target-specific\n  /// intrinsics. This function will be called from the InstCombine pass every\n  /// time a target-specific intrinsic is encountered.\n  ///\n  /// \\returns None to not do anything target specific or a value that will be\n  /// returned from the InstCombiner. It is possible to return null and stop\n  /// further processing of the intrinsic by returning nullptr.\n  Optional<Instruction *> instCombineIntrinsic(InstCombiner &IC,\n                                               IntrinsicInst &II) const;\n  /// Can be used to implement target-specific instruction combining.\n  /// \\see instCombineIntrinsic\n  Optional<Value *>\n  simplifyDemandedUseBitsIntrinsic(InstCombiner &IC, IntrinsicInst &II,\n                                   APInt DemandedMask, KnownBits &Known,\n                                   bool &KnownBitsComputed) const;\n  /// Can be used to implement target-specific instruction combining.\n  /// \\see instCombineIntrinsic\n  Optional<Value *> simplifyDemandedVectorEltsIntrinsic(\n      InstCombiner &IC, IntrinsicInst &II, APInt DemandedElts, APInt &UndefElts,\n      APInt &UndefElts2, APInt &UndefElts3,\n      std::function<void(Instruction *, unsigned, APInt, APInt &)>\n          SimplifyAndSetOp) const;\n  /// @}\n\n  /// \\name Scalar Target Information\n  /// @{\n\n  /// Flags indicating the kind of support for population count.\n  ///\n  /// Compared to the SW implementation, HW support is supposed to\n  /// significantly boost the performance when the population is dense, and it\n  /// may or may not degrade performance if the population is sparse. A HW\n  /// support is considered as \"Fast\" if it can outperform, or is on a par\n  /// with, SW implementation when the population is sparse; otherwise, it is\n  /// considered as \"Slow\".\n  enum PopcntSupportKind { PSK_Software, PSK_SlowHardware, PSK_FastHardware };\n\n  /// Return true if the specified immediate is legal add immediate, that\n  /// is the target has add instructions which can add a register with the\n  /// immediate without having to materialize the immediate into a register.\n  bool isLegalAddImmediate(int64_t Imm) const;\n\n  /// Return true if the specified immediate is legal icmp immediate,\n  /// that is the target has icmp instructions which can compare a register\n  /// against the immediate without having to materialize the immediate into a\n  /// register.\n  bool isLegalICmpImmediate(int64_t Imm) const;\n\n  /// Return true if the addressing mode represented by AM is legal for\n  /// this target, for a load/store of the specified type.\n  /// The type may be VoidTy, in which case only return true if the addressing\n  /// mode is legal for a load/store of any legal type.\n  /// If target returns true in LSRWithInstrQueries(), I may be valid.\n  /// TODO: Handle pre/postinc as well.\n  bool isLegalAddressingMode(Type *Ty, GlobalValue *BaseGV, int64_t BaseOffset,\n                             bool HasBaseReg, int64_t Scale,\n                             unsigned AddrSpace = 0,\n                             Instruction *I = nullptr) const;\n\n  /// Return true if LSR cost of C1 is lower than C1.\n  bool isLSRCostLess(TargetTransformInfo::LSRCost &C1,\n                     TargetTransformInfo::LSRCost &C2) const;\n\n  /// Return true if LSR major cost is number of registers. Targets which\n  /// implement their own isLSRCostLess and unset number of registers as major\n  /// cost should return false, otherwise return true.\n  bool isNumRegsMajorCostOfLSR() const;\n\n  /// \\returns true if LSR should not optimize a chain that includes \\p I.\n  bool isProfitableLSRChainElement(Instruction *I) const;\n\n  /// Return true if the target can fuse a compare and branch.\n  /// Loop-strength-reduction (LSR) uses that knowledge to adjust its cost\n  /// calculation for the instructions in a loop.\n  bool canMacroFuseCmp() const;\n\n  /// Return true if the target can save a compare for loop count, for example\n  /// hardware loop saves a compare.\n  bool canSaveCmp(Loop *L, BranchInst **BI, ScalarEvolution *SE, LoopInfo *LI,\n                  DominatorTree *DT, AssumptionCache *AC,\n                  TargetLibraryInfo *LibInfo) const;\n\n  enum AddressingModeKind {\n    AMK_PreIndexed,\n    AMK_PostIndexed,\n    AMK_None\n  };\n\n  /// Return the preferred addressing mode LSR should make efforts to generate.\n  AddressingModeKind getPreferredAddressingMode(const Loop *L,\n                                                ScalarEvolution *SE) const;\n\n  /// Return true if the target supports masked store.\n  bool isLegalMaskedStore(Type *DataType, Align Alignment) const;\n  /// Return true if the target supports masked load.\n  bool isLegalMaskedLoad(Type *DataType, Align Alignment) const;\n\n  /// Return true if the target supports nontemporal store.\n  bool isLegalNTStore(Type *DataType, Align Alignment) const;\n  /// Return true if the target supports nontemporal load.\n  bool isLegalNTLoad(Type *DataType, Align Alignment) const;\n\n  /// Return true if the target supports masked scatter.\n  bool isLegalMaskedScatter(Type *DataType, Align Alignment) const;\n  /// Return true if the target supports masked gather.\n  bool isLegalMaskedGather(Type *DataType, Align Alignment) const;\n\n  /// Return true if the target supports masked compress store.\n  bool isLegalMaskedCompressStore(Type *DataType) const;\n  /// Return true if the target supports masked expand load.\n  bool isLegalMaskedExpandLoad(Type *DataType) const;\n\n  /// Return true if the target has a unified operation to calculate division\n  /// and remainder. If so, the additional implicit multiplication and\n  /// subtraction required to calculate a remainder from division are free. This\n  /// can enable more aggressive transformations for division and remainder than\n  /// would typically be allowed using throughput or size cost models.\n  bool hasDivRemOp(Type *DataType, bool IsSigned) const;\n\n  /// Return true if the given instruction (assumed to be a memory access\n  /// instruction) has a volatile variant. If that's the case then we can avoid\n  /// addrspacecast to generic AS for volatile loads/stores. Default\n  /// implementation returns false, which prevents address space inference for\n  /// volatile loads/stores.\n  bool hasVolatileVariant(Instruction *I, unsigned AddrSpace) const;\n\n  /// Return true if target doesn't mind addresses in vectors.\n  bool prefersVectorizedAddressing() const;\n\n  /// Return the cost of the scaling factor used in the addressing\n  /// mode represented by AM for this target, for a load/store\n  /// of the specified type.\n  /// If the AM is supported, the return value must be >= 0.\n  /// If the AM is not supported, it returns a negative value.\n  /// TODO: Handle pre/postinc as well.\n  int getScalingFactorCost(Type *Ty, GlobalValue *BaseGV, int64_t BaseOffset,\n                           bool HasBaseReg, int64_t Scale,\n                           unsigned AddrSpace = 0) const;\n\n  /// Return true if the loop strength reduce pass should make\n  /// Instruction* based TTI queries to isLegalAddressingMode(). This is\n  /// needed on SystemZ, where e.g. a memcpy can only have a 12 bit unsigned\n  /// immediate offset and no index register.\n  bool LSRWithInstrQueries() const;\n\n  /// Return true if it's free to truncate a value of type Ty1 to type\n  /// Ty2. e.g. On x86 it's free to truncate a i32 value in register EAX to i16\n  /// by referencing its sub-register AX.\n  bool isTruncateFree(Type *Ty1, Type *Ty2) const;\n\n  /// Return true if it is profitable to hoist instruction in the\n  /// then/else to before if.\n  bool isProfitableToHoist(Instruction *I) const;\n\n  bool useAA() const;\n\n  /// Return true if this type is legal.\n  bool isTypeLegal(Type *Ty) const;\n\n  /// Returns the estimated number of registers required to represent \\p Ty.\n  unsigned getRegUsageForType(Type *Ty) const;\n\n  /// Return true if switches should be turned into lookup tables for the\n  /// target.\n  bool shouldBuildLookupTables() const;\n\n  /// Return true if switches should be turned into lookup tables\n  /// containing this constant value for the target.\n  bool shouldBuildLookupTablesForConstant(Constant *C) const;\n\n  /// Return true if the input function which is cold at all call sites,\n  ///  should use coldcc calling convention.\n  bool useColdCCForColdCall(Function &F) const;\n\n  /// Estimate the overhead of scalarizing an instruction. Insert and Extract\n  /// are set if the demanded result elements need to be inserted and/or\n  /// extracted from vectors.\n  unsigned getScalarizationOverhead(VectorType *Ty, const APInt &DemandedElts,\n                                    bool Insert, bool Extract) const;\n\n  /// Estimate the overhead of scalarizing an instructions unique\n  /// non-constant operands. The (potentially vector) types to use for each of\n  /// argument are passes via Tys.\n  unsigned getOperandsScalarizationOverhead(ArrayRef<const Value *> Args,\n                                            ArrayRef<Type *> Tys) const;\n\n  /// If target has efficient vector element load/store instructions, it can\n  /// return true here so that insertion/extraction costs are not added to\n  /// the scalarization cost of a load/store.\n  bool supportsEfficientVectorElementLoadStore() const;\n\n  /// Don't restrict interleaved unrolling to small loops.\n  bool enableAggressiveInterleaving(bool LoopHasReductions) const;\n\n  /// Returns options for expansion of memcmp. IsZeroCmp is\n  // true if this is the expansion of memcmp(p1, p2, s) == 0.\n  struct MemCmpExpansionOptions {\n    // Return true if memcmp expansion is enabled.\n    operator bool() const { return MaxNumLoads > 0; }\n\n    // Maximum number of load operations.\n    unsigned MaxNumLoads = 0;\n\n    // The list of available load sizes (in bytes), sorted in decreasing order.\n    SmallVector<unsigned, 8> LoadSizes;\n\n    // For memcmp expansion when the memcmp result is only compared equal or\n    // not-equal to 0, allow up to this number of load pairs per block. As an\n    // example, this may allow 'memcmp(a, b, 3) == 0' in a single block:\n    //   a0 = load2bytes &a[0]\n    //   b0 = load2bytes &b[0]\n    //   a2 = load1byte  &a[2]\n    //   b2 = load1byte  &b[2]\n    //   r  = cmp eq (a0 ^ b0 | a2 ^ b2), 0\n    unsigned NumLoadsPerBlock = 1;\n\n    // Set to true to allow overlapping loads. For example, 7-byte compares can\n    // be done with two 4-byte compares instead of 4+2+1-byte compares. This\n    // requires all loads in LoadSizes to be doable in an unaligned way.\n    bool AllowOverlappingLoads = false;\n  };\n  MemCmpExpansionOptions enableMemCmpExpansion(bool OptSize,\n                                               bool IsZeroCmp) const;\n\n  /// Enable matching of interleaved access groups.\n  bool enableInterleavedAccessVectorization() const;\n\n  /// Enable matching of interleaved access groups that contain predicated\n  /// accesses or gaps and therefore vectorized using masked\n  /// vector loads/stores.\n  bool enableMaskedInterleavedAccessVectorization() const;\n\n  /// Indicate that it is potentially unsafe to automatically vectorize\n  /// floating-point operations because the semantics of vector and scalar\n  /// floating-point semantics may differ. For example, ARM NEON v7 SIMD math\n  /// does not support IEEE-754 denormal numbers, while depending on the\n  /// platform, scalar floating-point math does.\n  /// This applies to floating-point math operations and calls, not memory\n  /// operations, shuffles, or casts.\n  bool isFPVectorizationPotentiallyUnsafe() const;\n\n  /// Determine if the target supports unaligned memory accesses.\n  bool allowsMisalignedMemoryAccesses(LLVMContext &Context, unsigned BitWidth,\n                                      unsigned AddressSpace = 0,\n                                      Align Alignment = Align(1),\n                                      bool *Fast = nullptr) const;\n\n  /// Return hardware support for population count.\n  PopcntSupportKind getPopcntSupport(unsigned IntTyWidthInBit) const;\n\n  /// Return true if the hardware has a fast square-root instruction.\n  bool haveFastSqrt(Type *Ty) const;\n\n  /// Return true if it is faster to check if a floating-point value is NaN\n  /// (or not-NaN) versus a comparison against a constant FP zero value.\n  /// Targets should override this if materializing a 0.0 for comparison is\n  /// generally as cheap as checking for ordered/unordered.\n  bool isFCmpOrdCheaperThanFCmpZero(Type *Ty) const;\n\n  /// Return the expected cost of supporting the floating point operation\n  /// of the specified type.\n  int getFPOpCost(Type *Ty) const;\n\n  /// Return the expected cost of materializing for the given integer\n  /// immediate of the specified type.\n  int getIntImmCost(const APInt &Imm, Type *Ty, TargetCostKind CostKind) const;\n\n  /// Return the expected cost of materialization for the given integer\n  /// immediate of the specified type for a given instruction. The cost can be\n  /// zero if the immediate can be folded into the specified instruction.\n  int getIntImmCostInst(unsigned Opc, unsigned Idx, const APInt &Imm, Type *Ty,\n                        TargetCostKind CostKind,\n                        Instruction *Inst = nullptr) const;\n  int getIntImmCostIntrin(Intrinsic::ID IID, unsigned Idx, const APInt &Imm,\n                          Type *Ty, TargetCostKind CostKind) const;\n\n  /// Return the expected cost for the given integer when optimising\n  /// for size. This is different than the other integer immediate cost\n  /// functions in that it is subtarget agnostic. This is useful when you e.g.\n  /// target one ISA such as Aarch32 but smaller encodings could be possible\n  /// with another such as Thumb. This return value is used as a penalty when\n  /// the total costs for a constant is calculated (the bigger the cost, the\n  /// more beneficial constant hoisting is).\n  int getIntImmCodeSizeCost(unsigned Opc, unsigned Idx, const APInt &Imm,\n                            Type *Ty) const;\n  /// @}\n\n  /// \\name Vector Target Information\n  /// @{\n\n  /// The various kinds of shuffle patterns for vector queries.\n  enum ShuffleKind {\n    SK_Broadcast,        ///< Broadcast element 0 to all other elements.\n    SK_Reverse,          ///< Reverse the order of the vector.\n    SK_Select,           ///< Selects elements from the corresponding lane of\n                         ///< either source operand. This is equivalent to a\n                         ///< vector select with a constant condition operand.\n    SK_Transpose,        ///< Transpose two vectors.\n    SK_InsertSubvector,  ///< InsertSubvector. Index indicates start offset.\n    SK_ExtractSubvector, ///< ExtractSubvector Index indicates start offset.\n    SK_PermuteTwoSrc,    ///< Merge elements from two source vectors into one\n                         ///< with any shuffle mask.\n    SK_PermuteSingleSrc  ///< Shuffle elements of single source vector with any\n                         ///< shuffle mask.\n  };\n\n  /// Kind of the reduction data.\n  enum ReductionKind {\n    RK_None,           /// Not a reduction.\n    RK_Arithmetic,     /// Binary reduction data.\n    RK_MinMax,         /// Min/max reduction data.\n    RK_UnsignedMinMax, /// Unsigned min/max reduction data.\n  };\n\n  /// Contains opcode + LHS/RHS parts of the reduction operations.\n  struct ReductionData {\n    ReductionData() = delete;\n    ReductionData(ReductionKind Kind, unsigned Opcode, Value *LHS, Value *RHS)\n        : Opcode(Opcode), LHS(LHS), RHS(RHS), Kind(Kind) {\n      assert(Kind != RK_None && \"expected binary or min/max reduction only.\");\n    }\n    unsigned Opcode = 0;\n    Value *LHS = nullptr;\n    Value *RHS = nullptr;\n    ReductionKind Kind = RK_None;\n    bool hasSameData(ReductionData &RD) const {\n      return Kind == RD.Kind && Opcode == RD.Opcode;\n    }\n  };\n\n  static ReductionKind matchPairwiseReduction(\n    const ExtractElementInst *ReduxRoot, unsigned &Opcode, VectorType *&Ty);\n\n  static ReductionKind matchVectorSplittingReduction(\n    const ExtractElementInst *ReduxRoot, unsigned &Opcode, VectorType *&Ty);\n\n  static ReductionKind matchVectorReduction(const ExtractElementInst *ReduxRoot,\n                                            unsigned &Opcode, VectorType *&Ty,\n                                            bool &IsPairwise);\n\n  /// Additional information about an operand's possible values.\n  enum OperandValueKind {\n    OK_AnyValue,               // Operand can have any value.\n    OK_UniformValue,           // Operand is uniform (splat of a value).\n    OK_UniformConstantValue,   // Operand is uniform constant.\n    OK_NonUniformConstantValue // Operand is a non uniform constant value.\n  };\n\n  /// Additional properties of an operand's values.\n  enum OperandValueProperties { OP_None = 0, OP_PowerOf2 = 1 };\n\n  /// \\return the number of registers in the target-provided register class.\n  unsigned getNumberOfRegisters(unsigned ClassID) const;\n\n  /// \\return the target-provided register class ID for the provided type,\n  /// accounting for type promotion and other type-legalization techniques that\n  /// the target might apply. However, it specifically does not account for the\n  /// scalarization or splitting of vector types. Should a vector type require\n  /// scalarization or splitting into multiple underlying vector registers, that\n  /// type should be mapped to a register class containing no registers.\n  /// Specifically, this is designed to provide a simple, high-level view of the\n  /// register allocation later performed by the backend. These register classes\n  /// don't necessarily map onto the register classes used by the backend.\n  /// FIXME: It's not currently possible to determine how many registers\n  /// are used by the provided type.\n  unsigned getRegisterClassForType(bool Vector, Type *Ty = nullptr) const;\n\n  /// \\return the target-provided register class name\n  const char *getRegisterClassName(unsigned ClassID) const;\n\n  /// \\return The width of the largest scalar or vector register type.\n  unsigned getRegisterBitWidth(bool Vector) const;\n\n  /// \\return The width of the smallest vector register type.\n  unsigned getMinVectorRegisterBitWidth() const;\n\n  /// \\return The maximum value of vscale if the target specifies an\n  ///  architectural maximum vector length, and None otherwise.\n  Optional<unsigned> getMaxVScale() const;\n\n  /// \\return True if the vectorization factor should be chosen to\n  /// make the vector of the smallest element type match the size of a\n  /// vector register. For wider element types, this could result in\n  /// creating vectors that span multiple vector registers.\n  /// If false, the vectorization factor will be chosen based on the\n  /// size of the widest element type.\n  bool shouldMaximizeVectorBandwidth(bool OptSize) const;\n\n  /// \\return The minimum vectorization factor for types of given element\n  /// bit width, or 0 if there is no minimum VF. The returned value only\n  /// applies when shouldMaximizeVectorBandwidth returns true.\n  /// If IsScalable is true, the returned ElementCount must be a scalable VF.\n  ElementCount getMinimumVF(unsigned ElemWidth, bool IsScalable) const;\n\n  /// \\return The maximum vectorization factor for types of given element\n  /// bit width and opcode, or 0 if there is no maximum VF.\n  /// Currently only used by the SLP vectorizer.\n  unsigned getMaximumVF(unsigned ElemWidth, unsigned Opcode) const;\n\n  /// \\return True if it should be considered for address type promotion.\n  /// \\p AllowPromotionWithoutCommonHeader Set true if promoting \\p I is\n  /// profitable without finding other extensions fed by the same input.\n  bool shouldConsiderAddressTypePromotion(\n      const Instruction &I, bool &AllowPromotionWithoutCommonHeader) const;\n\n  /// \\return The size of a cache line in bytes.\n  unsigned getCacheLineSize() const;\n\n  /// The possible cache levels\n  enum class CacheLevel {\n    L1D, // The L1 data cache\n    L2D, // The L2 data cache\n\n    // We currently do not model L3 caches, as their sizes differ widely between\n    // microarchitectures. Also, we currently do not have a use for L3 cache\n    // size modeling yet.\n  };\n\n  /// \\return The size of the cache level in bytes, if available.\n  Optional<unsigned> getCacheSize(CacheLevel Level) const;\n\n  /// \\return The associativity of the cache level, if available.\n  Optional<unsigned> getCacheAssociativity(CacheLevel Level) const;\n\n  /// \\return How much before a load we should place the prefetch\n  /// instruction.  This is currently measured in number of\n  /// instructions.\n  unsigned getPrefetchDistance() const;\n\n  /// Some HW prefetchers can handle accesses up to a certain constant stride.\n  /// Sometimes prefetching is beneficial even below the HW prefetcher limit,\n  /// and the arguments provided are meant to serve as a basis for deciding this\n  /// for a particular loop.\n  ///\n  /// \\param NumMemAccesses        Number of memory accesses in the loop.\n  /// \\param NumStridedMemAccesses Number of the memory accesses that\n  ///                              ScalarEvolution could find a known stride\n  ///                              for.\n  /// \\param NumPrefetches         Number of software prefetches that will be\n  ///                              emitted as determined by the addresses\n  ///                              involved and the cache line size.\n  /// \\param HasCall               True if the loop contains a call.\n  ///\n  /// \\return This is the minimum stride in bytes where it makes sense to start\n  ///         adding SW prefetches. The default is 1, i.e. prefetch with any\n  ///         stride.\n  unsigned getMinPrefetchStride(unsigned NumMemAccesses,\n                                unsigned NumStridedMemAccesses,\n                                unsigned NumPrefetches, bool HasCall) const;\n\n  /// \\return The maximum number of iterations to prefetch ahead.  If\n  /// the required number of iterations is more than this number, no\n  /// prefetching is performed.\n  unsigned getMaxPrefetchIterationsAhead() const;\n\n  /// \\return True if prefetching should also be done for writes.\n  bool enableWritePrefetching() const;\n\n  /// \\return The maximum interleave factor that any transform should try to\n  /// perform for this target. This number depends on the level of parallelism\n  /// and the number of execution units in the CPU.\n  unsigned getMaxInterleaveFactor(unsigned VF) const;\n\n  /// Collect properties of V used in cost analysis, e.g. OP_PowerOf2.\n  static OperandValueKind getOperandInfo(const Value *V,\n                                         OperandValueProperties &OpProps);\n\n  /// This is an approximation of reciprocal throughput of a math/logic op.\n  /// A higher cost indicates less expected throughput.\n  /// From Agner Fog's guides, reciprocal throughput is \"the average number of\n  /// clock cycles per instruction when the instructions are not part of a\n  /// limiting dependency chain.\"\n  /// Therefore, costs should be scaled to account for multiple execution units\n  /// on the target that can process this type of instruction. For example, if\n  /// there are 5 scalar integer units and 2 vector integer units that can\n  /// calculate an 'add' in a single cycle, this model should indicate that the\n  /// cost of the vector add instruction is 2.5 times the cost of the scalar\n  /// add instruction.\n  /// \\p Args is an optional argument which holds the instruction operands\n  /// values so the TTI can analyze those values searching for special\n  /// cases or optimizations based on those values.\n  /// \\p CxtI is the optional original context instruction, if one exists, to\n  /// provide even more information.\n  int getArithmeticInstrCost(\n      unsigned Opcode, Type *Ty,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput,\n      OperandValueKind Opd1Info = OK_AnyValue,\n      OperandValueKind Opd2Info = OK_AnyValue,\n      OperandValueProperties Opd1PropInfo = OP_None,\n      OperandValueProperties Opd2PropInfo = OP_None,\n      ArrayRef<const Value *> Args = ArrayRef<const Value *>(),\n      const Instruction *CxtI = nullptr) const;\n\n  /// \\return The cost of a shuffle instruction of kind Kind and of type Tp.\n  /// The index and subtype parameters are used by the subvector insertion and\n  /// extraction shuffle kinds to show the insert/extract point and the type of\n  /// the subvector being inserted/extracted.\n  /// NOTE: For subvector extractions Tp represents the source type.\n  int getShuffleCost(ShuffleKind Kind, VectorType *Tp, int Index = 0,\n                     VectorType *SubTp = nullptr) const;\n\n  /// Represents a hint about the context in which a cast is used.\n  ///\n  /// For zext/sext, the context of the cast is the operand, which must be a\n  /// load of some kind. For trunc, the context is of the cast is the single\n  /// user of the instruction, which must be a store of some kind.\n  ///\n  /// This enum allows the vectorizer to give getCastInstrCost an idea of the\n  /// type of cast it's dealing with, as not every cast is equal. For instance,\n  /// the zext of a load may be free, but the zext of an interleaving load can\n  //// be (very) expensive!\n  ///\n  /// See \\c getCastContextHint to compute a CastContextHint from a cast\n  /// Instruction*. Callers can use it if they don't need to override the\n  /// context and just want it to be calculated from the instruction.\n  ///\n  /// FIXME: This handles the types of load/store that the vectorizer can\n  /// produce, which are the cases where the context instruction is most\n  /// likely to be incorrect. There are other situations where that can happen\n  /// too, which might be handled here but in the long run a more general\n  /// solution of costing multiple instructions at the same times may be better.\n  enum class CastContextHint : uint8_t {\n    None,          ///< The cast is not used with a load/store of any kind.\n    Normal,        ///< The cast is used with a normal load/store.\n    Masked,        ///< The cast is used with a masked load/store.\n    GatherScatter, ///< The cast is used with a gather/scatter.\n    Interleave,    ///< The cast is used with an interleaved load/store.\n    Reversed,      ///< The cast is used with a reversed load/store.\n  };\n\n  /// Calculates a CastContextHint from \\p I.\n  /// This should be used by callers of getCastInstrCost if they wish to\n  /// determine the context from some instruction.\n  /// \\returns the CastContextHint for ZExt/SExt/Trunc, None if \\p I is nullptr,\n  /// or if it's another type of cast.\n  static CastContextHint getCastContextHint(const Instruction *I);\n\n  /// \\return The expected cost of cast instructions, such as bitcast, trunc,\n  /// zext, etc. If there is an existing instruction that holds Opcode, it\n  /// may be passed in the 'I' parameter.\n  int getCastInstrCost(unsigned Opcode, Type *Dst, Type *Src,\n                       TTI::CastContextHint CCH,\n                       TTI::TargetCostKind CostKind = TTI::TCK_SizeAndLatency,\n                       const Instruction *I = nullptr) const;\n\n  /// \\return The expected cost of a sign- or zero-extended vector extract. Use\n  /// -1 to indicate that there is no information about the index value.\n  int getExtractWithExtendCost(unsigned Opcode, Type *Dst, VectorType *VecTy,\n                               unsigned Index = -1) const;\n\n  /// \\return The expected cost of control-flow related instructions such as\n  /// Phi, Ret, Br.\n  int getCFInstrCost(unsigned Opcode,\n                     TTI::TargetCostKind CostKind = TTI::TCK_SizeAndLatency) const;\n\n  /// \\returns The expected cost of compare and select instructions. If there\n  /// is an existing instruction that holds Opcode, it may be passed in the\n  /// 'I' parameter. The \\p VecPred parameter can be used to indicate the select\n  /// is using a compare with the specified predicate as condition. When vector\n  /// types are passed, \\p VecPred must be used for all lanes.\n  int getCmpSelInstrCost(\n      unsigned Opcode, Type *ValTy, Type *CondTy = nullptr,\n      CmpInst::Predicate VecPred = CmpInst::BAD_ICMP_PREDICATE,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput,\n      const Instruction *I = nullptr) const;\n\n  /// \\return The expected cost of vector Insert and Extract.\n  /// Use -1 to indicate that there is no information on the index value.\n  int getVectorInstrCost(unsigned Opcode, Type *Val, unsigned Index = -1) const;\n\n  /// \\return The cost of Load and Store instructions.\n  int getMemoryOpCost(unsigned Opcode, Type *Src, Align Alignment,\n                      unsigned AddressSpace,\n                      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput,\n                      const Instruction *I = nullptr) const;\n\n  /// \\return The cost of masked Load and Store instructions.\n  int getMaskedMemoryOpCost(\n      unsigned Opcode, Type *Src, Align Alignment, unsigned AddressSpace,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput) const;\n\n  /// \\return The cost of Gather or Scatter operation\n  /// \\p Opcode - is a type of memory access Load or Store\n  /// \\p DataTy - a vector type of the data to be loaded or stored\n  /// \\p Ptr - pointer [or vector of pointers] - address[es] in memory\n  /// \\p VariableMask - true when the memory access is predicated with a mask\n  ///                   that is not a compile-time constant\n  /// \\p Alignment - alignment of single element\n  /// \\p I - the optional original context instruction, if one exists, e.g. the\n  ///        load/store to transform or the call to the gather/scatter intrinsic\n  int getGatherScatterOpCost(\n      unsigned Opcode, Type *DataTy, const Value *Ptr, bool VariableMask,\n      Align Alignment, TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput,\n      const Instruction *I = nullptr) const;\n\n  /// \\return The cost of the interleaved memory operation.\n  /// \\p Opcode is the memory operation code\n  /// \\p VecTy is the vector type of the interleaved access.\n  /// \\p Factor is the interleave factor\n  /// \\p Indices is the indices for interleaved load members (as interleaved\n  ///    load allows gaps)\n  /// \\p Alignment is the alignment of the memory operation\n  /// \\p AddressSpace is address space of the pointer.\n  /// \\p UseMaskForCond indicates if the memory access is predicated.\n  /// \\p UseMaskForGaps indicates if gaps should be masked.\n  int getInterleavedMemoryOpCost(\n      unsigned Opcode, Type *VecTy, unsigned Factor, ArrayRef<unsigned> Indices,\n      Align Alignment, unsigned AddressSpace,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput,\n      bool UseMaskForCond = false, bool UseMaskForGaps = false) const;\n\n  /// Calculate the cost of performing a vector reduction.\n  ///\n  /// This is the cost of reducing the vector value of type \\p Ty to a scalar\n  /// value using the operation denoted by \\p Opcode. The form of the reduction\n  /// can either be a pairwise reduction or a reduction that splits the vector\n  /// at every reduction level.\n  ///\n  /// Pairwise:\n  ///  (v0, v1, v2, v3)\n  ///  ((v0+v1), (v2+v3), undef, undef)\n  /// Split:\n  ///  (v0, v1, v2, v3)\n  ///  ((v0+v2), (v1+v3), undef, undef)\n  int getArithmeticReductionCost(\n    unsigned Opcode, VectorType *Ty, bool IsPairwiseForm,\n    TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput) const;\n\n  int getMinMaxReductionCost(\n    VectorType *Ty, VectorType *CondTy, bool IsPairwiseForm, bool IsUnsigned,\n    TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput) const;\n\n  /// Calculate the cost of an extended reduction pattern, similar to\n  /// getArithmeticReductionCost of an Add reduction with an extension and\n  /// optional multiply. This is the cost of as:\n  /// ResTy vecreduce.add(ext(Ty A)), or if IsMLA flag is set then:\n  /// ResTy vecreduce.add(mul(ext(Ty A), ext(Ty B)). The reduction happens\n  /// on a VectorType with ResTy elements and Ty lanes.\n  InstructionCost getExtendedAddReductionCost(\n      bool IsMLA, bool IsUnsigned, Type *ResTy, VectorType *Ty,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput) const;\n\n  /// \\returns The cost of Intrinsic instructions. Analyses the real arguments.\n  /// Three cases are handled: 1. scalar instruction 2. vector instruction\n  /// 3. scalar instruction which is to be vectorized.\n  int getIntrinsicInstrCost(const IntrinsicCostAttributes &ICA,\n                            TTI::TargetCostKind CostKind) const;\n\n  /// \\returns The cost of Call instructions.\n  int getCallInstrCost(Function *F, Type *RetTy, ArrayRef<Type *> Tys,\n                 TTI::TargetCostKind CostKind = TTI::TCK_SizeAndLatency) const;\n\n  /// \\returns The number of pieces into which the provided type must be\n  /// split during legalization. Zero is returned when the answer is unknown.\n  unsigned getNumberOfParts(Type *Tp) const;\n\n  /// \\returns The cost of the address computation. For most targets this can be\n  /// merged into the instruction indexing mode. Some targets might want to\n  /// distinguish between address computation for memory operations on vector\n  /// types and scalar types. Such targets should override this function.\n  /// The 'SE' parameter holds pointer for the scalar evolution object which\n  /// is used in order to get the Ptr step value in case of constant stride.\n  /// The 'Ptr' parameter holds SCEV of the access pointer.\n  int getAddressComputationCost(Type *Ty, ScalarEvolution *SE = nullptr,\n                                const SCEV *Ptr = nullptr) const;\n\n  /// \\returns The cost, if any, of keeping values of the given types alive\n  /// over a callsite.\n  ///\n  /// Some types may require the use of register classes that do not have\n  /// any callee-saved registers, so would require a spill and fill.\n  unsigned getCostOfKeepingLiveOverCall(ArrayRef<Type *> Tys) const;\n\n  /// \\returns True if the intrinsic is a supported memory intrinsic.  Info\n  /// will contain additional information - whether the intrinsic may write\n  /// or read to memory, volatility and the pointer.  Info is undefined\n  /// if false is returned.\n  bool getTgtMemIntrinsic(IntrinsicInst *Inst, MemIntrinsicInfo &Info) const;\n\n  /// \\returns The maximum element size, in bytes, for an element\n  /// unordered-atomic memory intrinsic.\n  unsigned getAtomicMemIntrinsicMaxElementSize() const;\n\n  /// \\returns A value which is the result of the given memory intrinsic.  New\n  /// instructions may be created to extract the result from the given intrinsic\n  /// memory operation.  Returns nullptr if the target cannot create a result\n  /// from the given intrinsic.\n  Value *getOrCreateResultFromMemIntrinsic(IntrinsicInst *Inst,\n                                           Type *ExpectedType) const;\n\n  /// \\returns The type to use in a loop expansion of a memcpy call.\n  Type *getMemcpyLoopLoweringType(LLVMContext &Context, Value *Length,\n                                  unsigned SrcAddrSpace, unsigned DestAddrSpace,\n                                  unsigned SrcAlign, unsigned DestAlign) const;\n\n  /// \\param[out] OpsOut The operand types to copy RemainingBytes of memory.\n  /// \\param RemainingBytes The number of bytes to copy.\n  ///\n  /// Calculates the operand types to use when copying \\p RemainingBytes of\n  /// memory, where source and destination alignments are \\p SrcAlign and\n  /// \\p DestAlign respectively.\n  void getMemcpyLoopResidualLoweringType(\n      SmallVectorImpl<Type *> &OpsOut, LLVMContext &Context,\n      unsigned RemainingBytes, unsigned SrcAddrSpace, unsigned DestAddrSpace,\n      unsigned SrcAlign, unsigned DestAlign) const;\n\n  /// \\returns True if the two functions have compatible attributes for inlining\n  /// purposes.\n  bool areInlineCompatible(const Function *Caller,\n                           const Function *Callee) const;\n\n  /// \\returns True if the caller and callee agree on how \\p Args will be passed\n  /// to the callee.\n  /// \\param[out] Args The list of compatible arguments.  The implementation may\n  /// filter out any incompatible args from this list.\n  bool areFunctionArgsABICompatible(const Function *Caller,\n                                    const Function *Callee,\n                                    SmallPtrSetImpl<Argument *> &Args) const;\n\n  /// The type of load/store indexing.\n  enum MemIndexedMode {\n    MIM_Unindexed, ///< No indexing.\n    MIM_PreInc,    ///< Pre-incrementing.\n    MIM_PreDec,    ///< Pre-decrementing.\n    MIM_PostInc,   ///< Post-incrementing.\n    MIM_PostDec    ///< Post-decrementing.\n  };\n\n  /// \\returns True if the specified indexed load for the given type is legal.\n  bool isIndexedLoadLegal(enum MemIndexedMode Mode, Type *Ty) const;\n\n  /// \\returns True if the specified indexed store for the given type is legal.\n  bool isIndexedStoreLegal(enum MemIndexedMode Mode, Type *Ty) const;\n\n  /// \\returns The bitwidth of the largest vector type that should be used to\n  /// load/store in the given address space.\n  unsigned getLoadStoreVecRegBitWidth(unsigned AddrSpace) const;\n\n  /// \\returns True if the load instruction is legal to vectorize.\n  bool isLegalToVectorizeLoad(LoadInst *LI) const;\n\n  /// \\returns True if the store instruction is legal to vectorize.\n  bool isLegalToVectorizeStore(StoreInst *SI) const;\n\n  /// \\returns True if it is legal to vectorize the given load chain.\n  bool isLegalToVectorizeLoadChain(unsigned ChainSizeInBytes, Align Alignment,\n                                   unsigned AddrSpace) const;\n\n  /// \\returns True if it is legal to vectorize the given store chain.\n  bool isLegalToVectorizeStoreChain(unsigned ChainSizeInBytes, Align Alignment,\n                                    unsigned AddrSpace) const;\n\n  /// \\returns True if it is legal to vectorize the given reduction kind.\n  bool isLegalToVectorizeReduction(RecurrenceDescriptor RdxDesc,\n                                   ElementCount VF) const;\n\n  /// \\returns The new vector factor value if the target doesn't support \\p\n  /// SizeInBytes loads or has a better vector factor.\n  unsigned getLoadVectorFactor(unsigned VF, unsigned LoadSize,\n                               unsigned ChainSizeInBytes,\n                               VectorType *VecTy) const;\n\n  /// \\returns The new vector factor value if the target doesn't support \\p\n  /// SizeInBytes stores or has a better vector factor.\n  unsigned getStoreVectorFactor(unsigned VF, unsigned StoreSize,\n                                unsigned ChainSizeInBytes,\n                                VectorType *VecTy) const;\n\n  /// Flags describing the kind of vector reduction.\n  struct ReductionFlags {\n    ReductionFlags() : IsMaxOp(false), IsSigned(false), NoNaN(false) {}\n    bool IsMaxOp;  ///< If the op a min/max kind, true if it's a max operation.\n    bool IsSigned; ///< Whether the operation is a signed int reduction.\n    bool NoNaN;    ///< If op is an fp min/max, whether NaNs may be present.\n  };\n\n  /// \\returns True if the target prefers reductions in loop.\n  bool preferInLoopReduction(unsigned Opcode, Type *Ty,\n                             ReductionFlags Flags) const;\n\n  /// \\returns True if the target prefers reductions select kept in the loop\n  /// when tail folding. i.e.\n  /// loop:\n  ///   p = phi (0, s)\n  ///   a = add (p, x)\n  ///   s = select (mask, a, p)\n  /// vecreduce.add(s)\n  ///\n  /// As opposed to the normal scheme of p = phi (0, a) which allows the select\n  /// to be pulled out of the loop. If the select(.., add, ..) can be predicated\n  /// by the target, this can lead to cleaner code generation.\n  bool preferPredicatedReductionSelect(unsigned Opcode, Type *Ty,\n                                       ReductionFlags Flags) const;\n\n  /// \\returns True if the target wants to expand the given reduction intrinsic\n  /// into a shuffle sequence.\n  bool shouldExpandReduction(const IntrinsicInst *II) const;\n\n  /// \\returns the size cost of rematerializing a GlobalValue address relative\n  /// to a stack reload.\n  unsigned getGISelRematGlobalCost() const;\n\n  /// \\returns True if the target supports scalable vectors.\n  bool supportsScalableVectors() const;\n\n  /// \\name Vector Predication Information\n  /// @{\n  /// Whether the target supports the %evl parameter of VP intrinsic efficiently\n  /// in hardware. (see LLVM Language Reference - \"Vector Predication\n  /// Intrinsics\") Use of %evl is discouraged when that is not the case.\n  bool hasActiveVectorLength() const;\n\n  /// @}\n\n  /// @}\n\nprivate:\n  /// Estimate the latency of specified instruction.\n  /// Returns 1 as the default value.\n  int getInstructionLatency(const Instruction *I) const;\n\n  /// Returns the expected throughput cost of the instruction.\n  /// Returns -1 if the cost is unknown.\n  int getInstructionThroughput(const Instruction *I) const;\n\n  /// The abstract base class used to type erase specific TTI\n  /// implementations.\n  class Concept;\n\n  /// The template model for the base class which wraps a concrete\n  /// implementation in a type erased interface.\n  template <typename T> class Model;\n\n  std::unique_ptr<Concept> TTIImpl;\n};\n\nclass TargetTransformInfo::Concept {\npublic:\n  virtual ~Concept() = 0;\n  virtual const DataLayout &getDataLayout() const = 0;\n  virtual int getGEPCost(Type *PointeeType, const Value *Ptr,\n                         ArrayRef<const Value *> Operands,\n                         TTI::TargetCostKind CostKind) = 0;\n  virtual unsigned getInliningThresholdMultiplier() = 0;\n  virtual unsigned adjustInliningThreshold(const CallBase *CB) = 0;\n  virtual int getInlinerVectorBonusPercent() = 0;\n  virtual int getMemcpyCost(const Instruction *I) = 0;\n  virtual unsigned\n  getEstimatedNumberOfCaseClusters(const SwitchInst &SI, unsigned &JTSize,\n                                   ProfileSummaryInfo *PSI,\n                                   BlockFrequencyInfo *BFI) = 0;\n  virtual int getUserCost(const User *U, ArrayRef<const Value *> Operands,\n                          TargetCostKind CostKind) = 0;\n  virtual bool hasBranchDivergence() = 0;\n  virtual bool useGPUDivergenceAnalysis() = 0;\n  virtual bool isSourceOfDivergence(const Value *V) = 0;\n  virtual bool isAlwaysUniform(const Value *V) = 0;\n  virtual unsigned getFlatAddressSpace() = 0;\n  virtual bool collectFlatAddressOperands(SmallVectorImpl<int> &OpIndexes,\n                                          Intrinsic::ID IID) const = 0;\n  virtual bool isNoopAddrSpaceCast(unsigned FromAS, unsigned ToAS) const = 0;\n  virtual unsigned getAssumedAddrSpace(const Value *V) const = 0;\n  virtual Value *rewriteIntrinsicWithAddressSpace(IntrinsicInst *II,\n                                                  Value *OldV,\n                                                  Value *NewV) const = 0;\n  virtual bool isLoweredToCall(const Function *F) = 0;\n  virtual void getUnrollingPreferences(Loop *L, ScalarEvolution &,\n                                       UnrollingPreferences &UP) = 0;\n  virtual void getPeelingPreferences(Loop *L, ScalarEvolution &SE,\n                                     PeelingPreferences &PP) = 0;\n  virtual bool isHardwareLoopProfitable(Loop *L, ScalarEvolution &SE,\n                                        AssumptionCache &AC,\n                                        TargetLibraryInfo *LibInfo,\n                                        HardwareLoopInfo &HWLoopInfo) = 0;\n  virtual bool\n  preferPredicateOverEpilogue(Loop *L, LoopInfo *LI, ScalarEvolution &SE,\n                              AssumptionCache &AC, TargetLibraryInfo *TLI,\n                              DominatorTree *DT, const LoopAccessInfo *LAI) = 0;\n  virtual bool emitGetActiveLaneMask() = 0;\n  virtual Optional<Instruction *> instCombineIntrinsic(InstCombiner &IC,\n                                                       IntrinsicInst &II) = 0;\n  virtual Optional<Value *>\n  simplifyDemandedUseBitsIntrinsic(InstCombiner &IC, IntrinsicInst &II,\n                                   APInt DemandedMask, KnownBits &Known,\n                                   bool &KnownBitsComputed) = 0;\n  virtual Optional<Value *> simplifyDemandedVectorEltsIntrinsic(\n      InstCombiner &IC, IntrinsicInst &II, APInt DemandedElts, APInt &UndefElts,\n      APInt &UndefElts2, APInt &UndefElts3,\n      std::function<void(Instruction *, unsigned, APInt, APInt &)>\n          SimplifyAndSetOp) = 0;\n  virtual bool isLegalAddImmediate(int64_t Imm) = 0;\n  virtual bool isLegalICmpImmediate(int64_t Imm) = 0;\n  virtual bool isLegalAddressingMode(Type *Ty, GlobalValue *BaseGV,\n                                     int64_t BaseOffset, bool HasBaseReg,\n                                     int64_t Scale, unsigned AddrSpace,\n                                     Instruction *I) = 0;\n  virtual bool isLSRCostLess(TargetTransformInfo::LSRCost &C1,\n                             TargetTransformInfo::LSRCost &C2) = 0;\n  virtual bool isNumRegsMajorCostOfLSR() = 0;\n  virtual bool isProfitableLSRChainElement(Instruction *I) = 0;\n  virtual bool canMacroFuseCmp() = 0;\n  virtual bool canSaveCmp(Loop *L, BranchInst **BI, ScalarEvolution *SE,\n                          LoopInfo *LI, DominatorTree *DT, AssumptionCache *AC,\n                          TargetLibraryInfo *LibInfo) = 0;\n  virtual AddressingModeKind\n    getPreferredAddressingMode(const Loop *L, ScalarEvolution *SE) const = 0;\n  virtual bool isLegalMaskedStore(Type *DataType, Align Alignment) = 0;\n  virtual bool isLegalMaskedLoad(Type *DataType, Align Alignment) = 0;\n  virtual bool isLegalNTStore(Type *DataType, Align Alignment) = 0;\n  virtual bool isLegalNTLoad(Type *DataType, Align Alignment) = 0;\n  virtual bool isLegalMaskedScatter(Type *DataType, Align Alignment) = 0;\n  virtual bool isLegalMaskedGather(Type *DataType, Align Alignment) = 0;\n  virtual bool isLegalMaskedCompressStore(Type *DataType) = 0;\n  virtual bool isLegalMaskedExpandLoad(Type *DataType) = 0;\n  virtual bool hasDivRemOp(Type *DataType, bool IsSigned) = 0;\n  virtual bool hasVolatileVariant(Instruction *I, unsigned AddrSpace) = 0;\n  virtual bool prefersVectorizedAddressing() = 0;\n  virtual int getScalingFactorCost(Type *Ty, GlobalValue *BaseGV,\n                                   int64_t BaseOffset, bool HasBaseReg,\n                                   int64_t Scale, unsigned AddrSpace) = 0;\n  virtual bool LSRWithInstrQueries() = 0;\n  virtual bool isTruncateFree(Type *Ty1, Type *Ty2) = 0;\n  virtual bool isProfitableToHoist(Instruction *I) = 0;\n  virtual bool useAA() = 0;\n  virtual bool isTypeLegal(Type *Ty) = 0;\n  virtual unsigned getRegUsageForType(Type *Ty) = 0;\n  virtual bool shouldBuildLookupTables() = 0;\n  virtual bool shouldBuildLookupTablesForConstant(Constant *C) = 0;\n  virtual bool useColdCCForColdCall(Function &F) = 0;\n  virtual unsigned getScalarizationOverhead(VectorType *Ty,\n                                            const APInt &DemandedElts,\n                                            bool Insert, bool Extract) = 0;\n  virtual unsigned\n  getOperandsScalarizationOverhead(ArrayRef<const Value *> Args,\n                                   ArrayRef<Type *> Tys) = 0;\n  virtual bool supportsEfficientVectorElementLoadStore() = 0;\n  virtual bool enableAggressiveInterleaving(bool LoopHasReductions) = 0;\n  virtual MemCmpExpansionOptions\n  enableMemCmpExpansion(bool OptSize, bool IsZeroCmp) const = 0;\n  virtual bool enableInterleavedAccessVectorization() = 0;\n  virtual bool enableMaskedInterleavedAccessVectorization() = 0;\n  virtual bool isFPVectorizationPotentiallyUnsafe() = 0;\n  virtual bool allowsMisalignedMemoryAccesses(LLVMContext &Context,\n                                              unsigned BitWidth,\n                                              unsigned AddressSpace,\n                                              Align Alignment,\n                                              bool *Fast) = 0;\n  virtual PopcntSupportKind getPopcntSupport(unsigned IntTyWidthInBit) = 0;\n  virtual bool haveFastSqrt(Type *Ty) = 0;\n  virtual bool isFCmpOrdCheaperThanFCmpZero(Type *Ty) = 0;\n  virtual int getFPOpCost(Type *Ty) = 0;\n  virtual int getIntImmCodeSizeCost(unsigned Opc, unsigned Idx,\n                                    const APInt &Imm, Type *Ty) = 0;\n  virtual int getIntImmCost(const APInt &Imm, Type *Ty,\n                            TargetCostKind CostKind) = 0;\n  virtual int getIntImmCostInst(unsigned Opc, unsigned Idx, const APInt &Imm,\n                                Type *Ty, TargetCostKind CostKind,\n                                Instruction *Inst = nullptr) = 0;\n  virtual int getIntImmCostIntrin(Intrinsic::ID IID, unsigned Idx,\n                                  const APInt &Imm, Type *Ty,\n                                  TargetCostKind CostKind) = 0;\n  virtual unsigned getNumberOfRegisters(unsigned ClassID) const = 0;\n  virtual unsigned getRegisterClassForType(bool Vector,\n                                           Type *Ty = nullptr) const = 0;\n  virtual const char *getRegisterClassName(unsigned ClassID) const = 0;\n  virtual unsigned getRegisterBitWidth(bool Vector) const = 0;\n  virtual unsigned getMinVectorRegisterBitWidth() = 0;\n  virtual Optional<unsigned> getMaxVScale() const = 0;\n  virtual bool shouldMaximizeVectorBandwidth(bool OptSize) const = 0;\n  virtual ElementCount getMinimumVF(unsigned ElemWidth,\n                                    bool IsScalable) const = 0;\n  virtual unsigned getMaximumVF(unsigned ElemWidth, unsigned Opcode) const = 0;\n  virtual bool shouldConsiderAddressTypePromotion(\n      const Instruction &I, bool &AllowPromotionWithoutCommonHeader) = 0;\n  virtual unsigned getCacheLineSize() const = 0;\n  virtual Optional<unsigned> getCacheSize(CacheLevel Level) const = 0;\n  virtual Optional<unsigned> getCacheAssociativity(CacheLevel Level) const = 0;\n\n  /// \\return How much before a load we should place the prefetch\n  /// instruction.  This is currently measured in number of\n  /// instructions.\n  virtual unsigned getPrefetchDistance() const = 0;\n\n  /// \\return Some HW prefetchers can handle accesses up to a certain\n  /// constant stride.  This is the minimum stride in bytes where it\n  /// makes sense to start adding SW prefetches.  The default is 1,\n  /// i.e. prefetch with any stride.  Sometimes prefetching is beneficial\n  /// even below the HW prefetcher limit, and the arguments provided are\n  /// meant to serve as a basis for deciding this for a particular loop.\n  virtual unsigned getMinPrefetchStride(unsigned NumMemAccesses,\n                                        unsigned NumStridedMemAccesses,\n                                        unsigned NumPrefetches,\n                                        bool HasCall) const = 0;\n\n  /// \\return The maximum number of iterations to prefetch ahead.  If\n  /// the required number of iterations is more than this number, no\n  /// prefetching is performed.\n  virtual unsigned getMaxPrefetchIterationsAhead() const = 0;\n\n  /// \\return True if prefetching should also be done for writes.\n  virtual bool enableWritePrefetching() const = 0;\n\n  virtual unsigned getMaxInterleaveFactor(unsigned VF) = 0;\n  virtual unsigned getArithmeticInstrCost(\n      unsigned Opcode, Type *Ty,\n      TTI::TargetCostKind CostKind,\n      OperandValueKind Opd1Info,\n      OperandValueKind Opd2Info, OperandValueProperties Opd1PropInfo,\n      OperandValueProperties Opd2PropInfo, ArrayRef<const Value *> Args,\n      const Instruction *CxtI = nullptr) = 0;\n  virtual int getShuffleCost(ShuffleKind Kind, VectorType *Tp, int Index,\n                             VectorType *SubTp) = 0;\n  virtual int getCastInstrCost(unsigned Opcode, Type *Dst, Type *Src,\n                               CastContextHint CCH,\n                               TTI::TargetCostKind CostKind,\n                               const Instruction *I) = 0;\n  virtual int getExtractWithExtendCost(unsigned Opcode, Type *Dst,\n                                       VectorType *VecTy, unsigned Index) = 0;\n  virtual int getCFInstrCost(unsigned Opcode,\n                             TTI::TargetCostKind CostKind) = 0;\n  virtual int getCmpSelInstrCost(unsigned Opcode, Type *ValTy, Type *CondTy,\n                                 CmpInst::Predicate VecPred,\n                                 TTI::TargetCostKind CostKind,\n                                 const Instruction *I) = 0;\n  virtual int getVectorInstrCost(unsigned Opcode, Type *Val,\n                                 unsigned Index) = 0;\n  virtual int getMemoryOpCost(unsigned Opcode, Type *Src, Align Alignment,\n                              unsigned AddressSpace,\n                              TTI::TargetCostKind CostKind,\n                              const Instruction *I) = 0;\n  virtual int getMaskedMemoryOpCost(unsigned Opcode, Type *Src, Align Alignment,\n                                    unsigned AddressSpace,\n                                    TTI::TargetCostKind CostKind) = 0;\n  virtual int getGatherScatterOpCost(unsigned Opcode, Type *DataTy,\n                                     const Value *Ptr, bool VariableMask,\n                                     Align Alignment,\n                                     TTI::TargetCostKind CostKind,\n                                     const Instruction *I = nullptr) = 0;\n\n  virtual int getInterleavedMemoryOpCost(\n      unsigned Opcode, Type *VecTy, unsigned Factor, ArrayRef<unsigned> Indices,\n      Align Alignment, unsigned AddressSpace, TTI::TargetCostKind CostKind,\n      bool UseMaskForCond = false, bool UseMaskForGaps = false) = 0;\n  virtual int getArithmeticReductionCost(unsigned Opcode, VectorType *Ty,\n                                         bool IsPairwiseForm,\n                                         TTI::TargetCostKind CostKind) = 0;\n  virtual int getMinMaxReductionCost(VectorType *Ty, VectorType *CondTy,\n                                     bool IsPairwiseForm, bool IsUnsigned,\n                                     TTI::TargetCostKind CostKind) = 0;\n  virtual InstructionCost getExtendedAddReductionCost(\n      bool IsMLA, bool IsUnsigned, Type *ResTy, VectorType *Ty,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput) = 0;\n  virtual int getIntrinsicInstrCost(const IntrinsicCostAttributes &ICA,\n                                    TTI::TargetCostKind CostKind) = 0;\n  virtual int getCallInstrCost(Function *F, Type *RetTy,\n                               ArrayRef<Type *> Tys,\n                               TTI::TargetCostKind CostKind) = 0;\n  virtual unsigned getNumberOfParts(Type *Tp) = 0;\n  virtual int getAddressComputationCost(Type *Ty, ScalarEvolution *SE,\n                                        const SCEV *Ptr) = 0;\n  virtual unsigned getCostOfKeepingLiveOverCall(ArrayRef<Type *> Tys) = 0;\n  virtual bool getTgtMemIntrinsic(IntrinsicInst *Inst,\n                                  MemIntrinsicInfo &Info) = 0;\n  virtual unsigned getAtomicMemIntrinsicMaxElementSize() const = 0;\n  virtual Value *getOrCreateResultFromMemIntrinsic(IntrinsicInst *Inst,\n                                                   Type *ExpectedType) = 0;\n  virtual Type *getMemcpyLoopLoweringType(LLVMContext &Context, Value *Length,\n                                          unsigned SrcAddrSpace,\n                                          unsigned DestAddrSpace,\n                                          unsigned SrcAlign,\n                                          unsigned DestAlign) const = 0;\n  virtual void getMemcpyLoopResidualLoweringType(\n      SmallVectorImpl<Type *> &OpsOut, LLVMContext &Context,\n      unsigned RemainingBytes, unsigned SrcAddrSpace, unsigned DestAddrSpace,\n      unsigned SrcAlign, unsigned DestAlign) const = 0;\n  virtual bool areInlineCompatible(const Function *Caller,\n                                   const Function *Callee) const = 0;\n  virtual bool\n  areFunctionArgsABICompatible(const Function *Caller, const Function *Callee,\n                               SmallPtrSetImpl<Argument *> &Args) const = 0;\n  virtual bool isIndexedLoadLegal(MemIndexedMode Mode, Type *Ty) const = 0;\n  virtual bool isIndexedStoreLegal(MemIndexedMode Mode, Type *Ty) const = 0;\n  virtual unsigned getLoadStoreVecRegBitWidth(unsigned AddrSpace) const = 0;\n  virtual bool isLegalToVectorizeLoad(LoadInst *LI) const = 0;\n  virtual bool isLegalToVectorizeStore(StoreInst *SI) const = 0;\n  virtual bool isLegalToVectorizeLoadChain(unsigned ChainSizeInBytes,\n                                           Align Alignment,\n                                           unsigned AddrSpace) const = 0;\n  virtual bool isLegalToVectorizeStoreChain(unsigned ChainSizeInBytes,\n                                            Align Alignment,\n                                            unsigned AddrSpace) const = 0;\n  virtual bool isLegalToVectorizeReduction(RecurrenceDescriptor RdxDesc,\n                                           ElementCount VF) const = 0;\n  virtual unsigned getLoadVectorFactor(unsigned VF, unsigned LoadSize,\n                                       unsigned ChainSizeInBytes,\n                                       VectorType *VecTy) const = 0;\n  virtual unsigned getStoreVectorFactor(unsigned VF, unsigned StoreSize,\n                                        unsigned ChainSizeInBytes,\n                                        VectorType *VecTy) const = 0;\n  virtual bool preferInLoopReduction(unsigned Opcode, Type *Ty,\n                                     ReductionFlags) const = 0;\n  virtual bool preferPredicatedReductionSelect(unsigned Opcode, Type *Ty,\n                                               ReductionFlags) const = 0;\n  virtual bool shouldExpandReduction(const IntrinsicInst *II) const = 0;\n  virtual unsigned getGISelRematGlobalCost() const = 0;\n  virtual bool supportsScalableVectors() const = 0;\n  virtual bool hasActiveVectorLength() const = 0;\n  virtual int getInstructionLatency(const Instruction *I) = 0;\n};\n\ntemplate <typename T>\nclass TargetTransformInfo::Model final : public TargetTransformInfo::Concept {\n  T Impl;\n\npublic:\n  Model(T Impl) : Impl(std::move(Impl)) {}\n  ~Model() override {}\n\n  const DataLayout &getDataLayout() const override {\n    return Impl.getDataLayout();\n  }\n\n  int getGEPCost(Type *PointeeType, const Value *Ptr,\n                 ArrayRef<const Value *> Operands,\n                 enum TargetTransformInfo::TargetCostKind CostKind) override {\n    return Impl.getGEPCost(PointeeType, Ptr, Operands);\n  }\n  unsigned getInliningThresholdMultiplier() override {\n    return Impl.getInliningThresholdMultiplier();\n  }\n  unsigned adjustInliningThreshold(const CallBase *CB) override {\n    return Impl.adjustInliningThreshold(CB);\n  }\n  int getInlinerVectorBonusPercent() override {\n    return Impl.getInlinerVectorBonusPercent();\n  }\n  int getMemcpyCost(const Instruction *I) override {\n    return Impl.getMemcpyCost(I);\n  }\n  int getUserCost(const User *U, ArrayRef<const Value *> Operands,\n                  TargetCostKind CostKind) override {\n    return Impl.getUserCost(U, Operands, CostKind);\n  }\n  bool hasBranchDivergence() override { return Impl.hasBranchDivergence(); }\n  bool useGPUDivergenceAnalysis() override {\n    return Impl.useGPUDivergenceAnalysis();\n  }\n  bool isSourceOfDivergence(const Value *V) override {\n    return Impl.isSourceOfDivergence(V);\n  }\n\n  bool isAlwaysUniform(const Value *V) override {\n    return Impl.isAlwaysUniform(V);\n  }\n\n  unsigned getFlatAddressSpace() override { return Impl.getFlatAddressSpace(); }\n\n  bool collectFlatAddressOperands(SmallVectorImpl<int> &OpIndexes,\n                                  Intrinsic::ID IID) const override {\n    return Impl.collectFlatAddressOperands(OpIndexes, IID);\n  }\n\n  bool isNoopAddrSpaceCast(unsigned FromAS, unsigned ToAS) const override {\n    return Impl.isNoopAddrSpaceCast(FromAS, ToAS);\n  }\n\n  unsigned getAssumedAddrSpace(const Value *V) const override {\n    return Impl.getAssumedAddrSpace(V);\n  }\n\n  Value *rewriteIntrinsicWithAddressSpace(IntrinsicInst *II, Value *OldV,\n                                          Value *NewV) const override {\n    return Impl.rewriteIntrinsicWithAddressSpace(II, OldV, NewV);\n  }\n\n  bool isLoweredToCall(const Function *F) override {\n    return Impl.isLoweredToCall(F);\n  }\n  void getUnrollingPreferences(Loop *L, ScalarEvolution &SE,\n                               UnrollingPreferences &UP) override {\n    return Impl.getUnrollingPreferences(L, SE, UP);\n  }\n  void getPeelingPreferences(Loop *L, ScalarEvolution &SE,\n                             PeelingPreferences &PP) override {\n    return Impl.getPeelingPreferences(L, SE, PP);\n  }\n  bool isHardwareLoopProfitable(Loop *L, ScalarEvolution &SE,\n                                AssumptionCache &AC, TargetLibraryInfo *LibInfo,\n                                HardwareLoopInfo &HWLoopInfo) override {\n    return Impl.isHardwareLoopProfitable(L, SE, AC, LibInfo, HWLoopInfo);\n  }\n  bool preferPredicateOverEpilogue(Loop *L, LoopInfo *LI, ScalarEvolution &SE,\n                                   AssumptionCache &AC, TargetLibraryInfo *TLI,\n                                   DominatorTree *DT,\n                                   const LoopAccessInfo *LAI) override {\n    return Impl.preferPredicateOverEpilogue(L, LI, SE, AC, TLI, DT, LAI);\n  }\n  bool emitGetActiveLaneMask() override {\n    return Impl.emitGetActiveLaneMask();\n  }\n  Optional<Instruction *> instCombineIntrinsic(InstCombiner &IC,\n                                               IntrinsicInst &II) override {\n    return Impl.instCombineIntrinsic(IC, II);\n  }\n  Optional<Value *>\n  simplifyDemandedUseBitsIntrinsic(InstCombiner &IC, IntrinsicInst &II,\n                                   APInt DemandedMask, KnownBits &Known,\n                                   bool &KnownBitsComputed) override {\n    return Impl.simplifyDemandedUseBitsIntrinsic(IC, II, DemandedMask, Known,\n                                                 KnownBitsComputed);\n  }\n  Optional<Value *> simplifyDemandedVectorEltsIntrinsic(\n      InstCombiner &IC, IntrinsicInst &II, APInt DemandedElts, APInt &UndefElts,\n      APInt &UndefElts2, APInt &UndefElts3,\n      std::function<void(Instruction *, unsigned, APInt, APInt &)>\n          SimplifyAndSetOp) override {\n    return Impl.simplifyDemandedVectorEltsIntrinsic(\n        IC, II, DemandedElts, UndefElts, UndefElts2, UndefElts3,\n        SimplifyAndSetOp);\n  }\n  bool isLegalAddImmediate(int64_t Imm) override {\n    return Impl.isLegalAddImmediate(Imm);\n  }\n  bool isLegalICmpImmediate(int64_t Imm) override {\n    return Impl.isLegalICmpImmediate(Imm);\n  }\n  bool isLegalAddressingMode(Type *Ty, GlobalValue *BaseGV, int64_t BaseOffset,\n                             bool HasBaseReg, int64_t Scale, unsigned AddrSpace,\n                             Instruction *I) override {\n    return Impl.isLegalAddressingMode(Ty, BaseGV, BaseOffset, HasBaseReg, Scale,\n                                      AddrSpace, I);\n  }\n  bool isLSRCostLess(TargetTransformInfo::LSRCost &C1,\n                     TargetTransformInfo::LSRCost &C2) override {\n    return Impl.isLSRCostLess(C1, C2);\n  }\n  bool isNumRegsMajorCostOfLSR() override {\n    return Impl.isNumRegsMajorCostOfLSR();\n  }\n  bool isProfitableLSRChainElement(Instruction *I) override {\n    return Impl.isProfitableLSRChainElement(I);\n  }\n  bool canMacroFuseCmp() override { return Impl.canMacroFuseCmp(); }\n  bool canSaveCmp(Loop *L, BranchInst **BI, ScalarEvolution *SE, LoopInfo *LI,\n                  DominatorTree *DT, AssumptionCache *AC,\n                  TargetLibraryInfo *LibInfo) override {\n    return Impl.canSaveCmp(L, BI, SE, LI, DT, AC, LibInfo);\n  }\n  AddressingModeKind\n    getPreferredAddressingMode(const Loop *L,\n                               ScalarEvolution *SE) const override {\n    return Impl.getPreferredAddressingMode(L, SE);\n  }\n  bool isLegalMaskedStore(Type *DataType, Align Alignment) override {\n    return Impl.isLegalMaskedStore(DataType, Alignment);\n  }\n  bool isLegalMaskedLoad(Type *DataType, Align Alignment) override {\n    return Impl.isLegalMaskedLoad(DataType, Alignment);\n  }\n  bool isLegalNTStore(Type *DataType, Align Alignment) override {\n    return Impl.isLegalNTStore(DataType, Alignment);\n  }\n  bool isLegalNTLoad(Type *DataType, Align Alignment) override {\n    return Impl.isLegalNTLoad(DataType, Alignment);\n  }\n  bool isLegalMaskedScatter(Type *DataType, Align Alignment) override {\n    return Impl.isLegalMaskedScatter(DataType, Alignment);\n  }\n  bool isLegalMaskedGather(Type *DataType, Align Alignment) override {\n    return Impl.isLegalMaskedGather(DataType, Alignment);\n  }\n  bool isLegalMaskedCompressStore(Type *DataType) override {\n    return Impl.isLegalMaskedCompressStore(DataType);\n  }\n  bool isLegalMaskedExpandLoad(Type *DataType) override {\n    return Impl.isLegalMaskedExpandLoad(DataType);\n  }\n  bool hasDivRemOp(Type *DataType, bool IsSigned) override {\n    return Impl.hasDivRemOp(DataType, IsSigned);\n  }\n  bool hasVolatileVariant(Instruction *I, unsigned AddrSpace) override {\n    return Impl.hasVolatileVariant(I, AddrSpace);\n  }\n  bool prefersVectorizedAddressing() override {\n    return Impl.prefersVectorizedAddressing();\n  }\n  int getScalingFactorCost(Type *Ty, GlobalValue *BaseGV, int64_t BaseOffset,\n                           bool HasBaseReg, int64_t Scale,\n                           unsigned AddrSpace) override {\n    return Impl.getScalingFactorCost(Ty, BaseGV, BaseOffset, HasBaseReg, Scale,\n                                     AddrSpace);\n  }\n  bool LSRWithInstrQueries() override { return Impl.LSRWithInstrQueries(); }\n  bool isTruncateFree(Type *Ty1, Type *Ty2) override {\n    return Impl.isTruncateFree(Ty1, Ty2);\n  }\n  bool isProfitableToHoist(Instruction *I) override {\n    return Impl.isProfitableToHoist(I);\n  }\n  bool useAA() override { return Impl.useAA(); }\n  bool isTypeLegal(Type *Ty) override { return Impl.isTypeLegal(Ty); }\n  unsigned getRegUsageForType(Type *Ty) override {\n    return Impl.getRegUsageForType(Ty);\n  }\n  bool shouldBuildLookupTables() override {\n    return Impl.shouldBuildLookupTables();\n  }\n  bool shouldBuildLookupTablesForConstant(Constant *C) override {\n    return Impl.shouldBuildLookupTablesForConstant(C);\n  }\n  bool useColdCCForColdCall(Function &F) override {\n    return Impl.useColdCCForColdCall(F);\n  }\n\n  unsigned getScalarizationOverhead(VectorType *Ty, const APInt &DemandedElts,\n                                    bool Insert, bool Extract) override {\n    return Impl.getScalarizationOverhead(Ty, DemandedElts, Insert, Extract);\n  }\n  unsigned getOperandsScalarizationOverhead(ArrayRef<const Value *> Args,\n                                            ArrayRef<Type *> Tys) override {\n    return Impl.getOperandsScalarizationOverhead(Args, Tys);\n  }\n\n  bool supportsEfficientVectorElementLoadStore() override {\n    return Impl.supportsEfficientVectorElementLoadStore();\n  }\n\n  bool enableAggressiveInterleaving(bool LoopHasReductions) override {\n    return Impl.enableAggressiveInterleaving(LoopHasReductions);\n  }\n  MemCmpExpansionOptions enableMemCmpExpansion(bool OptSize,\n                                               bool IsZeroCmp) const override {\n    return Impl.enableMemCmpExpansion(OptSize, IsZeroCmp);\n  }\n  bool enableInterleavedAccessVectorization() override {\n    return Impl.enableInterleavedAccessVectorization();\n  }\n  bool enableMaskedInterleavedAccessVectorization() override {\n    return Impl.enableMaskedInterleavedAccessVectorization();\n  }\n  bool isFPVectorizationPotentiallyUnsafe() override {\n    return Impl.isFPVectorizationPotentiallyUnsafe();\n  }\n  bool allowsMisalignedMemoryAccesses(LLVMContext &Context, unsigned BitWidth,\n                                      unsigned AddressSpace, Align Alignment,\n                                      bool *Fast) override {\n    return Impl.allowsMisalignedMemoryAccesses(Context, BitWidth, AddressSpace,\n                                               Alignment, Fast);\n  }\n  PopcntSupportKind getPopcntSupport(unsigned IntTyWidthInBit) override {\n    return Impl.getPopcntSupport(IntTyWidthInBit);\n  }\n  bool haveFastSqrt(Type *Ty) override { return Impl.haveFastSqrt(Ty); }\n\n  bool isFCmpOrdCheaperThanFCmpZero(Type *Ty) override {\n    return Impl.isFCmpOrdCheaperThanFCmpZero(Ty);\n  }\n\n  int getFPOpCost(Type *Ty) override { return Impl.getFPOpCost(Ty); }\n\n  int getIntImmCodeSizeCost(unsigned Opc, unsigned Idx, const APInt &Imm,\n                            Type *Ty) override {\n    return Impl.getIntImmCodeSizeCost(Opc, Idx, Imm, Ty);\n  }\n  int getIntImmCost(const APInt &Imm, Type *Ty,\n                    TargetCostKind CostKind) override {\n    return Impl.getIntImmCost(Imm, Ty, CostKind);\n  }\n  int getIntImmCostInst(unsigned Opc, unsigned Idx, const APInt &Imm, Type *Ty,\n                        TargetCostKind CostKind,\n                        Instruction *Inst = nullptr) override {\n    return Impl.getIntImmCostInst(Opc, Idx, Imm, Ty, CostKind, Inst);\n  }\n  int getIntImmCostIntrin(Intrinsic::ID IID, unsigned Idx, const APInt &Imm,\n                          Type *Ty, TargetCostKind CostKind) override {\n    return Impl.getIntImmCostIntrin(IID, Idx, Imm, Ty, CostKind);\n  }\n  unsigned getNumberOfRegisters(unsigned ClassID) const override {\n    return Impl.getNumberOfRegisters(ClassID);\n  }\n  unsigned getRegisterClassForType(bool Vector,\n                                   Type *Ty = nullptr) const override {\n    return Impl.getRegisterClassForType(Vector, Ty);\n  }\n  const char *getRegisterClassName(unsigned ClassID) const override {\n    return Impl.getRegisterClassName(ClassID);\n  }\n  unsigned getRegisterBitWidth(bool Vector) const override {\n    return Impl.getRegisterBitWidth(Vector);\n  }\n  unsigned getMinVectorRegisterBitWidth() override {\n    return Impl.getMinVectorRegisterBitWidth();\n  }\n  Optional<unsigned> getMaxVScale() const override {\n    return Impl.getMaxVScale();\n  }\n  bool shouldMaximizeVectorBandwidth(bool OptSize) const override {\n    return Impl.shouldMaximizeVectorBandwidth(OptSize);\n  }\n  ElementCount getMinimumVF(unsigned ElemWidth,\n                            bool IsScalable) const override {\n    return Impl.getMinimumVF(ElemWidth, IsScalable);\n  }\n  unsigned getMaximumVF(unsigned ElemWidth, unsigned Opcode) const override {\n    return Impl.getMaximumVF(ElemWidth, Opcode);\n  }\n  bool shouldConsiderAddressTypePromotion(\n      const Instruction &I, bool &AllowPromotionWithoutCommonHeader) override {\n    return Impl.shouldConsiderAddressTypePromotion(\n        I, AllowPromotionWithoutCommonHeader);\n  }\n  unsigned getCacheLineSize() const override { return Impl.getCacheLineSize(); }\n  Optional<unsigned> getCacheSize(CacheLevel Level) const override {\n    return Impl.getCacheSize(Level);\n  }\n  Optional<unsigned> getCacheAssociativity(CacheLevel Level) const override {\n    return Impl.getCacheAssociativity(Level);\n  }\n\n  /// Return the preferred prefetch distance in terms of instructions.\n  ///\n  unsigned getPrefetchDistance() const override {\n    return Impl.getPrefetchDistance();\n  }\n\n  /// Return the minimum stride necessary to trigger software\n  /// prefetching.\n  ///\n  unsigned getMinPrefetchStride(unsigned NumMemAccesses,\n                                unsigned NumStridedMemAccesses,\n                                unsigned NumPrefetches,\n                                bool HasCall) const override {\n    return Impl.getMinPrefetchStride(NumMemAccesses, NumStridedMemAccesses,\n                                     NumPrefetches, HasCall);\n  }\n\n  /// Return the maximum prefetch distance in terms of loop\n  /// iterations.\n  ///\n  unsigned getMaxPrefetchIterationsAhead() const override {\n    return Impl.getMaxPrefetchIterationsAhead();\n  }\n\n  /// \\return True if prefetching should also be done for writes.\n  bool enableWritePrefetching() const override {\n    return Impl.enableWritePrefetching();\n  }\n\n  unsigned getMaxInterleaveFactor(unsigned VF) override {\n    return Impl.getMaxInterleaveFactor(VF);\n  }\n  unsigned getEstimatedNumberOfCaseClusters(const SwitchInst &SI,\n                                            unsigned &JTSize,\n                                            ProfileSummaryInfo *PSI,\n                                            BlockFrequencyInfo *BFI) override {\n    return Impl.getEstimatedNumberOfCaseClusters(SI, JTSize, PSI, BFI);\n  }\n  unsigned getArithmeticInstrCost(unsigned Opcode, Type *Ty,\n                                  TTI::TargetCostKind CostKind,\n                                  OperandValueKind Opd1Info,\n                                  OperandValueKind Opd2Info,\n                                  OperandValueProperties Opd1PropInfo,\n                                  OperandValueProperties Opd2PropInfo,\n                                  ArrayRef<const Value *> Args,\n                                  const Instruction *CxtI = nullptr) override {\n    return Impl.getArithmeticInstrCost(Opcode, Ty, CostKind, Opd1Info, Opd2Info,\n                                       Opd1PropInfo, Opd2PropInfo, Args, CxtI);\n  }\n  int getShuffleCost(ShuffleKind Kind, VectorType *Tp, int Index,\n                     VectorType *SubTp) override {\n    return Impl.getShuffleCost(Kind, Tp, Index, SubTp);\n  }\n  int getCastInstrCost(unsigned Opcode, Type *Dst, Type *Src,\n                       CastContextHint CCH, TTI::TargetCostKind CostKind,\n                       const Instruction *I) override {\n    return Impl.getCastInstrCost(Opcode, Dst, Src, CCH, CostKind, I);\n  }\n  int getExtractWithExtendCost(unsigned Opcode, Type *Dst, VectorType *VecTy,\n                               unsigned Index) override {\n    return Impl.getExtractWithExtendCost(Opcode, Dst, VecTy, Index);\n  }\n  int getCFInstrCost(unsigned Opcode, TTI::TargetCostKind CostKind) override {\n    return Impl.getCFInstrCost(Opcode, CostKind);\n  }\n  int getCmpSelInstrCost(unsigned Opcode, Type *ValTy, Type *CondTy,\n                         CmpInst::Predicate VecPred,\n                         TTI::TargetCostKind CostKind,\n                         const Instruction *I) override {\n    return Impl.getCmpSelInstrCost(Opcode, ValTy, CondTy, VecPred, CostKind, I);\n  }\n  int getVectorInstrCost(unsigned Opcode, Type *Val, unsigned Index) override {\n    return Impl.getVectorInstrCost(Opcode, Val, Index);\n  }\n  int getMemoryOpCost(unsigned Opcode, Type *Src, Align Alignment,\n                      unsigned AddressSpace, TTI::TargetCostKind CostKind,\n                      const Instruction *I) override {\n    return Impl.getMemoryOpCost(Opcode, Src, Alignment, AddressSpace,\n                                CostKind, I);\n  }\n  int getMaskedMemoryOpCost(unsigned Opcode, Type *Src, Align Alignment,\n                            unsigned AddressSpace,\n                            TTI::TargetCostKind CostKind) override {\n    return Impl.getMaskedMemoryOpCost(Opcode, Src, Alignment, AddressSpace,\n                                      CostKind);\n  }\n  int getGatherScatterOpCost(unsigned Opcode, Type *DataTy, const Value *Ptr,\n                             bool VariableMask, Align Alignment,\n                             TTI::TargetCostKind CostKind,\n                             const Instruction *I = nullptr) override {\n    return Impl.getGatherScatterOpCost(Opcode, DataTy, Ptr, VariableMask,\n                                       Alignment, CostKind, I);\n  }\n  int getInterleavedMemoryOpCost(unsigned Opcode, Type *VecTy, unsigned Factor,\n                                 ArrayRef<unsigned> Indices, Align Alignment,\n                                 unsigned AddressSpace,\n                                 TTI::TargetCostKind CostKind,\n                                 bool UseMaskForCond,\n                                 bool UseMaskForGaps) override {\n    return Impl.getInterleavedMemoryOpCost(Opcode, VecTy, Factor, Indices,\n                                           Alignment, AddressSpace, CostKind,\n                                           UseMaskForCond, UseMaskForGaps);\n  }\n  int getArithmeticReductionCost(unsigned Opcode, VectorType *Ty,\n                                 bool IsPairwiseForm,\n                                 TTI::TargetCostKind CostKind) override {\n    return Impl.getArithmeticReductionCost(Opcode, Ty, IsPairwiseForm,\n                                           CostKind);\n  }\n  int getMinMaxReductionCost(VectorType *Ty, VectorType *CondTy,\n                             bool IsPairwiseForm, bool IsUnsigned,\n                             TTI::TargetCostKind CostKind) override {\n    return Impl.getMinMaxReductionCost(Ty, CondTy, IsPairwiseForm, IsUnsigned,\n                                       CostKind);\n  }\n  InstructionCost getExtendedAddReductionCost(\n      bool IsMLA, bool IsUnsigned, Type *ResTy, VectorType *Ty,\n      TTI::TargetCostKind CostKind = TTI::TCK_RecipThroughput) override {\n    return Impl.getExtendedAddReductionCost(IsMLA, IsUnsigned, ResTy, Ty,\n                                            CostKind);\n  }\n  int getIntrinsicInstrCost(const IntrinsicCostAttributes &ICA,\n                            TTI::TargetCostKind CostKind) override {\n    return Impl.getIntrinsicInstrCost(ICA, CostKind);\n  }\n  int getCallInstrCost(Function *F, Type *RetTy,\n                       ArrayRef<Type *> Tys,\n                       TTI::TargetCostKind CostKind) override {\n    return Impl.getCallInstrCost(F, RetTy, Tys, CostKind);\n  }\n  unsigned getNumberOfParts(Type *Tp) override {\n    return Impl.getNumberOfParts(Tp);\n  }\n  int getAddressComputationCost(Type *Ty, ScalarEvolution *SE,\n                                const SCEV *Ptr) override {\n    return Impl.getAddressComputationCost(Ty, SE, Ptr);\n  }\n  unsigned getCostOfKeepingLiveOverCall(ArrayRef<Type *> Tys) override {\n    return Impl.getCostOfKeepingLiveOverCall(Tys);\n  }\n  bool getTgtMemIntrinsic(IntrinsicInst *Inst,\n                          MemIntrinsicInfo &Info) override {\n    return Impl.getTgtMemIntrinsic(Inst, Info);\n  }\n  unsigned getAtomicMemIntrinsicMaxElementSize() const override {\n    return Impl.getAtomicMemIntrinsicMaxElementSize();\n  }\n  Value *getOrCreateResultFromMemIntrinsic(IntrinsicInst *Inst,\n                                           Type *ExpectedType) override {\n    return Impl.getOrCreateResultFromMemIntrinsic(Inst, ExpectedType);\n  }\n  Type *getMemcpyLoopLoweringType(LLVMContext &Context, Value *Length,\n                                  unsigned SrcAddrSpace, unsigned DestAddrSpace,\n                                  unsigned SrcAlign,\n                                  unsigned DestAlign) const override {\n    return Impl.getMemcpyLoopLoweringType(Context, Length, SrcAddrSpace,\n                                          DestAddrSpace, SrcAlign, DestAlign);\n  }\n  void getMemcpyLoopResidualLoweringType(\n      SmallVectorImpl<Type *> &OpsOut, LLVMContext &Context,\n      unsigned RemainingBytes, unsigned SrcAddrSpace, unsigned DestAddrSpace,\n      unsigned SrcAlign, unsigned DestAlign) const override {\n    Impl.getMemcpyLoopResidualLoweringType(OpsOut, Context, RemainingBytes,\n                                           SrcAddrSpace, DestAddrSpace,\n                                           SrcAlign, DestAlign);\n  }\n  bool areInlineCompatible(const Function *Caller,\n                           const Function *Callee) const override {\n    return Impl.areInlineCompatible(Caller, Callee);\n  }\n  bool areFunctionArgsABICompatible(\n      const Function *Caller, const Function *Callee,\n      SmallPtrSetImpl<Argument *> &Args) const override {\n    return Impl.areFunctionArgsABICompatible(Caller, Callee, Args);\n  }\n  bool isIndexedLoadLegal(MemIndexedMode Mode, Type *Ty) const override {\n    return Impl.isIndexedLoadLegal(Mode, Ty, getDataLayout());\n  }\n  bool isIndexedStoreLegal(MemIndexedMode Mode, Type *Ty) const override {\n    return Impl.isIndexedStoreLegal(Mode, Ty, getDataLayout());\n  }\n  unsigned getLoadStoreVecRegBitWidth(unsigned AddrSpace) const override {\n    return Impl.getLoadStoreVecRegBitWidth(AddrSpace);\n  }\n  bool isLegalToVectorizeLoad(LoadInst *LI) const override {\n    return Impl.isLegalToVectorizeLoad(LI);\n  }\n  bool isLegalToVectorizeStore(StoreInst *SI) const override {\n    return Impl.isLegalToVectorizeStore(SI);\n  }\n  bool isLegalToVectorizeLoadChain(unsigned ChainSizeInBytes, Align Alignment,\n                                   unsigned AddrSpace) const override {\n    return Impl.isLegalToVectorizeLoadChain(ChainSizeInBytes, Alignment,\n                                            AddrSpace);\n  }\n  bool isLegalToVectorizeStoreChain(unsigned ChainSizeInBytes, Align Alignment,\n                                    unsigned AddrSpace) const override {\n    return Impl.isLegalToVectorizeStoreChain(ChainSizeInBytes, Alignment,\n                                             AddrSpace);\n  }\n  bool isLegalToVectorizeReduction(RecurrenceDescriptor RdxDesc,\n                                   ElementCount VF) const override {\n    return Impl.isLegalToVectorizeReduction(RdxDesc, VF);\n  }\n  unsigned getLoadVectorFactor(unsigned VF, unsigned LoadSize,\n                               unsigned ChainSizeInBytes,\n                               VectorType *VecTy) const override {\n    return Impl.getLoadVectorFactor(VF, LoadSize, ChainSizeInBytes, VecTy);\n  }\n  unsigned getStoreVectorFactor(unsigned VF, unsigned StoreSize,\n                                unsigned ChainSizeInBytes,\n                                VectorType *VecTy) const override {\n    return Impl.getStoreVectorFactor(VF, StoreSize, ChainSizeInBytes, VecTy);\n  }\n  bool preferInLoopReduction(unsigned Opcode, Type *Ty,\n                             ReductionFlags Flags) const override {\n    return Impl.preferInLoopReduction(Opcode, Ty, Flags);\n  }\n  bool preferPredicatedReductionSelect(unsigned Opcode, Type *Ty,\n                                       ReductionFlags Flags) const override {\n    return Impl.preferPredicatedReductionSelect(Opcode, Ty, Flags);\n  }\n  bool shouldExpandReduction(const IntrinsicInst *II) const override {\n    return Impl.shouldExpandReduction(II);\n  }\n\n  unsigned getGISelRematGlobalCost() const override {\n    return Impl.getGISelRematGlobalCost();\n  }\n\n  bool supportsScalableVectors() const override {\n    return Impl.supportsScalableVectors();\n  }\n\n  bool hasActiveVectorLength() const override {\n    return Impl.hasActiveVectorLength();\n  }\n\n  int getInstructionLatency(const Instruction *I) override {\n    return Impl.getInstructionLatency(I);\n  }\n};\n\ntemplate <typename T>\nTargetTransformInfo::TargetTransformInfo(T Impl)\n    : TTIImpl(new Model<T>(Impl)) {}\n\n/// Analysis pass providing the \\c TargetTransformInfo.\n///\n/// The core idea of the TargetIRAnalysis is to expose an interface through\n/// which LLVM targets can analyze and provide information about the middle\n/// end's target-independent IR. This supports use cases such as target-aware\n/// cost modeling of IR constructs.\n///\n/// This is a function analysis because much of the cost modeling for targets\n/// is done in a subtarget specific way and LLVM supports compiling different\n/// functions targeting different subtargets in order to support runtime\n/// dispatch according to the observed subtarget.\nclass TargetIRAnalysis : public AnalysisInfoMixin<TargetIRAnalysis> {\npublic:\n  typedef TargetTransformInfo Result;\n\n  /// Default construct a target IR analysis.\n  ///\n  /// This will use the module's datalayout to construct a baseline\n  /// conservative TTI result.\n  TargetIRAnalysis();\n\n  /// Construct an IR analysis pass around a target-provide callback.\n  ///\n  /// The callback will be called with a particular function for which the TTI\n  /// is needed and must return a TTI object for that function.\n  TargetIRAnalysis(std::function<Result(const Function &)> TTICallback);\n\n  // Value semantics. We spell out the constructors for MSVC.\n  TargetIRAnalysis(const TargetIRAnalysis &Arg)\n      : TTICallback(Arg.TTICallback) {}\n  TargetIRAnalysis(TargetIRAnalysis &&Arg)\n      : TTICallback(std::move(Arg.TTICallback)) {}\n  TargetIRAnalysis &operator=(const TargetIRAnalysis &RHS) {\n    TTICallback = RHS.TTICallback;\n    return *this;\n  }\n  TargetIRAnalysis &operator=(TargetIRAnalysis &&RHS) {\n    TTICallback = std::move(RHS.TTICallback);\n    return *this;\n  }\n\n  Result run(const Function &F, FunctionAnalysisManager &);\n\nprivate:\n  friend AnalysisInfoMixin<TargetIRAnalysis>;\n  static AnalysisKey Key;\n\n  /// The callback used to produce a result.\n  ///\n  /// We use a completely opaque callback so that targets can provide whatever\n  /// mechanism they desire for constructing the TTI for a given function.\n  ///\n  /// FIXME: Should we really use std::function? It's relatively inefficient.\n  /// It might be possible to arrange for even stateful callbacks to outlive\n  /// the analysis and thus use a function_ref which would be lighter weight.\n  /// This may also be less error prone as the callback is likely to reference\n  /// the external TargetMachine, and that reference needs to never dangle.\n  std::function<Result(const Function &)> TTICallback;\n\n  /// Helper function used as the callback in the default constructor.\n  static Result getDefaultTTI(const Function &F);\n};\n\n/// Wrapper pass for TargetTransformInfo.\n///\n/// This pass can be constructed from a TTI object which it stores internally\n/// and is queried by passes.\nclass TargetTransformInfoWrapperPass : public ImmutablePass {\n  TargetIRAnalysis TIRA;\n  Optional<TargetTransformInfo> TTI;\n\n  virtual void anchor();\n\npublic:\n  static char ID;\n\n  /// We must provide a default constructor for the pass but it should\n  /// never be used.\n  ///\n  /// Use the constructor below or call one of the creation routines.\n  TargetTransformInfoWrapperPass();\n\n  explicit TargetTransformInfoWrapperPass(TargetIRAnalysis TIRA);\n\n  TargetTransformInfo &getTTI(const Function &F);\n};\n\n/// Create an analysis pass wrapper around a TTI object.\n///\n/// This analysis pass just holds the TTI instance and makes it available to\n/// clients.\nImmutablePass *createTargetTransformInfoWrapperPass(TargetIRAnalysis TIRA);\n\n} // namespace llvm\n\n#endif\n"}, "33": {"id": 33, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Attributes.h", "content": "//===- llvm/Attributes.h - Container for Attributes -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This file contains the simple types necessary to represent the\n/// attributes associated with functions and their calls.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_ATTRIBUTES_H\n#define LLVM_IR_ATTRIBUTES_H\n\n#include \"llvm-c/Types.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Config/llvm-config.h\"\n#include \"llvm/Support/Alignment.h\"\n#include \"llvm/Support/PointerLikeTypeTraits.h\"\n#include <bitset>\n#include <cassert>\n#include <cstdint>\n#include <map>\n#include <string>\n#include <utility>\n\nnamespace llvm {\n\nclass AttrBuilder;\nclass AttributeImpl;\nclass AttributeListImpl;\nclass AttributeSetNode;\ntemplate<typename T> struct DenseMapInfo;\nclass FoldingSetNodeID;\nclass Function;\nclass LLVMContext;\nclass Type;\n\n//===----------------------------------------------------------------------===//\n/// \\class\n/// Functions, function parameters, and return types can have attributes\n/// to indicate how they should be treated by optimizations and code\n/// generation. This class represents one of those attributes. It's light-weight\n/// and should be passed around by-value.\nclass Attribute {\npublic:\n  /// This enumeration lists the attributes that can be associated with\n  /// parameters, function results, or the function itself.\n  ///\n  /// Note: The `uwtable' attribute is about the ABI or the user mandating an\n  /// entry in the unwind table. The `nounwind' attribute is about an exception\n  /// passing by the function.\n  ///\n  /// In a theoretical system that uses tables for profiling and SjLj for\n  /// exceptions, they would be fully independent. In a normal system that uses\n  /// tables for both, the semantics are:\n  ///\n  /// nil                = Needs an entry because an exception might pass by.\n  /// nounwind           = No need for an entry\n  /// uwtable            = Needs an entry because the ABI says so and because\n  ///                      an exception might pass by.\n  /// uwtable + nounwind = Needs an entry because the ABI says so.\n\n  enum AttrKind {\n    // IR-Level Attributes\n    None,                  ///< No attributes have been set\n    #define GET_ATTR_NAMES\n    #define ATTRIBUTE_ENUM(ENUM_NAME, OTHER) ENUM_NAME,\n    #include \"llvm/IR/Attributes.inc\"\n    EndAttrKinds,          ///< Sentinal value useful for loops\n    EmptyKey,              ///< Use as Empty key for DenseMap of AttrKind\n    TombstoneKey,          ///< Use as Tombstone key for DenseMap of AttrKind\n  };\n\nprivate:\n  AttributeImpl *pImpl = nullptr;\n\n  Attribute(AttributeImpl *A) : pImpl(A) {}\n\npublic:\n  Attribute() = default;\n\n  //===--------------------------------------------------------------------===//\n  // Attribute Construction\n  //===--------------------------------------------------------------------===//\n\n  /// Return a uniquified Attribute object.\n  static Attribute get(LLVMContext &Context, AttrKind Kind, uint64_t Val = 0);\n  static Attribute get(LLVMContext &Context, StringRef Kind,\n                       StringRef Val = StringRef());\n  static Attribute get(LLVMContext &Context, AttrKind Kind, Type *Ty);\n\n  /// Return a uniquified Attribute object that has the specific\n  /// alignment set.\n  static Attribute getWithAlignment(LLVMContext &Context, Align Alignment);\n  static Attribute getWithStackAlignment(LLVMContext &Context, Align Alignment);\n  static Attribute getWithDereferenceableBytes(LLVMContext &Context,\n                                              uint64_t Bytes);\n  static Attribute getWithDereferenceableOrNullBytes(LLVMContext &Context,\n                                                     uint64_t Bytes);\n  static Attribute getWithAllocSizeArgs(LLVMContext &Context,\n                                        unsigned ElemSizeArg,\n                                        const Optional<unsigned> &NumElemsArg);\n  static Attribute getWithByValType(LLVMContext &Context, Type *Ty);\n  static Attribute getWithStructRetType(LLVMContext &Context, Type *Ty);\n  static Attribute getWithByRefType(LLVMContext &Context, Type *Ty);\n  static Attribute getWithPreallocatedType(LLVMContext &Context, Type *Ty);\n\n  /// For a typed attribute, return the equivalent attribute with the type\n  /// changed to \\p ReplacementTy.\n  Attribute getWithNewType(LLVMContext &Context, Type *ReplacementTy) {\n    assert(isTypeAttribute() && \"this requires a typed attribute\");\n    return get(Context, getKindAsEnum(), ReplacementTy);\n  }\n\n  static Attribute::AttrKind getAttrKindFromName(StringRef AttrName);\n\n  static StringRef getNameFromAttrKind(Attribute::AttrKind AttrKind);\n\n  /// Return true if and only if the attribute has an Argument.\n  static bool doesAttrKindHaveArgument(Attribute::AttrKind AttrKind);\n\n  /// Return true if the provided string matches the IR name of an attribute.\n  /// example: \"noalias\" return true but not \"NoAlias\"\n  static bool isExistingAttribute(StringRef Name);\n\n  //===--------------------------------------------------------------------===//\n  // Attribute Accessors\n  //===--------------------------------------------------------------------===//\n\n  /// Return true if the attribute is an Attribute::AttrKind type.\n  bool isEnumAttribute() const;\n\n  /// Return true if the attribute is an integer attribute.\n  bool isIntAttribute() const;\n\n  /// Return true if the attribute is a string (target-dependent)\n  /// attribute.\n  bool isStringAttribute() const;\n\n  /// Return true if the attribute is a type attribute.\n  bool isTypeAttribute() const;\n\n  /// Return true if the attribute is any kind of attribute.\n  bool isValid() const { return pImpl; }\n\n  /// Return true if the attribute is present.\n  bool hasAttribute(AttrKind Val) const;\n\n  /// Return true if the target-dependent attribute is present.\n  bool hasAttribute(StringRef Val) const;\n\n  /// Return the attribute's kind as an enum (Attribute::AttrKind). This\n  /// requires the attribute to be an enum or integer attribute.\n  Attribute::AttrKind getKindAsEnum() const;\n\n  /// Return the attribute's value as an integer. This requires that the\n  /// attribute be an integer attribute.\n  uint64_t getValueAsInt() const;\n\n  /// Return the attribute's kind as a string. This requires the\n  /// attribute to be a string attribute.\n  StringRef getKindAsString() const;\n\n  /// Return the attribute's value as a string. This requires the\n  /// attribute to be a string attribute.\n  StringRef getValueAsString() const;\n\n  /// Return the attribute's value as a Type. This requires the attribute to be\n  /// a type attribute.\n  Type *getValueAsType() const;\n\n  /// Returns the alignment field of an attribute as a byte alignment\n  /// value.\n  MaybeAlign getAlignment() const;\n\n  /// Returns the stack alignment field of an attribute as a byte\n  /// alignment value.\n  MaybeAlign getStackAlignment() const;\n\n  /// Returns the number of dereferenceable bytes from the\n  /// dereferenceable attribute.\n  uint64_t getDereferenceableBytes() const;\n\n  /// Returns the number of dereferenceable_or_null bytes from the\n  /// dereferenceable_or_null attribute.\n  uint64_t getDereferenceableOrNullBytes() const;\n\n  /// Returns the argument numbers for the allocsize attribute (or pair(0, 0)\n  /// if not known).\n  std::pair<unsigned, Optional<unsigned>> getAllocSizeArgs() const;\n\n  /// The Attribute is converted to a string of equivalent mnemonic. This\n  /// is, presumably, for writing out the mnemonics for the assembly writer.\n  std::string getAsString(bool InAttrGrp = false) const;\n\n  /// Equality and non-equality operators.\n  bool operator==(Attribute A) const { return pImpl == A.pImpl; }\n  bool operator!=(Attribute A) const { return pImpl != A.pImpl; }\n\n  /// Less-than operator. Useful for sorting the attributes list.\n  bool operator<(Attribute A) const;\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  /// Return a raw pointer that uniquely identifies this attribute.\n  void *getRawPointer() const {\n    return pImpl;\n  }\n\n  /// Get an attribute from a raw pointer created by getRawPointer.\n  static Attribute fromRawPointer(void *RawPtr) {\n    return Attribute(reinterpret_cast<AttributeImpl*>(RawPtr));\n  }\n};\n\n// Specialized opaque value conversions.\ninline LLVMAttributeRef wrap(Attribute Attr) {\n  return reinterpret_cast<LLVMAttributeRef>(Attr.getRawPointer());\n}\n\n// Specialized opaque value conversions.\ninline Attribute unwrap(LLVMAttributeRef Attr) {\n  return Attribute::fromRawPointer(Attr);\n}\n\n//===----------------------------------------------------------------------===//\n/// \\class\n/// This class holds the attributes for a particular argument, parameter,\n/// function, or return value. It is an immutable value type that is cheap to\n/// copy. Adding and removing enum attributes is intended to be fast, but adding\n/// and removing string or integer attributes involves a FoldingSet lookup.\nclass AttributeSet {\n  friend AttributeListImpl;\n  template <typename Ty> friend struct DenseMapInfo;\n\n  // TODO: Extract AvailableAttrs from AttributeSetNode and store them here.\n  // This will allow an efficient implementation of addAttribute and\n  // removeAttribute for enum attrs.\n\n  /// Private implementation pointer.\n  AttributeSetNode *SetNode = nullptr;\n\nprivate:\n  explicit AttributeSet(AttributeSetNode *ASN) : SetNode(ASN) {}\n\npublic:\n  /// AttributeSet is a trivially copyable value type.\n  AttributeSet() = default;\n  AttributeSet(const AttributeSet &) = default;\n  ~AttributeSet() = default;\n\n  static AttributeSet get(LLVMContext &C, const AttrBuilder &B);\n  static AttributeSet get(LLVMContext &C, ArrayRef<Attribute> Attrs);\n\n  bool operator==(const AttributeSet &O) const { return SetNode == O.SetNode; }\n  bool operator!=(const AttributeSet &O) const { return !(*this == O); }\n\n  /// Add an argument attribute. Returns a new set because attribute sets are\n  /// immutable.\n  LLVM_NODISCARD AttributeSet addAttribute(LLVMContext &C,\n                                           Attribute::AttrKind Kind) const;\n\n  /// Add a target-dependent attribute. Returns a new set because attribute sets\n  /// are immutable.\n  LLVM_NODISCARD AttributeSet addAttribute(LLVMContext &C, StringRef Kind,\n                                           StringRef Value = StringRef()) const;\n\n  /// Add attributes to the attribute set. Returns a new set because attribute\n  /// sets are immutable.\n  LLVM_NODISCARD AttributeSet addAttributes(LLVMContext &C,\n                                            AttributeSet AS) const;\n\n  /// Remove the specified attribute from this set. Returns a new set because\n  /// attribute sets are immutable.\n  LLVM_NODISCARD AttributeSet removeAttribute(LLVMContext &C,\n                                              Attribute::AttrKind Kind) const;\n\n  /// Remove the specified attribute from this set. Returns a new set because\n  /// attribute sets are immutable.\n  LLVM_NODISCARD AttributeSet removeAttribute(LLVMContext &C,\n                                              StringRef Kind) const;\n\n  /// Remove the specified attributes from this set. Returns a new set because\n  /// attribute sets are immutable.\n  LLVM_NODISCARD AttributeSet\n  removeAttributes(LLVMContext &C, const AttrBuilder &AttrsToRemove) const;\n\n  /// Return the number of attributes in this set.\n  unsigned getNumAttributes() const;\n\n  /// Return true if attributes exists in this set.\n  bool hasAttributes() const { return SetNode != nullptr; }\n\n  /// Return true if the attribute exists in this set.\n  bool hasAttribute(Attribute::AttrKind Kind) const;\n\n  /// Return true if the attribute exists in this set.\n  bool hasAttribute(StringRef Kind) const;\n\n  /// Return the attribute object.\n  Attribute getAttribute(Attribute::AttrKind Kind) const;\n\n  /// Return the target-dependent attribute object.\n  Attribute getAttribute(StringRef Kind) const;\n\n  MaybeAlign getAlignment() const;\n  MaybeAlign getStackAlignment() const;\n  uint64_t getDereferenceableBytes() const;\n  uint64_t getDereferenceableOrNullBytes() const;\n  Type *getByValType() const;\n  Type *getStructRetType() const;\n  Type *getByRefType() const;\n  Type *getPreallocatedType() const;\n  std::pair<unsigned, Optional<unsigned>> getAllocSizeArgs() const;\n  std::string getAsString(bool InAttrGrp = false) const;\n\n  using iterator = const Attribute *;\n\n  iterator begin() const;\n  iterator end() const;\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  void dump() const;\n#endif\n};\n\n//===----------------------------------------------------------------------===//\n/// \\class\n/// Provide DenseMapInfo for AttributeSet.\ntemplate <> struct DenseMapInfo<AttributeSet> {\n  static AttributeSet getEmptyKey() {\n    auto Val = static_cast<uintptr_t>(-1);\n    Val <<= PointerLikeTypeTraits<void *>::NumLowBitsAvailable;\n    return AttributeSet(reinterpret_cast<AttributeSetNode *>(Val));\n  }\n\n  static AttributeSet getTombstoneKey() {\n    auto Val = static_cast<uintptr_t>(-2);\n    Val <<= PointerLikeTypeTraits<void *>::NumLowBitsAvailable;\n    return AttributeSet(reinterpret_cast<AttributeSetNode *>(Val));\n  }\n\n  static unsigned getHashValue(AttributeSet AS) {\n    return (unsigned((uintptr_t)AS.SetNode) >> 4) ^\n           (unsigned((uintptr_t)AS.SetNode) >> 9);\n  }\n\n  static bool isEqual(AttributeSet LHS, AttributeSet RHS) { return LHS == RHS; }\n};\n\n//===----------------------------------------------------------------------===//\n/// \\class\n/// This class holds the attributes for a function, its return value, and\n/// its parameters. You access the attributes for each of them via an index into\n/// the AttributeList object. The function attributes are at index\n/// `AttributeList::FunctionIndex', the return value is at index\n/// `AttributeList::ReturnIndex', and the attributes for the parameters start at\n/// index `AttributeList::FirstArgIndex'.\nclass AttributeList {\npublic:\n  enum AttrIndex : unsigned {\n    ReturnIndex = 0U,\n    FunctionIndex = ~0U,\n    FirstArgIndex = 1,\n  };\n\nprivate:\n  friend class AttrBuilder;\n  friend class AttributeListImpl;\n  friend class AttributeSet;\n  friend class AttributeSetNode;\n  template <typename Ty> friend struct DenseMapInfo;\n\n  /// The attributes that we are managing. This can be null to represent\n  /// the empty attributes list.\n  AttributeListImpl *pImpl = nullptr;\n\npublic:\n  /// Create an AttributeList with the specified parameters in it.\n  static AttributeList get(LLVMContext &C,\n                           ArrayRef<std::pair<unsigned, Attribute>> Attrs);\n  static AttributeList get(LLVMContext &C,\n                           ArrayRef<std::pair<unsigned, AttributeSet>> Attrs);\n\n  /// Create an AttributeList from attribute sets for a function, its\n  /// return value, and all of its arguments.\n  static AttributeList get(LLVMContext &C, AttributeSet FnAttrs,\n                           AttributeSet RetAttrs,\n                           ArrayRef<AttributeSet> ArgAttrs);\n\nprivate:\n  explicit AttributeList(AttributeListImpl *LI) : pImpl(LI) {}\n\n  static AttributeList getImpl(LLVMContext &C, ArrayRef<AttributeSet> AttrSets);\n\n  AttributeList setAttributes(LLVMContext &C, unsigned Index,\n                              AttributeSet Attrs) const;\n\npublic:\n  AttributeList() = default;\n\n  //===--------------------------------------------------------------------===//\n  // AttributeList Construction and Mutation\n  //===--------------------------------------------------------------------===//\n\n  /// Return an AttributeList with the specified parameters in it.\n  static AttributeList get(LLVMContext &C, ArrayRef<AttributeList> Attrs);\n  static AttributeList get(LLVMContext &C, unsigned Index,\n                           ArrayRef<Attribute::AttrKind> Kinds);\n  static AttributeList get(LLVMContext &C, unsigned Index,\n                           ArrayRef<Attribute::AttrKind> Kinds,\n                           ArrayRef<uint64_t> Values);\n  static AttributeList get(LLVMContext &C, unsigned Index,\n                           ArrayRef<StringRef> Kind);\n  static AttributeList get(LLVMContext &C, unsigned Index,\n                           const AttrBuilder &B);\n\n  /// Add an attribute to the attribute set at the given index.\n  /// Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addAttribute(LLVMContext &C, unsigned Index,\n                                            Attribute::AttrKind Kind) const;\n\n  /// Add an attribute to the attribute set at the given index.\n  /// Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList\n  addAttribute(LLVMContext &C, unsigned Index, StringRef Kind,\n               StringRef Value = StringRef()) const;\n\n  /// Add an attribute to the attribute set at the given index.\n  /// Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addAttribute(LLVMContext &C, unsigned Index,\n                                            Attribute A) const;\n\n  /// Add attributes to the attribute set at the given index.\n  /// Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addAttributes(LLVMContext &C, unsigned Index,\n                                             const AttrBuilder &B) const;\n\n  /// Add an argument attribute to the list. Returns a new list because\n  /// attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addParamAttribute(\n      LLVMContext &C, unsigned ArgNo, Attribute::AttrKind Kind) const {\n    return addAttribute(C, ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Add an argument attribute to the list. Returns a new list because\n  /// attribute lists are immutable.\n  LLVM_NODISCARD AttributeList\n  addParamAttribute(LLVMContext &C, unsigned ArgNo, StringRef Kind,\n                    StringRef Value = StringRef()) const {\n    return addAttribute(C, ArgNo + FirstArgIndex, Kind, Value);\n  }\n\n  /// Add an attribute to the attribute list at the given arg indices. Returns a\n  /// new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addParamAttribute(LLVMContext &C,\n                                                 ArrayRef<unsigned> ArgNos,\n                                                 Attribute A) const;\n\n  /// Add an argument attribute to the list. Returns a new list because\n  /// attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addParamAttributes(LLVMContext &C,\n                                                  unsigned ArgNo,\n                                                  const AttrBuilder &B) const {\n    return addAttributes(C, ArgNo + FirstArgIndex, B);\n  }\n\n  /// Remove the specified attribute at the specified index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeAttribute(LLVMContext &C, unsigned Index,\n                                               Attribute::AttrKind Kind) const;\n\n  /// Remove the specified attribute at the specified index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeAttribute(LLVMContext &C, unsigned Index,\n                                               StringRef Kind) const;\n\n  /// Remove the specified attributes at the specified index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeAttributes(\n      LLVMContext &C, unsigned Index, const AttrBuilder &AttrsToRemove) const;\n\n  /// Remove all attributes at the specified index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeAttributes(LLVMContext &C,\n                                                unsigned Index) const;\n\n  /// Remove the specified attribute at the specified arg index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeParamAttribute(\n      LLVMContext &C, unsigned ArgNo, Attribute::AttrKind Kind) const {\n    return removeAttribute(C, ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Remove the specified attribute at the specified arg index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeParamAttribute(LLVMContext &C,\n                                                    unsigned ArgNo,\n                                                    StringRef Kind) const {\n    return removeAttribute(C, ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Remove the specified attribute at the specified arg index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeParamAttributes(\n      LLVMContext &C, unsigned ArgNo, const AttrBuilder &AttrsToRemove) const {\n    return removeAttributes(C, ArgNo + FirstArgIndex, AttrsToRemove);\n  }\n\n  /// Remove all attributes at the specified arg index from this\n  /// attribute list. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList removeParamAttributes(LLVMContext &C,\n                                                     unsigned ArgNo) const {\n    return removeAttributes(C, ArgNo + FirstArgIndex);\n  }\n\n  /// Replace the type contained by attribute \\p AttrKind at index \\p ArgNo wih\n  /// \\p ReplacementTy, preserving all other attributes.\n  LLVM_NODISCARD AttributeList replaceAttributeType(LLVMContext &C,\n                                                    unsigned ArgNo,\n                                                    Attribute::AttrKind Kind,\n                                                    Type *ReplacementTy) const {\n    Attribute Attr = getAttribute(ArgNo, Kind);\n    auto Attrs = removeAttribute(C, ArgNo, Kind);\n    return Attrs.addAttribute(C, ArgNo, Attr.getWithNewType(C, ReplacementTy));\n  }\n\n  /// \\brief Add the dereferenceable attribute to the attribute set at the given\n  /// index. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addDereferenceableAttr(LLVMContext &C,\n                                                      unsigned Index,\n                                                      uint64_t Bytes) const;\n\n  /// \\brief Add the dereferenceable attribute to the attribute set at the given\n  /// arg index. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addDereferenceableParamAttr(\n      LLVMContext &C, unsigned ArgNo, uint64_t Bytes) const {\n    return addDereferenceableAttr(C, ArgNo + FirstArgIndex, Bytes);\n  }\n\n  /// Add the dereferenceable_or_null attribute to the attribute set at\n  /// the given index. Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList addDereferenceableOrNullAttr(\n      LLVMContext &C, unsigned Index, uint64_t Bytes) const;\n\n  /// Add the dereferenceable_or_null attribute to the attribute set at\n  /// the given arg index. Returns a new list because attribute lists are\n  /// immutable.\n  LLVM_NODISCARD AttributeList addDereferenceableOrNullParamAttr(\n      LLVMContext &C, unsigned ArgNo, uint64_t Bytes) const {\n    return addDereferenceableOrNullAttr(C, ArgNo + FirstArgIndex, Bytes);\n  }\n\n  /// Add the allocsize attribute to the attribute set at the given index.\n  /// Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList\n  addAllocSizeAttr(LLVMContext &C, unsigned Index, unsigned ElemSizeArg,\n                   const Optional<unsigned> &NumElemsArg);\n\n  /// Add the allocsize attribute to the attribute set at the given arg index.\n  /// Returns a new list because attribute lists are immutable.\n  LLVM_NODISCARD AttributeList\n  addAllocSizeParamAttr(LLVMContext &C, unsigned ArgNo, unsigned ElemSizeArg,\n                        const Optional<unsigned> &NumElemsArg) {\n    return addAllocSizeAttr(C, ArgNo + FirstArgIndex, ElemSizeArg, NumElemsArg);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // AttributeList Accessors\n  //===--------------------------------------------------------------------===//\n\n  /// The attributes for the specified index are returned.\n  AttributeSet getAttributes(unsigned Index) const;\n\n  /// The attributes for the argument or parameter at the given index are\n  /// returned.\n  AttributeSet getParamAttributes(unsigned ArgNo) const;\n\n  /// The attributes for the ret value are returned.\n  AttributeSet getRetAttributes() const;\n\n  /// The function attributes are returned.\n  AttributeSet getFnAttributes() const;\n\n  /// Return true if the attribute exists at the given index.\n  bool hasAttribute(unsigned Index, Attribute::AttrKind Kind) const;\n\n  /// Return true if the attribute exists at the given index.\n  bool hasAttribute(unsigned Index, StringRef Kind) const;\n\n  /// Return true if attribute exists at the given index.\n  bool hasAttributes(unsigned Index) const;\n\n  /// Return true if the attribute exists for the given argument\n  bool hasParamAttr(unsigned ArgNo, Attribute::AttrKind Kind) const {\n    return hasAttribute(ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Return true if the attribute exists for the given argument\n  bool hasParamAttr(unsigned ArgNo, StringRef Kind) const {\n    return hasAttribute(ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Return true if attributes exists for the given argument\n  bool hasParamAttrs(unsigned ArgNo) const {\n    return hasAttributes(ArgNo + FirstArgIndex);\n  }\n\n  /// Equivalent to hasAttribute(AttributeList::FunctionIndex, Kind) but\n  /// may be faster.\n  bool hasFnAttribute(Attribute::AttrKind Kind) const;\n\n  /// Equivalent to hasAttribute(AttributeList::FunctionIndex, Kind) but\n  /// may be faster.\n  bool hasFnAttribute(StringRef Kind) const;\n\n  /// Equivalent to hasAttribute(ArgNo + FirstArgIndex, Kind).\n  bool hasParamAttribute(unsigned ArgNo, Attribute::AttrKind Kind) const;\n\n  /// Return true if the specified attribute is set for at least one\n  /// parameter or for the return value. If Index is not nullptr, the index\n  /// of a parameter with the specified attribute is provided.\n  bool hasAttrSomewhere(Attribute::AttrKind Kind,\n                        unsigned *Index = nullptr) const;\n\n  /// Return the attribute object that exists at the given index.\n  Attribute getAttribute(unsigned Index, Attribute::AttrKind Kind) const;\n\n  /// Return the attribute object that exists at the given index.\n  Attribute getAttribute(unsigned Index, StringRef Kind) const;\n\n  /// Return the attribute object that exists at the arg index.\n  Attribute getParamAttr(unsigned ArgNo, Attribute::AttrKind Kind) const {\n    return getAttribute(ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Return the attribute object that exists at the given index.\n  Attribute getParamAttr(unsigned ArgNo, StringRef Kind) const {\n    return getAttribute(ArgNo + FirstArgIndex, Kind);\n  }\n\n  /// Return the alignment of the return value.\n  MaybeAlign getRetAlignment() const;\n\n  /// Return the alignment for the specified function parameter.\n  MaybeAlign getParamAlignment(unsigned ArgNo) const;\n\n  /// Return the byval type for the specified function parameter.\n  Type *getParamByValType(unsigned ArgNo) const;\n\n  /// Return the sret type for the specified function parameter.\n  Type *getParamStructRetType(unsigned ArgNo) const;\n\n  /// Return the byref type for the specified function parameter.\n  Type *getParamByRefType(unsigned ArgNo) const;\n\n  /// Return the preallocated type for the specified function parameter.\n  Type *getParamPreallocatedType(unsigned ArgNo) const;\n\n  /// Get the stack alignment.\n  MaybeAlign getStackAlignment(unsigned Index) const;\n\n  /// Get the number of dereferenceable bytes (or zero if unknown).\n  uint64_t getDereferenceableBytes(unsigned Index) const;\n\n  /// Get the number of dereferenceable bytes (or zero if unknown) of an\n  /// arg.\n  uint64_t getParamDereferenceableBytes(unsigned ArgNo) const {\n    return getDereferenceableBytes(ArgNo + FirstArgIndex);\n  }\n\n  /// Get the number of dereferenceable_or_null bytes (or zero if\n  /// unknown).\n  uint64_t getDereferenceableOrNullBytes(unsigned Index) const;\n\n  /// Get the number of dereferenceable_or_null bytes (or zero if\n  /// unknown) of an arg.\n  uint64_t getParamDereferenceableOrNullBytes(unsigned ArgNo) const {\n    return getDereferenceableOrNullBytes(ArgNo + FirstArgIndex);\n  }\n\n  /// Get the allocsize argument numbers (or pair(0, 0) if unknown).\n  std::pair<unsigned, Optional<unsigned>>\n  getAllocSizeArgs(unsigned Index) const;\n\n  /// Return the attributes at the index as a string.\n  std::string getAsString(unsigned Index, bool InAttrGrp = false) const;\n\n  //===--------------------------------------------------------------------===//\n  // AttributeList Introspection\n  //===--------------------------------------------------------------------===//\n\n  using iterator = const AttributeSet *;\n\n  iterator begin() const;\n  iterator end() const;\n\n  unsigned getNumAttrSets() const;\n\n  /// Use these to iterate over the valid attribute indices.\n  unsigned index_begin() const { return AttributeList::FunctionIndex; }\n  unsigned index_end() const { return getNumAttrSets() - 1; }\n\n  /// operator==/!= - Provide equality predicates.\n  bool operator==(const AttributeList &RHS) const { return pImpl == RHS.pImpl; }\n  bool operator!=(const AttributeList &RHS) const { return pImpl != RHS.pImpl; }\n\n  /// Return a raw pointer that uniquely identifies this attribute list.\n  void *getRawPointer() const {\n    return pImpl;\n  }\n\n  /// Return true if there are no attributes.\n  bool isEmpty() const { return pImpl == nullptr; }\n\n  void dump() const;\n};\n\n//===----------------------------------------------------------------------===//\n/// \\class\n/// Provide DenseMapInfo for AttributeList.\ntemplate <> struct DenseMapInfo<AttributeList> {\n  static AttributeList getEmptyKey() {\n    auto Val = static_cast<uintptr_t>(-1);\n    Val <<= PointerLikeTypeTraits<void*>::NumLowBitsAvailable;\n    return AttributeList(reinterpret_cast<AttributeListImpl *>(Val));\n  }\n\n  static AttributeList getTombstoneKey() {\n    auto Val = static_cast<uintptr_t>(-2);\n    Val <<= PointerLikeTypeTraits<void*>::NumLowBitsAvailable;\n    return AttributeList(reinterpret_cast<AttributeListImpl *>(Val));\n  }\n\n  static unsigned getHashValue(AttributeList AS) {\n    return (unsigned((uintptr_t)AS.pImpl) >> 4) ^\n           (unsigned((uintptr_t)AS.pImpl) >> 9);\n  }\n\n  static bool isEqual(AttributeList LHS, AttributeList RHS) {\n    return LHS == RHS;\n  }\n};\n\n//===----------------------------------------------------------------------===//\n/// \\class\n/// This class is used in conjunction with the Attribute::get method to\n/// create an Attribute object. The object itself is uniquified. The Builder's\n/// value, however, is not. So this can be used as a quick way to test for\n/// equality, presence of attributes, etc.\nclass AttrBuilder {\n  std::bitset<Attribute::EndAttrKinds> Attrs;\n  std::map<std::string, std::string, std::less<>> TargetDepAttrs;\n  MaybeAlign Alignment;\n  MaybeAlign StackAlignment;\n  uint64_t DerefBytes = 0;\n  uint64_t DerefOrNullBytes = 0;\n  uint64_t AllocSizeArgs = 0;\n  Type *ByValType = nullptr;\n  Type *StructRetType = nullptr;\n  Type *ByRefType = nullptr;\n  Type *PreallocatedType = nullptr;\n\npublic:\n  AttrBuilder() = default;\n\n  AttrBuilder(const Attribute &A) {\n    addAttribute(A);\n  }\n\n  AttrBuilder(AttributeList AS, unsigned Idx);\n  AttrBuilder(AttributeSet AS);\n\n  void clear();\n\n  /// Add an attribute to the builder.\n  AttrBuilder &addAttribute(Attribute::AttrKind Val) {\n    assert((unsigned)Val < Attribute::EndAttrKinds &&\n           \"Attribute out of range!\");\n    assert(!Attribute::doesAttrKindHaveArgument(Val) &&\n           \"Adding integer attribute without adding a value!\");\n    Attrs[Val] = true;\n    return *this;\n  }\n\n  /// Add the Attribute object to the builder.\n  AttrBuilder &addAttribute(Attribute A);\n\n  /// Add the target-dependent attribute to the builder.\n  AttrBuilder &addAttribute(StringRef A, StringRef V = StringRef());\n\n  /// Remove an attribute from the builder.\n  AttrBuilder &removeAttribute(Attribute::AttrKind Val);\n\n  /// Remove the attributes from the builder.\n  AttrBuilder &removeAttributes(AttributeList A, uint64_t WithoutIndex);\n\n  /// Remove the target-dependent attribute to the builder.\n  AttrBuilder &removeAttribute(StringRef A);\n\n  /// Add the attributes from the builder.\n  AttrBuilder &merge(const AttrBuilder &B);\n\n  /// Remove the attributes from the builder.\n  AttrBuilder &remove(const AttrBuilder &B);\n\n  /// Return true if the builder has any attribute that's in the\n  /// specified builder.\n  bool overlaps(const AttrBuilder &B) const;\n\n  /// Return true if the builder has the specified attribute.\n  bool contains(Attribute::AttrKind A) const {\n    assert((unsigned)A < Attribute::EndAttrKinds && \"Attribute out of range!\");\n    return Attrs[A];\n  }\n\n  /// Return true if the builder has the specified target-dependent\n  /// attribute.\n  bool contains(StringRef A) const;\n\n  /// Return true if the builder has IR-level attributes.\n  bool hasAttributes() const;\n\n  /// Return true if the builder has any attribute that's in the\n  /// specified attribute.\n  bool hasAttributes(AttributeList A, uint64_t Index) const;\n\n  /// Return true if the builder has an alignment attribute.\n  bool hasAlignmentAttr() const;\n\n  /// Retrieve the alignment attribute, if it exists.\n  MaybeAlign getAlignment() const { return Alignment; }\n\n  /// Retrieve the stack alignment attribute, if it exists.\n  MaybeAlign getStackAlignment() const { return StackAlignment; }\n\n  /// Retrieve the number of dereferenceable bytes, if the\n  /// dereferenceable attribute exists (zero is returned otherwise).\n  uint64_t getDereferenceableBytes() const { return DerefBytes; }\n\n  /// Retrieve the number of dereferenceable_or_null bytes, if the\n  /// dereferenceable_or_null attribute exists (zero is returned otherwise).\n  uint64_t getDereferenceableOrNullBytes() const { return DerefOrNullBytes; }\n\n  /// Retrieve the byval type.\n  Type *getByValType() const { return ByValType; }\n\n  /// Retrieve the sret type.\n  Type *getStructRetType() const { return StructRetType; }\n\n  /// Retrieve the byref type.\n  Type *getByRefType() const { return ByRefType; }\n\n  /// Retrieve the preallocated type.\n  Type *getPreallocatedType() const { return PreallocatedType; }\n\n  /// Retrieve the allocsize args, if the allocsize attribute exists.  If it\n  /// doesn't exist, pair(0, 0) is returned.\n  std::pair<unsigned, Optional<unsigned>> getAllocSizeArgs() const;\n\n  /// This turns an alignment into the form used internally in Attribute.\n  /// This call has no effect if Align is not set.\n  AttrBuilder &addAlignmentAttr(MaybeAlign Align);\n\n  /// This turns an int alignment (which must be a power of 2) into the\n  /// form used internally in Attribute.\n  /// This call has no effect if Align is 0.\n  /// Deprecated, use the version using a MaybeAlign.\n  inline AttrBuilder &addAlignmentAttr(unsigned Align) {\n    return addAlignmentAttr(MaybeAlign(Align));\n  }\n\n  /// This turns a stack alignment into the form used internally in Attribute.\n  /// This call has no effect if Align is not set.\n  AttrBuilder &addStackAlignmentAttr(MaybeAlign Align);\n\n  /// This turns an int stack alignment (which must be a power of 2) into\n  /// the form used internally in Attribute.\n  /// This call has no effect if Align is 0.\n  /// Deprecated, use the version using a MaybeAlign.\n  inline AttrBuilder &addStackAlignmentAttr(unsigned Align) {\n    return addStackAlignmentAttr(MaybeAlign(Align));\n  }\n\n  /// This turns the number of dereferenceable bytes into the form used\n  /// internally in Attribute.\n  AttrBuilder &addDereferenceableAttr(uint64_t Bytes);\n\n  /// This turns the number of dereferenceable_or_null bytes into the\n  /// form used internally in Attribute.\n  AttrBuilder &addDereferenceableOrNullAttr(uint64_t Bytes);\n\n  /// This turns one (or two) ints into the form used internally in Attribute.\n  AttrBuilder &addAllocSizeAttr(unsigned ElemSizeArg,\n                                const Optional<unsigned> &NumElemsArg);\n\n  /// This turns a byval type into the form used internally in Attribute.\n  AttrBuilder &addByValAttr(Type *Ty);\n\n  /// This turns a sret type into the form used internally in Attribute.\n  AttrBuilder &addStructRetAttr(Type *Ty);\n\n  /// This turns a byref type into the form used internally in Attribute.\n  AttrBuilder &addByRefAttr(Type *Ty);\n\n  /// This turns a preallocated type into the form used internally in Attribute.\n  AttrBuilder &addPreallocatedAttr(Type *Ty);\n\n  /// Add an allocsize attribute, using the representation returned by\n  /// Attribute.getIntValue().\n  AttrBuilder &addAllocSizeAttrFromRawRepr(uint64_t RawAllocSizeRepr);\n\n  /// Return true if the builder contains no target-independent\n  /// attributes.\n  bool empty() const { return Attrs.none(); }\n\n  // Iterators for target-dependent attributes.\n  using td_type = std::pair<std::string, std::string>;\n  using td_iterator = decltype(TargetDepAttrs)::iterator;\n  using td_const_iterator = decltype(TargetDepAttrs)::const_iterator;\n  using td_range = iterator_range<td_iterator>;\n  using td_const_range = iterator_range<td_const_iterator>;\n\n  td_iterator td_begin() { return TargetDepAttrs.begin(); }\n  td_iterator td_end() { return TargetDepAttrs.end(); }\n\n  td_const_iterator td_begin() const { return TargetDepAttrs.begin(); }\n  td_const_iterator td_end() const { return TargetDepAttrs.end(); }\n\n  td_range td_attrs() { return td_range(td_begin(), td_end()); }\n\n  td_const_range td_attrs() const {\n    return td_const_range(td_begin(), td_end());\n  }\n\n  bool td_empty() const { return TargetDepAttrs.empty(); }\n\n  bool operator==(const AttrBuilder &B) const;\n  bool operator!=(const AttrBuilder &B) const { return !(*this == B); }\n};\n\nnamespace AttributeFuncs {\n\n/// Which attributes cannot be applied to a type.\nAttrBuilder typeIncompatible(Type *Ty);\n\n/// \\returns Return true if the two functions have compatible target-independent\n/// attributes for inlining purposes.\nbool areInlineCompatible(const Function &Caller, const Function &Callee);\n\n\n/// Checks  if there are any incompatible function attributes between\n/// \\p A and \\p B.\n///\n/// \\param [in] A - The first function to be compared with.\n/// \\param [in] B - The second function to be compared with.\n/// \\returns true if the functions have compatible attributes.\nbool areOutlineCompatible(const Function &A, const Function &B);\n\n/// Merge caller's and callee's attributes.\nvoid mergeAttributesForInlining(Function &Caller, const Function &Callee);\n\n/// Merges the functions attributes from \\p ToMerge into function \\p Base.\n///\n/// \\param [in,out] Base - The function being merged into.\n/// \\param [in] ToMerge - The function to merge attributes from.\nvoid mergeAttributesForOutlining(Function &Base, const Function &ToMerge);\n\n} // end namespace AttributeFuncs\n\n} // end namespace llvm\n\n#endif // LLVM_IR_ATTRIBUTES_H\n"}, "35": {"id": 35, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/ConstantRange.h", "content": "//===- ConstantRange.h - Represent a range ----------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Represent a range of possible values that may occur when the program is run\n// for an integral value.  This keeps track of a lower and upper bound for the\n// constant, which MAY wrap around the end of the numeric range.  To do this, it\n// keeps track of a [lower, upper) bound, which specifies an interval just like\n// STL iterators.  When used with boolean values, the following are important\n// ranges: :\n//\n//  [F, F) = {}     = Empty set\n//  [T, F) = {T}\n//  [F, T) = {F}\n//  [T, T) = {F, T} = Full set\n//\n// The other integral ranges use min/max values for special range values. For\n// example, for 8-bit types, it uses:\n// [0, 0)     = {}       = Empty set\n// [255, 255) = {0..255} = Full Set\n//\n// Note that ConstantRange can be used to represent either signed or\n// unsigned ranges.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_CONSTANTRANGE_H\n#define LLVM_IR_CONSTANTRANGE_H\n\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/Support/Compiler.h\"\n#include <cstdint>\n\nnamespace llvm {\n\nclass MDNode;\nclass raw_ostream;\nstruct KnownBits;\n\n/// This class represents a range of values.\nclass LLVM_NODISCARD ConstantRange {\n  APInt Lower, Upper;\n\n  /// Create empty constant range with same bitwidth.\n  ConstantRange getEmpty() const {\n    return ConstantRange(getBitWidth(), false);\n  }\n\n  /// Create full constant range with same bitwidth.\n  ConstantRange getFull() const {\n    return ConstantRange(getBitWidth(), true);\n  }\n\npublic:\n  /// Initialize a full or empty set for the specified bit width.\n  explicit ConstantRange(uint32_t BitWidth, bool isFullSet);\n\n  /// Initialize a range to hold the single specified value.\n  ConstantRange(APInt Value);\n\n  /// Initialize a range of values explicitly. This will assert out if\n  /// Lower==Upper and Lower != Min or Max value for its type. It will also\n  /// assert out if the two APInt's are not the same bit width.\n  ConstantRange(APInt Lower, APInt Upper);\n\n  /// Create empty constant range with the given bit width.\n  static ConstantRange getEmpty(uint32_t BitWidth) {\n    return ConstantRange(BitWidth, false);\n  }\n\n  /// Create full constant range with the given bit width.\n  static ConstantRange getFull(uint32_t BitWidth) {\n    return ConstantRange(BitWidth, true);\n  }\n\n  /// Create non-empty constant range with the given bounds. If Lower and\n  /// Upper are the same, a full range is returned.\n  static ConstantRange getNonEmpty(APInt Lower, APInt Upper) {\n    if (Lower == Upper)\n      return getFull(Lower.getBitWidth());\n    return ConstantRange(std::move(Lower), std::move(Upper));\n  }\n\n  /// Initialize a range based on a known bits constraint. The IsSigned flag\n  /// indicates whether the constant range should not wrap in the signed or\n  /// unsigned domain.\n  static ConstantRange fromKnownBits(const KnownBits &Known, bool IsSigned);\n\n  /// Produce the smallest range such that all values that may satisfy the given\n  /// predicate with any value contained within Other is contained in the\n  /// returned range.  Formally, this returns a superset of\n  /// 'union over all y in Other . { x : icmp op x y is true }'.  If the exact\n  /// answer is not representable as a ConstantRange, the return value will be a\n  /// proper superset of the above.\n  ///\n  /// Example: Pred = ult and Other = i8 [2, 5) returns Result = [0, 4)\n  static ConstantRange makeAllowedICmpRegion(CmpInst::Predicate Pred,\n                                             const ConstantRange &Other);\n\n  /// Produce the largest range such that all values in the returned range\n  /// satisfy the given predicate with all values contained within Other.\n  /// Formally, this returns a subset of\n  /// 'intersection over all y in Other . { x : icmp op x y is true }'.  If the\n  /// exact answer is not representable as a ConstantRange, the return value\n  /// will be a proper subset of the above.\n  ///\n  /// Example: Pred = ult and Other = i8 [2, 5) returns [0, 2)\n  static ConstantRange makeSatisfyingICmpRegion(CmpInst::Predicate Pred,\n                                                const ConstantRange &Other);\n\n  /// Produce the exact range such that all values in the returned range satisfy\n  /// the given predicate with any value contained within Other. Formally, this\n  /// returns the exact answer when the superset of 'union over all y in Other\n  /// is exactly same as the subset of intersection over all y in Other.\n  /// { x : icmp op x y is true}'.\n  ///\n  /// Example: Pred = ult and Other = i8 3 returns [0, 3)\n  static ConstantRange makeExactICmpRegion(CmpInst::Predicate Pred,\n                                           const APInt &Other);\n\n  /// Produce the largest range containing all X such that \"X BinOp Y\" is\n  /// guaranteed not to wrap (overflow) for *all* Y in Other. However, there may\n  /// be *some* Y in Other for which additional X not contained in the result\n  /// also do not overflow.\n  ///\n  /// NoWrapKind must be one of OBO::NoUnsignedWrap or OBO::NoSignedWrap.\n  ///\n  /// Examples:\n  ///  typedef OverflowingBinaryOperator OBO;\n  ///  #define MGNR makeGuaranteedNoWrapRegion\n  ///  MGNR(Add, [i8 1, 2), OBO::NoSignedWrap) == [-128, 127)\n  ///  MGNR(Add, [i8 1, 2), OBO::NoUnsignedWrap) == [0, -1)\n  ///  MGNR(Add, [i8 0, 1), OBO::NoUnsignedWrap) == Full Set\n  ///  MGNR(Add, [i8 -1, 6), OBO::NoSignedWrap) == [INT_MIN+1, INT_MAX-4)\n  ///  MGNR(Sub, [i8 1, 2), OBO::NoSignedWrap) == [-127, 128)\n  ///  MGNR(Sub, [i8 1, 2), OBO::NoUnsignedWrap) == [1, 0)\n  static ConstantRange makeGuaranteedNoWrapRegion(Instruction::BinaryOps BinOp,\n                                                  const ConstantRange &Other,\n                                                  unsigned NoWrapKind);\n\n  /// Produce the range that contains X if and only if \"X BinOp Other\" does\n  /// not wrap.\n  static ConstantRange makeExactNoWrapRegion(Instruction::BinaryOps BinOp,\n                                             const APInt &Other,\n                                             unsigned NoWrapKind);\n\n  /// Returns true if ConstantRange calculations are supported for intrinsic\n  /// with \\p IntrinsicID.\n  static bool isIntrinsicSupported(Intrinsic::ID IntrinsicID);\n\n  /// Compute range of intrinsic result for the given operand ranges.\n  static ConstantRange intrinsic(Intrinsic::ID IntrinsicID,\n                                 ArrayRef<ConstantRange> Ops);\n\n  /// Set up \\p Pred and \\p RHS such that\n  /// ConstantRange::makeExactICmpRegion(Pred, RHS) == *this.  Return true if\n  /// successful.\n  bool getEquivalentICmp(CmpInst::Predicate &Pred, APInt &RHS) const;\n\n  /// Return the lower value for this range.\n  const APInt &getLower() const { return Lower; }\n\n  /// Return the upper value for this range.\n  const APInt &getUpper() const { return Upper; }\n\n  /// Get the bit width of this ConstantRange.\n  uint32_t getBitWidth() const { return Lower.getBitWidth(); }\n\n  /// Return true if this set contains all of the elements possible\n  /// for this data-type.\n  bool isFullSet() const;\n\n  /// Return true if this set contains no members.\n  bool isEmptySet() const;\n\n  /// Return true if this set wraps around the unsigned domain. Special cases:\n  ///  * Empty set: Not wrapped.\n  ///  * Full set: Not wrapped.\n  ///  * [X, 0) == [X, Max]: Not wrapped.\n  bool isWrappedSet() const;\n\n  /// Return true if the exclusive upper bound wraps around the unsigned\n  /// domain. Special cases:\n  ///  * Empty set: Not wrapped.\n  ///  * Full set: Not wrapped.\n  ///  * [X, 0): Wrapped.\n  bool isUpperWrapped() const;\n\n  /// Return true if this set wraps around the signed domain. Special cases:\n  ///  * Empty set: Not wrapped.\n  ///  * Full set: Not wrapped.\n  ///  * [X, SignedMin) == [X, SignedMax]: Not wrapped.\n  bool isSignWrappedSet() const;\n\n  /// Return true if the (exclusive) upper bound wraps around the signed\n  /// domain. Special cases:\n  ///  * Empty set: Not wrapped.\n  ///  * Full set: Not wrapped.\n  ///  * [X, SignedMin): Wrapped.\n  bool isUpperSignWrapped() const;\n\n  /// Return true if the specified value is in the set.\n  bool contains(const APInt &Val) const;\n\n  /// Return true if the other range is a subset of this one.\n  bool contains(const ConstantRange &CR) const;\n\n  /// If this set contains a single element, return it, otherwise return null.\n  const APInt *getSingleElement() const {\n    if (Upper == Lower + 1)\n      return &Lower;\n    return nullptr;\n  }\n\n  /// If this set contains all but a single element, return it, otherwise return\n  /// null.\n  const APInt *getSingleMissingElement() const {\n    if (Lower == Upper + 1)\n      return &Upper;\n    return nullptr;\n  }\n\n  /// Return true if this set contains exactly one member.\n  bool isSingleElement() const { return getSingleElement() != nullptr; }\n\n  /// Compare set size of this range with the range CR.\n  bool isSizeStrictlySmallerThan(const ConstantRange &CR) const;\n\n  /// Compare set size of this range with Value.\n  bool isSizeLargerThan(uint64_t MaxSize) const;\n\n  /// Return true if all values in this range are negative.\n  bool isAllNegative() const;\n\n  /// Return true if all values in this range are non-negative.\n  bool isAllNonNegative() const;\n\n  /// Return the largest unsigned value contained in the ConstantRange.\n  APInt getUnsignedMax() const;\n\n  /// Return the smallest unsigned value contained in the ConstantRange.\n  APInt getUnsignedMin() const;\n\n  /// Return the largest signed value contained in the ConstantRange.\n  APInt getSignedMax() const;\n\n  /// Return the smallest signed value contained in the ConstantRange.\n  APInt getSignedMin() const;\n\n  /// Return true if this range is equal to another range.\n  bool operator==(const ConstantRange &CR) const {\n    return Lower == CR.Lower && Upper == CR.Upper;\n  }\n  bool operator!=(const ConstantRange &CR) const {\n    return !operator==(CR);\n  }\n\n  /// Compute the maximal number of active bits needed to represent every value\n  /// in this range.\n  unsigned getActiveBits() const;\n\n  /// Compute the maximal number of bits needed to represent every value\n  /// in this signed range.\n  unsigned getMinSignedBits() const;\n\n  /// Subtract the specified constant from the endpoints of this constant range.\n  ConstantRange subtract(const APInt &CI) const;\n\n  /// Subtract the specified range from this range (aka relative complement of\n  /// the sets).\n  ConstantRange difference(const ConstantRange &CR) const;\n\n  /// If represented precisely, the result of some range operations may consist\n  /// of multiple disjoint ranges. As only a single range may be returned, any\n  /// range covering these disjoint ranges constitutes a valid result, but some\n  /// may be more useful than others depending on context. The preferred range\n  /// type specifies whether a range that is non-wrapping in the unsigned or\n  /// signed domain, or has the smallest size, is preferred. If a signedness is\n  /// preferred but all ranges are non-wrapping or all wrapping, then the\n  /// smallest set size is preferred. If there are multiple smallest sets, any\n  /// one of them may be returned.\n  enum PreferredRangeType { Smallest, Unsigned, Signed };\n\n  /// Return the range that results from the intersection of this range with\n  /// another range. If the intersection is disjoint, such that two results\n  /// are possible, the preferred range is determined by the PreferredRangeType.\n  ConstantRange intersectWith(const ConstantRange &CR,\n                              PreferredRangeType Type = Smallest) const;\n\n  /// Return the range that results from the union of this range\n  /// with another range.  The resultant range is guaranteed to include the\n  /// elements of both sets, but may contain more.  For example, [3, 9) union\n  /// [12,15) is [3, 15), which includes 9, 10, and 11, which were not included\n  /// in either set before.\n  ConstantRange unionWith(const ConstantRange &CR,\n                          PreferredRangeType Type = Smallest) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an application of the specified cast operator to this range. \\p\n  /// BitWidth is the target bitwidth of the cast.  For casts which don't\n  /// change bitwidth, it must be the same as the source bitwidth.  For casts\n  /// which do change bitwidth, the bitwidth must be consistent with the\n  /// requested cast and source bitwidth.\n  ConstantRange castOp(Instruction::CastOps CastOp,\n                       uint32_t BitWidth) const;\n\n  /// Return a new range in the specified integer type, which must\n  /// be strictly larger than the current type.  The returned range will\n  /// correspond to the possible range of values if the source range had been\n  /// zero extended to BitWidth.\n  ConstantRange zeroExtend(uint32_t BitWidth) const;\n\n  /// Return a new range in the specified integer type, which must\n  /// be strictly larger than the current type.  The returned range will\n  /// correspond to the possible range of values if the source range had been\n  /// sign extended to BitWidth.\n  ConstantRange signExtend(uint32_t BitWidth) const;\n\n  /// Return a new range in the specified integer type, which must be\n  /// strictly smaller than the current type.  The returned range will\n  /// correspond to the possible range of values if the source range had been\n  /// truncated to the specified type.\n  ConstantRange truncate(uint32_t BitWidth) const;\n\n  /// Make this range have the bit width given by \\p BitWidth. The\n  /// value is zero extended, truncated, or left alone to make it that width.\n  ConstantRange zextOrTrunc(uint32_t BitWidth) const;\n\n  /// Make this range have the bit width given by \\p BitWidth. The\n  /// value is sign extended, truncated, or left alone to make it that width.\n  ConstantRange sextOrTrunc(uint32_t BitWidth) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an application of the specified binary operator to an left hand side\n  /// of this range and a right hand side of \\p Other.\n  ConstantRange binaryOp(Instruction::BinaryOps BinOp,\n                         const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an application of the specified overflowing binary operator to a\n  /// left hand side of this range and a right hand side of \\p Other given\n  /// the provided knowledge about lack of wrapping \\p NoWrapKind.\n  ConstantRange overflowingBinaryOp(Instruction::BinaryOps BinOp,\n                                    const ConstantRange &Other,\n                                    unsigned NoWrapKind) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an addition of a value in this range and a value in \\p Other.\n  ConstantRange add(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an addition with wrap type \\p NoWrapKind of a value in this\n  /// range and a value in \\p Other.\n  /// If the result range is disjoint, the preferred range is determined by the\n  /// \\p PreferredRangeType.\n  ConstantRange addWithNoWrap(const ConstantRange &Other, unsigned NoWrapKind,\n                              PreferredRangeType RangeType = Smallest) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a subtraction of a value in this range and a value in \\p Other.\n  ConstantRange sub(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an subtraction with wrap type \\p NoWrapKind of a value in this\n  /// range and a value in \\p Other.\n  /// If the result range is disjoint, the preferred range is determined by the\n  /// \\p PreferredRangeType.\n  ConstantRange subWithNoWrap(const ConstantRange &Other, unsigned NoWrapKind,\n                              PreferredRangeType RangeType = Smallest) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a multiplication of a value in this range and a value in \\p Other,\n  /// treating both this and \\p Other as unsigned ranges.\n  ConstantRange multiply(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a signed maximum of a value in this range and a value in \\p Other.\n  ConstantRange smax(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an unsigned maximum of a value in this range and a value in \\p Other.\n  ConstantRange umax(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a signed minimum of a value in this range and a value in \\p Other.\n  ConstantRange smin(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an unsigned minimum of a value in this range and a value in \\p Other.\n  ConstantRange umin(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an unsigned division of a value in this range and a value in\n  /// \\p Other.\n  ConstantRange udiv(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a signed division of a value in this range and a value in\n  /// \\p Other. Division by zero and division of SignedMin by -1 are considered\n  /// undefined behavior, in line with IR, and do not contribute towards the\n  /// result.\n  ConstantRange sdiv(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from an unsigned remainder operation of a value in this range and a\n  /// value in \\p Other.\n  ConstantRange urem(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a signed remainder operation of a value in this range and a\n  /// value in \\p Other.\n  ConstantRange srem(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting from\n  /// a binary-xor of a value in this range by an all-one value,\n  /// aka bitwise complement operation.\n  ConstantRange binaryNot() const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a binary-and of a value in this range by a value in \\p Other.\n  ConstantRange binaryAnd(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a binary-or of a value in this range by a value in \\p Other.\n  ConstantRange binaryOr(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a binary-xor of a value in this range by a value in \\p Other.\n  ConstantRange binaryXor(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting\n  /// from a left shift of a value in this range by a value in \\p Other.\n  /// TODO: This isn't fully implemented yet.\n  ConstantRange shl(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting from a\n  /// logical right shift of a value in this range and a value in \\p Other.\n  ConstantRange lshr(const ConstantRange &Other) const;\n\n  /// Return a new range representing the possible values resulting from a\n  /// arithmetic right shift of a value in this range and a value in \\p Other.\n  ConstantRange ashr(const ConstantRange &Other) const;\n\n  /// Perform an unsigned saturating addition of two constant ranges.\n  ConstantRange uadd_sat(const ConstantRange &Other) const;\n\n  /// Perform a signed saturating addition of two constant ranges.\n  ConstantRange sadd_sat(const ConstantRange &Other) const;\n\n  /// Perform an unsigned saturating subtraction of two constant ranges.\n  ConstantRange usub_sat(const ConstantRange &Other) const;\n\n  /// Perform a signed saturating subtraction of two constant ranges.\n  ConstantRange ssub_sat(const ConstantRange &Other) const;\n\n  /// Perform an unsigned saturating multiplication of two constant ranges.\n  ConstantRange umul_sat(const ConstantRange &Other) const;\n\n  /// Perform a signed saturating multiplication of two constant ranges.\n  ConstantRange smul_sat(const ConstantRange &Other) const;\n\n  /// Perform an unsigned saturating left shift of this constant range by a\n  /// value in \\p Other.\n  ConstantRange ushl_sat(const ConstantRange &Other) const;\n\n  /// Perform a signed saturating left shift of this constant range by a\n  /// value in \\p Other.\n  ConstantRange sshl_sat(const ConstantRange &Other) const;\n\n  /// Return a new range that is the logical not of the current set.\n  ConstantRange inverse() const;\n\n  /// Calculate absolute value range. If the original range contains signed\n  /// min, then the resulting range will contain signed min if and only if\n  /// \\p IntMinIsPoison is false.\n  ConstantRange abs(bool IntMinIsPoison = false) const;\n\n  /// Represents whether an operation on the given constant range is known to\n  /// always or never overflow.\n  enum class OverflowResult {\n    /// Always overflows in the direction of signed/unsigned min value.\n    AlwaysOverflowsLow,\n    /// Always overflows in the direction of signed/unsigned max value.\n    AlwaysOverflowsHigh,\n    /// May or may not overflow.\n    MayOverflow,\n    /// Never overflows.\n    NeverOverflows,\n  };\n\n  /// Return whether unsigned add of the two ranges always/never overflows.\n  OverflowResult unsignedAddMayOverflow(const ConstantRange &Other) const;\n\n  /// Return whether signed add of the two ranges always/never overflows.\n  OverflowResult signedAddMayOverflow(const ConstantRange &Other) const;\n\n  /// Return whether unsigned sub of the two ranges always/never overflows.\n  OverflowResult unsignedSubMayOverflow(const ConstantRange &Other) const;\n\n  /// Return whether signed sub of the two ranges always/never overflows.\n  OverflowResult signedSubMayOverflow(const ConstantRange &Other) const;\n\n  /// Return whether unsigned mul of the two ranges always/never overflows.\n  OverflowResult unsignedMulMayOverflow(const ConstantRange &Other) const;\n\n  /// Print out the bounds to a stream.\n  void print(raw_ostream &OS) const;\n\n  /// Allow printing from a debugger easily.\n  void dump() const;\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const ConstantRange &CR) {\n  CR.print(OS);\n  return OS;\n}\n\n/// Parse out a conservative ConstantRange from !range metadata.\n///\n/// E.g. if RangeMD is !{i32 0, i32 10, i32 15, i32 20} then return [0, 20).\nConstantRange getConstantRangeFromMetadata(const MDNode &RangeMD);\n\n} // end namespace llvm\n\n#endif // LLVM_IR_CONSTANTRANGE_H\n"}, "39": {"id": 39, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DebugLoc.h", "content": "//===- DebugLoc.h - Debug Location Information ------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines a number of light weight data structures used\n// to describe and track debug location information.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_DEBUGLOC_H\n#define LLVM_IR_DEBUGLOC_H\n\n#include \"llvm/IR/TrackingMDRef.h\"\n#include \"llvm/Support/DataTypes.h\"\n\nnamespace llvm {\n\n  class LLVMContext;\n  class raw_ostream;\n  class DILocation;\n\n  /// A debug info location.\n  ///\n  /// This class is a wrapper around a tracking reference to an \\a DILocation\n  /// pointer.\n  ///\n  /// To avoid extra includes, \\a DebugLoc doubles the \\a DILocation API with a\n  /// one based on relatively opaque \\a MDNode pointers.\n  class DebugLoc {\n    TrackingMDNodeRef Loc;\n\n  public:\n    DebugLoc() = default;\n\n    /// Construct from an \\a DILocation.\n    DebugLoc(const DILocation *L);\n\n    /// Construct from an \\a MDNode.\n    ///\n    /// Note: if \\c N is not an \\a DILocation, a verifier check will fail, and\n    /// accessors will crash.  However, construction from other nodes is\n    /// supported in order to handle forward references when reading textual\n    /// IR.\n    explicit DebugLoc(const MDNode *N);\n\n    /// Get the underlying \\a DILocation.\n    ///\n    /// \\pre !*this or \\c isa<DILocation>(getAsMDNode()).\n    /// @{\n    DILocation *get() const;\n    operator DILocation *() const { return get(); }\n    DILocation *operator->() const { return get(); }\n    DILocation &operator*() const { return *get(); }\n    /// @}\n\n    /// Check for null.\n    ///\n    /// Check for null in a way that is safe with broken debug info.  Unlike\n    /// the conversion to \\c DILocation, this doesn't require that \\c Loc is of\n    /// the right type.  Important for cases like \\a llvm::StripDebugInfo() and\n    /// \\a Instruction::hasMetadata().\n    explicit operator bool() const { return Loc; }\n\n    /// Check whether this has a trivial destructor.\n    bool hasTrivialDestructor() const { return Loc.hasTrivialDestructor(); }\n\n    enum { ReplaceLastInlinedAt = true };\n    /// Rebuild the entire inlined-at chain for this instruction so that the top of\n    /// the chain now is inlined-at the new call site.\n    /// \\param   InlinedAt    The new outermost inlined-at in the chain.\n    static DebugLoc appendInlinedAt(const DebugLoc &DL, DILocation *InlinedAt,\n                                    LLVMContext &Ctx,\n                                    DenseMap<const MDNode *, MDNode *> &Cache);\n\n    unsigned getLine() const;\n    unsigned getCol() const;\n    MDNode *getScope() const;\n    DILocation *getInlinedAt() const;\n\n    /// Get the fully inlined-at scope for a DebugLoc.\n    ///\n    /// Gets the inlined-at scope for a DebugLoc.\n    MDNode *getInlinedAtScope() const;\n\n    /// Find the debug info location for the start of the function.\n    ///\n    /// Walk up the scope chain of given debug loc and find line number info\n    /// for the function.\n    ///\n    /// FIXME: Remove this.  Users should use DILocation/DILocalScope API to\n    /// find the subprogram, and then DILocation::get().\n    DebugLoc getFnDebugLoc() const;\n\n    /// Return \\c this as a bar \\a MDNode.\n    MDNode *getAsMDNode() const { return Loc; }\n\n    /// Check if the DebugLoc corresponds to an implicit code.\n    bool isImplicitCode() const;\n    void setImplicitCode(bool ImplicitCode);\n\n    bool operator==(const DebugLoc &DL) const { return Loc == DL.Loc; }\n    bool operator!=(const DebugLoc &DL) const { return Loc != DL.Loc; }\n\n    void dump() const;\n\n    /// prints source location /path/to/file.exe:line:col @[inlined at]\n    void print(raw_ostream &OS) const;\n  };\n\n} // end namespace llvm\n\n#endif // LLVM_IR_DEBUGLOC_H\n"}, "40": {"id": 40, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DerivedTypes.h", "content": "//===- llvm/DerivedTypes.h - Classes for handling data types ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file contains the declarations of classes that represent \"derived\n// types\".  These are things like \"arrays of x\" or \"structure of x, y, z\" or\n// \"function returning x taking (y,z) as parameters\", etc...\n//\n// The implementations of these classes live in the Type.cpp file.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_DERIVEDTYPES_H\n#define LLVM_IR_DERIVEDTYPES_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/Compiler.h\"\n#include \"llvm/Support/TypeSize.h\"\n#include <cassert>\n#include <cstdint>\n\nnamespace llvm {\n\nclass Value;\nclass APInt;\nclass LLVMContext;\n\n/// Class to represent integer types. Note that this class is also used to\n/// represent the built-in integer types: Int1Ty, Int8Ty, Int16Ty, Int32Ty and\n/// Int64Ty.\n/// Integer representation type\nclass IntegerType : public Type {\n  friend class LLVMContextImpl;\n\nprotected:\n  explicit IntegerType(LLVMContext &C, unsigned NumBits) : Type(C, IntegerTyID){\n    setSubclassData(NumBits);\n  }\n\npublic:\n  /// This enum is just used to hold constants we need for IntegerType.\n  enum {\n    MIN_INT_BITS = 1,        ///< Minimum number of bits that can be specified\n    MAX_INT_BITS = (1<<24)-1 ///< Maximum number of bits that can be specified\n      ///< Note that bit width is stored in the Type classes SubclassData field\n      ///< which has 24 bits. This yields a maximum bit width of 16,777,215\n      ///< bits.\n  };\n\n  /// This static method is the primary way of constructing an IntegerType.\n  /// If an IntegerType with the same NumBits value was previously instantiated,\n  /// that instance will be returned. Otherwise a new one will be created. Only\n  /// one instance with a given NumBits value is ever created.\n  /// Get or create an IntegerType instance.\n  static IntegerType *get(LLVMContext &C, unsigned NumBits);\n\n  /// Returns type twice as wide the input type.\n  IntegerType *getExtendedType() const {\n    return Type::getIntNTy(getContext(), 2 * getScalarSizeInBits());\n  }\n\n  /// Get the number of bits in this IntegerType\n  unsigned getBitWidth() const { return getSubclassData(); }\n\n  /// Return a bitmask with ones set for all of the bits that can be set by an\n  /// unsigned version of this type. This is 0xFF for i8, 0xFFFF for i16, etc.\n  uint64_t getBitMask() const {\n    return ~uint64_t(0UL) >> (64-getBitWidth());\n  }\n\n  /// Return a uint64_t with just the most significant bit set (the sign bit, if\n  /// the value is treated as a signed number).\n  uint64_t getSignBit() const {\n    return 1ULL << (getBitWidth()-1);\n  }\n\n  /// For example, this is 0xFF for an 8 bit integer, 0xFFFF for i16, etc.\n  /// @returns a bit mask with ones set for all the bits of this type.\n  /// Get a bit mask for this type.\n  APInt getMask() const;\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast.\n  static bool classof(const Type *T) {\n    return T->getTypeID() == IntegerTyID;\n  }\n};\n\nunsigned Type::getIntegerBitWidth() const {\n  return cast<IntegerType>(this)->getBitWidth();\n}\n\n/// Class to represent function types\n///\nclass FunctionType : public Type {\n  FunctionType(Type *Result, ArrayRef<Type*> Params, bool IsVarArgs);\n\npublic:\n  FunctionType(const FunctionType &) = delete;\n  FunctionType &operator=(const FunctionType &) = delete;\n\n  /// This static method is the primary way of constructing a FunctionType.\n  static FunctionType *get(Type *Result,\n                           ArrayRef<Type*> Params, bool isVarArg);\n\n  /// Create a FunctionType taking no parameters.\n  static FunctionType *get(Type *Result, bool isVarArg);\n\n  /// Return true if the specified type is valid as a return type.\n  static bool isValidReturnType(Type *RetTy);\n\n  /// Return true if the specified type is valid as an argument type.\n  static bool isValidArgumentType(Type *ArgTy);\n\n  bool isVarArg() const { return getSubclassData()!=0; }\n  Type *getReturnType() const { return ContainedTys[0]; }\n\n  using param_iterator = Type::subtype_iterator;\n\n  param_iterator param_begin() const { return ContainedTys + 1; }\n  param_iterator param_end() const { return &ContainedTys[NumContainedTys]; }\n  ArrayRef<Type *> params() const {\n    return makeArrayRef(param_begin(), param_end());\n  }\n\n  /// Parameter type accessors.\n  Type *getParamType(unsigned i) const { return ContainedTys[i+1]; }\n\n  /// Return the number of fixed parameters this function type requires.\n  /// This does not consider varargs.\n  unsigned getNumParams() const { return NumContainedTys - 1; }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast.\n  static bool classof(const Type *T) {\n    return T->getTypeID() == FunctionTyID;\n  }\n};\nstatic_assert(alignof(FunctionType) >= alignof(Type *),\n              \"Alignment sufficient for objects appended to FunctionType\");\n\nbool Type::isFunctionVarArg() const {\n  return cast<FunctionType>(this)->isVarArg();\n}\n\nType *Type::getFunctionParamType(unsigned i) const {\n  return cast<FunctionType>(this)->getParamType(i);\n}\n\nunsigned Type::getFunctionNumParams() const {\n  return cast<FunctionType>(this)->getNumParams();\n}\n\n/// A handy container for a FunctionType+Callee-pointer pair, which can be\n/// passed around as a single entity. This assists in replacing the use of\n/// PointerType::getElementType() to access the function's type, since that's\n/// slated for removal as part of the [opaque pointer types] project.\nclass FunctionCallee {\npublic:\n  // Allow implicit conversion from types which have a getFunctionType member\n  // (e.g. Function and InlineAsm).\n  template <typename T, typename U = decltype(&T::getFunctionType)>\n  FunctionCallee(T *Fn)\n      : FnTy(Fn ? Fn->getFunctionType() : nullptr), Callee(Fn) {}\n\n  FunctionCallee(FunctionType *FnTy, Value *Callee)\n      : FnTy(FnTy), Callee(Callee) {\n    assert((FnTy == nullptr) == (Callee == nullptr));\n  }\n\n  FunctionCallee(std::nullptr_t) {}\n\n  FunctionCallee() = default;\n\n  FunctionType *getFunctionType() { return FnTy; }\n\n  Value *getCallee() { return Callee; }\n\n  explicit operator bool() { return Callee; }\n\nprivate:\n  FunctionType *FnTy = nullptr;\n  Value *Callee = nullptr;\n};\n\n/// Class to represent struct types. There are two different kinds of struct\n/// types: Literal structs and Identified structs.\n///\n/// Literal struct types (e.g. { i32, i32 }) are uniqued structurally, and must\n/// always have a body when created.  You can get one of these by using one of\n/// the StructType::get() forms.\n///\n/// Identified structs (e.g. %foo or %42) may optionally have a name and are not\n/// uniqued.  The names for identified structs are managed at the LLVMContext\n/// level, so there can only be a single identified struct with a given name in\n/// a particular LLVMContext.  Identified structs may also optionally be opaque\n/// (have no body specified).  You get one of these by using one of the\n/// StructType::create() forms.\n///\n/// Independent of what kind of struct you have, the body of a struct type are\n/// laid out in memory consecutively with the elements directly one after the\n/// other (if the struct is packed) or (if not packed) with padding between the\n/// elements as defined by DataLayout (which is required to match what the code\n/// generator for a target expects).\n///\nclass StructType : public Type {\n  StructType(LLVMContext &C) : Type(C, StructTyID) {}\n\n  enum {\n    /// This is the contents of the SubClassData field.\n    SCDB_HasBody = 1,\n    SCDB_Packed = 2,\n    SCDB_IsLiteral = 4,\n    SCDB_IsSized = 8\n  };\n\n  /// For a named struct that actually has a name, this is a pointer to the\n  /// symbol table entry (maintained by LLVMContext) for the struct.\n  /// This is null if the type is an literal struct or if it is a identified\n  /// type that has an empty name.\n  void *SymbolTableEntry = nullptr;\n\npublic:\n  StructType(const StructType &) = delete;\n  StructType &operator=(const StructType &) = delete;\n\n  /// This creates an identified struct.\n  static StructType *create(LLVMContext &Context, StringRef Name);\n  static StructType *create(LLVMContext &Context);\n\n  static StructType *create(ArrayRef<Type *> Elements, StringRef Name,\n                            bool isPacked = false);\n  static StructType *create(ArrayRef<Type *> Elements);\n  static StructType *create(LLVMContext &Context, ArrayRef<Type *> Elements,\n                            StringRef Name, bool isPacked = false);\n  static StructType *create(LLVMContext &Context, ArrayRef<Type *> Elements);\n  template <class... Tys>\n  static std::enable_if_t<are_base_of<Type, Tys...>::value, StructType *>\n  create(StringRef Name, Type *elt1, Tys *... elts) {\n    assert(elt1 && \"Cannot create a struct type with no elements with this\");\n    SmallVector<llvm::Type *, 8> StructFields({elt1, elts...});\n    return create(StructFields, Name);\n  }\n\n  /// This static method is the primary way to create a literal StructType.\n  static StructType *get(LLVMContext &Context, ArrayRef<Type*> Elements,\n                         bool isPacked = false);\n\n  /// Create an empty structure type.\n  static StructType *get(LLVMContext &Context, bool isPacked = false);\n\n  /// This static method is a convenience method for creating structure types by\n  /// specifying the elements as arguments. Note that this method always returns\n  /// a non-packed struct, and requires at least one element type.\n  template <class... Tys>\n  static std::enable_if_t<are_base_of<Type, Tys...>::value, StructType *>\n  get(Type *elt1, Tys *... elts) {\n    assert(elt1 && \"Cannot create a struct type with no elements with this\");\n    LLVMContext &Ctx = elt1->getContext();\n    SmallVector<llvm::Type *, 8> StructFields({elt1, elts...});\n    return llvm::StructType::get(Ctx, StructFields);\n  }\n\n  /// Return the type with the specified name, or null if there is none by that\n  /// name.\n  static StructType *getTypeByName(LLVMContext &C, StringRef Name);\n\n  bool isPacked() const { return (getSubclassData() & SCDB_Packed) != 0; }\n\n  /// Return true if this type is uniqued by structural equivalence, false if it\n  /// is a struct definition.\n  bool isLiteral() const { return (getSubclassData() & SCDB_IsLiteral) != 0; }\n\n  /// Return true if this is a type with an identity that has no body specified\n  /// yet. These prints as 'opaque' in .ll files.\n  bool isOpaque() const { return (getSubclassData() & SCDB_HasBody) == 0; }\n\n  /// isSized - Return true if this is a sized type.\n  bool isSized(SmallPtrSetImpl<Type *> *Visited = nullptr) const;\n\n  /// Returns true if this struct contains a scalable vector.\n  bool containsScalableVectorType() const;\n\n  /// Return true if this is a named struct that has a non-empty name.\n  bool hasName() const { return SymbolTableEntry != nullptr; }\n\n  /// Return the name for this struct type if it has an identity.\n  /// This may return an empty string for an unnamed struct type.  Do not call\n  /// this on an literal type.\n  StringRef getName() const;\n\n  /// Change the name of this type to the specified name, or to a name with a\n  /// suffix if there is a collision. Do not call this on an literal type.\n  void setName(StringRef Name);\n\n  /// Specify a body for an opaque identified type.\n  void setBody(ArrayRef<Type*> Elements, bool isPacked = false);\n\n  template <typename... Tys>\n  std::enable_if_t<are_base_of<Type, Tys...>::value, void>\n  setBody(Type *elt1, Tys *... elts) {\n    assert(elt1 && \"Cannot create a struct type with no elements with this\");\n    SmallVector<llvm::Type *, 8> StructFields({elt1, elts...});\n    setBody(StructFields);\n  }\n\n  /// Return true if the specified type is valid as a element type.\n  static bool isValidElementType(Type *ElemTy);\n\n  // Iterator access to the elements.\n  using element_iterator = Type::subtype_iterator;\n\n  element_iterator element_begin() const { return ContainedTys; }\n  element_iterator element_end() const { return &ContainedTys[NumContainedTys];}\n  ArrayRef<Type *> elements() const {\n    return makeArrayRef(element_begin(), element_end());\n  }\n\n  /// Return true if this is layout identical to the specified struct.\n  bool isLayoutIdentical(StructType *Other) const;\n\n  /// Random access to the elements\n  unsigned getNumElements() const { return NumContainedTys; }\n  Type *getElementType(unsigned N) const {\n    assert(N < NumContainedTys && \"Element number out of range!\");\n    return ContainedTys[N];\n  }\n  /// Given an index value into the type, return the type of the element.\n  Type *getTypeAtIndex(const Value *V) const;\n  Type *getTypeAtIndex(unsigned N) const { return getElementType(N); }\n  bool indexValid(const Value *V) const;\n  bool indexValid(unsigned Idx) const { return Idx < getNumElements(); }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast.\n  static bool classof(const Type *T) {\n    return T->getTypeID() == StructTyID;\n  }\n};\n\nStringRef Type::getStructName() const {\n  return cast<StructType>(this)->getName();\n}\n\nunsigned Type::getStructNumElements() const {\n  return cast<StructType>(this)->getNumElements();\n}\n\nType *Type::getStructElementType(unsigned N) const {\n  return cast<StructType>(this)->getElementType(N);\n}\n\n/// Class to represent array types.\nclass ArrayType : public Type {\n  /// The element type of the array.\n  Type *ContainedType;\n  /// Number of elements in the array.\n  uint64_t NumElements;\n\n  ArrayType(Type *ElType, uint64_t NumEl);\n\npublic:\n  ArrayType(const ArrayType &) = delete;\n  ArrayType &operator=(const ArrayType &) = delete;\n\n  uint64_t getNumElements() const { return NumElements; }\n  Type *getElementType() const { return ContainedType; }\n\n  /// This static method is the primary way to construct an ArrayType\n  static ArrayType *get(Type *ElementType, uint64_t NumElements);\n\n  /// Return true if the specified type is valid as a element type.\n  static bool isValidElementType(Type *ElemTy);\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast.\n  static bool classof(const Type *T) {\n    return T->getTypeID() == ArrayTyID;\n  }\n};\n\nuint64_t Type::getArrayNumElements() const {\n  return cast<ArrayType>(this)->getNumElements();\n}\n\n/// Base class of all SIMD vector types\nclass VectorType : public Type {\n  /// A fully specified VectorType is of the form <vscale x n x Ty>. 'n' is the\n  /// minimum number of elements of type Ty contained within the vector, and\n  /// 'vscale x' indicates that the total element count is an integer multiple\n  /// of 'n', where the multiple is either guaranteed to be one, or is\n  /// statically unknown at compile time.\n  ///\n  /// If the multiple is known to be 1, then the extra term is discarded in\n  /// textual IR:\n  ///\n  /// <4 x i32>          - a vector containing 4 i32s\n  /// <vscale x 4 x i32> - a vector containing an unknown integer multiple\n  ///                      of 4 i32s\n\n  /// The element type of the vector.\n  Type *ContainedType;\n\nprotected:\n  /// The element quantity of this vector. The meaning of this value depends\n  /// on the type of vector:\n  /// - For FixedVectorType = <ElementQuantity x ty>, there are\n  ///   exactly ElementQuantity elements in this vector.\n  /// - For ScalableVectorType = <vscale x ElementQuantity x ty>,\n  ///   there are vscale * ElementQuantity elements in this vector, where\n  ///   vscale is a runtime-constant integer greater than 0.\n  const unsigned ElementQuantity;\n\n  VectorType(Type *ElType, unsigned EQ, Type::TypeID TID);\n\npublic:\n  VectorType(const VectorType &) = delete;\n  VectorType &operator=(const VectorType &) = delete;\n\n  Type *getElementType() const { return ContainedType; }\n\n  /// This static method is the primary way to construct an VectorType.\n  static VectorType *get(Type *ElementType, ElementCount EC);\n\n  static VectorType *get(Type *ElementType, unsigned NumElements,\n                         bool Scalable) {\n    return VectorType::get(ElementType,\n                           ElementCount::get(NumElements, Scalable));\n  }\n\n  static VectorType *get(Type *ElementType, const VectorType *Other) {\n    return VectorType::get(ElementType, Other->getElementCount());\n  }\n\n  /// This static method gets a VectorType with the same number of elements as\n  /// the input type, and the element type is an integer type of the same width\n  /// as the input element type.\n  static VectorType *getInteger(VectorType *VTy) {\n    unsigned EltBits = VTy->getElementType()->getPrimitiveSizeInBits();\n    assert(EltBits && \"Element size must be of a non-zero size\");\n    Type *EltTy = IntegerType::get(VTy->getContext(), EltBits);\n    return VectorType::get(EltTy, VTy->getElementCount());\n  }\n\n  /// This static method is like getInteger except that the element types are\n  /// twice as wide as the elements in the input type.\n  static VectorType *getExtendedElementVectorType(VectorType *VTy) {\n    assert(VTy->isIntOrIntVectorTy() && \"VTy expected to be a vector of ints.\");\n    auto *EltTy = cast<IntegerType>(VTy->getElementType());\n    return VectorType::get(EltTy->getExtendedType(), VTy->getElementCount());\n  }\n\n  // This static method gets a VectorType with the same number of elements as\n  // the input type, and the element type is an integer or float type which\n  // is half as wide as the elements in the input type.\n  static VectorType *getTruncatedElementVectorType(VectorType *VTy) {\n    Type *EltTy;\n    if (VTy->getElementType()->isFloatingPointTy()) {\n      switch(VTy->getElementType()->getTypeID()) {\n      case DoubleTyID:\n        EltTy = Type::getFloatTy(VTy->getContext());\n        break;\n      case FloatTyID:\n        EltTy = Type::getHalfTy(VTy->getContext());\n        break;\n      default:\n        llvm_unreachable(\"Cannot create narrower fp vector element type\");\n      }\n    } else {\n      unsigned EltBits = VTy->getElementType()->getPrimitiveSizeInBits();\n      assert((EltBits & 1) == 0 &&\n             \"Cannot truncate vector element with odd bit-width\");\n      EltTy = IntegerType::get(VTy->getContext(), EltBits / 2);\n    }\n    return VectorType::get(EltTy, VTy->getElementCount());\n  }\n\n  // This static method returns a VectorType with a smaller number of elements\n  // of a larger type than the input element type. For example, a <16 x i8>\n  // subdivided twice would return <4 x i32>\n  static VectorType *getSubdividedVectorType(VectorType *VTy, int NumSubdivs) {\n    for (int i = 0; i < NumSubdivs; ++i) {\n      VTy = VectorType::getDoubleElementsVectorType(VTy);\n      VTy = VectorType::getTruncatedElementVectorType(VTy);\n    }\n    return VTy;\n  }\n\n  /// This static method returns a VectorType with half as many elements as the\n  /// input type and the same element type.\n  static VectorType *getHalfElementsVectorType(VectorType *VTy) {\n    auto EltCnt = VTy->getElementCount();\n    assert(EltCnt.isKnownEven() &&\n           \"Cannot halve vector with odd number of elements.\");\n    return VectorType::get(VTy->getElementType(),\n                           EltCnt.divideCoefficientBy(2));\n  }\n\n  /// This static method returns a VectorType with twice as many elements as the\n  /// input type and the same element type.\n  static VectorType *getDoubleElementsVectorType(VectorType *VTy) {\n    auto EltCnt = VTy->getElementCount();\n    assert((EltCnt.getKnownMinValue() * 2ull) <= UINT_MAX &&\n           \"Too many elements in vector\");\n    return VectorType::get(VTy->getElementType(), EltCnt * 2);\n  }\n\n  /// Return true if the specified type is valid as a element type.\n  static bool isValidElementType(Type *ElemTy);\n\n  /// Return an ElementCount instance to represent the (possibly scalable)\n  /// number of elements in the vector.\n  inline ElementCount getElementCount() const;\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast.\n  static bool classof(const Type *T) {\n    return T->getTypeID() == FixedVectorTyID ||\n           T->getTypeID() == ScalableVectorTyID;\n  }\n};\n\n/// Class to represent fixed width SIMD vectors\nclass FixedVectorType : public VectorType {\nprotected:\n  FixedVectorType(Type *ElTy, unsigned NumElts)\n      : VectorType(ElTy, NumElts, FixedVectorTyID) {}\n\npublic:\n  static FixedVectorType *get(Type *ElementType, unsigned NumElts);\n\n  static FixedVectorType *get(Type *ElementType, const FixedVectorType *FVTy) {\n    return get(ElementType, FVTy->getNumElements());\n  }\n\n  static FixedVectorType *getInteger(FixedVectorType *VTy) {\n    return cast<FixedVectorType>(VectorType::getInteger(VTy));\n  }\n\n  static FixedVectorType *getExtendedElementVectorType(FixedVectorType *VTy) {\n    return cast<FixedVectorType>(VectorType::getExtendedElementVectorType(VTy));\n  }\n\n  static FixedVectorType *getTruncatedElementVectorType(FixedVectorType *VTy) {\n    return cast<FixedVectorType>(\n        VectorType::getTruncatedElementVectorType(VTy));\n  }\n\n  static FixedVectorType *getSubdividedVectorType(FixedVectorType *VTy,\n                                                  int NumSubdivs) {\n    return cast<FixedVectorType>(\n        VectorType::getSubdividedVectorType(VTy, NumSubdivs));\n  }\n\n  static FixedVectorType *getHalfElementsVectorType(FixedVectorType *VTy) {\n    return cast<FixedVectorType>(VectorType::getHalfElementsVectorType(VTy));\n  }\n\n  static FixedVectorType *getDoubleElementsVectorType(FixedVectorType *VTy) {\n    return cast<FixedVectorType>(VectorType::getDoubleElementsVectorType(VTy));\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeID() == FixedVectorTyID;\n  }\n\n  unsigned getNumElements() const { return ElementQuantity; }\n};\n\n/// Class to represent scalable SIMD vectors\nclass ScalableVectorType : public VectorType {\nprotected:\n  ScalableVectorType(Type *ElTy, unsigned MinNumElts)\n      : VectorType(ElTy, MinNumElts, ScalableVectorTyID) {}\n\npublic:\n  static ScalableVectorType *get(Type *ElementType, unsigned MinNumElts);\n\n  static ScalableVectorType *get(Type *ElementType,\n                                 const ScalableVectorType *SVTy) {\n    return get(ElementType, SVTy->getMinNumElements());\n  }\n\n  static ScalableVectorType *getInteger(ScalableVectorType *VTy) {\n    return cast<ScalableVectorType>(VectorType::getInteger(VTy));\n  }\n\n  static ScalableVectorType *\n  getExtendedElementVectorType(ScalableVectorType *VTy) {\n    return cast<ScalableVectorType>(\n        VectorType::getExtendedElementVectorType(VTy));\n  }\n\n  static ScalableVectorType *\n  getTruncatedElementVectorType(ScalableVectorType *VTy) {\n    return cast<ScalableVectorType>(\n        VectorType::getTruncatedElementVectorType(VTy));\n  }\n\n  static ScalableVectorType *getSubdividedVectorType(ScalableVectorType *VTy,\n                                                     int NumSubdivs) {\n    return cast<ScalableVectorType>(\n        VectorType::getSubdividedVectorType(VTy, NumSubdivs));\n  }\n\n  static ScalableVectorType *\n  getHalfElementsVectorType(ScalableVectorType *VTy) {\n    return cast<ScalableVectorType>(VectorType::getHalfElementsVectorType(VTy));\n  }\n\n  static ScalableVectorType *\n  getDoubleElementsVectorType(ScalableVectorType *VTy) {\n    return cast<ScalableVectorType>(\n        VectorType::getDoubleElementsVectorType(VTy));\n  }\n\n  /// Get the minimum number of elements in this vector. The actual number of\n  /// elements in the vector is an integer multiple of this value.\n  uint64_t getMinNumElements() const { return ElementQuantity; }\n\n  static bool classof(const Type *T) {\n    return T->getTypeID() == ScalableVectorTyID;\n  }\n};\n\ninline ElementCount VectorType::getElementCount() const {\n  return ElementCount::get(ElementQuantity, isa<ScalableVectorType>(this));\n}\n\n/// Class to represent pointers.\nclass PointerType : public Type {\n  explicit PointerType(Type *ElType, unsigned AddrSpace);\n\n  Type *PointeeTy;\n\npublic:\n  PointerType(const PointerType &) = delete;\n  PointerType &operator=(const PointerType &) = delete;\n\n  /// This constructs a pointer to an object of the specified type in a numbered\n  /// address space.\n  static PointerType *get(Type *ElementType, unsigned AddressSpace);\n\n  /// This constructs a pointer to an object of the specified type in the\n  /// generic address space (address space zero).\n  static PointerType *getUnqual(Type *ElementType) {\n    return PointerType::get(ElementType, 0);\n  }\n\n  Type *getElementType() const { return PointeeTy; }\n\n  /// Return true if the specified type is valid as a element type.\n  static bool isValidElementType(Type *ElemTy);\n\n  /// Return true if we can load or store from a pointer to this type.\n  static bool isLoadableOrStorableType(Type *ElemTy);\n\n  /// Return the address space of the Pointer type.\n  inline unsigned getAddressSpace() const { return getSubclassData(); }\n\n  /// Implement support type inquiry through isa, cast, and dyn_cast.\n  static bool classof(const Type *T) {\n    return T->getTypeID() == PointerTyID;\n  }\n};\n\nType *Type::getExtendedType() const {\n  assert(\n      isIntOrIntVectorTy() &&\n      \"Original type expected to be a vector of integers or a scalar integer.\");\n  if (auto *VTy = dyn_cast<VectorType>(this))\n    return VectorType::getExtendedElementVectorType(\n        const_cast<VectorType *>(VTy));\n  return cast<IntegerType>(this)->getExtendedType();\n}\n\nType *Type::getWithNewBitWidth(unsigned NewBitWidth) const {\n  assert(\n      isIntOrIntVectorTy() &&\n      \"Original type expected to be a vector of integers or a scalar integer.\");\n  Type *NewType = getIntNTy(getContext(), NewBitWidth);\n  if (auto *VTy = dyn_cast<VectorType>(this))\n    NewType = VectorType::get(NewType, VTy->getElementCount());\n  return NewType;\n}\n\nunsigned Type::getPointerAddressSpace() const {\n  return cast<PointerType>(getScalarType())->getAddressSpace();\n}\n\n} // end namespace llvm\n\n#endif // LLVM_IR_DERIVEDTYPES_H\n"}, "41": {"id": 41, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "content": "//===- llvm/IR/DiagnosticInfo.h - Diagnostic Declaration --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file declares the different classes involved in low level diagnostics.\n//\n// Diagnostics reporting is still done as part of the LLVMContext.\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_DIAGNOSTICINFO_H\n#define LLVM_IR_DIAGNOSTICINFO_H\n\n#include \"llvm-c/Types.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/IR/DebugLoc.h\"\n#include \"llvm/Support/CBindingWrapping.h\"\n#include \"llvm/Support/TypeSize.h\"\n#include \"llvm/Support/YAMLTraits.h\"\n#include <algorithm>\n#include <cstdint>\n#include <functional>\n#include <iterator>\n#include <string>\n\nnamespace llvm {\n\n// Forward declarations.\nclass DiagnosticPrinter;\nclass Function;\nclass Instruction;\nclass InstructionCost;\nclass LLVMContext;\nclass Module;\nclass SMDiagnostic;\n\n/// Defines the different supported severity of a diagnostic.\nenum DiagnosticSeverity : char {\n  DS_Error,\n  DS_Warning,\n  DS_Remark,\n  // A note attaches additional information to one of the previous diagnostic\n  // types.\n  DS_Note\n};\n\n/// Defines the different supported kind of a diagnostic.\n/// This enum should be extended with a new ID for each added concrete subclass.\nenum DiagnosticKind {\n  DK_InlineAsm,\n  DK_ResourceLimit,\n  DK_StackSize,\n  DK_Linker,\n  DK_Lowering,\n  DK_DebugMetadataVersion,\n  DK_DebugMetadataInvalid,\n  DK_ISelFallback,\n  DK_SampleProfile,\n  DK_OptimizationRemark,\n  DK_OptimizationRemarkMissed,\n  DK_OptimizationRemarkAnalysis,\n  DK_OptimizationRemarkAnalysisFPCommute,\n  DK_OptimizationRemarkAnalysisAliasing,\n  DK_OptimizationFailure,\n  DK_FirstRemark = DK_OptimizationRemark,\n  DK_LastRemark = DK_OptimizationFailure,\n  DK_MachineOptimizationRemark,\n  DK_MachineOptimizationRemarkMissed,\n  DK_MachineOptimizationRemarkAnalysis,\n  DK_FirstMachineRemark = DK_MachineOptimizationRemark,\n  DK_LastMachineRemark = DK_MachineOptimizationRemarkAnalysis,\n  DK_MIRParser,\n  DK_PGOProfile,\n  DK_Unsupported,\n  DK_SrcMgr,\n  DK_FirstPluginKind // Must be last value to work with\n                     // getNextAvailablePluginDiagnosticKind\n};\n\n/// Get the next available kind ID for a plugin diagnostic.\n/// Each time this function is called, it returns a different number.\n/// Therefore, a plugin that wants to \"identify\" its own classes\n/// with a dynamic identifier, just have to use this method to get a new ID\n/// and assign it to each of its classes.\n/// The returned ID will be greater than or equal to DK_FirstPluginKind.\n/// Thus, the plugin identifiers will not conflict with the\n/// DiagnosticKind values.\nint getNextAvailablePluginDiagnosticKind();\n\n/// This is the base abstract class for diagnostic reporting in\n/// the backend.\n/// The print method must be overloaded by the subclasses to print a\n/// user-friendly message in the client of the backend (let us call it a\n/// frontend).\nclass DiagnosticInfo {\nprivate:\n  /// Kind defines the kind of report this is about.\n  const /* DiagnosticKind */ int Kind;\n  /// Severity gives the severity of the diagnostic.\n  const DiagnosticSeverity Severity;\n\n  virtual void anchor();\npublic:\n  DiagnosticInfo(/* DiagnosticKind */ int Kind, DiagnosticSeverity Severity)\n      : Kind(Kind), Severity(Severity) {}\n\n  virtual ~DiagnosticInfo() = default;\n\n  /* DiagnosticKind */ int getKind() const { return Kind; }\n  DiagnosticSeverity getSeverity() const { return Severity; }\n\n  /// Print using the given \\p DP a user-friendly message.\n  /// This is the default message that will be printed to the user.\n  /// It is used when the frontend does not directly take advantage\n  /// of the information contained in fields of the subclasses.\n  /// The printed message must not end with '.' nor start with a severity\n  /// keyword.\n  virtual void print(DiagnosticPrinter &DP) const = 0;\n};\n\nusing DiagnosticHandlerFunction = std::function<void(const DiagnosticInfo &)>;\n\n/// Diagnostic information for inline asm reporting.\n/// This is basically a message and an optional location.\nclass DiagnosticInfoInlineAsm : public DiagnosticInfo {\nprivate:\n  /// Optional line information. 0 if not set.\n  unsigned LocCookie = 0;\n  /// Message to be reported.\n  const Twine &MsgStr;\n  /// Optional origin of the problem.\n  const Instruction *Instr = nullptr;\n\npublic:\n  /// \\p MsgStr is the message to be reported to the frontend.\n  /// This class does not copy \\p MsgStr, therefore the reference must be valid\n  /// for the whole life time of the Diagnostic.\n  DiagnosticInfoInlineAsm(const Twine &MsgStr,\n                          DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfo(DK_InlineAsm, Severity), MsgStr(MsgStr) {}\n\n  /// \\p LocCookie if non-zero gives the line number for this report.\n  /// \\p MsgStr gives the message.\n  /// This class does not copy \\p MsgStr, therefore the reference must be valid\n  /// for the whole life time of the Diagnostic.\n  DiagnosticInfoInlineAsm(unsigned LocCookie, const Twine &MsgStr,\n                          DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfo(DK_InlineAsm, Severity), LocCookie(LocCookie),\n        MsgStr(MsgStr) {}\n\n  /// \\p Instr gives the original instruction that triggered the diagnostic.\n  /// \\p MsgStr gives the message.\n  /// This class does not copy \\p MsgStr, therefore the reference must be valid\n  /// for the whole life time of the Diagnostic.\n  /// Same for \\p I.\n  DiagnosticInfoInlineAsm(const Instruction &I, const Twine &MsgStr,\n                          DiagnosticSeverity Severity = DS_Error);\n\n  unsigned getLocCookie() const { return LocCookie; }\n  const Twine &getMsgStr() const { return MsgStr; }\n  const Instruction *getInstruction() const { return Instr; }\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_InlineAsm;\n  }\n};\n\n/// Diagnostic information for stack size etc. reporting.\n/// This is basically a function and a size.\nclass DiagnosticInfoResourceLimit : public DiagnosticInfo {\nprivate:\n  /// The function that is concerned by this resource limit diagnostic.\n  const Function &Fn;\n\n  /// Description of the resource type (e.g. stack size)\n  const char *ResourceName;\n\n  /// The computed size usage\n  uint64_t ResourceSize;\n\n  // Threshould passed\n  uint64_t ResourceLimit;\n\npublic:\n  /// \\p The function that is concerned by this stack size diagnostic.\n  /// \\p The computed stack size.\n  DiagnosticInfoResourceLimit(const Function &Fn, const char *ResourceName,\n                              uint64_t ResourceSize,\n                              DiagnosticSeverity Severity = DS_Warning,\n                              DiagnosticKind Kind = DK_ResourceLimit,\n                              uint64_t ResourceLimit = 0)\n      : DiagnosticInfo(Kind, Severity), Fn(Fn), ResourceName(ResourceName),\n        ResourceSize(ResourceSize), ResourceLimit(ResourceLimit) {}\n\n  const Function &getFunction() const { return Fn; }\n  const char *getResourceName() const { return ResourceName; }\n  uint64_t getResourceSize() const { return ResourceSize; }\n  uint64_t getResourceLimit() const { return ResourceLimit; }\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_ResourceLimit || DI->getKind() == DK_StackSize;\n  }\n};\n\nclass DiagnosticInfoStackSize : public DiagnosticInfoResourceLimit {\n  void anchor() override;\npublic:\n  DiagnosticInfoStackSize(const Function &Fn, uint64_t StackSize,\n                          DiagnosticSeverity Severity = DS_Warning,\n                          uint64_t StackLimit = 0)\n      : DiagnosticInfoResourceLimit(Fn, \"stack size\", StackSize, Severity,\n                                    DK_StackSize, StackLimit) {}\n\n  uint64_t getStackSize() const { return getResourceSize(); }\n  uint64_t getStackLimit() const { return getResourceLimit(); }\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_StackSize;\n  }\n};\n\n/// Diagnostic information for debug metadata version reporting.\n/// This is basically a module and a version.\nclass DiagnosticInfoDebugMetadataVersion : public DiagnosticInfo {\nprivate:\n  /// The module that is concerned by this debug metadata version diagnostic.\n  const Module &M;\n  /// The actual metadata version.\n  unsigned MetadataVersion;\n\npublic:\n  /// \\p The module that is concerned by this debug metadata version diagnostic.\n  /// \\p The actual metadata version.\n  DiagnosticInfoDebugMetadataVersion(const Module &M, unsigned MetadataVersion,\n                                     DiagnosticSeverity Severity = DS_Warning)\n      : DiagnosticInfo(DK_DebugMetadataVersion, Severity), M(M),\n        MetadataVersion(MetadataVersion) {}\n\n  const Module &getModule() const { return M; }\n  unsigned getMetadataVersion() const { return MetadataVersion; }\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_DebugMetadataVersion;\n  }\n};\n\n/// Diagnostic information for stripping invalid debug metadata.\nclass DiagnosticInfoIgnoringInvalidDebugMetadata : public DiagnosticInfo {\nprivate:\n  /// The module that is concerned by this debug metadata version diagnostic.\n  const Module &M;\n\npublic:\n  /// \\p The module that is concerned by this debug metadata version diagnostic.\n  DiagnosticInfoIgnoringInvalidDebugMetadata(\n      const Module &M, DiagnosticSeverity Severity = DS_Warning)\n      : DiagnosticInfo(DK_DebugMetadataVersion, Severity), M(M) {}\n\n  const Module &getModule() const { return M; }\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_DebugMetadataInvalid;\n  }\n};\n\n/// Diagnostic information for the sample profiler.\nclass DiagnosticInfoSampleProfile : public DiagnosticInfo {\npublic:\n  DiagnosticInfoSampleProfile(StringRef FileName, unsigned LineNum,\n                              const Twine &Msg,\n                              DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfo(DK_SampleProfile, Severity), FileName(FileName),\n        LineNum(LineNum), Msg(Msg) {}\n  DiagnosticInfoSampleProfile(StringRef FileName, const Twine &Msg,\n                              DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfo(DK_SampleProfile, Severity), FileName(FileName),\n        Msg(Msg) {}\n  DiagnosticInfoSampleProfile(const Twine &Msg,\n                              DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfo(DK_SampleProfile, Severity), Msg(Msg) {}\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_SampleProfile;\n  }\n\n  StringRef getFileName() const { return FileName; }\n  unsigned getLineNum() const { return LineNum; }\n  const Twine &getMsg() const { return Msg; }\n\nprivate:\n  /// Name of the input file associated with this diagnostic.\n  StringRef FileName;\n\n  /// Line number where the diagnostic occurred. If 0, no line number will\n  /// be emitted in the message.\n  unsigned LineNum = 0;\n\n  /// Message to report.\n  const Twine &Msg;\n};\n\n/// Diagnostic information for the PGO profiler.\nclass DiagnosticInfoPGOProfile : public DiagnosticInfo {\npublic:\n  DiagnosticInfoPGOProfile(const char *FileName, const Twine &Msg,\n                           DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfo(DK_PGOProfile, Severity), FileName(FileName), Msg(Msg) {}\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_PGOProfile;\n  }\n\n  const char *getFileName() const { return FileName; }\n  const Twine &getMsg() const { return Msg; }\n\nprivate:\n  /// Name of the input file associated with this diagnostic.\n  const char *FileName;\n\n  /// Message to report.\n  const Twine &Msg;\n};\n\nclass DiagnosticLocation {\n  DIFile *File = nullptr;\n  unsigned Line = 0;\n  unsigned Column = 0;\n\npublic:\n  DiagnosticLocation() = default;\n  DiagnosticLocation(const DebugLoc &DL);\n  DiagnosticLocation(const DISubprogram *SP);\n\n  bool isValid() const { return File; }\n  /// Return the full path to the file.\n  std::string getAbsolutePath() const;\n  /// Return the file name relative to the compilation directory.\n  StringRef getRelativePath() const;\n  unsigned getLine() const { return Line; }\n  unsigned getColumn() const { return Column; }\n};\n\n/// Common features for diagnostics with an associated location.\nclass DiagnosticInfoWithLocationBase : public DiagnosticInfo {\n  void anchor() override;\npublic:\n  /// \\p Fn is the function where the diagnostic is being emitted. \\p Loc is\n  /// the location information to use in the diagnostic.\n  DiagnosticInfoWithLocationBase(enum DiagnosticKind Kind,\n                                 enum DiagnosticSeverity Severity,\n                                 const Function &Fn,\n                                 const DiagnosticLocation &Loc)\n      : DiagnosticInfo(Kind, Severity), Fn(Fn), Loc(Loc) {}\n\n  /// Return true if location information is available for this diagnostic.\n  bool isLocationAvailable() const { return Loc.isValid(); }\n\n  /// Return a string with the location information for this diagnostic\n  /// in the format \"file:line:col\". If location information is not available,\n  /// it returns \"<unknown>:0:0\".\n  std::string getLocationStr() const;\n\n  /// Return location information for this diagnostic in three parts:\n  /// the relative source file path, line number and column.\n  void getLocation(StringRef &RelativePath, unsigned &Line,\n                   unsigned &Column) const;\n\n  /// Return the absolute path tot the file.\n  std::string getAbsolutePath() const;\n  \n  const Function &getFunction() const { return Fn; }\n  DiagnosticLocation getLocation() const { return Loc; }\n\nprivate:\n  /// Function where this diagnostic is triggered.\n  const Function &Fn;\n\n  /// Debug location where this diagnostic is triggered.\n  DiagnosticLocation Loc;\n};\n\n/// Common features for diagnostics dealing with optimization remarks\n/// that are used by both IR and MIR passes.\nclass DiagnosticInfoOptimizationBase : public DiagnosticInfoWithLocationBase {\npublic:\n  /// Used to set IsVerbose via the stream interface.\n  struct setIsVerbose {};\n\n  /// When an instance of this is inserted into the stream, the arguments\n  /// following will not appear in the remark printed in the compiler output\n  /// (-Rpass) but only in the optimization record file\n  /// (-fsave-optimization-record).\n  struct setExtraArgs {};\n\n  /// Used in the streaming interface as the general argument type.  It\n  /// internally converts everything into a key-value pair.\n  struct Argument {\n    std::string Key;\n    std::string Val;\n    // If set, the debug location corresponding to the value.\n    DiagnosticLocation Loc;\n\n    explicit Argument(StringRef Str = \"\") : Key(\"String\"), Val(Str) {}\n    Argument(StringRef Key, const Value *V);\n    Argument(StringRef Key, const Type *T);\n    Argument(StringRef Key, StringRef S);\n    Argument(StringRef Key, const char *S) : Argument(Key, StringRef(S)) {};\n    Argument(StringRef Key, int N);\n    Argument(StringRef Key, float N);\n    Argument(StringRef Key, long N);\n    Argument(StringRef Key, long long N);\n    Argument(StringRef Key, unsigned N);\n    Argument(StringRef Key, unsigned long N);\n    Argument(StringRef Key, unsigned long long N);\n    Argument(StringRef Key, ElementCount EC);\n    Argument(StringRef Key, bool B) : Key(Key), Val(B ? \"true\" : \"false\") {}\n    Argument(StringRef Key, DebugLoc dl);\n    Argument(StringRef Key, InstructionCost C);\n  };\n\n  /// \\p PassName is the name of the pass emitting this diagnostic. \\p\n  /// RemarkName is a textual identifier for the remark (single-word,\n  /// camel-case). \\p Fn is the function where the diagnostic is being emitted.\n  /// \\p Loc is the location information to use in the diagnostic. If line table\n  /// information is available, the diagnostic will include the source code\n  /// location.\n  DiagnosticInfoOptimizationBase(enum DiagnosticKind Kind,\n                                 enum DiagnosticSeverity Severity,\n                                 const char *PassName, StringRef RemarkName,\n                                 const Function &Fn,\n                                 const DiagnosticLocation &Loc)\n      : DiagnosticInfoWithLocationBase(Kind, Severity, Fn, Loc),\n        PassName(PassName), RemarkName(RemarkName) {}\n\n  void insert(StringRef S);\n  void insert(Argument A);\n  void insert(setIsVerbose V);\n  void insert(setExtraArgs EA);\n\n  /// \\see DiagnosticInfo::print.\n  void print(DiagnosticPrinter &DP) const override;\n\n  /// Return true if this optimization remark is enabled by one of\n  /// of the LLVM command line flags (-pass-remarks, -pass-remarks-missed,\n  /// or -pass-remarks-analysis). Note that this only handles the LLVM\n  /// flags. We cannot access Clang flags from here (they are handled\n  /// in BackendConsumer::OptimizationRemarkHandler).\n  virtual bool isEnabled() const = 0;\n\n  StringRef getPassName() const { return PassName; }\n  StringRef getRemarkName() const { return RemarkName; }\n  std::string getMsg() const;\n  Optional<uint64_t> getHotness() const { return Hotness; }\n  void setHotness(Optional<uint64_t> H) { Hotness = H; }\n\n  bool isVerbose() const { return IsVerbose; }\n\n  ArrayRef<Argument> getArgs() const { return Args; }\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return (DI->getKind() >= DK_FirstRemark &&\n            DI->getKind() <= DK_LastRemark) ||\n           (DI->getKind() >= DK_FirstMachineRemark &&\n            DI->getKind() <= DK_LastMachineRemark);\n  }\n\n  bool isPassed() const {\n    return (getKind() == DK_OptimizationRemark ||\n            getKind() == DK_MachineOptimizationRemark);\n  }\n\n  bool isMissed() const {\n    return (getKind() == DK_OptimizationRemarkMissed ||\n            getKind() == DK_MachineOptimizationRemarkMissed);\n  }\n\n  bool isAnalysis() const {\n    return (getKind() == DK_OptimizationRemarkAnalysis ||\n            getKind() == DK_MachineOptimizationRemarkAnalysis);\n  }\n\nprotected:\n  /// Name of the pass that triggers this report. If this matches the\n  /// regular expression given in -Rpass=regexp, then the remark will\n  /// be emitted.\n  const char *PassName;\n\n  /// Textual identifier for the remark (single-word, camel-case). Can be used\n  /// by external tools reading the output file for optimization remarks to\n  /// identify the remark.\n  StringRef RemarkName;\n\n  /// If profile information is available, this is the number of times the\n  /// corresponding code was executed in a profile instrumentation run.\n  Optional<uint64_t> Hotness;\n\n  /// Arguments collected via the streaming interface.\n  SmallVector<Argument, 4> Args;\n\n  /// The remark is expected to be noisy.\n  bool IsVerbose = false;\n\n  /// If positive, the index of the first argument that only appear in\n  /// the optimization records and not in the remark printed in the compiler\n  /// output.\n  int FirstExtraArgIndex = -1;\n};\n\n/// Allow the insertion operator to return the actual remark type rather than a\n/// common base class.  This allows returning the result of the insertion\n/// directly by value, e.g. return OptimizationRemarkAnalysis(...) << \"blah\".\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               StringRef>\n               S) {\n  R.insert(S);\n  return R;\n}\n\n/// Also allow r-value for the remark to allow insertion into a\n/// temporarily-constructed remark.\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &&R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               StringRef>\n               S) {\n  R.insert(S);\n  return R;\n}\n\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               DiagnosticInfoOptimizationBase::Argument>\n               A) {\n  R.insert(A);\n  return R;\n}\n\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &&R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               DiagnosticInfoOptimizationBase::Argument>\n               A) {\n  R.insert(A);\n  return R;\n}\n\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               DiagnosticInfoOptimizationBase::setIsVerbose>\n               V) {\n  R.insert(V);\n  return R;\n}\n\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &&R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               DiagnosticInfoOptimizationBase::setIsVerbose>\n               V) {\n  R.insert(V);\n  return R;\n}\n\ntemplate <class RemarkT>\nRemarkT &\noperator<<(RemarkT &R,\n           std::enable_if_t<\n               std::is_base_of<DiagnosticInfoOptimizationBase, RemarkT>::value,\n               DiagnosticInfoOptimizationBase::setExtraArgs>\n               EA) {\n  R.insert(EA);\n  return R;\n}\n\n/// Common features for diagnostics dealing with optimization remarks\n/// that are used by IR passes.\nclass DiagnosticInfoIROptimization : public DiagnosticInfoOptimizationBase {\n  void anchor() override;\npublic:\n  /// \\p PassName is the name of the pass emitting this diagnostic. \\p\n  /// RemarkName is a textual identifier for the remark (single-word,\n  /// camel-case). \\p Fn is the function where the diagnostic is being emitted.\n  /// \\p Loc is the location information to use in the diagnostic. If line table\n  /// information is available, the diagnostic will include the source code\n  /// location. \\p CodeRegion is IR value (currently basic block) that the\n  /// optimization operates on. This is currently used to provide run-time\n  /// hotness information with PGO.\n  DiagnosticInfoIROptimization(enum DiagnosticKind Kind,\n                               enum DiagnosticSeverity Severity,\n                               const char *PassName, StringRef RemarkName,\n                               const Function &Fn,\n                               const DiagnosticLocation &Loc,\n                               const Value *CodeRegion = nullptr)\n      : DiagnosticInfoOptimizationBase(Kind, Severity, PassName, RemarkName, Fn,\n                                       Loc),\n        CodeRegion(CodeRegion) {}\n\n  /// This is ctor variant allows a pass to build an optimization remark\n  /// from an existing remark.\n  ///\n  /// This is useful when a transformation pass (e.g LV) wants to emit a remark\n  /// (\\p Orig) generated by one of its analyses (e.g. LAA) as its own analysis\n  /// remark.  The string \\p Prepend will be emitted before the original\n  /// message.\n  DiagnosticInfoIROptimization(const char *PassName, StringRef Prepend,\n                               const DiagnosticInfoIROptimization &Orig)\n      : DiagnosticInfoOptimizationBase(\n            (DiagnosticKind)Orig.getKind(), Orig.getSeverity(), PassName,\n            Orig.RemarkName, Orig.getFunction(), Orig.getLocation()),\n        CodeRegion(Orig.getCodeRegion()) {\n    *this << Prepend;\n    std::copy(Orig.Args.begin(), Orig.Args.end(), std::back_inserter(Args));\n  }\n\n  /// Legacy interface.\n  /// \\p PassName is the name of the pass emitting this diagnostic.\n  /// \\p Fn is the function where the diagnostic is being emitted. \\p Loc is\n  /// the location information to use in the diagnostic. If line table\n  /// information is available, the diagnostic will include the source code\n  /// location. \\p Msg is the message to show. Note that this class does not\n  /// copy this message, so this reference must be valid for the whole life time\n  /// of the diagnostic.\n  DiagnosticInfoIROptimization(enum DiagnosticKind Kind,\n                               enum DiagnosticSeverity Severity,\n                               const char *PassName, const Function &Fn,\n                               const DiagnosticLocation &Loc, const Twine &Msg)\n      : DiagnosticInfoOptimizationBase(Kind, Severity, PassName, \"\", Fn, Loc) {\n    *this << Msg.str();\n  }\n\n  const Value *getCodeRegion() const { return CodeRegion; }\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() >= DK_FirstRemark && DI->getKind() <= DK_LastRemark;\n  }\n\nprivate:\n  /// The IR value (currently basic block) that the optimization operates on.\n  /// This is currently used to provide run-time hotness information with PGO.\n  const Value *CodeRegion = nullptr;\n};\n\n/// Diagnostic information for applied optimization remarks.\nclass OptimizationRemark : public DiagnosticInfoIROptimization {\npublic:\n  /// \\p PassName is the name of the pass emitting this diagnostic. If this name\n  /// matches the regular expression given in -Rpass=, then the diagnostic will\n  /// be emitted. \\p RemarkName is a textual identifier for the remark (single-\n  /// word, camel-case). \\p Loc is the debug location and \\p CodeRegion is the\n  /// region that the optimization operates on (currently only block is\n  /// supported).\n  OptimizationRemark(const char *PassName, StringRef RemarkName,\n                     const DiagnosticLocation &Loc, const Value *CodeRegion);\n\n  /// Same as above, but the debug location and code region are derived from \\p\n  /// Instr.\n  OptimizationRemark(const char *PassName, StringRef RemarkName,\n                     const Instruction *Inst);\n\n  /// Same as above, but the debug location and code region are derived from \\p\n  /// Func.\n  OptimizationRemark(const char *PassName, StringRef RemarkName,\n                     const Function *Func);\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_OptimizationRemark;\n  }\n\n  /// \\see DiagnosticInfoOptimizationBase::isEnabled.\n  bool isEnabled() const override;\n\nprivate:\n  /// This is deprecated now and only used by the function API below.\n  /// \\p PassName is the name of the pass emitting this diagnostic. If\n  /// this name matches the regular expression given in -Rpass=, then the\n  /// diagnostic will be emitted. \\p Fn is the function where the diagnostic\n  /// is being emitted. \\p Loc is the location information to use in the\n  /// diagnostic. If line table information is available, the diagnostic\n  /// will include the source code location. \\p Msg is the message to show.\n  /// Note that this class does not copy this message, so this reference\n  /// must be valid for the whole life time of the diagnostic.\n  OptimizationRemark(const char *PassName, const Function &Fn,\n                     const DiagnosticLocation &Loc, const Twine &Msg)\n      : DiagnosticInfoIROptimization(DK_OptimizationRemark, DS_Remark, PassName,\n                                     Fn, Loc, Msg) {}\n};\n\n/// Diagnostic information for missed-optimization remarks.\nclass OptimizationRemarkMissed : public DiagnosticInfoIROptimization {\npublic:\n  /// \\p PassName is the name of the pass emitting this diagnostic. If this name\n  /// matches the regular expression given in -Rpass-missed=, then the\n  /// diagnostic will be emitted. \\p RemarkName is a textual identifier for the\n  /// remark (single-word, camel-case). \\p Loc is the debug location and \\p\n  /// CodeRegion is the region that the optimization operates on (currently only\n  /// block is supported).\n  OptimizationRemarkMissed(const char *PassName, StringRef RemarkName,\n                           const DiagnosticLocation &Loc,\n                           const Value *CodeRegion);\n\n  /// Same as above but \\p Inst is used to derive code region and debug\n  /// location.\n  OptimizationRemarkMissed(const char *PassName, StringRef RemarkName,\n                           const Instruction *Inst);\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_OptimizationRemarkMissed;\n  }\n\n  /// \\see DiagnosticInfoOptimizationBase::isEnabled.\n  bool isEnabled() const override;\n\nprivate:\n  /// This is deprecated now and only used by the function API below.\n  /// \\p PassName is the name of the pass emitting this diagnostic. If\n  /// this name matches the regular expression given in -Rpass-missed=, then the\n  /// diagnostic will be emitted. \\p Fn is the function where the diagnostic\n  /// is being emitted. \\p Loc is the location information to use in the\n  /// diagnostic. If line table information is available, the diagnostic\n  /// will include the source code location. \\p Msg is the message to show.\n  /// Note that this class does not copy this message, so this reference\n  /// must be valid for the whole life time of the diagnostic.\n  OptimizationRemarkMissed(const char *PassName, const Function &Fn,\n                           const DiagnosticLocation &Loc, const Twine &Msg)\n      : DiagnosticInfoIROptimization(DK_OptimizationRemarkMissed, DS_Remark,\n                                     PassName, Fn, Loc, Msg) {}\n};\n\n/// Diagnostic information for optimization analysis remarks.\nclass OptimizationRemarkAnalysis : public DiagnosticInfoIROptimization {\npublic:\n  /// \\p PassName is the name of the pass emitting this diagnostic. If this name\n  /// matches the regular expression given in -Rpass-analysis=, then the\n  /// diagnostic will be emitted. \\p RemarkName is a textual identifier for the\n  /// remark (single-word, camel-case). \\p Loc is the debug location and \\p\n  /// CodeRegion is the region that the optimization operates on (currently only\n  /// block is supported).\n  OptimizationRemarkAnalysis(const char *PassName, StringRef RemarkName,\n                             const DiagnosticLocation &Loc,\n                             const Value *CodeRegion);\n\n  /// This is ctor variant allows a pass to build an optimization remark\n  /// from an existing remark.\n  ///\n  /// This is useful when a transformation pass (e.g LV) wants to emit a remark\n  /// (\\p Orig) generated by one of its analyses (e.g. LAA) as its own analysis\n  /// remark.  The string \\p Prepend will be emitted before the original\n  /// message.\n  OptimizationRemarkAnalysis(const char *PassName, StringRef Prepend,\n                             const OptimizationRemarkAnalysis &Orig)\n      : DiagnosticInfoIROptimization(PassName, Prepend, Orig) {}\n\n  /// Same as above but \\p Inst is used to derive code region and debug\n  /// location.\n  OptimizationRemarkAnalysis(const char *PassName, StringRef RemarkName,\n                             const Instruction *Inst);\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_OptimizationRemarkAnalysis;\n  }\n\n  /// \\see DiagnosticInfoOptimizationBase::isEnabled.\n  bool isEnabled() const override;\n\n  static const char *AlwaysPrint;\n\n  bool shouldAlwaysPrint() const { return getPassName() == AlwaysPrint; }\n\nprotected:\n  OptimizationRemarkAnalysis(enum DiagnosticKind Kind, const char *PassName,\n                             const Function &Fn, const DiagnosticLocation &Loc,\n                             const Twine &Msg)\n      : DiagnosticInfoIROptimization(Kind, DS_Remark, PassName, Fn, Loc, Msg) {}\n\n  OptimizationRemarkAnalysis(enum DiagnosticKind Kind, const char *PassName,\n                             StringRef RemarkName,\n                             const DiagnosticLocation &Loc,\n                             const Value *CodeRegion);\n\nprivate:\n  /// This is deprecated now and only used by the function API below.\n  /// \\p PassName is the name of the pass emitting this diagnostic. If\n  /// this name matches the regular expression given in -Rpass-analysis=, then\n  /// the diagnostic will be emitted. \\p Fn is the function where the diagnostic\n  /// is being emitted. \\p Loc is the location information to use in the\n  /// diagnostic. If line table information is available, the diagnostic will\n  /// include the source code location. \\p Msg is the message to show. Note that\n  /// this class does not copy this message, so this reference must be valid for\n  /// the whole life time of the diagnostic.\n  OptimizationRemarkAnalysis(const char *PassName, const Function &Fn,\n                             const DiagnosticLocation &Loc, const Twine &Msg)\n      : DiagnosticInfoIROptimization(DK_OptimizationRemarkAnalysis, DS_Remark,\n                                     PassName, Fn, Loc, Msg) {}\n};\n\n/// Diagnostic information for optimization analysis remarks related to\n/// floating-point non-commutativity.\nclass OptimizationRemarkAnalysisFPCommute : public OptimizationRemarkAnalysis {\n  void anchor() override;\npublic:\n  /// \\p PassName is the name of the pass emitting this diagnostic. If this name\n  /// matches the regular expression given in -Rpass-analysis=, then the\n  /// diagnostic will be emitted. \\p RemarkName is a textual identifier for the\n  /// remark (single-word, camel-case). \\p Loc is the debug location and \\p\n  /// CodeRegion is the region that the optimization operates on (currently only\n  /// block is supported). The front-end will append its own message related to\n  /// options that address floating-point non-commutativity.\n  OptimizationRemarkAnalysisFPCommute(const char *PassName,\n                                      StringRef RemarkName,\n                                      const DiagnosticLocation &Loc,\n                                      const Value *CodeRegion)\n      : OptimizationRemarkAnalysis(DK_OptimizationRemarkAnalysisFPCommute,\n                                   PassName, RemarkName, Loc, CodeRegion) {}\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_OptimizationRemarkAnalysisFPCommute;\n  }\n\nprivate:\n  /// This is deprecated now and only used by the function API below.\n  /// \\p PassName is the name of the pass emitting this diagnostic. If\n  /// this name matches the regular expression given in -Rpass-analysis=, then\n  /// the diagnostic will be emitted. \\p Fn is the function where the diagnostic\n  /// is being emitted. \\p Loc is the location information to use in the\n  /// diagnostic. If line table information is available, the diagnostic will\n  /// include the source code location. \\p Msg is the message to show. The\n  /// front-end will append its own message related to options that address\n  /// floating-point non-commutativity. Note that this class does not copy this\n  /// message, so this reference must be valid for the whole life time of the\n  /// diagnostic.\n  OptimizationRemarkAnalysisFPCommute(const char *PassName, const Function &Fn,\n                                      const DiagnosticLocation &Loc,\n                                      const Twine &Msg)\n      : OptimizationRemarkAnalysis(DK_OptimizationRemarkAnalysisFPCommute,\n                                   PassName, Fn, Loc, Msg) {}\n};\n\n/// Diagnostic information for optimization analysis remarks related to\n/// pointer aliasing.\nclass OptimizationRemarkAnalysisAliasing : public OptimizationRemarkAnalysis {\n  void anchor() override;\npublic:\n  /// \\p PassName is the name of the pass emitting this diagnostic. If this name\n  /// matches the regular expression given in -Rpass-analysis=, then the\n  /// diagnostic will be emitted. \\p RemarkName is a textual identifier for the\n  /// remark (single-word, camel-case). \\p Loc is the debug location and \\p\n  /// CodeRegion is the region that the optimization operates on (currently only\n  /// block is supported). The front-end will append its own message related to\n  /// options that address pointer aliasing legality.\n  OptimizationRemarkAnalysisAliasing(const char *PassName, StringRef RemarkName,\n                                     const DiagnosticLocation &Loc,\n                                     const Value *CodeRegion)\n      : OptimizationRemarkAnalysis(DK_OptimizationRemarkAnalysisAliasing,\n                                   PassName, RemarkName, Loc, CodeRegion) {}\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_OptimizationRemarkAnalysisAliasing;\n  }\n\nprivate:\n  /// This is deprecated now and only used by the function API below.\n  /// \\p PassName is the name of the pass emitting this diagnostic. If\n  /// this name matches the regular expression given in -Rpass-analysis=, then\n  /// the diagnostic will be emitted. \\p Fn is the function where the diagnostic\n  /// is being emitted. \\p Loc is the location information to use in the\n  /// diagnostic. If line table information is available, the diagnostic will\n  /// include the source code location. \\p Msg is the message to show. The\n  /// front-end will append its own message related to options that address\n  /// pointer aliasing legality. Note that this class does not copy this\n  /// message, so this reference must be valid for the whole life time of the\n  /// diagnostic.\n  OptimizationRemarkAnalysisAliasing(const char *PassName, const Function &Fn,\n                                     const DiagnosticLocation &Loc,\n                                     const Twine &Msg)\n      : OptimizationRemarkAnalysis(DK_OptimizationRemarkAnalysisAliasing,\n                                   PassName, Fn, Loc, Msg) {}\n};\n\n/// Diagnostic information for machine IR parser.\n// FIXME: Remove this, use DiagnosticInfoSrcMgr instead.\nclass DiagnosticInfoMIRParser : public DiagnosticInfo {\n  const SMDiagnostic &Diagnostic;\n\npublic:\n  DiagnosticInfoMIRParser(DiagnosticSeverity Severity,\n                          const SMDiagnostic &Diagnostic)\n      : DiagnosticInfo(DK_MIRParser, Severity), Diagnostic(Diagnostic) {}\n\n  const SMDiagnostic &getDiagnostic() const { return Diagnostic; }\n\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_MIRParser;\n  }\n};\n\n/// Diagnostic information for ISel fallback path.\nclass DiagnosticInfoISelFallback : public DiagnosticInfo {\n  /// The function that is concerned by this diagnostic.\n  const Function &Fn;\n\npublic:\n  DiagnosticInfoISelFallback(const Function &Fn,\n                             DiagnosticSeverity Severity = DS_Warning)\n      : DiagnosticInfo(DK_ISelFallback, Severity), Fn(Fn) {}\n\n  const Function &getFunction() const { return Fn; }\n\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_ISelFallback;\n  }\n};\n\n// Create wrappers for C Binding types (see CBindingWrapping.h).\nDEFINE_SIMPLE_CONVERSION_FUNCTIONS(DiagnosticInfo, LLVMDiagnosticInfoRef)\n\n/// Diagnostic information for optimization failures.\nclass DiagnosticInfoOptimizationFailure : public DiagnosticInfoIROptimization {\npublic:\n  /// \\p Fn is the function where the diagnostic is being emitted. \\p Loc is\n  /// the location information to use in the diagnostic. If line table\n  /// information is available, the diagnostic will include the source code\n  /// location. \\p Msg is the message to show. Note that this class does not\n  /// copy this message, so this reference must be valid for the whole life time\n  /// of the diagnostic.\n  DiagnosticInfoOptimizationFailure(const Function &Fn,\n                                    const DiagnosticLocation &Loc,\n                                    const Twine &Msg)\n      : DiagnosticInfoIROptimization(DK_OptimizationFailure, DS_Warning,\n                                     nullptr, Fn, Loc, Msg) {}\n\n  /// \\p PassName is the name of the pass emitting this diagnostic.  \\p\n  /// RemarkName is a textual identifier for the remark (single-word,\n  /// camel-case).  \\p Loc is the debug location and \\p CodeRegion is the\n  /// region that the optimization operates on (currently basic block is\n  /// supported).\n  DiagnosticInfoOptimizationFailure(const char *PassName, StringRef RemarkName,\n                                    const DiagnosticLocation &Loc,\n                                    const Value *CodeRegion);\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_OptimizationFailure;\n  }\n\n  /// \\see DiagnosticInfoOptimizationBase::isEnabled.\n  bool isEnabled() const override;\n};\n\n/// Diagnostic information for unsupported feature in backend.\nclass DiagnosticInfoUnsupported : public DiagnosticInfoWithLocationBase {\nprivate:\n  Twine Msg;\n\npublic:\n  /// \\p Fn is the function where the diagnostic is being emitted. \\p Loc is\n  /// the location information to use in the diagnostic. If line table\n  /// information is available, the diagnostic will include the source code\n  /// location. \\p Msg is the message to show. Note that this class does not\n  /// copy this message, so this reference must be valid for the whole life time\n  /// of the diagnostic.\n  DiagnosticInfoUnsupported(\n      const Function &Fn, const Twine &Msg,\n      const DiagnosticLocation &Loc = DiagnosticLocation(),\n      DiagnosticSeverity Severity = DS_Error)\n      : DiagnosticInfoWithLocationBase(DK_Unsupported, Severity, Fn, Loc),\n        Msg(Msg) {}\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_Unsupported;\n  }\n\n  const Twine &getMessage() const { return Msg; }\n\n  void print(DiagnosticPrinter &DP) const override;\n};\n\nstatic DiagnosticSeverity getDiagnosticSeverity(SourceMgr::DiagKind DK) {\n  switch (DK) {\n  case llvm::SourceMgr::DK_Error:\n    return DS_Error;\n    break;\n  case llvm::SourceMgr::DK_Warning:\n    return DS_Warning;\n    break;\n  case llvm::SourceMgr::DK_Note:\n    return DS_Note;\n    break;\n  case llvm::SourceMgr::DK_Remark:\n    return DS_Remark;\n    break;\n  }\n  llvm_unreachable(\"unknown SourceMgr::DiagKind\");\n}\n\n/// Diagnostic information for SMDiagnostic reporting.\nclass DiagnosticInfoSrcMgr : public DiagnosticInfo {\n  const SMDiagnostic &Diagnostic;\n\n  // For inlineasm !srcloc translation.\n  bool InlineAsmDiag;\n  unsigned LocCookie;\n\npublic:\n  DiagnosticInfoSrcMgr(const SMDiagnostic &Diagnostic,\n                       bool InlineAsmDiag = true, unsigned LocCookie = 0)\n      : DiagnosticInfo(DK_SrcMgr, getDiagnosticSeverity(Diagnostic.getKind())),\n        Diagnostic(Diagnostic), InlineAsmDiag(InlineAsmDiag),\n        LocCookie(LocCookie) {}\n\n  bool isInlineAsmDiag() const { return InlineAsmDiag; }\n  const SMDiagnostic &getSMDiag() const { return Diagnostic; }\n  unsigned getLocCookie() const { return LocCookie; }\n  void print(DiagnosticPrinter &DP) const override;\n\n  static bool classof(const DiagnosticInfo *DI) {\n    return DI->getKind() == DK_SrcMgr;\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_IR_DIAGNOSTICINFO_H\n"}, "42": {"id": 42, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Dominators.h", "content": "//===- Dominators.h - Dominator Info Calculation ----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the DominatorTree class, which provides fast and efficient\n// dominance queries.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_DOMINATORS_H\n#define LLVM_IR_DOMINATORS_H\n\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/DepthFirstIterator.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/Hashing.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/GenericDomTree.h\"\n#include <utility>\n\nnamespace llvm {\n\nclass Function;\nclass Instruction;\nclass Module;\nclass raw_ostream;\n\nextern template class DomTreeNodeBase<BasicBlock>;\nextern template class DominatorTreeBase<BasicBlock, false>; // DomTree\nextern template class DominatorTreeBase<BasicBlock, true>; // PostDomTree\n\nextern template class cfg::Update<BasicBlock *>;\n\nnamespace DomTreeBuilder {\nusing BBDomTree = DomTreeBase<BasicBlock>;\nusing BBPostDomTree = PostDomTreeBase<BasicBlock>;\n\nusing BBUpdates = ArrayRef<llvm::cfg::Update<BasicBlock *>>;\n\nusing BBDomTreeGraphDiff = GraphDiff<BasicBlock *, false>;\nusing BBPostDomTreeGraphDiff = GraphDiff<BasicBlock *, true>;\n\nextern template void Calculate<BBDomTree>(BBDomTree &DT);\nextern template void CalculateWithUpdates<BBDomTree>(BBDomTree &DT,\n                                                     BBUpdates U);\n\nextern template void Calculate<BBPostDomTree>(BBPostDomTree &DT);\n\nextern template void InsertEdge<BBDomTree>(BBDomTree &DT, BasicBlock *From,\n                                           BasicBlock *To);\nextern template void InsertEdge<BBPostDomTree>(BBPostDomTree &DT,\n                                               BasicBlock *From,\n                                               BasicBlock *To);\n\nextern template void DeleteEdge<BBDomTree>(BBDomTree &DT, BasicBlock *From,\n                                           BasicBlock *To);\nextern template void DeleteEdge<BBPostDomTree>(BBPostDomTree &DT,\n                                               BasicBlock *From,\n                                               BasicBlock *To);\n\nextern template void ApplyUpdates<BBDomTree>(BBDomTree &DT,\n                                             BBDomTreeGraphDiff &,\n                                             BBDomTreeGraphDiff *);\nextern template void ApplyUpdates<BBPostDomTree>(BBPostDomTree &DT,\n                                                 BBPostDomTreeGraphDiff &,\n                                                 BBPostDomTreeGraphDiff *);\n\nextern template bool Verify<BBDomTree>(const BBDomTree &DT,\n                                       BBDomTree::VerificationLevel VL);\nextern template bool Verify<BBPostDomTree>(const BBPostDomTree &DT,\n                                           BBPostDomTree::VerificationLevel VL);\n}  // namespace DomTreeBuilder\n\nusing DomTreeNode = DomTreeNodeBase<BasicBlock>;\n\nclass BasicBlockEdge {\n  const BasicBlock *Start;\n  const BasicBlock *End;\n\npublic:\n  BasicBlockEdge(const BasicBlock *Start_, const BasicBlock *End_) :\n    Start(Start_), End(End_) {}\n\n  BasicBlockEdge(const std::pair<BasicBlock *, BasicBlock *> &Pair)\n      : Start(Pair.first), End(Pair.second) {}\n\n  BasicBlockEdge(const std::pair<const BasicBlock *, const BasicBlock *> &Pair)\n      : Start(Pair.first), End(Pair.second) {}\n\n  const BasicBlock *getStart() const {\n    return Start;\n  }\n\n  const BasicBlock *getEnd() const {\n    return End;\n  }\n\n  /// Check if this is the only edge between Start and End.\n  bool isSingleEdge() const;\n};\n\ntemplate <> struct DenseMapInfo<BasicBlockEdge> {\n  using BBInfo = DenseMapInfo<const BasicBlock *>;\n\n  static unsigned getHashValue(const BasicBlockEdge *V);\n\n  static inline BasicBlockEdge getEmptyKey() {\n    return BasicBlockEdge(BBInfo::getEmptyKey(), BBInfo::getEmptyKey());\n  }\n\n  static inline BasicBlockEdge getTombstoneKey() {\n    return BasicBlockEdge(BBInfo::getTombstoneKey(), BBInfo::getTombstoneKey());\n  }\n\n  static unsigned getHashValue(const BasicBlockEdge &Edge) {\n    return hash_combine(BBInfo::getHashValue(Edge.getStart()),\n                        BBInfo::getHashValue(Edge.getEnd()));\n  }\n\n  static bool isEqual(const BasicBlockEdge &LHS, const BasicBlockEdge &RHS) {\n    return BBInfo::isEqual(LHS.getStart(), RHS.getStart()) &&\n           BBInfo::isEqual(LHS.getEnd(), RHS.getEnd());\n  }\n};\n\n/// Concrete subclass of DominatorTreeBase that is used to compute a\n/// normal dominator tree.\n///\n/// Definition: A block is said to be forward statically reachable if there is\n/// a path from the entry of the function to the block.  A statically reachable\n/// block may become statically unreachable during optimization.\n///\n/// A forward unreachable block may appear in the dominator tree, or it may\n/// not.  If it does, dominance queries will return results as if all reachable\n/// blocks dominate it.  When asking for a Node corresponding to a potentially\n/// unreachable block, calling code must handle the case where the block was\n/// unreachable and the result of getNode() is nullptr.\n///\n/// Generally, a block known to be unreachable when the dominator tree is\n/// constructed will not be in the tree.  One which becomes unreachable after\n/// the dominator tree is initially constructed may still exist in the tree,\n/// even if the tree is properly updated. Calling code should not rely on the\n/// preceding statements; this is stated only to assist human understanding.\nclass DominatorTree : public DominatorTreeBase<BasicBlock, false> {\n public:\n  using Base = DominatorTreeBase<BasicBlock, false>;\n\n  DominatorTree() = default;\n  explicit DominatorTree(Function &F) { recalculate(F); }\n  explicit DominatorTree(DominatorTree &DT, DomTreeBuilder::BBUpdates U) {\n    recalculate(*DT.Parent, U);\n  }\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // Ensure base-class overloads are visible.\n  using Base::dominates;\n\n  /// Return true if the (end of the) basic block BB dominates the use U.\n  bool dominates(const BasicBlock *BB, const Use &U) const;\n\n  /// Return true if value Def dominates use U, in the sense that Def is\n  /// available at U, and could be substituted as the used value without\n  /// violating the SSA dominance requirement.\n  ///\n  /// In particular, it is worth noting that:\n  ///  * Non-instruction Defs dominate everything.\n  ///  * Def does not dominate a use in Def itself (outside of degenerate cases\n  ///    like unreachable code or trivial phi cycles).\n  ///  * Invoke/callbr Defs only dominate uses in their default destination.\n  bool dominates(const Value *Def, const Use &U) const;\n  /// Return true if value Def dominates all possible uses inside instruction\n  /// User. Same comments as for the Use-based API apply.\n  bool dominates(const Value *Def, const Instruction *User) const;\n  // Does not accept Value to avoid ambiguity with dominance checks between\n  // two basic blocks.\n  bool dominates(const Instruction *Def, const BasicBlock *BB) const;\n\n  /// Return true if an edge dominates a use.\n  ///\n  /// If BBE is not a unique edge between start and end of the edge, it can\n  /// never dominate the use.\n  bool dominates(const BasicBlockEdge &BBE, const Use &U) const;\n  bool dominates(const BasicBlockEdge &BBE, const BasicBlock *BB) const;\n  /// Returns true if edge \\p BBE1 dominates edge \\p BBE2.\n  bool dominates(const BasicBlockEdge &BBE1, const BasicBlockEdge &BBE2) const;\n\n  // Ensure base class overloads are visible.\n  using Base::isReachableFromEntry;\n\n  /// Provide an overload for a Use.\n  bool isReachableFromEntry(const Use &U) const;\n\n  // Pop up a GraphViz/gv window with the Dominator Tree rendered using `dot`.\n  void viewGraph(const Twine &Name, const Twine &Title);\n  void viewGraph();\n};\n\n//===-------------------------------------\n// DominatorTree GraphTraits specializations so the DominatorTree can be\n// iterable by generic graph iterators.\n\ntemplate <class Node, class ChildIterator> struct DomTreeGraphTraitsBase {\n  using NodeRef = Node *;\n  using ChildIteratorType = ChildIterator;\n  using nodes_iterator = df_iterator<Node *, df_iterator_default_set<Node*>>;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->end(); }\n\n  static nodes_iterator nodes_begin(NodeRef N) {\n    return df_begin(getEntryNode(N));\n  }\n\n  static nodes_iterator nodes_end(NodeRef N) { return df_end(getEntryNode(N)); }\n};\n\ntemplate <>\nstruct GraphTraits<DomTreeNode *>\n    : public DomTreeGraphTraitsBase<DomTreeNode, DomTreeNode::const_iterator> {\n};\n\ntemplate <>\nstruct GraphTraits<const DomTreeNode *>\n    : public DomTreeGraphTraitsBase<const DomTreeNode,\n                                    DomTreeNode::const_iterator> {};\n\ntemplate <> struct GraphTraits<DominatorTree*>\n  : public GraphTraits<DomTreeNode*> {\n  static NodeRef getEntryNode(DominatorTree *DT) { return DT->getRootNode(); }\n\n  static nodes_iterator nodes_begin(DominatorTree *N) {\n    return df_begin(getEntryNode(N));\n  }\n\n  static nodes_iterator nodes_end(DominatorTree *N) {\n    return df_end(getEntryNode(N));\n  }\n};\n\n/// Analysis pass which computes a \\c DominatorTree.\nclass DominatorTreeAnalysis : public AnalysisInfoMixin<DominatorTreeAnalysis> {\n  friend AnalysisInfoMixin<DominatorTreeAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result typedef for this analysis pass.\n  using Result = DominatorTree;\n\n  /// Run the analysis pass over a function and produce a dominator tree.\n  DominatorTree run(Function &F, FunctionAnalysisManager &);\n};\n\n/// Printer pass for the \\c DominatorTree.\nclass DominatorTreePrinterPass\n    : public PassInfoMixin<DominatorTreePrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit DominatorTreePrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c DominatorTree.\nstruct DominatorTreeVerifierPass : PassInfoMixin<DominatorTreeVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy analysis pass which computes a \\c DominatorTree.\nclass DominatorTreeWrapperPass : public FunctionPass {\n  DominatorTree DT;\n\npublic:\n  static char ID;\n\n  DominatorTreeWrapperPass();\n\n  DominatorTree &getDomTree() { return DT; }\n  const DominatorTree &getDomTree() const { return DT; }\n\n  bool runOnFunction(Function &F) override;\n\n  void verifyAnalysis() const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override {\n    AU.setPreservesAll();\n  }\n\n  void releaseMemory() override { DT.reset(); }\n\n  void print(raw_ostream &OS, const Module *M = nullptr) const override;\n};\n} // end namespace llvm\n\n#endif // LLVM_IR_DOMINATORS_H\n"}, "43": {"id": 43, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/InstrTypes.h", "content": "//===- llvm/InstrTypes.h - Important Instruction subclasses -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines various meta classes of instructions that exist in the VM\n// representation.  Specific concrete subclasses of these may be found in the\n// i*.h files...\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_INSTRTYPES_H\n#define LLVM_IR_INSTRTYPES_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/StringMap.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/IR/Attributes.h\"\n#include \"llvm/IR/CallingConv.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/LLVMContext.h\"\n#include \"llvm/IR/OperandTraits.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/IR/User.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <iterator>\n#include <string>\n#include <vector>\n\nnamespace llvm {\n\nnamespace Intrinsic {\ntypedef unsigned ID;\n}\n\n//===----------------------------------------------------------------------===//\n//                          UnaryInstruction Class\n//===----------------------------------------------------------------------===//\n\nclass UnaryInstruction : public Instruction {\nprotected:\n  UnaryInstruction(Type *Ty, unsigned iType, Value *V,\n                   Instruction *IB = nullptr)\n    : Instruction(Ty, iType, &Op<0>(), 1, IB) {\n    Op<0>() = V;\n  }\n  UnaryInstruction(Type *Ty, unsigned iType, Value *V, BasicBlock *IAE)\n    : Instruction(Ty, iType, &Op<0>(), 1, IAE) {\n    Op<0>() = V;\n  }\n\npublic:\n  // allocate space for exactly one operand\n  void *operator new(size_t s) {\n    return User::operator new(s, 1);\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->isUnaryOp() ||\n           I->getOpcode() == Instruction::Alloca ||\n           I->getOpcode() == Instruction::Load ||\n           I->getOpcode() == Instruction::VAArg ||\n           I->getOpcode() == Instruction::ExtractValue ||\n           (I->getOpcode() >= CastOpsBegin && I->getOpcode() < CastOpsEnd);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<UnaryInstruction> :\n  public FixedNumOperandTraits<UnaryInstruction, 1> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(UnaryInstruction, Value)\n\n//===----------------------------------------------------------------------===//\n//                                UnaryOperator Class\n//===----------------------------------------------------------------------===//\n\nclass UnaryOperator : public UnaryInstruction {\n  void AssertOK();\n\nprotected:\n  UnaryOperator(UnaryOps iType, Value *S, Type *Ty,\n                const Twine &Name, Instruction *InsertBefore);\n  UnaryOperator(UnaryOps iType, Value *S, Type *Ty,\n                const Twine &Name, BasicBlock *InsertAtEnd);\n\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  UnaryOperator *cloneImpl() const;\n\npublic:\n\n  /// Construct a unary instruction, given the opcode and an operand.\n  /// Optionally (if InstBefore is specified) insert the instruction\n  /// into a BasicBlock right before the specified instruction.  The specified\n  /// Instruction is allowed to be a dereferenced end iterator.\n  ///\n  static UnaryOperator *Create(UnaryOps Op, Value *S,\n                               const Twine &Name = Twine(),\n                               Instruction *InsertBefore = nullptr);\n\n  /// Construct a unary instruction, given the opcode and an operand.\n  /// Also automatically insert this instruction to the end of the\n  /// BasicBlock specified.\n  ///\n  static UnaryOperator *Create(UnaryOps Op, Value *S,\n                               const Twine &Name,\n                               BasicBlock *InsertAtEnd);\n\n  /// These methods just forward to Create, and are useful when you\n  /// statically know what type of instruction you're going to create.  These\n  /// helpers just save some typing.\n#define HANDLE_UNARY_INST(N, OPC, CLASS) \\\n  static UnaryOperator *Create##OPC(Value *V, const Twine &Name = \"\") {\\\n    return Create(Instruction::OPC, V, Name);\\\n  }\n#include \"llvm/IR/Instruction.def\"\n#define HANDLE_UNARY_INST(N, OPC, CLASS) \\\n  static UnaryOperator *Create##OPC(Value *V, const Twine &Name, \\\n                                    BasicBlock *BB) {\\\n    return Create(Instruction::OPC, V, Name, BB);\\\n  }\n#include \"llvm/IR/Instruction.def\"\n#define HANDLE_UNARY_INST(N, OPC, CLASS) \\\n  static UnaryOperator *Create##OPC(Value *V, const Twine &Name, \\\n                                    Instruction *I) {\\\n    return Create(Instruction::OPC, V, Name, I);\\\n  }\n#include \"llvm/IR/Instruction.def\"\n\n  static UnaryOperator *\n  CreateWithCopiedFlags(UnaryOps Opc, Value *V, Instruction *CopyO,\n                        const Twine &Name = \"\",\n                        Instruction *InsertBefore = nullptr) {\n    UnaryOperator *UO = Create(Opc, V, Name, InsertBefore);\n    UO->copyIRFlags(CopyO);\n    return UO;\n  }\n\n  static UnaryOperator *CreateFNegFMF(Value *Op, Instruction *FMFSource,\n                                      const Twine &Name = \"\",\n                                      Instruction *InsertBefore = nullptr) {\n    return CreateWithCopiedFlags(Instruction::FNeg, Op, FMFSource, Name,\n                                 InsertBefore);\n  }\n\n  UnaryOps getOpcode() const {\n    return static_cast<UnaryOps>(Instruction::getOpcode());\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->isUnaryOp();\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                           BinaryOperator Class\n//===----------------------------------------------------------------------===//\n\nclass BinaryOperator : public Instruction {\n  void AssertOK();\n\nprotected:\n  BinaryOperator(BinaryOps iType, Value *S1, Value *S2, Type *Ty,\n                 const Twine &Name, Instruction *InsertBefore);\n  BinaryOperator(BinaryOps iType, Value *S1, Value *S2, Type *Ty,\n                 const Twine &Name, BasicBlock *InsertAtEnd);\n\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  BinaryOperator *cloneImpl() const;\n\npublic:\n  // allocate space for exactly two operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 2);\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Construct a binary instruction, given the opcode and the two\n  /// operands.  Optionally (if InstBefore is specified) insert the instruction\n  /// into a BasicBlock right before the specified instruction.  The specified\n  /// Instruction is allowed to be a dereferenced end iterator.\n  ///\n  static BinaryOperator *Create(BinaryOps Op, Value *S1, Value *S2,\n                                const Twine &Name = Twine(),\n                                Instruction *InsertBefore = nullptr);\n\n  /// Construct a binary instruction, given the opcode and the two\n  /// operands.  Also automatically insert this instruction to the end of the\n  /// BasicBlock specified.\n  ///\n  static BinaryOperator *Create(BinaryOps Op, Value *S1, Value *S2,\n                                const Twine &Name, BasicBlock *InsertAtEnd);\n\n  /// These methods just forward to Create, and are useful when you\n  /// statically know what type of instruction you're going to create.  These\n  /// helpers just save some typing.\n#define HANDLE_BINARY_INST(N, OPC, CLASS) \\\n  static BinaryOperator *Create##OPC(Value *V1, Value *V2, \\\n                                     const Twine &Name = \"\") {\\\n    return Create(Instruction::OPC, V1, V2, Name);\\\n  }\n#include \"llvm/IR/Instruction.def\"\n#define HANDLE_BINARY_INST(N, OPC, CLASS) \\\n  static BinaryOperator *Create##OPC(Value *V1, Value *V2, \\\n                                     const Twine &Name, BasicBlock *BB) {\\\n    return Create(Instruction::OPC, V1, V2, Name, BB);\\\n  }\n#include \"llvm/IR/Instruction.def\"\n#define HANDLE_BINARY_INST(N, OPC, CLASS) \\\n  static BinaryOperator *Create##OPC(Value *V1, Value *V2, \\\n                                     const Twine &Name, Instruction *I) {\\\n    return Create(Instruction::OPC, V1, V2, Name, I);\\\n  }\n#include \"llvm/IR/Instruction.def\"\n\n  static BinaryOperator *CreateWithCopiedFlags(BinaryOps Opc,\n                                               Value *V1, Value *V2,\n                                               Instruction *CopyO,\n                                               const Twine &Name = \"\") {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name);\n    BO->copyIRFlags(CopyO);\n    return BO;\n  }\n\n  static BinaryOperator *CreateFAddFMF(Value *V1, Value *V2,\n                                       Instruction *FMFSource,\n                                       const Twine &Name = \"\") {\n    return CreateWithCopiedFlags(Instruction::FAdd, V1, V2, FMFSource, Name);\n  }\n  static BinaryOperator *CreateFSubFMF(Value *V1, Value *V2,\n                                       Instruction *FMFSource,\n                                       const Twine &Name = \"\") {\n    return CreateWithCopiedFlags(Instruction::FSub, V1, V2, FMFSource, Name);\n  }\n  static BinaryOperator *CreateFMulFMF(Value *V1, Value *V2,\n                                       Instruction *FMFSource,\n                                       const Twine &Name = \"\") {\n    return CreateWithCopiedFlags(Instruction::FMul, V1, V2, FMFSource, Name);\n  }\n  static BinaryOperator *CreateFDivFMF(Value *V1, Value *V2,\n                                       Instruction *FMFSource,\n                                       const Twine &Name = \"\") {\n    return CreateWithCopiedFlags(Instruction::FDiv, V1, V2, FMFSource, Name);\n  }\n  static BinaryOperator *CreateFRemFMF(Value *V1, Value *V2,\n                                       Instruction *FMFSource,\n                                       const Twine &Name = \"\") {\n    return CreateWithCopiedFlags(Instruction::FRem, V1, V2, FMFSource, Name);\n  }\n\n  static BinaryOperator *CreateNSW(BinaryOps Opc, Value *V1, Value *V2,\n                                   const Twine &Name = \"\") {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name);\n    BO->setHasNoSignedWrap(true);\n    return BO;\n  }\n  static BinaryOperator *CreateNSW(BinaryOps Opc, Value *V1, Value *V2,\n                                   const Twine &Name, BasicBlock *BB) {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name, BB);\n    BO->setHasNoSignedWrap(true);\n    return BO;\n  }\n  static BinaryOperator *CreateNSW(BinaryOps Opc, Value *V1, Value *V2,\n                                   const Twine &Name, Instruction *I) {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name, I);\n    BO->setHasNoSignedWrap(true);\n    return BO;\n  }\n\n  static BinaryOperator *CreateNUW(BinaryOps Opc, Value *V1, Value *V2,\n                                   const Twine &Name = \"\") {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name);\n    BO->setHasNoUnsignedWrap(true);\n    return BO;\n  }\n  static BinaryOperator *CreateNUW(BinaryOps Opc, Value *V1, Value *V2,\n                                   const Twine &Name, BasicBlock *BB) {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name, BB);\n    BO->setHasNoUnsignedWrap(true);\n    return BO;\n  }\n  static BinaryOperator *CreateNUW(BinaryOps Opc, Value *V1, Value *V2,\n                                   const Twine &Name, Instruction *I) {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name, I);\n    BO->setHasNoUnsignedWrap(true);\n    return BO;\n  }\n\n  static BinaryOperator *CreateExact(BinaryOps Opc, Value *V1, Value *V2,\n                                     const Twine &Name = \"\") {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name);\n    BO->setIsExact(true);\n    return BO;\n  }\n  static BinaryOperator *CreateExact(BinaryOps Opc, Value *V1, Value *V2,\n                                     const Twine &Name, BasicBlock *BB) {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name, BB);\n    BO->setIsExact(true);\n    return BO;\n  }\n  static BinaryOperator *CreateExact(BinaryOps Opc, Value *V1, Value *V2,\n                                     const Twine &Name, Instruction *I) {\n    BinaryOperator *BO = Create(Opc, V1, V2, Name, I);\n    BO->setIsExact(true);\n    return BO;\n  }\n\n#define DEFINE_HELPERS(OPC, NUWNSWEXACT)                                       \\\n  static BinaryOperator *Create##NUWNSWEXACT##OPC(Value *V1, Value *V2,        \\\n                                                  const Twine &Name = \"\") {    \\\n    return Create##NUWNSWEXACT(Instruction::OPC, V1, V2, Name);                \\\n  }                                                                            \\\n  static BinaryOperator *Create##NUWNSWEXACT##OPC(                             \\\n      Value *V1, Value *V2, const Twine &Name, BasicBlock *BB) {               \\\n    return Create##NUWNSWEXACT(Instruction::OPC, V1, V2, Name, BB);            \\\n  }                                                                            \\\n  static BinaryOperator *Create##NUWNSWEXACT##OPC(                             \\\n      Value *V1, Value *V2, const Twine &Name, Instruction *I) {               \\\n    return Create##NUWNSWEXACT(Instruction::OPC, V1, V2, Name, I);             \\\n  }\n\n  DEFINE_HELPERS(Add, NSW) // CreateNSWAdd\n  DEFINE_HELPERS(Add, NUW) // CreateNUWAdd\n  DEFINE_HELPERS(Sub, NSW) // CreateNSWSub\n  DEFINE_HELPERS(Sub, NUW) // CreateNUWSub\n  DEFINE_HELPERS(Mul, NSW) // CreateNSWMul\n  DEFINE_HELPERS(Mul, NUW) // CreateNUWMul\n  DEFINE_HELPERS(Shl, NSW) // CreateNSWShl\n  DEFINE_HELPERS(Shl, NUW) // CreateNUWShl\n\n  DEFINE_HELPERS(SDiv, Exact)  // CreateExactSDiv\n  DEFINE_HELPERS(UDiv, Exact)  // CreateExactUDiv\n  DEFINE_HELPERS(AShr, Exact)  // CreateExactAShr\n  DEFINE_HELPERS(LShr, Exact)  // CreateExactLShr\n\n#undef DEFINE_HELPERS\n\n  /// Helper functions to construct and inspect unary operations (NEG and NOT)\n  /// via binary operators SUB and XOR:\n  ///\n  /// Create the NEG and NOT instructions out of SUB and XOR instructions.\n  ///\n  static BinaryOperator *CreateNeg(Value *Op, const Twine &Name = \"\",\n                                   Instruction *InsertBefore = nullptr);\n  static BinaryOperator *CreateNeg(Value *Op, const Twine &Name,\n                                   BasicBlock *InsertAtEnd);\n  static BinaryOperator *CreateNSWNeg(Value *Op, const Twine &Name = \"\",\n                                      Instruction *InsertBefore = nullptr);\n  static BinaryOperator *CreateNSWNeg(Value *Op, const Twine &Name,\n                                      BasicBlock *InsertAtEnd);\n  static BinaryOperator *CreateNUWNeg(Value *Op, const Twine &Name = \"\",\n                                      Instruction *InsertBefore = nullptr);\n  static BinaryOperator *CreateNUWNeg(Value *Op, const Twine &Name,\n                                      BasicBlock *InsertAtEnd);\n  static BinaryOperator *CreateNot(Value *Op, const Twine &Name = \"\",\n                                   Instruction *InsertBefore = nullptr);\n  static BinaryOperator *CreateNot(Value *Op, const Twine &Name,\n                                   BasicBlock *InsertAtEnd);\n\n  BinaryOps getOpcode() const {\n    return static_cast<BinaryOps>(Instruction::getOpcode());\n  }\n\n  /// Exchange the two operands to this instruction.\n  /// This instruction is safe to use on any binary instruction and\n  /// does not modify the semantics of the instruction.  If the instruction\n  /// cannot be reversed (ie, it's a Div), then return true.\n  ///\n  bool swapOperands();\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->isBinaryOp();\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<BinaryOperator> :\n  public FixedNumOperandTraits<BinaryOperator, 2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(BinaryOperator, Value)\n\n//===----------------------------------------------------------------------===//\n//                               CastInst Class\n//===----------------------------------------------------------------------===//\n\n/// This is the base class for all instructions that perform data\n/// casts. It is simply provided so that instruction category testing\n/// can be performed with code like:\n///\n/// if (isa<CastInst>(Instr)) { ... }\n/// Base class of casting instructions.\nclass CastInst : public UnaryInstruction {\nprotected:\n  /// Constructor with insert-before-instruction semantics for subclasses\n  CastInst(Type *Ty, unsigned iType, Value *S,\n           const Twine &NameStr = \"\", Instruction *InsertBefore = nullptr)\n    : UnaryInstruction(Ty, iType, S, InsertBefore) {\n    setName(NameStr);\n  }\n  /// Constructor with insert-at-end-of-block semantics for subclasses\n  CastInst(Type *Ty, unsigned iType, Value *S,\n           const Twine &NameStr, BasicBlock *InsertAtEnd)\n    : UnaryInstruction(Ty, iType, S, InsertAtEnd) {\n    setName(NameStr);\n  }\n\npublic:\n  /// Provides a way to construct any of the CastInst subclasses using an\n  /// opcode instead of the subclass's constructor. The opcode must be in the\n  /// CastOps category (Instruction::isCast(opcode) returns true). This\n  /// constructor has insert-before-instruction semantics to automatically\n  /// insert the new CastInst before InsertBefore (if it is non-null).\n  /// Construct any of the CastInst subclasses\n  static CastInst *Create(\n    Instruction::CastOps,    ///< The opcode of the cast instruction\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n  /// Provides a way to construct any of the CastInst subclasses using an\n  /// opcode instead of the subclass's constructor. The opcode must be in the\n  /// CastOps category. This constructor has insert-at-end-of-block semantics\n  /// to automatically insert the new CastInst at the end of InsertAtEnd (if\n  /// its non-null).\n  /// Construct any of the CastInst subclasses\n  static CastInst *Create(\n    Instruction::CastOps,    ///< The opcode for the cast instruction\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which operand is casted\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create a ZExt or BitCast cast instruction\n  static CastInst *CreateZExtOrBitCast(\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a ZExt or BitCast cast instruction\n  static CastInst *CreateZExtOrBitCast(\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which operand is casted\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create a SExt or BitCast cast instruction\n  static CastInst *CreateSExtOrBitCast(\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a SExt or BitCast cast instruction\n  static CastInst *CreateSExtOrBitCast(\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which operand is casted\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create a BitCast AddrSpaceCast, or a PtrToInt cast instruction.\n  static CastInst *CreatePointerCast(\n    Value *S,                ///< The pointer value to be casted (operand 0)\n    Type *Ty,          ///< The type to which operand is casted\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create a BitCast, AddrSpaceCast or a PtrToInt cast instruction.\n  static CastInst *CreatePointerCast(\n    Value *S,                ///< The pointer value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a BitCast or an AddrSpaceCast cast instruction.\n  static CastInst *CreatePointerBitCastOrAddrSpaceCast(\n    Value *S,                ///< The pointer value to be casted (operand 0)\n    Type *Ty,          ///< The type to which operand is casted\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create a BitCast or an AddrSpaceCast cast instruction.\n  static CastInst *CreatePointerBitCastOrAddrSpaceCast(\n    Value *S,                ///< The pointer value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a BitCast, a PtrToInt, or an IntToPTr cast instruction.\n  ///\n  /// If the value is a pointer type and the destination an integer type,\n  /// creates a PtrToInt cast. If the value is an integer type and the\n  /// destination a pointer type, creates an IntToPtr cast. Otherwise, creates\n  /// a bitcast.\n  static CastInst *CreateBitOrPointerCast(\n    Value *S,                ///< The pointer value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a ZExt, BitCast, or Trunc for int -> int casts.\n  static CastInst *CreateIntegerCast(\n    Value *S,                ///< The pointer value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    bool isSigned,           ///< Whether to regard S as signed or not\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a ZExt, BitCast, or Trunc for int -> int casts.\n  static CastInst *CreateIntegerCast(\n    Value *S,                ///< The integer value to be casted (operand 0)\n    Type *Ty,          ///< The integer type to which operand is casted\n    bool isSigned,           ///< Whether to regard S as signed or not\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create an FPExt, BitCast, or FPTrunc for fp -> fp casts\n  static CastInst *CreateFPCast(\n    Value *S,                ///< The floating point value to be casted\n    Type *Ty,          ///< The floating point type to cast to\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create an FPExt, BitCast, or FPTrunc for fp -> fp casts\n  static CastInst *CreateFPCast(\n    Value *S,                ///< The floating point value to be casted\n    Type *Ty,          ///< The floating point type to cast to\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Create a Trunc or BitCast cast instruction\n  static CastInst *CreateTruncOrBitCast(\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which cast should be made\n    const Twine &Name = \"\", ///< Name for the instruction\n    Instruction *InsertBefore = nullptr ///< Place to insert the instruction\n  );\n\n  /// Create a Trunc or BitCast cast instruction\n  static CastInst *CreateTruncOrBitCast(\n    Value *S,                ///< The value to be casted (operand 0)\n    Type *Ty,          ///< The type to which operand is casted\n    const Twine &Name, ///< The name for the instruction\n    BasicBlock *InsertAtEnd  ///< The block to insert the instruction into\n  );\n\n  /// Check whether a bitcast between these types is valid\n  static bool isBitCastable(\n    Type *SrcTy, ///< The Type from which the value should be cast.\n    Type *DestTy ///< The Type to which the value should be cast.\n  );\n\n  /// Check whether a bitcast, inttoptr, or ptrtoint cast between these\n  /// types is valid and a no-op.\n  ///\n  /// This ensures that any pointer<->integer cast has enough bits in the\n  /// integer and any other cast is a bitcast.\n  static bool isBitOrNoopPointerCastable(\n      Type *SrcTy,  ///< The Type from which the value should be cast.\n      Type *DestTy, ///< The Type to which the value should be cast.\n      const DataLayout &DL);\n\n  /// Returns the opcode necessary to cast Val into Ty using usual casting\n  /// rules.\n  /// Infer the opcode for cast operand and type\n  static Instruction::CastOps getCastOpcode(\n    const Value *Val, ///< The value to cast\n    bool SrcIsSigned, ///< Whether to treat the source as signed\n    Type *Ty,   ///< The Type to which the value should be casted\n    bool DstIsSigned  ///< Whether to treate the dest. as signed\n  );\n\n  /// There are several places where we need to know if a cast instruction\n  /// only deals with integer source and destination types. To simplify that\n  /// logic, this method is provided.\n  /// @returns true iff the cast has only integral typed operand and dest type.\n  /// Determine if this is an integer-only cast.\n  bool isIntegerCast() const;\n\n  /// A lossless cast is one that does not alter the basic value. It implies\n  /// a no-op cast but is more stringent, preventing things like int->float,\n  /// long->double, or int->ptr.\n  /// @returns true iff the cast is lossless.\n  /// Determine if this is a lossless cast.\n  bool isLosslessCast() const;\n\n  /// A no-op cast is one that can be effected without changing any bits.\n  /// It implies that the source and destination types are the same size. The\n  /// DataLayout argument is to determine the pointer size when examining casts\n  /// involving Integer and Pointer types. They are no-op casts if the integer\n  /// is the same size as the pointer. However, pointer size varies with\n  /// platform.  Note that a precondition of this method is that the cast is\n  /// legal - i.e. the instruction formed with these operands would verify.\n  static bool isNoopCast(\n    Instruction::CastOps Opcode, ///< Opcode of cast\n    Type *SrcTy,         ///< SrcTy of cast\n    Type *DstTy,         ///< DstTy of cast\n    const DataLayout &DL ///< DataLayout to get the Int Ptr type from.\n  );\n\n  /// Determine if this cast is a no-op cast.\n  ///\n  /// \\param DL is the DataLayout to determine pointer size.\n  bool isNoopCast(const DataLayout &DL) const;\n\n  /// Determine how a pair of casts can be eliminated, if they can be at all.\n  /// This is a helper function for both CastInst and ConstantExpr.\n  /// @returns 0 if the CastInst pair can't be eliminated, otherwise\n  /// returns Instruction::CastOps value for a cast that can replace\n  /// the pair, casting SrcTy to DstTy.\n  /// Determine if a cast pair is eliminable\n  static unsigned isEliminableCastPair(\n    Instruction::CastOps firstOpcode,  ///< Opcode of first cast\n    Instruction::CastOps secondOpcode, ///< Opcode of second cast\n    Type *SrcTy, ///< SrcTy of 1st cast\n    Type *MidTy, ///< DstTy of 1st cast & SrcTy of 2nd cast\n    Type *DstTy, ///< DstTy of 2nd cast\n    Type *SrcIntPtrTy, ///< Integer type corresponding to Ptr SrcTy, or null\n    Type *MidIntPtrTy, ///< Integer type corresponding to Ptr MidTy, or null\n    Type *DstIntPtrTy  ///< Integer type corresponding to Ptr DstTy, or null\n  );\n\n  /// Return the opcode of this CastInst\n  Instruction::CastOps getOpcode() const {\n    return Instruction::CastOps(Instruction::getOpcode());\n  }\n\n  /// Return the source type, as a convenience\n  Type* getSrcTy() const { return getOperand(0)->getType(); }\n  /// Return the destination type, as a convenience\n  Type* getDestTy() const { return getType(); }\n\n  /// This method can be used to determine if a cast from SrcTy to DstTy using\n  /// Opcode op is valid or not.\n  /// @returns true iff the proposed cast is valid.\n  /// Determine if a cast is valid without creating one.\n  static bool castIsValid(Instruction::CastOps op, Type *SrcTy, Type *DstTy);\n  static bool castIsValid(Instruction::CastOps op, Value *S, Type *DstTy) {\n    return castIsValid(op, S->getType(), DstTy);\n  }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->isCast();\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                               CmpInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class is the base class for the comparison instructions.\n/// Abstract base class of comparison instructions.\nclass CmpInst : public Instruction {\npublic:\n  /// This enumeration lists the possible predicates for CmpInst subclasses.\n  /// Values in the range 0-31 are reserved for FCmpInst, while values in the\n  /// range 32-64 are reserved for ICmpInst. This is necessary to ensure the\n  /// predicate values are not overlapping between the classes.\n  ///\n  /// Some passes (e.g. InstCombine) depend on the bit-wise characteristics of\n  /// FCMP_* values. Changing the bit patterns requires a potential change to\n  /// those passes.\n  enum Predicate : unsigned {\n    // Opcode            U L G E    Intuitive operation\n    FCMP_FALSE = 0, ///< 0 0 0 0    Always false (always folded)\n    FCMP_OEQ = 1,   ///< 0 0 0 1    True if ordered and equal\n    FCMP_OGT = 2,   ///< 0 0 1 0    True if ordered and greater than\n    FCMP_OGE = 3,   ///< 0 0 1 1    True if ordered and greater than or equal\n    FCMP_OLT = 4,   ///< 0 1 0 0    True if ordered and less than\n    FCMP_OLE = 5,   ///< 0 1 0 1    True if ordered and less than or equal\n    FCMP_ONE = 6,   ///< 0 1 1 0    True if ordered and operands are unequal\n    FCMP_ORD = 7,   ///< 0 1 1 1    True if ordered (no nans)\n    FCMP_UNO = 8,   ///< 1 0 0 0    True if unordered: isnan(X) | isnan(Y)\n    FCMP_UEQ = 9,   ///< 1 0 0 1    True if unordered or equal\n    FCMP_UGT = 10,  ///< 1 0 1 0    True if unordered or greater than\n    FCMP_UGE = 11,  ///< 1 0 1 1    True if unordered, greater than, or equal\n    FCMP_ULT = 12,  ///< 1 1 0 0    True if unordered or less than\n    FCMP_ULE = 13,  ///< 1 1 0 1    True if unordered, less than, or equal\n    FCMP_UNE = 14,  ///< 1 1 1 0    True if unordered or not equal\n    FCMP_TRUE = 15, ///< 1 1 1 1    Always true (always folded)\n    FIRST_FCMP_PREDICATE = FCMP_FALSE,\n    LAST_FCMP_PREDICATE = FCMP_TRUE,\n    BAD_FCMP_PREDICATE = FCMP_TRUE + 1,\n    ICMP_EQ = 32,  ///< equal\n    ICMP_NE = 33,  ///< not equal\n    ICMP_UGT = 34, ///< unsigned greater than\n    ICMP_UGE = 35, ///< unsigned greater or equal\n    ICMP_ULT = 36, ///< unsigned less than\n    ICMP_ULE = 37, ///< unsigned less or equal\n    ICMP_SGT = 38, ///< signed greater than\n    ICMP_SGE = 39, ///< signed greater or equal\n    ICMP_SLT = 40, ///< signed less than\n    ICMP_SLE = 41, ///< signed less or equal\n    FIRST_ICMP_PREDICATE = ICMP_EQ,\n    LAST_ICMP_PREDICATE = ICMP_SLE,\n    BAD_ICMP_PREDICATE = ICMP_SLE + 1\n  };\n  using PredicateField =\n      Bitfield::Element<Predicate, 0, 6, LAST_ICMP_PREDICATE>;\n\nprotected:\n  CmpInst(Type *ty, Instruction::OtherOps op, Predicate pred,\n          Value *LHS, Value *RHS, const Twine &Name = \"\",\n          Instruction *InsertBefore = nullptr,\n          Instruction *FlagsSource = nullptr);\n\n  CmpInst(Type *ty, Instruction::OtherOps op, Predicate pred,\n          Value *LHS, Value *RHS, const Twine &Name,\n          BasicBlock *InsertAtEnd);\n\npublic:\n  // allocate space for exactly two operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 2);\n  }\n\n  /// Construct a compare instruction, given the opcode, the predicate and\n  /// the two operands.  Optionally (if InstBefore is specified) insert the\n  /// instruction into a BasicBlock right before the specified instruction.\n  /// The specified Instruction is allowed to be a dereferenced end iterator.\n  /// Create a CmpInst\n  static CmpInst *Create(OtherOps Op,\n                         Predicate predicate, Value *S1,\n                         Value *S2, const Twine &Name = \"\",\n                         Instruction *InsertBefore = nullptr);\n\n  /// Construct a compare instruction, given the opcode, the predicate and the\n  /// two operands.  Also automatically insert this instruction to the end of\n  /// the BasicBlock specified.\n  /// Create a CmpInst\n  static CmpInst *Create(OtherOps Op, Predicate predicate, Value *S1,\n                         Value *S2, const Twine &Name, BasicBlock *InsertAtEnd);\n\n  /// Get the opcode casted to the right type\n  OtherOps getOpcode() const {\n    return static_cast<OtherOps>(Instruction::getOpcode());\n  }\n\n  /// Return the predicate for this instruction.\n  Predicate getPredicate() const { return getSubclassData<PredicateField>(); }\n\n  /// Set the predicate for this instruction to the specified value.\n  void setPredicate(Predicate P) { setSubclassData<PredicateField>(P); }\n\n  static bool isFPPredicate(Predicate P) {\n    static_assert(FIRST_FCMP_PREDICATE == 0,\n                  \"FIRST_FCMP_PREDICATE is required to be 0\");\n    return P <= LAST_FCMP_PREDICATE;\n  }\n\n  static bool isIntPredicate(Predicate P) {\n    return P >= FIRST_ICMP_PREDICATE && P <= LAST_ICMP_PREDICATE;\n  }\n\n  static StringRef getPredicateName(Predicate P);\n\n  bool isFPPredicate() const { return isFPPredicate(getPredicate()); }\n  bool isIntPredicate() const { return isIntPredicate(getPredicate()); }\n\n  /// For example, EQ -> NE, UGT -> ULE, SLT -> SGE,\n  ///              OEQ -> UNE, UGT -> OLE, OLT -> UGE, etc.\n  /// @returns the inverse predicate for the instruction's current predicate.\n  /// Return the inverse of the instruction's predicate.\n  Predicate getInversePredicate() const {\n    return getInversePredicate(getPredicate());\n  }\n\n  /// For example, EQ -> NE, UGT -> ULE, SLT -> SGE,\n  ///              OEQ -> UNE, UGT -> OLE, OLT -> UGE, etc.\n  /// @returns the inverse predicate for predicate provided in \\p pred.\n  /// Return the inverse of a given predicate\n  static Predicate getInversePredicate(Predicate pred);\n\n  /// For example, EQ->EQ, SLE->SGE, ULT->UGT,\n  ///              OEQ->OEQ, ULE->UGE, OLT->OGT, etc.\n  /// @returns the predicate that would be the result of exchanging the two\n  /// operands of the CmpInst instruction without changing the result\n  /// produced.\n  /// Return the predicate as if the operands were swapped\n  Predicate getSwappedPredicate() const {\n    return getSwappedPredicate(getPredicate());\n  }\n\n  /// This is a static version that you can use without an instruction\n  /// available.\n  /// Return the predicate as if the operands were swapped.\n  static Predicate getSwappedPredicate(Predicate pred);\n\n  /// This is a static version that you can use without an instruction\n  /// available.\n  /// @returns true if the comparison predicate is strict, false otherwise.\n  static bool isStrictPredicate(Predicate predicate);\n\n  /// @returns true if the comparison predicate is strict, false otherwise.\n  /// Determine if this instruction is using an strict comparison predicate.\n  bool isStrictPredicate() const { return isStrictPredicate(getPredicate()); }\n\n  /// This is a static version that you can use without an instruction\n  /// available.\n  /// @returns true if the comparison predicate is non-strict, false otherwise.\n  static bool isNonStrictPredicate(Predicate predicate);\n\n  /// @returns true if the comparison predicate is non-strict, false otherwise.\n  /// Determine if this instruction is using an non-strict comparison predicate.\n  bool isNonStrictPredicate() const {\n    return isNonStrictPredicate(getPredicate());\n  }\n\n  /// For example, SGE -> SGT, SLE -> SLT, ULE -> ULT, UGE -> UGT.\n  /// Returns the strict version of non-strict comparisons.\n  Predicate getStrictPredicate() const {\n    return getStrictPredicate(getPredicate());\n  }\n\n  /// This is a static version that you can use without an instruction\n  /// available.\n  /// @returns the strict version of comparison provided in \\p pred.\n  /// If \\p pred is not a strict comparison predicate, returns \\p pred.\n  /// Returns the strict version of non-strict comparisons.\n  static Predicate getStrictPredicate(Predicate pred);\n\n  /// For example, SGT -> SGE, SLT -> SLE, ULT -> ULE, UGT -> UGE.\n  /// Returns the non-strict version of strict comparisons.\n  Predicate getNonStrictPredicate() const {\n    return getNonStrictPredicate(getPredicate());\n  }\n\n  /// This is a static version that you can use without an instruction\n  /// available.\n  /// @returns the non-strict version of comparison provided in \\p pred.\n  /// If \\p pred is not a strict comparison predicate, returns \\p pred.\n  /// Returns the non-strict version of strict comparisons.\n  static Predicate getNonStrictPredicate(Predicate pred);\n\n  /// This is a static version that you can use without an instruction\n  /// available.\n  /// Return the flipped strictness of predicate\n  static Predicate getFlippedStrictnessPredicate(Predicate pred);\n\n  /// For predicate of kind \"is X or equal to 0\" returns the predicate \"is X\".\n  /// For predicate of kind \"is X\" returns the predicate \"is X or equal to 0\".\n  /// does not support other kind of predicates.\n  /// @returns the predicate that does not contains is equal to zero if\n  /// it had and vice versa.\n  /// Return the flipped strictness of predicate\n  Predicate getFlippedStrictnessPredicate() const {\n    return getFlippedStrictnessPredicate(getPredicate());\n  }\n\n  /// Provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// This is just a convenience that dispatches to the subclasses.\n  /// Swap the operands and adjust predicate accordingly to retain\n  /// the same comparison.\n  void swapOperands();\n\n  /// This is just a convenience that dispatches to the subclasses.\n  /// Determine if this CmpInst is commutative.\n  bool isCommutative() const;\n\n  /// Determine if this is an equals/not equals predicate.\n  /// This is a static version that you can use without an instruction\n  /// available.\n  static bool isEquality(Predicate pred);\n\n  /// Determine if this is an equals/not equals predicate.\n  bool isEquality() const { return isEquality(getPredicate()); }\n\n  /// Return true if the predicate is relational (not EQ or NE).\n  static bool isRelational(Predicate P) { return !isEquality(P); }\n\n  /// Return true if the predicate is relational (not EQ or NE).\n  bool isRelational() const { return !isEquality(); }\n\n  /// @returns true if the comparison is signed, false otherwise.\n  /// Determine if this instruction is using a signed comparison.\n  bool isSigned() const {\n    return isSigned(getPredicate());\n  }\n\n  /// @returns true if the comparison is unsigned, false otherwise.\n  /// Determine if this instruction is using an unsigned comparison.\n  bool isUnsigned() const {\n    return isUnsigned(getPredicate());\n  }\n\n  /// For example, ULT->SLT, ULE->SLE, UGT->SGT, UGE->SGE, SLT->Failed assert\n  /// @returns the signed version of the unsigned predicate pred.\n  /// return the signed version of a predicate\n  static Predicate getSignedPredicate(Predicate pred);\n\n  /// For example, ULT->SLT, ULE->SLE, UGT->SGT, UGE->SGE, SLT->Failed assert\n  /// @returns the signed version of the predicate for this instruction (which\n  /// has to be an unsigned predicate).\n  /// return the signed version of a predicate\n  Predicate getSignedPredicate() {\n    return getSignedPredicate(getPredicate());\n  }\n\n  /// For example, SLT->ULT, SLE->ULE, SGT->UGT, SGE->UGE, ULT->Failed assert\n  /// @returns the unsigned version of the signed predicate pred.\n  static Predicate getUnsignedPredicate(Predicate pred);\n\n  /// For example, SLT->ULT, SLE->ULE, SGT->UGT, SGE->UGE, ULT->Failed assert\n  /// @returns the unsigned version of the predicate for this instruction (which\n  /// has to be an signed predicate).\n  /// return the unsigned version of a predicate\n  Predicate getUnsignedPredicate() {\n    return getUnsignedPredicate(getPredicate());\n  }\n\n  /// For example, SLT->ULT, ULT->SLT, SLE->ULE, ULE->SLE, EQ->Failed assert\n  /// @returns the unsigned version of the signed predicate pred or\n  ///          the signed version of the signed predicate pred.\n  static Predicate getFlippedSignednessPredicate(Predicate pred);\n\n  /// For example, SLT->ULT, ULT->SLT, SLE->ULE, ULE->SLE, EQ->Failed assert\n  /// @returns the unsigned version of the signed predicate pred or\n  ///          the signed version of the signed predicate pred.\n  Predicate getFlippedSignednessPredicate() {\n    return getFlippedSignednessPredicate(getPredicate());\n  }\n\n  /// This is just a convenience.\n  /// Determine if this is true when both operands are the same.\n  bool isTrueWhenEqual() const {\n    return isTrueWhenEqual(getPredicate());\n  }\n\n  /// This is just a convenience.\n  /// Determine if this is false when both operands are the same.\n  bool isFalseWhenEqual() const {\n    return isFalseWhenEqual(getPredicate());\n  }\n\n  /// @returns true if the predicate is unsigned, false otherwise.\n  /// Determine if the predicate is an unsigned operation.\n  static bool isUnsigned(Predicate predicate);\n\n  /// @returns true if the predicate is signed, false otherwise.\n  /// Determine if the predicate is an signed operation.\n  static bool isSigned(Predicate predicate);\n\n  /// Determine if the predicate is an ordered operation.\n  static bool isOrdered(Predicate predicate);\n\n  /// Determine if the predicate is an unordered operation.\n  static bool isUnordered(Predicate predicate);\n\n  /// Determine if the predicate is true when comparing a value with itself.\n  static bool isTrueWhenEqual(Predicate predicate);\n\n  /// Determine if the predicate is false when comparing a value with itself.\n  static bool isFalseWhenEqual(Predicate predicate);\n\n  /// Determine if Pred1 implies Pred2 is true when two compares have matching\n  /// operands.\n  static bool isImpliedTrueByMatchingCmp(Predicate Pred1, Predicate Pred2);\n\n  /// Determine if Pred1 implies Pred2 is false when two compares have matching\n  /// operands.\n  static bool isImpliedFalseByMatchingCmp(Predicate Pred1, Predicate Pred2);\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::ICmp ||\n           I->getOpcode() == Instruction::FCmp;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\n  /// Create a result type for fcmp/icmp\n  static Type* makeCmpResultType(Type* opnd_type) {\n    if (VectorType* vt = dyn_cast<VectorType>(opnd_type)) {\n      return VectorType::get(Type::getInt1Ty(opnd_type->getContext()),\n                             vt->getElementCount());\n    }\n    return Type::getInt1Ty(opnd_type->getContext());\n  }\n\nprivate:\n  // Shadow Value::setValueSubclassData with a private forwarding method so that\n  // subclasses cannot accidentally use it.\n  void setValueSubclassData(unsigned short D) {\n    Value::setValueSubclassData(D);\n  }\n};\n\n// FIXME: these are redundant if CmpInst < BinaryOperator\ntemplate <>\nstruct OperandTraits<CmpInst> : public FixedNumOperandTraits<CmpInst, 2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(CmpInst, Value)\n\n/// A lightweight accessor for an operand bundle meant to be passed\n/// around by value.\nstruct OperandBundleUse {\n  ArrayRef<Use> Inputs;\n\n  OperandBundleUse() = default;\n  explicit OperandBundleUse(StringMapEntry<uint32_t> *Tag, ArrayRef<Use> Inputs)\n      : Inputs(Inputs), Tag(Tag) {}\n\n  /// Return true if the operand at index \\p Idx in this operand bundle\n  /// has the attribute A.\n  bool operandHasAttr(unsigned Idx, Attribute::AttrKind A) const {\n    if (isDeoptOperandBundle())\n      if (A == Attribute::ReadOnly || A == Attribute::NoCapture)\n        return Inputs[Idx]->getType()->isPointerTy();\n\n    // Conservative answer:  no operands have any attributes.\n    return false;\n  }\n\n  /// Return the tag of this operand bundle as a string.\n  StringRef getTagName() const {\n    return Tag->getKey();\n  }\n\n  /// Return the tag of this operand bundle as an integer.\n  ///\n  /// Operand bundle tags are interned by LLVMContextImpl::getOrInsertBundleTag,\n  /// and this function returns the unique integer getOrInsertBundleTag\n  /// associated the tag of this operand bundle to.\n  uint32_t getTagID() const {\n    return Tag->getValue();\n  }\n\n  /// Return true if this is a \"deopt\" operand bundle.\n  bool isDeoptOperandBundle() const {\n    return getTagID() == LLVMContext::OB_deopt;\n  }\n\n  /// Return true if this is a \"funclet\" operand bundle.\n  bool isFuncletOperandBundle() const {\n    return getTagID() == LLVMContext::OB_funclet;\n  }\n\n  /// Return true if this is a \"cfguardtarget\" operand bundle.\n  bool isCFGuardTargetOperandBundle() const {\n    return getTagID() == LLVMContext::OB_cfguardtarget;\n  }\n\nprivate:\n  /// Pointer to an entry in LLVMContextImpl::getOrInsertBundleTag.\n  StringMapEntry<uint32_t> *Tag;\n};\n\n/// A container for an operand bundle being viewed as a set of values\n/// rather than a set of uses.\n///\n/// Unlike OperandBundleUse, OperandBundleDefT owns the memory it carries, and\n/// so it is possible to create and pass around \"self-contained\" instances of\n/// OperandBundleDef and ConstOperandBundleDef.\ntemplate <typename InputTy> class OperandBundleDefT {\n  std::string Tag;\n  std::vector<InputTy> Inputs;\n\npublic:\n  explicit OperandBundleDefT(std::string Tag, std::vector<InputTy> Inputs)\n      : Tag(std::move(Tag)), Inputs(std::move(Inputs)) {}\n  explicit OperandBundleDefT(std::string Tag, ArrayRef<InputTy> Inputs)\n      : Tag(std::move(Tag)), Inputs(Inputs) {}\n\n  explicit OperandBundleDefT(const OperandBundleUse &OBU) {\n    Tag = std::string(OBU.getTagName());\n    llvm::append_range(Inputs, OBU.Inputs);\n  }\n\n  ArrayRef<InputTy> inputs() const { return Inputs; }\n\n  using input_iterator = typename std::vector<InputTy>::const_iterator;\n\n  size_t input_size() const { return Inputs.size(); }\n  input_iterator input_begin() const { return Inputs.begin(); }\n  input_iterator input_end() const { return Inputs.end(); }\n\n  StringRef getTag() const { return Tag; }\n};\n\nusing OperandBundleDef = OperandBundleDefT<Value *>;\nusing ConstOperandBundleDef = OperandBundleDefT<const Value *>;\n\n//===----------------------------------------------------------------------===//\n//                               CallBase Class\n//===----------------------------------------------------------------------===//\n\n/// Base class for all callable instructions (InvokeInst and CallInst)\n/// Holds everything related to calling a function.\n///\n/// All call-like instructions are required to use a common operand layout:\n/// - Zero or more arguments to the call,\n/// - Zero or more operand bundles with zero or more operand inputs each\n///   bundle,\n/// - Zero or more subclass controlled operands\n/// - The called function.\n///\n/// This allows this base class to easily access the called function and the\n/// start of the arguments without knowing how many other operands a particular\n/// subclass requires. Note that accessing the end of the argument list isn't\n/// as cheap as most other operations on the base class.\nclass CallBase : public Instruction {\nprotected:\n  // The first two bits are reserved by CallInst for fast retrieval,\n  using CallInstReservedField = Bitfield::Element<unsigned, 0, 2>;\n  using CallingConvField =\n      Bitfield::Element<CallingConv::ID, CallInstReservedField::NextBit, 10,\n                        CallingConv::MaxID>;\n  static_assert(\n      Bitfield::areContiguous<CallInstReservedField, CallingConvField>(),\n      \"Bitfields must be contiguous\");\n\n  /// The last operand is the called operand.\n  static constexpr int CalledOperandOpEndIdx = -1;\n\n  AttributeList Attrs; ///< parameter attributes for callable\n  FunctionType *FTy;\n\n  template <class... ArgsTy>\n  CallBase(AttributeList const &A, FunctionType *FT, ArgsTy &&... Args)\n      : Instruction(std::forward<ArgsTy>(Args)...), Attrs(A), FTy(FT) {}\n\n  using Instruction::Instruction;\n\n  bool hasDescriptor() const { return Value::HasDescriptor; }\n\n  unsigned getNumSubclassExtraOperands() const {\n    switch (getOpcode()) {\n    case Instruction::Call:\n      return 0;\n    case Instruction::Invoke:\n      return 2;\n    case Instruction::CallBr:\n      return getNumSubclassExtraOperandsDynamic();\n    }\n    llvm_unreachable(\"Invalid opcode!\");\n  }\n\n  /// Get the number of extra operands for instructions that don't have a fixed\n  /// number of extra operands.\n  unsigned getNumSubclassExtraOperandsDynamic() const;\n\npublic:\n  using Instruction::getContext;\n\n  /// Create a clone of \\p CB with a different set of operand bundles and\n  /// insert it before \\p InsertPt.\n  ///\n  /// The returned call instruction is identical \\p CB in every way except that\n  /// the operand bundles for the new instruction are set to the operand bundles\n  /// in \\p Bundles.\n  static CallBase *Create(CallBase *CB, ArrayRef<OperandBundleDef> Bundles,\n                          Instruction *InsertPt = nullptr);\n\n  /// Create a clone of \\p CB with the operand bundle with the tag matching\n  /// \\p Bundle's tag replaced with Bundle, and insert it before \\p InsertPt.\n  ///\n  /// The returned call instruction is identical \\p CI in every way except that\n  /// the specified operand bundle has been replaced.\n  static CallBase *Create(CallBase *CB,\n                          OperandBundleDef Bundle,\n                          Instruction *InsertPt = nullptr);\n\n  /// Create a clone of \\p CB with operand bundle \\p OB added.\n  static CallBase *addOperandBundle(CallBase *CB, uint32_t ID,\n                                    OperandBundleDef OB,\n                                    Instruction *InsertPt = nullptr);\n\n  /// Create a clone of \\p CB with operand bundle \\p ID removed.\n  static CallBase *removeOperandBundle(CallBase *CB, uint32_t ID,\n                                       Instruction *InsertPt = nullptr);\n\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Call ||\n           I->getOpcode() == Instruction::Invoke ||\n           I->getOpcode() == Instruction::CallBr;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\n  FunctionType *getFunctionType() const { return FTy; }\n\n  void mutateFunctionType(FunctionType *FTy) {\n    Value::mutateType(FTy->getReturnType());\n    this->FTy = FTy;\n  }\n\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// data_operands_begin/data_operands_end - Return iterators iterating over\n  /// the call / invoke argument list and bundle operands.  For invokes, this is\n  /// the set of instruction operands except the invoke target and the two\n  /// successor blocks; and for calls this is the set of instruction operands\n  /// except the call target.\n  User::op_iterator data_operands_begin() { return op_begin(); }\n  User::const_op_iterator data_operands_begin() const {\n    return const_cast<CallBase *>(this)->data_operands_begin();\n  }\n  User::op_iterator data_operands_end() {\n    // Walk from the end of the operands over the called operand and any\n    // subclass operands.\n    return op_end() - getNumSubclassExtraOperands() - 1;\n  }\n  User::const_op_iterator data_operands_end() const {\n    return const_cast<CallBase *>(this)->data_operands_end();\n  }\n  iterator_range<User::op_iterator> data_ops() {\n    return make_range(data_operands_begin(), data_operands_end());\n  }\n  iterator_range<User::const_op_iterator> data_ops() const {\n    return make_range(data_operands_begin(), data_operands_end());\n  }\n  bool data_operands_empty() const {\n    return data_operands_end() == data_operands_begin();\n  }\n  unsigned data_operands_size() const {\n    return std::distance(data_operands_begin(), data_operands_end());\n  }\n\n  bool isDataOperand(const Use *U) const {\n    assert(this == U->getUser() &&\n           \"Only valid to query with a use of this instruction!\");\n    return data_operands_begin() <= U && U < data_operands_end();\n  }\n  bool isDataOperand(Value::const_user_iterator UI) const {\n    return isDataOperand(&UI.getUse());\n  }\n\n  /// Given a value use iterator, return the data operand corresponding to it.\n  /// Iterator must actually correspond to a data operand.\n  unsigned getDataOperandNo(Value::const_user_iterator UI) const {\n    return getDataOperandNo(&UI.getUse());\n  }\n\n  /// Given a use for a data operand, get the data operand number that\n  /// corresponds to it.\n  unsigned getDataOperandNo(const Use *U) const {\n    assert(isDataOperand(U) && \"Data operand # out of range!\");\n    return U - data_operands_begin();\n  }\n\n  /// Return the iterator pointing to the beginning of the argument list.\n  User::op_iterator arg_begin() { return op_begin(); }\n  User::const_op_iterator arg_begin() const {\n    return const_cast<CallBase *>(this)->arg_begin();\n  }\n\n  /// Return the iterator pointing to the end of the argument list.\n  User::op_iterator arg_end() {\n    // From the end of the data operands, walk backwards past the bundle\n    // operands.\n    return data_operands_end() - getNumTotalBundleOperands();\n  }\n  User::const_op_iterator arg_end() const {\n    return const_cast<CallBase *>(this)->arg_end();\n  }\n\n  /// Iteration adapter for range-for loops.\n  iterator_range<User::op_iterator> args() {\n    return make_range(arg_begin(), arg_end());\n  }\n  iterator_range<User::const_op_iterator> args() const {\n    return make_range(arg_begin(), arg_end());\n  }\n  bool arg_empty() const { return arg_end() == arg_begin(); }\n  unsigned arg_size() const { return arg_end() - arg_begin(); }\n\n  // Legacy API names that duplicate the above and will be removed once users\n  // are migrated.\n  iterator_range<User::op_iterator> arg_operands() {\n    return make_range(arg_begin(), arg_end());\n  }\n  iterator_range<User::const_op_iterator> arg_operands() const {\n    return make_range(arg_begin(), arg_end());\n  }\n  unsigned getNumArgOperands() const { return arg_size(); }\n\n  Value *getArgOperand(unsigned i) const {\n    assert(i < getNumArgOperands() && \"Out of bounds!\");\n    return getOperand(i);\n  }\n\n  void setArgOperand(unsigned i, Value *v) {\n    assert(i < getNumArgOperands() && \"Out of bounds!\");\n    setOperand(i, v);\n  }\n\n  /// Wrappers for getting the \\c Use of a call argument.\n  const Use &getArgOperandUse(unsigned i) const {\n    assert(i < getNumArgOperands() && \"Out of bounds!\");\n    return User::getOperandUse(i);\n  }\n  Use &getArgOperandUse(unsigned i) {\n    assert(i < getNumArgOperands() && \"Out of bounds!\");\n    return User::getOperandUse(i);\n  }\n\n  bool isArgOperand(const Use *U) const {\n    assert(this == U->getUser() &&\n           \"Only valid to query with a use of this instruction!\");\n    return arg_begin() <= U && U < arg_end();\n  }\n  bool isArgOperand(Value::const_user_iterator UI) const {\n    return isArgOperand(&UI.getUse());\n  }\n\n  /// Given a use for a arg operand, get the arg operand number that\n  /// corresponds to it.\n  unsigned getArgOperandNo(const Use *U) const {\n    assert(isArgOperand(U) && \"Arg operand # out of range!\");\n    return U - arg_begin();\n  }\n\n  /// Given a value use iterator, return the arg operand number corresponding to\n  /// it. Iterator must actually correspond to a data operand.\n  unsigned getArgOperandNo(Value::const_user_iterator UI) const {\n    return getArgOperandNo(&UI.getUse());\n  }\n\n  /// Returns true if this CallSite passes the given Value* as an argument to\n  /// the called function.\n  bool hasArgument(const Value *V) const {\n    return llvm::is_contained(args(), V);\n  }\n\n  Value *getCalledOperand() const { return Op<CalledOperandOpEndIdx>(); }\n\n  const Use &getCalledOperandUse() const { return Op<CalledOperandOpEndIdx>(); }\n  Use &getCalledOperandUse() { return Op<CalledOperandOpEndIdx>(); }\n\n  /// Returns the function called, or null if this is an\n  /// indirect function invocation.\n  Function *getCalledFunction() const {\n    return dyn_cast_or_null<Function>(getCalledOperand());\n  }\n\n  /// Return true if the callsite is an indirect call.\n  bool isIndirectCall() const;\n\n  /// Determine whether the passed iterator points to the callee operand's Use.\n  bool isCallee(Value::const_user_iterator UI) const {\n    return isCallee(&UI.getUse());\n  }\n\n  /// Determine whether this Use is the callee operand's Use.\n  bool isCallee(const Use *U) const { return &getCalledOperandUse() == U; }\n\n  /// Helper to get the caller (the parent function).\n  Function *getCaller();\n  const Function *getCaller() const {\n    return const_cast<CallBase *>(this)->getCaller();\n  }\n\n  /// Tests if this call site must be tail call optimized. Only a CallInst can\n  /// be tail call optimized.\n  bool isMustTailCall() const;\n\n  /// Tests if this call site is marked as a tail call.\n  bool isTailCall() const;\n\n  /// Returns the intrinsic ID of the intrinsic called or\n  /// Intrinsic::not_intrinsic if the called function is not an intrinsic, or if\n  /// this is an indirect call.\n  Intrinsic::ID getIntrinsicID() const;\n\n  void setCalledOperand(Value *V) { Op<CalledOperandOpEndIdx>() = V; }\n\n  /// Sets the function called, including updating the function type.\n  void setCalledFunction(Function *Fn) {\n    setCalledFunction(Fn->getFunctionType(), Fn);\n  }\n\n  /// Sets the function called, including updating the function type.\n  void setCalledFunction(FunctionCallee Fn) {\n    setCalledFunction(Fn.getFunctionType(), Fn.getCallee());\n  }\n\n  /// Sets the function called, including updating to the specified function\n  /// type.\n  void setCalledFunction(FunctionType *FTy, Value *Fn) {\n    this->FTy = FTy;\n    assert(FTy == cast<FunctionType>(\n                      cast<PointerType>(Fn->getType())->getElementType()));\n    // This function doesn't mutate the return type, only the function\n    // type. Seems broken, but I'm just gonna stick an assert in for now.\n    assert(getType() == FTy->getReturnType());\n    setCalledOperand(Fn);\n  }\n\n  CallingConv::ID getCallingConv() const {\n    return getSubclassData<CallingConvField>();\n  }\n\n  void setCallingConv(CallingConv::ID CC) {\n    setSubclassData<CallingConvField>(CC);\n  }\n\n  /// Check if this call is an inline asm statement.\n  bool isInlineAsm() const { return isa<InlineAsm>(getCalledOperand()); }\n\n  /// \\name Attribute API\n  ///\n  /// These methods access and modify attributes on this call (including\n  /// looking through to the attributes on the called function when necessary).\n  ///@{\n\n  /// Return the parameter attributes for this call.\n  ///\n  AttributeList getAttributes() const { return Attrs; }\n\n  /// Set the parameter attributes for this call.\n  ///\n  void setAttributes(AttributeList A) { Attrs = A; }\n\n  /// Determine whether this call has the given attribute. If it does not\n  /// then determine if the called function has the attribute, but only if\n  /// the attribute is allowed for the call.\n  bool hasFnAttr(Attribute::AttrKind Kind) const {\n    assert(Kind != Attribute::NoBuiltin &&\n           \"Use CallBase::isNoBuiltin() to check for Attribute::NoBuiltin\");\n    return hasFnAttrImpl(Kind);\n  }\n\n  /// Determine whether this call has the given attribute. If it does not\n  /// then determine if the called function has the attribute, but only if\n  /// the attribute is allowed for the call.\n  bool hasFnAttr(StringRef Kind) const { return hasFnAttrImpl(Kind); }\n\n  /// adds the attribute to the list of attributes.\n  void addAttribute(unsigned i, Attribute::AttrKind Kind) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.addAttribute(getContext(), i, Kind);\n    setAttributes(PAL);\n  }\n\n  /// adds the attribute to the list of attributes.\n  void addAttribute(unsigned i, Attribute Attr) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.addAttribute(getContext(), i, Attr);\n    setAttributes(PAL);\n  }\n\n  /// Adds the attribute to the indicated argument\n  void addParamAttr(unsigned ArgNo, Attribute::AttrKind Kind) {\n    assert(ArgNo < getNumArgOperands() && \"Out of bounds\");\n    AttributeList PAL = getAttributes();\n    PAL = PAL.addParamAttribute(getContext(), ArgNo, Kind);\n    setAttributes(PAL);\n  }\n\n  /// Adds the attribute to the indicated argument\n  void addParamAttr(unsigned ArgNo, Attribute Attr) {\n    assert(ArgNo < getNumArgOperands() && \"Out of bounds\");\n    AttributeList PAL = getAttributes();\n    PAL = PAL.addParamAttribute(getContext(), ArgNo, Attr);\n    setAttributes(PAL);\n  }\n\n  /// removes the attribute from the list of attributes.\n  void removeAttribute(unsigned i, Attribute::AttrKind Kind) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.removeAttribute(getContext(), i, Kind);\n    setAttributes(PAL);\n  }\n\n  /// removes the attribute from the list of attributes.\n  void removeAttribute(unsigned i, StringRef Kind) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.removeAttribute(getContext(), i, Kind);\n    setAttributes(PAL);\n  }\n\n  void removeAttributes(unsigned i, const AttrBuilder &Attrs) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.removeAttributes(getContext(), i, Attrs);\n    setAttributes(PAL);\n  }\n\n  /// Removes the attribute from the given argument\n  void removeParamAttr(unsigned ArgNo, Attribute::AttrKind Kind) {\n    assert(ArgNo < getNumArgOperands() && \"Out of bounds\");\n    AttributeList PAL = getAttributes();\n    PAL = PAL.removeParamAttribute(getContext(), ArgNo, Kind);\n    setAttributes(PAL);\n  }\n\n  /// Removes the attribute from the given argument\n  void removeParamAttr(unsigned ArgNo, StringRef Kind) {\n    assert(ArgNo < getNumArgOperands() && \"Out of bounds\");\n    AttributeList PAL = getAttributes();\n    PAL = PAL.removeParamAttribute(getContext(), ArgNo, Kind);\n    setAttributes(PAL);\n  }\n\n  /// adds the dereferenceable attribute to the list of attributes.\n  void addDereferenceableAttr(unsigned i, uint64_t Bytes) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.addDereferenceableAttr(getContext(), i, Bytes);\n    setAttributes(PAL);\n  }\n\n  /// adds the dereferenceable_or_null attribute to the list of\n  /// attributes.\n  void addDereferenceableOrNullAttr(unsigned i, uint64_t Bytes) {\n    AttributeList PAL = getAttributes();\n    PAL = PAL.addDereferenceableOrNullAttr(getContext(), i, Bytes);\n    setAttributes(PAL);\n  }\n\n  /// Determine whether the return value has the given attribute.\n  bool hasRetAttr(Attribute::AttrKind Kind) const {\n    return hasRetAttrImpl(Kind);\n  }\n  /// Determine whether the return value has the given attribute.\n  bool hasRetAttr(StringRef Kind) const { return hasRetAttrImpl(Kind); }\n\n  /// Determine whether the argument or parameter has the given attribute.\n  bool paramHasAttr(unsigned ArgNo, Attribute::AttrKind Kind) const;\n\n  /// Get the attribute of a given kind at a position.\n  Attribute getAttribute(unsigned i, Attribute::AttrKind Kind) const {\n    return getAttributes().getAttribute(i, Kind);\n  }\n\n  /// Get the attribute of a given kind at a position.\n  Attribute getAttribute(unsigned i, StringRef Kind) const {\n    return getAttributes().getAttribute(i, Kind);\n  }\n\n  /// Get the attribute of a given kind from a given arg\n  Attribute getParamAttr(unsigned ArgNo, Attribute::AttrKind Kind) const {\n    assert(ArgNo < getNumArgOperands() && \"Out of bounds\");\n    return getAttributes().getParamAttr(ArgNo, Kind);\n  }\n\n  /// Get the attribute of a given kind from a given arg\n  Attribute getParamAttr(unsigned ArgNo, StringRef Kind) const {\n    assert(ArgNo < getNumArgOperands() && \"Out of bounds\");\n    return getAttributes().getParamAttr(ArgNo, Kind);\n  }\n\n  /// Return true if the data operand at index \\p i has the attribute \\p\n  /// A.\n  ///\n  /// Data operands include call arguments and values used in operand bundles,\n  /// but does not include the callee operand.  This routine dispatches to the\n  /// underlying AttributeList or the OperandBundleUser as appropriate.\n  ///\n  /// The index \\p i is interpreted as\n  ///\n  ///  \\p i == Attribute::ReturnIndex  -> the return value\n  ///  \\p i in [1, arg_size + 1)  -> argument number (\\p i - 1)\n  ///  \\p i in [arg_size + 1, data_operand_size + 1) -> bundle operand at index\n  ///     (\\p i - 1) in the operand list.\n  bool dataOperandHasImpliedAttr(unsigned i, Attribute::AttrKind Kind) const {\n    // Note that we have to add one because `i` isn't zero-indexed.\n    assert(i < (getNumArgOperands() + getNumTotalBundleOperands() + 1) &&\n           \"Data operand index out of bounds!\");\n\n    // The attribute A can either be directly specified, if the operand in\n    // question is a call argument; or be indirectly implied by the kind of its\n    // containing operand bundle, if the operand is a bundle operand.\n\n    if (i == AttributeList::ReturnIndex)\n      return hasRetAttr(Kind);\n\n    // FIXME: Avoid these i - 1 calculations and update the API to use\n    // zero-based indices.\n    if (i < (getNumArgOperands() + 1))\n      return paramHasAttr(i - 1, Kind);\n\n    assert(hasOperandBundles() && i >= (getBundleOperandsStartIndex() + 1) &&\n           \"Must be either a call argument or an operand bundle!\");\n    return bundleOperandHasAttr(i - 1, Kind);\n  }\n\n  /// Determine whether this data operand is not captured.\n  // FIXME: Once this API is no longer duplicated in `CallSite`, rename this to\n  // better indicate that this may return a conservative answer.\n  bool doesNotCapture(unsigned OpNo) const {\n    return dataOperandHasImpliedAttr(OpNo + 1, Attribute::NoCapture);\n  }\n\n  /// Determine whether this argument is passed by value.\n  bool isByValArgument(unsigned ArgNo) const {\n    return paramHasAttr(ArgNo, Attribute::ByVal);\n  }\n\n  /// Determine whether this argument is passed in an alloca.\n  bool isInAllocaArgument(unsigned ArgNo) const {\n    return paramHasAttr(ArgNo, Attribute::InAlloca);\n  }\n\n  /// Determine whether this argument is passed by value, in an alloca, or is\n  /// preallocated.\n  bool isPassPointeeByValueArgument(unsigned ArgNo) const {\n    return paramHasAttr(ArgNo, Attribute::ByVal) ||\n           paramHasAttr(ArgNo, Attribute::InAlloca) ||\n           paramHasAttr(ArgNo, Attribute::Preallocated);\n  }\n\n  /// Determine whether passing undef to this argument is undefined behavior.\n  /// If passing undef to this argument is UB, passing poison is UB as well\n  /// because poison is more undefined than undef.\n  bool isPassingUndefUB(unsigned ArgNo) const {\n    return paramHasAttr(ArgNo, Attribute::NoUndef) ||\n           // dereferenceable implies noundef.\n           paramHasAttr(ArgNo, Attribute::Dereferenceable) ||\n           // dereferenceable implies noundef, and null is a well-defined value.\n           paramHasAttr(ArgNo, Attribute::DereferenceableOrNull);\n  }\n\n  /// Determine if there are is an inalloca argument. Only the last argument can\n  /// have the inalloca attribute.\n  bool hasInAllocaArgument() const {\n    return !arg_empty() && paramHasAttr(arg_size() - 1, Attribute::InAlloca);\n  }\n\n  // FIXME: Once this API is no longer duplicated in `CallSite`, rename this to\n  // better indicate that this may return a conservative answer.\n  bool doesNotAccessMemory(unsigned OpNo) const {\n    return dataOperandHasImpliedAttr(OpNo + 1, Attribute::ReadNone);\n  }\n\n  // FIXME: Once this API is no longer duplicated in `CallSite`, rename this to\n  // better indicate that this may return a conservative answer.\n  bool onlyReadsMemory(unsigned OpNo) const {\n    return dataOperandHasImpliedAttr(OpNo + 1, Attribute::ReadOnly) ||\n           dataOperandHasImpliedAttr(OpNo + 1, Attribute::ReadNone);\n  }\n\n  // FIXME: Once this API is no longer duplicated in `CallSite`, rename this to\n  // better indicate that this may return a conservative answer.\n  bool doesNotReadMemory(unsigned OpNo) const {\n    return dataOperandHasImpliedAttr(OpNo + 1, Attribute::WriteOnly) ||\n           dataOperandHasImpliedAttr(OpNo + 1, Attribute::ReadNone);\n  }\n\n  LLVM_ATTRIBUTE_DEPRECATED(unsigned getRetAlignment() const,\n                            \"Use getRetAlign() instead\") {\n    if (const auto MA = Attrs.getRetAlignment())\n      return MA->value();\n    return 0;\n  }\n\n  /// Extract the alignment of the return value.\n  MaybeAlign getRetAlign() const { return Attrs.getRetAlignment(); }\n\n  /// Extract the alignment for a call or parameter (0=unknown).\n  LLVM_ATTRIBUTE_DEPRECATED(unsigned getParamAlignment(unsigned ArgNo) const,\n                            \"Use getParamAlign() instead\") {\n    if (const auto MA = Attrs.getParamAlignment(ArgNo))\n      return MA->value();\n    return 0;\n  }\n\n  /// Extract the alignment for a call or parameter (0=unknown).\n  MaybeAlign getParamAlign(unsigned ArgNo) const {\n    return Attrs.getParamAlignment(ArgNo);\n  }\n\n  /// Extract the byval type for a call or parameter.\n  Type *getParamByValType(unsigned ArgNo) const {\n    Type *Ty = Attrs.getParamByValType(ArgNo);\n    return Ty ? Ty : getArgOperand(ArgNo)->getType()->getPointerElementType();\n  }\n\n  /// Extract the preallocated type for a call or parameter.\n  Type *getParamPreallocatedType(unsigned ArgNo) const {\n    Type *Ty = Attrs.getParamPreallocatedType(ArgNo);\n    return Ty ? Ty : getArgOperand(ArgNo)->getType()->getPointerElementType();\n  }\n\n  /// Extract the number of dereferenceable bytes for a call or\n  /// parameter (0=unknown).\n  uint64_t getDereferenceableBytes(unsigned i) const {\n    return Attrs.getDereferenceableBytes(i);\n  }\n\n  /// Extract the number of dereferenceable_or_null bytes for a call or\n  /// parameter (0=unknown).\n  uint64_t getDereferenceableOrNullBytes(unsigned i) const {\n    return Attrs.getDereferenceableOrNullBytes(i);\n  }\n\n  /// Return true if the return value is known to be not null.\n  /// This may be because it has the nonnull attribute, or because at least\n  /// one byte is dereferenceable and the pointer is in addrspace(0).\n  bool isReturnNonNull() const;\n\n  /// Determine if the return value is marked with NoAlias attribute.\n  bool returnDoesNotAlias() const {\n    return Attrs.hasAttribute(AttributeList::ReturnIndex, Attribute::NoAlias);\n  }\n\n  /// If one of the arguments has the 'returned' attribute, returns its\n  /// operand value. Otherwise, return nullptr.\n  Value *getReturnedArgOperand() const;\n\n  /// Return true if the call should not be treated as a call to a\n  /// builtin.\n  bool isNoBuiltin() const {\n    return hasFnAttrImpl(Attribute::NoBuiltin) &&\n           !hasFnAttrImpl(Attribute::Builtin);\n  }\n\n  /// Determine if the call requires strict floating point semantics.\n  bool isStrictFP() const { return hasFnAttr(Attribute::StrictFP); }\n\n  /// Return true if the call should not be inlined.\n  bool isNoInline() const { return hasFnAttr(Attribute::NoInline); }\n  void setIsNoInline() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::NoInline);\n  }\n  /// Determine if the call does not access memory.\n  bool doesNotAccessMemory() const { return hasFnAttr(Attribute::ReadNone); }\n  void setDoesNotAccessMemory() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::ReadNone);\n  }\n\n  /// Determine if the call does not access or only reads memory.\n  bool onlyReadsMemory() const {\n    return doesNotAccessMemory() || hasFnAttr(Attribute::ReadOnly);\n  }\n\n  void setOnlyReadsMemory() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::ReadOnly);\n  }\n\n  /// Determine if the call does not access or only writes memory.\n  bool doesNotReadMemory() const {\n    return doesNotAccessMemory() || hasFnAttr(Attribute::WriteOnly);\n  }\n  void setDoesNotReadMemory() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::WriteOnly);\n  }\n\n  /// Determine if the call can access memmory only using pointers based\n  /// on its arguments.\n  bool onlyAccessesArgMemory() const {\n    return hasFnAttr(Attribute::ArgMemOnly);\n  }\n  void setOnlyAccessesArgMemory() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::ArgMemOnly);\n  }\n\n  /// Determine if the function may only access memory that is\n  /// inaccessible from the IR.\n  bool onlyAccessesInaccessibleMemory() const {\n    return hasFnAttr(Attribute::InaccessibleMemOnly);\n  }\n  void setOnlyAccessesInaccessibleMemory() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::InaccessibleMemOnly);\n  }\n\n  /// Determine if the function may only access memory that is\n  /// either inaccessible from the IR or pointed to by its arguments.\n  bool onlyAccessesInaccessibleMemOrArgMem() const {\n    return hasFnAttr(Attribute::InaccessibleMemOrArgMemOnly);\n  }\n  void setOnlyAccessesInaccessibleMemOrArgMem() {\n    addAttribute(AttributeList::FunctionIndex,\n                 Attribute::InaccessibleMemOrArgMemOnly);\n  }\n  /// Determine if the call cannot return.\n  bool doesNotReturn() const { return hasFnAttr(Attribute::NoReturn); }\n  void setDoesNotReturn() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::NoReturn);\n  }\n\n  /// Determine if the call should not perform indirect branch tracking.\n  bool doesNoCfCheck() const { return hasFnAttr(Attribute::NoCfCheck); }\n\n  /// Determine if the call cannot unwind.\n  bool doesNotThrow() const { return hasFnAttr(Attribute::NoUnwind); }\n  void setDoesNotThrow() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::NoUnwind);\n  }\n\n  /// Determine if the invoke cannot be duplicated.\n  bool cannotDuplicate() const { return hasFnAttr(Attribute::NoDuplicate); }\n  void setCannotDuplicate() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::NoDuplicate);\n  }\n\n  /// Determine if the call cannot be tail merged.\n  bool cannotMerge() const { return hasFnAttr(Attribute::NoMerge); }\n  void setCannotMerge() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::NoMerge);\n  }\n\n  /// Determine if the invoke is convergent\n  bool isConvergent() const { return hasFnAttr(Attribute::Convergent); }\n  void setConvergent() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::Convergent);\n  }\n  void setNotConvergent() {\n    removeAttribute(AttributeList::FunctionIndex, Attribute::Convergent);\n  }\n\n  /// Determine if the call returns a structure through first\n  /// pointer argument.\n  bool hasStructRetAttr() const {\n    if (getNumArgOperands() == 0)\n      return false;\n\n    // Be friendly and also check the callee.\n    return paramHasAttr(0, Attribute::StructRet);\n  }\n\n  /// Determine if any call argument is an aggregate passed by value.\n  bool hasByValArgument() const {\n    return Attrs.hasAttrSomewhere(Attribute::ByVal);\n  }\n\n  ///@{\n  // End of attribute API.\n\n  /// \\name Operand Bundle API\n  ///\n  /// This group of methods provides the API to access and manipulate operand\n  /// bundles on this call.\n  /// @{\n\n  /// Return the number of operand bundles associated with this User.\n  unsigned getNumOperandBundles() const {\n    return std::distance(bundle_op_info_begin(), bundle_op_info_end());\n  }\n\n  /// Return true if this User has any operand bundles.\n  bool hasOperandBundles() const { return getNumOperandBundles() != 0; }\n\n  /// Return the index of the first bundle operand in the Use array.\n  unsigned getBundleOperandsStartIndex() const {\n    assert(hasOperandBundles() && \"Don't call otherwise!\");\n    return bundle_op_info_begin()->Begin;\n  }\n\n  /// Return the index of the last bundle operand in the Use array.\n  unsigned getBundleOperandsEndIndex() const {\n    assert(hasOperandBundles() && \"Don't call otherwise!\");\n    return bundle_op_info_end()[-1].End;\n  }\n\n  /// Return true if the operand at index \\p Idx is a bundle operand.\n  bool isBundleOperand(unsigned Idx) const {\n    return hasOperandBundles() && Idx >= getBundleOperandsStartIndex() &&\n           Idx < getBundleOperandsEndIndex();\n  }\n\n  /// Returns true if the use is a bundle operand.\n  bool isBundleOperand(const Use *U) const {\n    assert(this == U->getUser() &&\n           \"Only valid to query with a use of this instruction!\");\n    return hasOperandBundles() && isBundleOperand(U - op_begin());\n  }\n  bool isBundleOperand(Value::const_user_iterator UI) const {\n    return isBundleOperand(&UI.getUse());\n  }\n\n  /// Return the total number operands (not operand bundles) used by\n  /// every operand bundle in this OperandBundleUser.\n  unsigned getNumTotalBundleOperands() const {\n    if (!hasOperandBundles())\n      return 0;\n\n    unsigned Begin = getBundleOperandsStartIndex();\n    unsigned End = getBundleOperandsEndIndex();\n\n    assert(Begin <= End && \"Should be!\");\n    return End - Begin;\n  }\n\n  /// Return the operand bundle at a specific index.\n  OperandBundleUse getOperandBundleAt(unsigned Index) const {\n    assert(Index < getNumOperandBundles() && \"Index out of bounds!\");\n    return operandBundleFromBundleOpInfo(*(bundle_op_info_begin() + Index));\n  }\n\n  /// Return the number of operand bundles with the tag Name attached to\n  /// this instruction.\n  unsigned countOperandBundlesOfType(StringRef Name) const {\n    unsigned Count = 0;\n    for (unsigned i = 0, e = getNumOperandBundles(); i != e; ++i)\n      if (getOperandBundleAt(i).getTagName() == Name)\n        Count++;\n\n    return Count;\n  }\n\n  /// Return the number of operand bundles with the tag ID attached to\n  /// this instruction.\n  unsigned countOperandBundlesOfType(uint32_t ID) const {\n    unsigned Count = 0;\n    for (unsigned i = 0, e = getNumOperandBundles(); i != e; ++i)\n      if (getOperandBundleAt(i).getTagID() == ID)\n        Count++;\n\n    return Count;\n  }\n\n  /// Return an operand bundle by name, if present.\n  ///\n  /// It is an error to call this for operand bundle types that may have\n  /// multiple instances of them on the same instruction.\n  Optional<OperandBundleUse> getOperandBundle(StringRef Name) const {\n    assert(countOperandBundlesOfType(Name) < 2 && \"Precondition violated!\");\n\n    for (unsigned i = 0, e = getNumOperandBundles(); i != e; ++i) {\n      OperandBundleUse U = getOperandBundleAt(i);\n      if (U.getTagName() == Name)\n        return U;\n    }\n\n    return None;\n  }\n\n  /// Return an operand bundle by tag ID, if present.\n  ///\n  /// It is an error to call this for operand bundle types that may have\n  /// multiple instances of them on the same instruction.\n  Optional<OperandBundleUse> getOperandBundle(uint32_t ID) const {\n    assert(countOperandBundlesOfType(ID) < 2 && \"Precondition violated!\");\n\n    for (unsigned i = 0, e = getNumOperandBundles(); i != e; ++i) {\n      OperandBundleUse U = getOperandBundleAt(i);\n      if (U.getTagID() == ID)\n        return U;\n    }\n\n    return None;\n  }\n\n  /// Return the list of operand bundles attached to this instruction as\n  /// a vector of OperandBundleDefs.\n  ///\n  /// This function copies the OperandBundeUse instances associated with this\n  /// OperandBundleUser to a vector of OperandBundleDefs.  Note:\n  /// OperandBundeUses and OperandBundleDefs are non-trivially *different*\n  /// representations of operand bundles (see documentation above).\n  void getOperandBundlesAsDefs(SmallVectorImpl<OperandBundleDef> &Defs) const;\n\n  /// Return the operand bundle for the operand at index OpIdx.\n  ///\n  /// It is an error to call this with an OpIdx that does not correspond to an\n  /// bundle operand.\n  OperandBundleUse getOperandBundleForOperand(unsigned OpIdx) const {\n    return operandBundleFromBundleOpInfo(getBundleOpInfoForOperand(OpIdx));\n  }\n\n  /// Return true if this operand bundle user has operand bundles that\n  /// may read from the heap.\n  bool hasReadingOperandBundles() const {\n    // Implementation note: this is a conservative implementation of operand\n    // bundle semantics, where *any* operand bundle forces a callsite to be at\n    // least readonly.\n    return hasOperandBundles();\n  }\n\n  /// Return true if this operand bundle user has operand bundles that\n  /// may write to the heap.\n  bool hasClobberingOperandBundles() const {\n    for (auto &BOI : bundle_op_infos()) {\n      if (BOI.Tag->second == LLVMContext::OB_deopt ||\n          BOI.Tag->second == LLVMContext::OB_funclet)\n        continue;\n\n      // This instruction has an operand bundle that is not known to us.\n      // Assume the worst.\n      return true;\n    }\n\n    return false;\n  }\n\n  /// Return true if the bundle operand at index \\p OpIdx has the\n  /// attribute \\p A.\n  bool bundleOperandHasAttr(unsigned OpIdx,  Attribute::AttrKind A) const {\n    auto &BOI = getBundleOpInfoForOperand(OpIdx);\n    auto OBU = operandBundleFromBundleOpInfo(BOI);\n    return OBU.operandHasAttr(OpIdx - BOI.Begin, A);\n  }\n\n  /// Return true if \\p Other has the same sequence of operand bundle\n  /// tags with the same number of operands on each one of them as this\n  /// OperandBundleUser.\n  bool hasIdenticalOperandBundleSchema(const CallBase &Other) const {\n    if (getNumOperandBundles() != Other.getNumOperandBundles())\n      return false;\n\n    return std::equal(bundle_op_info_begin(), bundle_op_info_end(),\n                      Other.bundle_op_info_begin());\n  }\n\n  /// Return true if this operand bundle user contains operand bundles\n  /// with tags other than those specified in \\p IDs.\n  bool hasOperandBundlesOtherThan(ArrayRef<uint32_t> IDs) const {\n    for (unsigned i = 0, e = getNumOperandBundles(); i != e; ++i) {\n      uint32_t ID = getOperandBundleAt(i).getTagID();\n      if (!is_contained(IDs, ID))\n        return true;\n    }\n    return false;\n  }\n\n  /// Is the function attribute S disallowed by some operand bundle on\n  /// this operand bundle user?\n  bool isFnAttrDisallowedByOpBundle(StringRef S) const {\n    // Operand bundles only possibly disallow readnone, readonly and argmemonly\n    // attributes.  All String attributes are fine.\n    return false;\n  }\n\n  /// Is the function attribute A disallowed by some operand bundle on\n  /// this operand bundle user?\n  bool isFnAttrDisallowedByOpBundle(Attribute::AttrKind A) const {\n    switch (A) {\n    default:\n      return false;\n\n    case Attribute::InaccessibleMemOrArgMemOnly:\n      return hasReadingOperandBundles();\n\n    case Attribute::InaccessibleMemOnly:\n      return hasReadingOperandBundles();\n\n    case Attribute::ArgMemOnly:\n      return hasReadingOperandBundles();\n\n    case Attribute::ReadNone:\n      return hasReadingOperandBundles();\n\n    case Attribute::ReadOnly:\n      return hasClobberingOperandBundles();\n    }\n\n    llvm_unreachable(\"switch has a default case!\");\n  }\n\n  /// Used to keep track of an operand bundle.  See the main comment on\n  /// OperandBundleUser above.\n  struct BundleOpInfo {\n    /// The operand bundle tag, interned by\n    /// LLVMContextImpl::getOrInsertBundleTag.\n    StringMapEntry<uint32_t> *Tag;\n\n    /// The index in the Use& vector where operands for this operand\n    /// bundle starts.\n    uint32_t Begin;\n\n    /// The index in the Use& vector where operands for this operand\n    /// bundle ends.\n    uint32_t End;\n\n    bool operator==(const BundleOpInfo &Other) const {\n      return Tag == Other.Tag && Begin == Other.Begin && End == Other.End;\n    }\n  };\n\n  /// Simple helper function to map a BundleOpInfo to an\n  /// OperandBundleUse.\n  OperandBundleUse\n  operandBundleFromBundleOpInfo(const BundleOpInfo &BOI) const {\n    auto begin = op_begin();\n    ArrayRef<Use> Inputs(begin + BOI.Begin, begin + BOI.End);\n    return OperandBundleUse(BOI.Tag, Inputs);\n  }\n\n  using bundle_op_iterator = BundleOpInfo *;\n  using const_bundle_op_iterator = const BundleOpInfo *;\n\n  /// Return the start of the list of BundleOpInfo instances associated\n  /// with this OperandBundleUser.\n  ///\n  /// OperandBundleUser uses the descriptor area co-allocated with the host User\n  /// to store some meta information about which operands are \"normal\" operands,\n  /// and which ones belong to some operand bundle.\n  ///\n  /// The layout of an operand bundle user is\n  ///\n  ///          +-----------uint32_t End-------------------------------------+\n  ///          |                                                            |\n  ///          |  +--------uint32_t Begin--------------------+              |\n  ///          |  |                                          |              |\n  ///          ^  ^                                          v              v\n  ///  |------|------|----|----|----|----|----|---------|----|---------|----|-----\n  ///  | BOI0 | BOI1 | .. | DU | U0 | U1 | .. | BOI0_U0 | .. | BOI1_U0 | .. | Un\n  ///  |------|------|----|----|----|----|----|---------|----|---------|----|-----\n  ///   v  v                                  ^              ^\n  ///   |  |                                  |              |\n  ///   |  +--------uint32_t Begin------------+              |\n  ///   |                                                    |\n  ///   +-----------uint32_t End-----------------------------+\n  ///\n  ///\n  /// BOI0, BOI1 ... are descriptions of operand bundles in this User's use\n  /// list. These descriptions are installed and managed by this class, and\n  /// they're all instances of OperandBundleUser<T>::BundleOpInfo.\n  ///\n  /// DU is an additional descriptor installed by User's 'operator new' to keep\n  /// track of the 'BOI0 ... BOIN' co-allocation.  OperandBundleUser does not\n  /// access or modify DU in any way, it's an implementation detail private to\n  /// User.\n  ///\n  /// The regular Use& vector for the User starts at U0.  The operand bundle\n  /// uses are part of the Use& vector, just like normal uses.  In the diagram\n  /// above, the operand bundle uses start at BOI0_U0.  Each instance of\n  /// BundleOpInfo has information about a contiguous set of uses constituting\n  /// an operand bundle, and the total set of operand bundle uses themselves\n  /// form a contiguous set of uses (i.e. there are no gaps between uses\n  /// corresponding to individual operand bundles).\n  ///\n  /// This class does not know the location of the set of operand bundle uses\n  /// within the use list -- that is decided by the User using this class via\n  /// the BeginIdx argument in populateBundleOperandInfos.\n  ///\n  /// Currently operand bundle users with hung-off operands are not supported.\n  bundle_op_iterator bundle_op_info_begin() {\n    if (!hasDescriptor())\n      return nullptr;\n\n    uint8_t *BytesBegin = getDescriptor().begin();\n    return reinterpret_cast<bundle_op_iterator>(BytesBegin);\n  }\n\n  /// Return the start of the list of BundleOpInfo instances associated\n  /// with this OperandBundleUser.\n  const_bundle_op_iterator bundle_op_info_begin() const {\n    auto *NonConstThis = const_cast<CallBase *>(this);\n    return NonConstThis->bundle_op_info_begin();\n  }\n\n  /// Return the end of the list of BundleOpInfo instances associated\n  /// with this OperandBundleUser.\n  bundle_op_iterator bundle_op_info_end() {\n    if (!hasDescriptor())\n      return nullptr;\n\n    uint8_t *BytesEnd = getDescriptor().end();\n    return reinterpret_cast<bundle_op_iterator>(BytesEnd);\n  }\n\n  /// Return the end of the list of BundleOpInfo instances associated\n  /// with this OperandBundleUser.\n  const_bundle_op_iterator bundle_op_info_end() const {\n    auto *NonConstThis = const_cast<CallBase *>(this);\n    return NonConstThis->bundle_op_info_end();\n  }\n\n  /// Return the range [\\p bundle_op_info_begin, \\p bundle_op_info_end).\n  iterator_range<bundle_op_iterator> bundle_op_infos() {\n    return make_range(bundle_op_info_begin(), bundle_op_info_end());\n  }\n\n  /// Return the range [\\p bundle_op_info_begin, \\p bundle_op_info_end).\n  iterator_range<const_bundle_op_iterator> bundle_op_infos() const {\n    return make_range(bundle_op_info_begin(), bundle_op_info_end());\n  }\n\n  /// Populate the BundleOpInfo instances and the Use& vector from \\p\n  /// Bundles.  Return the op_iterator pointing to the Use& one past the last\n  /// last bundle operand use.\n  ///\n  /// Each \\p OperandBundleDef instance is tracked by a OperandBundleInfo\n  /// instance allocated in this User's descriptor.\n  op_iterator populateBundleOperandInfos(ArrayRef<OperandBundleDef> Bundles,\n                                         const unsigned BeginIndex);\n\npublic:\n  /// Return the BundleOpInfo for the operand at index OpIdx.\n  ///\n  /// It is an error to call this with an OpIdx that does not correspond to an\n  /// bundle operand.\n  BundleOpInfo &getBundleOpInfoForOperand(unsigned OpIdx);\n  const BundleOpInfo &getBundleOpInfoForOperand(unsigned OpIdx) const {\n    return const_cast<CallBase *>(this)->getBundleOpInfoForOperand(OpIdx);\n  }\n\nprotected:\n  /// Return the total number of values used in \\p Bundles.\n  static unsigned CountBundleInputs(ArrayRef<OperandBundleDef> Bundles) {\n    unsigned Total = 0;\n    for (auto &B : Bundles)\n      Total += B.input_size();\n    return Total;\n  }\n\n  /// @}\n  // End of operand bundle API.\n\nprivate:\n  bool hasFnAttrOnCalledFunction(Attribute::AttrKind Kind) const;\n  bool hasFnAttrOnCalledFunction(StringRef Kind) const;\n\n  template <typename AttrKind> bool hasFnAttrImpl(AttrKind Kind) const {\n    if (Attrs.hasFnAttribute(Kind))\n      return true;\n\n    // Operand bundles override attributes on the called function, but don't\n    // override attributes directly present on the call instruction.\n    if (isFnAttrDisallowedByOpBundle(Kind))\n      return false;\n\n    return hasFnAttrOnCalledFunction(Kind);\n  }\n\n  /// Determine whether the return value has the given attribute. Supports\n  /// Attribute::AttrKind and StringRef as \\p AttrKind types.\n  template <typename AttrKind> bool hasRetAttrImpl(AttrKind Kind) const {\n    if (Attrs.hasAttribute(AttributeList::ReturnIndex, Kind))\n      return true;\n\n    // Look at the callee, if available.\n    if (const Function *F = getCalledFunction())\n      return F->getAttributes().hasAttribute(AttributeList::ReturnIndex, Kind);\n    return false;\n  }\n};\n\ntemplate <>\nstruct OperandTraits<CallBase> : public VariadicOperandTraits<CallBase, 1> {};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(CallBase, Value)\n\n//===----------------------------------------------------------------------===//\n//                           FuncletPadInst Class\n//===----------------------------------------------------------------------===//\nclass FuncletPadInst : public Instruction {\nprivate:\n  FuncletPadInst(const FuncletPadInst &CPI);\n\n  explicit FuncletPadInst(Instruction::FuncletPadOps Op, Value *ParentPad,\n                          ArrayRef<Value *> Args, unsigned Values,\n                          const Twine &NameStr, Instruction *InsertBefore);\n  explicit FuncletPadInst(Instruction::FuncletPadOps Op, Value *ParentPad,\n                          ArrayRef<Value *> Args, unsigned Values,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  void init(Value *ParentPad, ArrayRef<Value *> Args, const Twine &NameStr);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n  friend class CatchPadInst;\n  friend class CleanupPadInst;\n\n  FuncletPadInst *cloneImpl() const;\n\npublic:\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// getNumArgOperands - Return the number of funcletpad arguments.\n  ///\n  unsigned getNumArgOperands() const { return getNumOperands() - 1; }\n\n  /// Convenience accessors\n\n  /// Return the outer EH-pad this funclet is nested within.\n  ///\n  /// Note: This returns the associated CatchSwitchInst if this FuncletPadInst\n  /// is a CatchPadInst.\n  Value *getParentPad() const { return Op<-1>(); }\n  void setParentPad(Value *ParentPad) {\n    assert(ParentPad);\n    Op<-1>() = ParentPad;\n  }\n\n  /// getArgOperand/setArgOperand - Return/set the i-th funcletpad argument.\n  ///\n  Value *getArgOperand(unsigned i) const { return getOperand(i); }\n  void setArgOperand(unsigned i, Value *v) { setOperand(i, v); }\n\n  /// arg_operands - iteration adapter for range-for loops.\n  op_range arg_operands() { return op_range(op_begin(), op_end() - 1); }\n\n  /// arg_operands - iteration adapter for range-for loops.\n  const_op_range arg_operands() const {\n    return const_op_range(op_begin(), op_end() - 1);\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) { return I->isFuncletPad(); }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<FuncletPadInst>\n    : public VariadicOperandTraits<FuncletPadInst, /*MINARITY=*/1> {};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(FuncletPadInst, Value)\n\n} // end namespace llvm\n\n#endif // LLVM_IR_INSTRTYPES_H\n"}, "44": {"id": 44, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "content": "//===- llvm/Instructions.h - Instruction subclass definitions ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file exposes the class definitions of all of the subclasses of the\n// Instruction class.  This is meant to be an easy way to get access to all\n// instruction subclasses.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_INSTRUCTIONS_H\n#define LLVM_IR_INSTRUCTIONS_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/Bitfields.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/ADT/iterator.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/IR/Attributes.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/CallingConv.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/Constant.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/OperandTraits.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/IR/Use.h\"\n#include \"llvm/IR/User.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/Support/AtomicOrdering.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <iterator>\n\nnamespace llvm {\n\nclass APInt;\nclass ConstantInt;\nclass DataLayout;\nclass LLVMContext;\n\n//===----------------------------------------------------------------------===//\n//                                AllocaInst Class\n//===----------------------------------------------------------------------===//\n\n/// an instruction to allocate memory on the stack\nclass AllocaInst : public UnaryInstruction {\n  Type *AllocatedType;\n\n  using AlignmentField = AlignmentBitfieldElementT<0>;\n  using UsedWithInAllocaField = BoolBitfieldElementT<AlignmentField::NextBit>;\n  using SwiftErrorField = BoolBitfieldElementT<UsedWithInAllocaField::NextBit>;\n  static_assert(Bitfield::areContiguous<AlignmentField, UsedWithInAllocaField,\n                                        SwiftErrorField>(),\n                \"Bitfields must be contiguous\");\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  AllocaInst *cloneImpl() const;\n\npublic:\n  explicit AllocaInst(Type *Ty, unsigned AddrSpace, Value *ArraySize,\n                      const Twine &Name, Instruction *InsertBefore);\n  AllocaInst(Type *Ty, unsigned AddrSpace, Value *ArraySize,\n             const Twine &Name, BasicBlock *InsertAtEnd);\n\n  AllocaInst(Type *Ty, unsigned AddrSpace, const Twine &Name,\n             Instruction *InsertBefore);\n  AllocaInst(Type *Ty, unsigned AddrSpace,\n             const Twine &Name, BasicBlock *InsertAtEnd);\n\n  AllocaInst(Type *Ty, unsigned AddrSpace, Value *ArraySize, Align Align,\n             const Twine &Name = \"\", Instruction *InsertBefore = nullptr);\n  AllocaInst(Type *Ty, unsigned AddrSpace, Value *ArraySize, Align Align,\n             const Twine &Name, BasicBlock *InsertAtEnd);\n\n  /// Return true if there is an allocation size parameter to the allocation\n  /// instruction that is not 1.\n  bool isArrayAllocation() const;\n\n  /// Get the number of elements allocated. For a simple allocation of a single\n  /// element, this will return a constant 1 value.\n  const Value *getArraySize() const { return getOperand(0); }\n  Value *getArraySize() { return getOperand(0); }\n\n  /// Overload to return most specific pointer type.\n  PointerType *getType() const {\n    return cast<PointerType>(Instruction::getType());\n  }\n\n  /// Get allocation size in bits. Returns None if size can't be determined,\n  /// e.g. in case of a VLA.\n  Optional<TypeSize> getAllocationSizeInBits(const DataLayout &DL) const;\n\n  /// Return the type that is being allocated by the instruction.\n  Type *getAllocatedType() const { return AllocatedType; }\n  /// for use only in special circumstances that need to generically\n  /// transform a whole instruction (eg: IR linking and vectorization).\n  void setAllocatedType(Type *Ty) { AllocatedType = Ty; }\n\n  /// Return the alignment of the memory that is being allocated by the\n  /// instruction.\n  Align getAlign() const {\n    return Align(1ULL << getSubclassData<AlignmentField>());\n  }\n\n  void setAlignment(Align Align) {\n    setSubclassData<AlignmentField>(Log2(Align));\n  }\n\n  // FIXME: Remove this one transition to Align is over.\n  unsigned getAlignment() const { return getAlign().value(); }\n\n  /// Return true if this alloca is in the entry block of the function and is a\n  /// constant size. If so, the code generator will fold it into the\n  /// prolog/epilog code, so it is basically free.\n  bool isStaticAlloca() const;\n\n  /// Return true if this alloca is used as an inalloca argument to a call. Such\n  /// allocas are never considered static even if they are in the entry block.\n  bool isUsedWithInAlloca() const {\n    return getSubclassData<UsedWithInAllocaField>();\n  }\n\n  /// Specify whether this alloca is used to represent the arguments to a call.\n  void setUsedWithInAlloca(bool V) {\n    setSubclassData<UsedWithInAllocaField>(V);\n  }\n\n  /// Return true if this alloca is used as a swifterror argument to a call.\n  bool isSwiftError() const { return getSubclassData<SwiftErrorField>(); }\n  /// Specify whether this alloca is used to represent a swifterror.\n  void setSwiftError(bool V) { setSubclassData<SwiftErrorField>(V); }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::Alloca);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                LoadInst Class\n//===----------------------------------------------------------------------===//\n\n/// An instruction for reading from memory. This uses the SubclassData field in\n/// Value to store whether or not the load is volatile.\nclass LoadInst : public UnaryInstruction {\n  using VolatileField = BoolBitfieldElementT<0>;\n  using AlignmentField = AlignmentBitfieldElementT<VolatileField::NextBit>;\n  using OrderingField = AtomicOrderingBitfieldElementT<AlignmentField::NextBit>;\n  static_assert(\n      Bitfield::areContiguous<VolatileField, AlignmentField, OrderingField>(),\n      \"Bitfields must be contiguous\");\n\n  void AssertOK();\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  LoadInst *cloneImpl() const;\n\npublic:\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr,\n           Instruction *InsertBefore);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, BasicBlock *InsertAtEnd);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, bool isVolatile,\n           Instruction *InsertBefore);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, bool isVolatile,\n           BasicBlock *InsertAtEnd);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, bool isVolatile,\n           Align Align, Instruction *InsertBefore = nullptr);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, bool isVolatile,\n           Align Align, BasicBlock *InsertAtEnd);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, bool isVolatile,\n           Align Align, AtomicOrdering Order,\n           SyncScope::ID SSID = SyncScope::System,\n           Instruction *InsertBefore = nullptr);\n  LoadInst(Type *Ty, Value *Ptr, const Twine &NameStr, bool isVolatile,\n           Align Align, AtomicOrdering Order, SyncScope::ID SSID,\n           BasicBlock *InsertAtEnd);\n\n  /// Return true if this is a load from a volatile memory location.\n  bool isVolatile() const { return getSubclassData<VolatileField>(); }\n\n  /// Specify whether this is a volatile load or not.\n  void setVolatile(bool V) { setSubclassData<VolatileField>(V); }\n\n  /// Return the alignment of the access that is being performed.\n  /// FIXME: Remove this function once transition to Align is over.\n  /// Use getAlign() instead.\n  unsigned getAlignment() const { return getAlign().value(); }\n\n  /// Return the alignment of the access that is being performed.\n  Align getAlign() const {\n    return Align(1ULL << (getSubclassData<AlignmentField>()));\n  }\n\n  void setAlignment(Align Align) {\n    setSubclassData<AlignmentField>(Log2(Align));\n  }\n\n  /// Returns the ordering constraint of this load instruction.\n  AtomicOrdering getOrdering() const {\n    return getSubclassData<OrderingField>();\n  }\n  /// Sets the ordering constraint of this load instruction.  May not be Release\n  /// or AcquireRelease.\n  void setOrdering(AtomicOrdering Ordering) {\n    setSubclassData<OrderingField>(Ordering);\n  }\n\n  /// Returns the synchronization scope ID of this load instruction.\n  SyncScope::ID getSyncScopeID() const {\n    return SSID;\n  }\n\n  /// Sets the synchronization scope ID of this load instruction.\n  void setSyncScopeID(SyncScope::ID SSID) {\n    this->SSID = SSID;\n  }\n\n  /// Sets the ordering constraint and the synchronization scope ID of this load\n  /// instruction.\n  void setAtomic(AtomicOrdering Ordering,\n                 SyncScope::ID SSID = SyncScope::System) {\n    setOrdering(Ordering);\n    setSyncScopeID(SSID);\n  }\n\n  bool isSimple() const { return !isAtomic() && !isVolatile(); }\n\n  bool isUnordered() const {\n    return (getOrdering() == AtomicOrdering::NotAtomic ||\n            getOrdering() == AtomicOrdering::Unordered) &&\n           !isVolatile();\n  }\n\n  Value *getPointerOperand() { return getOperand(0); }\n  const Value *getPointerOperand() const { return getOperand(0); }\n  static unsigned getPointerOperandIndex() { return 0U; }\n  Type *getPointerOperandType() const { return getPointerOperand()->getType(); }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperandType()->getPointerAddressSpace();\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Load;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n\n  /// The synchronization scope ID of this load instruction.  Not quite enough\n  /// room in SubClassData for everything, so synchronization scope ID gets its\n  /// own field.\n  SyncScope::ID SSID;\n};\n\n//===----------------------------------------------------------------------===//\n//                                StoreInst Class\n//===----------------------------------------------------------------------===//\n\n/// An instruction for storing to memory.\nclass StoreInst : public Instruction {\n  using VolatileField = BoolBitfieldElementT<0>;\n  using AlignmentField = AlignmentBitfieldElementT<VolatileField::NextBit>;\n  using OrderingField = AtomicOrderingBitfieldElementT<AlignmentField::NextBit>;\n  static_assert(\n      Bitfield::areContiguous<VolatileField, AlignmentField, OrderingField>(),\n      \"Bitfields must be contiguous\");\n\n  void AssertOK();\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  StoreInst *cloneImpl() const;\n\npublic:\n  StoreInst(Value *Val, Value *Ptr, Instruction *InsertBefore);\n  StoreInst(Value *Val, Value *Ptr, BasicBlock *InsertAtEnd);\n  StoreInst(Value *Val, Value *Ptr, bool isVolatile, Instruction *InsertBefore);\n  StoreInst(Value *Val, Value *Ptr, bool isVolatile, BasicBlock *InsertAtEnd);\n  StoreInst(Value *Val, Value *Ptr, bool isVolatile, Align Align,\n            Instruction *InsertBefore = nullptr);\n  StoreInst(Value *Val, Value *Ptr, bool isVolatile, Align Align,\n            BasicBlock *InsertAtEnd);\n  StoreInst(Value *Val, Value *Ptr, bool isVolatile, Align Align,\n            AtomicOrdering Order, SyncScope::ID SSID = SyncScope::System,\n            Instruction *InsertBefore = nullptr);\n  StoreInst(Value *Val, Value *Ptr, bool isVolatile, Align Align,\n            AtomicOrdering Order, SyncScope::ID SSID, BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly two operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 2);\n  }\n\n  /// Return true if this is a store to a volatile memory location.\n  bool isVolatile() const { return getSubclassData<VolatileField>(); }\n\n  /// Specify whether this is a volatile store or not.\n  void setVolatile(bool V) { setSubclassData<VolatileField>(V); }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Return the alignment of the access that is being performed\n  /// FIXME: Remove this function once transition to Align is over.\n  /// Use getAlign() instead.\n  unsigned getAlignment() const { return getAlign().value(); }\n\n  Align getAlign() const {\n    return Align(1ULL << (getSubclassData<AlignmentField>()));\n  }\n\n  void setAlignment(Align Align) {\n    setSubclassData<AlignmentField>(Log2(Align));\n  }\n\n  /// Returns the ordering constraint of this store instruction.\n  AtomicOrdering getOrdering() const {\n    return getSubclassData<OrderingField>();\n  }\n\n  /// Sets the ordering constraint of this store instruction.  May not be\n  /// Acquire or AcquireRelease.\n  void setOrdering(AtomicOrdering Ordering) {\n    setSubclassData<OrderingField>(Ordering);\n  }\n\n  /// Returns the synchronization scope ID of this store instruction.\n  SyncScope::ID getSyncScopeID() const {\n    return SSID;\n  }\n\n  /// Sets the synchronization scope ID of this store instruction.\n  void setSyncScopeID(SyncScope::ID SSID) {\n    this->SSID = SSID;\n  }\n\n  /// Sets the ordering constraint and the synchronization scope ID of this\n  /// store instruction.\n  void setAtomic(AtomicOrdering Ordering,\n                 SyncScope::ID SSID = SyncScope::System) {\n    setOrdering(Ordering);\n    setSyncScopeID(SSID);\n  }\n\n  bool isSimple() const { return !isAtomic() && !isVolatile(); }\n\n  bool isUnordered() const {\n    return (getOrdering() == AtomicOrdering::NotAtomic ||\n            getOrdering() == AtomicOrdering::Unordered) &&\n           !isVolatile();\n  }\n\n  Value *getValueOperand() { return getOperand(0); }\n  const Value *getValueOperand() const { return getOperand(0); }\n\n  Value *getPointerOperand() { return getOperand(1); }\n  const Value *getPointerOperand() const { return getOperand(1); }\n  static unsigned getPointerOperandIndex() { return 1U; }\n  Type *getPointerOperandType() const { return getPointerOperand()->getType(); }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperandType()->getPointerAddressSpace();\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Store;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n\n  /// The synchronization scope ID of this store instruction.  Not quite enough\n  /// room in SubClassData for everything, so synchronization scope ID gets its\n  /// own field.\n  SyncScope::ID SSID;\n};\n\ntemplate <>\nstruct OperandTraits<StoreInst> : public FixedNumOperandTraits<StoreInst, 2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(StoreInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                                FenceInst Class\n//===----------------------------------------------------------------------===//\n\n/// An instruction for ordering other memory operations.\nclass FenceInst : public Instruction {\n  using OrderingField = AtomicOrderingBitfieldElementT<0>;\n\n  void Init(AtomicOrdering Ordering, SyncScope::ID SSID);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  FenceInst *cloneImpl() const;\n\npublic:\n  // Ordering may only be Acquire, Release, AcquireRelease, or\n  // SequentiallyConsistent.\n  FenceInst(LLVMContext &C, AtomicOrdering Ordering,\n            SyncScope::ID SSID = SyncScope::System,\n            Instruction *InsertBefore = nullptr);\n  FenceInst(LLVMContext &C, AtomicOrdering Ordering, SyncScope::ID SSID,\n            BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly zero operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 0);\n  }\n\n  /// Returns the ordering constraint of this fence instruction.\n  AtomicOrdering getOrdering() const {\n    return getSubclassData<OrderingField>();\n  }\n\n  /// Sets the ordering constraint of this fence instruction.  May only be\n  /// Acquire, Release, AcquireRelease, or SequentiallyConsistent.\n  void setOrdering(AtomicOrdering Ordering) {\n    setSubclassData<OrderingField>(Ordering);\n  }\n\n  /// Returns the synchronization scope ID of this fence instruction.\n  SyncScope::ID getSyncScopeID() const {\n    return SSID;\n  }\n\n  /// Sets the synchronization scope ID of this fence instruction.\n  void setSyncScopeID(SyncScope::ID SSID) {\n    this->SSID = SSID;\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Fence;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n\n  /// The synchronization scope ID of this fence instruction.  Not quite enough\n  /// room in SubClassData for everything, so synchronization scope ID gets its\n  /// own field.\n  SyncScope::ID SSID;\n};\n\n//===----------------------------------------------------------------------===//\n//                                AtomicCmpXchgInst Class\n//===----------------------------------------------------------------------===//\n\n/// An instruction that atomically checks whether a\n/// specified value is in a memory location, and, if it is, stores a new value\n/// there. The value returned by this instruction is a pair containing the\n/// original value as first element, and an i1 indicating success (true) or\n/// failure (false) as second element.\n///\nclass AtomicCmpXchgInst : public Instruction {\n  void Init(Value *Ptr, Value *Cmp, Value *NewVal, Align Align,\n            AtomicOrdering SuccessOrdering, AtomicOrdering FailureOrdering,\n            SyncScope::ID SSID);\n\n  template <unsigned Offset>\n  using AtomicOrderingBitfieldElement =\n      typename Bitfield::Element<AtomicOrdering, Offset, 3,\n                                 AtomicOrdering::LAST>;\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  AtomicCmpXchgInst *cloneImpl() const;\n\npublic:\n  AtomicCmpXchgInst(Value *Ptr, Value *Cmp, Value *NewVal, Align Alignment,\n                    AtomicOrdering SuccessOrdering,\n                    AtomicOrdering FailureOrdering, SyncScope::ID SSID,\n                    Instruction *InsertBefore = nullptr);\n  AtomicCmpXchgInst(Value *Ptr, Value *Cmp, Value *NewVal, Align Alignment,\n                    AtomicOrdering SuccessOrdering,\n                    AtomicOrdering FailureOrdering, SyncScope::ID SSID,\n                    BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly three operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 3);\n  }\n\n  using VolatileField = BoolBitfieldElementT<0>;\n  using WeakField = BoolBitfieldElementT<VolatileField::NextBit>;\n  using SuccessOrderingField =\n      AtomicOrderingBitfieldElementT<WeakField::NextBit>;\n  using FailureOrderingField =\n      AtomicOrderingBitfieldElementT<SuccessOrderingField::NextBit>;\n  using AlignmentField =\n      AlignmentBitfieldElementT<FailureOrderingField::NextBit>;\n  static_assert(\n      Bitfield::areContiguous<VolatileField, WeakField, SuccessOrderingField,\n                              FailureOrderingField, AlignmentField>(),\n      \"Bitfields must be contiguous\");\n\n  /// Return the alignment of the memory that is being allocated by the\n  /// instruction.\n  Align getAlign() const {\n    return Align(1ULL << getSubclassData<AlignmentField>());\n  }\n\n  void setAlignment(Align Align) {\n    setSubclassData<AlignmentField>(Log2(Align));\n  }\n\n  /// Return true if this is a cmpxchg from a volatile memory\n  /// location.\n  ///\n  bool isVolatile() const { return getSubclassData<VolatileField>(); }\n\n  /// Specify whether this is a volatile cmpxchg.\n  ///\n  void setVolatile(bool V) { setSubclassData<VolatileField>(V); }\n\n  /// Return true if this cmpxchg may spuriously fail.\n  bool isWeak() const { return getSubclassData<WeakField>(); }\n\n  void setWeak(bool IsWeak) { setSubclassData<WeakField>(IsWeak); }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Returns the success ordering constraint of this cmpxchg instruction.\n  AtomicOrdering getSuccessOrdering() const {\n    return getSubclassData<SuccessOrderingField>();\n  }\n\n  /// Sets the success ordering constraint of this cmpxchg instruction.\n  void setSuccessOrdering(AtomicOrdering Ordering) {\n    assert(Ordering != AtomicOrdering::NotAtomic &&\n           \"CmpXchg instructions can only be atomic.\");\n    setSubclassData<SuccessOrderingField>(Ordering);\n  }\n\n  /// Returns the failure ordering constraint of this cmpxchg instruction.\n  AtomicOrdering getFailureOrdering() const {\n    return getSubclassData<FailureOrderingField>();\n  }\n\n  /// Sets the failure ordering constraint of this cmpxchg instruction.\n  void setFailureOrdering(AtomicOrdering Ordering) {\n    assert(Ordering != AtomicOrdering::NotAtomic &&\n           \"CmpXchg instructions can only be atomic.\");\n    setSubclassData<FailureOrderingField>(Ordering);\n  }\n\n  /// Returns the synchronization scope ID of this cmpxchg instruction.\n  SyncScope::ID getSyncScopeID() const {\n    return SSID;\n  }\n\n  /// Sets the synchronization scope ID of this cmpxchg instruction.\n  void setSyncScopeID(SyncScope::ID SSID) {\n    this->SSID = SSID;\n  }\n\n  Value *getPointerOperand() { return getOperand(0); }\n  const Value *getPointerOperand() const { return getOperand(0); }\n  static unsigned getPointerOperandIndex() { return 0U; }\n\n  Value *getCompareOperand() { return getOperand(1); }\n  const Value *getCompareOperand() const { return getOperand(1); }\n\n  Value *getNewValOperand() { return getOperand(2); }\n  const Value *getNewValOperand() const { return getOperand(2); }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperand()->getType()->getPointerAddressSpace();\n  }\n\n  /// Returns the strongest permitted ordering on failure, given the\n  /// desired ordering on success.\n  ///\n  /// If the comparison in a cmpxchg operation fails, there is no atomic store\n  /// so release semantics cannot be provided. So this function drops explicit\n  /// Release requests from the AtomicOrdering. A SequentiallyConsistent\n  /// operation would remain SequentiallyConsistent.\n  static AtomicOrdering\n  getStrongestFailureOrdering(AtomicOrdering SuccessOrdering) {\n    switch (SuccessOrdering) {\n    default:\n      llvm_unreachable(\"invalid cmpxchg success ordering\");\n    case AtomicOrdering::Release:\n    case AtomicOrdering::Monotonic:\n      return AtomicOrdering::Monotonic;\n    case AtomicOrdering::AcquireRelease:\n    case AtomicOrdering::Acquire:\n      return AtomicOrdering::Acquire;\n    case AtomicOrdering::SequentiallyConsistent:\n      return AtomicOrdering::SequentiallyConsistent;\n    }\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::AtomicCmpXchg;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n\n  /// The synchronization scope ID of this cmpxchg instruction.  Not quite\n  /// enough room in SubClassData for everything, so synchronization scope ID\n  /// gets its own field.\n  SyncScope::ID SSID;\n};\n\ntemplate <>\nstruct OperandTraits<AtomicCmpXchgInst> :\n    public FixedNumOperandTraits<AtomicCmpXchgInst, 3> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(AtomicCmpXchgInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                                AtomicRMWInst Class\n//===----------------------------------------------------------------------===//\n\n/// an instruction that atomically reads a memory location,\n/// combines it with another value, and then stores the result back.  Returns\n/// the old value.\n///\nclass AtomicRMWInst : public Instruction {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  AtomicRMWInst *cloneImpl() const;\n\npublic:\n  /// This enumeration lists the possible modifications atomicrmw can make.  In\n  /// the descriptions, 'p' is the pointer to the instruction's memory location,\n  /// 'old' is the initial value of *p, and 'v' is the other value passed to the\n  /// instruction.  These instructions always return 'old'.\n  enum BinOp : unsigned {\n    /// *p = v\n    Xchg,\n    /// *p = old + v\n    Add,\n    /// *p = old - v\n    Sub,\n    /// *p = old & v\n    And,\n    /// *p = ~(old & v)\n    Nand,\n    /// *p = old | v\n    Or,\n    /// *p = old ^ v\n    Xor,\n    /// *p = old >signed v ? old : v\n    Max,\n    /// *p = old <signed v ? old : v\n    Min,\n    /// *p = old >unsigned v ? old : v\n    UMax,\n    /// *p = old <unsigned v ? old : v\n    UMin,\n\n    /// *p = old + v\n    FAdd,\n\n    /// *p = old - v\n    FSub,\n\n    FIRST_BINOP = Xchg,\n    LAST_BINOP = FSub,\n    BAD_BINOP\n  };\n\nprivate:\n  template <unsigned Offset>\n  using AtomicOrderingBitfieldElement =\n      typename Bitfield::Element<AtomicOrdering, Offset, 3,\n                                 AtomicOrdering::LAST>;\n\n  template <unsigned Offset>\n  using BinOpBitfieldElement =\n      typename Bitfield::Element<BinOp, Offset, 4, BinOp::LAST_BINOP>;\n\npublic:\n  AtomicRMWInst(BinOp Operation, Value *Ptr, Value *Val, Align Alignment,\n                AtomicOrdering Ordering, SyncScope::ID SSID,\n                Instruction *InsertBefore = nullptr);\n  AtomicRMWInst(BinOp Operation, Value *Ptr, Value *Val, Align Alignment,\n                AtomicOrdering Ordering, SyncScope::ID SSID,\n                BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly two operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 2);\n  }\n\n  using VolatileField = BoolBitfieldElementT<0>;\n  using AtomicOrderingField =\n      AtomicOrderingBitfieldElementT<VolatileField::NextBit>;\n  using OperationField = BinOpBitfieldElement<AtomicOrderingField::NextBit>;\n  using AlignmentField = AlignmentBitfieldElementT<OperationField::NextBit>;\n  static_assert(Bitfield::areContiguous<VolatileField, AtomicOrderingField,\n                                        OperationField, AlignmentField>(),\n                \"Bitfields must be contiguous\");\n\n  BinOp getOperation() const { return getSubclassData<OperationField>(); }\n\n  static StringRef getOperationName(BinOp Op);\n\n  static bool isFPOperation(BinOp Op) {\n    switch (Op) {\n    case AtomicRMWInst::FAdd:\n    case AtomicRMWInst::FSub:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  void setOperation(BinOp Operation) {\n    setSubclassData<OperationField>(Operation);\n  }\n\n  /// Return the alignment of the memory that is being allocated by the\n  /// instruction.\n  Align getAlign() const {\n    return Align(1ULL << getSubclassData<AlignmentField>());\n  }\n\n  void setAlignment(Align Align) {\n    setSubclassData<AlignmentField>(Log2(Align));\n  }\n\n  /// Return true if this is a RMW on a volatile memory location.\n  ///\n  bool isVolatile() const { return getSubclassData<VolatileField>(); }\n\n  /// Specify whether this is a volatile RMW or not.\n  ///\n  void setVolatile(bool V) { setSubclassData<VolatileField>(V); }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Returns the ordering constraint of this rmw instruction.\n  AtomicOrdering getOrdering() const {\n    return getSubclassData<AtomicOrderingField>();\n  }\n\n  /// Sets the ordering constraint of this rmw instruction.\n  void setOrdering(AtomicOrdering Ordering) {\n    assert(Ordering != AtomicOrdering::NotAtomic &&\n           \"atomicrmw instructions can only be atomic.\");\n    setSubclassData<AtomicOrderingField>(Ordering);\n  }\n\n  /// Returns the synchronization scope ID of this rmw instruction.\n  SyncScope::ID getSyncScopeID() const {\n    return SSID;\n  }\n\n  /// Sets the synchronization scope ID of this rmw instruction.\n  void setSyncScopeID(SyncScope::ID SSID) {\n    this->SSID = SSID;\n  }\n\n  Value *getPointerOperand() { return getOperand(0); }\n  const Value *getPointerOperand() const { return getOperand(0); }\n  static unsigned getPointerOperandIndex() { return 0U; }\n\n  Value *getValOperand() { return getOperand(1); }\n  const Value *getValOperand() const { return getOperand(1); }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperand()->getType()->getPointerAddressSpace();\n  }\n\n  bool isFloatingPointOperation() const {\n    return isFPOperation(getOperation());\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::AtomicRMW;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  void Init(BinOp Operation, Value *Ptr, Value *Val, Align Align,\n            AtomicOrdering Ordering, SyncScope::ID SSID);\n\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n\n  /// The synchronization scope ID of this rmw instruction.  Not quite enough\n  /// room in SubClassData for everything, so synchronization scope ID gets its\n  /// own field.\n  SyncScope::ID SSID;\n};\n\ntemplate <>\nstruct OperandTraits<AtomicRMWInst>\n    : public FixedNumOperandTraits<AtomicRMWInst,2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(AtomicRMWInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                             GetElementPtrInst Class\n//===----------------------------------------------------------------------===//\n\n// checkGEPType - Simple wrapper function to give a better assertion failure\n// message on bad indexes for a gep instruction.\n//\ninline Type *checkGEPType(Type *Ty) {\n  assert(Ty && \"Invalid GetElementPtrInst indices for type!\");\n  return Ty;\n}\n\n/// an instruction for type-safe pointer arithmetic to\n/// access elements of arrays and structs\n///\nclass GetElementPtrInst : public Instruction {\n  Type *SourceElementType;\n  Type *ResultElementType;\n\n  GetElementPtrInst(const GetElementPtrInst &GEPI);\n\n  /// Constructors - Create a getelementptr instruction with a base pointer an\n  /// list of indices. The first ctor can optionally insert before an existing\n  /// instruction, the second appends the new instruction to the specified\n  /// BasicBlock.\n  inline GetElementPtrInst(Type *PointeeType, Value *Ptr,\n                           ArrayRef<Value *> IdxList, unsigned Values,\n                           const Twine &NameStr, Instruction *InsertBefore);\n  inline GetElementPtrInst(Type *PointeeType, Value *Ptr,\n                           ArrayRef<Value *> IdxList, unsigned Values,\n                           const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  void init(Value *Ptr, ArrayRef<Value *> IdxList, const Twine &NameStr);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  GetElementPtrInst *cloneImpl() const;\n\npublic:\n  static GetElementPtrInst *Create(Type *PointeeType, Value *Ptr,\n                                   ArrayRef<Value *> IdxList,\n                                   const Twine &NameStr = \"\",\n                                   Instruction *InsertBefore = nullptr) {\n    unsigned Values = 1 + unsigned(IdxList.size());\n    if (!PointeeType)\n      PointeeType =\n          cast<PointerType>(Ptr->getType()->getScalarType())->getElementType();\n    else\n      assert(\n          PointeeType ==\n          cast<PointerType>(Ptr->getType()->getScalarType())->getElementType());\n    return new (Values) GetElementPtrInst(PointeeType, Ptr, IdxList, Values,\n                                          NameStr, InsertBefore);\n  }\n\n  static GetElementPtrInst *Create(Type *PointeeType, Value *Ptr,\n                                   ArrayRef<Value *> IdxList,\n                                   const Twine &NameStr,\n                                   BasicBlock *InsertAtEnd) {\n    unsigned Values = 1 + unsigned(IdxList.size());\n    if (!PointeeType)\n      PointeeType =\n          cast<PointerType>(Ptr->getType()->getScalarType())->getElementType();\n    else\n      assert(\n          PointeeType ==\n          cast<PointerType>(Ptr->getType()->getScalarType())->getElementType());\n    return new (Values) GetElementPtrInst(PointeeType, Ptr, IdxList, Values,\n                                          NameStr, InsertAtEnd);\n  }\n\n  /// Create an \"inbounds\" getelementptr. See the documentation for the\n  /// \"inbounds\" flag in LangRef.html for details.\n  static GetElementPtrInst *CreateInBounds(Value *Ptr,\n                                           ArrayRef<Value *> IdxList,\n                                           const Twine &NameStr = \"\",\n                                           Instruction *InsertBefore = nullptr){\n    return CreateInBounds(nullptr, Ptr, IdxList, NameStr, InsertBefore);\n  }\n\n  static GetElementPtrInst *\n  CreateInBounds(Type *PointeeType, Value *Ptr, ArrayRef<Value *> IdxList,\n                 const Twine &NameStr = \"\",\n                 Instruction *InsertBefore = nullptr) {\n    GetElementPtrInst *GEP =\n        Create(PointeeType, Ptr, IdxList, NameStr, InsertBefore);\n    GEP->setIsInBounds(true);\n    return GEP;\n  }\n\n  static GetElementPtrInst *CreateInBounds(Value *Ptr,\n                                           ArrayRef<Value *> IdxList,\n                                           const Twine &NameStr,\n                                           BasicBlock *InsertAtEnd) {\n    return CreateInBounds(nullptr, Ptr, IdxList, NameStr, InsertAtEnd);\n  }\n\n  static GetElementPtrInst *CreateInBounds(Type *PointeeType, Value *Ptr,\n                                           ArrayRef<Value *> IdxList,\n                                           const Twine &NameStr,\n                                           BasicBlock *InsertAtEnd) {\n    GetElementPtrInst *GEP =\n        Create(PointeeType, Ptr, IdxList, NameStr, InsertAtEnd);\n    GEP->setIsInBounds(true);\n    return GEP;\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  Type *getSourceElementType() const { return SourceElementType; }\n\n  void setSourceElementType(Type *Ty) { SourceElementType = Ty; }\n  void setResultElementType(Type *Ty) { ResultElementType = Ty; }\n\n  Type *getResultElementType() const {\n    assert(ResultElementType ==\n           cast<PointerType>(getType()->getScalarType())->getElementType());\n    return ResultElementType;\n  }\n\n  /// Returns the address space of this instruction's pointer type.\n  unsigned getAddressSpace() const {\n    // Note that this is always the same as the pointer operand's address space\n    // and that is cheaper to compute, so cheat here.\n    return getPointerAddressSpace();\n  }\n\n  /// Returns the result type of a getelementptr with the given source\n  /// element type and indexes.\n  ///\n  /// Null is returned if the indices are invalid for the specified\n  /// source element type.\n  static Type *getIndexedType(Type *Ty, ArrayRef<Value *> IdxList);\n  static Type *getIndexedType(Type *Ty, ArrayRef<Constant *> IdxList);\n  static Type *getIndexedType(Type *Ty, ArrayRef<uint64_t> IdxList);\n\n  /// Return the type of the element at the given index of an indexable\n  /// type.  This is equivalent to \"getIndexedType(Agg, {Zero, Idx})\".\n  ///\n  /// Returns null if the type can't be indexed, or the given index is not\n  /// legal for the given type.\n  static Type *getTypeAtIndex(Type *Ty, Value *Idx);\n  static Type *getTypeAtIndex(Type *Ty, uint64_t Idx);\n\n  inline op_iterator       idx_begin()       { return op_begin()+1; }\n  inline const_op_iterator idx_begin() const { return op_begin()+1; }\n  inline op_iterator       idx_end()         { return op_end(); }\n  inline const_op_iterator idx_end()   const { return op_end(); }\n\n  inline iterator_range<op_iterator> indices() {\n    return make_range(idx_begin(), idx_end());\n  }\n\n  inline iterator_range<const_op_iterator> indices() const {\n    return make_range(idx_begin(), idx_end());\n  }\n\n  Value *getPointerOperand() {\n    return getOperand(0);\n  }\n  const Value *getPointerOperand() const {\n    return getOperand(0);\n  }\n  static unsigned getPointerOperandIndex() {\n    return 0U;    // get index for modifying correct operand.\n  }\n\n  /// Method to return the pointer operand as a\n  /// PointerType.\n  Type *getPointerOperandType() const {\n    return getPointerOperand()->getType();\n  }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperandType()->getPointerAddressSpace();\n  }\n\n  /// Returns the pointer type returned by the GEP\n  /// instruction, which may be a vector of pointers.\n  static Type *getGEPReturnType(Type *ElTy, Value *Ptr,\n                                ArrayRef<Value *> IdxList) {\n    Type *PtrTy = PointerType::get(checkGEPType(getIndexedType(ElTy, IdxList)),\n                                   Ptr->getType()->getPointerAddressSpace());\n    // Vector GEP\n    if (auto *PtrVTy = dyn_cast<VectorType>(Ptr->getType())) {\n      ElementCount EltCount = PtrVTy->getElementCount();\n      return VectorType::get(PtrTy, EltCount);\n    }\n    for (Value *Index : IdxList)\n      if (auto *IndexVTy = dyn_cast<VectorType>(Index->getType())) {\n        ElementCount EltCount = IndexVTy->getElementCount();\n        return VectorType::get(PtrTy, EltCount);\n      }\n    // Scalar GEP\n    return PtrTy;\n  }\n\n  unsigned getNumIndices() const {  // Note: always non-negative\n    return getNumOperands() - 1;\n  }\n\n  bool hasIndices() const {\n    return getNumOperands() > 1;\n  }\n\n  /// Return true if all of the indices of this GEP are\n  /// zeros.  If so, the result pointer and the first operand have the same\n  /// value, just potentially different types.\n  bool hasAllZeroIndices() const;\n\n  /// Return true if all of the indices of this GEP are\n  /// constant integers.  If so, the result pointer and the first operand have\n  /// a constant offset between them.\n  bool hasAllConstantIndices() const;\n\n  /// Set or clear the inbounds flag on this GEP instruction.\n  /// See LangRef.html for the meaning of inbounds on a getelementptr.\n  void setIsInBounds(bool b = true);\n\n  /// Determine whether the GEP has the inbounds flag.\n  bool isInBounds() const;\n\n  /// Accumulate the constant address offset of this GEP if possible.\n  ///\n  /// This routine accepts an APInt into which it will accumulate the constant\n  /// offset of this GEP if the GEP is in fact constant. If the GEP is not\n  /// all-constant, it returns false and the value of the offset APInt is\n  /// undefined (it is *not* preserved!). The APInt passed into this routine\n  /// must be at least as wide as the IntPtr type for the address space of\n  /// the base GEP pointer.\n  bool accumulateConstantOffset(const DataLayout &DL, APInt &Offset) const;\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::GetElementPtr);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<GetElementPtrInst> :\n  public VariadicOperandTraits<GetElementPtrInst, 1> {\n};\n\nGetElementPtrInst::GetElementPtrInst(Type *PointeeType, Value *Ptr,\n                                     ArrayRef<Value *> IdxList, unsigned Values,\n                                     const Twine &NameStr,\n                                     Instruction *InsertBefore)\n    : Instruction(getGEPReturnType(PointeeType, Ptr, IdxList), GetElementPtr,\n                  OperandTraits<GetElementPtrInst>::op_end(this) - Values,\n                  Values, InsertBefore),\n      SourceElementType(PointeeType),\n      ResultElementType(getIndexedType(PointeeType, IdxList)) {\n  assert(ResultElementType ==\n         cast<PointerType>(getType()->getScalarType())->getElementType());\n  init(Ptr, IdxList, NameStr);\n}\n\nGetElementPtrInst::GetElementPtrInst(Type *PointeeType, Value *Ptr,\n                                     ArrayRef<Value *> IdxList, unsigned Values,\n                                     const Twine &NameStr,\n                                     BasicBlock *InsertAtEnd)\n    : Instruction(getGEPReturnType(PointeeType, Ptr, IdxList), GetElementPtr,\n                  OperandTraits<GetElementPtrInst>::op_end(this) - Values,\n                  Values, InsertAtEnd),\n      SourceElementType(PointeeType),\n      ResultElementType(getIndexedType(PointeeType, IdxList)) {\n  assert(ResultElementType ==\n         cast<PointerType>(getType()->getScalarType())->getElementType());\n  init(Ptr, IdxList, NameStr);\n}\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(GetElementPtrInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               ICmpInst Class\n//===----------------------------------------------------------------------===//\n\n/// This instruction compares its operands according to the predicate given\n/// to the constructor. It only operates on integers or pointers. The operands\n/// must be identical types.\n/// Represent an integer comparison operator.\nclass ICmpInst: public CmpInst {\n  void AssertOK() {\n    assert(isIntPredicate() &&\n           \"Invalid ICmp predicate value\");\n    assert(getOperand(0)->getType() == getOperand(1)->getType() &&\n          \"Both operands to ICmp instruction are not of the same type!\");\n    // Check that the operands are the right type\n    assert((getOperand(0)->getType()->isIntOrIntVectorTy() ||\n            getOperand(0)->getType()->isPtrOrPtrVectorTy()) &&\n           \"Invalid operand types for ICmp instruction\");\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical ICmpInst\n  ICmpInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics.\n  ICmpInst(\n    Instruction *InsertBefore,  ///< Where to insert\n    Predicate pred,  ///< The predicate to use for the comparison\n    Value *LHS,      ///< The left-hand-side of the expression\n    Value *RHS,      ///< The right-hand-side of the expression\n    const Twine &NameStr = \"\"  ///< Name of the instruction\n  ) : CmpInst(makeCmpResultType(LHS->getType()),\n              Instruction::ICmp, pred, LHS, RHS, NameStr,\n              InsertBefore) {\n#ifndef NDEBUG\n  AssertOK();\n#endif\n  }\n\n  /// Constructor with insert-at-end semantics.\n  ICmpInst(\n    BasicBlock &InsertAtEnd, ///< Block to insert into.\n    Predicate pred,  ///< The predicate to use for the comparison\n    Value *LHS,      ///< The left-hand-side of the expression\n    Value *RHS,      ///< The right-hand-side of the expression\n    const Twine &NameStr = \"\"  ///< Name of the instruction\n  ) : CmpInst(makeCmpResultType(LHS->getType()),\n              Instruction::ICmp, pred, LHS, RHS, NameStr,\n              &InsertAtEnd) {\n#ifndef NDEBUG\n  AssertOK();\n#endif\n  }\n\n  /// Constructor with no-insertion semantics\n  ICmpInst(\n    Predicate pred, ///< The predicate to use for the comparison\n    Value *LHS,     ///< The left-hand-side of the expression\n    Value *RHS,     ///< The right-hand-side of the expression\n    const Twine &NameStr = \"\" ///< Name of the instruction\n  ) : CmpInst(makeCmpResultType(LHS->getType()),\n              Instruction::ICmp, pred, LHS, RHS, NameStr) {\n#ifndef NDEBUG\n  AssertOK();\n#endif\n  }\n\n  /// For example, EQ->EQ, SLE->SLE, UGT->SGT, etc.\n  /// @returns the predicate that would be the result if the operand were\n  /// regarded as signed.\n  /// Return the signed version of the predicate\n  Predicate getSignedPredicate() const {\n    return getSignedPredicate(getPredicate());\n  }\n\n  /// This is a static version that you can use without an instruction.\n  /// Return the signed version of the predicate.\n  static Predicate getSignedPredicate(Predicate pred);\n\n  /// For example, EQ->EQ, SLE->ULE, UGT->UGT, etc.\n  /// @returns the predicate that would be the result if the operand were\n  /// regarded as unsigned.\n  /// Return the unsigned version of the predicate\n  Predicate getUnsignedPredicate() const {\n    return getUnsignedPredicate(getPredicate());\n  }\n\n  /// This is a static version that you can use without an instruction.\n  /// Return the unsigned version of the predicate.\n  static Predicate getUnsignedPredicate(Predicate pred);\n\n  /// Return true if this predicate is either EQ or NE.  This also\n  /// tests for commutativity.\n  static bool isEquality(Predicate P) {\n    return P == ICMP_EQ || P == ICMP_NE;\n  }\n\n  /// Return true if this predicate is either EQ or NE.  This also\n  /// tests for commutativity.\n  bool isEquality() const {\n    return isEquality(getPredicate());\n  }\n\n  /// @returns true if the predicate of this ICmpInst is commutative\n  /// Determine if this relation is commutative.\n  bool isCommutative() const { return isEquality(); }\n\n  /// Return true if the predicate is relational (not EQ or NE).\n  ///\n  bool isRelational() const {\n    return !isEquality();\n  }\n\n  /// Return true if the predicate is relational (not EQ or NE).\n  ///\n  static bool isRelational(Predicate P) {\n    return !isEquality(P);\n  }\n\n  /// Return true if the predicate is SGT or UGT.\n  ///\n  static bool isGT(Predicate P) {\n    return P == ICMP_SGT || P == ICMP_UGT;\n  }\n\n  /// Return true if the predicate is SLT or ULT.\n  ///\n  static bool isLT(Predicate P) {\n    return P == ICMP_SLT || P == ICMP_ULT;\n  }\n\n  /// Return true if the predicate is SGE or UGE.\n  ///\n  static bool isGE(Predicate P) {\n    return P == ICMP_SGE || P == ICMP_UGE;\n  }\n\n  /// Return true if the predicate is SLE or ULE.\n  ///\n  static bool isLE(Predicate P) {\n    return P == ICMP_SLE || P == ICMP_ULE;\n  }\n\n  /// Exchange the two operands to this instruction in such a way that it does\n  /// not modify the semantics of the instruction. The predicate value may be\n  /// changed to retain the same result if the predicate is order dependent\n  /// (e.g. ult).\n  /// Swap operands and adjust predicate.\n  void swapOperands() {\n    setPredicate(getSwappedPredicate());\n    Op<0>().swap(Op<1>());\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::ICmp;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                               FCmpInst Class\n//===----------------------------------------------------------------------===//\n\n/// This instruction compares its operands according to the predicate given\n/// to the constructor. It only operates on floating point values or packed\n/// vectors of floating point values. The operands must be identical types.\n/// Represents a floating point comparison operator.\nclass FCmpInst: public CmpInst {\n  void AssertOK() {\n    assert(isFPPredicate() && \"Invalid FCmp predicate value\");\n    assert(getOperand(0)->getType() == getOperand(1)->getType() &&\n           \"Both operands to FCmp instruction are not of the same type!\");\n    // Check that the operands are the right type\n    assert(getOperand(0)->getType()->isFPOrFPVectorTy() &&\n           \"Invalid operand types for FCmp instruction\");\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical FCmpInst\n  FCmpInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics.\n  FCmpInst(\n    Instruction *InsertBefore, ///< Where to insert\n    Predicate pred,  ///< The predicate to use for the comparison\n    Value *LHS,      ///< The left-hand-side of the expression\n    Value *RHS,      ///< The right-hand-side of the expression\n    const Twine &NameStr = \"\"  ///< Name of the instruction\n  ) : CmpInst(makeCmpResultType(LHS->getType()),\n              Instruction::FCmp, pred, LHS, RHS, NameStr,\n              InsertBefore) {\n    AssertOK();\n  }\n\n  /// Constructor with insert-at-end semantics.\n  FCmpInst(\n    BasicBlock &InsertAtEnd, ///< Block to insert into.\n    Predicate pred,  ///< The predicate to use for the comparison\n    Value *LHS,      ///< The left-hand-side of the expression\n    Value *RHS,      ///< The right-hand-side of the expression\n    const Twine &NameStr = \"\"  ///< Name of the instruction\n  ) : CmpInst(makeCmpResultType(LHS->getType()),\n              Instruction::FCmp, pred, LHS, RHS, NameStr,\n              &InsertAtEnd) {\n    AssertOK();\n  }\n\n  /// Constructor with no-insertion semantics\n  FCmpInst(\n    Predicate Pred, ///< The predicate to use for the comparison\n    Value *LHS,     ///< The left-hand-side of the expression\n    Value *RHS,     ///< The right-hand-side of the expression\n    const Twine &NameStr = \"\", ///< Name of the instruction\n    Instruction *FlagsSource = nullptr\n  ) : CmpInst(makeCmpResultType(LHS->getType()), Instruction::FCmp, Pred, LHS,\n              RHS, NameStr, nullptr, FlagsSource) {\n    AssertOK();\n  }\n\n  /// @returns true if the predicate of this instruction is EQ or NE.\n  /// Determine if this is an equality predicate.\n  static bool isEquality(Predicate Pred) {\n    return Pred == FCMP_OEQ || Pred == FCMP_ONE || Pred == FCMP_UEQ ||\n           Pred == FCMP_UNE;\n  }\n\n  /// @returns true if the predicate of this instruction is EQ or NE.\n  /// Determine if this is an equality predicate.\n  bool isEquality() const { return isEquality(getPredicate()); }\n\n  /// @returns true if the predicate of this instruction is commutative.\n  /// Determine if this is a commutative predicate.\n  bool isCommutative() const {\n    return isEquality() ||\n           getPredicate() == FCMP_FALSE ||\n           getPredicate() == FCMP_TRUE ||\n           getPredicate() == FCMP_ORD ||\n           getPredicate() == FCMP_UNO;\n  }\n\n  /// @returns true if the predicate is relational (not EQ or NE).\n  /// Determine if this a relational predicate.\n  bool isRelational() const { return !isEquality(); }\n\n  /// Exchange the two operands to this instruction in such a way that it does\n  /// not modify the semantics of the instruction. The predicate value may be\n  /// changed to retain the same result if the predicate is order dependent\n  /// (e.g. ult).\n  /// Swap operands and adjust predicate.\n  void swapOperands() {\n    setPredicate(getSwappedPredicate());\n    Op<0>().swap(Op<1>());\n  }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::FCmp;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n/// This class represents a function call, abstracting a target\n/// machine's calling convention.  This class uses low bit of the SubClassData\n/// field to indicate whether or not this is a tail call.  The rest of the bits\n/// hold the calling convention of the call.\n///\nclass CallInst : public CallBase {\n  CallInst(const CallInst &CI);\n\n  /// Construct a CallInst given a range of arguments.\n  /// Construct a CallInst from a range of arguments\n  inline CallInst(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                  ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr,\n                  Instruction *InsertBefore);\n\n  inline CallInst(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                  const Twine &NameStr, Instruction *InsertBefore)\n      : CallInst(Ty, Func, Args, None, NameStr, InsertBefore) {}\n\n  /// Construct a CallInst given a range of arguments.\n  /// Construct a CallInst from a range of arguments\n  inline CallInst(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                  ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr,\n                  BasicBlock *InsertAtEnd);\n\n  explicit CallInst(FunctionType *Ty, Value *F, const Twine &NameStr,\n                    Instruction *InsertBefore);\n\n  CallInst(FunctionType *ty, Value *F, const Twine &NameStr,\n           BasicBlock *InsertAtEnd);\n\n  void init(FunctionType *FTy, Value *Func, ArrayRef<Value *> Args,\n            ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr);\n  void init(FunctionType *FTy, Value *Func, const Twine &NameStr);\n\n  /// Compute the number of operands to allocate.\n  static int ComputeNumOperands(int NumArgs, int NumBundleInputs = 0) {\n    // We need one operand for the called function, plus the input operand\n    // counts provided.\n    return 1 + NumArgs + NumBundleInputs;\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  CallInst *cloneImpl() const;\n\npublic:\n  static CallInst *Create(FunctionType *Ty, Value *F, const Twine &NameStr = \"\",\n                          Instruction *InsertBefore = nullptr) {\n    return new (ComputeNumOperands(0)) CallInst(Ty, F, NameStr, InsertBefore);\n  }\n\n  static CallInst *Create(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                          const Twine &NameStr,\n                          Instruction *InsertBefore = nullptr) {\n    return new (ComputeNumOperands(Args.size()))\n        CallInst(Ty, Func, Args, None, NameStr, InsertBefore);\n  }\n\n  static CallInst *Create(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                          ArrayRef<OperandBundleDef> Bundles = None,\n                          const Twine &NameStr = \"\",\n                          Instruction *InsertBefore = nullptr) {\n    const int NumOperands =\n        ComputeNumOperands(Args.size(), CountBundleInputs(Bundles));\n    const unsigned DescriptorBytes = Bundles.size() * sizeof(BundleOpInfo);\n\n    return new (NumOperands, DescriptorBytes)\n        CallInst(Ty, Func, Args, Bundles, NameStr, InsertBefore);\n  }\n\n  static CallInst *Create(FunctionType *Ty, Value *F, const Twine &NameStr,\n                          BasicBlock *InsertAtEnd) {\n    return new (ComputeNumOperands(0)) CallInst(Ty, F, NameStr, InsertAtEnd);\n  }\n\n  static CallInst *Create(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return new (ComputeNumOperands(Args.size()))\n        CallInst(Ty, Func, Args, None, NameStr, InsertAtEnd);\n  }\n\n  static CallInst *Create(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                          ArrayRef<OperandBundleDef> Bundles,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    const int NumOperands =\n        ComputeNumOperands(Args.size(), CountBundleInputs(Bundles));\n    const unsigned DescriptorBytes = Bundles.size() * sizeof(BundleOpInfo);\n\n    return new (NumOperands, DescriptorBytes)\n        CallInst(Ty, Func, Args, Bundles, NameStr, InsertAtEnd);\n  }\n\n  static CallInst *Create(FunctionCallee Func, const Twine &NameStr = \"\",\n                          Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), NameStr,\n                  InsertBefore);\n  }\n\n  static CallInst *Create(FunctionCallee Func, ArrayRef<Value *> Args,\n                          ArrayRef<OperandBundleDef> Bundles = None,\n                          const Twine &NameStr = \"\",\n                          Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), Args, Bundles,\n                  NameStr, InsertBefore);\n  }\n\n  static CallInst *Create(FunctionCallee Func, ArrayRef<Value *> Args,\n                          const Twine &NameStr,\n                          Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), Args, NameStr,\n                  InsertBefore);\n  }\n\n  static CallInst *Create(FunctionCallee Func, const Twine &NameStr,\n                          BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), NameStr,\n                  InsertAtEnd);\n  }\n\n  static CallInst *Create(FunctionCallee Func, ArrayRef<Value *> Args,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), Args, NameStr,\n                  InsertAtEnd);\n  }\n\n  static CallInst *Create(FunctionCallee Func, ArrayRef<Value *> Args,\n                          ArrayRef<OperandBundleDef> Bundles,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), Args, Bundles,\n                  NameStr, InsertAtEnd);\n  }\n\n  /// Create a clone of \\p CI with a different set of operand bundles and\n  /// insert it before \\p InsertPt.\n  ///\n  /// The returned call instruction is identical \\p CI in every way except that\n  /// the operand bundles for the new instruction are set to the operand bundles\n  /// in \\p Bundles.\n  static CallInst *Create(CallInst *CI, ArrayRef<OperandBundleDef> Bundles,\n                          Instruction *InsertPt = nullptr);\n\n  /// Generate the IR for a call to malloc:\n  /// 1. Compute the malloc call's argument as the specified type's size,\n  ///    possibly multiplied by the array size if the array size is not\n  ///    constant 1.\n  /// 2. Call malloc with that argument.\n  /// 3. Bitcast the result of the malloc call to the specified type.\n  static Instruction *CreateMalloc(Instruction *InsertBefore, Type *IntPtrTy,\n                                   Type *AllocTy, Value *AllocSize,\n                                   Value *ArraySize = nullptr,\n                                   Function *MallocF = nullptr,\n                                   const Twine &Name = \"\");\n  static Instruction *CreateMalloc(BasicBlock *InsertAtEnd, Type *IntPtrTy,\n                                   Type *AllocTy, Value *AllocSize,\n                                   Value *ArraySize = nullptr,\n                                   Function *MallocF = nullptr,\n                                   const Twine &Name = \"\");\n  static Instruction *CreateMalloc(Instruction *InsertBefore, Type *IntPtrTy,\n                                   Type *AllocTy, Value *AllocSize,\n                                   Value *ArraySize = nullptr,\n                                   ArrayRef<OperandBundleDef> Bundles = None,\n                                   Function *MallocF = nullptr,\n                                   const Twine &Name = \"\");\n  static Instruction *CreateMalloc(BasicBlock *InsertAtEnd, Type *IntPtrTy,\n                                   Type *AllocTy, Value *AllocSize,\n                                   Value *ArraySize = nullptr,\n                                   ArrayRef<OperandBundleDef> Bundles = None,\n                                   Function *MallocF = nullptr,\n                                   const Twine &Name = \"\");\n  /// Generate the IR for a call to the builtin free function.\n  static Instruction *CreateFree(Value *Source, Instruction *InsertBefore);\n  static Instruction *CreateFree(Value *Source, BasicBlock *InsertAtEnd);\n  static Instruction *CreateFree(Value *Source,\n                                 ArrayRef<OperandBundleDef> Bundles,\n                                 Instruction *InsertBefore);\n  static Instruction *CreateFree(Value *Source,\n                                 ArrayRef<OperandBundleDef> Bundles,\n                                 BasicBlock *InsertAtEnd);\n\n  // Note that 'musttail' implies 'tail'.\n  enum TailCallKind : unsigned {\n    TCK_None = 0,\n    TCK_Tail = 1,\n    TCK_MustTail = 2,\n    TCK_NoTail = 3,\n    TCK_LAST = TCK_NoTail\n  };\n\n  using TailCallKindField = Bitfield::Element<TailCallKind, 0, 2, TCK_LAST>;\n  static_assert(\n      Bitfield::areContiguous<TailCallKindField, CallBase::CallingConvField>(),\n      \"Bitfields must be contiguous\");\n\n  TailCallKind getTailCallKind() const {\n    return getSubclassData<TailCallKindField>();\n  }\n\n  bool isTailCall() const {\n    TailCallKind Kind = getTailCallKind();\n    return Kind == TCK_Tail || Kind == TCK_MustTail;\n  }\n\n  bool isMustTailCall() const { return getTailCallKind() == TCK_MustTail; }\n\n  bool isNoTailCall() const { return getTailCallKind() == TCK_NoTail; }\n\n  void setTailCallKind(TailCallKind TCK) {\n    setSubclassData<TailCallKindField>(TCK);\n  }\n\n  void setTailCall(bool IsTc = true) {\n    setTailCallKind(IsTc ? TCK_Tail : TCK_None);\n  }\n\n  /// Return true if the call can return twice\n  bool canReturnTwice() const { return hasFnAttr(Attribute::ReturnsTwice); }\n  void setCanReturnTwice() {\n    addAttribute(AttributeList::FunctionIndex, Attribute::ReturnsTwice);\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Call;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\n  /// Updates profile metadata by scaling it by \\p S / \\p T.\n  void updateProfWeight(uint64_t S, uint64_t T);\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n};\n\nCallInst::CallInst(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                   ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr,\n                   BasicBlock *InsertAtEnd)\n    : CallBase(Ty->getReturnType(), Instruction::Call,\n               OperandTraits<CallBase>::op_end(this) -\n                   (Args.size() + CountBundleInputs(Bundles) + 1),\n               unsigned(Args.size() + CountBundleInputs(Bundles) + 1),\n               InsertAtEnd) {\n  init(Ty, Func, Args, Bundles, NameStr);\n}\n\nCallInst::CallInst(FunctionType *Ty, Value *Func, ArrayRef<Value *> Args,\n                   ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr,\n                   Instruction *InsertBefore)\n    : CallBase(Ty->getReturnType(), Instruction::Call,\n               OperandTraits<CallBase>::op_end(this) -\n                   (Args.size() + CountBundleInputs(Bundles) + 1),\n               unsigned(Args.size() + CountBundleInputs(Bundles) + 1),\n               InsertBefore) {\n  init(Ty, Func, Args, Bundles, NameStr);\n}\n\n//===----------------------------------------------------------------------===//\n//                               SelectInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents the LLVM 'select' instruction.\n///\nclass SelectInst : public Instruction {\n  SelectInst(Value *C, Value *S1, Value *S2, const Twine &NameStr,\n             Instruction *InsertBefore)\n    : Instruction(S1->getType(), Instruction::Select,\n                  &Op<0>(), 3, InsertBefore) {\n    init(C, S1, S2);\n    setName(NameStr);\n  }\n\n  SelectInst(Value *C, Value *S1, Value *S2, const Twine &NameStr,\n             BasicBlock *InsertAtEnd)\n    : Instruction(S1->getType(), Instruction::Select,\n                  &Op<0>(), 3, InsertAtEnd) {\n    init(C, S1, S2);\n    setName(NameStr);\n  }\n\n  void init(Value *C, Value *S1, Value *S2) {\n    assert(!areInvalidOperands(C, S1, S2) && \"Invalid operands for select\");\n    Op<0>() = C;\n    Op<1>() = S1;\n    Op<2>() = S2;\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  SelectInst *cloneImpl() const;\n\npublic:\n  static SelectInst *Create(Value *C, Value *S1, Value *S2,\n                            const Twine &NameStr = \"\",\n                            Instruction *InsertBefore = nullptr,\n                            Instruction *MDFrom = nullptr) {\n    SelectInst *Sel = new(3) SelectInst(C, S1, S2, NameStr, InsertBefore);\n    if (MDFrom)\n      Sel->copyMetadata(*MDFrom);\n    return Sel;\n  }\n\n  static SelectInst *Create(Value *C, Value *S1, Value *S2,\n                            const Twine &NameStr,\n                            BasicBlock *InsertAtEnd) {\n    return new(3) SelectInst(C, S1, S2, NameStr, InsertAtEnd);\n  }\n\n  const Value *getCondition() const { return Op<0>(); }\n  const Value *getTrueValue() const { return Op<1>(); }\n  const Value *getFalseValue() const { return Op<2>(); }\n  Value *getCondition() { return Op<0>(); }\n  Value *getTrueValue() { return Op<1>(); }\n  Value *getFalseValue() { return Op<2>(); }\n\n  void setCondition(Value *V) { Op<0>() = V; }\n  void setTrueValue(Value *V) { Op<1>() = V; }\n  void setFalseValue(Value *V) { Op<2>() = V; }\n\n  /// Swap the true and false values of the select instruction.\n  /// This doesn't swap prof metadata.\n  void swapValues() { Op<1>().swap(Op<2>()); }\n\n  /// Return a string if the specified operands are invalid\n  /// for a select operation, otherwise return null.\n  static const char *areInvalidOperands(Value *Cond, Value *True, Value *False);\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  OtherOps getOpcode() const {\n    return static_cast<OtherOps>(Instruction::getOpcode());\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Select;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<SelectInst> : public FixedNumOperandTraits<SelectInst, 3> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(SelectInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                                VAArgInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents the va_arg llvm instruction, which returns\n/// an argument of the specified type given a va_list and increments that list\n///\nclass VAArgInst : public UnaryInstruction {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  VAArgInst *cloneImpl() const;\n\npublic:\n  VAArgInst(Value *List, Type *Ty, const Twine &NameStr = \"\",\n             Instruction *InsertBefore = nullptr)\n    : UnaryInstruction(Ty, VAArg, List, InsertBefore) {\n    setName(NameStr);\n  }\n\n  VAArgInst(Value *List, Type *Ty, const Twine &NameStr,\n            BasicBlock *InsertAtEnd)\n    : UnaryInstruction(Ty, VAArg, List, InsertAtEnd) {\n    setName(NameStr);\n  }\n\n  Value *getPointerOperand() { return getOperand(0); }\n  const Value *getPointerOperand() const { return getOperand(0); }\n  static unsigned getPointerOperandIndex() { return 0U; }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == VAArg;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                ExtractElementInst Class\n//===----------------------------------------------------------------------===//\n\n/// This instruction extracts a single (scalar)\n/// element from a VectorType value\n///\nclass ExtractElementInst : public Instruction {\n  ExtractElementInst(Value *Vec, Value *Idx, const Twine &NameStr = \"\",\n                     Instruction *InsertBefore = nullptr);\n  ExtractElementInst(Value *Vec, Value *Idx, const Twine &NameStr,\n                     BasicBlock *InsertAtEnd);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  ExtractElementInst *cloneImpl() const;\n\npublic:\n  static ExtractElementInst *Create(Value *Vec, Value *Idx,\n                                   const Twine &NameStr = \"\",\n                                   Instruction *InsertBefore = nullptr) {\n    return new(2) ExtractElementInst(Vec, Idx, NameStr, InsertBefore);\n  }\n\n  static ExtractElementInst *Create(Value *Vec, Value *Idx,\n                                   const Twine &NameStr,\n                                   BasicBlock *InsertAtEnd) {\n    return new(2) ExtractElementInst(Vec, Idx, NameStr, InsertAtEnd);\n  }\n\n  /// Return true if an extractelement instruction can be\n  /// formed with the specified operands.\n  static bool isValidOperands(const Value *Vec, const Value *Idx);\n\n  Value *getVectorOperand() { return Op<0>(); }\n  Value *getIndexOperand() { return Op<1>(); }\n  const Value *getVectorOperand() const { return Op<0>(); }\n  const Value *getIndexOperand() const { return Op<1>(); }\n\n  VectorType *getVectorOperandType() const {\n    return cast<VectorType>(getVectorOperand()->getType());\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::ExtractElement;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<ExtractElementInst> :\n  public FixedNumOperandTraits<ExtractElementInst, 2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(ExtractElementInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                                InsertElementInst Class\n//===----------------------------------------------------------------------===//\n\n/// This instruction inserts a single (scalar)\n/// element into a VectorType value\n///\nclass InsertElementInst : public Instruction {\n  InsertElementInst(Value *Vec, Value *NewElt, Value *Idx,\n                    const Twine &NameStr = \"\",\n                    Instruction *InsertBefore = nullptr);\n  InsertElementInst(Value *Vec, Value *NewElt, Value *Idx, const Twine &NameStr,\n                    BasicBlock *InsertAtEnd);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  InsertElementInst *cloneImpl() const;\n\npublic:\n  static InsertElementInst *Create(Value *Vec, Value *NewElt, Value *Idx,\n                                   const Twine &NameStr = \"\",\n                                   Instruction *InsertBefore = nullptr) {\n    return new(3) InsertElementInst(Vec, NewElt, Idx, NameStr, InsertBefore);\n  }\n\n  static InsertElementInst *Create(Value *Vec, Value *NewElt, Value *Idx,\n                                   const Twine &NameStr,\n                                   BasicBlock *InsertAtEnd) {\n    return new(3) InsertElementInst(Vec, NewElt, Idx, NameStr, InsertAtEnd);\n  }\n\n  /// Return true if an insertelement instruction can be\n  /// formed with the specified operands.\n  static bool isValidOperands(const Value *Vec, const Value *NewElt,\n                              const Value *Idx);\n\n  /// Overload to return most specific vector type.\n  ///\n  VectorType *getType() const {\n    return cast<VectorType>(Instruction::getType());\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::InsertElement;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<InsertElementInst> :\n  public FixedNumOperandTraits<InsertElementInst, 3> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(InsertElementInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                           ShuffleVectorInst Class\n//===----------------------------------------------------------------------===//\n\nconstexpr int UndefMaskElem = -1;\n\n/// This instruction constructs a fixed permutation of two\n/// input vectors.\n///\n/// For each element of the result vector, the shuffle mask selects an element\n/// from one of the input vectors to copy to the result. Non-negative elements\n/// in the mask represent an index into the concatenated pair of input vectors.\n/// UndefMaskElem (-1) specifies that the result element is undefined.\n///\n/// For scalable vectors, all the elements of the mask must be 0 or -1. This\n/// requirement may be relaxed in the future.\nclass ShuffleVectorInst : public Instruction {\n  SmallVector<int, 4> ShuffleMask;\n  Constant *ShuffleMaskForBitcode;\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  ShuffleVectorInst *cloneImpl() const;\n\npublic:\n  ShuffleVectorInst(Value *V1, Value *V2, Value *Mask,\n                    const Twine &NameStr = \"\",\n                    Instruction *InsertBefor = nullptr);\n  ShuffleVectorInst(Value *V1, Value *V2, Value *Mask,\n                    const Twine &NameStr, BasicBlock *InsertAtEnd);\n  ShuffleVectorInst(Value *V1, Value *V2, ArrayRef<int> Mask,\n                    const Twine &NameStr = \"\",\n                    Instruction *InsertBefor = nullptr);\n  ShuffleVectorInst(Value *V1, Value *V2, ArrayRef<int> Mask,\n                    const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  void *operator new(size_t s) { return User::operator new(s, 2); }\n\n  /// Swap the operands and adjust the mask to preserve the semantics\n  /// of the instruction.\n  void commute();\n\n  /// Return true if a shufflevector instruction can be\n  /// formed with the specified operands.\n  static bool isValidOperands(const Value *V1, const Value *V2,\n                              const Value *Mask);\n  static bool isValidOperands(const Value *V1, const Value *V2,\n                              ArrayRef<int> Mask);\n\n  /// Overload to return most specific vector type.\n  ///\n  VectorType *getType() const {\n    return cast<VectorType>(Instruction::getType());\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Return the shuffle mask value of this instruction for the given element\n  /// index. Return UndefMaskElem if the element is undef.\n  int getMaskValue(unsigned Elt) const { return ShuffleMask[Elt]; }\n\n  /// Convert the input shuffle mask operand to a vector of integers. Undefined\n  /// elements of the mask are returned as UndefMaskElem.\n  static void getShuffleMask(const Constant *Mask,\n                             SmallVectorImpl<int> &Result);\n\n  /// Return the mask for this instruction as a vector of integers. Undefined\n  /// elements of the mask are returned as UndefMaskElem.\n  void getShuffleMask(SmallVectorImpl<int> &Result) const {\n    Result.assign(ShuffleMask.begin(), ShuffleMask.end());\n  }\n\n  /// Return the mask for this instruction, for use in bitcode.\n  ///\n  /// TODO: This is temporary until we decide a new bitcode encoding for\n  /// shufflevector.\n  Constant *getShuffleMaskForBitcode() const { return ShuffleMaskForBitcode; }\n\n  static Constant *convertShuffleMaskForBitcode(ArrayRef<int> Mask,\n                                                Type *ResultTy);\n\n  void setShuffleMask(ArrayRef<int> Mask);\n\n  ArrayRef<int> getShuffleMask() const { return ShuffleMask; }\n\n  /// Return true if this shuffle returns a vector with a different number of\n  /// elements than its source vectors.\n  /// Examples: shufflevector <4 x n> A, <4 x n> B, <1,2,3>\n  ///           shufflevector <4 x n> A, <4 x n> B, <1,2,3,4,5>\n  bool changesLength() const {\n    unsigned NumSourceElts = cast<VectorType>(Op<0>()->getType())\n                                 ->getElementCount()\n                                 .getKnownMinValue();\n    unsigned NumMaskElts = ShuffleMask.size();\n    return NumSourceElts != NumMaskElts;\n  }\n\n  /// Return true if this shuffle returns a vector with a greater number of\n  /// elements than its source vectors.\n  /// Example: shufflevector <2 x n> A, <2 x n> B, <1,2,3>\n  bool increasesLength() const {\n    unsigned NumSourceElts = cast<VectorType>(Op<0>()->getType())\n                                 ->getElementCount()\n                                 .getKnownMinValue();\n    unsigned NumMaskElts = ShuffleMask.size();\n    return NumSourceElts < NumMaskElts;\n  }\n\n  /// Return true if this shuffle mask chooses elements from exactly one source\n  /// vector.\n  /// Example: <7,5,undef,7>\n  /// This assumes that vector operands are the same length as the mask.\n  static bool isSingleSourceMask(ArrayRef<int> Mask);\n  static bool isSingleSourceMask(const Constant *Mask) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isSingleSourceMask(MaskAsInts);\n  }\n\n  /// Return true if this shuffle chooses elements from exactly one source\n  /// vector without changing the length of that vector.\n  /// Example: shufflevector <4 x n> A, <4 x n> B, <3,0,undef,3>\n  /// TODO: Optionally allow length-changing shuffles.\n  bool isSingleSource() const {\n    return !changesLength() && isSingleSourceMask(ShuffleMask);\n  }\n\n  /// Return true if this shuffle mask chooses elements from exactly one source\n  /// vector without lane crossings. A shuffle using this mask is not\n  /// necessarily a no-op because it may change the number of elements from its\n  /// input vectors or it may provide demanded bits knowledge via undef lanes.\n  /// Example: <undef,undef,2,3>\n  static bool isIdentityMask(ArrayRef<int> Mask);\n  static bool isIdentityMask(const Constant *Mask) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isIdentityMask(MaskAsInts);\n  }\n\n  /// Return true if this shuffle chooses elements from exactly one source\n  /// vector without lane crossings and does not change the number of elements\n  /// from its input vectors.\n  /// Example: shufflevector <4 x n> A, <4 x n> B, <4,undef,6,undef>\n  bool isIdentity() const {\n    return !changesLength() && isIdentityMask(ShuffleMask);\n  }\n\n  /// Return true if this shuffle lengthens exactly one source vector with\n  /// undefs in the high elements.\n  bool isIdentityWithPadding() const;\n\n  /// Return true if this shuffle extracts the first N elements of exactly one\n  /// source vector.\n  bool isIdentityWithExtract() const;\n\n  /// Return true if this shuffle concatenates its 2 source vectors. This\n  /// returns false if either input is undefined. In that case, the shuffle is\n  /// is better classified as an identity with padding operation.\n  bool isConcat() const;\n\n  /// Return true if this shuffle mask chooses elements from its source vectors\n  /// without lane crossings. A shuffle using this mask would be\n  /// equivalent to a vector select with a constant condition operand.\n  /// Example: <4,1,6,undef>\n  /// This returns false if the mask does not choose from both input vectors.\n  /// In that case, the shuffle is better classified as an identity shuffle.\n  /// This assumes that vector operands are the same length as the mask\n  /// (a length-changing shuffle can never be equivalent to a vector select).\n  static bool isSelectMask(ArrayRef<int> Mask);\n  static bool isSelectMask(const Constant *Mask) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isSelectMask(MaskAsInts);\n  }\n\n  /// Return true if this shuffle chooses elements from its source vectors\n  /// without lane crossings and all operands have the same number of elements.\n  /// In other words, this shuffle is equivalent to a vector select with a\n  /// constant condition operand.\n  /// Example: shufflevector <4 x n> A, <4 x n> B, <undef,1,6,3>\n  /// This returns false if the mask does not choose from both input vectors.\n  /// In that case, the shuffle is better classified as an identity shuffle.\n  /// TODO: Optionally allow length-changing shuffles.\n  bool isSelect() const {\n    return !changesLength() && isSelectMask(ShuffleMask);\n  }\n\n  /// Return true if this shuffle mask swaps the order of elements from exactly\n  /// one source vector.\n  /// Example: <7,6,undef,4>\n  /// This assumes that vector operands are the same length as the mask.\n  static bool isReverseMask(ArrayRef<int> Mask);\n  static bool isReverseMask(const Constant *Mask) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isReverseMask(MaskAsInts);\n  }\n\n  /// Return true if this shuffle swaps the order of elements from exactly\n  /// one source vector.\n  /// Example: shufflevector <4 x n> A, <4 x n> B, <3,undef,1,undef>\n  /// TODO: Optionally allow length-changing shuffles.\n  bool isReverse() const {\n    return !changesLength() && isReverseMask(ShuffleMask);\n  }\n\n  /// Return true if this shuffle mask chooses all elements with the same value\n  /// as the first element of exactly one source vector.\n  /// Example: <4,undef,undef,4>\n  /// This assumes that vector operands are the same length as the mask.\n  static bool isZeroEltSplatMask(ArrayRef<int> Mask);\n  static bool isZeroEltSplatMask(const Constant *Mask) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isZeroEltSplatMask(MaskAsInts);\n  }\n\n  /// Return true if all elements of this shuffle are the same value as the\n  /// first element of exactly one source vector without changing the length\n  /// of that vector.\n  /// Example: shufflevector <4 x n> A, <4 x n> B, <undef,0,undef,0>\n  /// TODO: Optionally allow length-changing shuffles.\n  /// TODO: Optionally allow splats from other elements.\n  bool isZeroEltSplat() const {\n    return !changesLength() && isZeroEltSplatMask(ShuffleMask);\n  }\n\n  /// Return true if this shuffle mask is a transpose mask.\n  /// Transpose vector masks transpose a 2xn matrix. They read corresponding\n  /// even- or odd-numbered vector elements from two n-dimensional source\n  /// vectors and write each result into consecutive elements of an\n  /// n-dimensional destination vector. Two shuffles are necessary to complete\n  /// the transpose, one for the even elements and another for the odd elements.\n  /// This description closely follows how the TRN1 and TRN2 AArch64\n  /// instructions operate.\n  ///\n  /// For example, a simple 2x2 matrix can be transposed with:\n  ///\n  ///   ; Original matrix\n  ///   m0 = < a, b >\n  ///   m1 = < c, d >\n  ///\n  ///   ; Transposed matrix\n  ///   t0 = < a, c > = shufflevector m0, m1, < 0, 2 >\n  ///   t1 = < b, d > = shufflevector m0, m1, < 1, 3 >\n  ///\n  /// For matrices having greater than n columns, the resulting nx2 transposed\n  /// matrix is stored in two result vectors such that one vector contains\n  /// interleaved elements from all the even-numbered rows and the other vector\n  /// contains interleaved elements from all the odd-numbered rows. For example,\n  /// a 2x4 matrix can be transposed with:\n  ///\n  ///   ; Original matrix\n  ///   m0 = < a, b, c, d >\n  ///   m1 = < e, f, g, h >\n  ///\n  ///   ; Transposed matrix\n  ///   t0 = < a, e, c, g > = shufflevector m0, m1 < 0, 4, 2, 6 >\n  ///   t1 = < b, f, d, h > = shufflevector m0, m1 < 1, 5, 3, 7 >\n  static bool isTransposeMask(ArrayRef<int> Mask);\n  static bool isTransposeMask(const Constant *Mask) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isTransposeMask(MaskAsInts);\n  }\n\n  /// Return true if this shuffle transposes the elements of its inputs without\n  /// changing the length of the vectors. This operation may also be known as a\n  /// merge or interleave. See the description for isTransposeMask() for the\n  /// exact specification.\n  /// Example: shufflevector <4 x n> A, <4 x n> B, <0,4,2,6>\n  bool isTranspose() const {\n    return !changesLength() && isTransposeMask(ShuffleMask);\n  }\n\n  /// Return true if this shuffle mask is an extract subvector mask.\n  /// A valid extract subvector mask returns a smaller vector from a single\n  /// source operand. The base extraction index is returned as well.\n  static bool isExtractSubvectorMask(ArrayRef<int> Mask, int NumSrcElts,\n                                     int &Index);\n  static bool isExtractSubvectorMask(const Constant *Mask, int NumSrcElts,\n                                     int &Index) {\n    assert(Mask->getType()->isVectorTy() && \"Shuffle needs vector constant.\");\n    // Not possible to express a shuffle mask for a scalable vector for this\n    // case.\n    if (isa<ScalableVectorType>(Mask->getType()))\n      return false;\n    SmallVector<int, 16> MaskAsInts;\n    getShuffleMask(Mask, MaskAsInts);\n    return isExtractSubvectorMask(MaskAsInts, NumSrcElts, Index);\n  }\n\n  /// Return true if this shuffle mask is an extract subvector mask.\n  bool isExtractSubvectorMask(int &Index) const {\n    // Not possible to express a shuffle mask for a scalable vector for this\n    // case.\n    if (isa<ScalableVectorType>(getType()))\n      return false;\n\n    int NumSrcElts =\n        cast<FixedVectorType>(Op<0>()->getType())->getNumElements();\n    return isExtractSubvectorMask(ShuffleMask, NumSrcElts, Index);\n  }\n\n  /// Change values in a shuffle permute mask assuming the two vector operands\n  /// of length InVecNumElts have swapped position.\n  static void commuteShuffleMask(MutableArrayRef<int> Mask,\n                                 unsigned InVecNumElts) {\n    for (int &Idx : Mask) {\n      if (Idx == -1)\n        continue;\n      Idx = Idx < (int)InVecNumElts ? Idx + InVecNumElts : Idx - InVecNumElts;\n      assert(Idx >= 0 && Idx < (int)InVecNumElts * 2 &&\n             \"shufflevector mask index out of range\");\n    }\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::ShuffleVector;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<ShuffleVectorInst>\n    : public FixedNumOperandTraits<ShuffleVectorInst, 2> {};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(ShuffleVectorInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                                ExtractValueInst Class\n//===----------------------------------------------------------------------===//\n\n/// This instruction extracts a struct member or array\n/// element value from an aggregate value.\n///\nclass ExtractValueInst : public UnaryInstruction {\n  SmallVector<unsigned, 4> Indices;\n\n  ExtractValueInst(const ExtractValueInst &EVI);\n\n  /// Constructors - Create a extractvalue instruction with a base aggregate\n  /// value and a list of indices.  The first ctor can optionally insert before\n  /// an existing instruction, the second appends the new instruction to the\n  /// specified BasicBlock.\n  inline ExtractValueInst(Value *Agg,\n                          ArrayRef<unsigned> Idxs,\n                          const Twine &NameStr,\n                          Instruction *InsertBefore);\n  inline ExtractValueInst(Value *Agg,\n                          ArrayRef<unsigned> Idxs,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  void init(ArrayRef<unsigned> Idxs, const Twine &NameStr);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  ExtractValueInst *cloneImpl() const;\n\npublic:\n  static ExtractValueInst *Create(Value *Agg,\n                                  ArrayRef<unsigned> Idxs,\n                                  const Twine &NameStr = \"\",\n                                  Instruction *InsertBefore = nullptr) {\n    return new\n      ExtractValueInst(Agg, Idxs, NameStr, InsertBefore);\n  }\n\n  static ExtractValueInst *Create(Value *Agg,\n                                  ArrayRef<unsigned> Idxs,\n                                  const Twine &NameStr,\n                                  BasicBlock *InsertAtEnd) {\n    return new ExtractValueInst(Agg, Idxs, NameStr, InsertAtEnd);\n  }\n\n  /// Returns the type of the element that would be extracted\n  /// with an extractvalue instruction with the specified parameters.\n  ///\n  /// Null is returned if the indices are invalid for the specified type.\n  static Type *getIndexedType(Type *Agg, ArrayRef<unsigned> Idxs);\n\n  using idx_iterator = const unsigned*;\n\n  inline idx_iterator idx_begin() const { return Indices.begin(); }\n  inline idx_iterator idx_end()   const { return Indices.end(); }\n  inline iterator_range<idx_iterator> indices() const {\n    return make_range(idx_begin(), idx_end());\n  }\n\n  Value *getAggregateOperand() {\n    return getOperand(0);\n  }\n  const Value *getAggregateOperand() const {\n    return getOperand(0);\n  }\n  static unsigned getAggregateOperandIndex() {\n    return 0U;                      // get index for modifying correct operand\n  }\n\n  ArrayRef<unsigned> getIndices() const {\n    return Indices;\n  }\n\n  unsigned getNumIndices() const {\n    return (unsigned)Indices.size();\n  }\n\n  bool hasIndices() const {\n    return true;\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::ExtractValue;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\nExtractValueInst::ExtractValueInst(Value *Agg,\n                                   ArrayRef<unsigned> Idxs,\n                                   const Twine &NameStr,\n                                   Instruction *InsertBefore)\n  : UnaryInstruction(checkGEPType(getIndexedType(Agg->getType(), Idxs)),\n                     ExtractValue, Agg, InsertBefore) {\n  init(Idxs, NameStr);\n}\n\nExtractValueInst::ExtractValueInst(Value *Agg,\n                                   ArrayRef<unsigned> Idxs,\n                                   const Twine &NameStr,\n                                   BasicBlock *InsertAtEnd)\n  : UnaryInstruction(checkGEPType(getIndexedType(Agg->getType(), Idxs)),\n                     ExtractValue, Agg, InsertAtEnd) {\n  init(Idxs, NameStr);\n}\n\n//===----------------------------------------------------------------------===//\n//                                InsertValueInst Class\n//===----------------------------------------------------------------------===//\n\n/// This instruction inserts a struct field of array element\n/// value into an aggregate value.\n///\nclass InsertValueInst : public Instruction {\n  SmallVector<unsigned, 4> Indices;\n\n  InsertValueInst(const InsertValueInst &IVI);\n\n  /// Constructors - Create a insertvalue instruction with a base aggregate\n  /// value, a value to insert, and a list of indices.  The first ctor can\n  /// optionally insert before an existing instruction, the second appends\n  /// the new instruction to the specified BasicBlock.\n  inline InsertValueInst(Value *Agg, Value *Val,\n                         ArrayRef<unsigned> Idxs,\n                         const Twine &NameStr,\n                         Instruction *InsertBefore);\n  inline InsertValueInst(Value *Agg, Value *Val,\n                         ArrayRef<unsigned> Idxs,\n                         const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  /// Constructors - These two constructors are convenience methods because one\n  /// and two index insertvalue instructions are so common.\n  InsertValueInst(Value *Agg, Value *Val, unsigned Idx,\n                  const Twine &NameStr = \"\",\n                  Instruction *InsertBefore = nullptr);\n  InsertValueInst(Value *Agg, Value *Val, unsigned Idx, const Twine &NameStr,\n                  BasicBlock *InsertAtEnd);\n\n  void init(Value *Agg, Value *Val, ArrayRef<unsigned> Idxs,\n            const Twine &NameStr);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  InsertValueInst *cloneImpl() const;\n\npublic:\n  // allocate space for exactly two operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 2);\n  }\n\n  static InsertValueInst *Create(Value *Agg, Value *Val,\n                                 ArrayRef<unsigned> Idxs,\n                                 const Twine &NameStr = \"\",\n                                 Instruction *InsertBefore = nullptr) {\n    return new InsertValueInst(Agg, Val, Idxs, NameStr, InsertBefore);\n  }\n\n  static InsertValueInst *Create(Value *Agg, Value *Val,\n                                 ArrayRef<unsigned> Idxs,\n                                 const Twine &NameStr,\n                                 BasicBlock *InsertAtEnd) {\n    return new InsertValueInst(Agg, Val, Idxs, NameStr, InsertAtEnd);\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  using idx_iterator = const unsigned*;\n\n  inline idx_iterator idx_begin() const { return Indices.begin(); }\n  inline idx_iterator idx_end()   const { return Indices.end(); }\n  inline iterator_range<idx_iterator> indices() const {\n    return make_range(idx_begin(), idx_end());\n  }\n\n  Value *getAggregateOperand() {\n    return getOperand(0);\n  }\n  const Value *getAggregateOperand() const {\n    return getOperand(0);\n  }\n  static unsigned getAggregateOperandIndex() {\n    return 0U;                      // get index for modifying correct operand\n  }\n\n  Value *getInsertedValueOperand() {\n    return getOperand(1);\n  }\n  const Value *getInsertedValueOperand() const {\n    return getOperand(1);\n  }\n  static unsigned getInsertedValueOperandIndex() {\n    return 1U;                      // get index for modifying correct operand\n  }\n\n  ArrayRef<unsigned> getIndices() const {\n    return Indices;\n  }\n\n  unsigned getNumIndices() const {\n    return (unsigned)Indices.size();\n  }\n\n  bool hasIndices() const {\n    return true;\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::InsertValue;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<InsertValueInst> :\n  public FixedNumOperandTraits<InsertValueInst, 2> {\n};\n\nInsertValueInst::InsertValueInst(Value *Agg,\n                                 Value *Val,\n                                 ArrayRef<unsigned> Idxs,\n                                 const Twine &NameStr,\n                                 Instruction *InsertBefore)\n  : Instruction(Agg->getType(), InsertValue,\n                OperandTraits<InsertValueInst>::op_begin(this),\n                2, InsertBefore) {\n  init(Agg, Val, Idxs, NameStr);\n}\n\nInsertValueInst::InsertValueInst(Value *Agg,\n                                 Value *Val,\n                                 ArrayRef<unsigned> Idxs,\n                                 const Twine &NameStr,\n                                 BasicBlock *InsertAtEnd)\n  : Instruction(Agg->getType(), InsertValue,\n                OperandTraits<InsertValueInst>::op_begin(this),\n                2, InsertAtEnd) {\n  init(Agg, Val, Idxs, NameStr);\n}\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(InsertValueInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               PHINode Class\n//===----------------------------------------------------------------------===//\n\n// PHINode - The PHINode class is used to represent the magical mystical PHI\n// node, that can not exist in nature, but can be synthesized in a computer\n// scientist's overactive imagination.\n//\nclass PHINode : public Instruction {\n  /// The number of operands actually allocated.  NumOperands is\n  /// the number actually in use.\n  unsigned ReservedSpace;\n\n  PHINode(const PHINode &PN);\n\n  explicit PHINode(Type *Ty, unsigned NumReservedValues,\n                   const Twine &NameStr = \"\",\n                   Instruction *InsertBefore = nullptr)\n    : Instruction(Ty, Instruction::PHI, nullptr, 0, InsertBefore),\n      ReservedSpace(NumReservedValues) {\n    setName(NameStr);\n    allocHungoffUses(ReservedSpace);\n  }\n\n  PHINode(Type *Ty, unsigned NumReservedValues, const Twine &NameStr,\n          BasicBlock *InsertAtEnd)\n    : Instruction(Ty, Instruction::PHI, nullptr, 0, InsertAtEnd),\n      ReservedSpace(NumReservedValues) {\n    setName(NameStr);\n    allocHungoffUses(ReservedSpace);\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  PHINode *cloneImpl() const;\n\n  // allocHungoffUses - this is more complicated than the generic\n  // User::allocHungoffUses, because we have to allocate Uses for the incoming\n  // values and pointers to the incoming blocks, all in one allocation.\n  void allocHungoffUses(unsigned N) {\n    User::allocHungoffUses(N, /* IsPhi */ true);\n  }\n\npublic:\n  /// Constructors - NumReservedValues is a hint for the number of incoming\n  /// edges that this phi node will have (use 0 if you really have no idea).\n  static PHINode *Create(Type *Ty, unsigned NumReservedValues,\n                         const Twine &NameStr = \"\",\n                         Instruction *InsertBefore = nullptr) {\n    return new PHINode(Ty, NumReservedValues, NameStr, InsertBefore);\n  }\n\n  static PHINode *Create(Type *Ty, unsigned NumReservedValues,\n                         const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return new PHINode(Ty, NumReservedValues, NameStr, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Block iterator interface. This provides access to the list of incoming\n  // basic blocks, which parallels the list of incoming values.\n\n  using block_iterator = BasicBlock **;\n  using const_block_iterator = BasicBlock * const *;\n\n  block_iterator block_begin() {\n    return reinterpret_cast<block_iterator>(op_begin() + ReservedSpace);\n  }\n\n  const_block_iterator block_begin() const {\n    return reinterpret_cast<const_block_iterator>(op_begin() + ReservedSpace);\n  }\n\n  block_iterator block_end() {\n    return block_begin() + getNumOperands();\n  }\n\n  const_block_iterator block_end() const {\n    return block_begin() + getNumOperands();\n  }\n\n  iterator_range<block_iterator> blocks() {\n    return make_range(block_begin(), block_end());\n  }\n\n  iterator_range<const_block_iterator> blocks() const {\n    return make_range(block_begin(), block_end());\n  }\n\n  op_range incoming_values() { return operands(); }\n\n  const_op_range incoming_values() const { return operands(); }\n\n  /// Return the number of incoming edges\n  ///\n  unsigned getNumIncomingValues() const { return getNumOperands(); }\n\n  /// Return incoming value number x\n  ///\n  Value *getIncomingValue(unsigned i) const {\n    return getOperand(i);\n  }\n  void setIncomingValue(unsigned i, Value *V) {\n    assert(V && \"PHI node got a null value!\");\n    assert(getType() == V->getType() &&\n           \"All operands to PHI node must be the same type as the PHI node!\");\n    setOperand(i, V);\n  }\n\n  static unsigned getOperandNumForIncomingValue(unsigned i) {\n    return i;\n  }\n\n  static unsigned getIncomingValueNumForOperand(unsigned i) {\n    return i;\n  }\n\n  /// Return incoming basic block number @p i.\n  ///\n  BasicBlock *getIncomingBlock(unsigned i) const {\n    return block_begin()[i];\n  }\n\n  /// Return incoming basic block corresponding\n  /// to an operand of the PHI.\n  ///\n  BasicBlock *getIncomingBlock(const Use &U) const {\n    assert(this == U.getUser() && \"Iterator doesn't point to PHI's Uses?\");\n    return getIncomingBlock(unsigned(&U - op_begin()));\n  }\n\n  /// Return incoming basic block corresponding\n  /// to value use iterator.\n  ///\n  BasicBlock *getIncomingBlock(Value::const_user_iterator I) const {\n    return getIncomingBlock(I.getUse());\n  }\n\n  void setIncomingBlock(unsigned i, BasicBlock *BB) {\n    assert(BB && \"PHI node got a null basic block!\");\n    block_begin()[i] = BB;\n  }\n\n  /// Replace every incoming basic block \\p Old to basic block \\p New.\n  void replaceIncomingBlockWith(const BasicBlock *Old, BasicBlock *New) {\n    assert(New && Old && \"PHI node got a null basic block!\");\n    for (unsigned Op = 0, NumOps = getNumOperands(); Op != NumOps; ++Op)\n      if (getIncomingBlock(Op) == Old)\n        setIncomingBlock(Op, New);\n  }\n\n  /// Add an incoming value to the end of the PHI list\n  ///\n  void addIncoming(Value *V, BasicBlock *BB) {\n    if (getNumOperands() == ReservedSpace)\n      growOperands();  // Get more space!\n    // Initialize some new operands.\n    setNumHungOffUseOperands(getNumOperands() + 1);\n    setIncomingValue(getNumOperands() - 1, V);\n    setIncomingBlock(getNumOperands() - 1, BB);\n  }\n\n  /// Remove an incoming value.  This is useful if a\n  /// predecessor basic block is deleted.  The value removed is returned.\n  ///\n  /// If the last incoming value for a PHI node is removed (and DeletePHIIfEmpty\n  /// is true), the PHI node is destroyed and any uses of it are replaced with\n  /// dummy values.  The only time there should be zero incoming values to a PHI\n  /// node is when the block is dead, so this strategy is sound.\n  ///\n  Value *removeIncomingValue(unsigned Idx, bool DeletePHIIfEmpty = true);\n\n  Value *removeIncomingValue(const BasicBlock *BB, bool DeletePHIIfEmpty=true) {\n    int Idx = getBasicBlockIndex(BB);\n    assert(Idx >= 0 && \"Invalid basic block argument to remove!\");\n    return removeIncomingValue(Idx, DeletePHIIfEmpty);\n  }\n\n  /// Return the first index of the specified basic\n  /// block in the value list for this PHI.  Returns -1 if no instance.\n  ///\n  int getBasicBlockIndex(const BasicBlock *BB) const {\n    for (unsigned i = 0, e = getNumOperands(); i != e; ++i)\n      if (block_begin()[i] == BB)\n        return i;\n    return -1;\n  }\n\n  Value *getIncomingValueForBlock(const BasicBlock *BB) const {\n    int Idx = getBasicBlockIndex(BB);\n    assert(Idx >= 0 && \"Invalid basic block argument!\");\n    return getIncomingValue(Idx);\n  }\n\n  /// Set every incoming value(s) for block \\p BB to \\p V.\n  void setIncomingValueForBlock(const BasicBlock *BB, Value *V) {\n    assert(BB && \"PHI node got a null basic block!\");\n    bool Found = false;\n    for (unsigned Op = 0, NumOps = getNumOperands(); Op != NumOps; ++Op)\n      if (getIncomingBlock(Op) == BB) {\n        Found = true;\n        setIncomingValue(Op, V);\n      }\n    (void)Found;\n    assert(Found && \"Invalid basic block argument to set!\");\n  }\n\n  /// If the specified PHI node always merges together the\n  /// same value, return the value, otherwise return null.\n  Value *hasConstantValue() const;\n\n  /// Whether the specified PHI node always merges\n  /// together the same value, assuming undefs are equal to a unique\n  /// non-undef value.\n  bool hasConstantOrUndefValue() const;\n\n  /// If the PHI node is complete which means all of its parent's predecessors\n  /// have incoming value in this PHI, return true, otherwise return false.\n  bool isComplete() const {\n    return llvm::all_of(predecessors(getParent()),\n                        [this](const BasicBlock *Pred) {\n                          return getBasicBlockIndex(Pred) >= 0;\n                        });\n  }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::PHI;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  void growOperands();\n};\n\ntemplate <>\nstruct OperandTraits<PHINode> : public HungoffOperandTraits<2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(PHINode, Value)\n\n//===----------------------------------------------------------------------===//\n//                           LandingPadInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// The landingpad instruction holds all of the information\n/// necessary to generate correct exception handling. The landingpad instruction\n/// cannot be moved from the top of a landing pad block, which itself is\n/// accessible only from the 'unwind' edge of an invoke. This uses the\n/// SubclassData field in Value to store whether or not the landingpad is a\n/// cleanup.\n///\nclass LandingPadInst : public Instruction {\n  using CleanupField = BoolBitfieldElementT<0>;\n\n  /// The number of operands actually allocated.  NumOperands is\n  /// the number actually in use.\n  unsigned ReservedSpace;\n\n  LandingPadInst(const LandingPadInst &LP);\n\npublic:\n  enum ClauseType { Catch, Filter };\n\nprivate:\n  explicit LandingPadInst(Type *RetTy, unsigned NumReservedValues,\n                          const Twine &NameStr, Instruction *InsertBefore);\n  explicit LandingPadInst(Type *RetTy, unsigned NumReservedValues,\n                          const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  // Allocate space for exactly zero operands.\n  void *operator new(size_t s) {\n    return User::operator new(s);\n  }\n\n  void growOperands(unsigned Size);\n  void init(unsigned NumReservedValues, const Twine &NameStr);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  LandingPadInst *cloneImpl() const;\n\npublic:\n  /// Constructors - NumReservedClauses is a hint for the number of incoming\n  /// clauses that this landingpad will have (use 0 if you really have no idea).\n  static LandingPadInst *Create(Type *RetTy, unsigned NumReservedClauses,\n                                const Twine &NameStr = \"\",\n                                Instruction *InsertBefore = nullptr);\n  static LandingPadInst *Create(Type *RetTy, unsigned NumReservedClauses,\n                                const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Return 'true' if this landingpad instruction is a\n  /// cleanup. I.e., it should be run when unwinding even if its landing pad\n  /// doesn't catch the exception.\n  bool isCleanup() const { return getSubclassData<CleanupField>(); }\n\n  /// Indicate that this landingpad instruction is a cleanup.\n  void setCleanup(bool V) { setSubclassData<CleanupField>(V); }\n\n  /// Add a catch or filter clause to the landing pad.\n  void addClause(Constant *ClauseVal);\n\n  /// Get the value of the clause at index Idx. Use isCatch/isFilter to\n  /// determine what type of clause this is.\n  Constant *getClause(unsigned Idx) const {\n    return cast<Constant>(getOperandList()[Idx]);\n  }\n\n  /// Return 'true' if the clause and index Idx is a catch clause.\n  bool isCatch(unsigned Idx) const {\n    return !isa<ArrayType>(getOperandList()[Idx]->getType());\n  }\n\n  /// Return 'true' if the clause and index Idx is a filter clause.\n  bool isFilter(unsigned Idx) const {\n    return isa<ArrayType>(getOperandList()[Idx]->getType());\n  }\n\n  /// Get the number of clauses for this landing pad.\n  unsigned getNumClauses() const { return getNumOperands(); }\n\n  /// Grow the size of the operand list to accommodate the new\n  /// number of clauses.\n  void reserveClauses(unsigned Size) { growOperands(Size); }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::LandingPad;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<LandingPadInst> : public HungoffOperandTraits<1> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(LandingPadInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               ReturnInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// Return a value (possibly void), from a function.  Execution\n/// does not continue in this function any longer.\n///\nclass ReturnInst : public Instruction {\n  ReturnInst(const ReturnInst &RI);\n\nprivate:\n  // ReturnInst constructors:\n  // ReturnInst()                  - 'ret void' instruction\n  // ReturnInst(    null)          - 'ret void' instruction\n  // ReturnInst(Value* X)          - 'ret X'    instruction\n  // ReturnInst(    null, Inst *I) - 'ret void' instruction, insert before I\n  // ReturnInst(Value* X, Inst *I) - 'ret X'    instruction, insert before I\n  // ReturnInst(    null, BB *B)   - 'ret void' instruction, insert @ end of B\n  // ReturnInst(Value* X, BB *B)   - 'ret X'    instruction, insert @ end of B\n  //\n  // NOTE: If the Value* passed is of type void then the constructor behaves as\n  // if it was passed NULL.\n  explicit ReturnInst(LLVMContext &C, Value *retVal = nullptr,\n                      Instruction *InsertBefore = nullptr);\n  ReturnInst(LLVMContext &C, Value *retVal, BasicBlock *InsertAtEnd);\n  explicit ReturnInst(LLVMContext &C, BasicBlock *InsertAtEnd);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  ReturnInst *cloneImpl() const;\n\npublic:\n  static ReturnInst* Create(LLVMContext &C, Value *retVal = nullptr,\n                            Instruction *InsertBefore = nullptr) {\n    return new(!!retVal) ReturnInst(C, retVal, InsertBefore);\n  }\n\n  static ReturnInst* Create(LLVMContext &C, Value *retVal,\n                            BasicBlock *InsertAtEnd) {\n    return new(!!retVal) ReturnInst(C, retVal, InsertAtEnd);\n  }\n\n  static ReturnInst* Create(LLVMContext &C, BasicBlock *InsertAtEnd) {\n    return new(0) ReturnInst(C, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Convenience accessor. Returns null if there is no return value.\n  Value *getReturnValue() const {\n    return getNumOperands() != 0 ? getOperand(0) : nullptr;\n  }\n\n  unsigned getNumSuccessors() const { return 0; }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::Ret);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  BasicBlock *getSuccessor(unsigned idx) const {\n    llvm_unreachable(\"ReturnInst has no successors!\");\n  }\n\n  void setSuccessor(unsigned idx, BasicBlock *B) {\n    llvm_unreachable(\"ReturnInst has no successors!\");\n  }\n};\n\ntemplate <>\nstruct OperandTraits<ReturnInst> : public VariadicOperandTraits<ReturnInst> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(ReturnInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               BranchInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// Conditional or Unconditional Branch instruction.\n///\nclass BranchInst : public Instruction {\n  /// Ops list - Branches are strange.  The operands are ordered:\n  ///  [Cond, FalseDest,] TrueDest.  This makes some accessors faster because\n  /// they don't have to check for cond/uncond branchness. These are mostly\n  /// accessed relative from op_end().\n  BranchInst(const BranchInst &BI);\n  // BranchInst constructors (where {B, T, F} are blocks, and C is a condition):\n  // BranchInst(BB *B)                           - 'br B'\n  // BranchInst(BB* T, BB *F, Value *C)          - 'br C, T, F'\n  // BranchInst(BB* B, Inst *I)                  - 'br B'        insert before I\n  // BranchInst(BB* T, BB *F, Value *C, Inst *I) - 'br C, T, F', insert before I\n  // BranchInst(BB* B, BB *I)                    - 'br B'        insert at end\n  // BranchInst(BB* T, BB *F, Value *C, BB *I)   - 'br C, T, F', insert at end\n  explicit BranchInst(BasicBlock *IfTrue, Instruction *InsertBefore = nullptr);\n  BranchInst(BasicBlock *IfTrue, BasicBlock *IfFalse, Value *Cond,\n             Instruction *InsertBefore = nullptr);\n  BranchInst(BasicBlock *IfTrue, BasicBlock *InsertAtEnd);\n  BranchInst(BasicBlock *IfTrue, BasicBlock *IfFalse, Value *Cond,\n             BasicBlock *InsertAtEnd);\n\n  void AssertOK();\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  BranchInst *cloneImpl() const;\n\npublic:\n  /// Iterator type that casts an operand to a basic block.\n  ///\n  /// This only makes sense because the successors are stored as adjacent\n  /// operands for branch instructions.\n  struct succ_op_iterator\n      : iterator_adaptor_base<succ_op_iterator, value_op_iterator,\n                              std::random_access_iterator_tag, BasicBlock *,\n                              ptrdiff_t, BasicBlock *, BasicBlock *> {\n    explicit succ_op_iterator(value_op_iterator I) : iterator_adaptor_base(I) {}\n\n    BasicBlock *operator*() const { return cast<BasicBlock>(*I); }\n    BasicBlock *operator->() const { return operator*(); }\n  };\n\n  /// The const version of `succ_op_iterator`.\n  struct const_succ_op_iterator\n      : iterator_adaptor_base<const_succ_op_iterator, const_value_op_iterator,\n                              std::random_access_iterator_tag,\n                              const BasicBlock *, ptrdiff_t, const BasicBlock *,\n                              const BasicBlock *> {\n    explicit const_succ_op_iterator(const_value_op_iterator I)\n        : iterator_adaptor_base(I) {}\n\n    const BasicBlock *operator*() const { return cast<BasicBlock>(*I); }\n    const BasicBlock *operator->() const { return operator*(); }\n  };\n\n  static BranchInst *Create(BasicBlock *IfTrue,\n                            Instruction *InsertBefore = nullptr) {\n    return new(1) BranchInst(IfTrue, InsertBefore);\n  }\n\n  static BranchInst *Create(BasicBlock *IfTrue, BasicBlock *IfFalse,\n                            Value *Cond, Instruction *InsertBefore = nullptr) {\n    return new(3) BranchInst(IfTrue, IfFalse, Cond, InsertBefore);\n  }\n\n  static BranchInst *Create(BasicBlock *IfTrue, BasicBlock *InsertAtEnd) {\n    return new(1) BranchInst(IfTrue, InsertAtEnd);\n  }\n\n  static BranchInst *Create(BasicBlock *IfTrue, BasicBlock *IfFalse,\n                            Value *Cond, BasicBlock *InsertAtEnd) {\n    return new(3) BranchInst(IfTrue, IfFalse, Cond, InsertAtEnd);\n  }\n\n  /// Transparently provide more efficient getOperand methods.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  bool isUnconditional() const { return getNumOperands() == 1; }\n  bool isConditional()   const { return getNumOperands() == 3; }\n\n  Value *getCondition() const {\n    assert(isConditional() && \"Cannot get condition of an uncond branch!\");\n    return Op<-3>();\n  }\n\n  void setCondition(Value *V) {\n    assert(isConditional() && \"Cannot set condition of unconditional branch!\");\n    Op<-3>() = V;\n  }\n\n  unsigned getNumSuccessors() const { return 1+isConditional(); }\n\n  BasicBlock *getSuccessor(unsigned i) const {\n    assert(i < getNumSuccessors() && \"Successor # out of range for Branch!\");\n    return cast_or_null<BasicBlock>((&Op<-1>() - i)->get());\n  }\n\n  void setSuccessor(unsigned idx, BasicBlock *NewSucc) {\n    assert(idx < getNumSuccessors() && \"Successor # out of range for Branch!\");\n    *(&Op<-1>() - idx) = NewSucc;\n  }\n\n  /// Swap the successors of this branch instruction.\n  ///\n  /// Swaps the successors of the branch instruction. This also swaps any\n  /// branch weight metadata associated with the instruction so that it\n  /// continues to map correctly to each operand.\n  void swapSuccessors();\n\n  iterator_range<succ_op_iterator> successors() {\n    return make_range(\n        succ_op_iterator(std::next(value_op_begin(), isConditional() ? 1 : 0)),\n        succ_op_iterator(value_op_end()));\n  }\n\n  iterator_range<const_succ_op_iterator> successors() const {\n    return make_range(const_succ_op_iterator(\n                          std::next(value_op_begin(), isConditional() ? 1 : 0)),\n                      const_succ_op_iterator(value_op_end()));\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::Br);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<BranchInst> : public VariadicOperandTraits<BranchInst, 1> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(BranchInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               SwitchInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// Multiway switch\n///\nclass SwitchInst : public Instruction {\n  unsigned ReservedSpace;\n\n  // Operand[0]    = Value to switch on\n  // Operand[1]    = Default basic block destination\n  // Operand[2n  ] = Value to match\n  // Operand[2n+1] = BasicBlock to go to on match\n  SwitchInst(const SwitchInst &SI);\n\n  /// Create a new switch instruction, specifying a value to switch on and a\n  /// default destination. The number of additional cases can be specified here\n  /// to make memory allocation more efficient. This constructor can also\n  /// auto-insert before another instruction.\n  SwitchInst(Value *Value, BasicBlock *Default, unsigned NumCases,\n             Instruction *InsertBefore);\n\n  /// Create a new switch instruction, specifying a value to switch on and a\n  /// default destination. The number of additional cases can be specified here\n  /// to make memory allocation more efficient. This constructor also\n  /// auto-inserts at the end of the specified BasicBlock.\n  SwitchInst(Value *Value, BasicBlock *Default, unsigned NumCases,\n             BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly zero operands\n  void *operator new(size_t s) {\n    return User::operator new(s);\n  }\n\n  void init(Value *Value, BasicBlock *Default, unsigned NumReserved);\n  void growOperands();\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  SwitchInst *cloneImpl() const;\n\npublic:\n  // -2\n  static const unsigned DefaultPseudoIndex = static_cast<unsigned>(~0L-1);\n\n  template <typename CaseHandleT> class CaseIteratorImpl;\n\n  /// A handle to a particular switch case. It exposes a convenient interface\n  /// to both the case value and the successor block.\n  ///\n  /// We define this as a template and instantiate it to form both a const and\n  /// non-const handle.\n  template <typename SwitchInstT, typename ConstantIntT, typename BasicBlockT>\n  class CaseHandleImpl {\n    // Directly befriend both const and non-const iterators.\n    friend class SwitchInst::CaseIteratorImpl<\n        CaseHandleImpl<SwitchInstT, ConstantIntT, BasicBlockT>>;\n\n  protected:\n    // Expose the switch type we're parameterized with to the iterator.\n    using SwitchInstType = SwitchInstT;\n\n    SwitchInstT *SI;\n    ptrdiff_t Index;\n\n    CaseHandleImpl() = default;\n    CaseHandleImpl(SwitchInstT *SI, ptrdiff_t Index) : SI(SI), Index(Index) {}\n\n  public:\n    /// Resolves case value for current case.\n    ConstantIntT *getCaseValue() const {\n      assert((unsigned)Index < SI->getNumCases() &&\n             \"Index out the number of cases.\");\n      return reinterpret_cast<ConstantIntT *>(SI->getOperand(2 + Index * 2));\n    }\n\n    /// Resolves successor for current case.\n    BasicBlockT *getCaseSuccessor() const {\n      assert(((unsigned)Index < SI->getNumCases() ||\n              (unsigned)Index == DefaultPseudoIndex) &&\n             \"Index out the number of cases.\");\n      return SI->getSuccessor(getSuccessorIndex());\n    }\n\n    /// Returns number of current case.\n    unsigned getCaseIndex() const { return Index; }\n\n    /// Returns successor index for current case successor.\n    unsigned getSuccessorIndex() const {\n      assert(((unsigned)Index == DefaultPseudoIndex ||\n              (unsigned)Index < SI->getNumCases()) &&\n             \"Index out the number of cases.\");\n      return (unsigned)Index != DefaultPseudoIndex ? Index + 1 : 0;\n    }\n\n    bool operator==(const CaseHandleImpl &RHS) const {\n      assert(SI == RHS.SI && \"Incompatible operators.\");\n      return Index == RHS.Index;\n    }\n  };\n\n  using ConstCaseHandle =\n      CaseHandleImpl<const SwitchInst, const ConstantInt, const BasicBlock>;\n\n  class CaseHandle\n      : public CaseHandleImpl<SwitchInst, ConstantInt, BasicBlock> {\n    friend class SwitchInst::CaseIteratorImpl<CaseHandle>;\n\n  public:\n    CaseHandle(SwitchInst *SI, ptrdiff_t Index) : CaseHandleImpl(SI, Index) {}\n\n    /// Sets the new value for current case.\n    void setValue(ConstantInt *V) {\n      assert((unsigned)Index < SI->getNumCases() &&\n             \"Index out the number of cases.\");\n      SI->setOperand(2 + Index*2, reinterpret_cast<Value*>(V));\n    }\n\n    /// Sets the new successor for current case.\n    void setSuccessor(BasicBlock *S) {\n      SI->setSuccessor(getSuccessorIndex(), S);\n    }\n  };\n\n  template <typename CaseHandleT>\n  class CaseIteratorImpl\n      : public iterator_facade_base<CaseIteratorImpl<CaseHandleT>,\n                                    std::random_access_iterator_tag,\n                                    CaseHandleT> {\n    using SwitchInstT = typename CaseHandleT::SwitchInstType;\n\n    CaseHandleT Case;\n\n  public:\n    /// Default constructed iterator is in an invalid state until assigned to\n    /// a case for a particular switch.\n    CaseIteratorImpl() = default;\n\n    /// Initializes case iterator for given SwitchInst and for given\n    /// case number.\n    CaseIteratorImpl(SwitchInstT *SI, unsigned CaseNum) : Case(SI, CaseNum) {}\n\n    /// Initializes case iterator for given SwitchInst and for given\n    /// successor index.\n    static CaseIteratorImpl fromSuccessorIndex(SwitchInstT *SI,\n                                               unsigned SuccessorIndex) {\n      assert(SuccessorIndex < SI->getNumSuccessors() &&\n             \"Successor index # out of range!\");\n      return SuccessorIndex != 0 ? CaseIteratorImpl(SI, SuccessorIndex - 1)\n                                 : CaseIteratorImpl(SI, DefaultPseudoIndex);\n    }\n\n    /// Support converting to the const variant. This will be a no-op for const\n    /// variant.\n    operator CaseIteratorImpl<ConstCaseHandle>() const {\n      return CaseIteratorImpl<ConstCaseHandle>(Case.SI, Case.Index);\n    }\n\n    CaseIteratorImpl &operator+=(ptrdiff_t N) {\n      // Check index correctness after addition.\n      // Note: Index == getNumCases() means end().\n      assert(Case.Index + N >= 0 &&\n             (unsigned)(Case.Index + N) <= Case.SI->getNumCases() &&\n             \"Case.Index out the number of cases.\");\n      Case.Index += N;\n      return *this;\n    }\n    CaseIteratorImpl &operator-=(ptrdiff_t N) {\n      // Check index correctness after subtraction.\n      // Note: Case.Index == getNumCases() means end().\n      assert(Case.Index - N >= 0 &&\n             (unsigned)(Case.Index - N) <= Case.SI->getNumCases() &&\n             \"Case.Index out the number of cases.\");\n      Case.Index -= N;\n      return *this;\n    }\n    ptrdiff_t operator-(const CaseIteratorImpl &RHS) const {\n      assert(Case.SI == RHS.Case.SI && \"Incompatible operators.\");\n      return Case.Index - RHS.Case.Index;\n    }\n    bool operator==(const CaseIteratorImpl &RHS) const {\n      return Case == RHS.Case;\n    }\n    bool operator<(const CaseIteratorImpl &RHS) const {\n      assert(Case.SI == RHS.Case.SI && \"Incompatible operators.\");\n      return Case.Index < RHS.Case.Index;\n    }\n    CaseHandleT &operator*() { return Case; }\n    const CaseHandleT &operator*() const { return Case; }\n  };\n\n  using CaseIt = CaseIteratorImpl<CaseHandle>;\n  using ConstCaseIt = CaseIteratorImpl<ConstCaseHandle>;\n\n  static SwitchInst *Create(Value *Value, BasicBlock *Default,\n                            unsigned NumCases,\n                            Instruction *InsertBefore = nullptr) {\n    return new SwitchInst(Value, Default, NumCases, InsertBefore);\n  }\n\n  static SwitchInst *Create(Value *Value, BasicBlock *Default,\n                            unsigned NumCases, BasicBlock *InsertAtEnd) {\n    return new SwitchInst(Value, Default, NumCases, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Accessor Methods for Switch stmt\n  Value *getCondition() const { return getOperand(0); }\n  void setCondition(Value *V) { setOperand(0, V); }\n\n  BasicBlock *getDefaultDest() const {\n    return cast<BasicBlock>(getOperand(1));\n  }\n\n  void setDefaultDest(BasicBlock *DefaultCase) {\n    setOperand(1, reinterpret_cast<Value*>(DefaultCase));\n  }\n\n  /// Return the number of 'cases' in this switch instruction, excluding the\n  /// default case.\n  unsigned getNumCases() const {\n    return getNumOperands()/2 - 1;\n  }\n\n  /// Returns a read/write iterator that points to the first case in the\n  /// SwitchInst.\n  CaseIt case_begin() {\n    return CaseIt(this, 0);\n  }\n\n  /// Returns a read-only iterator that points to the first case in the\n  /// SwitchInst.\n  ConstCaseIt case_begin() const {\n    return ConstCaseIt(this, 0);\n  }\n\n  /// Returns a read/write iterator that points one past the last in the\n  /// SwitchInst.\n  CaseIt case_end() {\n    return CaseIt(this, getNumCases());\n  }\n\n  /// Returns a read-only iterator that points one past the last in the\n  /// SwitchInst.\n  ConstCaseIt case_end() const {\n    return ConstCaseIt(this, getNumCases());\n  }\n\n  /// Iteration adapter for range-for loops.\n  iterator_range<CaseIt> cases() {\n    return make_range(case_begin(), case_end());\n  }\n\n  /// Constant iteration adapter for range-for loops.\n  iterator_range<ConstCaseIt> cases() const {\n    return make_range(case_begin(), case_end());\n  }\n\n  /// Returns an iterator that points to the default case.\n  /// Note: this iterator allows to resolve successor only. Attempt\n  /// to resolve case value causes an assertion.\n  /// Also note, that increment and decrement also causes an assertion and\n  /// makes iterator invalid.\n  CaseIt case_default() {\n    return CaseIt(this, DefaultPseudoIndex);\n  }\n  ConstCaseIt case_default() const {\n    return ConstCaseIt(this, DefaultPseudoIndex);\n  }\n\n  /// Search all of the case values for the specified constant. If it is\n  /// explicitly handled, return the case iterator of it, otherwise return\n  /// default case iterator to indicate that it is handled by the default\n  /// handler.\n  CaseIt findCaseValue(const ConstantInt *C) {\n    CaseIt I = llvm::find_if(\n        cases(), [C](CaseHandle &Case) { return Case.getCaseValue() == C; });\n    if (I != case_end())\n      return I;\n\n    return case_default();\n  }\n  ConstCaseIt findCaseValue(const ConstantInt *C) const {\n    ConstCaseIt I = llvm::find_if(cases(), [C](ConstCaseHandle &Case) {\n      return Case.getCaseValue() == C;\n    });\n    if (I != case_end())\n      return I;\n\n    return case_default();\n  }\n\n  /// Finds the unique case value for a given successor. Returns null if the\n  /// successor is not found, not unique, or is the default case.\n  ConstantInt *findCaseDest(BasicBlock *BB) {\n    if (BB == getDefaultDest())\n      return nullptr;\n\n    ConstantInt *CI = nullptr;\n    for (auto Case : cases()) {\n      if (Case.getCaseSuccessor() != BB)\n        continue;\n\n      if (CI)\n        return nullptr; // Multiple cases lead to BB.\n\n      CI = Case.getCaseValue();\n    }\n\n    return CI;\n  }\n\n  /// Add an entry to the switch instruction.\n  /// Note:\n  /// This action invalidates case_end(). Old case_end() iterator will\n  /// point to the added case.\n  void addCase(ConstantInt *OnVal, BasicBlock *Dest);\n\n  /// This method removes the specified case and its successor from the switch\n  /// instruction. Note that this operation may reorder the remaining cases at\n  /// index idx and above.\n  /// Note:\n  /// This action invalidates iterators for all cases following the one removed,\n  /// including the case_end() iterator. It returns an iterator for the next\n  /// case.\n  CaseIt removeCase(CaseIt I);\n\n  unsigned getNumSuccessors() const { return getNumOperands()/2; }\n  BasicBlock *getSuccessor(unsigned idx) const {\n    assert(idx < getNumSuccessors() &&\"Successor idx out of range for switch!\");\n    return cast<BasicBlock>(getOperand(idx*2+1));\n  }\n  void setSuccessor(unsigned idx, BasicBlock *NewSucc) {\n    assert(idx < getNumSuccessors() && \"Successor # out of range for switch!\");\n    setOperand(idx * 2 + 1, NewSucc);\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Switch;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n/// A wrapper class to simplify modification of SwitchInst cases along with\n/// their prof branch_weights metadata.\nclass SwitchInstProfUpdateWrapper {\n  SwitchInst &SI;\n  Optional<SmallVector<uint32_t, 8> > Weights = None;\n  bool Changed = false;\n\nprotected:\n  static MDNode *getProfBranchWeightsMD(const SwitchInst &SI);\n\n  MDNode *buildProfBranchWeightsMD();\n\n  void init();\n\npublic:\n  using CaseWeightOpt = Optional<uint32_t>;\n  SwitchInst *operator->() { return &SI; }\n  SwitchInst &operator*() { return SI; }\n  operator SwitchInst *() { return &SI; }\n\n  SwitchInstProfUpdateWrapper(SwitchInst &SI) : SI(SI) { init(); }\n\n  ~SwitchInstProfUpdateWrapper() {\n    if (Changed)\n      SI.setMetadata(LLVMContext::MD_prof, buildProfBranchWeightsMD());\n  }\n\n  /// Delegate the call to the underlying SwitchInst::removeCase() and remove\n  /// correspondent branch weight.\n  SwitchInst::CaseIt removeCase(SwitchInst::CaseIt I);\n\n  /// Delegate the call to the underlying SwitchInst::addCase() and set the\n  /// specified branch weight for the added case.\n  void addCase(ConstantInt *OnVal, BasicBlock *Dest, CaseWeightOpt W);\n\n  /// Delegate the call to the underlying SwitchInst::eraseFromParent() and mark\n  /// this object to not touch the underlying SwitchInst in destructor.\n  SymbolTableList<Instruction>::iterator eraseFromParent();\n\n  void setSuccessorWeight(unsigned idx, CaseWeightOpt W);\n  CaseWeightOpt getSuccessorWeight(unsigned idx);\n\n  static CaseWeightOpt getSuccessorWeight(const SwitchInst &SI, unsigned idx);\n};\n\ntemplate <>\nstruct OperandTraits<SwitchInst> : public HungoffOperandTraits<2> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(SwitchInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                             IndirectBrInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// Indirect Branch Instruction.\n///\nclass IndirectBrInst : public Instruction {\n  unsigned ReservedSpace;\n\n  // Operand[0]   = Address to jump to\n  // Operand[n+1] = n-th destination\n  IndirectBrInst(const IndirectBrInst &IBI);\n\n  /// Create a new indirectbr instruction, specifying an\n  /// Address to jump to.  The number of expected destinations can be specified\n  /// here to make memory allocation more efficient.  This constructor can also\n  /// autoinsert before another instruction.\n  IndirectBrInst(Value *Address, unsigned NumDests, Instruction *InsertBefore);\n\n  /// Create a new indirectbr instruction, specifying an\n  /// Address to jump to.  The number of expected destinations can be specified\n  /// here to make memory allocation more efficient.  This constructor also\n  /// autoinserts at the end of the specified BasicBlock.\n  IndirectBrInst(Value *Address, unsigned NumDests, BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly zero operands\n  void *operator new(size_t s) {\n    return User::operator new(s);\n  }\n\n  void init(Value *Address, unsigned NumDests);\n  void growOperands();\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  IndirectBrInst *cloneImpl() const;\n\npublic:\n  /// Iterator type that casts an operand to a basic block.\n  ///\n  /// This only makes sense because the successors are stored as adjacent\n  /// operands for indirectbr instructions.\n  struct succ_op_iterator\n      : iterator_adaptor_base<succ_op_iterator, value_op_iterator,\n                              std::random_access_iterator_tag, BasicBlock *,\n                              ptrdiff_t, BasicBlock *, BasicBlock *> {\n    explicit succ_op_iterator(value_op_iterator I) : iterator_adaptor_base(I) {}\n\n    BasicBlock *operator*() const { return cast<BasicBlock>(*I); }\n    BasicBlock *operator->() const { return operator*(); }\n  };\n\n  /// The const version of `succ_op_iterator`.\n  struct const_succ_op_iterator\n      : iterator_adaptor_base<const_succ_op_iterator, const_value_op_iterator,\n                              std::random_access_iterator_tag,\n                              const BasicBlock *, ptrdiff_t, const BasicBlock *,\n                              const BasicBlock *> {\n    explicit const_succ_op_iterator(const_value_op_iterator I)\n        : iterator_adaptor_base(I) {}\n\n    const BasicBlock *operator*() const { return cast<BasicBlock>(*I); }\n    const BasicBlock *operator->() const { return operator*(); }\n  };\n\n  static IndirectBrInst *Create(Value *Address, unsigned NumDests,\n                                Instruction *InsertBefore = nullptr) {\n    return new IndirectBrInst(Address, NumDests, InsertBefore);\n  }\n\n  static IndirectBrInst *Create(Value *Address, unsigned NumDests,\n                                BasicBlock *InsertAtEnd) {\n    return new IndirectBrInst(Address, NumDests, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors.\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Accessor Methods for IndirectBrInst instruction.\n  Value *getAddress() { return getOperand(0); }\n  const Value *getAddress() const { return getOperand(0); }\n  void setAddress(Value *V) { setOperand(0, V); }\n\n  /// return the number of possible destinations in this\n  /// indirectbr instruction.\n  unsigned getNumDestinations() const { return getNumOperands()-1; }\n\n  /// Return the specified destination.\n  BasicBlock *getDestination(unsigned i) { return getSuccessor(i); }\n  const BasicBlock *getDestination(unsigned i) const { return getSuccessor(i); }\n\n  /// Add a destination.\n  ///\n  void addDestination(BasicBlock *Dest);\n\n  /// This method removes the specified successor from the\n  /// indirectbr instruction.\n  void removeDestination(unsigned i);\n\n  unsigned getNumSuccessors() const { return getNumOperands()-1; }\n  BasicBlock *getSuccessor(unsigned i) const {\n    return cast<BasicBlock>(getOperand(i+1));\n  }\n  void setSuccessor(unsigned i, BasicBlock *NewSucc) {\n    setOperand(i + 1, NewSucc);\n  }\n\n  iterator_range<succ_op_iterator> successors() {\n    return make_range(succ_op_iterator(std::next(value_op_begin())),\n                      succ_op_iterator(value_op_end()));\n  }\n\n  iterator_range<const_succ_op_iterator> successors() const {\n    return make_range(const_succ_op_iterator(std::next(value_op_begin())),\n                      const_succ_op_iterator(value_op_end()));\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::IndirectBr;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<IndirectBrInst> : public HungoffOperandTraits<1> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(IndirectBrInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               InvokeInst Class\n//===----------------------------------------------------------------------===//\n\n/// Invoke instruction.  The SubclassData field is used to hold the\n/// calling convention of the call.\n///\nclass InvokeInst : public CallBase {\n  /// The number of operands for this call beyond the called function,\n  /// arguments, and operand bundles.\n  static constexpr int NumExtraOperands = 2;\n\n  /// The index from the end of the operand array to the normal destination.\n  static constexpr int NormalDestOpEndIdx = -3;\n\n  /// The index from the end of the operand array to the unwind destination.\n  static constexpr int UnwindDestOpEndIdx = -2;\n\n  InvokeInst(const InvokeInst &BI);\n\n  /// Construct an InvokeInst given a range of arguments.\n  ///\n  /// Construct an InvokeInst from a range of arguments\n  inline InvokeInst(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                    BasicBlock *IfException, ArrayRef<Value *> Args,\n                    ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                    const Twine &NameStr, Instruction *InsertBefore);\n\n  inline InvokeInst(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                    BasicBlock *IfException, ArrayRef<Value *> Args,\n                    ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                    const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  void init(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n            BasicBlock *IfException, ArrayRef<Value *> Args,\n            ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr);\n\n  /// Compute the number of operands to allocate.\n  static int ComputeNumOperands(int NumArgs, int NumBundleInputs = 0) {\n    // We need one operand for the called function, plus our extra operands and\n    // the input operand counts provided.\n    return 1 + NumExtraOperands + NumArgs + NumBundleInputs;\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  InvokeInst *cloneImpl() const;\n\npublic:\n  static InvokeInst *Create(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            const Twine &NameStr,\n                            Instruction *InsertBefore = nullptr) {\n    int NumOperands = ComputeNumOperands(Args.size());\n    return new (NumOperands)\n        InvokeInst(Ty, Func, IfNormal, IfException, Args, None, NumOperands,\n                   NameStr, InsertBefore);\n  }\n\n  static InvokeInst *Create(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles = None,\n                            const Twine &NameStr = \"\",\n                            Instruction *InsertBefore = nullptr) {\n    int NumOperands =\n        ComputeNumOperands(Args.size(), CountBundleInputs(Bundles));\n    unsigned DescriptorBytes = Bundles.size() * sizeof(BundleOpInfo);\n\n    return new (NumOperands, DescriptorBytes)\n        InvokeInst(Ty, Func, IfNormal, IfException, Args, Bundles, NumOperands,\n                   NameStr, InsertBefore);\n  }\n\n  static InvokeInst *Create(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    int NumOperands = ComputeNumOperands(Args.size());\n    return new (NumOperands)\n        InvokeInst(Ty, Func, IfNormal, IfException, Args, None, NumOperands,\n                   NameStr, InsertAtEnd);\n  }\n\n  static InvokeInst *Create(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles,\n                            const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    int NumOperands =\n        ComputeNumOperands(Args.size(), CountBundleInputs(Bundles));\n    unsigned DescriptorBytes = Bundles.size() * sizeof(BundleOpInfo);\n\n    return new (NumOperands, DescriptorBytes)\n        InvokeInst(Ty, Func, IfNormal, IfException, Args, Bundles, NumOperands,\n                   NameStr, InsertAtEnd);\n  }\n\n  static InvokeInst *Create(FunctionCallee Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            const Twine &NameStr,\n                            Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), IfNormal,\n                  IfException, Args, None, NameStr, InsertBefore);\n  }\n\n  static InvokeInst *Create(FunctionCallee Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles = None,\n                            const Twine &NameStr = \"\",\n                            Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), IfNormal,\n                  IfException, Args, Bundles, NameStr, InsertBefore);\n  }\n\n  static InvokeInst *Create(FunctionCallee Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), IfNormal,\n                  IfException, Args, NameStr, InsertAtEnd);\n  }\n\n  static InvokeInst *Create(FunctionCallee Func, BasicBlock *IfNormal,\n                            BasicBlock *IfException, ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles,\n                            const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), IfNormal,\n                  IfException, Args, Bundles, NameStr, InsertAtEnd);\n  }\n\n  /// Create a clone of \\p II with a different set of operand bundles and\n  /// insert it before \\p InsertPt.\n  ///\n  /// The returned invoke instruction is identical to \\p II in every way except\n  /// that the operand bundles for the new instruction are set to the operand\n  /// bundles in \\p Bundles.\n  static InvokeInst *Create(InvokeInst *II, ArrayRef<OperandBundleDef> Bundles,\n                            Instruction *InsertPt = nullptr);\n\n  // get*Dest - Return the destination basic blocks...\n  BasicBlock *getNormalDest() const {\n    return cast<BasicBlock>(Op<NormalDestOpEndIdx>());\n  }\n  BasicBlock *getUnwindDest() const {\n    return cast<BasicBlock>(Op<UnwindDestOpEndIdx>());\n  }\n  void setNormalDest(BasicBlock *B) {\n    Op<NormalDestOpEndIdx>() = reinterpret_cast<Value *>(B);\n  }\n  void setUnwindDest(BasicBlock *B) {\n    Op<UnwindDestOpEndIdx>() = reinterpret_cast<Value *>(B);\n  }\n\n  /// Get the landingpad instruction from the landing pad\n  /// block (the unwind destination).\n  LandingPadInst *getLandingPadInst() const;\n\n  BasicBlock *getSuccessor(unsigned i) const {\n    assert(i < 2 && \"Successor # out of range for invoke!\");\n    return i == 0 ? getNormalDest() : getUnwindDest();\n  }\n\n  void setSuccessor(unsigned i, BasicBlock *NewSucc) {\n    assert(i < 2 && \"Successor # out of range for invoke!\");\n    if (i == 0)\n      setNormalDest(NewSucc);\n    else\n      setUnwindDest(NewSucc);\n  }\n\n  unsigned getNumSuccessors() const { return 2; }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::Invoke);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n};\n\nInvokeInst::InvokeInst(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                       BasicBlock *IfException, ArrayRef<Value *> Args,\n                       ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                       const Twine &NameStr, Instruction *InsertBefore)\n    : CallBase(Ty->getReturnType(), Instruction::Invoke,\n               OperandTraits<CallBase>::op_end(this) - NumOperands, NumOperands,\n               InsertBefore) {\n  init(Ty, Func, IfNormal, IfException, Args, Bundles, NameStr);\n}\n\nInvokeInst::InvokeInst(FunctionType *Ty, Value *Func, BasicBlock *IfNormal,\n                       BasicBlock *IfException, ArrayRef<Value *> Args,\n                       ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                       const Twine &NameStr, BasicBlock *InsertAtEnd)\n    : CallBase(Ty->getReturnType(), Instruction::Invoke,\n               OperandTraits<CallBase>::op_end(this) - NumOperands, NumOperands,\n               InsertAtEnd) {\n  init(Ty, Func, IfNormal, IfException, Args, Bundles, NameStr);\n}\n\n//===----------------------------------------------------------------------===//\n//                              CallBrInst Class\n//===----------------------------------------------------------------------===//\n\n/// CallBr instruction, tracking function calls that may not return control but\n/// instead transfer it to a third location. The SubclassData field is used to\n/// hold the calling convention of the call.\n///\nclass CallBrInst : public CallBase {\n\n  unsigned NumIndirectDests;\n\n  CallBrInst(const CallBrInst &BI);\n\n  /// Construct a CallBrInst given a range of arguments.\n  ///\n  /// Construct a CallBrInst from a range of arguments\n  inline CallBrInst(FunctionType *Ty, Value *Func, BasicBlock *DefaultDest,\n                    ArrayRef<BasicBlock *> IndirectDests,\n                    ArrayRef<Value *> Args,\n                    ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                    const Twine &NameStr, Instruction *InsertBefore);\n\n  inline CallBrInst(FunctionType *Ty, Value *Func, BasicBlock *DefaultDest,\n                    ArrayRef<BasicBlock *> IndirectDests,\n                    ArrayRef<Value *> Args,\n                    ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                    const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  void init(FunctionType *FTy, Value *Func, BasicBlock *DefaultDest,\n            ArrayRef<BasicBlock *> IndirectDests, ArrayRef<Value *> Args,\n            ArrayRef<OperandBundleDef> Bundles, const Twine &NameStr);\n\n  /// Should the Indirect Destinations change, scan + update the Arg list.\n  void updateArgBlockAddresses(unsigned i, BasicBlock *B);\n\n  /// Compute the number of operands to allocate.\n  static int ComputeNumOperands(int NumArgs, int NumIndirectDests,\n                                int NumBundleInputs = 0) {\n    // We need one operand for the called function, plus our extra operands and\n    // the input operand counts provided.\n    return 2 + NumIndirectDests + NumArgs + NumBundleInputs;\n  }\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  CallBrInst *cloneImpl() const;\n\npublic:\n  static CallBrInst *Create(FunctionType *Ty, Value *Func,\n                            BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args, const Twine &NameStr,\n                            Instruction *InsertBefore = nullptr) {\n    int NumOperands = ComputeNumOperands(Args.size(), IndirectDests.size());\n    return new (NumOperands)\n        CallBrInst(Ty, Func, DefaultDest, IndirectDests, Args, None,\n                   NumOperands, NameStr, InsertBefore);\n  }\n\n  static CallBrInst *Create(FunctionType *Ty, Value *Func,\n                            BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles = None,\n                            const Twine &NameStr = \"\",\n                            Instruction *InsertBefore = nullptr) {\n    int NumOperands = ComputeNumOperands(Args.size(), IndirectDests.size(),\n                                         CountBundleInputs(Bundles));\n    unsigned DescriptorBytes = Bundles.size() * sizeof(BundleOpInfo);\n\n    return new (NumOperands, DescriptorBytes)\n        CallBrInst(Ty, Func, DefaultDest, IndirectDests, Args, Bundles,\n                   NumOperands, NameStr, InsertBefore);\n  }\n\n  static CallBrInst *Create(FunctionType *Ty, Value *Func,\n                            BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args, const Twine &NameStr,\n                            BasicBlock *InsertAtEnd) {\n    int NumOperands = ComputeNumOperands(Args.size(), IndirectDests.size());\n    return new (NumOperands)\n        CallBrInst(Ty, Func, DefaultDest, IndirectDests, Args, None,\n                   NumOperands, NameStr, InsertAtEnd);\n  }\n\n  static CallBrInst *Create(FunctionType *Ty, Value *Func,\n                            BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles,\n                            const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    int NumOperands = ComputeNumOperands(Args.size(), IndirectDests.size(),\n                                         CountBundleInputs(Bundles));\n    unsigned DescriptorBytes = Bundles.size() * sizeof(BundleOpInfo);\n\n    return new (NumOperands, DescriptorBytes)\n        CallBrInst(Ty, Func, DefaultDest, IndirectDests, Args, Bundles,\n                   NumOperands, NameStr, InsertAtEnd);\n  }\n\n  static CallBrInst *Create(FunctionCallee Func, BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args, const Twine &NameStr,\n                            Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), DefaultDest,\n                  IndirectDests, Args, NameStr, InsertBefore);\n  }\n\n  static CallBrInst *Create(FunctionCallee Func, BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles = None,\n                            const Twine &NameStr = \"\",\n                            Instruction *InsertBefore = nullptr) {\n    return Create(Func.getFunctionType(), Func.getCallee(), DefaultDest,\n                  IndirectDests, Args, Bundles, NameStr, InsertBefore);\n  }\n\n  static CallBrInst *Create(FunctionCallee Func, BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args, const Twine &NameStr,\n                            BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), DefaultDest,\n                  IndirectDests, Args, NameStr, InsertAtEnd);\n  }\n\n  static CallBrInst *Create(FunctionCallee Func,\n                            BasicBlock *DefaultDest,\n                            ArrayRef<BasicBlock *> IndirectDests,\n                            ArrayRef<Value *> Args,\n                            ArrayRef<OperandBundleDef> Bundles,\n                            const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    return Create(Func.getFunctionType(), Func.getCallee(), DefaultDest,\n                  IndirectDests, Args, Bundles, NameStr, InsertAtEnd);\n  }\n\n  /// Create a clone of \\p CBI with a different set of operand bundles and\n  /// insert it before \\p InsertPt.\n  ///\n  /// The returned callbr instruction is identical to \\p CBI in every way\n  /// except that the operand bundles for the new instruction are set to the\n  /// operand bundles in \\p Bundles.\n  static CallBrInst *Create(CallBrInst *CBI,\n                            ArrayRef<OperandBundleDef> Bundles,\n                            Instruction *InsertPt = nullptr);\n\n  /// Return the number of callbr indirect dest labels.\n  ///\n  unsigned getNumIndirectDests() const { return NumIndirectDests; }\n\n  /// getIndirectDestLabel - Return the i-th indirect dest label.\n  ///\n  Value *getIndirectDestLabel(unsigned i) const {\n    assert(i < getNumIndirectDests() && \"Out of bounds!\");\n    return getOperand(i + getNumArgOperands() + getNumTotalBundleOperands() +\n                      1);\n  }\n\n  Value *getIndirectDestLabelUse(unsigned i) const {\n    assert(i < getNumIndirectDests() && \"Out of bounds!\");\n    return getOperandUse(i + getNumArgOperands() + getNumTotalBundleOperands() +\n                         1);\n  }\n\n  // Return the destination basic blocks...\n  BasicBlock *getDefaultDest() const {\n    return cast<BasicBlock>(*(&Op<-1>() - getNumIndirectDests() - 1));\n  }\n  BasicBlock *getIndirectDest(unsigned i) const {\n    return cast_or_null<BasicBlock>(*(&Op<-1>() - getNumIndirectDests() + i));\n  }\n  SmallVector<BasicBlock *, 16> getIndirectDests() const {\n    SmallVector<BasicBlock *, 16> IndirectDests;\n    for (unsigned i = 0, e = getNumIndirectDests(); i < e; ++i)\n      IndirectDests.push_back(getIndirectDest(i));\n    return IndirectDests;\n  }\n  void setDefaultDest(BasicBlock *B) {\n    *(&Op<-1>() - getNumIndirectDests() - 1) = reinterpret_cast<Value *>(B);\n  }\n  void setIndirectDest(unsigned i, BasicBlock *B) {\n    updateArgBlockAddresses(i, B);\n    *(&Op<-1>() - getNumIndirectDests() + i) = reinterpret_cast<Value *>(B);\n  }\n\n  BasicBlock *getSuccessor(unsigned i) const {\n    assert(i < getNumSuccessors() + 1 &&\n           \"Successor # out of range for callbr!\");\n    return i == 0 ? getDefaultDest() : getIndirectDest(i - 1);\n  }\n\n  void setSuccessor(unsigned i, BasicBlock *NewSucc) {\n    assert(i < getNumIndirectDests() + 1 &&\n           \"Successor # out of range for callbr!\");\n    return i == 0 ? setDefaultDest(NewSucc) : setIndirectDest(i - 1, NewSucc);\n  }\n\n  unsigned getNumSuccessors() const { return getNumIndirectDests() + 1; }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::CallBr);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n};\n\nCallBrInst::CallBrInst(FunctionType *Ty, Value *Func, BasicBlock *DefaultDest,\n                       ArrayRef<BasicBlock *> IndirectDests,\n                       ArrayRef<Value *> Args,\n                       ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                       const Twine &NameStr, Instruction *InsertBefore)\n    : CallBase(Ty->getReturnType(), Instruction::CallBr,\n               OperandTraits<CallBase>::op_end(this) - NumOperands, NumOperands,\n               InsertBefore) {\n  init(Ty, Func, DefaultDest, IndirectDests, Args, Bundles, NameStr);\n}\n\nCallBrInst::CallBrInst(FunctionType *Ty, Value *Func, BasicBlock *DefaultDest,\n                       ArrayRef<BasicBlock *> IndirectDests,\n                       ArrayRef<Value *> Args,\n                       ArrayRef<OperandBundleDef> Bundles, int NumOperands,\n                       const Twine &NameStr, BasicBlock *InsertAtEnd)\n    : CallBase(Ty->getReturnType(), Instruction::CallBr,\n               OperandTraits<CallBase>::op_end(this) - NumOperands, NumOperands,\n               InsertAtEnd) {\n  init(Ty, Func, DefaultDest, IndirectDests, Args, Bundles, NameStr);\n}\n\n//===----------------------------------------------------------------------===//\n//                              ResumeInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// Resume the propagation of an exception.\n///\nclass ResumeInst : public Instruction {\n  ResumeInst(const ResumeInst &RI);\n\n  explicit ResumeInst(Value *Exn, Instruction *InsertBefore=nullptr);\n  ResumeInst(Value *Exn, BasicBlock *InsertAtEnd);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  ResumeInst *cloneImpl() const;\n\npublic:\n  static ResumeInst *Create(Value *Exn, Instruction *InsertBefore = nullptr) {\n    return new(1) ResumeInst(Exn, InsertBefore);\n  }\n\n  static ResumeInst *Create(Value *Exn, BasicBlock *InsertAtEnd) {\n    return new(1) ResumeInst(Exn, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Convenience accessor.\n  Value *getValue() const { return Op<0>(); }\n\n  unsigned getNumSuccessors() const { return 0; }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Resume;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  BasicBlock *getSuccessor(unsigned idx) const {\n    llvm_unreachable(\"ResumeInst has no successors!\");\n  }\n\n  void setSuccessor(unsigned idx, BasicBlock *NewSucc) {\n    llvm_unreachable(\"ResumeInst has no successors!\");\n  }\n};\n\ntemplate <>\nstruct OperandTraits<ResumeInst> :\n    public FixedNumOperandTraits<ResumeInst, 1> {\n};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(ResumeInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                         CatchSwitchInst Class\n//===----------------------------------------------------------------------===//\nclass CatchSwitchInst : public Instruction {\n  using UnwindDestField = BoolBitfieldElementT<0>;\n\n  /// The number of operands actually allocated.  NumOperands is\n  /// the number actually in use.\n  unsigned ReservedSpace;\n\n  // Operand[0] = Outer scope\n  // Operand[1] = Unwind block destination\n  // Operand[n] = BasicBlock to go to on match\n  CatchSwitchInst(const CatchSwitchInst &CSI);\n\n  /// Create a new switch instruction, specifying a\n  /// default destination.  The number of additional handlers can be specified\n  /// here to make memory allocation more efficient.\n  /// This constructor can also autoinsert before another instruction.\n  CatchSwitchInst(Value *ParentPad, BasicBlock *UnwindDest,\n                  unsigned NumHandlers, const Twine &NameStr,\n                  Instruction *InsertBefore);\n\n  /// Create a new switch instruction, specifying a\n  /// default destination.  The number of additional handlers can be specified\n  /// here to make memory allocation more efficient.\n  /// This constructor also autoinserts at the end of the specified BasicBlock.\n  CatchSwitchInst(Value *ParentPad, BasicBlock *UnwindDest,\n                  unsigned NumHandlers, const Twine &NameStr,\n                  BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly zero operands\n  void *operator new(size_t s) { return User::operator new(s); }\n\n  void init(Value *ParentPad, BasicBlock *UnwindDest, unsigned NumReserved);\n  void growOperands(unsigned Size);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  CatchSwitchInst *cloneImpl() const;\n\npublic:\n  static CatchSwitchInst *Create(Value *ParentPad, BasicBlock *UnwindDest,\n                                 unsigned NumHandlers,\n                                 const Twine &NameStr = \"\",\n                                 Instruction *InsertBefore = nullptr) {\n    return new CatchSwitchInst(ParentPad, UnwindDest, NumHandlers, NameStr,\n                               InsertBefore);\n  }\n\n  static CatchSwitchInst *Create(Value *ParentPad, BasicBlock *UnwindDest,\n                                 unsigned NumHandlers, const Twine &NameStr,\n                                 BasicBlock *InsertAtEnd) {\n    return new CatchSwitchInst(ParentPad, UnwindDest, NumHandlers, NameStr,\n                               InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  // Accessor Methods for CatchSwitch stmt\n  Value *getParentPad() const { return getOperand(0); }\n  void setParentPad(Value *ParentPad) { setOperand(0, ParentPad); }\n\n  // Accessor Methods for CatchSwitch stmt\n  bool hasUnwindDest() const { return getSubclassData<UnwindDestField>(); }\n  bool unwindsToCaller() const { return !hasUnwindDest(); }\n  BasicBlock *getUnwindDest() const {\n    if (hasUnwindDest())\n      return cast<BasicBlock>(getOperand(1));\n    return nullptr;\n  }\n  void setUnwindDest(BasicBlock *UnwindDest) {\n    assert(UnwindDest);\n    assert(hasUnwindDest());\n    setOperand(1, UnwindDest);\n  }\n\n  /// return the number of 'handlers' in this catchswitch\n  /// instruction, except the default handler\n  unsigned getNumHandlers() const {\n    if (hasUnwindDest())\n      return getNumOperands() - 2;\n    return getNumOperands() - 1;\n  }\n\nprivate:\n  static BasicBlock *handler_helper(Value *V) { return cast<BasicBlock>(V); }\n  static const BasicBlock *handler_helper(const Value *V) {\n    return cast<BasicBlock>(V);\n  }\n\npublic:\n  using DerefFnTy = BasicBlock *(*)(Value *);\n  using handler_iterator = mapped_iterator<op_iterator, DerefFnTy>;\n  using handler_range = iterator_range<handler_iterator>;\n  using ConstDerefFnTy = const BasicBlock *(*)(const Value *);\n  using const_handler_iterator =\n      mapped_iterator<const_op_iterator, ConstDerefFnTy>;\n  using const_handler_range = iterator_range<const_handler_iterator>;\n\n  /// Returns an iterator that points to the first handler in CatchSwitchInst.\n  handler_iterator handler_begin() {\n    op_iterator It = op_begin() + 1;\n    if (hasUnwindDest())\n      ++It;\n    return handler_iterator(It, DerefFnTy(handler_helper));\n  }\n\n  /// Returns an iterator that points to the first handler in the\n  /// CatchSwitchInst.\n  const_handler_iterator handler_begin() const {\n    const_op_iterator It = op_begin() + 1;\n    if (hasUnwindDest())\n      ++It;\n    return const_handler_iterator(It, ConstDerefFnTy(handler_helper));\n  }\n\n  /// Returns a read-only iterator that points one past the last\n  /// handler in the CatchSwitchInst.\n  handler_iterator handler_end() {\n    return handler_iterator(op_end(), DerefFnTy(handler_helper));\n  }\n\n  /// Returns an iterator that points one past the last handler in the\n  /// CatchSwitchInst.\n  const_handler_iterator handler_end() const {\n    return const_handler_iterator(op_end(), ConstDerefFnTy(handler_helper));\n  }\n\n  /// iteration adapter for range-for loops.\n  handler_range handlers() {\n    return make_range(handler_begin(), handler_end());\n  }\n\n  /// iteration adapter for range-for loops.\n  const_handler_range handlers() const {\n    return make_range(handler_begin(), handler_end());\n  }\n\n  /// Add an entry to the switch instruction...\n  /// Note:\n  /// This action invalidates handler_end(). Old handler_end() iterator will\n  /// point to the added handler.\n  void addHandler(BasicBlock *Dest);\n\n  void removeHandler(handler_iterator HI);\n\n  unsigned getNumSuccessors() const { return getNumOperands() - 1; }\n  BasicBlock *getSuccessor(unsigned Idx) const {\n    assert(Idx < getNumSuccessors() &&\n           \"Successor # out of range for catchswitch!\");\n    return cast<BasicBlock>(getOperand(Idx + 1));\n  }\n  void setSuccessor(unsigned Idx, BasicBlock *NewSucc) {\n    assert(Idx < getNumSuccessors() &&\n           \"Successor # out of range for catchswitch!\");\n    setOperand(Idx + 1, NewSucc);\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::CatchSwitch;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\ntemplate <>\nstruct OperandTraits<CatchSwitchInst> : public HungoffOperandTraits<2> {};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(CatchSwitchInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               CleanupPadInst Class\n//===----------------------------------------------------------------------===//\nclass CleanupPadInst : public FuncletPadInst {\nprivate:\n  explicit CleanupPadInst(Value *ParentPad, ArrayRef<Value *> Args,\n                          unsigned Values, const Twine &NameStr,\n                          Instruction *InsertBefore)\n      : FuncletPadInst(Instruction::CleanupPad, ParentPad, Args, Values,\n                       NameStr, InsertBefore) {}\n  explicit CleanupPadInst(Value *ParentPad, ArrayRef<Value *> Args,\n                          unsigned Values, const Twine &NameStr,\n                          BasicBlock *InsertAtEnd)\n      : FuncletPadInst(Instruction::CleanupPad, ParentPad, Args, Values,\n                       NameStr, InsertAtEnd) {}\n\npublic:\n  static CleanupPadInst *Create(Value *ParentPad, ArrayRef<Value *> Args = None,\n                                const Twine &NameStr = \"\",\n                                Instruction *InsertBefore = nullptr) {\n    unsigned Values = 1 + Args.size();\n    return new (Values)\n        CleanupPadInst(ParentPad, Args, Values, NameStr, InsertBefore);\n  }\n\n  static CleanupPadInst *Create(Value *ParentPad, ArrayRef<Value *> Args,\n                                const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    unsigned Values = 1 + Args.size();\n    return new (Values)\n        CleanupPadInst(ParentPad, Args, Values, NameStr, InsertAtEnd);\n  }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::CleanupPad;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                               CatchPadInst Class\n//===----------------------------------------------------------------------===//\nclass CatchPadInst : public FuncletPadInst {\nprivate:\n  explicit CatchPadInst(Value *CatchSwitch, ArrayRef<Value *> Args,\n                        unsigned Values, const Twine &NameStr,\n                        Instruction *InsertBefore)\n      : FuncletPadInst(Instruction::CatchPad, CatchSwitch, Args, Values,\n                       NameStr, InsertBefore) {}\n  explicit CatchPadInst(Value *CatchSwitch, ArrayRef<Value *> Args,\n                        unsigned Values, const Twine &NameStr,\n                        BasicBlock *InsertAtEnd)\n      : FuncletPadInst(Instruction::CatchPad, CatchSwitch, Args, Values,\n                       NameStr, InsertAtEnd) {}\n\npublic:\n  static CatchPadInst *Create(Value *CatchSwitch, ArrayRef<Value *> Args,\n                              const Twine &NameStr = \"\",\n                              Instruction *InsertBefore = nullptr) {\n    unsigned Values = 1 + Args.size();\n    return new (Values)\n        CatchPadInst(CatchSwitch, Args, Values, NameStr, InsertBefore);\n  }\n\n  static CatchPadInst *Create(Value *CatchSwitch, ArrayRef<Value *> Args,\n                              const Twine &NameStr, BasicBlock *InsertAtEnd) {\n    unsigned Values = 1 + Args.size();\n    return new (Values)\n        CatchPadInst(CatchSwitch, Args, Values, NameStr, InsertAtEnd);\n  }\n\n  /// Convenience accessors\n  CatchSwitchInst *getCatchSwitch() const {\n    return cast<CatchSwitchInst>(Op<-1>());\n  }\n  void setCatchSwitch(Value *CatchSwitch) {\n    assert(CatchSwitch);\n    Op<-1>() = CatchSwitch;\n  }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::CatchPad;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                               CatchReturnInst Class\n//===----------------------------------------------------------------------===//\n\nclass CatchReturnInst : public Instruction {\n  CatchReturnInst(const CatchReturnInst &RI);\n  CatchReturnInst(Value *CatchPad, BasicBlock *BB, Instruction *InsertBefore);\n  CatchReturnInst(Value *CatchPad, BasicBlock *BB, BasicBlock *InsertAtEnd);\n\n  void init(Value *CatchPad, BasicBlock *BB);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  CatchReturnInst *cloneImpl() const;\n\npublic:\n  static CatchReturnInst *Create(Value *CatchPad, BasicBlock *BB,\n                                 Instruction *InsertBefore = nullptr) {\n    assert(CatchPad);\n    assert(BB);\n    return new (2) CatchReturnInst(CatchPad, BB, InsertBefore);\n  }\n\n  static CatchReturnInst *Create(Value *CatchPad, BasicBlock *BB,\n                                 BasicBlock *InsertAtEnd) {\n    assert(CatchPad);\n    assert(BB);\n    return new (2) CatchReturnInst(CatchPad, BB, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  /// Convenience accessors.\n  CatchPadInst *getCatchPad() const { return cast<CatchPadInst>(Op<0>()); }\n  void setCatchPad(CatchPadInst *CatchPad) {\n    assert(CatchPad);\n    Op<0>() = CatchPad;\n  }\n\n  BasicBlock *getSuccessor() const { return cast<BasicBlock>(Op<1>()); }\n  void setSuccessor(BasicBlock *NewSucc) {\n    assert(NewSucc);\n    Op<1>() = NewSucc;\n  }\n  unsigned getNumSuccessors() const { return 1; }\n\n  /// Get the parentPad of this catchret's catchpad's catchswitch.\n  /// The successor block is implicitly a member of this funclet.\n  Value *getCatchSwitchParentPad() const {\n    return getCatchPad()->getCatchSwitch()->getParentPad();\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::CatchRet);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  BasicBlock *getSuccessor(unsigned Idx) const {\n    assert(Idx < getNumSuccessors() && \"Successor # out of range for catchret!\");\n    return getSuccessor();\n  }\n\n  void setSuccessor(unsigned Idx, BasicBlock *B) {\n    assert(Idx < getNumSuccessors() && \"Successor # out of range for catchret!\");\n    setSuccessor(B);\n  }\n};\n\ntemplate <>\nstruct OperandTraits<CatchReturnInst>\n    : public FixedNumOperandTraits<CatchReturnInst, 2> {};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(CatchReturnInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                               CleanupReturnInst Class\n//===----------------------------------------------------------------------===//\n\nclass CleanupReturnInst : public Instruction {\n  using UnwindDestField = BoolBitfieldElementT<0>;\n\nprivate:\n  CleanupReturnInst(const CleanupReturnInst &RI);\n  CleanupReturnInst(Value *CleanupPad, BasicBlock *UnwindBB, unsigned Values,\n                    Instruction *InsertBefore = nullptr);\n  CleanupReturnInst(Value *CleanupPad, BasicBlock *UnwindBB, unsigned Values,\n                    BasicBlock *InsertAtEnd);\n\n  void init(Value *CleanupPad, BasicBlock *UnwindBB);\n\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  CleanupReturnInst *cloneImpl() const;\n\npublic:\n  static CleanupReturnInst *Create(Value *CleanupPad,\n                                   BasicBlock *UnwindBB = nullptr,\n                                   Instruction *InsertBefore = nullptr) {\n    assert(CleanupPad);\n    unsigned Values = 1;\n    if (UnwindBB)\n      ++Values;\n    return new (Values)\n        CleanupReturnInst(CleanupPad, UnwindBB, Values, InsertBefore);\n  }\n\n  static CleanupReturnInst *Create(Value *CleanupPad, BasicBlock *UnwindBB,\n                                   BasicBlock *InsertAtEnd) {\n    assert(CleanupPad);\n    unsigned Values = 1;\n    if (UnwindBB)\n      ++Values;\n    return new (Values)\n        CleanupReturnInst(CleanupPad, UnwindBB, Values, InsertAtEnd);\n  }\n\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(Value);\n\n  bool hasUnwindDest() const { return getSubclassData<UnwindDestField>(); }\n  bool unwindsToCaller() const { return !hasUnwindDest(); }\n\n  /// Convenience accessor.\n  CleanupPadInst *getCleanupPad() const {\n    return cast<CleanupPadInst>(Op<0>());\n  }\n  void setCleanupPad(CleanupPadInst *CleanupPad) {\n    assert(CleanupPad);\n    Op<0>() = CleanupPad;\n  }\n\n  unsigned getNumSuccessors() const { return hasUnwindDest() ? 1 : 0; }\n\n  BasicBlock *getUnwindDest() const {\n    return hasUnwindDest() ? cast<BasicBlock>(Op<1>()) : nullptr;\n  }\n  void setUnwindDest(BasicBlock *NewDest) {\n    assert(NewDest);\n    assert(hasUnwindDest());\n    Op<1>() = NewDest;\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return (I->getOpcode() == Instruction::CleanupRet);\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  BasicBlock *getSuccessor(unsigned Idx) const {\n    assert(Idx == 0);\n    return getUnwindDest();\n  }\n\n  void setSuccessor(unsigned Idx, BasicBlock *B) {\n    assert(Idx == 0);\n    setUnwindDest(B);\n  }\n\n  // Shadow Instruction::setInstructionSubclassData with a private forwarding\n  // method so that subclasses cannot accidentally use it.\n  template <typename Bitfield>\n  void setSubclassData(typename Bitfield::Type Value) {\n    Instruction::setSubclassData<Bitfield>(Value);\n  }\n};\n\ntemplate <>\nstruct OperandTraits<CleanupReturnInst>\n    : public VariadicOperandTraits<CleanupReturnInst, /*MINARITY=*/1> {};\n\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(CleanupReturnInst, Value)\n\n//===----------------------------------------------------------------------===//\n//                           UnreachableInst Class\n//===----------------------------------------------------------------------===//\n\n//===---------------------------------------------------------------------------\n/// This function has undefined behavior.  In particular, the\n/// presence of this instruction indicates some higher level knowledge that the\n/// end of the block cannot be reached.\n///\nclass UnreachableInst : public Instruction {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  UnreachableInst *cloneImpl() const;\n\npublic:\n  explicit UnreachableInst(LLVMContext &C, Instruction *InsertBefore = nullptr);\n  explicit UnreachableInst(LLVMContext &C, BasicBlock *InsertAtEnd);\n\n  // allocate space for exactly zero operands\n  void *operator new(size_t s) {\n    return User::operator new(s, 0);\n  }\n\n  unsigned getNumSuccessors() const { return 0; }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Unreachable;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\nprivate:\n  BasicBlock *getSuccessor(unsigned idx) const {\n    llvm_unreachable(\"UnreachableInst has no successors!\");\n  }\n\n  void setSuccessor(unsigned idx, BasicBlock *B) {\n    llvm_unreachable(\"UnreachableInst has no successors!\");\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 TruncInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a truncation of integer types.\nclass TruncInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical TruncInst\n  TruncInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  TruncInst(\n    Value *S,                           ///< The value to be truncated\n    Type *Ty,                           ///< The (smaller) type to truncate to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  TruncInst(\n    Value *S,                     ///< The value to be truncated\n    Type *Ty,                     ///< The (smaller) type to truncate to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Trunc;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 ZExtInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents zero extension of integer types.\nclass ZExtInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical ZExtInst\n  ZExtInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  ZExtInst(\n    Value *S,                           ///< The value to be zero extended\n    Type *Ty,                           ///< The type to zero extend to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end semantics.\n  ZExtInst(\n    Value *S,                     ///< The value to be zero extended\n    Type *Ty,                     ///< The type to zero extend to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == ZExt;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 SExtInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a sign extension of integer types.\nclass SExtInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical SExtInst\n  SExtInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  SExtInst(\n    Value *S,                           ///< The value to be sign extended\n    Type *Ty,                           ///< The type to sign extend to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  SExtInst(\n    Value *S,                     ///< The value to be sign extended\n    Type *Ty,                     ///< The type to sign extend to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == SExt;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 FPTruncInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a truncation of floating point types.\nclass FPTruncInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical FPTruncInst\n  FPTruncInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  FPTruncInst(\n    Value *S,                           ///< The value to be truncated\n    Type *Ty,                           ///< The type to truncate to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-before-instruction semantics\n  FPTruncInst(\n    Value *S,                     ///< The value to be truncated\n    Type *Ty,                     ///< The type to truncate to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == FPTrunc;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 FPExtInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents an extension of floating point types.\nclass FPExtInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical FPExtInst\n  FPExtInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  FPExtInst(\n    Value *S,                           ///< The value to be extended\n    Type *Ty,                           ///< The type to extend to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  FPExtInst(\n    Value *S,                     ///< The value to be extended\n    Type *Ty,                     ///< The type to extend to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == FPExt;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 UIToFPInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a cast unsigned integer to floating point.\nclass UIToFPInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical UIToFPInst\n  UIToFPInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  UIToFPInst(\n    Value *S,                           ///< The value to be converted\n    Type *Ty,                           ///< The type to convert to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  UIToFPInst(\n    Value *S,                     ///< The value to be converted\n    Type *Ty,                     ///< The type to convert to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == UIToFP;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 SIToFPInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a cast from signed integer to floating point.\nclass SIToFPInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical SIToFPInst\n  SIToFPInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  SIToFPInst(\n    Value *S,                           ///< The value to be converted\n    Type *Ty,                           ///< The type to convert to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  SIToFPInst(\n    Value *S,                     ///< The value to be converted\n    Type *Ty,                     ///< The type to convert to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == SIToFP;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 FPToUIInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a cast from floating point to unsigned integer\nclass FPToUIInst  : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical FPToUIInst\n  FPToUIInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  FPToUIInst(\n    Value *S,                           ///< The value to be converted\n    Type *Ty,                           ///< The type to convert to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  FPToUIInst(\n    Value *S,                     ///< The value to be converted\n    Type *Ty,                     ///< The type to convert to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< Where to insert the new instruction\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == FPToUI;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 FPToSIInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a cast from floating point to signed integer.\nclass FPToSIInst  : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical FPToSIInst\n  FPToSIInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  FPToSIInst(\n    Value *S,                           ///< The value to be converted\n    Type *Ty,                           ///< The type to convert to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  FPToSIInst(\n    Value *S,                     ///< The value to be converted\n    Type *Ty,                     ///< The type to convert to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == FPToSI;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 IntToPtrInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a cast from an integer to a pointer.\nclass IntToPtrInst : public CastInst {\npublic:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Constructor with insert-before-instruction semantics\n  IntToPtrInst(\n    Value *S,                           ///< The value to be converted\n    Type *Ty,                           ///< The type to convert to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  IntToPtrInst(\n    Value *S,                     ///< The value to be converted\n    Type *Ty,                     ///< The type to convert to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Clone an identical IntToPtrInst.\n  IntToPtrInst *cloneImpl() const;\n\n  /// Returns the address space of this instruction's pointer type.\n  unsigned getAddressSpace() const {\n    return getType()->getPointerAddressSpace();\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == IntToPtr;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                                 PtrToIntInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a cast from a pointer to an integer.\nclass PtrToIntInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical PtrToIntInst.\n  PtrToIntInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  PtrToIntInst(\n    Value *S,                           ///< The value to be converted\n    Type *Ty,                           ///< The type to convert to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  PtrToIntInst(\n    Value *S,                     ///< The value to be converted\n    Type *Ty,                     ///< The type to convert to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  /// Gets the pointer operand.\n  Value *getPointerOperand() { return getOperand(0); }\n  /// Gets the pointer operand.\n  const Value *getPointerOperand() const { return getOperand(0); }\n  /// Gets the operand index of the pointer operand.\n  static unsigned getPointerOperandIndex() { return 0U; }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperand()->getType()->getPointerAddressSpace();\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == PtrToInt;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                             BitCastInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a no-op cast from one type to another.\nclass BitCastInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical BitCastInst.\n  BitCastInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  BitCastInst(\n    Value *S,                           ///< The value to be casted\n    Type *Ty,                           ///< The type to casted to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  BitCastInst(\n    Value *S,                     ///< The value to be casted\n    Type *Ty,                     ///< The type to casted to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == BitCast;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n//===----------------------------------------------------------------------===//\n//                          AddrSpaceCastInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a conversion between pointers from one address space\n/// to another.\nclass AddrSpaceCastInst : public CastInst {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical AddrSpaceCastInst.\n  AddrSpaceCastInst *cloneImpl() const;\n\npublic:\n  /// Constructor with insert-before-instruction semantics\n  AddrSpaceCastInst(\n    Value *S,                           ///< The value to be casted\n    Type *Ty,                           ///< The type to casted to\n    const Twine &NameStr = \"\",          ///< A name for the new instruction\n    Instruction *InsertBefore = nullptr ///< Where to insert the new instruction\n  );\n\n  /// Constructor with insert-at-end-of-block semantics\n  AddrSpaceCastInst(\n    Value *S,                     ///< The value to be casted\n    Type *Ty,                     ///< The type to casted to\n    const Twine &NameStr,         ///< A name for the new instruction\n    BasicBlock *InsertAtEnd       ///< The block to insert the instruction into\n  );\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == AddrSpaceCast;\n  }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n\n  /// Gets the pointer operand.\n  Value *getPointerOperand() {\n    return getOperand(0);\n  }\n\n  /// Gets the pointer operand.\n  const Value *getPointerOperand() const {\n    return getOperand(0);\n  }\n\n  /// Gets the operand index of the pointer operand.\n  static unsigned getPointerOperandIndex() {\n    return 0U;\n  }\n\n  /// Returns the address space of the pointer operand.\n  unsigned getSrcAddressSpace() const {\n    return getPointerOperand()->getType()->getPointerAddressSpace();\n  }\n\n  /// Returns the address space of the result.\n  unsigned getDestAddressSpace() const {\n    return getType()->getPointerAddressSpace();\n  }\n};\n\n/// A helper function that returns the pointer operand of a load or store\n/// instruction. Returns nullptr if not load or store.\ninline const Value *getLoadStorePointerOperand(const Value *V) {\n  if (auto *Load = dyn_cast<LoadInst>(V))\n    return Load->getPointerOperand();\n  if (auto *Store = dyn_cast<StoreInst>(V))\n    return Store->getPointerOperand();\n  return nullptr;\n}\ninline Value *getLoadStorePointerOperand(Value *V) {\n  return const_cast<Value *>(\n      getLoadStorePointerOperand(static_cast<const Value *>(V)));\n}\n\n/// A helper function that returns the pointer operand of a load, store\n/// or GEP instruction. Returns nullptr if not load, store, or GEP.\ninline const Value *getPointerOperand(const Value *V) {\n  if (auto *Ptr = getLoadStorePointerOperand(V))\n    return Ptr;\n  if (auto *Gep = dyn_cast<GetElementPtrInst>(V))\n    return Gep->getPointerOperand();\n  return nullptr;\n}\ninline Value *getPointerOperand(Value *V) {\n  return const_cast<Value *>(getPointerOperand(static_cast<const Value *>(V)));\n}\n\n/// A helper function that returns the alignment of load or store instruction.\ninline Align getLoadStoreAlignment(Value *I) {\n  assert((isa<LoadInst>(I) || isa<StoreInst>(I)) &&\n         \"Expected Load or Store instruction\");\n  if (auto *LI = dyn_cast<LoadInst>(I))\n    return LI->getAlign();\n  return cast<StoreInst>(I)->getAlign();\n}\n\n/// A helper function that returns the address space of the pointer operand of\n/// load or store instruction.\ninline unsigned getLoadStoreAddressSpace(Value *I) {\n  assert((isa<LoadInst>(I) || isa<StoreInst>(I)) &&\n         \"Expected Load or Store instruction\");\n  if (auto *LI = dyn_cast<LoadInst>(I))\n    return LI->getPointerAddressSpace();\n  return cast<StoreInst>(I)->getPointerAddressSpace();\n}\n\n//===----------------------------------------------------------------------===//\n//                              FreezeInst Class\n//===----------------------------------------------------------------------===//\n\n/// This class represents a freeze function that returns random concrete\n/// value if an operand is either a poison value or an undef value\nclass FreezeInst : public UnaryInstruction {\nprotected:\n  // Note: Instruction needs to be a friend here to call cloneImpl.\n  friend class Instruction;\n\n  /// Clone an identical FreezeInst\n  FreezeInst *cloneImpl() const;\n\npublic:\n  explicit FreezeInst(Value *S,\n                      const Twine &NameStr = \"\",\n                      Instruction *InsertBefore = nullptr);\n  FreezeInst(Value *S, const Twine &NameStr, BasicBlock *InsertAtEnd);\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static inline bool classof(const Instruction *I) {\n    return I->getOpcode() == Freeze;\n  }\n  static inline bool classof(const Value *V) {\n    return isa<Instruction>(V) && classof(cast<Instruction>(V));\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_IR_INSTRUCTIONS_H\n"}, "45": {"id": 45, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "content": "//===-- llvm/IntrinsicInst.h - Intrinsic Instruction Wrappers ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines classes that make it really easy to deal with intrinsic\n// functions with the isa/dyncast family of functions.  In particular, this\n// allows you to do things like:\n//\n//     if (MemCpyInst *MCI = dyn_cast<MemCpyInst>(Inst))\n//        ... MCI->getDest() ... MCI->getSource() ...\n//\n// All intrinsic function calls are instances of the call instruction, so these\n// are all subclasses of the CallInst class.  Note that none of these classes\n// has state or virtual methods, which is an important part of this gross/neat\n// hack working.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_INTRINSICINST_H\n#define LLVM_IR_INTRINSICINST_H\n\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/DebugInfoMetadata.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/IR/FPEnv.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/GlobalVariable.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/Intrinsics.h\"\n#include \"llvm/IR/Metadata.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/Support/Casting.h\"\n#include <cassert>\n#include <cstdint>\n\nnamespace llvm {\n\n/// A wrapper class for inspecting calls to intrinsic functions.\n/// This allows the standard isa/dyncast/cast functionality to work with calls\n/// to intrinsic functions.\nclass IntrinsicInst : public CallInst {\npublic:\n  IntrinsicInst() = delete;\n  IntrinsicInst(const IntrinsicInst &) = delete;\n  IntrinsicInst &operator=(const IntrinsicInst &) = delete;\n\n  /// Return the intrinsic ID of this intrinsic.\n  Intrinsic::ID getIntrinsicID() const {\n    return getCalledFunction()->getIntrinsicID();\n  }\n\n  /// Return true if swapping the first two arguments to the intrinsic produces\n  /// the same result.\n  bool isCommutative() const {\n    switch (getIntrinsicID()) {\n    case Intrinsic::maxnum:\n    case Intrinsic::minnum:\n    case Intrinsic::maximum:\n    case Intrinsic::minimum:\n    case Intrinsic::smax:\n    case Intrinsic::smin:\n    case Intrinsic::umax:\n    case Intrinsic::umin:\n    case Intrinsic::sadd_sat:\n    case Intrinsic::uadd_sat:\n    case Intrinsic::sadd_with_overflow:\n    case Intrinsic::uadd_with_overflow:\n    case Intrinsic::smul_with_overflow:\n    case Intrinsic::umul_with_overflow:\n    case Intrinsic::smul_fix:\n    case Intrinsic::umul_fix:\n    case Intrinsic::smul_fix_sat:\n    case Intrinsic::umul_fix_sat:\n    case Intrinsic::fma:\n    case Intrinsic::fmuladd:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  // Checks if the intrinsic is an annotation.\n  bool isAssumeLikeIntrinsic() const {\n    switch (getIntrinsicID()) {\n    default: break;\n    case Intrinsic::assume:\n    case Intrinsic::sideeffect:\n    case Intrinsic::pseudoprobe:\n    case Intrinsic::dbg_declare:\n    case Intrinsic::dbg_value:\n    case Intrinsic::dbg_label:\n    case Intrinsic::invariant_start:\n    case Intrinsic::invariant_end:\n    case Intrinsic::lifetime_start:\n    case Intrinsic::lifetime_end:\n    case Intrinsic::experimental_noalias_scope_decl:\n    case Intrinsic::objectsize:\n    case Intrinsic::ptr_annotation:\n    case Intrinsic::var_annotation:\n      return true;\n    }\n    return false;\n  }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const CallInst *I) {\n    if (const Function *CF = I->getCalledFunction())\n      return CF->isIntrinsic();\n    return false;\n  }\n  static bool classof(const Value *V) {\n    return isa<CallInst>(V) && classof(cast<CallInst>(V));\n  }\n};\n\n/// Check if \\p ID corresponds to a debug info intrinsic.\nstatic inline bool isDbgInfoIntrinsic(Intrinsic::ID ID) {\n  switch (ID) {\n  case Intrinsic::dbg_declare:\n  case Intrinsic::dbg_value:\n  case Intrinsic::dbg_addr:\n  case Intrinsic::dbg_label:\n    return true;\n  default:\n    return false;\n  }\n}\n\n/// This is the common base class for debug info intrinsics.\nclass DbgInfoIntrinsic : public IntrinsicInst {\npublic:\n  /// \\name Casting methods\n  /// @{\n  static bool classof(const IntrinsicInst *I) {\n    return isDbgInfoIntrinsic(I->getIntrinsicID());\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n  /// @}\n};\n\n/// This is the common base class for debug info intrinsics for variables.\nclass DbgVariableIntrinsic : public DbgInfoIntrinsic {\npublic:\n  // Iterator for ValueAsMetadata that internally uses direct pointer iteration\n  // over either a ValueAsMetadata* or a ValueAsMetadata**, dereferencing to the\n  // ValueAsMetadata .\n  class location_op_iterator\n      : public iterator_facade_base<location_op_iterator,\n                                    std::bidirectional_iterator_tag, Value *> {\n    PointerUnion<ValueAsMetadata *, ValueAsMetadata **> I;\n\n  public:\n    location_op_iterator(ValueAsMetadata *SingleIter) : I(SingleIter) {}\n    location_op_iterator(ValueAsMetadata **MultiIter) : I(MultiIter) {}\n\n    location_op_iterator(const location_op_iterator &R) : I(R.I) {}\n    location_op_iterator &operator=(const location_op_iterator &R) {\n      I = R.I;\n      return *this;\n    }\n    bool operator==(const location_op_iterator &RHS) const {\n      return I == RHS.I;\n    }\n    const Value *operator*() const {\n      ValueAsMetadata *VAM = I.is<ValueAsMetadata *>()\n                                 ? I.get<ValueAsMetadata *>()\n                                 : *I.get<ValueAsMetadata **>();\n      return VAM->getValue();\n    };\n    Value *operator*() {\n      ValueAsMetadata *VAM = I.is<ValueAsMetadata *>()\n                                 ? I.get<ValueAsMetadata *>()\n                                 : *I.get<ValueAsMetadata **>();\n      return VAM->getValue();\n    }\n    location_op_iterator &operator++() {\n      if (I.is<ValueAsMetadata *>())\n        I = I.get<ValueAsMetadata *>() + 1;\n      else\n        I = I.get<ValueAsMetadata **>() + 1;\n      return *this;\n    }\n    location_op_iterator &operator--() {\n      if (I.is<ValueAsMetadata *>())\n        I = I.get<ValueAsMetadata *>() - 1;\n      else\n        I = I.get<ValueAsMetadata **>() - 1;\n      return *this;\n    }\n  };\n\n  /// Get the locations corresponding to the variable referenced by the debug\n  /// info intrinsic.  Depending on the intrinsic, this could be the\n  /// variable's value or its address.\n  iterator_range<location_op_iterator> location_ops() const;\n\n  Value *getVariableLocationOp(unsigned OpIdx) const;\n\n  void replaceVariableLocationOp(Value *OldValue, Value *NewValue);\n  void replaceVariableLocationOp(unsigned OpIdx, Value *NewValue);\n\n  void setVariable(DILocalVariable *NewVar) {\n    setArgOperand(1, MetadataAsValue::get(NewVar->getContext(), NewVar));\n  }\n\n  void setExpression(DIExpression *NewExpr) {\n    setArgOperand(2, MetadataAsValue::get(NewExpr->getContext(), NewExpr));\n  }\n\n  unsigned getNumVariableLocationOps() const {\n    if (hasArgList())\n      return cast<DIArgList>(getRawLocation())->getArgs().size();\n    return 1;\n  }\n\n  bool hasArgList() const { return isa<DIArgList>(getRawLocation()); }\n\n  /// Does this describe the address of a local variable. True for dbg.addr\n  /// and dbg.declare, but not dbg.value, which describes its value.\n  bool isAddressOfVariable() const {\n    return getIntrinsicID() != Intrinsic::dbg_value;\n  }\n\n  void setUndef() {\n    // TODO: When/if we remove duplicate values from DIArgLists, we don't need\n    // this set anymore.\n    SmallPtrSet<Value *, 4> RemovedValues;\n    for (Value *OldValue : location_ops()) {\n      if (!RemovedValues.insert(OldValue).second)\n        continue;\n      Value *Undef = UndefValue::get(OldValue->getType());\n      replaceVariableLocationOp(OldValue, Undef);\n    }\n  }\n\n  bool isUndef() const {\n    return (getNumVariableLocationOps() == 0 &&\n            !getExpression()->isComplex()) ||\n           any_of(location_ops(), [](Value *V) { return isa<UndefValue>(V); });\n  }\n\n  DILocalVariable *getVariable() const {\n    return cast<DILocalVariable>(getRawVariable());\n  }\n\n  DIExpression *getExpression() const {\n    return cast<DIExpression>(getRawExpression());\n  }\n\n  Metadata *getRawLocation() const {\n    return cast<MetadataAsValue>(getArgOperand(0))->getMetadata();\n  }\n\n  Metadata *getRawVariable() const {\n    return cast<MetadataAsValue>(getArgOperand(1))->getMetadata();\n  }\n\n  Metadata *getRawExpression() const {\n    return cast<MetadataAsValue>(getArgOperand(2))->getMetadata();\n  }\n\n  /// Get the size (in bits) of the variable, or fragment of the variable that\n  /// is described.\n  Optional<uint64_t> getFragmentSizeInBits() const;\n\n  /// \\name Casting methods\n  /// @{\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::dbg_declare:\n    case Intrinsic::dbg_value:\n    case Intrinsic::dbg_addr:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n  /// @}\nprivate:\n  void setArgOperand(unsigned i, Value *v) {\n    DbgInfoIntrinsic::setArgOperand(i, v);\n  }\n  void setOperand(unsigned i, Value *v) { DbgInfoIntrinsic::setOperand(i, v); }\n};\n\n/// This represents the llvm.dbg.declare instruction.\nclass DbgDeclareInst : public DbgVariableIntrinsic {\npublic:\n  Value *getAddress() const {\n    assert(getNumVariableLocationOps() == 1 &&\n           \"dbg.declare must have exactly 1 location operand.\");\n    return getVariableLocationOp(0);\n  }\n\n  /// \\name Casting methods\n  /// @{\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::dbg_declare;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n  /// @}\n};\n\n/// This represents the llvm.dbg.addr instruction.\nclass DbgAddrIntrinsic : public DbgVariableIntrinsic {\npublic:\n  Value *getAddress() const {\n    assert(getNumVariableLocationOps() == 1 &&\n           \"dbg.addr must have exactly 1 location operand.\");\n    return getVariableLocationOp(0);\n  }\n\n  /// \\name Casting methods\n  /// @{\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::dbg_addr;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This represents the llvm.dbg.value instruction.\nclass DbgValueInst : public DbgVariableIntrinsic {\npublic:\n  // The default argument should only be used in ISel, and the default option\n  // should be removed once ISel support for multiple location ops is complete.\n  Value *getValue(unsigned OpIdx = 0) const {\n    return getVariableLocationOp(OpIdx);\n  }\n  iterator_range<location_op_iterator> getValues() const {\n    return location_ops();\n  }\n\n  /// \\name Casting methods\n  /// @{\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::dbg_value;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n  /// @}\n};\n\n/// This represents the llvm.dbg.label instruction.\nclass DbgLabelInst : public DbgInfoIntrinsic {\npublic:\n  DILabel *getLabel() const { return cast<DILabel>(getRawLabel()); }\n\n  Metadata *getRawLabel() const {\n    return cast<MetadataAsValue>(getArgOperand(0))->getMetadata();\n  }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  /// @{\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::dbg_label;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n  /// @}\n};\n\n/// This is the common base class for vector predication intrinsics.\nclass VPIntrinsic : public IntrinsicInst {\npublic:\n  static Optional<int> GetMaskParamPos(Intrinsic::ID IntrinsicID);\n  static Optional<int> GetVectorLengthParamPos(Intrinsic::ID IntrinsicID);\n\n  /// The llvm.vp.* intrinsics for this instruction Opcode\n  static Intrinsic::ID GetForOpcode(unsigned OC);\n\n  // Whether \\p ID is a VP intrinsic ID.\n  static bool IsVPIntrinsic(Intrinsic::ID);\n\n  /// \\return the mask parameter or nullptr.\n  Value *getMaskParam() const;\n\n  /// \\return the vector length parameter or nullptr.\n  Value *getVectorLengthParam() const;\n\n  /// \\return whether the vector length param can be ignored.\n  bool canIgnoreVectorLengthParam() const;\n\n  /// \\return the static element count (vector number of elements) the vector\n  /// length parameter applies to.\n  ElementCount getStaticVectorLength() const;\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    return IsVPIntrinsic(I->getIntrinsicID());\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  // Equivalent non-predicated opcode\n  unsigned getFunctionalOpcode() const {\n    return GetFunctionalOpcodeForVP(getIntrinsicID());\n  }\n\n  // Equivalent non-predicated opcode\n  static unsigned GetFunctionalOpcodeForVP(Intrinsic::ID ID);\n};\n\n/// This is the common base class for constrained floating point intrinsics.\nclass ConstrainedFPIntrinsic : public IntrinsicInst {\npublic:\n  bool isUnaryOp() const;\n  bool isTernaryOp() const;\n  Optional<RoundingMode> getRoundingMode() const;\n  Optional<fp::ExceptionBehavior> getExceptionBehavior() const;\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I);\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// Constrained floating point compare intrinsics.\nclass ConstrainedFPCmpIntrinsic : public ConstrainedFPIntrinsic {\npublic:\n  FCmpInst::Predicate getPredicate() const;\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::experimental_constrained_fcmp:\n    case Intrinsic::experimental_constrained_fcmps:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents an intrinsic that is based on a binary operation.\n/// This includes op.with.overflow and saturating add/sub intrinsics.\nclass BinaryOpIntrinsic : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::uadd_with_overflow:\n    case Intrinsic::sadd_with_overflow:\n    case Intrinsic::usub_with_overflow:\n    case Intrinsic::ssub_with_overflow:\n    case Intrinsic::umul_with_overflow:\n    case Intrinsic::smul_with_overflow:\n    case Intrinsic::uadd_sat:\n    case Intrinsic::sadd_sat:\n    case Intrinsic::usub_sat:\n    case Intrinsic::ssub_sat:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  Value *getLHS() const { return const_cast<Value *>(getArgOperand(0)); }\n  Value *getRHS() const { return const_cast<Value *>(getArgOperand(1)); }\n\n  /// Returns the binary operation underlying the intrinsic.\n  Instruction::BinaryOps getBinaryOp() const;\n\n  /// Whether the intrinsic is signed or unsigned.\n  bool isSigned() const;\n\n  /// Returns one of OBO::NoSignedWrap or OBO::NoUnsignedWrap.\n  unsigned getNoWrapKind() const;\n};\n\n/// Represents an op.with.overflow intrinsic.\nclass WithOverflowInst : public BinaryOpIntrinsic {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::uadd_with_overflow:\n    case Intrinsic::sadd_with_overflow:\n    case Intrinsic::usub_with_overflow:\n    case Intrinsic::ssub_with_overflow:\n    case Intrinsic::umul_with_overflow:\n    case Intrinsic::smul_with_overflow:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// Represents a saturating add/sub intrinsic.\nclass SaturatingInst : public BinaryOpIntrinsic {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::uadd_sat:\n    case Intrinsic::sadd_sat:\n    case Intrinsic::usub_sat:\n    case Intrinsic::ssub_sat:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// Common base class for all memory intrinsics. Simply provides\n/// common methods.\n/// Written as CRTP to avoid a common base class amongst the\n/// three atomicity hierarchies.\ntemplate <typename Derived> class MemIntrinsicBase : public IntrinsicInst {\nprivate:\n  enum { ARG_DEST = 0, ARG_LENGTH = 2 };\n\npublic:\n  Value *getRawDest() const {\n    return const_cast<Value *>(getArgOperand(ARG_DEST));\n  }\n  const Use &getRawDestUse() const { return getArgOperandUse(ARG_DEST); }\n  Use &getRawDestUse() { return getArgOperandUse(ARG_DEST); }\n\n  Value *getLength() const {\n    return const_cast<Value *>(getArgOperand(ARG_LENGTH));\n  }\n  const Use &getLengthUse() const { return getArgOperandUse(ARG_LENGTH); }\n  Use &getLengthUse() { return getArgOperandUse(ARG_LENGTH); }\n\n  /// This is just like getRawDest, but it strips off any cast\n  /// instructions (including addrspacecast) that feed it, giving the\n  /// original input.  The returned value is guaranteed to be a pointer.\n  Value *getDest() const { return getRawDest()->stripPointerCasts(); }\n\n  unsigned getDestAddressSpace() const {\n    return cast<PointerType>(getRawDest()->getType())->getAddressSpace();\n  }\n\n  /// FIXME: Remove this function once transition to Align is over.\n  /// Use getDestAlign() instead.\n  unsigned getDestAlignment() const {\n    if (auto MA = getParamAlign(ARG_DEST))\n      return MA->value();\n    return 0;\n  }\n  MaybeAlign getDestAlign() const { return getParamAlign(ARG_DEST); }\n\n  /// Set the specified arguments of the instruction.\n  void setDest(Value *Ptr) {\n    assert(getRawDest()->getType() == Ptr->getType() &&\n           \"setDest called with pointer of wrong type!\");\n    setArgOperand(ARG_DEST, Ptr);\n  }\n\n  /// FIXME: Remove this function once transition to Align is over.\n  /// Use the version that takes MaybeAlign instead of this one.\n  void setDestAlignment(unsigned Alignment) {\n    setDestAlignment(MaybeAlign(Alignment));\n  }\n  void setDestAlignment(MaybeAlign Alignment) {\n    removeParamAttr(ARG_DEST, Attribute::Alignment);\n    if (Alignment)\n      addParamAttr(ARG_DEST,\n                   Attribute::getWithAlignment(getContext(), *Alignment));\n  }\n  void setDestAlignment(Align Alignment) {\n    removeParamAttr(ARG_DEST, Attribute::Alignment);\n    addParamAttr(ARG_DEST,\n                 Attribute::getWithAlignment(getContext(), Alignment));\n  }\n\n  void setLength(Value *L) {\n    assert(getLength()->getType() == L->getType() &&\n           \"setLength called with value of wrong type!\");\n    setArgOperand(ARG_LENGTH, L);\n  }\n};\n\n/// Common base class for all memory transfer intrinsics. Simply provides\n/// common methods.\ntemplate <class BaseCL> class MemTransferBase : public BaseCL {\nprivate:\n  enum { ARG_SOURCE = 1 };\n\npublic:\n  /// Return the arguments to the instruction.\n  Value *getRawSource() const {\n    return const_cast<Value *>(BaseCL::getArgOperand(ARG_SOURCE));\n  }\n  const Use &getRawSourceUse() const {\n    return BaseCL::getArgOperandUse(ARG_SOURCE);\n  }\n  Use &getRawSourceUse() { return BaseCL::getArgOperandUse(ARG_SOURCE); }\n\n  /// This is just like getRawSource, but it strips off any cast\n  /// instructions that feed it, giving the original input.  The returned\n  /// value is guaranteed to be a pointer.\n  Value *getSource() const { return getRawSource()->stripPointerCasts(); }\n\n  unsigned getSourceAddressSpace() const {\n    return cast<PointerType>(getRawSource()->getType())->getAddressSpace();\n  }\n\n  /// FIXME: Remove this function once transition to Align is over.\n  /// Use getSourceAlign() instead.\n  unsigned getSourceAlignment() const {\n    if (auto MA = BaseCL::getParamAlign(ARG_SOURCE))\n      return MA->value();\n    return 0;\n  }\n\n  MaybeAlign getSourceAlign() const {\n    return BaseCL::getParamAlign(ARG_SOURCE);\n  }\n\n  void setSource(Value *Ptr) {\n    assert(getRawSource()->getType() == Ptr->getType() &&\n           \"setSource called with pointer of wrong type!\");\n    BaseCL::setArgOperand(ARG_SOURCE, Ptr);\n  }\n\n  /// FIXME: Remove this function once transition to Align is over.\n  /// Use the version that takes MaybeAlign instead of this one.\n  void setSourceAlignment(unsigned Alignment) {\n    setSourceAlignment(MaybeAlign(Alignment));\n  }\n  void setSourceAlignment(MaybeAlign Alignment) {\n    BaseCL::removeParamAttr(ARG_SOURCE, Attribute::Alignment);\n    if (Alignment)\n      BaseCL::addParamAttr(ARG_SOURCE, Attribute::getWithAlignment(\n                                           BaseCL::getContext(), *Alignment));\n  }\n  void setSourceAlignment(Align Alignment) {\n    BaseCL::removeParamAttr(ARG_SOURCE, Attribute::Alignment);\n    BaseCL::addParamAttr(ARG_SOURCE, Attribute::getWithAlignment(\n                                         BaseCL::getContext(), Alignment));\n  }\n};\n\n/// Common base class for all memset intrinsics. Simply provides\n/// common methods.\ntemplate <class BaseCL> class MemSetBase : public BaseCL {\nprivate:\n  enum { ARG_VALUE = 1 };\n\npublic:\n  Value *getValue() const {\n    return const_cast<Value *>(BaseCL::getArgOperand(ARG_VALUE));\n  }\n  const Use &getValueUse() const { return BaseCL::getArgOperandUse(ARG_VALUE); }\n  Use &getValueUse() { return BaseCL::getArgOperandUse(ARG_VALUE); }\n\n  void setValue(Value *Val) {\n    assert(getValue()->getType() == Val->getType() &&\n           \"setValue called with value of wrong type!\");\n    BaseCL::setArgOperand(ARG_VALUE, Val);\n  }\n};\n\n// The common base class for the atomic memset/memmove/memcpy intrinsics\n// i.e. llvm.element.unordered.atomic.memset/memcpy/memmove\nclass AtomicMemIntrinsic : public MemIntrinsicBase<AtomicMemIntrinsic> {\nprivate:\n  enum { ARG_ELEMENTSIZE = 3 };\n\npublic:\n  Value *getRawElementSizeInBytes() const {\n    return const_cast<Value *>(getArgOperand(ARG_ELEMENTSIZE));\n  }\n\n  ConstantInt *getElementSizeInBytesCst() const {\n    return cast<ConstantInt>(getRawElementSizeInBytes());\n  }\n\n  uint32_t getElementSizeInBytes() const {\n    return getElementSizeInBytesCst()->getZExtValue();\n  }\n\n  void setElementSizeInBytes(Constant *V) {\n    assert(V->getType() == Type::getInt8Ty(getContext()) &&\n           \"setElementSizeInBytes called with value of wrong type!\");\n    setArgOperand(ARG_ELEMENTSIZE, V);\n  }\n\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy_element_unordered_atomic:\n    case Intrinsic::memmove_element_unordered_atomic:\n    case Intrinsic::memset_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents atomic memset intrinsic\n// i.e. llvm.element.unordered.atomic.memset\nclass AtomicMemSetInst : public MemSetBase<AtomicMemIntrinsic> {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memset_element_unordered_atomic;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n// This class wraps the atomic memcpy/memmove intrinsics\n// i.e. llvm.element.unordered.atomic.memcpy/memmove\nclass AtomicMemTransferInst : public MemTransferBase<AtomicMemIntrinsic> {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy_element_unordered_atomic:\n    case Intrinsic::memmove_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents the atomic memcpy intrinsic\n/// i.e. llvm.element.unordered.atomic.memcpy\nclass AtomicMemCpyInst : public AtomicMemTransferInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memcpy_element_unordered_atomic;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents the atomic memmove intrinsic\n/// i.e. llvm.element.unordered.atomic.memmove\nclass AtomicMemMoveInst : public AtomicMemTransferInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memmove_element_unordered_atomic;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This is the common base class for memset/memcpy/memmove.\nclass MemIntrinsic : public MemIntrinsicBase<MemIntrinsic> {\nprivate:\n  enum { ARG_VOLATILE = 3 };\n\npublic:\n  ConstantInt *getVolatileCst() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(ARG_VOLATILE)));\n  }\n\n  bool isVolatile() const { return !getVolatileCst()->isZero(); }\n\n  void setVolatile(Constant *V) { setArgOperand(ARG_VOLATILE, V); }\n\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy:\n    case Intrinsic::memmove:\n    case Intrinsic::memset:\n    case Intrinsic::memcpy_inline:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class wraps the llvm.memset intrinsic.\nclass MemSetInst : public MemSetBase<MemIntrinsic> {\npublic:\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memset;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class wraps the llvm.memcpy/memmove intrinsics.\nclass MemTransferInst : public MemTransferBase<MemIntrinsic> {\npublic:\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy:\n    case Intrinsic::memmove:\n    case Intrinsic::memcpy_inline:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class wraps the llvm.memcpy intrinsic.\nclass MemCpyInst : public MemTransferInst {\npublic:\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memcpy;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class wraps the llvm.memmove intrinsic.\nclass MemMoveInst : public MemTransferInst {\npublic:\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memmove;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class wraps the llvm.memcpy.inline intrinsic.\nclass MemCpyInlineInst : public MemTransferInst {\npublic:\n  ConstantInt *getLength() const {\n    return cast<ConstantInt>(MemTransferInst::getLength());\n  }\n  // Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::memcpy_inline;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n// The common base class for any memset/memmove/memcpy intrinsics;\n// whether they be atomic or non-atomic.\n// i.e. llvm.element.unordered.atomic.memset/memcpy/memmove\n//  and llvm.memset/memcpy/memmove\nclass AnyMemIntrinsic : public MemIntrinsicBase<AnyMemIntrinsic> {\npublic:\n  bool isVolatile() const {\n    // Only the non-atomic intrinsics can be volatile\n    if (auto *MI = dyn_cast<MemIntrinsic>(this))\n      return MI->isVolatile();\n    return false;\n  }\n\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy:\n    case Intrinsic::memcpy_inline:\n    case Intrinsic::memmove:\n    case Intrinsic::memset:\n    case Intrinsic::memcpy_element_unordered_atomic:\n    case Intrinsic::memmove_element_unordered_atomic:\n    case Intrinsic::memset_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents any memset intrinsic\n// i.e. llvm.element.unordered.atomic.memset\n// and  llvm.memset\nclass AnyMemSetInst : public MemSetBase<AnyMemIntrinsic> {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memset:\n    case Intrinsic::memset_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n// This class wraps any memcpy/memmove intrinsics\n// i.e. llvm.element.unordered.atomic.memcpy/memmove\n// and  llvm.memcpy/memmove\nclass AnyMemTransferInst : public MemTransferBase<AnyMemIntrinsic> {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy:\n    case Intrinsic::memcpy_inline:\n    case Intrinsic::memmove:\n    case Intrinsic::memcpy_element_unordered_atomic:\n    case Intrinsic::memmove_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents any memcpy intrinsic\n/// i.e. llvm.element.unordered.atomic.memcpy\n///  and llvm.memcpy\nclass AnyMemCpyInst : public AnyMemTransferInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memcpy:\n    case Intrinsic::memcpy_inline:\n    case Intrinsic::memcpy_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This class represents any memmove intrinsic\n/// i.e. llvm.element.unordered.atomic.memmove\n///  and llvm.memmove\nclass AnyMemMoveInst : public AnyMemTransferInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    switch (I->getIntrinsicID()) {\n    case Intrinsic::memmove:\n    case Intrinsic::memmove_element_unordered_atomic:\n      return true;\n    default:\n      return false;\n    }\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This represents the llvm.va_start intrinsic.\nclass VAStartInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::vastart;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  Value *getArgList() const { return const_cast<Value *>(getArgOperand(0)); }\n};\n\n/// This represents the llvm.va_end intrinsic.\nclass VAEndInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::vaend;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  Value *getArgList() const { return const_cast<Value *>(getArgOperand(0)); }\n};\n\n/// This represents the llvm.va_copy intrinsic.\nclass VACopyInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::vacopy;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  Value *getDest() const { return const_cast<Value *>(getArgOperand(0)); }\n  Value *getSrc() const { return const_cast<Value *>(getArgOperand(1)); }\n};\n\n/// This represents the llvm.instrprof_increment intrinsic.\nclass InstrProfIncrementInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::instrprof_increment;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  GlobalVariable *getName() const {\n    return cast<GlobalVariable>(\n        const_cast<Value *>(getArgOperand(0))->stripPointerCasts());\n  }\n\n  ConstantInt *getHash() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(1)));\n  }\n\n  ConstantInt *getNumCounters() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(2)));\n  }\n\n  ConstantInt *getIndex() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(3)));\n  }\n\n  Value *getStep() const;\n};\n\nclass InstrProfIncrementInstStep : public InstrProfIncrementInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::instrprof_increment_step;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n};\n\n/// This represents the llvm.instrprof_value_profile intrinsic.\nclass InstrProfValueProfileInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::instrprof_value_profile;\n  }\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  GlobalVariable *getName() const {\n    return cast<GlobalVariable>(\n        const_cast<Value *>(getArgOperand(0))->stripPointerCasts());\n  }\n\n  ConstantInt *getHash() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(1)));\n  }\n\n  Value *getTargetValue() const {\n    return cast<Value>(const_cast<Value *>(getArgOperand(2)));\n  }\n\n  ConstantInt *getValueKind() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(3)));\n  }\n\n  // Returns the value site index.\n  ConstantInt *getIndex() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(4)));\n  }\n};\n\nclass PseudoProbeInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::pseudoprobe;\n  }\n\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  ConstantInt *getFuncGuid() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(0)));\n  }\n\n  ConstantInt *getIndex() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(1)));\n  }\n\n  ConstantInt *getAttributes() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(2)));\n  }\n\n  ConstantInt *getFactor() const {\n    return cast<ConstantInt>(const_cast<Value *>(getArgOperand(3)));\n  }\n};\n\nclass NoAliasScopeDeclInst : public IntrinsicInst {\npublic:\n  static bool classof(const IntrinsicInst *I) {\n    return I->getIntrinsicID() == Intrinsic::experimental_noalias_scope_decl;\n  }\n\n  static bool classof(const Value *V) {\n    return isa<IntrinsicInst>(V) && classof(cast<IntrinsicInst>(V));\n  }\n\n  MDNode *getScopeList() const {\n    auto *MV =\n        cast<MetadataAsValue>(getOperand(Intrinsic::NoAliasScopeDeclScopeArg));\n    return cast<MDNode>(MV->getMetadata());\n  }\n\n  void setScopeList(MDNode *ScopeList) {\n    setOperand(Intrinsic::NoAliasScopeDeclScopeArg,\n               MetadataAsValue::get(getContext(), ScopeList));\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_IR_INTRINSICINST_H\n"}, "46": {"id": 46, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/LegacyPassManagers.h", "content": "//===- LegacyPassManagers.h - Legacy Pass Infrastructure --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file declares the LLVM Pass Manager infrastructure.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_LEGACYPASSMANAGERS_H\n#define LLVM_IR_LEGACYPASSMANAGERS_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Pass.h\"\n#include <vector>\n\n//===----------------------------------------------------------------------===//\n// Overview:\n// The Pass Manager Infrastructure manages passes. It's responsibilities are:\n//\n//   o Manage optimization pass execution order\n//   o Make required Analysis information available before pass P is run\n//   o Release memory occupied by dead passes\n//   o If Analysis information is dirtied by a pass then regenerate Analysis\n//     information before it is consumed by another pass.\n//\n// Pass Manager Infrastructure uses multiple pass managers.  They are\n// PassManager, FunctionPassManager, MPPassManager, FPPassManager, BBPassManager.\n// This class hierarchy uses multiple inheritance but pass managers do not\n// derive from another pass manager.\n//\n// PassManager and FunctionPassManager are two top-level pass manager that\n// represents the external interface of this entire pass manager infrastucture.\n//\n// Important classes :\n//\n// [o] class PMTopLevelManager;\n//\n// Two top level managers, PassManager and FunctionPassManager, derive from\n// PMTopLevelManager. PMTopLevelManager manages information used by top level\n// managers such as last user info.\n//\n// [o] class PMDataManager;\n//\n// PMDataManager manages information, e.g. list of available analysis info,\n// used by a pass manager to manage execution order of passes. It also provides\n// a place to implement common pass manager APIs. All pass managers derive from\n// PMDataManager.\n//\n// [o] class FunctionPassManager;\n//\n// This is a external interface used to manage FunctionPasses. This\n// interface relies on FunctionPassManagerImpl to do all the tasks.\n//\n// [o] class FunctionPassManagerImpl : public ModulePass, PMDataManager,\n//                                     public PMTopLevelManager;\n//\n// FunctionPassManagerImpl is a top level manager. It manages FPPassManagers\n//\n// [o] class FPPassManager : public ModulePass, public PMDataManager;\n//\n// FPPassManager manages FunctionPasses and BBPassManagers\n//\n// [o] class MPPassManager : public Pass, public PMDataManager;\n//\n// MPPassManager manages ModulePasses and FPPassManagers\n//\n// [o] class PassManager;\n//\n// This is a external interface used by various tools to manages passes. It\n// relies on PassManagerImpl to do all the tasks.\n//\n// [o] class PassManagerImpl : public Pass, public PMDataManager,\n//                             public PMTopLevelManager\n//\n// PassManagerImpl is a top level pass manager responsible for managing\n// MPPassManagers.\n//===----------------------------------------------------------------------===//\n\n#include \"llvm/Support/PrettyStackTrace.h\"\n\nnamespace llvm {\ntemplate <typename T> class ArrayRef;\nclass Module;\nclass StringRef;\nclass Value;\nclass Timer;\nclass PMDataManager;\n\n// enums for debugging strings\nenum PassDebuggingString {\n  EXECUTION_MSG, // \"Executing Pass '\" + PassName\n  MODIFICATION_MSG, // \"Made Modification '\" + PassName\n  FREEING_MSG, // \" Freeing Pass '\" + PassName\n  ON_FUNCTION_MSG, // \"' on Function '\" + FunctionName + \"'...\\n\"\n  ON_MODULE_MSG, // \"' on Module '\" + ModuleName + \"'...\\n\"\n  ON_REGION_MSG, // \"' on Region '\" + Msg + \"'...\\n'\"\n  ON_LOOP_MSG, // \"' on Loop '\" + Msg + \"'...\\n'\"\n  ON_CG_MSG // \"' on Call Graph Nodes '\" + Msg + \"'...\\n'\"\n};\n\n/// PassManagerPrettyStackEntry - This is used to print informative information\n/// about what pass is running when/if a stack trace is generated.\nclass PassManagerPrettyStackEntry : public PrettyStackTraceEntry {\n  Pass *P;\n  Value *V;\n  Module *M;\n\npublic:\n  explicit PassManagerPrettyStackEntry(Pass *p)\n    : P(p), V(nullptr), M(nullptr) {}  // When P is releaseMemory'd.\n  PassManagerPrettyStackEntry(Pass *p, Value &v)\n    : P(p), V(&v), M(nullptr) {} // When P is run on V\n  PassManagerPrettyStackEntry(Pass *p, Module &m)\n    : P(p), V(nullptr), M(&m) {} // When P is run on M\n\n  /// print - Emit information about this stack frame to OS.\n  void print(raw_ostream &OS) const override;\n};\n\n//===----------------------------------------------------------------------===//\n// PMStack\n//\n/// PMStack - This class implements a stack data structure of PMDataManager\n/// pointers.\n///\n/// Top level pass managers (see PassManager.cpp) maintain active Pass Managers\n/// using PMStack. Each Pass implements assignPassManager() to connect itself\n/// with appropriate manager. assignPassManager() walks PMStack to find\n/// suitable manager.\nclass PMStack {\npublic:\n  typedef std::vector<PMDataManager *>::const_reverse_iterator iterator;\n  iterator begin() const { return S.rbegin(); }\n  iterator end() const { return S.rend(); }\n\n  void pop();\n  PMDataManager *top() const { return S.back(); }\n  void push(PMDataManager *PM);\n  bool empty() const { return S.empty(); }\n\n  void dump() const;\n\nprivate:\n  std::vector<PMDataManager *> S;\n};\n\n//===----------------------------------------------------------------------===//\n// PMTopLevelManager\n//\n/// PMTopLevelManager manages LastUser info and collects common APIs used by\n/// top level pass managers.\nclass PMTopLevelManager {\nprotected:\n  explicit PMTopLevelManager(PMDataManager *PMDM);\n\n  unsigned getNumContainedManagers() const {\n    return (unsigned)PassManagers.size();\n  }\n\n  void initializeAllAnalysisInfo();\n\nprivate:\n  virtual PMDataManager *getAsPMDataManager() = 0;\n  virtual PassManagerType getTopLevelPassManagerType() = 0;\n\npublic:\n  /// Schedule pass P for execution. Make sure that passes required by\n  /// P are run before P is run. Update analysis info maintained by\n  /// the manager. Remove dead passes. This is a recursive function.\n  void schedulePass(Pass *P);\n\n  /// Set pass P as the last user of the given analysis passes.\n  void setLastUser(ArrayRef<Pass*> AnalysisPasses, Pass *P);\n\n  /// Collect passes whose last user is P\n  void collectLastUses(SmallVectorImpl<Pass *> &LastUses, Pass *P);\n\n  /// Find the pass that implements Analysis AID. Search immutable\n  /// passes and all pass managers. If desired pass is not found\n  /// then return NULL.\n  Pass *findAnalysisPass(AnalysisID AID);\n\n  /// Retrieve the PassInfo for an analysis.\n  const PassInfo *findAnalysisPassInfo(AnalysisID AID) const;\n\n  /// Find analysis usage information for the pass P.\n  AnalysisUsage *findAnalysisUsage(Pass *P);\n\n  virtual ~PMTopLevelManager();\n\n  /// Add immutable pass and initialize it.\n  void addImmutablePass(ImmutablePass *P);\n\n  inline SmallVectorImpl<ImmutablePass *>& getImmutablePasses() {\n    return ImmutablePasses;\n  }\n\n  void addPassManager(PMDataManager *Manager) {\n    PassManagers.push_back(Manager);\n  }\n\n  // Add Manager into the list of managers that are not directly\n  // maintained by this top level pass manager\n  inline void addIndirectPassManager(PMDataManager *Manager) {\n    IndirectPassManagers.push_back(Manager);\n  }\n\n  // Print passes managed by this top level manager.\n  void dumpPasses() const;\n  void dumpArguments() const;\n\n  // Active Pass Managers\n  PMStack activeStack;\n\nprotected:\n  /// Collection of pass managers\n  SmallVector<PMDataManager *, 8> PassManagers;\n\nprivate:\n  /// Collection of pass managers that are not directly maintained\n  /// by this pass manager\n  SmallVector<PMDataManager *, 8> IndirectPassManagers;\n\n  // Map to keep track of last user of the analysis pass.\n  // LastUser->second is the last user of Lastuser->first.\n  // This is kept in sync with InversedLastUser.\n  DenseMap<Pass *, Pass *> LastUser;\n\n  // Map to keep track of passes that are last used by a pass.\n  // This is kept in sync with LastUser.\n  DenseMap<Pass *, SmallPtrSet<Pass *, 8> > InversedLastUser;\n\n  /// Immutable passes are managed by top level manager.\n  SmallVector<ImmutablePass *, 16> ImmutablePasses;\n\n  /// Map from ID to immutable passes.\n  SmallDenseMap<AnalysisID, ImmutablePass *, 8> ImmutablePassMap;\n\n\n  /// A wrapper around AnalysisUsage for the purpose of uniqueing.  The wrapper\n  /// is used to avoid needing to make AnalysisUsage itself a folding set node.\n  struct AUFoldingSetNode : public FoldingSetNode {\n    AnalysisUsage AU;\n    AUFoldingSetNode(const AnalysisUsage &AU) : AU(AU) {}\n    void Profile(FoldingSetNodeID &ID) const {\n      Profile(ID, AU);\n    }\n    static void Profile(FoldingSetNodeID &ID, const AnalysisUsage &AU) {\n      // TODO: We could consider sorting the dependency arrays within the\n      // AnalysisUsage (since they are conceptually unordered).\n      ID.AddBoolean(AU.getPreservesAll());\n      auto ProfileVec = [&](const SmallVectorImpl<AnalysisID>& Vec) {\n        ID.AddInteger(Vec.size());\n        for(AnalysisID AID : Vec)\n          ID.AddPointer(AID);\n      };\n      ProfileVec(AU.getRequiredSet());\n      ProfileVec(AU.getRequiredTransitiveSet());\n      ProfileVec(AU.getPreservedSet());\n      ProfileVec(AU.getUsedSet());\n    }\n  };\n\n  // Contains all of the unique combinations of AnalysisUsage.  This is helpful\n  // when we have multiple instances of the same pass since they'll usually\n  // have the same analysis usage and can share storage.\n  FoldingSet<AUFoldingSetNode> UniqueAnalysisUsages;\n\n  // Allocator used for allocating UAFoldingSetNodes.  This handles deletion of\n  // all allocated nodes in one fell swoop.\n  SpecificBumpPtrAllocator<AUFoldingSetNode> AUFoldingSetNodeAllocator;\n\n  // Maps from a pass to it's associated entry in UniqueAnalysisUsages.  Does\n  // not own the storage associated with either key or value..\n  DenseMap<Pass *, AnalysisUsage*> AnUsageMap;\n\n  /// Collection of PassInfo objects found via analysis IDs and in this top\n  /// level manager. This is used to memoize queries to the pass registry.\n  /// FIXME: This is an egregious hack because querying the pass registry is\n  /// either slow or racy.\n  mutable DenseMap<AnalysisID, const PassInfo *> AnalysisPassInfos;\n};\n\n//===----------------------------------------------------------------------===//\n// PMDataManager\n\n/// PMDataManager provides the common place to manage the analysis data\n/// used by pass managers.\nclass PMDataManager {\npublic:\n  explicit PMDataManager() : TPM(nullptr), Depth(0) {\n    initializeAnalysisInfo();\n  }\n\n  virtual ~PMDataManager();\n\n  virtual Pass *getAsPass() = 0;\n\n  /// Augment AvailableAnalysis by adding analysis made available by pass P.\n  void recordAvailableAnalysis(Pass *P);\n\n  /// verifyPreservedAnalysis -- Verify analysis presreved by pass P.\n  void verifyPreservedAnalysis(Pass *P);\n\n  /// Remove Analysis that is not preserved by the pass\n  void removeNotPreservedAnalysis(Pass *P);\n\n  /// Remove dead passes used by P.\n  void removeDeadPasses(Pass *P, StringRef Msg,\n                        enum PassDebuggingString);\n\n  /// Remove P.\n  void freePass(Pass *P, StringRef Msg,\n                enum PassDebuggingString);\n\n  /// Add pass P into the PassVector. Update\n  /// AvailableAnalysis appropriately if ProcessAnalysis is true.\n  void add(Pass *P, bool ProcessAnalysis = true);\n\n  /// Add RequiredPass into list of lower level passes required by pass P.\n  /// RequiredPass is run on the fly by Pass Manager when P requests it\n  /// through getAnalysis interface.\n  virtual void addLowerLevelRequiredPass(Pass *P, Pass *RequiredPass);\n\n  virtual std::tuple<Pass *, bool> getOnTheFlyPass(Pass *P, AnalysisID PI,\n                                                   Function &F);\n\n  /// Initialize available analysis information.\n  void initializeAnalysisInfo() {\n    AvailableAnalysis.clear();\n    for (auto &IA : InheritedAnalysis)\n      IA = nullptr;\n  }\n\n  // Return true if P preserves high level analysis used by other\n  // passes that are managed by this manager.\n  bool preserveHigherLevelAnalysis(Pass *P);\n\n  /// Populate UsedPasses with analysis pass that are used or required by pass\n  /// P and are available. Populate ReqPassNotAvailable with analysis pass that\n  /// are required by pass P but are not available.\n  void collectRequiredAndUsedAnalyses(\n      SmallVectorImpl<Pass *> &UsedPasses,\n      SmallVectorImpl<AnalysisID> &ReqPassNotAvailable, Pass *P);\n\n  /// All Required analyses should be available to the pass as it runs!  Here\n  /// we fill in the AnalysisImpls member of the pass so that it can\n  /// successfully use the getAnalysis() method to retrieve the\n  /// implementations it needs.\n  void initializeAnalysisImpl(Pass *P);\n\n  /// Find the pass that implements Analysis AID. If desired pass is not found\n  /// then return NULL.\n  Pass *findAnalysisPass(AnalysisID AID, bool Direction);\n\n  // Access toplevel manager\n  PMTopLevelManager *getTopLevelManager() { return TPM; }\n  void setTopLevelManager(PMTopLevelManager *T) { TPM = T; }\n\n  unsigned getDepth() const { return Depth; }\n  void setDepth(unsigned newDepth) { Depth = newDepth; }\n\n  // Print routines used by debug-pass\n  void dumpLastUses(Pass *P, unsigned Offset) const;\n  void dumpPassArguments() const;\n  void dumpPassInfo(Pass *P, enum PassDebuggingString S1,\n                    enum PassDebuggingString S2, StringRef Msg);\n  void dumpRequiredSet(const Pass *P) const;\n  void dumpPreservedSet(const Pass *P) const;\n  void dumpUsedSet(const Pass *P) const;\n\n  unsigned getNumContainedPasses() const {\n    return (unsigned)PassVector.size();\n  }\n\n  virtual PassManagerType getPassManagerType() const {\n    assert ( 0 && \"Invalid use of getPassManagerType\");\n    return PMT_Unknown;\n  }\n\n  DenseMap<AnalysisID, Pass*> *getAvailableAnalysis() {\n    return &AvailableAnalysis;\n  }\n\n  // Collect AvailableAnalysis from all the active Pass Managers.\n  void populateInheritedAnalysis(PMStack &PMS) {\n    unsigned Index = 0;\n    for (PMDataManager *PMDM : PMS)\n      InheritedAnalysis[Index++] = PMDM->getAvailableAnalysis();\n  }\n\n  /// Set the initial size of the module if the user has specified that they\n  /// want remarks for size.\n  /// Returns 0 if the remark was not requested.\n  unsigned initSizeRemarkInfo(\n      Module &M,\n      StringMap<std::pair<unsigned, unsigned>> &FunctionToInstrCount);\n\n  /// Emit a remark signifying that the number of IR instructions in the module\n  /// changed.\n  /// \\p F is optionally passed by passes which run on Functions, and thus\n  /// always know whether or not a non-empty function is available.\n  ///\n  /// \\p FunctionToInstrCount maps the name of a \\p Function to a pair. The\n  /// first member of the pair is the IR count of the \\p Function before running\n  /// \\p P, and the second member is the IR count of the \\p Function after\n  /// running \\p P.\n  void emitInstrCountChangedRemark(\n      Pass *P, Module &M, int64_t Delta, unsigned CountBefore,\n      StringMap<std::pair<unsigned, unsigned>> &FunctionToInstrCount,\n      Function *F = nullptr);\n\nprotected:\n  // Top level manager.\n  PMTopLevelManager *TPM;\n\n  // Collection of pass that are managed by this manager\n  SmallVector<Pass *, 16> PassVector;\n\n  // Collection of Analysis provided by Parent pass manager and\n  // used by current pass manager. At at time there can not be more\n  // then PMT_Last active pass mangers.\n  DenseMap<AnalysisID, Pass *> *InheritedAnalysis[PMT_Last];\n\n  /// isPassDebuggingExecutionsOrMore - Return true if -debug-pass=Executions\n  /// or higher is specified.\n  bool isPassDebuggingExecutionsOrMore() const;\n\nprivate:\n  void dumpAnalysisUsage(StringRef Msg, const Pass *P,\n                         const AnalysisUsage::VectorType &Set) const;\n\n  // Set of available Analysis. This information is used while scheduling\n  // pass. If a pass requires an analysis which is not available then\n  // the required analysis pass is scheduled to run before the pass itself is\n  // scheduled to run.\n  DenseMap<AnalysisID, Pass*> AvailableAnalysis;\n\n  // Collection of higher level analysis used by the pass managed by\n  // this manager.\n  SmallVector<Pass *, 16> HigherLevelAnalysis;\n\n  unsigned Depth;\n};\n\n//===----------------------------------------------------------------------===//\n// FPPassManager\n//\n/// FPPassManager manages BBPassManagers and FunctionPasses.\n/// It batches all function passes and basic block pass managers together and\n/// sequence them to process one function at a time before processing next\n/// function.\nclass FPPassManager : public ModulePass, public PMDataManager {\npublic:\n  static char ID;\n  explicit FPPassManager()\n  : ModulePass(ID), PMDataManager() { }\n\n  /// run - Execute all of the passes scheduled for execution.  Keep track of\n  /// whether any of the passes modifies the module, and if so, return true.\n  bool runOnFunction(Function &F);\n  bool runOnModule(Module &M) override;\n\n  /// cleanup - After running all passes, clean up pass manager cache.\n  void cleanup();\n\n  /// doInitialization - Overrides ModulePass doInitialization for global\n  /// initialization tasks\n  ///\n  using ModulePass::doInitialization;\n\n  /// doInitialization - Run all of the initializers for the function passes.\n  ///\n  bool doInitialization(Module &M) override;\n\n  /// doFinalization - Overrides ModulePass doFinalization for global\n  /// finalization tasks\n  ///\n  using ModulePass::doFinalization;\n\n  /// doFinalization - Run all of the finalizers for the function passes.\n  ///\n  bool doFinalization(Module &M) override;\n\n  PMDataManager *getAsPMDataManager() override { return this; }\n  Pass *getAsPass() override { return this; }\n\n  /// Pass Manager itself does not invalidate any analysis info.\n  void getAnalysisUsage(AnalysisUsage &Info) const override {\n    Info.setPreservesAll();\n  }\n\n  // Print passes managed by this manager\n  void dumpPassStructure(unsigned Offset) override;\n\n  StringRef getPassName() const override { return \"Function Pass Manager\"; }\n\n  FunctionPass *getContainedPass(unsigned N) {\n    assert ( N < PassVector.size() && \"Pass number out of range!\");\n    FunctionPass *FP = static_cast<FunctionPass *>(PassVector[N]);\n    return FP;\n  }\n\n  PassManagerType getPassManagerType() const override {\n    return PMT_FunctionPassManager;\n  }\n};\n\n}\n\n#endif\n"}, "48": {"id": 48, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Operator.h", "content": "//===-- llvm/Operator.h - Operator utility subclass -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines various classes for working with Instructions and\n// ConstantExprs.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_OPERATOR_H\n#define LLVM_IR_OPERATOR_H\n\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/Support/Casting.h\"\n#include <cstddef>\n\nnamespace llvm {\n\n/// This is a utility class that provides an abstraction for the common\n/// functionality between Instructions and ConstantExprs.\nclass Operator : public User {\npublic:\n  // The Operator class is intended to be used as a utility, and is never itself\n  // instantiated.\n  Operator() = delete;\n  ~Operator() = delete;\n\n  void *operator new(size_t s) = delete;\n\n  /// Return the opcode for this Instruction or ConstantExpr.\n  unsigned getOpcode() const {\n    if (const Instruction *I = dyn_cast<Instruction>(this))\n      return I->getOpcode();\n    return cast<ConstantExpr>(this)->getOpcode();\n  }\n\n  /// If V is an Instruction or ConstantExpr, return its opcode.\n  /// Otherwise return UserOp1.\n  static unsigned getOpcode(const Value *V) {\n    if (const Instruction *I = dyn_cast<Instruction>(V))\n      return I->getOpcode();\n    if (const ConstantExpr *CE = dyn_cast<ConstantExpr>(V))\n      return CE->getOpcode();\n    return Instruction::UserOp1;\n  }\n\n  static bool classof(const Instruction *) { return true; }\n  static bool classof(const ConstantExpr *) { return true; }\n  static bool classof(const Value *V) {\n    return isa<Instruction>(V) || isa<ConstantExpr>(V);\n  }\n};\n\n/// Utility class for integer operators which may exhibit overflow - Add, Sub,\n/// Mul, and Shl. It does not include SDiv, despite that operator having the\n/// potential for overflow.\nclass OverflowingBinaryOperator : public Operator {\npublic:\n  enum {\n    AnyWrap        = 0,\n    NoUnsignedWrap = (1 << 0),\n    NoSignedWrap   = (1 << 1)\n  };\n\nprivate:\n  friend class Instruction;\n  friend class ConstantExpr;\n\n  void setHasNoUnsignedWrap(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~NoUnsignedWrap) | (B * NoUnsignedWrap);\n  }\n  void setHasNoSignedWrap(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~NoSignedWrap) | (B * NoSignedWrap);\n  }\n\npublic:\n  /// Test whether this operation is known to never\n  /// undergo unsigned overflow, aka the nuw property.\n  bool hasNoUnsignedWrap() const {\n    return SubclassOptionalData & NoUnsignedWrap;\n  }\n\n  /// Test whether this operation is known to never\n  /// undergo signed overflow, aka the nsw property.\n  bool hasNoSignedWrap() const {\n    return (SubclassOptionalData & NoSignedWrap) != 0;\n  }\n\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Instruction::Add ||\n           I->getOpcode() == Instruction::Sub ||\n           I->getOpcode() == Instruction::Mul ||\n           I->getOpcode() == Instruction::Shl;\n  }\n  static bool classof(const ConstantExpr *CE) {\n    return CE->getOpcode() == Instruction::Add ||\n           CE->getOpcode() == Instruction::Sub ||\n           CE->getOpcode() == Instruction::Mul ||\n           CE->getOpcode() == Instruction::Shl;\n  }\n  static bool classof(const Value *V) {\n    return (isa<Instruction>(V) && classof(cast<Instruction>(V))) ||\n           (isa<ConstantExpr>(V) && classof(cast<ConstantExpr>(V)));\n  }\n};\n\n/// A udiv or sdiv instruction, which can be marked as \"exact\",\n/// indicating that no bits are destroyed.\nclass PossiblyExactOperator : public Operator {\npublic:\n  enum {\n    IsExact = (1 << 0)\n  };\n\nprivate:\n  friend class Instruction;\n  friend class ConstantExpr;\n\n  void setIsExact(bool B) {\n    SubclassOptionalData = (SubclassOptionalData & ~IsExact) | (B * IsExact);\n  }\n\npublic:\n  /// Test whether this division is known to be exact, with zero remainder.\n  bool isExact() const {\n    return SubclassOptionalData & IsExact;\n  }\n\n  static bool isPossiblyExactOpcode(unsigned OpC) {\n    return OpC == Instruction::SDiv ||\n           OpC == Instruction::UDiv ||\n           OpC == Instruction::AShr ||\n           OpC == Instruction::LShr;\n  }\n\n  static bool classof(const ConstantExpr *CE) {\n    return isPossiblyExactOpcode(CE->getOpcode());\n  }\n  static bool classof(const Instruction *I) {\n    return isPossiblyExactOpcode(I->getOpcode());\n  }\n  static bool classof(const Value *V) {\n    return (isa<Instruction>(V) && classof(cast<Instruction>(V))) ||\n           (isa<ConstantExpr>(V) && classof(cast<ConstantExpr>(V)));\n  }\n};\n\n/// Convenience struct for specifying and reasoning about fast-math flags.\nclass FastMathFlags {\nprivate:\n  friend class FPMathOperator;\n\n  unsigned Flags = 0;\n\n  FastMathFlags(unsigned F) {\n    // If all 7 bits are set, turn this into -1. If the number of bits grows,\n    // this must be updated. This is intended to provide some forward binary\n    // compatibility insurance for the meaning of 'fast' in case bits are added.\n    if (F == 0x7F) Flags = ~0U;\n    else Flags = F;\n  }\n\npublic:\n  // This is how the bits are used in Value::SubclassOptionalData so they\n  // should fit there too.\n  // WARNING: We're out of space. SubclassOptionalData only has 7 bits. New\n  // functionality will require a change in how this information is stored.\n  enum {\n    AllowReassoc    = (1 << 0),\n    NoNaNs          = (1 << 1),\n    NoInfs          = (1 << 2),\n    NoSignedZeros   = (1 << 3),\n    AllowReciprocal = (1 << 4),\n    AllowContract   = (1 << 5),\n    ApproxFunc      = (1 << 6)\n  };\n\n  FastMathFlags() = default;\n\n  static FastMathFlags getFast() {\n    FastMathFlags FMF;\n    FMF.setFast();\n    return FMF;\n  }\n\n  bool any() const { return Flags != 0; }\n  bool none() const { return Flags == 0; }\n  bool all() const { return Flags == ~0U; }\n\n  void clear() { Flags = 0; }\n  void set()   { Flags = ~0U; }\n\n  /// Flag queries\n  bool allowReassoc() const    { return 0 != (Flags & AllowReassoc); }\n  bool noNaNs() const          { return 0 != (Flags & NoNaNs); }\n  bool noInfs() const          { return 0 != (Flags & NoInfs); }\n  bool noSignedZeros() const   { return 0 != (Flags & NoSignedZeros); }\n  bool allowReciprocal() const { return 0 != (Flags & AllowReciprocal); }\n  bool allowContract() const   { return 0 != (Flags & AllowContract); }\n  bool approxFunc() const      { return 0 != (Flags & ApproxFunc); }\n  /// 'Fast' means all bits are set.\n  bool isFast() const          { return all(); }\n\n  /// Flag setters\n  void setAllowReassoc(bool B = true) {\n    Flags = (Flags & ~AllowReassoc) | B * AllowReassoc;\n  }\n  void setNoNaNs(bool B = true) {\n    Flags = (Flags & ~NoNaNs) | B * NoNaNs;\n  }\n  void setNoInfs(bool B = true) {\n    Flags = (Flags & ~NoInfs) | B * NoInfs;\n  }\n  void setNoSignedZeros(bool B = true) {\n    Flags = (Flags & ~NoSignedZeros) | B * NoSignedZeros;\n  }\n  void setAllowReciprocal(bool B = true) {\n    Flags = (Flags & ~AllowReciprocal) | B * AllowReciprocal;\n  }\n  void setAllowContract(bool B = true) {\n    Flags = (Flags & ~AllowContract) | B * AllowContract;\n  }\n  void setApproxFunc(bool B = true) {\n    Flags = (Flags & ~ApproxFunc) | B * ApproxFunc;\n  }\n  void setFast(bool B = true) { B ? set() : clear(); }\n\n  void operator&=(const FastMathFlags &OtherFlags) {\n    Flags &= OtherFlags.Flags;\n  }\n  void operator|=(const FastMathFlags &OtherFlags) {\n    Flags |= OtherFlags.Flags;\n  }\n};\n\n/// Utility class for floating point operations which can have\n/// information about relaxed accuracy requirements attached to them.\nclass FPMathOperator : public Operator {\nprivate:\n  friend class Instruction;\n\n  /// 'Fast' means all bits are set.\n  void setFast(bool B) {\n    setHasAllowReassoc(B);\n    setHasNoNaNs(B);\n    setHasNoInfs(B);\n    setHasNoSignedZeros(B);\n    setHasAllowReciprocal(B);\n    setHasAllowContract(B);\n    setHasApproxFunc(B);\n  }\n\n  void setHasAllowReassoc(bool B) {\n    SubclassOptionalData =\n    (SubclassOptionalData & ~FastMathFlags::AllowReassoc) |\n    (B * FastMathFlags::AllowReassoc);\n  }\n\n  void setHasNoNaNs(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~FastMathFlags::NoNaNs) |\n      (B * FastMathFlags::NoNaNs);\n  }\n\n  void setHasNoInfs(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~FastMathFlags::NoInfs) |\n      (B * FastMathFlags::NoInfs);\n  }\n\n  void setHasNoSignedZeros(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~FastMathFlags::NoSignedZeros) |\n      (B * FastMathFlags::NoSignedZeros);\n  }\n\n  void setHasAllowReciprocal(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~FastMathFlags::AllowReciprocal) |\n      (B * FastMathFlags::AllowReciprocal);\n  }\n\n  void setHasAllowContract(bool B) {\n    SubclassOptionalData =\n        (SubclassOptionalData & ~FastMathFlags::AllowContract) |\n        (B * FastMathFlags::AllowContract);\n  }\n\n  void setHasApproxFunc(bool B) {\n    SubclassOptionalData =\n        (SubclassOptionalData & ~FastMathFlags::ApproxFunc) |\n        (B * FastMathFlags::ApproxFunc);\n  }\n\n  /// Convenience function for setting multiple fast-math flags.\n  /// FMF is a mask of the bits to set.\n  void setFastMathFlags(FastMathFlags FMF) {\n    SubclassOptionalData |= FMF.Flags;\n  }\n\n  /// Convenience function for copying all fast-math flags.\n  /// All values in FMF are transferred to this operator.\n  void copyFastMathFlags(FastMathFlags FMF) {\n    SubclassOptionalData = FMF.Flags;\n  }\n\npublic:\n  /// Test if this operation allows all non-strict floating-point transforms.\n  bool isFast() const {\n    return ((SubclassOptionalData & FastMathFlags::AllowReassoc) != 0 &&\n            (SubclassOptionalData & FastMathFlags::NoNaNs) != 0 &&\n            (SubclassOptionalData & FastMathFlags::NoInfs) != 0 &&\n            (SubclassOptionalData & FastMathFlags::NoSignedZeros) != 0 &&\n            (SubclassOptionalData & FastMathFlags::AllowReciprocal) != 0 &&\n            (SubclassOptionalData & FastMathFlags::AllowContract) != 0 &&\n            (SubclassOptionalData & FastMathFlags::ApproxFunc) != 0);\n  }\n\n  /// Test if this operation may be simplified with reassociative transforms.\n  bool hasAllowReassoc() const {\n    return (SubclassOptionalData & FastMathFlags::AllowReassoc) != 0;\n  }\n\n  /// Test if this operation's arguments and results are assumed not-NaN.\n  bool hasNoNaNs() const {\n    return (SubclassOptionalData & FastMathFlags::NoNaNs) != 0;\n  }\n\n  /// Test if this operation's arguments and results are assumed not-infinite.\n  bool hasNoInfs() const {\n    return (SubclassOptionalData & FastMathFlags::NoInfs) != 0;\n  }\n\n  /// Test if this operation can ignore the sign of zero.\n  bool hasNoSignedZeros() const {\n    return (SubclassOptionalData & FastMathFlags::NoSignedZeros) != 0;\n  }\n\n  /// Test if this operation can use reciprocal multiply instead of division.\n  bool hasAllowReciprocal() const {\n    return (SubclassOptionalData & FastMathFlags::AllowReciprocal) != 0;\n  }\n\n  /// Test if this operation can be floating-point contracted (FMA).\n  bool hasAllowContract() const {\n    return (SubclassOptionalData & FastMathFlags::AllowContract) != 0;\n  }\n\n  /// Test if this operation allows approximations of math library functions or\n  /// intrinsics.\n  bool hasApproxFunc() const {\n    return (SubclassOptionalData & FastMathFlags::ApproxFunc) != 0;\n  }\n\n  /// Convenience function for getting all the fast-math flags\n  FastMathFlags getFastMathFlags() const {\n    return FastMathFlags(SubclassOptionalData);\n  }\n\n  /// Get the maximum error permitted by this operation in ULPs. An accuracy of\n  /// 0.0 means that the operation should be performed with the default\n  /// precision.\n  float getFPAccuracy() const;\n\n  static bool classof(const Value *V) {\n    unsigned Opcode;\n    if (auto *I = dyn_cast<Instruction>(V))\n      Opcode = I->getOpcode();\n    else if (auto *CE = dyn_cast<ConstantExpr>(V))\n      Opcode = CE->getOpcode();\n    else\n      return false;\n\n    switch (Opcode) {\n    case Instruction::FNeg:\n    case Instruction::FAdd:\n    case Instruction::FSub:\n    case Instruction::FMul:\n    case Instruction::FDiv:\n    case Instruction::FRem:\n    // FIXME: To clean up and correct the semantics of fast-math-flags, FCmp\n    //        should not be treated as a math op, but the other opcodes should.\n    //        This would make things consistent with Select/PHI (FP value type\n    //        determines whether they are math ops and, therefore, capable of\n    //        having fast-math-flags).\n    case Instruction::FCmp:\n      return true;\n    case Instruction::PHI:\n    case Instruction::Select:\n    case Instruction::Call: {\n      Type *Ty = V->getType();\n      while (ArrayType *ArrTy = dyn_cast<ArrayType>(Ty))\n        Ty = ArrTy->getElementType();\n      return Ty->isFPOrFPVectorTy();\n    }\n    default:\n      return false;\n    }\n  }\n};\n\n/// A helper template for defining operators for individual opcodes.\ntemplate<typename SuperClass, unsigned Opc>\nclass ConcreteOperator : public SuperClass {\npublic:\n  static bool classof(const Instruction *I) {\n    return I->getOpcode() == Opc;\n  }\n  static bool classof(const ConstantExpr *CE) {\n    return CE->getOpcode() == Opc;\n  }\n  static bool classof(const Value *V) {\n    return (isa<Instruction>(V) && classof(cast<Instruction>(V))) ||\n           (isa<ConstantExpr>(V) && classof(cast<ConstantExpr>(V)));\n  }\n};\n\nclass AddOperator\n  : public ConcreteOperator<OverflowingBinaryOperator, Instruction::Add> {\n};\nclass SubOperator\n  : public ConcreteOperator<OverflowingBinaryOperator, Instruction::Sub> {\n};\nclass MulOperator\n  : public ConcreteOperator<OverflowingBinaryOperator, Instruction::Mul> {\n};\nclass ShlOperator\n  : public ConcreteOperator<OverflowingBinaryOperator, Instruction::Shl> {\n};\n\nclass SDivOperator\n  : public ConcreteOperator<PossiblyExactOperator, Instruction::SDiv> {\n};\nclass UDivOperator\n  : public ConcreteOperator<PossiblyExactOperator, Instruction::UDiv> {\n};\nclass AShrOperator\n  : public ConcreteOperator<PossiblyExactOperator, Instruction::AShr> {\n};\nclass LShrOperator\n  : public ConcreteOperator<PossiblyExactOperator, Instruction::LShr> {\n};\n\nclass ZExtOperator : public ConcreteOperator<Operator, Instruction::ZExt> {};\n\nclass GEPOperator\n  : public ConcreteOperator<Operator, Instruction::GetElementPtr> {\n  friend class GetElementPtrInst;\n  friend class ConstantExpr;\n\n  enum {\n    IsInBounds = (1 << 0),\n    // InRangeIndex: bits 1-6\n  };\n\n  void setIsInBounds(bool B) {\n    SubclassOptionalData =\n      (SubclassOptionalData & ~IsInBounds) | (B * IsInBounds);\n  }\n\npublic:\n  /// Test whether this is an inbounds GEP, as defined by LangRef.html.\n  bool isInBounds() const {\n    return SubclassOptionalData & IsInBounds;\n  }\n\n  /// Returns the offset of the index with an inrange attachment, or None if\n  /// none.\n  Optional<unsigned> getInRangeIndex() const {\n    if (SubclassOptionalData >> 1 == 0) return None;\n    return (SubclassOptionalData >> 1) - 1;\n  }\n\n  inline op_iterator       idx_begin()       { return op_begin()+1; }\n  inline const_op_iterator idx_begin() const { return op_begin()+1; }\n  inline op_iterator       idx_end()         { return op_end(); }\n  inline const_op_iterator idx_end()   const { return op_end(); }\n\n  Value *getPointerOperand() {\n    return getOperand(0);\n  }\n  const Value *getPointerOperand() const {\n    return getOperand(0);\n  }\n  static unsigned getPointerOperandIndex() {\n    return 0U;                      // get index for modifying correct operand\n  }\n\n  /// Method to return the pointer operand as a PointerType.\n  Type *getPointerOperandType() const {\n    return getPointerOperand()->getType();\n  }\n\n  Type *getSourceElementType() const;\n  Type *getResultElementType() const;\n\n  /// Method to return the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return getPointerOperandType()->getPointerAddressSpace();\n  }\n\n  unsigned getNumIndices() const {  // Note: always non-negative\n    return getNumOperands() - 1;\n  }\n\n  bool hasIndices() const {\n    return getNumOperands() > 1;\n  }\n\n  /// Return true if all of the indices of this GEP are zeros.\n  /// If so, the result pointer and the first operand have the same\n  /// value, just potentially different types.\n  bool hasAllZeroIndices() const {\n    for (const_op_iterator I = idx_begin(), E = idx_end(); I != E; ++I) {\n      if (ConstantInt *C = dyn_cast<ConstantInt>(I))\n        if (C->isZero())\n          continue;\n      return false;\n    }\n    return true;\n  }\n\n  /// Return true if all of the indices of this GEP are constant integers.\n  /// If so, the result pointer and the first operand have\n  /// a constant offset between them.\n  bool hasAllConstantIndices() const {\n    for (const_op_iterator I = idx_begin(), E = idx_end(); I != E; ++I) {\n      if (!isa<ConstantInt>(I))\n        return false;\n    }\n    return true;\n  }\n\n  unsigned countNonConstantIndices() const {\n    return count_if(make_range(idx_begin(), idx_end()), [](const Use& use) {\n        return !isa<ConstantInt>(*use);\n      });\n  }\n\n  /// Compute the maximum alignment that this GEP is garranteed to preserve.\n  Align getMaxPreservedAlignment(const DataLayout &DL) const;\n\n  /// Accumulate the constant address offset of this GEP if possible.\n  ///\n  /// This routine accepts an APInt into which it will try to accumulate the\n  /// constant offset of this GEP.\n  ///\n  /// If \\p ExternalAnalysis is provided it will be used to calculate a offset\n  /// when a operand of GEP is not constant.\n  /// For example, for a value \\p ExternalAnalysis might try to calculate a\n  /// lower bound. If \\p ExternalAnalysis is successful, it should return true.\n  ///\n  /// If the \\p ExternalAnalysis returns false or the value returned by \\p\n  /// ExternalAnalysis results in a overflow/underflow, this routine returns\n  /// false and the value of the offset APInt is undefined (it is *not*\n  /// preserved!).\n  ///\n  /// The APInt passed into this routine must be at exactly as wide as the\n  /// IntPtr type for the address space of the base GEP pointer.\n  bool accumulateConstantOffset(\n      const DataLayout &DL, APInt &Offset,\n      function_ref<bool(Value &, APInt &)> ExternalAnalysis = nullptr) const;\n\n  static bool accumulateConstantOffset(\n      Type *SourceType, ArrayRef<const Value *> Index, const DataLayout &DL,\n      APInt &Offset,\n      function_ref<bool(Value &, APInt &)> ExternalAnalysis = nullptr);\n};\n\nclass PtrToIntOperator\n    : public ConcreteOperator<Operator, Instruction::PtrToInt> {\n  friend class PtrToInt;\n  friend class ConstantExpr;\n\npublic:\n  Value *getPointerOperand() {\n    return getOperand(0);\n  }\n  const Value *getPointerOperand() const {\n    return getOperand(0);\n  }\n\n  static unsigned getPointerOperandIndex() {\n    return 0U;                      // get index for modifying correct operand\n  }\n\n  /// Method to return the pointer operand as a PointerType.\n  Type *getPointerOperandType() const {\n    return getPointerOperand()->getType();\n  }\n\n  /// Method to return the address space of the pointer operand.\n  unsigned getPointerAddressSpace() const {\n    return cast<PointerType>(getPointerOperandType())->getAddressSpace();\n  }\n};\n\nclass BitCastOperator\n    : public ConcreteOperator<Operator, Instruction::BitCast> {\n  friend class BitCastInst;\n  friend class ConstantExpr;\n\npublic:\n  Type *getSrcTy() const {\n    return getOperand(0)->getType();\n  }\n\n  Type *getDestTy() const {\n    return getType();\n  }\n};\n\nclass AddrSpaceCastOperator\n    : public ConcreteOperator<Operator, Instruction::AddrSpaceCast> {\n  friend class AddrSpaceCastInst;\n  friend class ConstantExpr;\n\npublic:\n  Value *getPointerOperand() { return getOperand(0); }\n\n  const Value *getPointerOperand() const { return getOperand(0); }\n\n  unsigned getSrcAddressSpace() const {\n    return getPointerOperand()->getType()->getPointerAddressSpace();\n  }\n\n  unsigned getDestAddressSpace() const {\n    return getType()->getPointerAddressSpace();\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_IR_OPERATOR_H\n"}, "50": {"id": 50, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/PassManagerImpl.h", "content": "//===- PassManagerImpl.h - Pass management infrastructure -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n///\n/// Provides implementations for PassManager and AnalysisManager template\n/// methods. These classes should be explicitly instantiated for any IR unit,\n/// and files doing the explicit instantiation should include this header.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_PASSMANAGERIMPL_H\n#define LLVM_IR_PASSMANAGERIMPL_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\ntemplate <typename IRUnitT, typename... ExtraArgTs>\ninline AnalysisManager<IRUnitT, ExtraArgTs...>::AnalysisManager(\n    bool DebugLogging)\n    : DebugLogging(DebugLogging) {}\n\ntemplate <typename IRUnitT, typename... ExtraArgTs>\ninline AnalysisManager<IRUnitT, ExtraArgTs...>::AnalysisManager(\n    AnalysisManager &&) = default;\n\ntemplate <typename IRUnitT, typename... ExtraArgTs>\ninline AnalysisManager<IRUnitT, ExtraArgTs...> &\nAnalysisManager<IRUnitT, ExtraArgTs...>::operator=(AnalysisManager &&) =\n    default;\n\ntemplate <typename IRUnitT, typename... ExtraArgTs>\ninline void\nAnalysisManager<IRUnitT, ExtraArgTs...>::clear(IRUnitT &IR,\n                                               llvm::StringRef Name) {\n  if (DebugLogging)\n    dbgs() << \"Clearing all analysis results for: \" << Name << \"\\n\";\n\n  auto ResultsListI = AnalysisResultLists.find(&IR);\n  if (ResultsListI == AnalysisResultLists.end())\n    return;\n  // Delete the map entries that point into the results list.\n  for (auto &IDAndResult : ResultsListI->second)\n    AnalysisResults.erase({IDAndResult.first, &IR});\n\n  // And actually destroy and erase the results associated with this IR.\n  AnalysisResultLists.erase(ResultsListI);\n}\n\ntemplate <typename IRUnitT, typename... ExtraArgTs>\ninline typename AnalysisManager<IRUnitT, ExtraArgTs...>::ResultConceptT &\nAnalysisManager<IRUnitT, ExtraArgTs...>::getResultImpl(\n    AnalysisKey *ID, IRUnitT &IR, ExtraArgTs... ExtraArgs) {\n  typename AnalysisResultMapT::iterator RI;\n  bool Inserted;\n  std::tie(RI, Inserted) = AnalysisResults.insert(std::make_pair(\n      std::make_pair(ID, &IR), typename AnalysisResultListT::iterator()));\n\n  // If we don't have a cached result for this function, look up the pass and\n  // run it to produce a result, which we then add to the cache.\n  if (Inserted) {\n    auto &P = this->lookUpPass(ID);\n\n    PassInstrumentation PI;\n    if (ID != PassInstrumentationAnalysis::ID()) {\n      PI = getResult<PassInstrumentationAnalysis>(IR, ExtraArgs...);\n      PI.runBeforeAnalysis(P, IR);\n    }\n\n    AnalysisResultListT &ResultList = AnalysisResultLists[&IR];\n    ResultList.emplace_back(ID, P.run(IR, *this, ExtraArgs...));\n\n    PI.runAfterAnalysis(P, IR);\n\n    // P.run may have inserted elements into AnalysisResults and invalidated\n    // RI.\n    RI = AnalysisResults.find({ID, &IR});\n    assert(RI != AnalysisResults.end() && \"we just inserted it!\");\n\n    RI->second = std::prev(ResultList.end());\n  }\n\n  return *RI->second->second;\n}\n\ntemplate <typename IRUnitT, typename... ExtraArgTs>\ninline void AnalysisManager<IRUnitT, ExtraArgTs...>::invalidate(\n    IRUnitT &IR, const PreservedAnalyses &PA) {\n  // We're done if all analyses on this IR unit are preserved.\n  if (PA.allAnalysesInSetPreserved<AllAnalysesOn<IRUnitT>>())\n    return;\n\n  // Track whether each analysis's result is invalidated in\n  // IsResultInvalidated.\n  SmallDenseMap<AnalysisKey *, bool, 8> IsResultInvalidated;\n  Invalidator Inv(IsResultInvalidated, AnalysisResults);\n  AnalysisResultListT &ResultsList = AnalysisResultLists[&IR];\n  for (auto &AnalysisResultPair : ResultsList) {\n    // This is basically the same thing as Invalidator::invalidate, but we\n    // can't call it here because we're operating on the type-erased result.\n    // Moreover if we instead called invalidate() directly, it would do an\n    // unnecessary look up in ResultsList.\n    AnalysisKey *ID = AnalysisResultPair.first;\n    auto &Result = *AnalysisResultPair.second;\n\n    auto IMapI = IsResultInvalidated.find(ID);\n    if (IMapI != IsResultInvalidated.end())\n      // This result was already handled via the Invalidator.\n      continue;\n\n    // Try to invalidate the result, giving it the Invalidator so it can\n    // recursively query for any dependencies it has and record the result.\n    // Note that we cannot reuse 'IMapI' here or pre-insert the ID, as\n    // Result.invalidate may insert things into the map, invalidating our\n    // iterator.\n    bool Inserted =\n        IsResultInvalidated.insert({ID, Result.invalidate(IR, PA, Inv)}).second;\n    (void)Inserted;\n    assert(Inserted && \"Should never have already inserted this ID, likely \"\n                       \"indicates a cycle!\");\n  }\n\n  // Now erase the results that were marked above as invalidated.\n  if (!IsResultInvalidated.empty()) {\n    for (auto I = ResultsList.begin(), E = ResultsList.end(); I != E;) {\n      AnalysisKey *ID = I->first;\n      if (!IsResultInvalidated.lookup(ID)) {\n        ++I;\n        continue;\n      }\n\n      if (DebugLogging)\n        dbgs() << \"Invalidating analysis: \" << this->lookUpPass(ID).name()\n               << \" on \" << IR.getName() << \"\\n\";\n\n      I = ResultsList.erase(I);\n      AnalysisResults.erase({ID, &IR});\n    }\n  }\n\n  if (ResultsList.empty())\n    AnalysisResultLists.erase(&IR);\n}\n} // end namespace llvm\n\n#endif // LLVM_IR_PASSMANAGERIMPL_H\n"}, "55": {"id": 55, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/PassAnalysisSupport.h", "content": "//===- llvm/PassAnalysisSupport.h - Analysis Pass Support code --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines stuff that is used to define and \"use\" Analysis Passes.\n// This file is automatically #included by Pass.h, so:\n//\n//           NO .CPP FILES SHOULD INCLUDE THIS FILE DIRECTLY\n//\n// Instead, #include Pass.h\n//\n//===----------------------------------------------------------------------===//\n\n#if !defined(LLVM_PASS_H) || defined(LLVM_PASSANALYSISSUPPORT_H)\n#error \"Do not include <PassAnalysisSupport.h>; include <Pass.h> instead\"\n#endif\n\n#ifndef LLVM_PASSANALYSISSUPPORT_H\n#define LLVM_PASSANALYSISSUPPORT_H\n\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include <cassert>\n#include <tuple>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\nclass Function;\nclass Pass;\nclass PMDataManager;\nclass StringRef;\n\n//===----------------------------------------------------------------------===//\n/// Represent the analysis usage information of a pass.  This tracks analyses\n/// that the pass REQUIRES (must be available when the pass runs), REQUIRES\n/// TRANSITIVE (must be available throughout the lifetime of the pass), and\n/// analyses that the pass PRESERVES (the pass does not invalidate the results\n/// of these analyses).  This information is provided by a pass to the Pass\n/// infrastructure through the getAnalysisUsage virtual function.\n///\nclass AnalysisUsage {\npublic:\n  using VectorType = SmallVectorImpl<AnalysisID>;\n\nprivate:\n  /// Sets of analyses required and preserved by a pass\n  // TODO: It's not clear that SmallVector is an appropriate data structure for\n  // this usecase.  The sizes were picked to minimize wasted space, but are\n  // otherwise fairly meaningless.\n  SmallVector<AnalysisID, 8> Required;\n  SmallVector<AnalysisID, 2> RequiredTransitive;\n  SmallVector<AnalysisID, 2> Preserved;\n  SmallVector<AnalysisID, 0> Used;\n  bool PreservesAll = false;\n\n  void pushUnique(VectorType &Set, AnalysisID ID) {\n    if (!llvm::is_contained(Set, ID))\n      Set.push_back(ID);\n  }\n\npublic:\n  AnalysisUsage() = default;\n\n  ///@{\n  /// Add the specified ID to the required set of the usage info for a pass.\n  AnalysisUsage &addRequiredID(const void *ID);\n  AnalysisUsage &addRequiredID(char &ID);\n  template<class PassClass>\n  AnalysisUsage &addRequired() {\n    return addRequiredID(PassClass::ID);\n  }\n\n  AnalysisUsage &addRequiredTransitiveID(char &ID);\n  template<class PassClass>\n  AnalysisUsage &addRequiredTransitive() {\n    return addRequiredTransitiveID(PassClass::ID);\n  }\n  ///@}\n\n  ///@{\n  /// Add the specified ID to the set of analyses preserved by this pass.\n  AnalysisUsage &addPreservedID(const void *ID) {\n    pushUnique(Preserved, ID);\n    return *this;\n  }\n  AnalysisUsage &addPreservedID(char &ID) {\n    pushUnique(Preserved, &ID);\n    return *this;\n  }\n  /// Add the specified Pass class to the set of analyses preserved by this pass.\n  template<class PassClass>\n  AnalysisUsage &addPreserved() {\n    pushUnique(Preserved, &PassClass::ID);\n    return *this;\n  }\n  ///@}\n\n  ///@{\n  /// Add the specified ID to the set of analyses used by this pass if they are\n  /// available..\n  AnalysisUsage &addUsedIfAvailableID(const void *ID) {\n    pushUnique(Used, ID);\n    return *this;\n  }\n  AnalysisUsage &addUsedIfAvailableID(char &ID) {\n    pushUnique(Used, &ID);\n    return *this;\n  }\n  /// Add the specified Pass class to the set of analyses used by this pass.\n  template<class PassClass>\n  AnalysisUsage &addUsedIfAvailable() {\n    pushUnique(Used, &PassClass::ID);\n    return *this;\n  }\n  ///@}\n\n  /// Add the Pass with the specified argument string to the set of analyses\n  /// preserved by this pass. If no such Pass exists, do nothing. This can be\n  /// useful when a pass is trivially preserved, but may not be linked in. Be\n  /// careful about spelling!\n  AnalysisUsage &addPreserved(StringRef Arg);\n\n  /// Set by analyses that do not transform their input at all\n  void setPreservesAll() { PreservesAll = true; }\n\n  /// Determine whether a pass said it does not transform its input at all\n  bool getPreservesAll() const { return PreservesAll; }\n\n  /// This function should be called by the pass, iff they do not:\n  ///\n  ///  1. Add or remove basic blocks from the function\n  ///  2. Modify terminator instructions in any way.\n  ///\n  /// This function annotates the AnalysisUsage info object to say that analyses\n  /// that only depend on the CFG are preserved by this pass.\n  void setPreservesCFG();\n\n  const VectorType &getRequiredSet() const { return Required; }\n  const VectorType &getRequiredTransitiveSet() const {\n    return RequiredTransitive;\n  }\n  const VectorType &getPreservedSet() const { return Preserved; }\n  const VectorType &getUsedSet() const { return Used; }\n};\n\n//===----------------------------------------------------------------------===//\n/// AnalysisResolver - Simple interface used by Pass objects to pull all\n/// analysis information out of pass manager that is responsible to manage\n/// the pass.\n///\nclass AnalysisResolver {\npublic:\n  AnalysisResolver() = delete;\n  explicit AnalysisResolver(PMDataManager &P) : PM(P) {}\n\n  PMDataManager &getPMDataManager() { return PM; }\n\n  /// Find pass that is implementing PI.\n  Pass *findImplPass(AnalysisID PI) {\n    Pass *ResultPass = nullptr;\n    for (const auto &AnalysisImpl : AnalysisImpls) {\n      if (AnalysisImpl.first == PI) {\n        ResultPass = AnalysisImpl.second;\n        break;\n      }\n    }\n    return ResultPass;\n  }\n\n  /// Find pass that is implementing PI. Initialize pass for Function F.\n  std::tuple<Pass *, bool> findImplPass(Pass *P, AnalysisID PI, Function &F);\n\n  void addAnalysisImplsPair(AnalysisID PI, Pass *P) {\n    if (findImplPass(PI) == P)\n      return;\n    std::pair<AnalysisID, Pass*> pir = std::make_pair(PI,P);\n    AnalysisImpls.push_back(pir);\n  }\n\n  /// Clear cache that is used to connect a pass to the analysis (PassInfo).\n  void clearAnalysisImpls() {\n    AnalysisImpls.clear();\n  }\n\n  /// Return analysis result or null if it doesn't exist.\n  Pass *getAnalysisIfAvailable(AnalysisID ID) const;\n\nprivate:\n  /// This keeps track of which passes implements the interfaces that are\n  /// required by the current pass (to implement getAnalysis()).\n  std::vector<std::pair<AnalysisID, Pass *>> AnalysisImpls;\n\n  /// PassManager that is used to resolve analysis info\n  PMDataManager &PM;\n};\n\n/// getAnalysisIfAvailable<AnalysisType>() - Subclasses use this function to\n/// get analysis information that might be around, for example to update it.\n/// This is different than getAnalysis in that it can fail (if the analysis\n/// results haven't been computed), so should only be used if you can handle\n/// the case when the analysis is not available.  This method is often used by\n/// transformation APIs to update analysis results for a pass automatically as\n/// the transform is performed.\ntemplate<typename AnalysisType>\nAnalysisType *Pass::getAnalysisIfAvailable() const {\n  assert(Resolver && \"Pass not resident in a PassManager object!\");\n\n  const void *PI = &AnalysisType::ID;\n\n  Pass *ResultPass = Resolver->getAnalysisIfAvailable(PI);\n  if (!ResultPass) return nullptr;\n\n  // Because the AnalysisType may not be a subclass of pass (for\n  // AnalysisGroups), we use getAdjustedAnalysisPointer here to potentially\n  // adjust the return pointer (because the class may multiply inherit, once\n  // from pass, once from AnalysisType).\n  return (AnalysisType*)ResultPass->getAdjustedAnalysisPointer(PI);\n}\n\n/// getAnalysis<AnalysisType>() - This function is used by subclasses to get\n/// to the analysis information that they claim to use by overriding the\n/// getAnalysisUsage function.\ntemplate<typename AnalysisType>\nAnalysisType &Pass::getAnalysis() const {\n  assert(Resolver && \"Pass has not been inserted into a PassManager object!\");\n  return getAnalysisID<AnalysisType>(&AnalysisType::ID);\n}\n\ntemplate<typename AnalysisType>\nAnalysisType &Pass::getAnalysisID(AnalysisID PI) const {\n  assert(PI && \"getAnalysis for unregistered pass!\");\n  assert(Resolver&&\"Pass has not been inserted into a PassManager object!\");\n  // PI *must* appear in AnalysisImpls.  Because the number of passes used\n  // should be a small number, we just do a linear search over a (dense)\n  // vector.\n  Pass *ResultPass = Resolver->findImplPass(PI);\n  assert(ResultPass &&\n         \"getAnalysis*() called on an analysis that was not \"\n         \"'required' by pass!\");\n\n  // Because the AnalysisType may not be a subclass of pass (for\n  // AnalysisGroups), we use getAdjustedAnalysisPointer here to potentially\n  // adjust the return pointer (because the class may multiply inherit, once\n  // from pass, once from AnalysisType).\n  return *(AnalysisType*)ResultPass->getAdjustedAnalysisPointer(PI);\n}\n\n/// getAnalysis<AnalysisType>() - This function is used by subclasses to get\n/// to the analysis information that they claim to use by overriding the\n/// getAnalysisUsage function. If as part of the dependencies, an IR\n/// transformation is triggered (e.g. because the analysis requires\n/// BreakCriticalEdges), and Changed is non null, *Changed is updated.\ntemplate <typename AnalysisType>\nAnalysisType &Pass::getAnalysis(Function &F, bool *Changed) {\n  assert(Resolver &&\"Pass has not been inserted into a PassManager object!\");\n\n  return getAnalysisID<AnalysisType>(&AnalysisType::ID, F, Changed);\n}\n\ntemplate <typename AnalysisType>\nAnalysisType &Pass::getAnalysisID(AnalysisID PI, Function &F, bool *Changed) {\n  assert(PI && \"getAnalysis for unregistered pass!\");\n  assert(Resolver && \"Pass has not been inserted into a PassManager object!\");\n  // PI *must* appear in AnalysisImpls.  Because the number of passes used\n  // should be a small number, we just do a linear search over a (dense)\n  // vector.\n  Pass *ResultPass;\n  bool LocalChanged;\n  std::tie(ResultPass, LocalChanged) = Resolver->findImplPass(this, PI, F);\n\n  assert(ResultPass && \"Unable to find requested analysis info\");\n  if (Changed)\n    *Changed |= LocalChanged;\n  else\n    assert(!LocalChanged &&\n           \"A pass trigged a code update but the update status is lost\");\n\n  // Because the AnalysisType may not be a subclass of pass (for\n  // AnalysisGroups), we use getAdjustedAnalysisPointer here to potentially\n  // adjust the return pointer (because the class may multiply inherit, once\n  // from pass, once from AnalysisType).\n  return *(AnalysisType*)ResultPass->getAdjustedAnalysisPointer(PI);\n}\n\n} // end namespace llvm\n\n#endif // LLVM_PASSANALYSISSUPPORT_H\n"}, "59": {"id": 59, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Support/CommandLine.h", "content": "//===- llvm/Support/CommandLine.h - Command line handler --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This class implements a command line argument processor that is useful when\n// creating a tool.  It provides a simple, minimalistic interface that is easily\n// extensible and supports nonlocal (library) command line options.\n//\n// Note that rather than trying to figure out what this code does, you should\n// read the library documentation located in docs/CommandLine.html or looks at\n// the many example usages in tools/*/*.cpp\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_SUPPORT_COMMANDLINE_H\n#define LLVM_SUPPORT_COMMANDLINE_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/StringMap.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"llvm/Support/ManagedStatic.h\"\n#include \"llvm/Support/VirtualFileSystem.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <cassert>\n#include <climits>\n#include <cstddef>\n#include <functional>\n#include <initializer_list>\n#include <string>\n#include <type_traits>\n#include <vector>\n\nnamespace llvm {\n\nclass StringSaver;\n\n/// cl Namespace - This namespace contains all of the command line option\n/// processing machinery.  It is intentionally a short name to make qualified\n/// usage concise.\nnamespace cl {\n\n//===----------------------------------------------------------------------===//\n// ParseCommandLineOptions - Command line option processing entry point.\n//\n// Returns true on success. Otherwise, this will print the error message to\n// stderr and exit if \\p Errs is not set (nullptr by default), or print the\n// error message to \\p Errs and return false if \\p Errs is provided.\n//\n// If EnvVar is not nullptr, command-line options are also parsed from the\n// environment variable named by EnvVar.  Precedence is given to occurrences\n// from argv.  This precedence is currently implemented by parsing argv after\n// the environment variable, so it is only implemented correctly for options\n// that give precedence to later occurrences.  If your program supports options\n// that give precedence to earlier occurrences, you will need to extend this\n// function to support it correctly.\nbool ParseCommandLineOptions(int argc, const char *const *argv,\n                             StringRef Overview = \"\",\n                             raw_ostream *Errs = nullptr,\n                             const char *EnvVar = nullptr,\n                             bool LongOptionsUseDoubleDash = false);\n\n// Function pointer type for printing version information.\nusing VersionPrinterTy = std::function<void(raw_ostream &)>;\n\n///===---------------------------------------------------------------------===//\n/// SetVersionPrinter - Override the default (LLVM specific) version printer\n///                     used to print out the version when --version is given\n///                     on the command line. This allows other systems using the\n///                     CommandLine utilities to print their own version string.\nvoid SetVersionPrinter(VersionPrinterTy func);\n\n///===---------------------------------------------------------------------===//\n/// AddExtraVersionPrinter - Add an extra printer to use in addition to the\n///                          default one. This can be called multiple times,\n///                          and each time it adds a new function to the list\n///                          which will be called after the basic LLVM version\n///                          printing is complete. Each can then add additional\n///                          information specific to the tool.\nvoid AddExtraVersionPrinter(VersionPrinterTy func);\n\n// PrintOptionValues - Print option values.\n// With -print-options print the difference between option values and defaults.\n// With -print-all-options print all option values.\n// (Currently not perfect, but best-effort.)\nvoid PrintOptionValues();\n\n// Forward declaration - AddLiteralOption needs to be up here to make gcc happy.\nclass Option;\n\n/// Adds a new option for parsing and provides the option it refers to.\n///\n/// \\param O pointer to the option\n/// \\param Name the string name for the option to handle during parsing\n///\n/// Literal options are used by some parsers to register special option values.\n/// This is how the PassNameParser registers pass names for opt.\nvoid AddLiteralOption(Option &O, StringRef Name);\n\n//===----------------------------------------------------------------------===//\n// Flags permitted to be passed to command line arguments\n//\n\nenum NumOccurrencesFlag { // Flags for the number of occurrences allowed\n  Optional = 0x00,        // Zero or One occurrence\n  ZeroOrMore = 0x01,      // Zero or more occurrences allowed\n  Required = 0x02,        // One occurrence required\n  OneOrMore = 0x03,       // One or more occurrences required\n\n  // ConsumeAfter - Indicates that this option is fed anything that follows the\n  // last positional argument required by the application (it is an error if\n  // there are zero positional arguments, and a ConsumeAfter option is used).\n  // Thus, for example, all arguments to LLI are processed until a filename is\n  // found.  Once a filename is found, all of the succeeding arguments are\n  // passed, unprocessed, to the ConsumeAfter option.\n  //\n  ConsumeAfter = 0x04\n};\n\nenum ValueExpected { // Is a value required for the option?\n  // zero reserved for the unspecified value\n  ValueOptional = 0x01,  // The value can appear... or not\n  ValueRequired = 0x02,  // The value is required to appear!\n  ValueDisallowed = 0x03 // A value may not be specified (for flags)\n};\n\nenum OptionHidden {   // Control whether -help shows this option\n  NotHidden = 0x00,   // Option included in -help & -help-hidden\n  Hidden = 0x01,      // -help doesn't, but -help-hidden does\n  ReallyHidden = 0x02 // Neither -help nor -help-hidden show this arg\n};\n\n// Formatting flags - This controls special features that the option might have\n// that cause it to be parsed differently...\n//\n// Prefix - This option allows arguments that are otherwise unrecognized to be\n// matched by options that are a prefix of the actual value.  This is useful for\n// cases like a linker, where options are typically of the form '-lfoo' or\n// '-L../../include' where -l or -L are the actual flags.  When prefix is\n// enabled, and used, the value for the flag comes from the suffix of the\n// argument.\n//\n// AlwaysPrefix - Only allow the behavior enabled by the Prefix flag and reject\n// the Option=Value form.\n//\n\nenum FormattingFlags {\n  NormalFormatting = 0x00, // Nothing special\n  Positional = 0x01,       // Is a positional argument, no '-' required\n  Prefix = 0x02,           // Can this option directly prefix its value?\n  AlwaysPrefix = 0x03      // Can this option only directly prefix its value?\n};\n\nenum MiscFlags {             // Miscellaneous flags to adjust argument\n  CommaSeparated = 0x01,     // Should this cl::list split between commas?\n  PositionalEatsArgs = 0x02, // Should this positional cl::list eat -args?\n  Sink = 0x04,               // Should this cl::list eat all unknown options?\n\n  // Grouping - Can this option group with other options?\n  // If this is enabled, multiple letter options are allowed to bunch together\n  // with only a single hyphen for the whole group.  This allows emulation\n  // of the behavior that ls uses for example: ls -la === ls -l -a\n  Grouping = 0x08,\n\n  // Default option\n  DefaultOption = 0x10\n};\n\n//===----------------------------------------------------------------------===//\n// Option Category class\n//\nclass OptionCategory {\nprivate:\n  StringRef const Name;\n  StringRef const Description;\n\n  void registerCategory();\n\npublic:\n  OptionCategory(StringRef const Name,\n                 StringRef const Description = \"\")\n      : Name(Name), Description(Description) {\n    registerCategory();\n  }\n\n  StringRef getName() const { return Name; }\n  StringRef getDescription() const { return Description; }\n};\n\n// The general Option Category (used as default category).\nextern OptionCategory GeneralCategory;\n\n//===----------------------------------------------------------------------===//\n// SubCommand class\n//\nclass SubCommand {\nprivate:\n  StringRef Name;\n  StringRef Description;\n\nprotected:\n  void registerSubCommand();\n  void unregisterSubCommand();\n\npublic:\n  SubCommand(StringRef Name, StringRef Description = \"\")\n      : Name(Name), Description(Description) {\n        registerSubCommand();\n  }\n  SubCommand() = default;\n\n  void reset();\n\n  explicit operator bool() const;\n\n  StringRef getName() const { return Name; }\n  StringRef getDescription() const { return Description; }\n\n  SmallVector<Option *, 4> PositionalOpts;\n  SmallVector<Option *, 4> SinkOpts;\n  StringMap<Option *> OptionsMap;\n\n  Option *ConsumeAfterOpt = nullptr; // The ConsumeAfter option if it exists.\n};\n\n// A special subcommand representing no subcommand\nextern ManagedStatic<SubCommand> TopLevelSubCommand;\n\n// A special subcommand that can be used to put an option into all subcommands.\nextern ManagedStatic<SubCommand> AllSubCommands;\n\n//===----------------------------------------------------------------------===//\n// Option Base class\n//\nclass Option {\n  friend class alias;\n\n  // handleOccurrences - Overriden by subclasses to handle the value passed into\n  // an argument.  Should return true if there was an error processing the\n  // argument and the program should exit.\n  //\n  virtual bool handleOccurrence(unsigned pos, StringRef ArgName,\n                                StringRef Arg) = 0;\n\n  virtual enum ValueExpected getValueExpectedFlagDefault() const {\n    return ValueOptional;\n  }\n\n  // Out of line virtual function to provide home for the class.\n  virtual void anchor();\n\n  uint16_t NumOccurrences; // The number of times specified\n  // Occurrences, HiddenFlag, and Formatting are all enum types but to avoid\n  // problems with signed enums in bitfields.\n  uint16_t Occurrences : 3; // enum NumOccurrencesFlag\n  // not using the enum type for 'Value' because zero is an implementation\n  // detail representing the non-value\n  uint16_t Value : 2;\n  uint16_t HiddenFlag : 2; // enum OptionHidden\n  uint16_t Formatting : 2; // enum FormattingFlags\n  uint16_t Misc : 5;\n  uint16_t FullyInitialized : 1; // Has addArgument been called?\n  uint16_t Position;             // Position of last occurrence of the option\n  uint16_t AdditionalVals;       // Greater than 0 for multi-valued option.\n\npublic:\n  StringRef ArgStr;   // The argument string itself (ex: \"help\", \"o\")\n  StringRef HelpStr;  // The descriptive text message for -help\n  StringRef ValueStr; // String describing what the value of this option is\n  SmallVector<OptionCategory *, 1>\n      Categories;                    // The Categories this option belongs to\n  SmallPtrSet<SubCommand *, 1> Subs; // The subcommands this option belongs to.\n\n  inline enum NumOccurrencesFlag getNumOccurrencesFlag() const {\n    return (enum NumOccurrencesFlag)Occurrences;\n  }\n\n  inline enum ValueExpected getValueExpectedFlag() const {\n    return Value ? ((enum ValueExpected)Value) : getValueExpectedFlagDefault();\n  }\n\n  inline enum OptionHidden getOptionHiddenFlag() const {\n    return (enum OptionHidden)HiddenFlag;\n  }\n\n  inline enum FormattingFlags getFormattingFlag() const {\n    return (enum FormattingFlags)Formatting;\n  }\n\n  inline unsigned getMiscFlags() const { return Misc; }\n  inline unsigned getPosition() const { return Position; }\n  inline unsigned getNumAdditionalVals() const { return AdditionalVals; }\n\n  // hasArgStr - Return true if the argstr != \"\"\n  bool hasArgStr() const { return !ArgStr.empty(); }\n  bool isPositional() const { return getFormattingFlag() == cl::Positional; }\n  bool isSink() const { return getMiscFlags() & cl::Sink; }\n  bool isDefaultOption() const { return getMiscFlags() & cl::DefaultOption; }\n\n  bool isConsumeAfter() const {\n    return getNumOccurrencesFlag() == cl::ConsumeAfter;\n  }\n\n  bool isInAllSubCommands() const {\n    return any_of(Subs, [](const SubCommand *SC) {\n      return SC == &*AllSubCommands;\n    });\n  }\n\n  //-------------------------------------------------------------------------===\n  // Accessor functions set by OptionModifiers\n  //\n  void setArgStr(StringRef S);\n  void setDescription(StringRef S) { HelpStr = S; }\n  void setValueStr(StringRef S) { ValueStr = S; }\n  void setNumOccurrencesFlag(enum NumOccurrencesFlag Val) { Occurrences = Val; }\n  void setValueExpectedFlag(enum ValueExpected Val) { Value = Val; }\n  void setHiddenFlag(enum OptionHidden Val) { HiddenFlag = Val; }\n  void setFormattingFlag(enum FormattingFlags V) { Formatting = V; }\n  void setMiscFlag(enum MiscFlags M) { Misc |= M; }\n  void setPosition(unsigned pos) { Position = pos; }\n  void addCategory(OptionCategory &C);\n  void addSubCommand(SubCommand &S) { Subs.insert(&S); }\n\nprotected:\n  explicit Option(enum NumOccurrencesFlag OccurrencesFlag,\n                  enum OptionHidden Hidden)\n      : NumOccurrences(0), Occurrences(OccurrencesFlag), Value(0),\n        HiddenFlag(Hidden), Formatting(NormalFormatting), Misc(0),\n        FullyInitialized(false), Position(0), AdditionalVals(0) {\n    Categories.push_back(&GeneralCategory);\n  }\n\n  inline void setNumAdditionalVals(unsigned n) { AdditionalVals = n; }\n\npublic:\n  virtual ~Option() = default;\n\n  // addArgument - Register this argument with the commandline system.\n  //\n  void addArgument();\n\n  /// Unregisters this option from the CommandLine system.\n  ///\n  /// This option must have been the last option registered.\n  /// For testing purposes only.\n  void removeArgument();\n\n  // Return the width of the option tag for printing...\n  virtual size_t getOptionWidth() const = 0;\n\n  // printOptionInfo - Print out information about this option.  The\n  // to-be-maintained width is specified.\n  //\n  virtual void printOptionInfo(size_t GlobalWidth) const = 0;\n\n  virtual void printOptionValue(size_t GlobalWidth, bool Force) const = 0;\n\n  virtual void setDefault() = 0;\n\n  // Prints the help string for an option.\n  //\n  // This maintains the Indent for multi-line descriptions.\n  // FirstLineIndentedBy is the count of chars of the first line\n  //      i.e. the one containing the --<option name>.\n  static void printHelpStr(StringRef HelpStr, size_t Indent,\n                           size_t FirstLineIndentedBy);\n\n  // Prints the help string for an enum value.\n  //\n  // This maintains the Indent for multi-line descriptions.\n  // FirstLineIndentedBy is the count of chars of the first line\n  //      i.e. the one containing the =<value>.\n  static void printEnumValHelpStr(StringRef HelpStr, size_t Indent,\n                                  size_t FirstLineIndentedBy);\n\n  virtual void getExtraOptionNames(SmallVectorImpl<StringRef> &) {}\n\n  // addOccurrence - Wrapper around handleOccurrence that enforces Flags.\n  //\n  virtual bool addOccurrence(unsigned pos, StringRef ArgName, StringRef Value,\n                             bool MultiArg = false);\n\n  // Prints option name followed by message.  Always returns true.\n  bool error(const Twine &Message, StringRef ArgName = StringRef(), raw_ostream &Errs = llvm::errs());\n  bool error(const Twine &Message, raw_ostream &Errs) {\n    return error(Message, StringRef(), Errs);\n  }\n\n  inline int getNumOccurrences() const { return NumOccurrences; }\n  void reset();\n};\n\n//===----------------------------------------------------------------------===//\n// Command line option modifiers that can be used to modify the behavior of\n// command line option parsers...\n//\n\n// desc - Modifier to set the description shown in the -help output...\nstruct desc {\n  StringRef Desc;\n\n  desc(StringRef Str) : Desc(Str) {}\n\n  void apply(Option &O) const { O.setDescription(Desc); }\n};\n\n// value_desc - Modifier to set the value description shown in the -help\n// output...\nstruct value_desc {\n  StringRef Desc;\n\n  value_desc(StringRef Str) : Desc(Str) {}\n\n  void apply(Option &O) const { O.setValueStr(Desc); }\n};\n\n// init - Specify a default (initial) value for the command line argument, if\n// the default constructor for the argument type does not give you what you\n// want.  This is only valid on \"opt\" arguments, not on \"list\" arguments.\n//\ntemplate <class Ty> struct initializer {\n  const Ty &Init;\n  initializer(const Ty &Val) : Init(Val) {}\n\n  template <class Opt> void apply(Opt &O) const { O.setInitialValue(Init); }\n};\n\ntemplate <class Ty> initializer<Ty> init(const Ty &Val) {\n  return initializer<Ty>(Val);\n}\n\n// location - Allow the user to specify which external variable they want to\n// store the results of the command line argument processing into, if they don't\n// want to store it in the option itself.\n//\ntemplate <class Ty> struct LocationClass {\n  Ty &Loc;\n\n  LocationClass(Ty &L) : Loc(L) {}\n\n  template <class Opt> void apply(Opt &O) const { O.setLocation(O, Loc); }\n};\n\ntemplate <class Ty> LocationClass<Ty> location(Ty &L) {\n  return LocationClass<Ty>(L);\n}\n\n// cat - Specifiy the Option category for the command line argument to belong\n// to.\nstruct cat {\n  OptionCategory &Category;\n\n  cat(OptionCategory &c) : Category(c) {}\n\n  template <class Opt> void apply(Opt &O) const { O.addCategory(Category); }\n};\n\n// sub - Specify the subcommand that this option belongs to.\nstruct sub {\n  SubCommand &Sub;\n\n  sub(SubCommand &S) : Sub(S) {}\n\n  template <class Opt> void apply(Opt &O) const { O.addSubCommand(Sub); }\n};\n\n// Specify a callback function to be called when an option is seen.\n// Can be used to set other options automatically.\ntemplate <typename R, typename Ty> struct cb {\n  std::function<R(Ty)> CB;\n\n  cb(std::function<R(Ty)> CB) : CB(CB) {}\n\n  template <typename Opt> void apply(Opt &O) const { O.setCallback(CB); }\n};\n\nnamespace detail {\ntemplate <typename F>\nstruct callback_traits : public callback_traits<decltype(&F::operator())> {};\n\ntemplate <typename R, typename C, typename... Args>\nstruct callback_traits<R (C::*)(Args...) const> {\n  using result_type = R;\n  using arg_type = std::tuple_element_t<0, std::tuple<Args...>>;\n  static_assert(sizeof...(Args) == 1, \"callback function must have one and only one parameter\");\n  static_assert(std::is_same<result_type, void>::value,\n                \"callback return type must be void\");\n  static_assert(std::is_lvalue_reference<arg_type>::value &&\n                    std::is_const<std::remove_reference_t<arg_type>>::value,\n                \"callback arg_type must be a const lvalue reference\");\n};\n} // namespace detail\n\ntemplate <typename F>\ncb<typename detail::callback_traits<F>::result_type,\n   typename detail::callback_traits<F>::arg_type>\ncallback(F CB) {\n  using result_type = typename detail::callback_traits<F>::result_type;\n  using arg_type = typename detail::callback_traits<F>::arg_type;\n  return cb<result_type, arg_type>(CB);\n}\n\n//===----------------------------------------------------------------------===//\n// OptionValue class\n\n// Support value comparison outside the template.\nstruct GenericOptionValue {\n  virtual bool compare(const GenericOptionValue &V) const = 0;\n\nprotected:\n  GenericOptionValue() = default;\n  GenericOptionValue(const GenericOptionValue&) = default;\n  GenericOptionValue &operator=(const GenericOptionValue &) = default;\n  ~GenericOptionValue() = default;\n\nprivate:\n  virtual void anchor();\n};\n\ntemplate <class DataType> struct OptionValue;\n\n// The default value safely does nothing. Option value printing is only\n// best-effort.\ntemplate <class DataType, bool isClass>\nstruct OptionValueBase : public GenericOptionValue {\n  // Temporary storage for argument passing.\n  using WrapperType = OptionValue<DataType>;\n\n  bool hasValue() const { return false; }\n\n  const DataType &getValue() const { llvm_unreachable(\"no default value\"); }\n\n  // Some options may take their value from a different data type.\n  template <class DT> void setValue(const DT & /*V*/) {}\n\n  bool compare(const DataType & /*V*/) const { return false; }\n\n  bool compare(const GenericOptionValue & /*V*/) const override {\n    return false;\n  }\n\nprotected:\n  ~OptionValueBase() = default;\n};\n\n// Simple copy of the option value.\ntemplate <class DataType> class OptionValueCopy : public GenericOptionValue {\n  DataType Value;\n  bool Valid = false;\n\nprotected:\n  OptionValueCopy(const OptionValueCopy&) = default;\n  OptionValueCopy &operator=(const OptionValueCopy &) = default;\n  ~OptionValueCopy() = default;\n\npublic:\n  OptionValueCopy() = default;\n\n  bool hasValue() const { return Valid; }\n\n  const DataType &getValue() const {\n    assert(Valid && \"invalid option value\");\n    return Value;\n  }\n\n  void setValue(const DataType &V) {\n    Valid = true;\n    Value = V;\n  }\n\n  bool compare(const DataType &V) const { return Valid && (Value != V); }\n\n  bool compare(const GenericOptionValue &V) const override {\n    const OptionValueCopy<DataType> &VC =\n        static_cast<const OptionValueCopy<DataType> &>(V);\n    if (!VC.hasValue())\n      return false;\n    return compare(VC.getValue());\n  }\n};\n\n// Non-class option values.\ntemplate <class DataType>\nstruct OptionValueBase<DataType, false> : OptionValueCopy<DataType> {\n  using WrapperType = DataType;\n\nprotected:\n  OptionValueBase() = default;\n  OptionValueBase(const OptionValueBase&) = default;\n  OptionValueBase &operator=(const OptionValueBase &) = default;\n  ~OptionValueBase() = default;\n};\n\n// Top-level option class.\ntemplate <class DataType>\nstruct OptionValue final\n    : OptionValueBase<DataType, std::is_class<DataType>::value> {\n  OptionValue() = default;\n\n  OptionValue(const DataType &V) { this->setValue(V); }\n\n  // Some options may take their value from a different data type.\n  template <class DT> OptionValue<DataType> &operator=(const DT &V) {\n    this->setValue(V);\n    return *this;\n  }\n};\n\n// Other safe-to-copy-by-value common option types.\nenum boolOrDefault { BOU_UNSET, BOU_TRUE, BOU_FALSE };\ntemplate <>\nstruct OptionValue<cl::boolOrDefault> final\n    : OptionValueCopy<cl::boolOrDefault> {\n  using WrapperType = cl::boolOrDefault;\n\n  OptionValue() = default;\n\n  OptionValue(const cl::boolOrDefault &V) { this->setValue(V); }\n\n  OptionValue<cl::boolOrDefault> &operator=(const cl::boolOrDefault &V) {\n    setValue(V);\n    return *this;\n  }\n\nprivate:\n  void anchor() override;\n};\n\ntemplate <>\nstruct OptionValue<std::string> final : OptionValueCopy<std::string> {\n  using WrapperType = StringRef;\n\n  OptionValue() = default;\n\n  OptionValue(const std::string &V) { this->setValue(V); }\n\n  OptionValue<std::string> &operator=(const std::string &V) {\n    setValue(V);\n    return *this;\n  }\n\nprivate:\n  void anchor() override;\n};\n\n//===----------------------------------------------------------------------===//\n// Enum valued command line option\n//\n\n// This represents a single enum value, using \"int\" as the underlying type.\nstruct OptionEnumValue {\n  StringRef Name;\n  int Value;\n  StringRef Description;\n};\n\n#define clEnumVal(ENUMVAL, DESC)                                               \\\n  llvm::cl::OptionEnumValue { #ENUMVAL, int(ENUMVAL), DESC }\n#define clEnumValN(ENUMVAL, FLAGNAME, DESC)                                    \\\n  llvm::cl::OptionEnumValue { FLAGNAME, int(ENUMVAL), DESC }\n\n// values - For custom data types, allow specifying a group of values together\n// as the values that go into the mapping that the option handler uses.\n//\nclass ValuesClass {\n  // Use a vector instead of a map, because the lists should be short,\n  // the overhead is less, and most importantly, it keeps them in the order\n  // inserted so we can print our option out nicely.\n  SmallVector<OptionEnumValue, 4> Values;\n\npublic:\n  ValuesClass(std::initializer_list<OptionEnumValue> Options)\n      : Values(Options) {}\n\n  template <class Opt> void apply(Opt &O) const {\n    for (const auto &Value : Values)\n      O.getParser().addLiteralOption(Value.Name, Value.Value,\n                                     Value.Description);\n  }\n};\n\n/// Helper to build a ValuesClass by forwarding a variable number of arguments\n/// as an initializer list to the ValuesClass constructor.\ntemplate <typename... OptsTy> ValuesClass values(OptsTy... Options) {\n  return ValuesClass({Options...});\n}\n\n//===----------------------------------------------------------------------===//\n// parser class - Parameterizable parser for different data types.  By default,\n// known data types (string, int, bool) have specialized parsers, that do what\n// you would expect.  The default parser, used for data types that are not\n// built-in, uses a mapping table to map specific options to values, which is\n// used, among other things, to handle enum types.\n\n//--------------------------------------------------\n// generic_parser_base - This class holds all the non-generic code that we do\n// not need replicated for every instance of the generic parser.  This also\n// allows us to put stuff into CommandLine.cpp\n//\nclass generic_parser_base {\nprotected:\n  class GenericOptionInfo {\n  public:\n    GenericOptionInfo(StringRef name, StringRef helpStr)\n        : Name(name), HelpStr(helpStr) {}\n    StringRef Name;\n    StringRef HelpStr;\n  };\n\npublic:\n  generic_parser_base(Option &O) : Owner(O) {}\n\n  virtual ~generic_parser_base() = default;\n  // Base class should have virtual-destructor\n\n  // getNumOptions - Virtual function implemented by generic subclass to\n  // indicate how many entries are in Values.\n  //\n  virtual unsigned getNumOptions() const = 0;\n\n  // getOption - Return option name N.\n  virtual StringRef getOption(unsigned N) const = 0;\n\n  // getDescription - Return description N\n  virtual StringRef getDescription(unsigned N) const = 0;\n\n  // Return the width of the option tag for printing...\n  virtual size_t getOptionWidth(const Option &O) const;\n\n  virtual const GenericOptionValue &getOptionValue(unsigned N) const = 0;\n\n  // printOptionInfo - Print out information about this option.  The\n  // to-be-maintained width is specified.\n  //\n  virtual void printOptionInfo(const Option &O, size_t GlobalWidth) const;\n\n  void printGenericOptionDiff(const Option &O, const GenericOptionValue &V,\n                              const GenericOptionValue &Default,\n                              size_t GlobalWidth) const;\n\n  // printOptionDiff - print the value of an option and it's default.\n  //\n  // Template definition ensures that the option and default have the same\n  // DataType (via the same AnyOptionValue).\n  template <class AnyOptionValue>\n  void printOptionDiff(const Option &O, const AnyOptionValue &V,\n                       const AnyOptionValue &Default,\n                       size_t GlobalWidth) const {\n    printGenericOptionDiff(O, V, Default, GlobalWidth);\n  }\n\n  void initialize() {}\n\n  void getExtraOptionNames(SmallVectorImpl<StringRef> &OptionNames) {\n    // If there has been no argstr specified, that means that we need to add an\n    // argument for every possible option.  This ensures that our options are\n    // vectored to us.\n    if (!Owner.hasArgStr())\n      for (unsigned i = 0, e = getNumOptions(); i != e; ++i)\n        OptionNames.push_back(getOption(i));\n  }\n\n  enum ValueExpected getValueExpectedFlagDefault() const {\n    // If there is an ArgStr specified, then we are of the form:\n    //\n    //    -opt=O2   or   -opt O2  or  -optO2\n    //\n    // In which case, the value is required.  Otherwise if an arg str has not\n    // been specified, we are of the form:\n    //\n    //    -O2 or O2 or -la (where -l and -a are separate options)\n    //\n    // If this is the case, we cannot allow a value.\n    //\n    if (Owner.hasArgStr())\n      return ValueRequired;\n    else\n      return ValueDisallowed;\n  }\n\n  // findOption - Return the option number corresponding to the specified\n  // argument string.  If the option is not found, getNumOptions() is returned.\n  //\n  unsigned findOption(StringRef Name);\n\nprotected:\n  Option &Owner;\n};\n\n// Default parser implementation - This implementation depends on having a\n// mapping of recognized options to values of some sort.  In addition to this,\n// each entry in the mapping also tracks a help message that is printed with the\n// command line option for -help.  Because this is a simple mapping parser, the\n// data type can be any unsupported type.\n//\ntemplate <class DataType> class parser : public generic_parser_base {\nprotected:\n  class OptionInfo : public GenericOptionInfo {\n  public:\n    OptionInfo(StringRef name, DataType v, StringRef helpStr)\n        : GenericOptionInfo(name, helpStr), V(v) {}\n\n    OptionValue<DataType> V;\n  };\n  SmallVector<OptionInfo, 8> Values;\n\npublic:\n  parser(Option &O) : generic_parser_base(O) {}\n\n  using parser_data_type = DataType;\n\n  // Implement virtual functions needed by generic_parser_base\n  unsigned getNumOptions() const override { return unsigned(Values.size()); }\n  StringRef getOption(unsigned N) const override { return Values[N].Name; }\n  StringRef getDescription(unsigned N) const override {\n    return Values[N].HelpStr;\n  }\n\n  // getOptionValue - Return the value of option name N.\n  const GenericOptionValue &getOptionValue(unsigned N) const override {\n    return Values[N].V;\n  }\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, DataType &V) {\n    StringRef ArgVal;\n    if (Owner.hasArgStr())\n      ArgVal = Arg;\n    else\n      ArgVal = ArgName;\n\n    for (size_t i = 0, e = Values.size(); i != e; ++i)\n      if (Values[i].Name == ArgVal) {\n        V = Values[i].V.getValue();\n        return false;\n      }\n\n    return O.error(\"Cannot find option named '\" + ArgVal + \"'!\");\n  }\n\n  /// addLiteralOption - Add an entry to the mapping table.\n  ///\n  template <class DT>\n  void addLiteralOption(StringRef Name, const DT &V, StringRef HelpStr) {\n    assert(findOption(Name) == Values.size() && \"Option already exists!\");\n    OptionInfo X(Name, static_cast<DataType>(V), HelpStr);\n    Values.push_back(X);\n    AddLiteralOption(Owner, Name);\n  }\n\n  /// removeLiteralOption - Remove the specified option.\n  ///\n  void removeLiteralOption(StringRef Name) {\n    unsigned N = findOption(Name);\n    assert(N != Values.size() && \"Option not found!\");\n    Values.erase(Values.begin() + N);\n  }\n};\n\n//--------------------------------------------------\n// basic_parser - Super class of parsers to provide boilerplate code\n//\nclass basic_parser_impl { // non-template implementation of basic_parser<t>\npublic:\n  basic_parser_impl(Option &) {}\n\n  virtual ~basic_parser_impl() {}\n\n  enum ValueExpected getValueExpectedFlagDefault() const {\n    return ValueRequired;\n  }\n\n  void getExtraOptionNames(SmallVectorImpl<StringRef> &) {}\n\n  void initialize() {}\n\n  // Return the width of the option tag for printing...\n  size_t getOptionWidth(const Option &O) const;\n\n  // printOptionInfo - Print out information about this option.  The\n  // to-be-maintained width is specified.\n  //\n  void printOptionInfo(const Option &O, size_t GlobalWidth) const;\n\n  // printOptionNoValue - Print a placeholder for options that don't yet support\n  // printOptionDiff().\n  void printOptionNoValue(const Option &O, size_t GlobalWidth) const;\n\n  // getValueName - Overload in subclass to provide a better default value.\n  virtual StringRef getValueName() const { return \"value\"; }\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  virtual void anchor();\n\nprotected:\n  // A helper for basic_parser::printOptionDiff.\n  void printOptionName(const Option &O, size_t GlobalWidth) const;\n};\n\n// basic_parser - The real basic parser is just a template wrapper that provides\n// a typedef for the provided data type.\n//\ntemplate <class DataType> class basic_parser : public basic_parser_impl {\npublic:\n  using parser_data_type = DataType;\n  using OptVal = OptionValue<DataType>;\n\n  basic_parser(Option &O) : basic_parser_impl(O) {}\n};\n\n//--------------------------------------------------\n// parser<bool>\n//\ntemplate <> class parser<bool> : public basic_parser<bool> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, bool &Val);\n\n  void initialize() {}\n\n  enum ValueExpected getValueExpectedFlagDefault() const {\n    return ValueOptional;\n  }\n\n  // getValueName - Do not print =<value> at all.\n  StringRef getValueName() const override { return StringRef(); }\n\n  void printOptionDiff(const Option &O, bool V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<bool>;\n\n//--------------------------------------------------\n// parser<boolOrDefault>\ntemplate <> class parser<boolOrDefault> : public basic_parser<boolOrDefault> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, boolOrDefault &Val);\n\n  enum ValueExpected getValueExpectedFlagDefault() const {\n    return ValueOptional;\n  }\n\n  // getValueName - Do not print =<value> at all.\n  StringRef getValueName() const override { return StringRef(); }\n\n  void printOptionDiff(const Option &O, boolOrDefault V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<boolOrDefault>;\n\n//--------------------------------------------------\n// parser<int>\n//\ntemplate <> class parser<int> : public basic_parser<int> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, int &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"int\"; }\n\n  void printOptionDiff(const Option &O, int V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<int>;\n\n//--------------------------------------------------\n// parser<long>\n//\ntemplate <> class parser<long> final : public basic_parser<long> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, long &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"long\"; }\n\n  void printOptionDiff(const Option &O, long V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<long>;\n\n//--------------------------------------------------\n// parser<long long>\n//\ntemplate <> class parser<long long> : public basic_parser<long long> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, long long &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"long\"; }\n\n  void printOptionDiff(const Option &O, long long V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<long long>;\n\n//--------------------------------------------------\n// parser<unsigned>\n//\ntemplate <> class parser<unsigned> : public basic_parser<unsigned> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, unsigned &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"uint\"; }\n\n  void printOptionDiff(const Option &O, unsigned V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<unsigned>;\n\n//--------------------------------------------------\n// parser<unsigned long>\n//\ntemplate <>\nclass parser<unsigned long> final : public basic_parser<unsigned long> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, unsigned long &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"ulong\"; }\n\n  void printOptionDiff(const Option &O, unsigned long V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<unsigned long>;\n\n//--------------------------------------------------\n// parser<unsigned long long>\n//\ntemplate <>\nclass parser<unsigned long long> : public basic_parser<unsigned long long> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg,\n             unsigned long long &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"ulong\"; }\n\n  void printOptionDiff(const Option &O, unsigned long long V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<unsigned long long>;\n\n//--------------------------------------------------\n// parser<double>\n//\ntemplate <> class parser<double> : public basic_parser<double> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, double &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"number\"; }\n\n  void printOptionDiff(const Option &O, double V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<double>;\n\n//--------------------------------------------------\n// parser<float>\n//\ntemplate <> class parser<float> : public basic_parser<float> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &O, StringRef ArgName, StringRef Arg, float &Val);\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"number\"; }\n\n  void printOptionDiff(const Option &O, float V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<float>;\n\n//--------------------------------------------------\n// parser<std::string>\n//\ntemplate <> class parser<std::string> : public basic_parser<std::string> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &, StringRef, StringRef Arg, std::string &Value) {\n    Value = Arg.str();\n    return false;\n  }\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"string\"; }\n\n  void printOptionDiff(const Option &O, StringRef V, const OptVal &Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<std::string>;\n\n//--------------------------------------------------\n// parser<char>\n//\ntemplate <> class parser<char> : public basic_parser<char> {\npublic:\n  parser(Option &O) : basic_parser(O) {}\n\n  // parse - Return true on error.\n  bool parse(Option &, StringRef, StringRef Arg, char &Value) {\n    Value = Arg[0];\n    return false;\n  }\n\n  // getValueName - Overload in subclass to provide a better default value.\n  StringRef getValueName() const override { return \"char\"; }\n\n  void printOptionDiff(const Option &O, char V, OptVal Default,\n                       size_t GlobalWidth) const;\n\n  // An out-of-line virtual method to provide a 'home' for this class.\n  void anchor() override;\n};\n\nextern template class basic_parser<char>;\n\n//--------------------------------------------------\n// PrintOptionDiff\n//\n// This collection of wrappers is the intermediary between class opt and class\n// parser to handle all the template nastiness.\n\n// This overloaded function is selected by the generic parser.\ntemplate <class ParserClass, class DT>\nvoid printOptionDiff(const Option &O, const generic_parser_base &P, const DT &V,\n                     const OptionValue<DT> &Default, size_t GlobalWidth) {\n  OptionValue<DT> OV = V;\n  P.printOptionDiff(O, OV, Default, GlobalWidth);\n}\n\n// This is instantiated for basic parsers when the parsed value has a different\n// type than the option value. e.g. HelpPrinter.\ntemplate <class ParserDT, class ValDT> struct OptionDiffPrinter {\n  void print(const Option &O, const parser<ParserDT> &P, const ValDT & /*V*/,\n             const OptionValue<ValDT> & /*Default*/, size_t GlobalWidth) {\n    P.printOptionNoValue(O, GlobalWidth);\n  }\n};\n\n// This is instantiated for basic parsers when the parsed value has the same\n// type as the option value.\ntemplate <class DT> struct OptionDiffPrinter<DT, DT> {\n  void print(const Option &O, const parser<DT> &P, const DT &V,\n             const OptionValue<DT> &Default, size_t GlobalWidth) {\n    P.printOptionDiff(O, V, Default, GlobalWidth);\n  }\n};\n\n// This overloaded function is selected by the basic parser, which may parse a\n// different type than the option type.\ntemplate <class ParserClass, class ValDT>\nvoid printOptionDiff(\n    const Option &O,\n    const basic_parser<typename ParserClass::parser_data_type> &P,\n    const ValDT &V, const OptionValue<ValDT> &Default, size_t GlobalWidth) {\n\n  OptionDiffPrinter<typename ParserClass::parser_data_type, ValDT> printer;\n  printer.print(O, static_cast<const ParserClass &>(P), V, Default,\n                GlobalWidth);\n}\n\n//===----------------------------------------------------------------------===//\n// applicator class - This class is used because we must use partial\n// specialization to handle literal string arguments specially (const char* does\n// not correctly respond to the apply method).  Because the syntax to use this\n// is a pain, we have the 'apply' method below to handle the nastiness...\n//\ntemplate <class Mod> struct applicator {\n  template <class Opt> static void opt(const Mod &M, Opt &O) { M.apply(O); }\n};\n\n// Handle const char* as a special case...\ntemplate <unsigned n> struct applicator<char[n]> {\n  template <class Opt> static void opt(StringRef Str, Opt &O) {\n    O.setArgStr(Str);\n  }\n};\ntemplate <unsigned n> struct applicator<const char[n]> {\n  template <class Opt> static void opt(StringRef Str, Opt &O) {\n    O.setArgStr(Str);\n  }\n};\ntemplate <> struct applicator<StringRef > {\n  template <class Opt> static void opt(StringRef Str, Opt &O) {\n    O.setArgStr(Str);\n  }\n};\n\ntemplate <> struct applicator<NumOccurrencesFlag> {\n  static void opt(NumOccurrencesFlag N, Option &O) {\n    O.setNumOccurrencesFlag(N);\n  }\n};\n\ntemplate <> struct applicator<ValueExpected> {\n  static void opt(ValueExpected VE, Option &O) { O.setValueExpectedFlag(VE); }\n};\n\ntemplate <> struct applicator<OptionHidden> {\n  static void opt(OptionHidden OH, Option &O) { O.setHiddenFlag(OH); }\n};\n\ntemplate <> struct applicator<FormattingFlags> {\n  static void opt(FormattingFlags FF, Option &O) { O.setFormattingFlag(FF); }\n};\n\ntemplate <> struct applicator<MiscFlags> {\n  static void opt(MiscFlags MF, Option &O) {\n    assert((MF != Grouping || O.ArgStr.size() == 1) &&\n           \"cl::Grouping can only apply to single charater Options.\");\n    O.setMiscFlag(MF);\n  }\n};\n\n// apply method - Apply modifiers to an option in a type safe way.\ntemplate <class Opt, class Mod, class... Mods>\nvoid apply(Opt *O, const Mod &M, const Mods &... Ms) {\n  applicator<Mod>::opt(M, *O);\n  apply(O, Ms...);\n}\n\ntemplate <class Opt, class Mod> void apply(Opt *O, const Mod &M) {\n  applicator<Mod>::opt(M, *O);\n}\n\n//===----------------------------------------------------------------------===//\n// opt_storage class\n\n// Default storage class definition: external storage.  This implementation\n// assumes the user will specify a variable to store the data into with the\n// cl::location(x) modifier.\n//\ntemplate <class DataType, bool ExternalStorage, bool isClass>\nclass opt_storage {\n  DataType *Location = nullptr; // Where to store the object...\n  OptionValue<DataType> Default;\n\n  void check_location() const {\n    assert(Location && \"cl::location(...) not specified for a command \"\n                       \"line option with external storage, \"\n                       \"or cl::init specified before cl::location()!!\");\n  }\n\npublic:\n  opt_storage() = default;\n\n  bool setLocation(Option &O, DataType &L) {\n    if (Location)\n      return O.error(\"cl::location(x) specified more than once!\");\n    Location = &L;\n    Default = L;\n    return false;\n  }\n\n  template <class T> void setValue(const T &V, bool initial = false) {\n    check_location();\n    *Location = V;\n    if (initial)\n      Default = V;\n  }\n\n  DataType &getValue() {\n    check_location();\n    return *Location;\n  }\n  const DataType &getValue() const {\n    check_location();\n    return *Location;\n  }\n\n  operator DataType() const { return this->getValue(); }\n\n  const OptionValue<DataType> &getDefault() const { return Default; }\n};\n\n// Define how to hold a class type object, such as a string.  Since we can\n// inherit from a class, we do so.  This makes us exactly compatible with the\n// object in all cases that it is used.\n//\ntemplate <class DataType>\nclass opt_storage<DataType, false, true> : public DataType {\npublic:\n  OptionValue<DataType> Default;\n\n  template <class T> void setValue(const T &V, bool initial = false) {\n    DataType::operator=(V);\n    if (initial)\n      Default = V;\n  }\n\n  DataType &getValue() { return *this; }\n  const DataType &getValue() const { return *this; }\n\n  const OptionValue<DataType> &getDefault() const { return Default; }\n};\n\n// Define a partial specialization to handle things we cannot inherit from.  In\n// this case, we store an instance through containment, and overload operators\n// to get at the value.\n//\ntemplate <class DataType> class opt_storage<DataType, false, false> {\npublic:\n  DataType Value;\n  OptionValue<DataType> Default;\n\n  // Make sure we initialize the value with the default constructor for the\n  // type.\n  opt_storage() : Value(DataType()), Default(DataType()) {}\n\n  template <class T> void setValue(const T &V, bool initial = false) {\n    Value = V;\n    if (initial)\n      Default = V;\n  }\n  DataType &getValue() { return Value; }\n  DataType getValue() const { return Value; }\n\n  const OptionValue<DataType> &getDefault() const { return Default; }\n\n  operator DataType() const { return getValue(); }\n\n  // If the datatype is a pointer, support -> on it.\n  DataType operator->() const { return Value; }\n};\n\n//===----------------------------------------------------------------------===//\n// opt - A scalar command line option.\n//\ntemplate <class DataType, bool ExternalStorage = false,\n          class ParserClass = parser<DataType>>\nclass opt : public Option,\n            public opt_storage<DataType, ExternalStorage,\n                               std::is_class<DataType>::value> {\n  ParserClass Parser;\n\n  bool handleOccurrence(unsigned pos, StringRef ArgName,\n                        StringRef Arg) override {\n    typename ParserClass::parser_data_type Val =\n        typename ParserClass::parser_data_type();\n    if (Parser.parse(*this, ArgName, Arg, Val))\n      return true; // Parse error!\n    this->setValue(Val);\n    this->setPosition(pos);\n    Callback(Val);\n    return false;\n  }\n\n  enum ValueExpected getValueExpectedFlagDefault() const override {\n    return Parser.getValueExpectedFlagDefault();\n  }\n\n  void getExtraOptionNames(SmallVectorImpl<StringRef> &OptionNames) override {\n    return Parser.getExtraOptionNames(OptionNames);\n  }\n\n  // Forward printing stuff to the parser...\n  size_t getOptionWidth() const override {\n    return Parser.getOptionWidth(*this);\n  }\n\n  void printOptionInfo(size_t GlobalWidth) const override {\n    Parser.printOptionInfo(*this, GlobalWidth);\n  }\n\n  void printOptionValue(size_t GlobalWidth, bool Force) const override {\n    if (Force || this->getDefault().compare(this->getValue())) {\n      cl::printOptionDiff<ParserClass>(*this, Parser, this->getValue(),\n                                       this->getDefault(), GlobalWidth);\n    }\n  }\n\n  template <class T,\n            class = std::enable_if_t<std::is_assignable<T &, T>::value>>\n  void setDefaultImpl() {\n    const OptionValue<DataType> &V = this->getDefault();\n    if (V.hasValue())\n      this->setValue(V.getValue());\n  }\n\n  template <class T,\n            class = std::enable_if_t<!std::is_assignable<T &, T>::value>>\n  void setDefaultImpl(...) {}\n\n  void setDefault() override { setDefaultImpl<DataType>(); }\n\n  void done() {\n    addArgument();\n    Parser.initialize();\n  }\n\npublic:\n  // Command line options should not be copyable\n  opt(const opt &) = delete;\n  opt &operator=(const opt &) = delete;\n\n  // setInitialValue - Used by the cl::init modifier...\n  void setInitialValue(const DataType &V) { this->setValue(V, true); }\n\n  ParserClass &getParser() { return Parser; }\n\n  template <class T> DataType &operator=(const T &Val) {\n    this->setValue(Val);\n    Callback(Val);\n    return this->getValue();\n  }\n\n  template <class... Mods>\n  explicit opt(const Mods &... Ms)\n      : Option(llvm::cl::Optional, NotHidden), Parser(*this) {\n    apply(this, Ms...);\n    done();\n  }\n\n  void setCallback(\n      std::function<void(const typename ParserClass::parser_data_type &)> CB) {\n    Callback = CB;\n  }\n\n  std::function<void(const typename ParserClass::parser_data_type &)> Callback =\n      [](const typename ParserClass::parser_data_type &) {};\n};\n\nextern template class opt<unsigned>;\nextern template class opt<int>;\nextern template class opt<std::string>;\nextern template class opt<char>;\nextern template class opt<bool>;\n\n//===----------------------------------------------------------------------===//\n// list_storage class\n\n// Default storage class definition: external storage.  This implementation\n// assumes the user will specify a variable to store the data into with the\n// cl::location(x) modifier.\n//\ntemplate <class DataType, class StorageClass> class list_storage {\n  StorageClass *Location = nullptr; // Where to store the object...\n\npublic:\n  list_storage() = default;\n\n  void clear() {}\n\n  bool setLocation(Option &O, StorageClass &L) {\n    if (Location)\n      return O.error(\"cl::location(x) specified more than once!\");\n    Location = &L;\n    return false;\n  }\n\n  template <class T> void addValue(const T &V) {\n    assert(Location != 0 && \"cl::location(...) not specified for a command \"\n                            \"line option with external storage!\");\n    Location->push_back(V);\n  }\n};\n\n// Define how to hold a class type object, such as a string.\n// Originally this code inherited from std::vector. In transitioning to a new\n// API for command line options we should change this. The new implementation\n// of this list_storage specialization implements the minimum subset of the\n// std::vector API required for all the current clients.\n//\n// FIXME: Reduce this API to a more narrow subset of std::vector\n//\ntemplate <class DataType> class list_storage<DataType, bool> {\n  std::vector<DataType> Storage;\n\npublic:\n  using iterator = typename std::vector<DataType>::iterator;\n\n  iterator begin() { return Storage.begin(); }\n  iterator end() { return Storage.end(); }\n\n  using const_iterator = typename std::vector<DataType>::const_iterator;\n\n  const_iterator begin() const { return Storage.begin(); }\n  const_iterator end() const { return Storage.end(); }\n\n  using size_type = typename std::vector<DataType>::size_type;\n\n  size_type size() const { return Storage.size(); }\n\n  bool empty() const { return Storage.empty(); }\n\n  void push_back(const DataType &value) { Storage.push_back(value); }\n  void push_back(DataType &&value) { Storage.push_back(value); }\n\n  using reference = typename std::vector<DataType>::reference;\n  using const_reference = typename std::vector<DataType>::const_reference;\n\n  reference operator[](size_type pos) { return Storage[pos]; }\n  const_reference operator[](size_type pos) const { return Storage[pos]; }\n\n  void clear() {\n    Storage.clear();\n  }\n\n  iterator erase(const_iterator pos) { return Storage.erase(pos); }\n  iterator erase(const_iterator first, const_iterator last) {\n    return Storage.erase(first, last);\n  }\n\n  iterator erase(iterator pos) { return Storage.erase(pos); }\n  iterator erase(iterator first, iterator last) {\n    return Storage.erase(first, last);\n  }\n\n  iterator insert(const_iterator pos, const DataType &value) {\n    return Storage.insert(pos, value);\n  }\n  iterator insert(const_iterator pos, DataType &&value) {\n    return Storage.insert(pos, value);\n  }\n\n  iterator insert(iterator pos, const DataType &value) {\n    return Storage.insert(pos, value);\n  }\n  iterator insert(iterator pos, DataType &&value) {\n    return Storage.insert(pos, value);\n  }\n\n  reference front() { return Storage.front(); }\n  const_reference front() const { return Storage.front(); }\n\n  operator std::vector<DataType> &() { return Storage; }\n  operator ArrayRef<DataType>() const { return Storage; }\n  std::vector<DataType> *operator&() { return &Storage; }\n  const std::vector<DataType> *operator&() const { return &Storage; }\n\n  template <class T> void addValue(const T &V) { Storage.push_back(V); }\n};\n\n//===----------------------------------------------------------------------===//\n// list - A list of command line options.\n//\ntemplate <class DataType, class StorageClass = bool,\n          class ParserClass = parser<DataType>>\nclass list : public Option, public list_storage<DataType, StorageClass> {\n  std::vector<unsigned> Positions;\n  ParserClass Parser;\n\n  enum ValueExpected getValueExpectedFlagDefault() const override {\n    return Parser.getValueExpectedFlagDefault();\n  }\n\n  void getExtraOptionNames(SmallVectorImpl<StringRef> &OptionNames) override {\n    return Parser.getExtraOptionNames(OptionNames);\n  }\n\n  bool handleOccurrence(unsigned pos, StringRef ArgName,\n                        StringRef Arg) override {\n    typename ParserClass::parser_data_type Val =\n        typename ParserClass::parser_data_type();\n    if (Parser.parse(*this, ArgName, Arg, Val))\n      return true; // Parse Error!\n    list_storage<DataType, StorageClass>::addValue(Val);\n    setPosition(pos);\n    Positions.push_back(pos);\n    Callback(Val);\n    return false;\n  }\n\n  // Forward printing stuff to the parser...\n  size_t getOptionWidth() const override {\n    return Parser.getOptionWidth(*this);\n  }\n\n  void printOptionInfo(size_t GlobalWidth) const override {\n    Parser.printOptionInfo(*this, GlobalWidth);\n  }\n\n  // Unimplemented: list options don't currently store their default value.\n  void printOptionValue(size_t /*GlobalWidth*/, bool /*Force*/) const override {\n  }\n\n  void setDefault() override {\n    Positions.clear();\n    list_storage<DataType, StorageClass>::clear();\n  }\n\n  void done() {\n    addArgument();\n    Parser.initialize();\n  }\n\npublic:\n  // Command line options should not be copyable\n  list(const list &) = delete;\n  list &operator=(const list &) = delete;\n\n  ParserClass &getParser() { return Parser; }\n\n  unsigned getPosition(unsigned optnum) const {\n    assert(optnum < this->size() && \"Invalid option index\");\n    return Positions[optnum];\n  }\n\n  void setNumAdditionalVals(unsigned n) { Option::setNumAdditionalVals(n); }\n\n  template <class... Mods>\n  explicit list(const Mods &... Ms)\n      : Option(ZeroOrMore, NotHidden), Parser(*this) {\n    apply(this, Ms...);\n    done();\n  }\n\n  void setCallback(\n      std::function<void(const typename ParserClass::parser_data_type &)> CB) {\n    Callback = CB;\n  }\n\n  std::function<void(const typename ParserClass::parser_data_type &)> Callback =\n      [](const typename ParserClass::parser_data_type &) {};\n};\n\n// multi_val - Modifier to set the number of additional values.\nstruct multi_val {\n  unsigned AdditionalVals;\n  explicit multi_val(unsigned N) : AdditionalVals(N) {}\n\n  template <typename D, typename S, typename P>\n  void apply(list<D, S, P> &L) const {\n    L.setNumAdditionalVals(AdditionalVals);\n  }\n};\n\n//===----------------------------------------------------------------------===//\n// bits_storage class\n\n// Default storage class definition: external storage.  This implementation\n// assumes the user will specify a variable to store the data into with the\n// cl::location(x) modifier.\n//\ntemplate <class DataType, class StorageClass> class bits_storage {\n  unsigned *Location = nullptr; // Where to store the bits...\n\n  template <class T> static unsigned Bit(const T &V) {\n    unsigned BitPos = reinterpret_cast<unsigned>(V);\n    assert(BitPos < sizeof(unsigned) * CHAR_BIT &&\n           \"enum exceeds width of bit vector!\");\n    return 1 << BitPos;\n  }\n\npublic:\n  bits_storage() = default;\n\n  bool setLocation(Option &O, unsigned &L) {\n    if (Location)\n      return O.error(\"cl::location(x) specified more than once!\");\n    Location = &L;\n    return false;\n  }\n\n  template <class T> void addValue(const T &V) {\n    assert(Location != 0 && \"cl::location(...) not specified for a command \"\n                            \"line option with external storage!\");\n    *Location |= Bit(V);\n  }\n\n  unsigned getBits() { return *Location; }\n\n  template <class T> bool isSet(const T &V) {\n    return (*Location & Bit(V)) != 0;\n  }\n};\n\n// Define how to hold bits.  Since we can inherit from a class, we do so.\n// This makes us exactly compatible with the bits in all cases that it is used.\n//\ntemplate <class DataType> class bits_storage<DataType, bool> {\n  unsigned Bits; // Where to store the bits...\n\n  template <class T> static unsigned Bit(const T &V) {\n    unsigned BitPos = (unsigned)V;\n    assert(BitPos < sizeof(unsigned) * CHAR_BIT &&\n           \"enum exceeds width of bit vector!\");\n    return 1 << BitPos;\n  }\n\npublic:\n  template <class T> void addValue(const T &V) { Bits |= Bit(V); }\n\n  unsigned getBits() { return Bits; }\n\n  template <class T> bool isSet(const T &V) { return (Bits & Bit(V)) != 0; }\n};\n\n//===----------------------------------------------------------------------===//\n// bits - A bit vector of command options.\n//\ntemplate <class DataType, class Storage = bool,\n          class ParserClass = parser<DataType>>\nclass bits : public Option, public bits_storage<DataType, Storage> {\n  std::vector<unsigned> Positions;\n  ParserClass Parser;\n\n  enum ValueExpected getValueExpectedFlagDefault() const override {\n    return Parser.getValueExpectedFlagDefault();\n  }\n\n  void getExtraOptionNames(SmallVectorImpl<StringRef> &OptionNames) override {\n    return Parser.getExtraOptionNames(OptionNames);\n  }\n\n  bool handleOccurrence(unsigned pos, StringRef ArgName,\n                        StringRef Arg) override {\n    typename ParserClass::parser_data_type Val =\n        typename ParserClass::parser_data_type();\n    if (Parser.parse(*this, ArgName, Arg, Val))\n      return true; // Parse Error!\n    this->addValue(Val);\n    setPosition(pos);\n    Positions.push_back(pos);\n    Callback(Val);\n    return false;\n  }\n\n  // Forward printing stuff to the parser...\n  size_t getOptionWidth() const override {\n    return Parser.getOptionWidth(*this);\n  }\n\n  void printOptionInfo(size_t GlobalWidth) const override {\n    Parser.printOptionInfo(*this, GlobalWidth);\n  }\n\n  // Unimplemented: bits options don't currently store their default values.\n  void printOptionValue(size_t /*GlobalWidth*/, bool /*Force*/) const override {\n  }\n\n  void setDefault() override {}\n\n  void done() {\n    addArgument();\n    Parser.initialize();\n  }\n\npublic:\n  // Command line options should not be copyable\n  bits(const bits &) = delete;\n  bits &operator=(const bits &) = delete;\n\n  ParserClass &getParser() { return Parser; }\n\n  unsigned getPosition(unsigned optnum) const {\n    assert(optnum < this->size() && \"Invalid option index\");\n    return Positions[optnum];\n  }\n\n  template <class... Mods>\n  explicit bits(const Mods &... Ms)\n      : Option(ZeroOrMore, NotHidden), Parser(*this) {\n    apply(this, Ms...);\n    done();\n  }\n\n  void setCallback(\n      std::function<void(const typename ParserClass::parser_data_type &)> CB) {\n    Callback = CB;\n  }\n\n  std::function<void(const typename ParserClass::parser_data_type &)> Callback =\n      [](const typename ParserClass::parser_data_type &) {};\n};\n\n//===----------------------------------------------------------------------===//\n// Aliased command line option (alias this name to a preexisting name)\n//\n\nclass alias : public Option {\n  Option *AliasFor;\n\n  bool handleOccurrence(unsigned pos, StringRef /*ArgName*/,\n                        StringRef Arg) override {\n    return AliasFor->handleOccurrence(pos, AliasFor->ArgStr, Arg);\n  }\n\n  bool addOccurrence(unsigned pos, StringRef /*ArgName*/, StringRef Value,\n                     bool MultiArg = false) override {\n    return AliasFor->addOccurrence(pos, AliasFor->ArgStr, Value, MultiArg);\n  }\n\n  // Handle printing stuff...\n  size_t getOptionWidth() const override;\n  void printOptionInfo(size_t GlobalWidth) const override;\n\n  // Aliases do not need to print their values.\n  void printOptionValue(size_t /*GlobalWidth*/, bool /*Force*/) const override {\n  }\n\n  void setDefault() override { AliasFor->setDefault(); }\n\n  ValueExpected getValueExpectedFlagDefault() const override {\n    return AliasFor->getValueExpectedFlag();\n  }\n\n  void done() {\n    if (!hasArgStr())\n      error(\"cl::alias must have argument name specified!\");\n    if (!AliasFor)\n      error(\"cl::alias must have an cl::aliasopt(option) specified!\");\n    if (!Subs.empty())\n      error(\"cl::alias must not have cl::sub(), aliased option's cl::sub() will be used!\");\n    Subs = AliasFor->Subs;\n    Categories = AliasFor->Categories;\n    addArgument();\n  }\n\npublic:\n  // Command line options should not be copyable\n  alias(const alias &) = delete;\n  alias &operator=(const alias &) = delete;\n\n  void setAliasFor(Option &O) {\n    if (AliasFor)\n      error(\"cl::alias must only have one cl::aliasopt(...) specified!\");\n    AliasFor = &O;\n  }\n\n  template <class... Mods>\n  explicit alias(const Mods &... Ms)\n      : Option(Optional, Hidden), AliasFor(nullptr) {\n    apply(this, Ms...);\n    done();\n  }\n};\n\n// aliasfor - Modifier to set the option an alias aliases.\nstruct aliasopt {\n  Option &Opt;\n\n  explicit aliasopt(Option &O) : Opt(O) {}\n\n  void apply(alias &A) const { A.setAliasFor(Opt); }\n};\n\n// extrahelp - provide additional help at the end of the normal help\n// output. All occurrences of cl::extrahelp will be accumulated and\n// printed to stderr at the end of the regular help, just before\n// exit is called.\nstruct extrahelp {\n  StringRef morehelp;\n\n  explicit extrahelp(StringRef help);\n};\n\nvoid PrintVersionMessage();\n\n/// This function just prints the help message, exactly the same way as if the\n/// -help or -help-hidden option had been given on the command line.\n///\n/// \\param Hidden if true will print hidden options\n/// \\param Categorized if true print options in categories\nvoid PrintHelpMessage(bool Hidden = false, bool Categorized = false);\n\n//===----------------------------------------------------------------------===//\n// Public interface for accessing registered options.\n//\n\n/// Use this to get a StringMap to all registered named options\n/// (e.g. -help).\n///\n/// \\return A reference to the StringMap used by the cl APIs to parse options.\n///\n/// Access to unnamed arguments (i.e. positional) are not provided because\n/// it is expected that the client already has access to these.\n///\n/// Typical usage:\n/// \\code\n/// main(int argc,char* argv[]) {\n/// StringMap<llvm::cl::Option*> &opts = llvm::cl::getRegisteredOptions();\n/// assert(opts.count(\"help\") == 1)\n/// opts[\"help\"]->setDescription(\"Show alphabetical help information\")\n/// // More code\n/// llvm::cl::ParseCommandLineOptions(argc,argv);\n/// //More code\n/// }\n/// \\endcode\n///\n/// This interface is useful for modifying options in libraries that are out of\n/// the control of the client. The options should be modified before calling\n/// llvm::cl::ParseCommandLineOptions().\n///\n/// Hopefully this API can be deprecated soon. Any situation where options need\n/// to be modified by tools or libraries should be handled by sane APIs rather\n/// than just handing around a global list.\nStringMap<Option *> &getRegisteredOptions(SubCommand &Sub = *TopLevelSubCommand);\n\n/// Use this to get all registered SubCommands from the provided parser.\n///\n/// \\return A range of all SubCommand pointers registered with the parser.\n///\n/// Typical usage:\n/// \\code\n/// main(int argc, char* argv[]) {\n///   llvm::cl::ParseCommandLineOptions(argc, argv);\n///   for (auto* S : llvm::cl::getRegisteredSubcommands()) {\n///     if (*S) {\n///       std::cout << \"Executing subcommand: \" << S->getName() << std::endl;\n///       // Execute some function based on the name...\n///     }\n///   }\n/// }\n/// \\endcode\n///\n/// This interface is useful for defining subcommands in libraries and\n/// the dispatch from a single point (like in the main function).\niterator_range<typename SmallPtrSet<SubCommand *, 4>::iterator>\ngetRegisteredSubcommands();\n\n//===----------------------------------------------------------------------===//\n// Standalone command line processing utilities.\n//\n\n/// Tokenizes a command line that can contain escapes and quotes.\n//\n/// The quoting rules match those used by GCC and other tools that use\n/// libiberty's buildargv() or expandargv() utilities, and do not match bash.\n/// They differ from buildargv() on treatment of backslashes that do not escape\n/// a special character to make it possible to accept most Windows file paths.\n///\n/// \\param [in] Source The string to be split on whitespace with quotes.\n/// \\param [in] Saver Delegates back to the caller for saving parsed strings.\n/// \\param [in] MarkEOLs true if tokenizing a response file and you want end of\n/// lines and end of the response file to be marked with a nullptr string.\n/// \\param [out] NewArgv All parsed strings are appended to NewArgv.\nvoid TokenizeGNUCommandLine(StringRef Source, StringSaver &Saver,\n                            SmallVectorImpl<const char *> &NewArgv,\n                            bool MarkEOLs = false);\n\n/// Tokenizes a Windows command line which may contain quotes and escaped\n/// quotes.\n///\n/// See MSDN docs for CommandLineToArgvW for information on the quoting rules.\n/// http://msdn.microsoft.com/en-us/library/windows/desktop/17w5ykft(v=vs.85).aspx\n///\n/// \\param [in] Source The string to be split on whitespace with quotes.\n/// \\param [in] Saver Delegates back to the caller for saving parsed strings.\n/// \\param [in] MarkEOLs true if tokenizing a response file and you want end of\n/// lines and end of the response file to be marked with a nullptr string.\n/// \\param [out] NewArgv All parsed strings are appended to NewArgv.\nvoid TokenizeWindowsCommandLine(StringRef Source, StringSaver &Saver,\n                                SmallVectorImpl<const char *> &NewArgv,\n                                bool MarkEOLs = false);\n\n/// Tokenizes a Windows command line while attempting to avoid copies. If no\n/// quoting or escaping was used, this produces substrings of the original\n/// string. If a token requires unquoting, it will be allocated with the\n/// StringSaver.\nvoid TokenizeWindowsCommandLineNoCopy(StringRef Source, StringSaver &Saver,\n                                      SmallVectorImpl<StringRef> &NewArgv);\n\n/// String tokenization function type.  Should be compatible with either\n/// Windows or Unix command line tokenizers.\nusing TokenizerCallback = void (*)(StringRef Source, StringSaver &Saver,\n                                   SmallVectorImpl<const char *> &NewArgv,\n                                   bool MarkEOLs);\n\n/// Tokenizes content of configuration file.\n///\n/// \\param [in] Source The string representing content of config file.\n/// \\param [in] Saver Delegates back to the caller for saving parsed strings.\n/// \\param [out] NewArgv All parsed strings are appended to NewArgv.\n/// \\param [in] MarkEOLs Added for compatibility with TokenizerCallback.\n///\n/// It works like TokenizeGNUCommandLine with ability to skip comment lines.\n///\nvoid tokenizeConfigFile(StringRef Source, StringSaver &Saver,\n                        SmallVectorImpl<const char *> &NewArgv,\n                        bool MarkEOLs = false);\n\n/// Reads command line options from the given configuration file.\n///\n/// \\param [in] CfgFileName Path to configuration file.\n/// \\param [in] Saver  Objects that saves allocated strings.\n/// \\param [out] Argv Array to which the read options are added.\n/// \\return true if the file was successfully read.\n///\n/// It reads content of the specified file, tokenizes it and expands \"@file\"\n/// commands resolving file names in them relative to the directory where\n/// CfgFilename resides.\n///\nbool readConfigFile(StringRef CfgFileName, StringSaver &Saver,\n                    SmallVectorImpl<const char *> &Argv);\n\n/// Expand response files on a command line recursively using the given\n/// StringSaver and tokenization strategy.  Argv should contain the command line\n/// before expansion and will be modified in place. If requested, Argv will\n/// also be populated with nullptrs indicating where each response file line\n/// ends, which is useful for the \"/link\" argument that needs to consume all\n/// remaining arguments only until the next end of line, when in a response\n/// file.\n///\n/// \\param [in] Saver Delegates back to the caller for saving parsed strings.\n/// \\param [in] Tokenizer Tokenization strategy. Typically Unix or Windows.\n/// \\param [in,out] Argv Command line into which to expand response files.\n/// \\param [in] MarkEOLs Mark end of lines and the end of the response file\n/// with nullptrs in the Argv vector.\n/// \\param [in] RelativeNames true if names of nested response files must be\n/// resolved relative to including file.\n/// \\param [in] FS File system used for all file access when running the tool.\n/// \\param [in] CurrentDir Path used to resolve relative rsp files. If set to\n/// None, process' cwd is used instead.\n/// \\return true if all @files were expanded successfully or there were none.\nbool ExpandResponseFiles(\n    StringSaver &Saver, TokenizerCallback Tokenizer,\n    SmallVectorImpl<const char *> &Argv, bool MarkEOLs = false,\n    bool RelativeNames = false,\n    llvm::vfs::FileSystem &FS = *llvm::vfs::getRealFileSystem(),\n    llvm::Optional<llvm::StringRef> CurrentDir = llvm::None);\n\n/// A convenience helper which concatenates the options specified by the\n/// environment variable EnvVar and command line options, then expands response\n/// files recursively. The tokenizer is a predefined GNU or Windows one.\n/// \\return true if all @files were expanded successfully or there were none.\nbool expandResponseFiles(int Argc, const char *const *Argv, const char *EnvVar,\n                         StringSaver &Saver,\n                         SmallVectorImpl<const char *> &NewArgv);\n\n/// Mark all options not part of this category as cl::ReallyHidden.\n///\n/// \\param Category the category of options to keep displaying\n///\n/// Some tools (like clang-format) like to be able to hide all options that are\n/// not specific to the tool. This function allows a tool to specify a single\n/// option category to display in the -help output.\nvoid HideUnrelatedOptions(cl::OptionCategory &Category,\n                          SubCommand &Sub = *TopLevelSubCommand);\n\n/// Mark all options not part of the categories as cl::ReallyHidden.\n///\n/// \\param Categories the categories of options to keep displaying.\n///\n/// Some tools (like clang-format) like to be able to hide all options that are\n/// not specific to the tool. This function allows a tool to specify a single\n/// option category to display in the -help output.\nvoid HideUnrelatedOptions(ArrayRef<const cl::OptionCategory *> Categories,\n                          SubCommand &Sub = *TopLevelSubCommand);\n\n/// Reset all command line options to a state that looks as if they have\n/// never appeared on the command line.  This is useful for being able to parse\n/// a command line multiple times (especially useful for writing tests).\nvoid ResetAllOptionOccurrences();\n\n/// Reset the command line parser back to its initial state.  This\n/// removes\n/// all options, categories, and subcommands and returns the parser to a state\n/// where no options are supported.\nvoid ResetCommandLineParser();\n\n/// Parses `Arg` into the option handler `Handler`.\nbool ProvidePositionalOption(Option *Handler, StringRef Arg, int i);\n\n} // end namespace cl\n\n} // end namespace llvm\n\n#endif // LLVM_SUPPORT_COMMANDLINE_H\n"}, "65": {"id": 65, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Support/GenericDomTree.h", "content": "//===- GenericDomTree.h - Generic dominator trees for graphs ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// This file defines a set of templates that efficiently compute a dominator\n/// tree over a generic graph. This is used typically in LLVM for fast\n/// dominance queries on the CFG, but is fully generic w.r.t. the underlying\n/// graph types.\n///\n/// Unlike ADT/* graph algorithms, generic dominator tree has more requirements\n/// on the graph's NodeRef. The NodeRef should be a pointer and,\n/// NodeRef->getParent() must return the parent node that is also a pointer.\n///\n/// FIXME: Maybe GenericDomTree needs a TreeTraits, instead of GraphTraits.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_SUPPORT_GENERICDOMTREE_H\n#define LLVM_SUPPORT_GENERICDOMTREE_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Support/CFGDiff.h\"\n#include \"llvm/Support/CFGUpdate.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstddef>\n#include <iterator>\n#include <memory>\n#include <type_traits>\n#include <utility>\n\nnamespace llvm {\n\ntemplate <typename NodeT, bool IsPostDom>\nclass DominatorTreeBase;\n\nnamespace DomTreeBuilder {\ntemplate <typename DomTreeT>\nstruct SemiNCAInfo;\n}  // namespace DomTreeBuilder\n\n/// Base class for the actual dominator tree node.\ntemplate <class NodeT> class DomTreeNodeBase {\n  friend class PostDominatorTree;\n  friend class DominatorTreeBase<NodeT, false>;\n  friend class DominatorTreeBase<NodeT, true>;\n  friend struct DomTreeBuilder::SemiNCAInfo<DominatorTreeBase<NodeT, false>>;\n  friend struct DomTreeBuilder::SemiNCAInfo<DominatorTreeBase<NodeT, true>>;\n\n  NodeT *TheBB;\n  DomTreeNodeBase *IDom;\n  unsigned Level;\n  SmallVector<DomTreeNodeBase *, 4> Children;\n  mutable unsigned DFSNumIn = ~0;\n  mutable unsigned DFSNumOut = ~0;\n\n public:\n  DomTreeNodeBase(NodeT *BB, DomTreeNodeBase *iDom)\n      : TheBB(BB), IDom(iDom), Level(IDom ? IDom->Level + 1 : 0) {}\n\n  using iterator = typename SmallVector<DomTreeNodeBase *, 4>::iterator;\n  using const_iterator =\n      typename SmallVector<DomTreeNodeBase *, 4>::const_iterator;\n\n  iterator begin() { return Children.begin(); }\n  iterator end() { return Children.end(); }\n  const_iterator begin() const { return Children.begin(); }\n  const_iterator end() const { return Children.end(); }\n\n  DomTreeNodeBase *const &back() const { return Children.back(); }\n  DomTreeNodeBase *&back() { return Children.back(); }\n\n  iterator_range<iterator> children() { return make_range(begin(), end()); }\n  iterator_range<const_iterator> children() const {\n    return make_range(begin(), end());\n  }\n\n  NodeT *getBlock() const { return TheBB; }\n  DomTreeNodeBase *getIDom() const { return IDom; }\n  unsigned getLevel() const { return Level; }\n\n  std::unique_ptr<DomTreeNodeBase> addChild(\n      std::unique_ptr<DomTreeNodeBase> C) {\n    Children.push_back(C.get());\n    return C;\n  }\n\n  bool isLeaf() const { return Children.empty(); }\n  size_t getNumChildren() const { return Children.size(); }\n\n  void clearAllChildren() { Children.clear(); }\n\n  bool compare(const DomTreeNodeBase *Other) const {\n    if (getNumChildren() != Other->getNumChildren())\n      return true;\n\n    if (Level != Other->Level) return true;\n\n    SmallPtrSet<const NodeT *, 4> OtherChildren;\n    for (const DomTreeNodeBase *I : *Other) {\n      const NodeT *Nd = I->getBlock();\n      OtherChildren.insert(Nd);\n    }\n\n    for (const DomTreeNodeBase *I : *this) {\n      const NodeT *N = I->getBlock();\n      if (OtherChildren.count(N) == 0)\n        return true;\n    }\n    return false;\n  }\n\n  void setIDom(DomTreeNodeBase *NewIDom) {\n    assert(IDom && \"No immediate dominator?\");\n    if (IDom == NewIDom) return;\n\n    auto I = find(IDom->Children, this);\n    assert(I != IDom->Children.end() &&\n           \"Not in immediate dominator children set!\");\n    // I am no longer your child...\n    IDom->Children.erase(I);\n\n    // Switch to new dominator\n    IDom = NewIDom;\n    IDom->Children.push_back(this);\n\n    UpdateLevel();\n  }\n\n  /// getDFSNumIn/getDFSNumOut - These return the DFS visitation order for nodes\n  /// in the dominator tree. They are only guaranteed valid if\n  /// updateDFSNumbers() has been called.\n  unsigned getDFSNumIn() const { return DFSNumIn; }\n  unsigned getDFSNumOut() const { return DFSNumOut; }\n\nprivate:\n  // Return true if this node is dominated by other. Use this only if DFS info\n  // is valid.\n  bool DominatedBy(const DomTreeNodeBase *other) const {\n    return this->DFSNumIn >= other->DFSNumIn &&\n           this->DFSNumOut <= other->DFSNumOut;\n  }\n\n  void UpdateLevel() {\n    assert(IDom);\n    if (Level == IDom->Level + 1) return;\n\n    SmallVector<DomTreeNodeBase *, 64> WorkStack = {this};\n\n    while (!WorkStack.empty()) {\n      DomTreeNodeBase *Current = WorkStack.pop_back_val();\n      Current->Level = Current->IDom->Level + 1;\n\n      for (DomTreeNodeBase *C : *Current) {\n        assert(C->IDom);\n        if (C->Level != C->IDom->Level + 1) WorkStack.push_back(C);\n      }\n    }\n  }\n};\n\ntemplate <class NodeT>\nraw_ostream &operator<<(raw_ostream &O, const DomTreeNodeBase<NodeT> *Node) {\n  if (Node->getBlock())\n    Node->getBlock()->printAsOperand(O, false);\n  else\n    O << \" <<exit node>>\";\n\n  O << \" {\" << Node->getDFSNumIn() << \",\" << Node->getDFSNumOut() << \"} [\"\n    << Node->getLevel() << \"]\\n\";\n\n  return O;\n}\n\ntemplate <class NodeT>\nvoid PrintDomTree(const DomTreeNodeBase<NodeT> *N, raw_ostream &O,\n                  unsigned Lev) {\n  O.indent(2 * Lev) << \"[\" << Lev << \"] \" << N;\n  for (typename DomTreeNodeBase<NodeT>::const_iterator I = N->begin(),\n                                                       E = N->end();\n       I != E; ++I)\n    PrintDomTree<NodeT>(*I, O, Lev + 1);\n}\n\nnamespace DomTreeBuilder {\n// The routines below are provided in a separate header but referenced here.\ntemplate <typename DomTreeT>\nvoid Calculate(DomTreeT &DT);\n\ntemplate <typename DomTreeT>\nvoid CalculateWithUpdates(DomTreeT &DT,\n                          ArrayRef<typename DomTreeT::UpdateType> Updates);\n\ntemplate <typename DomTreeT>\nvoid InsertEdge(DomTreeT &DT, typename DomTreeT::NodePtr From,\n                typename DomTreeT::NodePtr To);\n\ntemplate <typename DomTreeT>\nvoid DeleteEdge(DomTreeT &DT, typename DomTreeT::NodePtr From,\n                typename DomTreeT::NodePtr To);\n\ntemplate <typename DomTreeT>\nvoid ApplyUpdates(DomTreeT &DT,\n                  GraphDiff<typename DomTreeT::NodePtr,\n                            DomTreeT::IsPostDominator> &PreViewCFG,\n                  GraphDiff<typename DomTreeT::NodePtr,\n                            DomTreeT::IsPostDominator> *PostViewCFG);\n\ntemplate <typename DomTreeT>\nbool Verify(const DomTreeT &DT, typename DomTreeT::VerificationLevel VL);\n}  // namespace DomTreeBuilder\n\n/// Core dominator tree base class.\n///\n/// This class is a generic template over graph nodes. It is instantiated for\n/// various graphs in the LLVM IR or in the code generator.\ntemplate <typename NodeT, bool IsPostDom>\nclass DominatorTreeBase {\n public:\n  static_assert(std::is_pointer<typename GraphTraits<NodeT *>::NodeRef>::value,\n                \"Currently DominatorTreeBase supports only pointer nodes\");\n  using NodeType = NodeT;\n  using NodePtr = NodeT *;\n  using ParentPtr = decltype(std::declval<NodeT *>()->getParent());\n  static_assert(std::is_pointer<ParentPtr>::value,\n                \"Currently NodeT's parent must be a pointer type\");\n  using ParentType = std::remove_pointer_t<ParentPtr>;\n  static constexpr bool IsPostDominator = IsPostDom;\n\n  using UpdateType = cfg::Update<NodePtr>;\n  using UpdateKind = cfg::UpdateKind;\n  static constexpr UpdateKind Insert = UpdateKind::Insert;\n  static constexpr UpdateKind Delete = UpdateKind::Delete;\n\n  enum class VerificationLevel { Fast, Basic, Full };\n\nprotected:\n  // Dominators always have a single root, postdominators can have more.\n  SmallVector<NodeT *, IsPostDom ? 4 : 1> Roots;\n\n  using DomTreeNodeMapType =\n     DenseMap<NodeT *, std::unique_ptr<DomTreeNodeBase<NodeT>>>;\n  DomTreeNodeMapType DomTreeNodes;\n  DomTreeNodeBase<NodeT> *RootNode = nullptr;\n  ParentPtr Parent = nullptr;\n\n  mutable bool DFSInfoValid = false;\n  mutable unsigned int SlowQueries = 0;\n\n  friend struct DomTreeBuilder::SemiNCAInfo<DominatorTreeBase>;\n\n public:\n  DominatorTreeBase() {}\n\n  DominatorTreeBase(DominatorTreeBase &&Arg)\n      : Roots(std::move(Arg.Roots)),\n        DomTreeNodes(std::move(Arg.DomTreeNodes)),\n        RootNode(Arg.RootNode),\n        Parent(Arg.Parent),\n        DFSInfoValid(Arg.DFSInfoValid),\n        SlowQueries(Arg.SlowQueries) {\n    Arg.wipe();\n  }\n\n  DominatorTreeBase &operator=(DominatorTreeBase &&RHS) {\n    Roots = std::move(RHS.Roots);\n    DomTreeNodes = std::move(RHS.DomTreeNodes);\n    RootNode = RHS.RootNode;\n    Parent = RHS.Parent;\n    DFSInfoValid = RHS.DFSInfoValid;\n    SlowQueries = RHS.SlowQueries;\n    RHS.wipe();\n    return *this;\n  }\n\n  DominatorTreeBase(const DominatorTreeBase &) = delete;\n  DominatorTreeBase &operator=(const DominatorTreeBase &) = delete;\n\n  /// Iteration over roots.\n  ///\n  /// This may include multiple blocks if we are computing post dominators.\n  /// For forward dominators, this will always be a single block (the entry\n  /// block).\n  using root_iterator = typename SmallVectorImpl<NodeT *>::iterator;\n  using const_root_iterator = typename SmallVectorImpl<NodeT *>::const_iterator;\n\n  root_iterator root_begin() { return Roots.begin(); }\n  const_root_iterator root_begin() const { return Roots.begin(); }\n  root_iterator root_end() { return Roots.end(); }\n  const_root_iterator root_end() const { return Roots.end(); }\n\n  size_t root_size() const { return Roots.size(); }\n\n  iterator_range<root_iterator> roots() {\n    return make_range(root_begin(), root_end());\n  }\n  iterator_range<const_root_iterator> roots() const {\n    return make_range(root_begin(), root_end());\n  }\n\n  /// isPostDominator - Returns true if analysis based of postdoms\n  ///\n  bool isPostDominator() const { return IsPostDominator; }\n\n  /// compare - Return false if the other dominator tree base matches this\n  /// dominator tree base. Otherwise return true.\n  bool compare(const DominatorTreeBase &Other) const {\n    if (Parent != Other.Parent) return true;\n\n    if (Roots.size() != Other.Roots.size())\n      return true;\n\n    if (!std::is_permutation(Roots.begin(), Roots.end(), Other.Roots.begin()))\n      return true;\n\n    const DomTreeNodeMapType &OtherDomTreeNodes = Other.DomTreeNodes;\n    if (DomTreeNodes.size() != OtherDomTreeNodes.size())\n      return true;\n\n    for (const auto &DomTreeNode : DomTreeNodes) {\n      NodeT *BB = DomTreeNode.first;\n      typename DomTreeNodeMapType::const_iterator OI =\n          OtherDomTreeNodes.find(BB);\n      if (OI == OtherDomTreeNodes.end())\n        return true;\n\n      DomTreeNodeBase<NodeT> &MyNd = *DomTreeNode.second;\n      DomTreeNodeBase<NodeT> &OtherNd = *OI->second;\n\n      if (MyNd.compare(&OtherNd))\n        return true;\n    }\n\n    return false;\n  }\n\n  /// getNode - return the (Post)DominatorTree node for the specified basic\n  /// block.  This is the same as using operator[] on this class.  The result\n  /// may (but is not required to) be null for a forward (backwards)\n  /// statically unreachable block.\n  DomTreeNodeBase<NodeT> *getNode(const NodeT *BB) const {\n    auto I = DomTreeNodes.find(BB);\n    if (I != DomTreeNodes.end())\n      return I->second.get();\n    return nullptr;\n  }\n\n  /// See getNode.\n  DomTreeNodeBase<NodeT> *operator[](const NodeT *BB) const {\n    return getNode(BB);\n  }\n\n  /// getRootNode - This returns the entry node for the CFG of the function.  If\n  /// this tree represents the post-dominance relations for a function, however,\n  /// this root may be a node with the block == NULL.  This is the case when\n  /// there are multiple exit nodes from a particular function.  Consumers of\n  /// post-dominance information must be capable of dealing with this\n  /// possibility.\n  ///\n  DomTreeNodeBase<NodeT> *getRootNode() { return RootNode; }\n  const DomTreeNodeBase<NodeT> *getRootNode() const { return RootNode; }\n\n  /// Get all nodes dominated by R, including R itself.\n  void getDescendants(NodeT *R, SmallVectorImpl<NodeT *> &Result) const {\n    Result.clear();\n    const DomTreeNodeBase<NodeT> *RN = getNode(R);\n    if (!RN)\n      return; // If R is unreachable, it will not be present in the DOM tree.\n    SmallVector<const DomTreeNodeBase<NodeT> *, 8> WL;\n    WL.push_back(RN);\n\n    while (!WL.empty()) {\n      const DomTreeNodeBase<NodeT> *N = WL.pop_back_val();\n      Result.push_back(N->getBlock());\n      WL.append(N->begin(), N->end());\n    }\n  }\n\n  /// properlyDominates - Returns true iff A dominates B and A != B.\n  /// Note that this is not a constant time operation!\n  ///\n  bool properlyDominates(const DomTreeNodeBase<NodeT> *A,\n                         const DomTreeNodeBase<NodeT> *B) const {\n    if (!A || !B)\n      return false;\n    if (A == B)\n      return false;\n    return dominates(A, B);\n  }\n\n  bool properlyDominates(const NodeT *A, const NodeT *B) const;\n\n  /// isReachableFromEntry - Return true if A is dominated by the entry\n  /// block of the function containing it.\n  bool isReachableFromEntry(const NodeT *A) const {\n    assert(!this->isPostDominator() &&\n           \"This is not implemented for post dominators\");\n    return isReachableFromEntry(getNode(const_cast<NodeT *>(A)));\n  }\n\n  bool isReachableFromEntry(const DomTreeNodeBase<NodeT> *A) const { return A; }\n\n  /// dominates - Returns true iff A dominates B.  Note that this is not a\n  /// constant time operation!\n  ///\n  bool dominates(const DomTreeNodeBase<NodeT> *A,\n                 const DomTreeNodeBase<NodeT> *B) const {\n    // A node trivially dominates itself.\n    if (B == A)\n      return true;\n\n    // An unreachable node is dominated by anything.\n    if (!isReachableFromEntry(B))\n      return true;\n\n    // And dominates nothing.\n    if (!isReachableFromEntry(A))\n      return false;\n\n    if (B->getIDom() == A) return true;\n\n    if (A->getIDom() == B) return false;\n\n    // A can only dominate B if it is higher in the tree.\n    if (A->getLevel() >= B->getLevel()) return false;\n\n    // Compare the result of the tree walk and the dfs numbers, if expensive\n    // checks are enabled.\n#ifdef EXPENSIVE_CHECKS\n    assert((!DFSInfoValid ||\n            (dominatedBySlowTreeWalk(A, B) == B->DominatedBy(A))) &&\n           \"Tree walk disagrees with dfs numbers!\");\n#endif\n\n    if (DFSInfoValid)\n      return B->DominatedBy(A);\n\n    // If we end up with too many slow queries, just update the\n    // DFS numbers on the theory that we are going to keep querying.\n    SlowQueries++;\n    if (SlowQueries > 32) {\n      updateDFSNumbers();\n      return B->DominatedBy(A);\n    }\n\n    return dominatedBySlowTreeWalk(A, B);\n  }\n\n  bool dominates(const NodeT *A, const NodeT *B) const;\n\n  NodeT *getRoot() const {\n    assert(this->Roots.size() == 1 && \"Should always have entry node!\");\n    return this->Roots[0];\n  }\n\n  /// Find nearest common dominator basic block for basic block A and B. A and B\n  /// must have tree nodes.\n  NodeT *findNearestCommonDominator(NodeT *A, NodeT *B) const {\n    assert(A && B && \"Pointers are not valid\");\n    assert(A->getParent() == B->getParent() &&\n           \"Two blocks are not in same function\");\n\n    // If either A or B is a entry block then it is nearest common dominator\n    // (for forward-dominators).\n    if (!isPostDominator()) {\n      NodeT &Entry = A->getParent()->front();\n      if (A == &Entry || B == &Entry)\n        return &Entry;\n    }\n\n    DomTreeNodeBase<NodeT> *NodeA = getNode(A);\n    DomTreeNodeBase<NodeT> *NodeB = getNode(B);\n    assert(NodeA && \"A must be in the tree\");\n    assert(NodeB && \"B must be in the tree\");\n\n    // Use level information to go up the tree until the levels match. Then\n    // continue going up til we arrive at the same node.\n    while (NodeA != NodeB) {\n      if (NodeA->getLevel() < NodeB->getLevel()) std::swap(NodeA, NodeB);\n\n      NodeA = NodeA->IDom;\n    }\n\n    return NodeA->getBlock();\n  }\n\n  const NodeT *findNearestCommonDominator(const NodeT *A,\n                                          const NodeT *B) const {\n    // Cast away the const qualifiers here. This is ok since\n    // const is re-introduced on the return type.\n    return findNearestCommonDominator(const_cast<NodeT *>(A),\n                                      const_cast<NodeT *>(B));\n  }\n\n  bool isVirtualRoot(const DomTreeNodeBase<NodeT> *A) const {\n    return isPostDominator() && !A->getBlock();\n  }\n\n  //===--------------------------------------------------------------------===//\n  // API to update (Post)DominatorTree information based on modifications to\n  // the CFG...\n\n  /// Inform the dominator tree about a sequence of CFG edge insertions and\n  /// deletions and perform a batch update on the tree.\n  ///\n  /// This function should be used when there were multiple CFG updates after\n  /// the last dominator tree update. It takes care of performing the updates\n  /// in sync with the CFG and optimizes away the redundant operations that\n  /// cancel each other.\n  /// The functions expects the sequence of updates to be balanced. Eg.:\n  ///  - {{Insert, A, B}, {Delete, A, B}, {Insert, A, B}} is fine, because\n  ///    logically it results in a single insertions.\n  ///  - {{Insert, A, B}, {Insert, A, B}} is invalid, because it doesn't make\n  ///    sense to insert the same edge twice.\n  ///\n  /// What's more, the functions assumes that it's safe to ask every node in the\n  /// CFG about its children and inverse children. This implies that deletions\n  /// of CFG edges must not delete the CFG nodes before calling this function.\n  ///\n  /// The applyUpdates function can reorder the updates and remove redundant\n  /// ones internally. The batch updater is also able to detect sequences of\n  /// zero and exactly one update -- it's optimized to do less work in these\n  /// cases.\n  ///\n  /// Note that for postdominators it automatically takes care of applying\n  /// updates on reverse edges internally (so there's no need to swap the\n  /// From and To pointers when constructing DominatorTree::UpdateType).\n  /// The type of updates is the same for DomTreeBase<T> and PostDomTreeBase<T>\n  /// with the same template parameter T.\n  ///\n  /// \\param Updates An unordered sequence of updates to perform. The current\n  /// CFG and the reverse of these updates provides the pre-view of the CFG.\n  ///\n  void applyUpdates(ArrayRef<UpdateType> Updates) {\n    GraphDiff<NodePtr, IsPostDominator> PreViewCFG(\n        Updates, /*ReverseApplyUpdates=*/true);\n    DomTreeBuilder::ApplyUpdates(*this, PreViewCFG, nullptr);\n  }\n\n  /// \\param Updates An unordered sequence of updates to perform. The current\n  /// CFG and the reverse of these updates provides the pre-view of the CFG.\n  /// \\param PostViewUpdates An unordered sequence of update to perform in order\n  /// to obtain a post-view of the CFG. The DT will be updated assuming the\n  /// obtained PostViewCFG is the desired end state.\n  void applyUpdates(ArrayRef<UpdateType> Updates,\n                    ArrayRef<UpdateType> PostViewUpdates) {\n    if (Updates.empty()) {\n      GraphDiff<NodePtr, IsPostDom> PostViewCFG(PostViewUpdates);\n      DomTreeBuilder::ApplyUpdates(*this, PostViewCFG, &PostViewCFG);\n    } else {\n      // PreViewCFG needs to merge Updates and PostViewCFG. The updates in\n      // Updates need to be reversed, and match the direction in PostViewCFG.\n      // The PostViewCFG is created with updates reversed (equivalent to changes\n      // made to the CFG), so the PreViewCFG needs all the updates reverse\n      // applied.\n      SmallVector<UpdateType> AllUpdates(Updates.begin(), Updates.end());\n      append_range(AllUpdates, PostViewUpdates);\n      GraphDiff<NodePtr, IsPostDom> PreViewCFG(AllUpdates,\n                                               /*ReverseApplyUpdates=*/true);\n      GraphDiff<NodePtr, IsPostDom> PostViewCFG(PostViewUpdates);\n      DomTreeBuilder::ApplyUpdates(*this, PreViewCFG, &PostViewCFG);\n    }\n  }\n\n  /// Inform the dominator tree about a CFG edge insertion and update the tree.\n  ///\n  /// This function has to be called just before or just after making the update\n  /// on the actual CFG. There cannot be any other updates that the dominator\n  /// tree doesn't know about.\n  ///\n  /// Note that for postdominators it automatically takes care of inserting\n  /// a reverse edge internally (so there's no need to swap the parameters).\n  ///\n  void insertEdge(NodeT *From, NodeT *To) {\n    assert(From);\n    assert(To);\n    assert(From->getParent() == Parent);\n    assert(To->getParent() == Parent);\n    DomTreeBuilder::InsertEdge(*this, From, To);\n  }\n\n  /// Inform the dominator tree about a CFG edge deletion and update the tree.\n  ///\n  /// This function has to be called just after making the update on the actual\n  /// CFG. An internal functions checks if the edge doesn't exist in the CFG in\n  /// DEBUG mode. There cannot be any other updates that the\n  /// dominator tree doesn't know about.\n  ///\n  /// Note that for postdominators it automatically takes care of deleting\n  /// a reverse edge internally (so there's no need to swap the parameters).\n  ///\n  void deleteEdge(NodeT *From, NodeT *To) {\n    assert(From);\n    assert(To);\n    assert(From->getParent() == Parent);\n    assert(To->getParent() == Parent);\n    DomTreeBuilder::DeleteEdge(*this, From, To);\n  }\n\n  /// Add a new node to the dominator tree information.\n  ///\n  /// This creates a new node as a child of DomBB dominator node, linking it\n  /// into the children list of the immediate dominator.\n  ///\n  /// \\param BB New node in CFG.\n  /// \\param DomBB CFG node that is dominator for BB.\n  /// \\returns New dominator tree node that represents new CFG node.\n  ///\n  DomTreeNodeBase<NodeT> *addNewBlock(NodeT *BB, NodeT *DomBB) {\n    assert(getNode(BB) == nullptr && \"Block already in dominator tree!\");\n    DomTreeNodeBase<NodeT> *IDomNode = getNode(DomBB);\n    assert(IDomNode && \"Not immediate dominator specified for block!\");\n    DFSInfoValid = false;\n    return createChild(BB, IDomNode);\n  }\n\n  /// Add a new node to the forward dominator tree and make it a new root.\n  ///\n  /// \\param BB New node in CFG.\n  /// \\returns New dominator tree node that represents new CFG node.\n  ///\n  DomTreeNodeBase<NodeT> *setNewRoot(NodeT *BB) {\n    assert(getNode(BB) == nullptr && \"Block already in dominator tree!\");\n    assert(!this->isPostDominator() &&\n           \"Cannot change root of post-dominator tree\");\n    DFSInfoValid = false;\n    DomTreeNodeBase<NodeT> *NewNode = createNode(BB);\n    if (Roots.empty()) {\n      addRoot(BB);\n    } else {\n      assert(Roots.size() == 1);\n      NodeT *OldRoot = Roots.front();\n      auto &OldNode = DomTreeNodes[OldRoot];\n      OldNode = NewNode->addChild(std::move(DomTreeNodes[OldRoot]));\n      OldNode->IDom = NewNode;\n      OldNode->UpdateLevel();\n      Roots[0] = BB;\n    }\n    return RootNode = NewNode;\n  }\n\n  /// changeImmediateDominator - This method is used to update the dominator\n  /// tree information when a node's immediate dominator changes.\n  ///\n  void changeImmediateDominator(DomTreeNodeBase<NodeT> *N,\n                                DomTreeNodeBase<NodeT> *NewIDom) {\n    assert(N && NewIDom && \"Cannot change null node pointers!\");\n    DFSInfoValid = false;\n    N->setIDom(NewIDom);\n  }\n\n  void changeImmediateDominator(NodeT *BB, NodeT *NewBB) {\n    changeImmediateDominator(getNode(BB), getNode(NewBB));\n  }\n\n  /// eraseNode - Removes a node from the dominator tree. Block must not\n  /// dominate any other blocks. Removes node from its immediate dominator's\n  /// children list. Deletes dominator node associated with basic block BB.\n  void eraseNode(NodeT *BB) {\n    DomTreeNodeBase<NodeT> *Node = getNode(BB);\n    assert(Node && \"Removing node that isn't in dominator tree.\");\n    assert(Node->isLeaf() && \"Node is not a leaf node.\");\n\n    DFSInfoValid = false;\n\n    // Remove node from immediate dominator's children list.\n    DomTreeNodeBase<NodeT> *IDom = Node->getIDom();\n    if (IDom) {\n      const auto I = find(IDom->Children, Node);\n      assert(I != IDom->Children.end() &&\n             \"Not in immediate dominator children set!\");\n      // I am no longer your child...\n      IDom->Children.erase(I);\n    }\n\n    DomTreeNodes.erase(BB);\n\n    if (!IsPostDom) return;\n\n    // Remember to update PostDominatorTree roots.\n    auto RIt = llvm::find(Roots, BB);\n    if (RIt != Roots.end()) {\n      std::swap(*RIt, Roots.back());\n      Roots.pop_back();\n    }\n  }\n\n  /// splitBlock - BB is split and now it has one successor. Update dominator\n  /// tree to reflect this change.\n  void splitBlock(NodeT *NewBB) {\n    if (IsPostDominator)\n      Split<Inverse<NodeT *>>(NewBB);\n    else\n      Split<NodeT *>(NewBB);\n  }\n\n  /// print - Convert to human readable form\n  ///\n  void print(raw_ostream &O) const {\n    O << \"=============================--------------------------------\\n\";\n    if (IsPostDominator)\n      O << \"Inorder PostDominator Tree: \";\n    else\n      O << \"Inorder Dominator Tree: \";\n    if (!DFSInfoValid)\n      O << \"DFSNumbers invalid: \" << SlowQueries << \" slow queries.\";\n    O << \"\\n\";\n\n    // The postdom tree can have a null root if there are no returns.\n    if (getRootNode()) PrintDomTree<NodeT>(getRootNode(), O, 1);\n    O << \"Roots: \";\n    for (const NodePtr Block : Roots) {\n      Block->printAsOperand(O, false);\n      O << \" \";\n    }\n    O << \"\\n\";\n  }\n\npublic:\n  /// updateDFSNumbers - Assign In and Out numbers to the nodes while walking\n  /// dominator tree in dfs order.\n  void updateDFSNumbers() const {\n    if (DFSInfoValid) {\n      SlowQueries = 0;\n      return;\n    }\n\n    SmallVector<std::pair<const DomTreeNodeBase<NodeT> *,\n                          typename DomTreeNodeBase<NodeT>::const_iterator>,\n                32> WorkStack;\n\n    const DomTreeNodeBase<NodeT> *ThisRoot = getRootNode();\n    assert((!Parent || ThisRoot) && \"Empty constructed DomTree\");\n    if (!ThisRoot)\n      return;\n\n    // Both dominators and postdominators have a single root node. In the case\n    // case of PostDominatorTree, this node is a virtual root.\n    WorkStack.push_back({ThisRoot, ThisRoot->begin()});\n\n    unsigned DFSNum = 0;\n    ThisRoot->DFSNumIn = DFSNum++;\n\n    while (!WorkStack.empty()) {\n      const DomTreeNodeBase<NodeT> *Node = WorkStack.back().first;\n      const auto ChildIt = WorkStack.back().second;\n\n      // If we visited all of the children of this node, \"recurse\" back up the\n      // stack setting the DFOutNum.\n      if (ChildIt == Node->end()) {\n        Node->DFSNumOut = DFSNum++;\n        WorkStack.pop_back();\n      } else {\n        // Otherwise, recursively visit this child.\n        const DomTreeNodeBase<NodeT> *Child = *ChildIt;\n        ++WorkStack.back().second;\n\n        WorkStack.push_back({Child, Child->begin()});\n        Child->DFSNumIn = DFSNum++;\n      }\n    }\n\n    SlowQueries = 0;\n    DFSInfoValid = true;\n  }\n\n  /// recalculate - compute a dominator tree for the given function\n  void recalculate(ParentType &Func) {\n    Parent = &Func;\n    DomTreeBuilder::Calculate(*this);\n  }\n\n  void recalculate(ParentType &Func, ArrayRef<UpdateType> Updates) {\n    Parent = &Func;\n    DomTreeBuilder::CalculateWithUpdates(*this, Updates);\n  }\n\n  /// verify - checks if the tree is correct. There are 3 level of verification:\n  ///  - Full --  verifies if the tree is correct by making sure all the\n  ///             properties (including the parent and the sibling property)\n  ///             hold.\n  ///             Takes O(N^3) time.\n  ///\n  ///  - Basic -- checks if the tree is correct, but compares it to a freshly\n  ///             constructed tree instead of checking the sibling property.\n  ///             Takes O(N^2) time.\n  ///\n  ///  - Fast  -- checks basic tree structure and compares it with a freshly\n  ///             constructed tree.\n  ///             Takes O(N^2) time worst case, but is faster in practise (same\n  ///             as tree construction).\n  bool verify(VerificationLevel VL = VerificationLevel::Full) const {\n    return DomTreeBuilder::Verify(*this, VL);\n  }\n\n  void reset() {\n    DomTreeNodes.clear();\n    Roots.clear();\n    RootNode = nullptr;\n    Parent = nullptr;\n    DFSInfoValid = false;\n    SlowQueries = 0;\n  }\n\nprotected:\n  void addRoot(NodeT *BB) { this->Roots.push_back(BB); }\n\n  DomTreeNodeBase<NodeT> *createChild(NodeT *BB, DomTreeNodeBase<NodeT> *IDom) {\n    return (DomTreeNodes[BB] = IDom->addChild(\n                std::make_unique<DomTreeNodeBase<NodeT>>(BB, IDom)))\n        .get();\n  }\n\n  DomTreeNodeBase<NodeT> *createNode(NodeT *BB) {\n    return (DomTreeNodes[BB] =\n                std::make_unique<DomTreeNodeBase<NodeT>>(BB, nullptr))\n        .get();\n  }\n\n  // NewBB is split and now it has one successor. Update dominator tree to\n  // reflect this change.\n  template <class N>\n  void Split(typename GraphTraits<N>::NodeRef NewBB) {\n    using GraphT = GraphTraits<N>;\n    using NodeRef = typename GraphT::NodeRef;\n    assert(std::distance(GraphT::child_begin(NewBB),\n                         GraphT::child_end(NewBB)) == 1 &&\n           \"NewBB should have a single successor!\");\n    NodeRef NewBBSucc = *GraphT::child_begin(NewBB);\n\n    SmallVector<NodeRef, 4> PredBlocks(children<Inverse<N>>(NewBB));\n\n    assert(!PredBlocks.empty() && \"No predblocks?\");\n\n    bool NewBBDominatesNewBBSucc = true;\n    for (auto Pred : children<Inverse<N>>(NewBBSucc)) {\n      if (Pred != NewBB && !dominates(NewBBSucc, Pred) &&\n          isReachableFromEntry(Pred)) {\n        NewBBDominatesNewBBSucc = false;\n        break;\n      }\n    }\n\n    // Find NewBB's immediate dominator and create new dominator tree node for\n    // NewBB.\n    NodeT *NewBBIDom = nullptr;\n    unsigned i = 0;\n    for (i = 0; i < PredBlocks.size(); ++i)\n      if (isReachableFromEntry(PredBlocks[i])) {\n        NewBBIDom = PredBlocks[i];\n        break;\n      }\n\n    // It's possible that none of the predecessors of NewBB are reachable;\n    // in that case, NewBB itself is unreachable, so nothing needs to be\n    // changed.\n    if (!NewBBIDom) return;\n\n    for (i = i + 1; i < PredBlocks.size(); ++i) {\n      if (isReachableFromEntry(PredBlocks[i]))\n        NewBBIDom = findNearestCommonDominator(NewBBIDom, PredBlocks[i]);\n    }\n\n    // Create the new dominator tree node... and set the idom of NewBB.\n    DomTreeNodeBase<NodeT> *NewBBNode = addNewBlock(NewBB, NewBBIDom);\n\n    // If NewBB strictly dominates other blocks, then it is now the immediate\n    // dominator of NewBBSucc.  Update the dominator tree as appropriate.\n    if (NewBBDominatesNewBBSucc) {\n      DomTreeNodeBase<NodeT> *NewBBSuccNode = getNode(NewBBSucc);\n      changeImmediateDominator(NewBBSuccNode, NewBBNode);\n    }\n  }\n\n private:\n  bool dominatedBySlowTreeWalk(const DomTreeNodeBase<NodeT> *A,\n                               const DomTreeNodeBase<NodeT> *B) const {\n    assert(A != B);\n    assert(isReachableFromEntry(B));\n    assert(isReachableFromEntry(A));\n\n    const unsigned ALevel = A->getLevel();\n    const DomTreeNodeBase<NodeT> *IDom;\n\n    // Don't walk nodes above A's subtree. When we reach A's level, we must\n    // either find A or be in some other subtree not dominated by A.\n    while ((IDom = B->getIDom()) != nullptr && IDom->getLevel() >= ALevel)\n      B = IDom;  // Walk up the tree\n\n    return B == A;\n  }\n\n  /// Wipe this tree's state without releasing any resources.\n  ///\n  /// This is essentially a post-move helper only. It leaves the object in an\n  /// assignable and destroyable state, but otherwise invalid.\n  void wipe() {\n    DomTreeNodes.clear();\n    RootNode = nullptr;\n    Parent = nullptr;\n  }\n};\n\ntemplate <typename T>\nusing DomTreeBase = DominatorTreeBase<T, false>;\n\ntemplate <typename T>\nusing PostDomTreeBase = DominatorTreeBase<T, true>;\n\n// These two functions are declared out of line as a workaround for building\n// with old (< r147295) versions of clang because of pr11642.\ntemplate <typename NodeT, bool IsPostDom>\nbool DominatorTreeBase<NodeT, IsPostDom>::dominates(const NodeT *A,\n                                                    const NodeT *B) const {\n  if (A == B)\n    return true;\n\n  // Cast away the const qualifiers here. This is ok since\n  // this function doesn't actually return the values returned\n  // from getNode.\n  return dominates(getNode(const_cast<NodeT *>(A)),\n                   getNode(const_cast<NodeT *>(B)));\n}\ntemplate <typename NodeT, bool IsPostDom>\nbool DominatorTreeBase<NodeT, IsPostDom>::properlyDominates(\n    const NodeT *A, const NodeT *B) const {\n  if (A == B)\n    return false;\n\n  // Cast away the const qualifiers here. This is ok since\n  // this function doesn't actually return the values returned\n  // from getNode.\n  return dominates(getNode(const_cast<NodeT *>(A)),\n                   getNode(const_cast<NodeT *>(B)));\n}\n\n} // end namespace llvm\n\n#endif // LLVM_SUPPORT_GENERICDOMTREE_H\n"}, "80": {"id": 80, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/DependenceInfo.h", "content": "//===--- polly/DependenceInfo.h - Polyhedral dependency analysis *- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Calculate the data dependency relations for a Scop using ISL.\n//\n// The integer set library (ISL) from Sven has an integrated dependency analysis\n// to calculate data dependences. This pass takes advantage of this and\n// calculates those dependences of a Scop.\n//\n// The dependences in this pass are exact in terms that for a specific read\n// statement instance only the last write statement instance is returned. In\n// case of may-writes, a set of possible write instances is returned. This\n// analysis will never produce redundant dependences.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_DEPENDENCE_INFO_H\n#define POLLY_DEPENDENCE_INFO_H\n\n#include \"polly/ScopPass.h\"\n#include \"isl/ctx.h\"\n#include \"isl/isl-noexceptions.h\"\n\nnamespace polly {\n\n/// The accumulated dependence information for a SCoP.\n///\n/// The Dependences struct holds all dependence information we collect and\n/// compute for one SCoP. It also offers an interface that allows users to\n/// query only specific parts.\nstruct Dependences {\n  // Granularities of the current dependence analysis\n  enum AnalysisLevel {\n    AL_Statement = 0,\n    // Distinguish accessed memory references in the same statement\n    AL_Reference,\n    // Distinguish memory access instances in the same statement\n    AL_Access,\n\n    NumAnalysisLevels\n  };\n\n  /// Map type for reduction dependences.\n  using ReductionDependencesMapTy = DenseMap<MemoryAccess *, isl_map *>;\n\n  /// Map type to associate statements with schedules.\n  using StatementToIslMapTy = DenseMap<ScopStmt *, isl::map>;\n\n  /// The type of the dependences.\n  ///\n  /// Reduction dependences are separated from RAW/WAW/WAR dependences because\n  /// we can ignore them during the scheduling. That's because the order\n  /// in which the reduction statements are executed does not matter. However,\n  /// if they are executed in parallel we need to take additional measures\n  /// (e.g, privatization) to ensure a correct result. The (reverse) transitive\n  /// closure of the reduction dependences are used to check for parallel\n  /// executed reduction statements during code generation. These dependences\n  /// connect all instances of a reduction with each other, they are therefore\n  /// cyclic and possibly \"reversed\".\n  enum Type {\n    // Write after read\n    TYPE_WAR = 1 << 0,\n\n    // Read after write\n    TYPE_RAW = 1 << 1,\n\n    // Write after write\n    TYPE_WAW = 1 << 2,\n\n    // Reduction dependences\n    TYPE_RED = 1 << 3,\n\n    // Transitive closure of the reduction dependences (& the reverse)\n    TYPE_TC_RED = 1 << 4,\n  };\n\n  const std::shared_ptr<isl_ctx> &getSharedIslCtx() const { return IslCtx; }\n\n  /// Get the dependences of type @p Kinds.\n  ///\n  /// @param Kinds This integer defines the different kinds of dependences\n  ///              that will be returned. To return more than one kind, the\n  ///              different kinds are 'ored' together.\n  isl::union_map getDependences(int Kinds) const;\n\n  /// Report if valid dependences are available.\n  bool hasValidDependences() const;\n\n  /// Return the reduction dependences caused by @p MA.\n  ///\n  /// @return The reduction dependences caused by @p MA or nullptr if none.\n  __isl_give isl_map *getReductionDependences(MemoryAccess *MA) const;\n\n  /// Return all reduction dependences.\n  const ReductionDependencesMapTy &getReductionDependences() const {\n    return ReductionDependences;\n  }\n\n  /// Check if a partial schedule is parallel wrt to @p Deps.\n  ///\n  /// @param Schedule       The subset of the schedule space that we want to\n  ///                       check.\n  /// @param Deps           The dependences @p Schedule needs to respect.\n  /// @param MinDistancePtr If not nullptr, the minimal dependence distance will\n  ///                       be returned at the address of that pointer\n  ///\n  /// @return Returns true, if executing parallel the outermost dimension of\n  ///         @p Schedule is valid according to the dependences @p Deps.\n  bool isParallel(__isl_keep isl_union_map *Schedule,\n                  __isl_take isl_union_map *Deps,\n                  __isl_give isl_pw_aff **MinDistancePtr = nullptr) const;\n\n  /// Check if a new schedule is valid.\n  ///\n  /// @param S             The current SCoP.\n  /// @param NewSchedules  The new schedules\n  ///\n  /// @return True if the new schedule is valid, false if it reverses\n  ///         dependences.\n  bool isValidSchedule(Scop &S, const StatementToIslMapTy &NewSchedules) const;\n\n  /// Print the stored dependence information.\n  void print(llvm::raw_ostream &OS) const;\n\n  /// Dump the dependence information stored to the dbgs stream.\n  void dump() const;\n\n  /// Return the granularity of this dependence analysis.\n  AnalysisLevel getDependenceLevel() { return Level; }\n\n  /// Allow the DependenceInfo access to private members and methods.\n  ///\n  /// To restrict access to the internal state, only the DependenceInfo class\n  /// is able to call or modify a Dependences struct.\n  friend struct DependenceAnalysis;\n  friend struct DependenceInfoPrinterPass;\n  friend class DependenceInfo;\n  friend class DependenceInfoWrapperPass;\n\n  /// Destructor that will free internal objects.\n  ~Dependences() { releaseMemory(); }\n\nprivate:\n  /// Create an empty dependences struct.\n  explicit Dependences(const std::shared_ptr<isl_ctx> &IslCtx,\n                       AnalysisLevel Level)\n      : RAW(nullptr), WAR(nullptr), WAW(nullptr), RED(nullptr), TC_RED(nullptr),\n        IslCtx(IslCtx), Level(Level) {}\n\n  /// Calculate and add at the privatization dependences.\n  void addPrivatizationDependences();\n\n  /// Calculate the dependences for a certain SCoP @p S.\n  void calculateDependences(Scop &S);\n\n  /// Set the reduction dependences for @p MA to @p Deps.\n  void setReductionDependences(MemoryAccess *MA, __isl_take isl_map *Deps);\n\n  /// Free the objects associated with this Dependences struct.\n  ///\n  /// The Dependences struct will again be \"empty\" afterwards.\n  void releaseMemory();\n\n  /// The different basic kinds of dependences we calculate.\n  isl_union_map *RAW;\n  isl_union_map *WAR;\n  isl_union_map *WAW;\n\n  /// The special reduction dependences.\n  isl_union_map *RED;\n\n  /// The (reverse) transitive closure of reduction dependences.\n  isl_union_map *TC_RED;\n\n  /// Mapping from memory accesses to their reduction dependences.\n  ReductionDependencesMapTy ReductionDependences;\n\n  /// Isl context from the SCoP.\n  std::shared_ptr<isl_ctx> IslCtx;\n\n  /// Granularity of this dependence analysis.\n  const AnalysisLevel Level;\n};\n\nstruct DependenceAnalysis : public AnalysisInfoMixin<DependenceAnalysis> {\n  static AnalysisKey Key;\n  struct Result {\n    Scop &S;\n    std::unique_ptr<Dependences> D[Dependences::NumAnalysisLevels];\n\n    /// Return the dependence information for the current SCoP.\n    ///\n    /// @param Level The granularity of dependence analysis result.\n    ///\n    /// @return The dependence analysis result\n    ///\n    const Dependences &getDependences(Dependences::AnalysisLevel Level);\n\n    /// Recompute dependences from schedule and memory accesses.\n    const Dependences &recomputeDependences(Dependences::AnalysisLevel Level);\n  };\n  Result run(Scop &S, ScopAnalysisManager &SAM,\n             ScopStandardAnalysisResults &SAR);\n};\n\nstruct DependenceInfoPrinterPass\n    : public PassInfoMixin<DependenceInfoPrinterPass> {\n  DependenceInfoPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Scop &S, ScopAnalysisManager &,\n                        ScopStandardAnalysisResults &, SPMUpdater &);\n\n  raw_ostream &OS;\n};\n\nclass DependenceInfo : public ScopPass {\npublic:\n  static char ID;\n\n  /// Construct a new DependenceInfo pass.\n  DependenceInfo() : ScopPass(ID) {}\n\n  /// Return the dependence information for the current SCoP.\n  ///\n  /// @param Level The granularity of dependence analysis result.\n  ///\n  /// @return The dependence analysis result\n  ///\n  const Dependences &getDependences(Dependences::AnalysisLevel Level);\n\n  /// Recompute dependences from schedule and memory accesses.\n  const Dependences &recomputeDependences(Dependences::AnalysisLevel Level);\n\n  /// Compute the dependence information for the SCoP @p S.\n  bool runOnScop(Scop &S) override;\n\n  /// Print the dependences for the given SCoP to @p OS.\n  void printScop(raw_ostream &OS, Scop &) const override;\n\n  /// Release the internal memory.\n  void releaseMemory() override {\n    for (auto &d : D)\n      d.reset();\n  }\n\n  /// Register all analyses and transformation required.\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\nprivate:\n  Scop *S;\n\n  /// Dependences struct for the current SCoP.\n  std::unique_ptr<Dependences> D[Dependences::NumAnalysisLevels];\n};\n\n/// Construct a new DependenceInfoWrapper pass.\nclass DependenceInfoWrapperPass : public FunctionPass {\npublic:\n  static char ID;\n\n  /// Construct a new DependenceInfoWrapper pass.\n  DependenceInfoWrapperPass() : FunctionPass(ID) {}\n\n  /// Return the dependence information for the given SCoP.\n  ///\n  /// @param S     SCoP object.\n  /// @param Level The granularity of dependence analysis result.\n  ///\n  /// @return The dependence analysis result\n  ///\n  const Dependences &getDependences(Scop *S, Dependences::AnalysisLevel Level);\n\n  /// Recompute dependences from schedule and memory accesses.\n  const Dependences &recomputeDependences(Scop *S,\n                                          Dependences::AnalysisLevel Level);\n\n  /// Compute the dependence information on-the-fly for the function.\n  bool runOnFunction(Function &F) override;\n\n  /// Print the dependences for the current function to @p OS.\n  void print(raw_ostream &OS, const Module *M = nullptr) const override;\n\n  /// Release the internal memory.\n  void releaseMemory() override { ScopToDepsMap.clear(); }\n\n  /// Register all analyses and transformation required.\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\nprivate:\n  using ScopToDepsMapTy = DenseMap<Scop *, std::unique_ptr<Dependences>>;\n\n  /// Scop to Dependence map for the current function.\n  ScopToDepsMapTy ScopToDepsMap;\n};\n} // namespace polly\n\nnamespace llvm {\nvoid initializeDependenceInfoPass(llvm::PassRegistry &);\nvoid initializeDependenceInfoWrapperPassPass(llvm::PassRegistry &);\n} // namespace llvm\n\n#endif\n"}, "81": {"id": 81, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/LinkAllPasses.h", "content": "//===- polly/LinkAllPasses.h ----------- Reference All Passes ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This header file pulls in all transformation and analysis passes for tools\n// like opt and bugpoint that need this functionality.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_LINKALLPASSES_H\n#define POLLY_LINKALLPASSES_H\n\n#include \"polly/CodeGen/PPCGCodeGeneration.h\"\n#include \"polly/Config/config.h\"\n#include \"polly/Support/DumpModulePass.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include <cstdlib>\n\nnamespace llvm {\nclass Pass;\nclass PassRegistry;\n} // namespace llvm\n\nnamespace polly {\nllvm::Pass *createCodePreparationPass();\nllvm::Pass *createScopInlinerPass();\nllvm::Pass *createDeadCodeElimPass();\nllvm::Pass *createDependenceInfoPass();\nllvm::Pass *createDependenceInfoWrapperPassPass();\nllvm::Pass *createDOTOnlyPrinterPass();\nllvm::Pass *createDOTOnlyViewerPass();\nllvm::Pass *createDOTPrinterPass();\nllvm::Pass *createDOTViewerPass();\nllvm::Pass *createJSONExporterPass();\nllvm::Pass *createJSONImporterPass();\nllvm::Pass *createPollyCanonicalizePass();\nllvm::Pass *createPolyhedralInfoPass();\nllvm::Pass *createScopDetectionWrapperPassPass();\nllvm::Pass *createScopInfoRegionPassPass();\nllvm::Pass *createScopInfoWrapperPassPass();\nllvm::Pass *createRewriteByrefParamsPass();\nllvm::Pass *createIslAstInfoWrapperPassPass();\nllvm::Pass *createCodeGenerationPass();\n#ifdef GPU_CODEGEN\nllvm::Pass *createPPCGCodeGenerationPass(GPUArch Arch = GPUArch::NVPTX64,\n                                         GPURuntime Runtime = GPURuntime::CUDA);\n\nllvm::Pass *\ncreateManagedMemoryRewritePassPass(GPUArch Arch = GPUArch::NVPTX64,\n                                   GPURuntime Runtime = GPURuntime::CUDA);\n#endif\nllvm::Pass *createIslScheduleOptimizerWrapperPass();\nllvm::Pass *createFlattenSchedulePass();\nllvm::Pass *createForwardOpTreeWrapperPass();\nllvm::Pass *createDeLICMWrapperPass();\nllvm::Pass *createMaximalStaticExpansionPass();\nllvm::Pass *createSimplifyWrapperPass(int);\nllvm::Pass *createPruneUnprofitableWrapperPass();\n\nextern char &CodePreparationID;\n} // namespace polly\n\nnamespace {\nstruct PollyForcePassLinking {\n  PollyForcePassLinking() {\n    // We must reference the passes in such a way that compilers will not\n    // delete it all as dead code, even with whole program optimization,\n    // yet is effectively a NO-OP. As the compiler isn't smart enough\n    // to know that getenv() never returns -1, this will do the job.\n    if (std::getenv(\"bar\") != (char *)-1)\n      return;\n\n    polly::createCodePreparationPass();\n    polly::createDeadCodeElimPass();\n    polly::createDependenceInfoPass();\n    polly::createDOTOnlyPrinterPass();\n    polly::createDOTOnlyViewerPass();\n    polly::createDOTPrinterPass();\n    polly::createDOTViewerPass();\n    polly::createJSONExporterPass();\n    polly::createJSONImporterPass();\n    polly::createScopDetectionWrapperPassPass();\n    polly::createScopInfoRegionPassPass();\n    polly::createPollyCanonicalizePass();\n    polly::createPolyhedralInfoPass();\n    polly::createIslAstInfoWrapperPassPass();\n    polly::createCodeGenerationPass();\n#ifdef GPU_CODEGEN\n    polly::createPPCGCodeGenerationPass();\n    polly::createManagedMemoryRewritePassPass();\n#endif\n    polly::createIslScheduleOptimizerWrapperPass();\n    polly::createMaximalStaticExpansionPass();\n    polly::createFlattenSchedulePass();\n    polly::createForwardOpTreeWrapperPass();\n    polly::createDeLICMWrapperPass();\n    polly::createDumpModulePass(\"\", true);\n    polly::createSimplifyWrapperPass(0);\n    polly::createPruneUnprofitableWrapperPass();\n  }\n} PollyForcePassLinking; // Force link by creating a global definition.\n} // namespace\n\nnamespace llvm {\nclass PassRegistry;\nvoid initializeCodePreparationPass(llvm::PassRegistry &);\nvoid initializeScopInlinerPass(llvm::PassRegistry &);\nvoid initializeDeadCodeElimPass(llvm::PassRegistry &);\nvoid initializeJSONExporterPass(llvm::PassRegistry &);\nvoid initializeJSONImporterPass(llvm::PassRegistry &);\nvoid initializeIslAstInfoWrapperPassPass(llvm::PassRegistry &);\nvoid initializeCodeGenerationPass(llvm::PassRegistry &);\nvoid initializeRewriteByrefParamsPass(llvm::PassRegistry &);\n#ifdef GPU_CODEGEN\nvoid initializePPCGCodeGenerationPass(llvm::PassRegistry &);\nvoid initializeManagedMemoryRewritePassPass(llvm::PassRegistry &);\n#endif\nvoid initializeIslScheduleOptimizerWrapperPassPass(llvm::PassRegistry &);\nvoid initializeMaximalStaticExpanderPass(llvm::PassRegistry &);\nvoid initializePollyCanonicalizePass(llvm::PassRegistry &);\nvoid initializeFlattenSchedulePass(llvm::PassRegistry &);\nvoid initializeForwardOpTreeWrapperPassPass(llvm::PassRegistry &);\nvoid initializeDeLICMWrapperPassPass(llvm::PassRegistry &);\nvoid initializeSimplifyWrapperPassPass(llvm::PassRegistry &);\nvoid initializePruneUnprofitableWrapperPassPass(llvm::PassRegistry &);\n} // namespace llvm\n\n#endif\n"}, "82": {"id": 82, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetection.h", "content": "//===- ScopDetection.h - Detect Scops ---------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Detect the maximal Scops of a function.\n//\n// A static control part (Scop) is a subgraph of the control flow graph (CFG)\n// that only has statically known control flow and can therefore be described\n// within the polyhedral model.\n//\n// Every Scop fulfills these restrictions:\n//\n// * It is a single entry single exit region\n//\n// * Only affine linear bounds in the loops\n//\n// Every natural loop in a Scop must have a number of loop iterations that can\n// be described as an affine linear function in surrounding loop iterators or\n// parameters. (A parameter is a scalar that does not change its value during\n// execution of the Scop).\n//\n// * Only comparisons of affine linear expressions in conditions\n//\n// * All loops and conditions perfectly nested\n//\n// The control flow needs to be structured such that it could be written using\n// just 'for' and 'if' statements, without the need for any 'goto', 'break' or\n// 'continue'.\n//\n// * Side effect free functions call\n//\n// Only function calls and intrinsics that do not have side effects are allowed\n// (readnone).\n//\n// The Scop detection finds the largest Scops by checking if the largest\n// region is a Scop. If this is not the case, its canonical subregions are\n// checked until a region is a Scop. It is now tried to extend this Scop by\n// creating a larger non canonical region.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_SCOPDETECTION_H\n#define POLLY_SCOPDETECTION_H\n\n#include \"polly/ScopDetectionDiagnostic.h\"\n#include \"polly/Support/ScopHelper.h\"\n#include \"llvm/Analysis/AliasSetTracker.h\"\n#include \"llvm/Analysis/RegionInfo.h\"\n#include \"llvm/Analysis/ScalarEvolutionExpressions.h\"\n#include \"llvm/Pass.h\"\n#include <set>\n\nnamespace llvm {\nclass AAResults;\n\nvoid initializeScopDetectionWrapperPassPass(PassRegistry &);\n} // namespace llvm\n\nnamespace polly {\nusing llvm::AAResults;\nusing llvm::AliasSetTracker;\nusing llvm::AnalysisInfoMixin;\nusing llvm::AnalysisKey;\nusing llvm::AnalysisUsage;\nusing llvm::BranchInst;\nusing llvm::CallInst;\nusing llvm::DenseMap;\nusing llvm::DominatorTree;\nusing llvm::Function;\nusing llvm::FunctionAnalysisManager;\nusing llvm::FunctionPass;\nusing llvm::IntrinsicInst;\nusing llvm::LoopInfo;\nusing llvm::Module;\nusing llvm::OptimizationRemarkEmitter;\nusing llvm::PassInfoMixin;\nusing llvm::PreservedAnalyses;\nusing llvm::RegionInfo;\nusing llvm::ScalarEvolution;\nusing llvm::SCEVUnknown;\nusing llvm::SetVector;\nusing llvm::SmallSetVector;\nusing llvm::SmallVectorImpl;\nusing llvm::StringRef;\nusing llvm::SwitchInst;\n\nusing ParamSetType = std::set<const SCEV *>;\n\n// Description of the shape of an array.\nstruct ArrayShape {\n  // Base pointer identifying all accesses to this array.\n  const SCEVUnknown *BasePointer;\n\n  // Sizes of each delinearized dimension.\n  SmallVector<const SCEV *, 4> DelinearizedSizes;\n\n  ArrayShape(const SCEVUnknown *B) : BasePointer(B) {}\n};\n\nstruct MemAcc {\n  const Instruction *Insn;\n\n  // A pointer to the shape description of the array.\n  std::shared_ptr<ArrayShape> Shape;\n\n  // Subscripts computed by delinearization.\n  SmallVector<const SCEV *, 4> DelinearizedSubscripts;\n\n  MemAcc(const Instruction *I, std::shared_ptr<ArrayShape> S)\n      : Insn(I), Shape(S) {}\n};\n\nusing MapInsnToMemAcc = std::map<const Instruction *, MemAcc>;\nusing PairInstSCEV = std::pair<const Instruction *, const SCEV *>;\nusing AFs = std::vector<PairInstSCEV>;\nusing BaseToAFs = std::map<const SCEVUnknown *, AFs>;\nusing BaseToElSize = std::map<const SCEVUnknown *, const SCEV *>;\n\nextern bool PollyTrackFailures;\nextern bool PollyDelinearize;\nextern bool PollyUseRuntimeAliasChecks;\nextern bool PollyProcessUnprofitable;\nextern bool PollyInvariantLoadHoisting;\nextern bool PollyAllowUnsignedOperations;\nextern bool PollyAllowFullFunction;\n\n/// A function attribute which will cause Polly to skip the function\nextern StringRef PollySkipFnAttr;\n\n//===----------------------------------------------------------------------===//\n/// Pass to detect the maximal static control parts (Scops) of a\n/// function.\nclass ScopDetection {\npublic:\n  using RegionSet = SetVector<const Region *>;\n\n  // Remember the valid regions\n  RegionSet ValidRegions;\n\n  /// Context variables for SCoP detection.\n  struct DetectionContext {\n    Region &CurRegion;   // The region to check.\n    AliasSetTracker AST; // The AliasSetTracker to hold the alias information.\n    bool Verifying;      // If we are in the verification phase?\n\n    /// Container to remember rejection reasons for this region.\n    RejectLog Log;\n\n    /// Map a base pointer to all access functions accessing it.\n    ///\n    /// This map is indexed by the base pointer. Each element of the map\n    /// is a list of memory accesses that reference this base pointer.\n    BaseToAFs Accesses;\n\n    /// The set of base pointers with non-affine accesses.\n    ///\n    /// This set contains all base pointers and the locations where they are\n    /// used for memory accesses that can not be detected as affine accesses.\n    llvm::SetVector<std::pair<const SCEVUnknown *, Loop *>> NonAffineAccesses;\n    BaseToElSize ElementSize;\n\n    /// The region has at least one load instruction.\n    bool hasLoads = false;\n\n    /// The region has at least one store instruction.\n    bool hasStores = false;\n\n    /// Flag to indicate the region has at least one unknown access.\n    bool HasUnknownAccess = false;\n\n    /// The set of non-affine subregions in the region we analyze.\n    RegionSet NonAffineSubRegionSet;\n\n    /// The set of loops contained in non-affine regions.\n    BoxedLoopsSetTy BoxedLoopsSet;\n\n    /// Loads that need to be invariant during execution.\n    InvariantLoadsSetTy RequiredILS;\n\n    /// Map to memory access description for the corresponding LLVM\n    ///        instructions.\n    MapInsnToMemAcc InsnToMemAcc;\n\n    /// Initialize a DetectionContext from scratch.\n    DetectionContext(Region &R, AAResults &AA, bool Verify)\n        : CurRegion(R), AST(AA), Verifying(Verify), Log(&R) {}\n  };\n\n  /// Helper data structure to collect statistics about loop counts.\n  struct LoopStats {\n    int NumLoops;\n    int MaxDepth;\n  };\n\n  int NextScopID = 0;\n  int getNextID() { return NextScopID++; }\n\nprivate:\n  //===--------------------------------------------------------------------===//\n\n  /// Analyses used\n  //@{\n  const DominatorTree &DT;\n  ScalarEvolution &SE;\n  LoopInfo &LI;\n  RegionInfo &RI;\n  AAResults &AA;\n  //@}\n\n  /// Map to remember detection contexts for all regions.\n  using DetectionContextMapTy =\n      DenseMap<BBPair, std::unique_ptr<DetectionContext>>;\n  mutable DetectionContextMapTy DetectionContextMap;\n\n  /// Remove cached results for @p R.\n  void removeCachedResults(const Region &R);\n\n  /// Remove cached results for the children of @p R recursively.\n  void removeCachedResultsRecursively(const Region &R);\n\n  /// Check if @p S0 and @p S1 do contain multiple possibly aliasing pointers.\n  ///\n  /// @param S0    A expression to check.\n  /// @param S1    Another expression to check or nullptr.\n  /// @param Scope The loop/scope the expressions are checked in.\n  ///\n  /// @returns True, if multiple possibly aliasing pointers are used in @p S0\n  ///          (and @p S1 if given).\n  bool involvesMultiplePtrs(const SCEV *S0, const SCEV *S1, Loop *Scope) const;\n\n  /// Add the region @p AR as over approximated sub-region in @p Context.\n  ///\n  /// @param AR      The non-affine subregion.\n  /// @param Context The current detection context.\n  ///\n  /// @returns True if the subregion can be over approximated, false otherwise.\n  bool addOverApproximatedRegion(Region *AR, DetectionContext &Context) const;\n\n  /// Find for a given base pointer terms that hint towards dimension\n  ///        sizes of a multi-dimensional array.\n  ///\n  /// @param Context      The current detection context.\n  /// @param BasePointer  A base pointer indicating the virtual array we are\n  ///                     interested in.\n  SmallVector<const SCEV *, 4>\n  getDelinearizationTerms(DetectionContext &Context,\n                          const SCEVUnknown *BasePointer) const;\n\n  /// Check if the dimension size of a delinearized array is valid.\n  ///\n  /// @param Context     The current detection context.\n  /// @param Sizes       The sizes of the different array dimensions.\n  /// @param BasePointer The base pointer we are interested in.\n  /// @param Scope       The location where @p BasePointer is being used.\n  /// @returns True if one or more array sizes could be derived - meaning: we\n  ///          see this array as multi-dimensional.\n  bool hasValidArraySizes(DetectionContext &Context,\n                          SmallVectorImpl<const SCEV *> &Sizes,\n                          const SCEVUnknown *BasePointer, Loop *Scope) const;\n\n  /// Derive access functions for a given base pointer.\n  ///\n  /// @param Context     The current detection context.\n  /// @param Sizes       The sizes of the different array dimensions.\n  /// @param BasePointer The base pointer of all the array for which to compute\n  ///                    access functions.\n  /// @param Shape       The shape that describes the derived array sizes and\n  ///                    which should be filled with newly computed access\n  ///                    functions.\n  /// @returns True if a set of affine access functions could be derived.\n  bool computeAccessFunctions(DetectionContext &Context,\n                              const SCEVUnknown *BasePointer,\n                              std::shared_ptr<ArrayShape> Shape) const;\n\n  /// Check if all accesses to a given BasePointer are affine.\n  ///\n  /// @param Context     The current detection context.\n  /// @param BasePointer the base pointer we are interested in.\n  /// @param Scope       The location where @p BasePointer is being used.\n  /// @param True if consistent (multi-dimensional) array accesses could be\n  ///        derived for this array.\n  bool hasBaseAffineAccesses(DetectionContext &Context,\n                             const SCEVUnknown *BasePointer, Loop *Scope) const;\n\n  // Delinearize all non affine memory accesses and return false when there\n  // exists a non affine memory access that cannot be delinearized. Return true\n  // when all array accesses are affine after delinearization.\n  bool hasAffineMemoryAccesses(DetectionContext &Context) const;\n\n  // Try to expand the region R. If R can be expanded return the expanded\n  // region, NULL otherwise.\n  Region *expandRegion(Region &R);\n\n  /// Find the Scops in this region tree.\n  ///\n  /// @param The region tree to scan for scops.\n  void findScops(Region &R);\n\n  /// Check if all basic block in the region are valid.\n  ///\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if all blocks in R are valid, false otherwise.\n  bool allBlocksValid(DetectionContext &Context) const;\n\n  /// Check if a region has sufficient compute instructions.\n  ///\n  /// This function checks if a region has a non-trivial number of instructions\n  /// in each loop. This can be used as an indicator whether a loop is worth\n  /// optimizing.\n  ///\n  /// @param Context  The context of scop detection.\n  /// @param NumLoops The number of loops in the region.\n  ///\n  /// @return True if region is has sufficient compute instructions,\n  ///         false otherwise.\n  bool hasSufficientCompute(DetectionContext &Context,\n                            int NumAffineLoops) const;\n\n  /// Check if the unique affine loop might be amendable to distribution.\n  ///\n  /// This function checks if the number of non-trivial blocks in the unique\n  /// affine loop in Context.CurRegion is at least two, thus if the loop might\n  /// be amendable to distribution.\n  ///\n  /// @param Context  The context of scop detection.\n  ///\n  /// @return True only if the affine loop might be amendable to distributable.\n  bool hasPossiblyDistributableLoop(DetectionContext &Context) const;\n\n  /// Check if a region is profitable to optimize.\n  ///\n  /// Regions that are unlikely to expose interesting optimization opportunities\n  /// are called 'unprofitable' and may be skipped during scop detection.\n  ///\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if region is profitable to optimize, false otherwise.\n  bool isProfitableRegion(DetectionContext &Context) const;\n\n  /// Check if a region is a Scop.\n  ///\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if R is a Scop, false otherwise.\n  bool isValidRegion(DetectionContext &Context) const;\n\n  /// Check if an intrinsic call can be part of a Scop.\n  ///\n  /// @param II      The intrinsic call instruction to check.\n  /// @param Context The current detection context.\n  ///\n  /// @return True if the call instruction is valid, false otherwise.\n  bool isValidIntrinsicInst(IntrinsicInst &II, DetectionContext &Context) const;\n\n  /// Check if a call instruction can be part of a Scop.\n  ///\n  /// @param CI      The call instruction to check.\n  /// @param Context The current detection context.\n  ///\n  /// @return True if the call instruction is valid, false otherwise.\n  bool isValidCallInst(CallInst &CI, DetectionContext &Context) const;\n\n  /// Check if the given loads could be invariant and can be hoisted.\n  ///\n  /// If true is returned the loads are added to the required invariant loads\n  /// contained in the @p Context.\n  ///\n  /// @param RequiredILS The loads to check.\n  /// @param Context     The current detection context.\n  ///\n  /// @return True if all loads can be assumed invariant.\n  bool onlyValidRequiredInvariantLoads(InvariantLoadsSetTy &RequiredILS,\n                                       DetectionContext &Context) const;\n\n  /// Check if a value is invariant in the region Reg.\n  ///\n  /// @param Val Value to check for invariance.\n  /// @param Reg The region to consider for the invariance of Val.\n  /// @param Ctx The current detection context.\n  ///\n  /// @return True if the value represented by Val is invariant in the region\n  ///         identified by Reg.\n  bool isInvariant(Value &Val, const Region &Reg, DetectionContext &Ctx) const;\n\n  /// Check if the memory access caused by @p Inst is valid.\n  ///\n  /// @param Inst    The access instruction.\n  /// @param AF      The access function.\n  /// @param BP      The access base pointer.\n  /// @param Context The current detection context.\n  bool isValidAccess(Instruction *Inst, const SCEV *AF, const SCEVUnknown *BP,\n                     DetectionContext &Context) const;\n\n  /// Check if a memory access can be part of a Scop.\n  ///\n  /// @param Inst The instruction accessing the memory.\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if the memory access is valid, false otherwise.\n  bool isValidMemoryAccess(MemAccInst Inst, DetectionContext &Context) const;\n\n  /// Check if an instruction has any non trivial scalar dependencies as part of\n  /// a Scop.\n  ///\n  /// @param Inst The instruction to check.\n  /// @param RefRegion The region in respect to which we check the access\n  ///                  function.\n  ///\n  /// @return True if the instruction has scalar dependences, false otherwise.\n  bool hasScalarDependency(Instruction &Inst, Region &RefRegion) const;\n\n  /// Check if an instruction can be part of a Scop.\n  ///\n  /// @param Inst The instruction to check.\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if the instruction is valid, false otherwise.\n  bool isValidInstruction(Instruction &Inst, DetectionContext &Context) const;\n\n  /// Check if the switch @p SI with condition @p Condition is valid.\n  ///\n  /// @param BB           The block to check.\n  /// @param SI           The switch to check.\n  /// @param Condition    The switch condition.\n  /// @param IsLoopBranch Flag to indicate the branch is a loop exit/latch.\n  /// @param Context      The context of scop detection.\n  ///\n  /// @return True if the branch @p BI is valid.\n  bool isValidSwitch(BasicBlock &BB, SwitchInst *SI, Value *Condition,\n                     bool IsLoopBranch, DetectionContext &Context) const;\n\n  /// Check if the branch @p BI with condition @p Condition is valid.\n  ///\n  /// @param BB           The block to check.\n  /// @param BI           The branch to check.\n  /// @param Condition    The branch condition.\n  /// @param IsLoopBranch Flag to indicate the branch is a loop exit/latch.\n  /// @param Context      The context of scop detection.\n  ///\n  /// @return True if the branch @p BI is valid.\n  bool isValidBranch(BasicBlock &BB, BranchInst *BI, Value *Condition,\n                     bool IsLoopBranch, DetectionContext &Context) const;\n\n  /// Check if the SCEV @p S is affine in the current @p Context.\n  ///\n  /// This will also use a heuristic to decide if we want to require loads to be\n  /// invariant to make the expression affine or if we want to treat is as\n  /// non-affine.\n  ///\n  /// @param S           The expression to be checked.\n  /// @param Scope       The loop nest in which @p S is used.\n  /// @param Context     The context of scop detection.\n  bool isAffine(const SCEV *S, Loop *Scope, DetectionContext &Context) const;\n\n  /// Check if the control flow in a basic block is valid.\n  ///\n  /// This function checks if a certain basic block is terminated by a\n  /// Terminator instruction we can handle or, if this is not the case,\n  /// registers this basic block as the start of a non-affine region.\n  ///\n  /// This function optionally allows unreachable statements.\n  ///\n  /// @param BB               The BB to check the control flow.\n  /// @param IsLoopBranch     Flag to indicate the branch is a loop exit/latch.\n  //  @param AllowUnreachable Allow unreachable statements.\n  /// @param Context          The context of scop detection.\n  ///\n  /// @return True if the BB contains only valid control flow.\n  bool isValidCFG(BasicBlock &BB, bool IsLoopBranch, bool AllowUnreachable,\n                  DetectionContext &Context) const;\n\n  /// Is a loop valid with respect to a given region.\n  ///\n  /// @param L The loop to check.\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if the loop is valid in the region.\n  bool isValidLoop(Loop *L, DetectionContext &Context) const;\n\n  /// Count the number of loops and the maximal loop depth in @p L.\n  ///\n  /// @param L The loop to check.\n  /// @param SE The scalar evolution analysis.\n  /// @param MinProfitableTrips The minimum number of trip counts from which\n  ///                           a loop is assumed to be profitable and\n  ///                           consequently is counted.\n  /// returns A tuple of number of loops and their maximal depth.\n  static ScopDetection::LoopStats\n  countBeneficialSubLoops(Loop *L, ScalarEvolution &SE,\n                          unsigned MinProfitableTrips);\n\n  /// Check if the function @p F is marked as invalid.\n  ///\n  /// @note An OpenMP subfunction will be marked as invalid.\n  bool isValidFunction(Function &F);\n\n  /// Can ISL compute the trip count of a loop.\n  ///\n  /// @param L The loop to check.\n  /// @param Context The context of scop detection.\n  ///\n  /// @return True if ISL can compute the trip count of the loop.\n  bool canUseISLTripCount(Loop *L, DetectionContext &Context) const;\n\n  /// Print the locations of all detected scops.\n  void printLocations(Function &F);\n\n  /// Check if a region is reducible or not.\n  ///\n  /// @param Region The region to check.\n  /// @param DbgLoc Parameter to save the location of instruction that\n  ///               causes irregular control flow if the region is irreducible.\n  ///\n  /// @return True if R is reducible, false otherwise.\n  bool isReducibleRegion(Region &R, DebugLoc &DbgLoc) const;\n\n  /// Track diagnostics for invalid scops.\n  ///\n  /// @param Context The context of scop detection.\n  /// @param Assert Throw an assert in verify mode or not.\n  /// @param Args Argument list that gets passed to the constructor of RR.\n  template <class RR, typename... Args>\n  inline bool invalid(DetectionContext &Context, bool Assert,\n                      Args &&...Arguments) const;\n\npublic:\n  ScopDetection(Function &F, const DominatorTree &DT, ScalarEvolution &SE,\n                LoopInfo &LI, RegionInfo &RI, AAResults &AA,\n                OptimizationRemarkEmitter &ORE);\n\n  /// Get the RegionInfo stored in this pass.\n  ///\n  /// This was added to give the DOT printer easy access to this information.\n  RegionInfo *getRI() const { return &RI; }\n\n  /// Get the LoopInfo stored in this pass.\n  LoopInfo *getLI() const { return &LI; }\n\n  /// Is the region is the maximum region of a Scop?\n  ///\n  /// @param R The Region to test if it is maximum.\n  /// @param Verify Rerun the scop detection to verify SCoP was not invalidated\n  ///               meanwhile. Do not use if the region's DetectionContect is\n  ///               referenced by a Scop that is still to be processed.\n  ///\n  /// @return Return true if R is the maximum Region in a Scop, false otherwise.\n  bool isMaxRegionInScop(const Region &R, bool Verify = true) const;\n\n  /// Return the detection context for @p R, nullptr if @p R was invalid.\n  DetectionContext *getDetectionContext(const Region *R) const;\n\n  /// Return the set of rejection causes for @p R.\n  const RejectLog *lookupRejectionLog(const Region *R) const;\n\n  /// Return true if @p SubR is a non-affine subregion in @p ScopR.\n  bool isNonAffineSubRegion(const Region *SubR, const Region *ScopR) const;\n\n  /// Get a message why a region is invalid\n  ///\n  /// @param R The region for which we get the error message\n  ///\n  /// @return The error or \"\" if no error appeared.\n  std::string regionIsInvalidBecause(const Region *R) const;\n\n  /// @name Maximum Region In Scops Iterators\n  ///\n  /// These iterators iterator over all maximum region in Scops of this\n  /// function.\n  //@{\n  using iterator = RegionSet::iterator;\n  using const_iterator = RegionSet::const_iterator;\n\n  iterator begin() { return ValidRegions.begin(); }\n  iterator end() { return ValidRegions.end(); }\n\n  const_iterator begin() const { return ValidRegions.begin(); }\n  const_iterator end() const { return ValidRegions.end(); }\n  //@}\n\n  /// Emit rejection remarks for all rejected regions.\n  ///\n  /// @param F The function to emit remarks for.\n  void emitMissedRemarks(const Function &F);\n\n  /// Mark the function as invalid so we will not extract any scop from\n  ///        the function.\n  ///\n  /// @param F The function to mark as invalid.\n  static void markFunctionAsInvalid(Function *F);\n\n  /// Verify if all valid Regions in this Function are still valid\n  /// after some transformations.\n  void verifyAnalysis() const;\n\n  /// Verify if R is still a valid part of Scop after some transformations.\n  ///\n  /// @param R The Region to verify.\n  void verifyRegion(const Region &R) const;\n\n  /// Count the number of loops and the maximal loop depth in @p R.\n  ///\n  /// @param R The region to check\n  /// @param SE The scalar evolution analysis.\n  /// @param MinProfitableTrips The minimum number of trip counts from which\n  ///                           a loop is assumed to be profitable and\n  ///                           consequently is counted.\n  /// returns A tuple of number of loops and their maximal depth.\n  static ScopDetection::LoopStats\n  countBeneficialLoops(Region *R, ScalarEvolution &SE, LoopInfo &LI,\n                       unsigned MinProfitableTrips);\n\nprivate:\n  /// OptimizationRemarkEmitter object used to emit diagnostic remarks\n  OptimizationRemarkEmitter &ORE;\n};\n\nstruct ScopAnalysis : public AnalysisInfoMixin<ScopAnalysis> {\n  static AnalysisKey Key;\n\n  using Result = ScopDetection;\n\n  ScopAnalysis();\n\n  Result run(Function &F, FunctionAnalysisManager &FAM);\n};\n\nstruct ScopAnalysisPrinterPass : public PassInfoMixin<ScopAnalysisPrinterPass> {\n  ScopAnalysisPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n\n  raw_ostream &OS;\n};\n\nstruct ScopDetectionWrapperPass : public FunctionPass {\n  static char ID;\n  std::unique_ptr<ScopDetection> Result;\n\n  ScopDetectionWrapperPass();\n\n  /// @name FunctionPass interface\n  //@{\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  void releaseMemory() override;\n  bool runOnFunction(Function &F) override;\n  void print(raw_ostream &OS, const Module *) const override;\n  //@}\n\n  ScopDetection &getSD() { return *Result; }\n  const ScopDetection &getSD() const { return *Result; }\n};\n} // namespace polly\n\n#endif // POLLY_SCOPDETECTION_H\n"}, "83": {"id": 83, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "content": "//===- ScopDetectionDiagnostic.h - Diagnostic for ScopDetection -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Small set of diagnostic helper classes to encapsulate any errors occurred\n// during the detection of Scops.\n//\n// The ScopDetection defines a set of error classes (via Statistic variables)\n// that groups a number of individual errors into a group, e.g. non-affinity\n// related errors.\n// On error we generate an object that carries enough additional information\n// to diagnose the error and generate a helpful error message.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_SCOPDETECTIONDIAGNOSTIC_H\n#define POLLY_SCOPDETECTIONDIAGNOSTIC_H\n\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/DebugLoc.h\"\n#include \"llvm/IR/Instruction.h\"\n#include <cstddef>\n\nnamespace llvm {\nclass AliasSet;\nclass BasicBlock;\nclass OptimizationRemarkEmitter;\nclass Region;\nclass SCEV;\n} // namespace llvm\n\nnamespace polly {\nusing llvm::AliasSet;\nusing llvm::BasicBlock;\nusing llvm::DebugLoc;\nusing llvm::Instruction;\nusing llvm::Loop;\nusing llvm::OptimizationRemarkEmitter;\nusing llvm::raw_ostream;\nusing llvm::Region;\nusing llvm::SCEV;\nusing llvm::SmallVector;\nusing llvm::Value;\n\n/// Type to hold region delimiters (entry & exit block).\nusing BBPair = std::pair<BasicBlock *, BasicBlock *>;\n\n/// Return the region delimiters (entry & exit block) of @p R.\nBBPair getBBPairForRegion(const Region *R);\n\n/// Set the begin and end source location for the region limited by @p P.\nvoid getDebugLocations(const BBPair &P, DebugLoc &Begin, DebugLoc &End);\n\nclass RejectLog;\n\n/// Emit optimization remarks about the rejected regions to the user.\n///\n/// This emits the content of the reject log as optimization remarks.\n/// Remember to at least track failures (-polly-detect-track-failures).\n/// @param P The region delimiters (entry & exit) we emit remarks for.\n/// @param Log The error log containing all messages being emitted as remark.\nvoid emitRejectionRemarks(const BBPair &P, const RejectLog &Log,\n                          OptimizationRemarkEmitter &ORE);\n\n// Discriminator for LLVM-style RTTI (dyn_cast<> et al.)\nenum class RejectReasonKind {\n  // CFG Category\n  CFG,\n  InvalidTerminator,\n  IrreducibleRegion,\n  UnreachableInExit,\n  LastCFG,\n\n  // Non-Affinity\n  AffFunc,\n  UndefCond,\n  InvalidCond,\n  UndefOperand,\n  NonAffBranch,\n  NoBasePtr,\n  UndefBasePtr,\n  VariantBasePtr,\n  NonAffineAccess,\n  DifferentElementSize,\n  LastAffFunc,\n\n  LoopBound,\n  LoopHasNoExit,\n  LoopHasMultipleExits,\n  LoopOnlySomeLatches,\n\n  FuncCall,\n  NonSimpleMemoryAccess,\n\n  Alias,\n\n  // Other\n  Other,\n  IntToPtr,\n  Alloca,\n  UnknownInst,\n  Entry,\n  Unprofitable,\n  LastOther\n};\n\n//===----------------------------------------------------------------------===//\n/// Base class of all reject reasons found during Scop detection.\n///\n/// Subclasses of RejectReason should provide means to capture enough\n/// diagnostic information to help clients figure out what and where something\n/// went wrong in the Scop detection.\nclass RejectReason {\nprivate:\n  const RejectReasonKind Kind;\n\nprotected:\n  static const DebugLoc Unknown;\n\npublic:\n  RejectReason(RejectReasonKind K);\n\n  virtual ~RejectReason() = default;\n\n  RejectReasonKind getKind() const { return Kind; }\n\n  /// Generate the remark name to identify this remark.\n  ///\n  /// @return A short string that identifies the error.\n  virtual std::string getRemarkName() const = 0;\n\n  /// Get the Basic Block containing this remark.\n  ///\n  /// @return The Basic Block containing this remark.\n  virtual const Value *getRemarkBB() const = 0;\n\n  /// Generate a reasonable diagnostic message describing this error.\n  ///\n  /// @return A debug message representing this error.\n  virtual std::string getMessage() const = 0;\n\n  /// Generate a message for the end-user describing this error.\n  ///\n  /// The message provided has to be suitable for the end-user. So it should\n  /// not reference any LLVM internal data structures or terminology.\n  /// Ideally, the message helps the end-user to increase the size of the\n  /// regions amenable to Polly.\n  ///\n  /// @return A short message representing this error.\n  virtual std::string getEndUserMessage() const { return \"Unspecified error.\"; }\n\n  /// Get the source location of this error.\n  ///\n  /// @return The debug location for this error.\n  virtual const DebugLoc &getDebugLoc() const;\n};\n\nusing RejectReasonPtr = std::shared_ptr<RejectReason>;\n\n/// Stores all errors that occurred during the detection.\nclass RejectLog {\n  Region *R;\n  SmallVector<RejectReasonPtr, 1> ErrorReports;\n\npublic:\n  explicit RejectLog(Region *R) : R(R) {}\n\n  using iterator = SmallVector<RejectReasonPtr, 1>::const_iterator;\n\n  iterator begin() const { return ErrorReports.begin(); }\n  iterator end() const { return ErrorReports.end(); }\n  size_t size() const { return ErrorReports.size(); }\n\n  /// Returns true, if we store at least one error.\n  ///\n  /// @return true, if we store at least one error.\n  bool hasErrors() const { return size() > 0; }\n\n  void print(raw_ostream &OS, int level = 0) const;\n\n  const Region *region() const { return R; }\n  void report(RejectReasonPtr Reject) { ErrorReports.push_back(Reject); }\n};\n\n//===----------------------------------------------------------------------===//\n/// Base class for CFG related reject reasons.\n///\n/// Scop candidates that violate structural restrictions can be grouped under\n/// this reject reason class.\nclass ReportCFG : public RejectReason {\npublic:\n  ReportCFG(const RejectReasonKind K);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures bad terminator within a Scop candidate.\nclass ReportInvalidTerminator : public ReportCFG {\n  BasicBlock *BB;\n\npublic:\n  ReportInvalidTerminator(BasicBlock *BB)\n      : ReportCFG(RejectReasonKind::InvalidTerminator), BB(BB) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures irreducible regions in CFG.\nclass ReportIrreducibleRegion : public ReportCFG {\n  Region *R;\n  DebugLoc DbgLoc;\n\npublic:\n  ReportIrreducibleRegion(Region *R, DebugLoc DbgLoc)\n      : ReportCFG(RejectReasonKind::IrreducibleRegion), R(R), DbgLoc(DbgLoc) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures regions with an unreachable in the exit block.\nclass ReportUnreachableInExit : public ReportCFG {\n  BasicBlock *BB;\n  DebugLoc DbgLoc;\n\npublic:\n  ReportUnreachableInExit(BasicBlock *BB, DebugLoc DbgLoc)\n      : ReportCFG(RejectReasonKind::UnreachableInExit), BB(BB), DbgLoc(DbgLoc) {\n  }\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Base class for non-affine reject reasons.\n///\n/// Scop candidates that violate restrictions to affinity are reported under\n/// this class.\nclass ReportAffFunc : public RejectReason {\nprotected:\n  // The instruction that caused non-affinity to occur.\n  const Instruction *Inst;\n\npublic:\n  ReportAffFunc(const RejectReasonKind K, const Instruction *Inst);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  const DebugLoc &getDebugLoc() const override { return Inst->getDebugLoc(); }\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures a condition that is based on an 'undef' value.\nclass ReportUndefCond : public ReportAffFunc {\n  // The BasicBlock we found the broken condition in.\n  BasicBlock *BB;\n\npublic:\n  ReportUndefCond(const Instruction *Inst, BasicBlock *BB)\n      : ReportAffFunc(RejectReasonKind::UndefCond, Inst), BB(BB) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures an invalid condition\n///\n/// Conditions have to be either constants or icmp instructions.\nclass ReportInvalidCond : public ReportAffFunc {\n  // The BasicBlock we found the broken condition in.\n  BasicBlock *BB;\n\npublic:\n  ReportInvalidCond(const Instruction *Inst, BasicBlock *BB)\n      : ReportAffFunc(RejectReasonKind::InvalidCond, Inst), BB(BB) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures an undefined operand.\nclass ReportUndefOperand : public ReportAffFunc {\n  // The BasicBlock we found the undefined operand in.\n  BasicBlock *BB;\n\npublic:\n  ReportUndefOperand(BasicBlock *BB, const Instruction *Inst)\n      : ReportAffFunc(RejectReasonKind::UndefOperand, Inst), BB(BB) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures a non-affine branch.\nclass ReportNonAffBranch : public ReportAffFunc {\n  // The BasicBlock we found the non-affine branch in.\n  BasicBlock *BB;\n\n  /// LHS & RHS of the failed condition.\n  //@{\n  const SCEV *LHS;\n  const SCEV *RHS;\n  //@}\n\npublic:\n  ReportNonAffBranch(BasicBlock *BB, const SCEV *LHS, const SCEV *RHS,\n                     const Instruction *Inst)\n      : ReportAffFunc(RejectReasonKind::NonAffBranch, Inst), BB(BB), LHS(LHS),\n        RHS(RHS) {}\n\n  const SCEV *lhs() { return LHS; }\n  const SCEV *rhs() { return RHS; }\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures a missing base pointer.\nclass ReportNoBasePtr : public ReportAffFunc {\npublic:\n  ReportNoBasePtr(const Instruction *Inst)\n      : ReportAffFunc(RejectReasonKind::NoBasePtr, Inst) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures an undefined base pointer.\nclass ReportUndefBasePtr : public ReportAffFunc {\npublic:\n  ReportUndefBasePtr(const Instruction *Inst)\n      : ReportAffFunc(RejectReasonKind::UndefBasePtr, Inst) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures a base pointer that is not invariant in the region.\nclass ReportVariantBasePtr : public ReportAffFunc {\n  // The variant base pointer.\n  Value *BaseValue;\n\npublic:\n  ReportVariantBasePtr(Value *BaseValue, const Instruction *Inst)\n      : ReportAffFunc(RejectReasonKind::VariantBasePtr, Inst),\n        BaseValue(BaseValue) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures a non-affine access function.\nclass ReportNonAffineAccess : public ReportAffFunc {\n  // The non-affine access function.\n  const SCEV *AccessFunction;\n\n  // The base pointer of the memory access.\n  const Value *BaseValue;\n\npublic:\n  ReportNonAffineAccess(const SCEV *AccessFunction, const Instruction *Inst,\n                        const Value *V)\n      : ReportAffFunc(RejectReasonKind::NonAffineAccess, Inst),\n        AccessFunction(AccessFunction), BaseValue(V) {}\n\n  const SCEV *get() { return AccessFunction; }\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Report array accesses with differing element size.\nclass ReportDifferentArrayElementSize : public ReportAffFunc {\n  // The base pointer of the memory access.\n  const Value *BaseValue;\n\npublic:\n  ReportDifferentArrayElementSize(const Instruction *Inst, const Value *V)\n      : ReportAffFunc(RejectReasonKind::DifferentElementSize, Inst),\n        BaseValue(V) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with non affine loop bounds.\nclass ReportLoopBound : public RejectReason {\n  // The offending loop.\n  Loop *L;\n\n  // The non-affine loop bound.\n  const SCEV *LoopCount;\n\n  // A copy of the offending loop's debug location.\n  const DebugLoc Loc;\n\npublic:\n  ReportLoopBound(Loop *L, const SCEV *LoopCount);\n\n  const SCEV *loopCount() { return LoopCount; }\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors when loop has no exit.\nclass ReportLoopHasNoExit : public RejectReason {\n  /// The loop that has no exit.\n  Loop *L;\n\n  const DebugLoc Loc;\n\npublic:\n  ReportLoopHasNoExit(Loop *L)\n      : RejectReason(RejectReasonKind::LoopHasNoExit), L(L),\n        Loc(L->getStartLoc()) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors when a loop has multiple exists.\nclass ReportLoopHasMultipleExits : public RejectReason {\n  /// The loop that has multiple exits.\n  Loop *L;\n\n  const DebugLoc Loc;\n\npublic:\n  ReportLoopHasMultipleExits(Loop *L)\n      : RejectReason(RejectReasonKind::LoopHasMultipleExits), L(L),\n        Loc(L->getStartLoc()) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors when not all loop latches are part of the scop.\nclass ReportLoopOnlySomeLatches : public RejectReason {\n  /// The loop for which not all loop latches are part of the scop.\n  Loop *L;\n\n  const DebugLoc Loc;\n\npublic:\n  ReportLoopOnlySomeLatches(Loop *L)\n      : RejectReason(RejectReasonKind::LoopOnlySomeLatches), L(L),\n        Loc(L->getStartLoc()) {}\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with non-side-effect-known function calls.\nclass ReportFuncCall : public RejectReason {\n  // The offending call instruction.\n  Instruction *Inst;\n\npublic:\n  ReportFuncCall(Instruction *Inst);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with aliasing.\nclass ReportAlias : public RejectReason {\npublic:\n  using PointerSnapshotTy = std::vector<const Value *>;\n\nprivate:\n  /// Format an invalid alias set.\n  ///\n  //  @param Prefix A prefix string to put before the list of aliasing pointers.\n  //  @param Suffix A suffix string to put after the list of aliasing pointers.\n  std::string formatInvalidAlias(std::string Prefix = \"\",\n                                 std::string Suffix = \"\") const;\n\n  Instruction *Inst;\n\n  // A snapshot of the llvm values that took part in the aliasing error.\n  mutable PointerSnapshotTy Pointers;\n\npublic:\n  ReportAlias(Instruction *Inst, AliasSet &AS);\n\n  const PointerSnapshotTy &getPointers() const { return Pointers; }\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Base class for otherwise ungrouped reject reasons.\nclass ReportOther : public RejectReason {\npublic:\n  ReportOther(const RejectReasonKind K);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  std::string getMessage() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with bad IntToPtr instructions.\nclass ReportIntToPtr : public ReportOther {\n  // The offending base value.\n  Instruction *BaseValue;\n\npublic:\n  ReportIntToPtr(Instruction *BaseValue);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with alloca instructions.\nclass ReportAlloca : public ReportOther {\n  Instruction *Inst;\n\npublic:\n  ReportAlloca(Instruction *Inst);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with unknown instructions.\nclass ReportUnknownInst : public ReportOther {\n  Instruction *Inst;\n\npublic:\n  ReportUnknownInst(Instruction *Inst);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with regions containing the function entry block.\nclass ReportEntry : public ReportOther {\n  BasicBlock *BB;\n\npublic:\n  ReportEntry(BasicBlock *BB);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Report regions that seem not profitable to be optimized.\nclass ReportUnprofitable : public ReportOther {\n  Region *R;\n\npublic:\n  ReportUnprofitable(Region *R);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  std::string getEndUserMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  //@}\n};\n\n//===----------------------------------------------------------------------===//\n/// Captures errors with non-simple memory accesses.\nclass ReportNonSimpleMemoryAccess : public ReportOther {\n  // The offending call instruction.\n  Instruction *Inst;\n\npublic:\n  ReportNonSimpleMemoryAccess(Instruction *Inst);\n\n  /// @name LLVM-RTTI interface\n  //@{\n  static bool classof(const RejectReason *RR);\n  //@}\n\n  /// @name RejectReason interface\n  //@{\n  std::string getRemarkName() const override;\n  const Value *getRemarkBB() const override;\n  std::string getMessage() const override;\n  const DebugLoc &getDebugLoc() const override;\n  std::string getEndUserMessage() const override;\n  //@}\n};\n} // namespace polly\n\n#endif // POLLY_SCOPDETECTIONDIAGNOSTIC_H\n"}, "84": {"id": 84, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopInfo.h", "content": "//===- polly/ScopInfo.h -----------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Store the polyhedral model representation of a static control flow region,\n// also called SCoP (Static Control Part).\n//\n// This representation is shared among several tools in the polyhedral\n// community, which are e.g. CLooG, Pluto, Loopo, Graphite.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_SCOPINFO_H\n#define POLLY_SCOPINFO_H\n\n#include \"polly/ScopDetection.h\"\n#include \"polly/Support/SCEVAffinator.h\"\n#include \"polly/Support/ScopHelper.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/Analysis/RegionPass.h\"\n#include \"llvm/IR/DebugLoc.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n#include \"isl/isl-noexceptions.h\"\n#include <cassert>\n#include <cstddef>\n#include <forward_list>\n\nnamespace llvm {\nvoid initializeScopInfoRegionPassPass(PassRegistry &);\nvoid initializeScopInfoWrapperPassPass(PassRegistry &);\n} // end namespace llvm\n\nnamespace polly {\nusing llvm::AnalysisInfoMixin;\nusing llvm::ArrayRef;\nusing llvm::AssertingVH;\nusing llvm::AssumptionCache;\nusing llvm::cast;\nusing llvm::DataLayout;\nusing llvm::DenseMap;\nusing llvm::DenseSet;\nusing llvm::function_ref;\nusing llvm::isa;\nusing llvm::iterator_range;\nusing llvm::LoadInst;\nusing llvm::make_range;\nusing llvm::MapVector;\nusing llvm::MemIntrinsic;\nusing llvm::Optional;\nusing llvm::PassInfoMixin;\nusing llvm::PHINode;\nusing llvm::RegionNode;\nusing llvm::RegionPass;\nusing llvm::RGPassManager;\nusing llvm::SetVector;\nusing llvm::SmallPtrSetImpl;\nusing llvm::SmallVector;\nusing llvm::SmallVectorImpl;\nusing llvm::StringMap;\nusing llvm::Type;\nusing llvm::Use;\nusing llvm::Value;\nusing llvm::ValueToValueMap;\n\nclass MemoryAccess;\n\n//===---------------------------------------------------------------------===//\n\nextern bool UseInstructionNames;\n\n// The maximal number of basic sets we allow during domain construction to\n// be created. More complex scops will result in very high compile time and\n// are also unlikely to result in good code.\nextern int const MaxDisjunctsInDomain;\n\n/// The different memory kinds used in Polly.\n///\n/// We distinguish between arrays and various scalar memory objects. We use\n/// the term ``array'' to describe memory objects that consist of a set of\n/// individual data elements arranged in a multi-dimensional grid. A scalar\n/// memory object describes an individual data element and is used to model\n/// the definition and uses of llvm::Values.\n///\n/// The polyhedral model does traditionally not reason about SSA values. To\n/// reason about llvm::Values we model them \"as if\" they were zero-dimensional\n/// memory objects, even though they were not actually allocated in (main)\n/// memory.  Memory for such objects is only alloca[ed] at CodeGeneration\n/// time. To relate the memory slots used during code generation with the\n/// llvm::Values they belong to the new names for these corresponding stack\n/// slots are derived by appending suffixes (currently \".s2a\" and \".phiops\")\n/// to the name of the original llvm::Value. To describe how def/uses are\n/// modeled exactly we use these suffixes here as well.\n///\n/// There are currently four different kinds of memory objects:\nenum class MemoryKind {\n  /// MemoryKind::Array: Models a one or multi-dimensional array\n  ///\n  /// A memory object that can be described by a multi-dimensional array.\n  /// Memory objects of this type are used to model actual multi-dimensional\n  /// arrays as they exist in LLVM-IR, but they are also used to describe\n  /// other objects:\n  ///   - A single data element allocated on the stack using 'alloca' is\n  ///     modeled as a one-dimensional, single-element array.\n  ///   - A single data element allocated as a global variable is modeled as\n  ///     one-dimensional, single-element array.\n  ///   - Certain multi-dimensional arrays with variable size, which in\n  ///     LLVM-IR are commonly expressed as a single-dimensional access with a\n  ///     complicated access function, are modeled as multi-dimensional\n  ///     memory objects (grep for \"delinearization\").\n  Array,\n\n  /// MemoryKind::Value: Models an llvm::Value\n  ///\n  /// Memory objects of type MemoryKind::Value are used to model the data flow\n  /// induced by llvm::Values. For each llvm::Value that is used across\n  /// BasicBlocks, one ScopArrayInfo object is created. A single memory WRITE\n  /// stores the llvm::Value at its definition into the memory object and at\n  /// each use of the llvm::Value (ignoring trivial intra-block uses) a\n  /// corresponding READ is added. For instance, the use/def chain of a\n  /// llvm::Value %V depicted below\n  ///              ______________________\n  ///              |DefBB:              |\n  ///              |  %V = float op ... |\n  ///              ----------------------\n  ///               |                  |\n  /// _________________               _________________\n  /// |UseBB1:        |               |UseBB2:        |\n  /// |  use float %V |               |  use float %V |\n  /// -----------------               -----------------\n  ///\n  /// is modeled as if the following memory accesses occurred:\n  ///\n  ///                        __________________________\n  ///                        |entry:                  |\n  ///                        |  %V.s2a = alloca float |\n  ///                        --------------------------\n  ///                                     |\n  ///                    ___________________________________\n  ///                    |DefBB:                           |\n  ///                    |  store %float %V, float* %V.s2a |\n  ///                    -----------------------------------\n  ///                           |                   |\n  /// ____________________________________ ___________________________________\n  /// |UseBB1:                           | |UseBB2:                          |\n  /// |  %V.reload1 = load float* %V.s2a | |  %V.reload2 = load float* %V.s2a|\n  /// |  use float %V.reload1            | |  use float %V.reload2           |\n  /// ------------------------------------ -----------------------------------\n  ///\n  Value,\n\n  /// MemoryKind::PHI: Models PHI nodes within the SCoP\n  ///\n  /// Besides the MemoryKind::Value memory object used to model the normal\n  /// llvm::Value dependences described above, PHI nodes require an additional\n  /// memory object of type MemoryKind::PHI to describe the forwarding of values\n  /// to\n  /// the PHI node.\n  ///\n  /// As an example, a PHIInst instructions\n  ///\n  /// %PHI = phi float [ %Val1, %IncomingBlock1 ], [ %Val2, %IncomingBlock2 ]\n  ///\n  /// is modeled as if the accesses occurred this way:\n  ///\n  ///                    _______________________________\n  ///                    |entry:                       |\n  ///                    |  %PHI.phiops = alloca float |\n  ///                    -------------------------------\n  ///                           |              |\n  /// __________________________________  __________________________________\n  /// |IncomingBlock1:                 |  |IncomingBlock2:                 |\n  /// |  ...                           |  |  ...                           |\n  /// |  store float %Val1 %PHI.phiops |  |  store float %Val2 %PHI.phiops |\n  /// |  br label % JoinBlock          |  |  br label %JoinBlock           |\n  /// ----------------------------------  ----------------------------------\n  ///                             \\            /\n  ///                              \\          /\n  ///               _________________________________________\n  ///               |JoinBlock:                             |\n  ///               |  %PHI = load float, float* PHI.phiops |\n  ///               -----------------------------------------\n  ///\n  /// Note that there can also be a scalar write access for %PHI if used in a\n  /// different BasicBlock, i.e. there can be a memory object %PHI.phiops as\n  /// well as a memory object %PHI.s2a.\n  PHI,\n\n  /// MemoryKind::ExitPHI: Models PHI nodes in the SCoP's exit block\n  ///\n  /// For PHI nodes in the Scop's exit block a special memory object kind is\n  /// used. The modeling used is identical to MemoryKind::PHI, with the\n  /// exception\n  /// that there are no READs from these memory objects. The PHINode's\n  /// llvm::Value is treated as a value escaping the SCoP. WRITE accesses\n  /// write directly to the escaping value's \".s2a\" alloca.\n  ExitPHI\n};\n\n/// Maps from a loop to the affine function expressing its backedge taken count.\n/// The backedge taken count already enough to express iteration domain as we\n/// only allow loops with canonical induction variable.\n/// A canonical induction variable is:\n/// an integer recurrence that starts at 0 and increments by one each time\n/// through the loop.\nusing LoopBoundMapType = std::map<const Loop *, const SCEV *>;\n\nusing AccFuncVector = std::vector<std::unique_ptr<MemoryAccess>>;\n\n/// A class to store information about arrays in the SCoP.\n///\n/// Objects are accessible via the ScoP, MemoryAccess or the id associated with\n/// the MemoryAccess access function.\n///\nclass ScopArrayInfo {\npublic:\n  /// Construct a ScopArrayInfo object.\n  ///\n  /// @param BasePtr        The array base pointer.\n  /// @param ElementType    The type of the elements stored in the array.\n  /// @param IslCtx         The isl context used to create the base pointer id.\n  /// @param DimensionSizes A vector containing the size of each dimension.\n  /// @param Kind           The kind of the array object.\n  /// @param DL             The data layout of the module.\n  /// @param S              The scop this array object belongs to.\n  /// @param BaseName       The optional name of this memory reference.\n  ScopArrayInfo(Value *BasePtr, Type *ElementType, isl::ctx IslCtx,\n                ArrayRef<const SCEV *> DimensionSizes, MemoryKind Kind,\n                const DataLayout &DL, Scop *S, const char *BaseName = nullptr);\n\n  /// Destructor to free the isl id of the base pointer.\n  ~ScopArrayInfo();\n\n  ///  Update the element type of the ScopArrayInfo object.\n  ///\n  ///  Memory accesses referencing this ScopArrayInfo object may use\n  ///  different element sizes. This function ensures the canonical element type\n  ///  stored is small enough to model accesses to the current element type as\n  ///  well as to @p NewElementType.\n  ///\n  ///  @param NewElementType An element type that is used to access this array.\n  void updateElementType(Type *NewElementType);\n\n  ///  Update the sizes of the ScopArrayInfo object.\n  ///\n  ///  A ScopArrayInfo object may be created without all outer dimensions being\n  ///  available. This function is called when new memory accesses are added for\n  ///  this ScopArrayInfo object. It verifies that sizes are compatible and adds\n  ///  additional outer array dimensions, if needed.\n  ///\n  ///  @param Sizes       A vector of array sizes where the rightmost array\n  ///                     sizes need to match the innermost array sizes already\n  ///                     defined in SAI.\n  ///  @param CheckConsistency Update sizes, even if new sizes are inconsistent\n  ///                          with old sizes\n  bool updateSizes(ArrayRef<const SCEV *> Sizes, bool CheckConsistency = true);\n\n  /// Make the ScopArrayInfo model a Fortran array.\n  /// It receives the Fortran array descriptor and stores this.\n  /// It also adds a piecewise expression for the outermost dimension\n  /// since this information is available for Fortran arrays at runtime.\n  void applyAndSetFAD(Value *FAD);\n\n  /// Get the FortranArrayDescriptor corresponding to this array if it exists,\n  /// nullptr otherwise.\n  Value *getFortranArrayDescriptor() const { return this->FAD; }\n\n  /// Set the base pointer to @p BP.\n  void setBasePtr(Value *BP) { BasePtr = BP; }\n\n  /// Return the base pointer.\n  Value *getBasePtr() const { return BasePtr; }\n\n  // Set IsOnHeap to the value in parameter.\n  void setIsOnHeap(bool value) { IsOnHeap = value; }\n\n  /// For indirect accesses return the origin SAI of the BP, else null.\n  const ScopArrayInfo *getBasePtrOriginSAI() const { return BasePtrOriginSAI; }\n\n  /// The set of derived indirect SAIs for this origin SAI.\n  const SmallSetVector<ScopArrayInfo *, 2> &getDerivedSAIs() const {\n    return DerivedSAIs;\n  }\n\n  /// Return the number of dimensions.\n  unsigned getNumberOfDimensions() const {\n    if (Kind == MemoryKind::PHI || Kind == MemoryKind::ExitPHI ||\n        Kind == MemoryKind::Value)\n      return 0;\n    return DimensionSizes.size();\n  }\n\n  /// Return the size of dimension @p dim as SCEV*.\n  //\n  //  Scalars do not have array dimensions and the first dimension of\n  //  a (possibly multi-dimensional) array also does not carry any size\n  //  information, in case the array is not newly created.\n  const SCEV *getDimensionSize(unsigned Dim) const {\n    assert(Dim < getNumberOfDimensions() && \"Invalid dimension\");\n    return DimensionSizes[Dim];\n  }\n\n  /// Return the size of dimension @p dim as isl::pw_aff.\n  //\n  //  Scalars do not have array dimensions and the first dimension of\n  //  a (possibly multi-dimensional) array also does not carry any size\n  //  information, in case the array is not newly created.\n  isl::pw_aff getDimensionSizePw(unsigned Dim) const {\n    assert(Dim < getNumberOfDimensions() && \"Invalid dimension\");\n    return DimensionSizesPw[Dim];\n  }\n\n  /// Get the canonical element type of this array.\n  ///\n  /// @returns The canonical element type of this array.\n  Type *getElementType() const { return ElementType; }\n\n  /// Get element size in bytes.\n  int getElemSizeInBytes() const;\n\n  /// Get the name of this memory reference.\n  std::string getName() const;\n\n  /// Return the isl id for the base pointer.\n  isl::id getBasePtrId() const;\n\n  /// Return what kind of memory this represents.\n  MemoryKind getKind() const { return Kind; }\n\n  /// Is this array info modeling an llvm::Value?\n  bool isValueKind() const { return Kind == MemoryKind::Value; }\n\n  /// Is this array info modeling special PHI node memory?\n  ///\n  /// During code generation of PHI nodes, there is a need for two kinds of\n  /// virtual storage. The normal one as it is used for all scalar dependences,\n  /// where the result of the PHI node is stored and later loaded from as well\n  /// as a second one where the incoming values of the PHI nodes are stored\n  /// into and reloaded when the PHI is executed. As both memories use the\n  /// original PHI node as virtual base pointer, we have this additional\n  /// attribute to distinguish the PHI node specific array modeling from the\n  /// normal scalar array modeling.\n  bool isPHIKind() const { return Kind == MemoryKind::PHI; }\n\n  /// Is this array info modeling an MemoryKind::ExitPHI?\n  bool isExitPHIKind() const { return Kind == MemoryKind::ExitPHI; }\n\n  /// Is this array info modeling an array?\n  bool isArrayKind() const { return Kind == MemoryKind::Array; }\n\n  /// Is this array allocated on heap\n  ///\n  /// This property is only relevant if the array is allocated by Polly instead\n  /// of pre-existing. If false, it is allocated using alloca instead malloca.\n  bool isOnHeap() const { return IsOnHeap; }\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Dump a readable representation to stderr.\n  void dump() const;\n#endif\n\n  /// Print a readable representation to @p OS.\n  ///\n  /// @param SizeAsPwAff Print the size as isl::pw_aff\n  void print(raw_ostream &OS, bool SizeAsPwAff = false) const;\n\n  /// Access the ScopArrayInfo associated with an access function.\n  static const ScopArrayInfo *getFromAccessFunction(isl::pw_multi_aff PMA);\n\n  /// Access the ScopArrayInfo associated with an isl Id.\n  static const ScopArrayInfo *getFromId(isl::id Id);\n\n  /// Get the space of this array access.\n  isl::space getSpace() const;\n\n  /// If the array is read only\n  bool isReadOnly();\n\n  /// Verify that @p Array is compatible to this ScopArrayInfo.\n  ///\n  /// Two arrays are compatible if their dimensionality, the sizes of their\n  /// dimensions, and their element sizes match.\n  ///\n  /// @param Array The array to compare against.\n  ///\n  /// @returns True, if the arrays are compatible, False otherwise.\n  bool isCompatibleWith(const ScopArrayInfo *Array) const;\n\nprivate:\n  void addDerivedSAI(ScopArrayInfo *DerivedSAI) {\n    DerivedSAIs.insert(DerivedSAI);\n  }\n\n  /// For indirect accesses this is the SAI of the BP origin.\n  const ScopArrayInfo *BasePtrOriginSAI;\n\n  /// For origin SAIs the set of derived indirect SAIs.\n  SmallSetVector<ScopArrayInfo *, 2> DerivedSAIs;\n\n  /// The base pointer.\n  AssertingVH<Value> BasePtr;\n\n  /// The canonical element type of this array.\n  ///\n  /// The canonical element type describes the minimal accessible element in\n  /// this array. Not all elements accessed, need to be of the very same type,\n  /// but the allocation size of the type of the elements loaded/stored from/to\n  /// this array needs to be a multiple of the allocation size of the canonical\n  /// type.\n  Type *ElementType;\n\n  /// The isl id for the base pointer.\n  isl::id Id;\n\n  /// True if the newly allocated array is on heap.\n  bool IsOnHeap = false;\n\n  /// The sizes of each dimension as SCEV*.\n  SmallVector<const SCEV *, 4> DimensionSizes;\n\n  /// The sizes of each dimension as isl::pw_aff.\n  SmallVector<isl::pw_aff, 4> DimensionSizesPw;\n\n  /// The type of this scop array info object.\n  ///\n  /// We distinguish between SCALAR, PHI and ARRAY objects.\n  MemoryKind Kind;\n\n  /// The data layout of the module.\n  const DataLayout &DL;\n\n  /// The scop this SAI object belongs to.\n  Scop &S;\n\n  /// If this array models a Fortran array, then this points\n  /// to the Fortran array descriptor.\n  Value *FAD = nullptr;\n};\n\n/// Represent memory accesses in statements.\nclass MemoryAccess {\n  friend class Scop;\n  friend class ScopStmt;\n  friend class ScopBuilder;\n\npublic:\n  /// The access type of a memory access\n  ///\n  /// There are three kind of access types:\n  ///\n  /// * A read access\n  ///\n  /// A certain set of memory locations are read and may be used for internal\n  /// calculations.\n  ///\n  /// * A must-write access\n  ///\n  /// A certain set of memory locations is definitely written. The old value is\n  /// replaced by a newly calculated value. The old value is not read or used at\n  /// all.\n  ///\n  /// * A may-write access\n  ///\n  /// A certain set of memory locations may be written. The memory location may\n  /// contain a new value if there is actually a write or the old value may\n  /// remain, if no write happens.\n  enum AccessType {\n    READ = 0x1,\n    MUST_WRITE = 0x2,\n    MAY_WRITE = 0x3,\n  };\n\n  /// Reduction access type\n  ///\n  /// Commutative and associative binary operations suitable for reductions\n  enum ReductionType {\n    RT_NONE, ///< Indicate no reduction at all\n    RT_ADD,  ///< Addition\n    RT_MUL,  ///< Multiplication\n    RT_BOR,  ///< Bitwise Or\n    RT_BXOR, ///< Bitwise XOr\n    RT_BAND, ///< Bitwise And\n  };\n\n  using SubscriptsTy = SmallVector<const SCEV *, 4>;\n\nprivate:\n  /// A unique identifier for this memory access.\n  ///\n  /// The identifier is unique between all memory accesses belonging to the same\n  /// scop statement.\n  isl::id Id;\n\n  /// What is modeled by this MemoryAccess.\n  /// @see MemoryKind\n  MemoryKind Kind;\n\n  /// Whether it a reading or writing access, and if writing, whether it\n  /// is conditional (MAY_WRITE).\n  enum AccessType AccType;\n\n  /// Reduction type for reduction like accesses, RT_NONE otherwise\n  ///\n  /// An access is reduction like if it is part of a load-store chain in which\n  /// both access the same memory location (use the same LLVM-IR value\n  /// as pointer reference). Furthermore, between the load and the store there\n  /// is exactly one binary operator which is known to be associative and\n  /// commutative.\n  ///\n  /// TODO:\n  ///\n  /// We can later lift the constraint that the same LLVM-IR value defines the\n  /// memory location to handle scops such as the following:\n  ///\n  ///    for i\n  ///      for j\n  ///        sum[i+j] = sum[i] + 3;\n  ///\n  /// Here not all iterations access the same memory location, but iterations\n  /// for which j = 0 holds do. After lifting the equality check in ScopBuilder,\n  /// subsequent transformations do not only need check if a statement is\n  /// reduction like, but they also need to verify that that the reduction\n  /// property is only exploited for statement instances that load from and\n  /// store to the same data location. Doing so at dependence analysis time\n  /// could allow us to handle the above example.\n  ReductionType RedType = RT_NONE;\n\n  /// Parent ScopStmt of this access.\n  ScopStmt *Statement;\n\n  /// The domain under which this access is not modeled precisely.\n  ///\n  /// The invalid domain for an access describes all parameter combinations\n  /// under which the statement looks to be executed but is in fact not because\n  /// some assumption/restriction makes the access invalid.\n  isl::set InvalidDomain;\n\n  // Properties describing the accessed array.\n  // TODO: It might be possible to move them to ScopArrayInfo.\n  // @{\n\n  /// The base address (e.g., A for A[i+j]).\n  ///\n  /// The #BaseAddr of a memory access of kind MemoryKind::Array is the base\n  /// pointer of the memory access.\n  /// The #BaseAddr of a memory access of kind MemoryKind::PHI or\n  /// MemoryKind::ExitPHI is the PHI node itself.\n  /// The #BaseAddr of a memory access of kind MemoryKind::Value is the\n  /// instruction defining the value.\n  AssertingVH<Value> BaseAddr;\n\n  /// Type a single array element wrt. this access.\n  Type *ElementType;\n\n  /// Size of each dimension of the accessed array.\n  SmallVector<const SCEV *, 4> Sizes;\n  // @}\n\n  // Properties describing the accessed element.\n  // @{\n\n  /// The access instruction of this memory access.\n  ///\n  /// For memory accesses of kind MemoryKind::Array the access instruction is\n  /// the Load or Store instruction performing the access.\n  ///\n  /// For memory accesses of kind MemoryKind::PHI or MemoryKind::ExitPHI the\n  /// access instruction of a load access is the PHI instruction. The access\n  /// instruction of a PHI-store is the incoming's block's terminator\n  /// instruction.\n  ///\n  /// For memory accesses of kind MemoryKind::Value the access instruction of a\n  /// load access is nullptr because generally there can be multiple\n  /// instructions in the statement using the same llvm::Value. The access\n  /// instruction of a write access is the instruction that defines the\n  /// llvm::Value.\n  Instruction *AccessInstruction = nullptr;\n\n  /// Incoming block and value of a PHINode.\n  SmallVector<std::pair<BasicBlock *, Value *>, 4> Incoming;\n\n  /// The value associated with this memory access.\n  ///\n  ///  - For array memory accesses (MemoryKind::Array) it is the loaded result\n  ///    or the stored value. If the access instruction is a memory intrinsic it\n  ///    the access value is also the memory intrinsic.\n  ///  - For accesses of kind MemoryKind::Value it is the access instruction\n  ///    itself.\n  ///  - For accesses of kind MemoryKind::PHI or MemoryKind::ExitPHI it is the\n  ///    PHI node itself (for both, READ and WRITE accesses).\n  ///\n  AssertingVH<Value> AccessValue;\n\n  /// Are all the subscripts affine expression?\n  bool IsAffine = true;\n\n  /// Subscript expression for each dimension.\n  SubscriptsTy Subscripts;\n\n  /// Relation from statement instances to the accessed array elements.\n  ///\n  /// In the common case this relation is a function that maps a set of loop\n  /// indices to the memory address from which a value is loaded/stored:\n  ///\n  ///      for i\n  ///        for j\n  ///    S:     A[i + 3 j] = ...\n  ///\n  ///    => { S[i,j] -> A[i + 3j] }\n  ///\n  /// In case the exact access function is not known, the access relation may\n  /// also be a one to all mapping { S[i,j] -> A[o] } describing that any\n  /// element accessible through A might be accessed.\n  ///\n  /// In case of an access to a larger element belonging to an array that also\n  /// contains smaller elements, the access relation models the larger access\n  /// with multiple smaller accesses of the size of the minimal array element\n  /// type:\n  ///\n  ///      short *A;\n  ///\n  ///      for i\n  ///    S:     A[i] = *((double*)&A[4 * i]);\n  ///\n  ///    => { S[i] -> A[i]; S[i] -> A[o] : 4i <= o <= 4i + 3 }\n  isl::map AccessRelation;\n\n  /// Updated access relation read from JSCOP file.\n  isl::map NewAccessRelation;\n\n  /// Fortran arrays whose sizes are not statically known are stored in terms\n  /// of a descriptor struct. This maintains a raw pointer to the memory,\n  /// along with auxiliary fields with information such as dimensions.\n  /// We hold a reference to the descriptor corresponding to a MemoryAccess\n  /// into a Fortran array. FAD for \"Fortran Array Descriptor\"\n  AssertingVH<Value> FAD;\n  // @}\n\n  isl::basic_map createBasicAccessMap(ScopStmt *Statement);\n\n  isl::set assumeNoOutOfBound();\n\n  /// Compute bounds on an over approximated  access relation.\n  ///\n  /// @param ElementSize The size of one element accessed.\n  void computeBoundsOnAccessRelation(unsigned ElementSize);\n\n  /// Get the original access function as read from IR.\n  isl::map getOriginalAccessRelation() const;\n\n  /// Return the space in which the access relation lives in.\n  isl::space getOriginalAccessRelationSpace() const;\n\n  /// Get the new access function imported or set by a pass\n  isl::map getNewAccessRelation() const;\n\n  /// Fold the memory access to consider parametric offsets\n  ///\n  /// To recover memory accesses with array size parameters in the subscript\n  /// expression we post-process the delinearization results.\n  ///\n  /// We would normally recover from an access A[exp0(i) * N + exp1(i)] into an\n  /// array A[][N] the 2D access A[exp0(i)][exp1(i)]. However, another valid\n  /// delinearization is A[exp0(i) - 1][exp1(i) + N] which - depending on the\n  /// range of exp1(i) - may be preferable. Specifically, for cases where we\n  /// know exp1(i) is negative, we want to choose the latter expression.\n  ///\n  /// As we commonly do not have any information about the range of exp1(i),\n  /// we do not choose one of the two options, but instead create a piecewise\n  /// access function that adds the (-1, N) offsets as soon as exp1(i) becomes\n  /// negative. For a 2D array such an access function is created by applying\n  /// the piecewise map:\n  ///\n  /// [i,j] -> [i, j] :      j >= 0\n  /// [i,j] -> [i-1, j+N] :  j <  0\n  ///\n  /// We can generalize this mapping to arbitrary dimensions by applying this\n  /// piecewise mapping pairwise from the rightmost to the leftmost access\n  /// dimension. It would also be possible to cover a wider range by introducing\n  /// more cases and adding multiple of Ns to these cases. However, this has\n  /// not yet been necessary.\n  /// The introduction of different cases necessarily complicates the memory\n  /// access function, but cases that can be statically proven to not happen\n  /// will be eliminated later on.\n  void foldAccessRelation();\n\n  /// Create the access relation for the underlying memory intrinsic.\n  void buildMemIntrinsicAccessRelation();\n\n  /// Assemble the access relation from all available information.\n  ///\n  /// In particular, used the information passes in the constructor and the\n  /// parent ScopStmt set by setStatment().\n  ///\n  /// @param SAI Info object for the accessed array.\n  void buildAccessRelation(const ScopArrayInfo *SAI);\n\n  /// Carry index overflows of dimensions with constant size to the next higher\n  /// dimension.\n  ///\n  /// For dimensions that have constant size, modulo the index by the size and\n  /// add up the carry (floored division) to the next higher dimension. This is\n  /// how overflow is defined in row-major order.\n  /// It happens e.g. when ScalarEvolution computes the offset to the base\n  /// pointer and would algebraically sum up all lower dimensions' indices of\n  /// constant size.\n  ///\n  /// Example:\n  ///   float (*A)[4];\n  ///   A[1][6] -> A[2][2]\n  void wrapConstantDimensions();\n\npublic:\n  /// Create a new MemoryAccess.\n  ///\n  /// @param Stmt       The parent statement.\n  /// @param AccessInst The instruction doing the access.\n  /// @param BaseAddr   The accessed array's address.\n  /// @param ElemType   The type of the accessed array elements.\n  /// @param AccType    Whether read or write access.\n  /// @param IsAffine   Whether the subscripts are affine expressions.\n  /// @param Kind       The kind of memory accessed.\n  /// @param Subscripts Subscript expressions\n  /// @param Sizes      Dimension lengths of the accessed array.\n  MemoryAccess(ScopStmt *Stmt, Instruction *AccessInst, AccessType AccType,\n               Value *BaseAddress, Type *ElemType, bool Affine,\n               ArrayRef<const SCEV *> Subscripts, ArrayRef<const SCEV *> Sizes,\n               Value *AccessValue, MemoryKind Kind);\n\n  /// Create a new MemoryAccess that corresponds to @p AccRel.\n  ///\n  /// Along with @p Stmt and @p AccType it uses information about dimension\n  /// lengths of the accessed array, the type of the accessed array elements,\n  /// the name of the accessed array that is derived from the object accessible\n  /// via @p AccRel.\n  ///\n  /// @param Stmt       The parent statement.\n  /// @param AccType    Whether read or write access.\n  /// @param AccRel     The access relation that describes the memory access.\n  MemoryAccess(ScopStmt *Stmt, AccessType AccType, isl::map AccRel);\n\n  MemoryAccess(const MemoryAccess &) = delete;\n  MemoryAccess &operator=(const MemoryAccess &) = delete;\n  ~MemoryAccess();\n\n  /// Add a new incoming block/value pairs for this PHI/ExitPHI access.\n  ///\n  /// @param IncomingBlock The PHI's incoming block.\n  /// @param IncomingValue The value when reaching the PHI from the @p\n  ///                      IncomingBlock.\n  void addIncoming(BasicBlock *IncomingBlock, Value *IncomingValue) {\n    assert(!isRead());\n    assert(isAnyPHIKind());\n    Incoming.emplace_back(std::make_pair(IncomingBlock, IncomingValue));\n  }\n\n  /// Return the list of possible PHI/ExitPHI values.\n  ///\n  /// After code generation moves some PHIs around during region simplification,\n  /// we cannot reliably locate the original PHI node and its incoming values\n  /// anymore. For this reason we remember these explicitly for all PHI-kind\n  /// accesses.\n  ArrayRef<std::pair<BasicBlock *, Value *>> getIncoming() const {\n    assert(isAnyPHIKind());\n    return Incoming;\n  }\n\n  /// Get the type of a memory access.\n  enum AccessType getType() { return AccType; }\n\n  /// Is this a reduction like access?\n  bool isReductionLike() const { return RedType != RT_NONE; }\n\n  /// Is this a read memory access?\n  bool isRead() const { return AccType == MemoryAccess::READ; }\n\n  /// Is this a must-write memory access?\n  bool isMustWrite() const { return AccType == MemoryAccess::MUST_WRITE; }\n\n  /// Is this a may-write memory access?\n  bool isMayWrite() const { return AccType == MemoryAccess::MAY_WRITE; }\n\n  /// Is this a write memory access?\n  bool isWrite() const { return isMustWrite() || isMayWrite(); }\n\n  /// Is this a memory intrinsic access (memcpy, memset, memmove)?\n  bool isMemoryIntrinsic() const {\n    return isa<MemIntrinsic>(getAccessInstruction());\n  }\n\n  /// Check if a new access relation was imported or set by a pass.\n  bool hasNewAccessRelation() const { return !NewAccessRelation.is_null(); }\n\n  /// Return the newest access relation of this access.\n  ///\n  /// There are two possibilities:\n  ///   1) The original access relation read from the LLVM-IR.\n  ///   2) A new access relation imported from a json file or set by another\n  ///      pass (e.g., for privatization).\n  ///\n  /// As 2) is by construction \"newer\" than 1) we return the new access\n  /// relation if present.\n  ///\n  isl::map getLatestAccessRelation() const {\n    return hasNewAccessRelation() ? getNewAccessRelation()\n                                  : getOriginalAccessRelation();\n  }\n\n  /// Old name of getLatestAccessRelation().\n  isl::map getAccessRelation() const { return getLatestAccessRelation(); }\n\n  /// Get an isl map describing the memory address accessed.\n  ///\n  /// In most cases the memory address accessed is well described by the access\n  /// relation obtained with getAccessRelation. However, in case of arrays\n  /// accessed with types of different size the access relation maps one access\n  /// to multiple smaller address locations. This method returns an isl map that\n  /// relates each dynamic statement instance to the unique memory location\n  /// that is loaded from / stored to.\n  ///\n  /// For an access relation { S[i] -> A[o] : 4i <= o <= 4i + 3 } this method\n  /// will return the address function { S[i] -> A[4i] }.\n  ///\n  /// @returns The address function for this memory access.\n  isl::map getAddressFunction() const;\n\n  /// Return the access relation after the schedule was applied.\n  isl::pw_multi_aff\n  applyScheduleToAccessRelation(isl::union_map Schedule) const;\n\n  /// Get an isl string representing the access function read from IR.\n  std::string getOriginalAccessRelationStr() const;\n\n  /// Get an isl string representing a new access function, if available.\n  std::string getNewAccessRelationStr() const;\n\n  /// Get an isl string representing the latest access relation.\n  std::string getAccessRelationStr() const;\n\n  /// Get the original base address of this access (e.g. A for A[i+j]) when\n  /// detected.\n  ///\n  /// This address may differ from the base address referenced by the original\n  /// ScopArrayInfo to which this array belongs, as this memory access may\n  /// have been canonicalized to a ScopArrayInfo which has a different but\n  /// identically-valued base pointer in case invariant load hoisting is\n  /// enabled.\n  Value *getOriginalBaseAddr() const { return BaseAddr; }\n\n  /// Get the detection-time base array isl::id for this access.\n  isl::id getOriginalArrayId() const;\n\n  /// Get the base array isl::id for this access, modifiable through\n  /// setNewAccessRelation().\n  isl::id getLatestArrayId() const;\n\n  /// Old name of getOriginalArrayId().\n  isl::id getArrayId() const { return getOriginalArrayId(); }\n\n  /// Get the detection-time ScopArrayInfo object for the base address.\n  const ScopArrayInfo *getOriginalScopArrayInfo() const;\n\n  /// Get the ScopArrayInfo object for the base address, or the one set\n  /// by setNewAccessRelation().\n  const ScopArrayInfo *getLatestScopArrayInfo() const;\n\n  /// Legacy name of getOriginalScopArrayInfo().\n  const ScopArrayInfo *getScopArrayInfo() const {\n    return getOriginalScopArrayInfo();\n  }\n\n  /// Return a string representation of the access's reduction type.\n  const std::string getReductionOperatorStr() const;\n\n  /// Return a string representation of the reduction type @p RT.\n  static const std::string getReductionOperatorStr(ReductionType RT);\n\n  /// Return the element type of the accessed array wrt. this access.\n  Type *getElementType() const { return ElementType; }\n\n  /// Return the access value of this memory access.\n  Value *getAccessValue() const { return AccessValue; }\n\n  /// Return llvm::Value that is stored by this access, if available.\n  ///\n  /// PHI nodes may not have a unique value available that is stored, as in\n  /// case of region statements one out of possibly several llvm::Values\n  /// might be stored. In this case nullptr is returned.\n  Value *tryGetValueStored() {\n    assert(isWrite() && \"Only write statement store values\");\n    if (isAnyPHIKind()) {\n      if (Incoming.size() == 1)\n        return Incoming[0].second;\n      return nullptr;\n    }\n    return AccessValue;\n  }\n\n  /// Return the access instruction of this memory access.\n  Instruction *getAccessInstruction() const { return AccessInstruction; }\n\n  ///  Return an iterator range containing the subscripts.\n  iterator_range<SubscriptsTy::const_iterator> subscripts() const {\n    return make_range(Subscripts.begin(), Subscripts.end());\n  }\n\n  /// Return the number of access function subscript.\n  unsigned getNumSubscripts() const { return Subscripts.size(); }\n\n  /// Return the access function subscript in the dimension @p Dim.\n  const SCEV *getSubscript(unsigned Dim) const { return Subscripts[Dim]; }\n\n  /// Compute the isl representation for the SCEV @p E wrt. this access.\n  ///\n  /// Note that this function will also adjust the invalid context accordingly.\n  isl::pw_aff getPwAff(const SCEV *E);\n\n  /// Get the invalid domain for this access.\n  isl::set getInvalidDomain() const { return InvalidDomain; }\n\n  /// Get the invalid context for this access.\n  isl::set getInvalidContext() const { return getInvalidDomain().params(); }\n\n  /// Get the stride of this memory access in the specified Schedule. Schedule\n  /// is a map from the statement to a schedule where the innermost dimension is\n  /// the dimension of the innermost loop containing the statement.\n  isl::set getStride(isl::map Schedule) const;\n\n  /// Get the FortranArrayDescriptor corresponding to this memory access if\n  /// it exists, and nullptr otherwise.\n  Value *getFortranArrayDescriptor() const { return this->FAD; }\n\n  /// Is the stride of the access equal to a certain width? Schedule is a map\n  /// from the statement to a schedule where the innermost dimension is the\n  /// dimension of the innermost loop containing the statement.\n  bool isStrideX(isl::map Schedule, int StrideWidth) const;\n\n  /// Is consecutive memory accessed for a given statement instance set?\n  /// Schedule is a map from the statement to a schedule where the innermost\n  /// dimension is the dimension of the innermost loop containing the\n  /// statement.\n  bool isStrideOne(isl::map Schedule) const;\n\n  /// Is always the same memory accessed for a given statement instance set?\n  /// Schedule is a map from the statement to a schedule where the innermost\n  /// dimension is the dimension of the innermost loop containing the\n  /// statement.\n  bool isStrideZero(isl::map Schedule) const;\n\n  /// Return the kind when this access was first detected.\n  MemoryKind getOriginalKind() const {\n    assert(!getOriginalScopArrayInfo() /* not yet initialized */ ||\n           getOriginalScopArrayInfo()->getKind() == Kind);\n    return Kind;\n  }\n\n  /// Return the kind considering a potential setNewAccessRelation.\n  MemoryKind getLatestKind() const {\n    return getLatestScopArrayInfo()->getKind();\n  }\n\n  /// Whether this is an access of an explicit load or store in the IR.\n  bool isOriginalArrayKind() const {\n    return getOriginalKind() == MemoryKind::Array;\n  }\n\n  /// Whether storage memory is either an custom .s2a/.phiops alloca\n  /// (false) or an existing pointer into an array (true).\n  bool isLatestArrayKind() const {\n    return getLatestKind() == MemoryKind::Array;\n  }\n\n  /// Old name of isOriginalArrayKind.\n  bool isArrayKind() const { return isOriginalArrayKind(); }\n\n  /// Whether this access is an array to a scalar memory object, without\n  /// considering changes by setNewAccessRelation.\n  ///\n  /// Scalar accesses are accesses to MemoryKind::Value, MemoryKind::PHI or\n  /// MemoryKind::ExitPHI.\n  bool isOriginalScalarKind() const {\n    return getOriginalKind() != MemoryKind::Array;\n  }\n\n  /// Whether this access is an array to a scalar memory object, also\n  /// considering changes by setNewAccessRelation.\n  bool isLatestScalarKind() const {\n    return getLatestKind() != MemoryKind::Array;\n  }\n\n  /// Old name of isOriginalScalarKind.\n  bool isScalarKind() const { return isOriginalScalarKind(); }\n\n  /// Was this MemoryAccess detected as a scalar dependences?\n  bool isOriginalValueKind() const {\n    return getOriginalKind() == MemoryKind::Value;\n  }\n\n  /// Is this MemoryAccess currently modeling scalar dependences?\n  bool isLatestValueKind() const {\n    return getLatestKind() == MemoryKind::Value;\n  }\n\n  /// Old name of isOriginalValueKind().\n  bool isValueKind() const { return isOriginalValueKind(); }\n\n  /// Was this MemoryAccess detected as a special PHI node access?\n  bool isOriginalPHIKind() const {\n    return getOriginalKind() == MemoryKind::PHI;\n  }\n\n  /// Is this MemoryAccess modeling special PHI node accesses, also\n  /// considering a potential change by setNewAccessRelation?\n  bool isLatestPHIKind() const { return getLatestKind() == MemoryKind::PHI; }\n\n  /// Old name of isOriginalPHIKind.\n  bool isPHIKind() const { return isOriginalPHIKind(); }\n\n  /// Was this MemoryAccess detected as the accesses of a PHI node in the\n  /// SCoP's exit block?\n  bool isOriginalExitPHIKind() const {\n    return getOriginalKind() == MemoryKind::ExitPHI;\n  }\n\n  /// Is this MemoryAccess modeling the accesses of a PHI node in the\n  /// SCoP's exit block? Can be changed to an array access using\n  /// setNewAccessRelation().\n  bool isLatestExitPHIKind() const {\n    return getLatestKind() == MemoryKind::ExitPHI;\n  }\n\n  /// Old name of isOriginalExitPHIKind().\n  bool isExitPHIKind() const { return isOriginalExitPHIKind(); }\n\n  /// Was this access detected as one of the two PHI types?\n  bool isOriginalAnyPHIKind() const {\n    return isOriginalPHIKind() || isOriginalExitPHIKind();\n  }\n\n  /// Does this access originate from one of the two PHI types? Can be\n  /// changed to an array access using setNewAccessRelation().\n  bool isLatestAnyPHIKind() const {\n    return isLatestPHIKind() || isLatestExitPHIKind();\n  }\n\n  /// Old name of isOriginalAnyPHIKind().\n  bool isAnyPHIKind() const { return isOriginalAnyPHIKind(); }\n\n  /// Get the statement that contains this memory access.\n  ScopStmt *getStatement() const { return Statement; }\n\n  /// Get the reduction type of this access\n  ReductionType getReductionType() const { return RedType; }\n\n  /// Set the array descriptor corresponding to the Array on which the\n  /// memory access is performed.\n  void setFortranArrayDescriptor(Value *FAD);\n\n  /// Update the original access relation.\n  ///\n  /// We need to update the original access relation during scop construction,\n  /// when unifying the memory accesses that access the same scop array info\n  /// object. After the scop has been constructed, the original access relation\n  /// should not be changed any more. Instead setNewAccessRelation should\n  /// be called.\n  void setAccessRelation(isl::map AccessRelation);\n\n  /// Set the updated access relation read from JSCOP file.\n  void setNewAccessRelation(isl::map NewAccessRelation);\n\n  /// Return whether the MemoryyAccess is a partial access. That is, the access\n  /// is not executed in some instances of the parent statement's domain.\n  bool isLatestPartialAccess() const;\n\n  /// Mark this a reduction like access\n  void markAsReductionLike(ReductionType RT) { RedType = RT; }\n\n  /// Align the parameters in the access relation to the scop context\n  void realignParams();\n\n  /// Update the dimensionality of the memory access.\n  ///\n  /// During scop construction some memory accesses may not be constructed with\n  /// their full dimensionality, but outer dimensions may have been omitted if\n  /// they took the value 'zero'. By updating the dimensionality of the\n  /// statement we add additional zero-valued dimensions to match the\n  /// dimensionality of the ScopArrayInfo object that belongs to this memory\n  /// access.\n  void updateDimensionality();\n\n  /// Get identifier for the memory access.\n  ///\n  /// This identifier is unique for all accesses that belong to the same scop\n  /// statement.\n  isl::id getId() const;\n\n  /// Print the MemoryAccess.\n  ///\n  /// @param OS The output stream the MemoryAccess is printed to.\n  void print(raw_ostream &OS) const;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print the MemoryAccess to stderr.\n  void dump() const;\n#endif\n\n  /// Is the memory access affine?\n  bool isAffine() const { return IsAffine; }\n};\n\nraw_ostream &operator<<(raw_ostream &OS, MemoryAccess::ReductionType RT);\n\n/// Ordered list type to hold accesses.\nusing MemoryAccessList = std::forward_list<MemoryAccess *>;\n\n/// Helper structure for invariant memory accesses.\nstruct InvariantAccess {\n  /// The memory access that is (partially) invariant.\n  MemoryAccess *MA;\n\n  /// The context under which the access is not invariant.\n  isl::set NonHoistableCtx;\n};\n\n/// Ordered container type to hold invariant accesses.\nusing InvariantAccessesTy = SmallVector<InvariantAccess, 8>;\n\n/// Type for equivalent invariant accesses and their domain context.\nstruct InvariantEquivClassTy {\n  /// The pointer that identifies this equivalence class\n  const SCEV *IdentifyingPointer;\n\n  /// Memory accesses now treated invariant\n  ///\n  /// These memory accesses access the pointer location that identifies\n  /// this equivalence class. They are treated as invariant and hoisted during\n  /// code generation.\n  MemoryAccessList InvariantAccesses;\n\n  /// The execution context under which the memory location is accessed\n  ///\n  /// It is the union of the execution domains of the memory accesses in the\n  /// InvariantAccesses list.\n  isl::set ExecutionContext;\n\n  /// The type of the invariant access\n  ///\n  /// It is used to differentiate between differently typed invariant loads from\n  /// the same location.\n  Type *AccessType;\n};\n\n/// Type for invariant accesses equivalence classes.\nusing InvariantEquivClassesTy = SmallVector<InvariantEquivClassTy, 8>;\n\n/// Statement of the Scop\n///\n/// A Scop statement represents an instruction in the Scop.\n///\n/// It is further described by its iteration domain, its schedule and its data\n/// accesses.\n/// At the moment every statement represents a single basic block of LLVM-IR.\nclass ScopStmt {\n  friend class ScopBuilder;\n\npublic:\n  /// Create the ScopStmt from a BasicBlock.\n  ScopStmt(Scop &parent, BasicBlock &bb, StringRef Name, Loop *SurroundingLoop,\n           std::vector<Instruction *> Instructions);\n\n  /// Create an overapproximating ScopStmt for the region @p R.\n  ///\n  /// @param EntryBlockInstructions The list of instructions that belong to the\n  ///                               entry block of the region statement.\n  ///                               Instructions are only tracked for entry\n  ///                               blocks for now. We currently do not allow\n  ///                               to modify the instructions of blocks later\n  ///                               in the region statement.\n  ScopStmt(Scop &parent, Region &R, StringRef Name, Loop *SurroundingLoop,\n           std::vector<Instruction *> EntryBlockInstructions);\n\n  /// Create a copy statement.\n  ///\n  /// @param Stmt       The parent statement.\n  /// @param SourceRel  The source location.\n  /// @param TargetRel  The target location.\n  /// @param Domain     The original domain under which the copy statement would\n  ///                   be executed.\n  ScopStmt(Scop &parent, isl::map SourceRel, isl::map TargetRel,\n           isl::set Domain);\n\n  ScopStmt(const ScopStmt &) = delete;\n  const ScopStmt &operator=(const ScopStmt &) = delete;\n  ~ScopStmt();\n\nprivate:\n  /// Polyhedral description\n  //@{\n\n  /// The Scop containing this ScopStmt.\n  Scop &Parent;\n\n  /// The domain under which this statement is not modeled precisely.\n  ///\n  /// The invalid domain for a statement describes all parameter combinations\n  /// under which the statement looks to be executed but is in fact not because\n  /// some assumption/restriction makes the statement/scop invalid.\n  isl::set InvalidDomain;\n\n  /// The iteration domain describes the set of iterations for which this\n  /// statement is executed.\n  ///\n  /// Example:\n  ///     for (i = 0; i < 100 + b; ++i)\n  ///       for (j = 0; j < i; ++j)\n  ///         S(i,j);\n  ///\n  /// 'S' is executed for different values of i and j. A vector of all\n  /// induction variables around S (i, j) is called iteration vector.\n  /// The domain describes the set of possible iteration vectors.\n  ///\n  /// In this case it is:\n  ///\n  ///     Domain: 0 <= i <= 100 + b\n  ///             0 <= j <= i\n  ///\n  /// A pair of statement and iteration vector (S, (5,3)) is called statement\n  /// instance.\n  isl::set Domain;\n\n  /// The memory accesses of this statement.\n  ///\n  /// The only side effects of a statement are its memory accesses.\n  using MemoryAccessVec = llvm::SmallVector<MemoryAccess *, 8>;\n  MemoryAccessVec MemAccs;\n\n  /// Mapping from instructions to (scalar) memory accesses.\n  DenseMap<const Instruction *, MemoryAccessList> InstructionToAccess;\n\n  /// The set of values defined elsewhere required in this ScopStmt and\n  ///        their MemoryKind::Value READ MemoryAccesses.\n  DenseMap<Value *, MemoryAccess *> ValueReads;\n\n  /// The set of values defined in this ScopStmt that are required\n  ///        elsewhere, mapped to their MemoryKind::Value WRITE MemoryAccesses.\n  DenseMap<Instruction *, MemoryAccess *> ValueWrites;\n\n  /// Map from PHI nodes to its incoming value when coming from this\n  ///        statement.\n  ///\n  /// Non-affine subregions can have multiple exiting blocks that are incoming\n  /// blocks of the PHI nodes. This map ensures that there is only one write\n  /// operation for the complete subregion. A PHI selecting the relevant value\n  /// will be inserted.\n  DenseMap<PHINode *, MemoryAccess *> PHIWrites;\n\n  /// Map from PHI nodes to its read access in this statement.\n  DenseMap<PHINode *, MemoryAccess *> PHIReads;\n\n  //@}\n\n  /// A SCoP statement represents either a basic block (affine/precise case) or\n  /// a whole region (non-affine case).\n  ///\n  /// Only one of the following two members will therefore be set and indicate\n  /// which kind of statement this is.\n  ///\n  ///{\n\n  /// The BasicBlock represented by this statement (in the affine case).\n  BasicBlock *BB = nullptr;\n\n  /// The region represented by this statement (in the non-affine case).\n  Region *R = nullptr;\n\n  ///}\n\n  /// The isl AST build for the new generated AST.\n  isl::ast_build Build;\n\n  SmallVector<Loop *, 4> NestLoops;\n\n  std::string BaseName;\n\n  /// The closest loop that contains this statement.\n  Loop *SurroundingLoop;\n\n  /// Vector for Instructions in this statement.\n  std::vector<Instruction *> Instructions;\n\n  /// Remove @p MA from dictionaries pointing to them.\n  void removeAccessData(MemoryAccess *MA);\n\npublic:\n  /// Get an isl_ctx pointer.\n  isl::ctx getIslCtx() const;\n\n  /// Get the iteration domain of this ScopStmt.\n  ///\n  /// @return The iteration domain of this ScopStmt.\n  isl::set getDomain() const;\n\n  /// Get the space of the iteration domain\n  ///\n  /// @return The space of the iteration domain\n  isl::space getDomainSpace() const;\n\n  /// Get the id of the iteration domain space\n  ///\n  /// @return The id of the iteration domain space\n  isl::id getDomainId() const;\n\n  /// Get an isl string representing this domain.\n  std::string getDomainStr() const;\n\n  /// Get the schedule function of this ScopStmt.\n  ///\n  /// @return The schedule function of this ScopStmt, if it does not contain\n  /// extension nodes, and nullptr, otherwise.\n  isl::map getSchedule() const;\n\n  /// Get an isl string representing this schedule.\n  ///\n  /// @return An isl string representing this schedule, if it does not contain\n  /// extension nodes, and an empty string, otherwise.\n  std::string getScheduleStr() const;\n\n  /// Get the invalid domain for this statement.\n  isl::set getInvalidDomain() const { return InvalidDomain; }\n\n  /// Get the invalid context for this statement.\n  isl::set getInvalidContext() const { return getInvalidDomain().params(); }\n\n  /// Set the invalid context for this statement to @p ID.\n  void setInvalidDomain(isl::set ID);\n\n  /// Get the BasicBlock represented by this ScopStmt (if any).\n  ///\n  /// @return The BasicBlock represented by this ScopStmt, or null if the\n  ///         statement represents a region.\n  BasicBlock *getBasicBlock() const { return BB; }\n\n  /// Return true if this statement represents a single basic block.\n  bool isBlockStmt() const { return BB != nullptr; }\n\n  /// Return true if this is a copy statement.\n  bool isCopyStmt() const { return BB == nullptr && R == nullptr; }\n\n  /// Get the region represented by this ScopStmt (if any).\n  ///\n  /// @return The region represented by this ScopStmt, or null if the statement\n  ///         represents a basic block.\n  Region *getRegion() const { return R; }\n\n  /// Return true if this statement represents a whole region.\n  bool isRegionStmt() const { return R != nullptr; }\n\n  /// Return a BasicBlock from this statement.\n  ///\n  /// For block statements, it returns the BasicBlock itself. For subregion\n  /// statements, return its entry block.\n  BasicBlock *getEntryBlock() const;\n\n  /// Return whether @p L is boxed within this statement.\n  bool contains(const Loop *L) const {\n    // Block statements never contain loops.\n    if (isBlockStmt())\n      return false;\n\n    return getRegion()->contains(L);\n  }\n\n  /// Return whether this statement represents @p BB.\n  bool represents(BasicBlock *BB) const {\n    if (isCopyStmt())\n      return false;\n    if (isBlockStmt())\n      return BB == getBasicBlock();\n    return getRegion()->contains(BB);\n  }\n\n  /// Return whether this statement contains @p Inst.\n  bool contains(Instruction *Inst) const {\n    if (!Inst)\n      return false;\n    if (isBlockStmt())\n      return std::find(Instructions.begin(), Instructions.end(), Inst) !=\n             Instructions.end();\n    return represents(Inst->getParent());\n  }\n\n  /// Return the closest innermost loop that contains this statement, but is not\n  /// contained in it.\n  ///\n  /// For block statement, this is just the loop that contains the block. Region\n  /// statements can contain boxed loops, so getting the loop of one of the\n  /// region's BBs might return such an inner loop. For instance, the region's\n  /// entry could be a header of a loop, but the region might extend to BBs\n  /// after the loop exit. Similarly, the region might only contain parts of the\n  /// loop body and still include the loop header.\n  ///\n  /// Most of the time the surrounding loop is the top element of #NestLoops,\n  /// except when it is empty. In that case it return the loop that the whole\n  /// SCoP is contained in. That can be nullptr if there is no such loop.\n  Loop *getSurroundingLoop() const {\n    assert(!isCopyStmt() &&\n           \"No surrounding loop for artificially created statements\");\n    return SurroundingLoop;\n  }\n\n  /// Return true if this statement does not contain any accesses.\n  bool isEmpty() const { return MemAccs.empty(); }\n\n  /// Find all array accesses for @p Inst.\n  ///\n  /// @param Inst The instruction accessing an array.\n  ///\n  /// @return A list of array accesses (MemoryKind::Array) accessed by @p Inst.\n  ///         If there is no such access, it returns nullptr.\n  const MemoryAccessList *\n  lookupArrayAccessesFor(const Instruction *Inst) const {\n    auto It = InstructionToAccess.find(Inst);\n    if (It == InstructionToAccess.end())\n      return nullptr;\n    if (It->second.empty())\n      return nullptr;\n    return &It->second;\n  }\n\n  /// Return the only array access for @p Inst, if existing.\n  ///\n  /// @param Inst The instruction for which to look up the access.\n  /// @returns The unique array memory access related to Inst or nullptr if\n  ///          no array access exists\n  MemoryAccess *getArrayAccessOrNULLFor(const Instruction *Inst) const {\n    auto It = InstructionToAccess.find(Inst);\n    if (It == InstructionToAccess.end())\n      return nullptr;\n\n    MemoryAccess *ArrayAccess = nullptr;\n\n    for (auto Access : It->getSecond()) {\n      if (!Access->isArrayKind())\n        continue;\n\n      assert(!ArrayAccess && \"More then one array access for instruction\");\n\n      ArrayAccess = Access;\n    }\n\n    return ArrayAccess;\n  }\n\n  /// Return the only array access for @p Inst.\n  ///\n  /// @param Inst The instruction for which to look up the access.\n  /// @returns The unique array memory access related to Inst.\n  MemoryAccess &getArrayAccessFor(const Instruction *Inst) const {\n    MemoryAccess *ArrayAccess = getArrayAccessOrNULLFor(Inst);\n\n    assert(ArrayAccess && \"No array access found for instruction!\");\n    return *ArrayAccess;\n  }\n\n  /// Return the MemoryAccess that writes the value of an instruction\n  ///        defined in this statement, or nullptr if not existing, respectively\n  ///        not yet added.\n  MemoryAccess *lookupValueWriteOf(Instruction *Inst) const {\n    assert((isRegionStmt() && R->contains(Inst)) ||\n           (!isRegionStmt() && Inst->getParent() == BB));\n    return ValueWrites.lookup(Inst);\n  }\n\n  /// Return the MemoryAccess that reloads a value, or nullptr if not\n  ///        existing, respectively not yet added.\n  MemoryAccess *lookupValueReadOf(Value *Inst) const {\n    return ValueReads.lookup(Inst);\n  }\n\n  /// Return the MemoryAccess that loads a PHINode value, or nullptr if not\n  /// existing, respectively not yet added.\n  MemoryAccess *lookupPHIReadOf(PHINode *PHI) const {\n    return PHIReads.lookup(PHI);\n  }\n\n  /// Return the PHI write MemoryAccess for the incoming values from any\n  ///        basic block in this ScopStmt, or nullptr if not existing,\n  ///        respectively not yet added.\n  MemoryAccess *lookupPHIWriteOf(PHINode *PHI) const {\n    assert(isBlockStmt() || R->getExit() == PHI->getParent());\n    return PHIWrites.lookup(PHI);\n  }\n\n  /// Return the input access of the value, or null if no such MemoryAccess\n  /// exists.\n  ///\n  /// The input access is the MemoryAccess that makes an inter-statement value\n  /// available in this statement by reading it at the start of this statement.\n  /// This can be a MemoryKind::Value if defined in another statement or a\n  /// MemoryKind::PHI if the value is a PHINode in this statement.\n  MemoryAccess *lookupInputAccessOf(Value *Val) const {\n    if (isa<PHINode>(Val))\n      if (auto InputMA = lookupPHIReadOf(cast<PHINode>(Val))) {\n        assert(!lookupValueReadOf(Val) && \"input accesses must be unique; a \"\n                                          \"statement cannot read a .s2a and \"\n                                          \".phiops simultaneously\");\n        return InputMA;\n      }\n\n    if (auto *InputMA = lookupValueReadOf(Val))\n      return InputMA;\n\n    return nullptr;\n  }\n\n  /// Add @p Access to this statement's list of accesses.\n  ///\n  /// @param Access  The access to add.\n  /// @param Prepend If true, will add @p Access before all other instructions\n  ///                (instead of appending it).\n  void addAccess(MemoryAccess *Access, bool Preprend = false);\n\n  /// Remove a MemoryAccess from this statement.\n  ///\n  /// Note that scalar accesses that are caused by MA will\n  /// be eliminated too.\n  void removeMemoryAccess(MemoryAccess *MA);\n\n  /// Remove @p MA from this statement.\n  ///\n  /// In contrast to removeMemoryAccess(), no other access will be eliminated.\n  ///\n  /// @param MA            The MemoryAccess to be removed.\n  /// @param AfterHoisting If true, also remove from data access lists.\n  ///                      These lists are filled during\n  ///                      ScopBuilder::buildAccessRelations. Therefore, if this\n  ///                      method is called before buildAccessRelations, false\n  ///                      must be passed.\n  void removeSingleMemoryAccess(MemoryAccess *MA, bool AfterHoisting = true);\n\n  using iterator = MemoryAccessVec::iterator;\n  using const_iterator = MemoryAccessVec::const_iterator;\n\n  iterator begin() { return MemAccs.begin(); }\n  iterator end() { return MemAccs.end(); }\n  const_iterator begin() const { return MemAccs.begin(); }\n  const_iterator end() const { return MemAccs.end(); }\n  size_t size() const { return MemAccs.size(); }\n\n  unsigned getNumIterators() const;\n\n  Scop *getParent() { return &Parent; }\n  const Scop *getParent() const { return &Parent; }\n\n  const std::vector<Instruction *> &getInstructions() const {\n    return Instructions;\n  }\n\n  /// Set the list of instructions for this statement. It replaces the current\n  /// list.\n  void setInstructions(ArrayRef<Instruction *> Range) {\n    Instructions.assign(Range.begin(), Range.end());\n  }\n\n  std::vector<Instruction *>::const_iterator insts_begin() const {\n    return Instructions.begin();\n  }\n\n  std::vector<Instruction *>::const_iterator insts_end() const {\n    return Instructions.end();\n  }\n\n  /// The range of instructions in this statement.\n  iterator_range<std::vector<Instruction *>::const_iterator> insts() const {\n    return {insts_begin(), insts_end()};\n  }\n\n  /// Insert an instruction before all other instructions in this statement.\n  void prependInstruction(Instruction *Inst) {\n    Instructions.insert(Instructions.begin(), Inst);\n  }\n\n  const char *getBaseName() const;\n\n  /// Set the isl AST build.\n  void setAstBuild(isl::ast_build B) { Build = B; }\n\n  /// Get the isl AST build.\n  isl::ast_build getAstBuild() const { return Build; }\n\n  /// Restrict the domain of the statement.\n  ///\n  /// @param NewDomain The new statement domain.\n  void restrictDomain(isl::set NewDomain);\n\n  /// Get the loop for a dimension.\n  ///\n  /// @param Dimension The dimension of the induction variable\n  /// @return The loop at a certain dimension.\n  Loop *getLoopForDimension(unsigned Dimension) const;\n\n  /// Align the parameters in the statement to the scop context\n  void realignParams();\n\n  /// Print the ScopStmt.\n  ///\n  /// @param OS                The output stream the ScopStmt is printed to.\n  /// @param PrintInstructions Whether to print the statement's instructions as\n  ///                          well.\n  void print(raw_ostream &OS, bool PrintInstructions) const;\n\n  /// Print the instructions in ScopStmt.\n  ///\n  void printInstructions(raw_ostream &OS) const;\n\n  /// Check whether there is a value read access for @p V in this statement, and\n  /// if not, create one.\n  ///\n  /// This allows to add MemoryAccesses after the initial creation of the Scop\n  /// by ScopBuilder.\n  ///\n  /// @return The already existing or newly created MemoryKind::Value READ\n  /// MemoryAccess.\n  ///\n  /// @see ScopBuilder::ensureValueRead(Value*,ScopStmt*)\n  MemoryAccess *ensureValueRead(Value *V);\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print the ScopStmt to stderr.\n  void dump() const;\n#endif\n};\n\n/// Print ScopStmt S to raw_ostream OS.\nraw_ostream &operator<<(raw_ostream &OS, const ScopStmt &S);\n\n/// Build the conditions sets for the branch condition @p Condition in\n/// the @p Domain.\n///\n/// This will fill @p ConditionSets with the conditions under which control\n/// will be moved from @p TI to its successors. Hence, @p ConditionSets will\n/// have as many elements as @p TI has successors. If @p TI is nullptr the\n/// context under which @p Condition is true/false will be returned as the\n/// new elements of @p ConditionSets.\nbool buildConditionSets(Scop &S, BasicBlock *BB, Value *Condition,\n                        Instruction *TI, Loop *L, __isl_keep isl_set *Domain,\n                        DenseMap<BasicBlock *, isl::set> &InvalidDomainMap,\n                        SmallVectorImpl<__isl_give isl_set *> &ConditionSets);\n\n/// Build condition sets for unsigned ICmpInst(s).\n/// Special handling is required for unsigned operands to ensure that if\n/// MSB (aka the Sign bit) is set for an operands in an unsigned ICmpInst\n/// it should wrap around.\n///\n/// @param IsStrictUpperBound holds information on the predicate relation\n/// between TestVal and UpperBound, i.e,\n/// TestVal < UpperBound  OR  TestVal <= UpperBound\n__isl_give isl_set *\nbuildUnsignedConditionSets(Scop &S, BasicBlock *BB, Value *Condition,\n                           __isl_keep isl_set *Domain, const SCEV *SCEV_TestVal,\n                           const SCEV *SCEV_UpperBound,\n                           DenseMap<BasicBlock *, isl::set> &InvalidDomainMap,\n                           bool IsStrictUpperBound);\n\n/// Build the conditions sets for the terminator @p TI in the @p Domain.\n///\n/// This will fill @p ConditionSets with the conditions under which control\n/// will be moved from @p TI to its successors. Hence, @p ConditionSets will\n/// have as many elements as @p TI has successors.\nbool buildConditionSets(Scop &S, BasicBlock *BB, Instruction *TI, Loop *L,\n                        __isl_keep isl_set *Domain,\n                        DenseMap<BasicBlock *, isl::set> &InvalidDomainMap,\n                        SmallVectorImpl<__isl_give isl_set *> &ConditionSets);\n\n/// Static Control Part\n///\n/// A Scop is the polyhedral representation of a control flow region detected\n/// by the Scop detection. It is generated by translating the LLVM-IR and\n/// abstracting its effects.\n///\n/// A Scop consists of a set of:\n///\n///   * A set of statements executed in the Scop.\n///\n///   * A set of global parameters\n///   Those parameters are scalar integer values, which are constant during\n///   execution.\n///\n///   * A context\n///   This context contains information about the values the parameters\n///   can take and relations between different parameters.\nclass Scop {\npublic:\n  /// Type to represent a pair of minimal/maximal access to an array.\n  using MinMaxAccessTy = std::pair<isl::pw_multi_aff, isl::pw_multi_aff>;\n\n  /// Vector of minimal/maximal accesses to different arrays.\n  using MinMaxVectorTy = SmallVector<MinMaxAccessTy, 4>;\n\n  /// Pair of minimal/maximal access vectors representing\n  /// read write and read only accesses\n  using MinMaxVectorPairTy = std::pair<MinMaxVectorTy, MinMaxVectorTy>;\n\n  /// Vector of pair of minimal/maximal access vectors representing\n  /// non read only and read only accesses for each alias group.\n  using MinMaxVectorPairVectorTy = SmallVector<MinMaxVectorPairTy, 4>;\n\nprivate:\n  friend class ScopBuilder;\n\n  /// Isl context.\n  ///\n  /// We need a shared_ptr with reference counter to delete the context when all\n  /// isl objects are deleted. We will distribute the shared_ptr to all objects\n  /// that use the context to create isl objects, and increase the reference\n  /// counter. By doing this, we guarantee that the context is deleted when we\n  /// delete the last object that creates isl objects with the context. This\n  /// declaration needs to be the first in class to gracefully destroy all isl\n  /// objects before the context.\n  std::shared_ptr<isl_ctx> IslCtx;\n\n  ScalarEvolution *SE;\n  DominatorTree *DT;\n\n  /// The underlying Region.\n  Region &R;\n\n  /// The name of the SCoP (identical to the regions name)\n  Optional<std::string> name;\n\n  // Access functions of the SCoP.\n  //\n  // This owns all the MemoryAccess objects of the Scop created in this pass.\n  AccFuncVector AccessFunctions;\n\n  /// Flag to indicate that the scheduler actually optimized the SCoP.\n  bool IsOptimized = false;\n\n  /// True if the underlying region has a single exiting block.\n  bool HasSingleExitEdge;\n\n  /// Flag to remember if the SCoP contained an error block or not.\n  bool HasErrorBlock = false;\n\n  /// Max loop depth.\n  unsigned MaxLoopDepth = 0;\n\n  /// Number of copy statements.\n  unsigned CopyStmtsNum = 0;\n\n  /// Flag to indicate if the Scop is to be skipped.\n  bool SkipScop = false;\n\n  using StmtSet = std::list<ScopStmt>;\n\n  /// The statements in this Scop.\n  StmtSet Stmts;\n\n  /// Parameters of this Scop\n  ParameterSetTy Parameters;\n\n  /// Mapping from parameters to their ids.\n  DenseMap<const SCEV *, isl::id> ParameterIds;\n\n  /// The context of the SCoP created during SCoP detection.\n  ScopDetection::DetectionContext &DC;\n\n  /// OptimizationRemarkEmitter object for displaying diagnostic remarks\n  OptimizationRemarkEmitter &ORE;\n\n  /// A map from basic blocks to vector of SCoP statements. Currently this\n  /// vector comprises only of a single statement.\n  DenseMap<BasicBlock *, std::vector<ScopStmt *>> StmtMap;\n\n  /// A map from instructions to SCoP statements.\n  DenseMap<Instruction *, ScopStmt *> InstStmtMap;\n\n  /// A map from basic blocks to their domains.\n  DenseMap<BasicBlock *, isl::set> DomainMap;\n\n  /// Constraints on parameters.\n  isl::set Context = nullptr;\n\n  /// The affinator used to translate SCEVs to isl expressions.\n  SCEVAffinator Affinator;\n\n  using ArrayInfoMapTy =\n      std::map<std::pair<AssertingVH<const Value>, MemoryKind>,\n               std::unique_ptr<ScopArrayInfo>>;\n\n  using ArrayNameMapTy = StringMap<std::unique_ptr<ScopArrayInfo>>;\n\n  using ArrayInfoSetTy = SetVector<ScopArrayInfo *>;\n\n  /// A map to remember ScopArrayInfo objects for all base pointers.\n  ///\n  /// As PHI nodes may have two array info objects associated, we add a flag\n  /// that distinguishes between the PHI node specific ArrayInfo object\n  /// and the normal one.\n  ArrayInfoMapTy ScopArrayInfoMap;\n\n  /// A map to remember ScopArrayInfo objects for all names of memory\n  ///        references.\n  ArrayNameMapTy ScopArrayNameMap;\n\n  /// A set to remember ScopArrayInfo objects.\n  /// @see Scop::ScopArrayInfoMap\n  ArrayInfoSetTy ScopArrayInfoSet;\n\n  /// The assumptions under which this scop was built.\n  ///\n  /// When constructing a scop sometimes the exact representation of a statement\n  /// or condition would be very complex, but there is a common case which is a\n  /// lot simpler, but which is only valid under certain assumptions. The\n  /// assumed context records the assumptions taken during the construction of\n  /// this scop and that need to be code generated as a run-time test.\n  isl::set AssumedContext;\n\n  /// The restrictions under which this SCoP was built.\n  ///\n  /// The invalid context is similar to the assumed context as it contains\n  /// constraints over the parameters. However, while we need the constraints\n  /// in the assumed context to be \"true\" the constraints in the invalid context\n  /// need to be \"false\". Otherwise they behave the same.\n  isl::set InvalidContext;\n\n  /// The context under which the SCoP must have defined behavior. Optimizer and\n  /// code generator can assume that the SCoP will only be executed with\n  /// parameter values within this context. This might be either because we can\n  /// prove that other values are impossible or explicitly have undefined\n  /// behavior, such as due to no-wrap flags. If this becomes too complex, can\n  /// also be nullptr.\n  ///\n  /// In contrast to Scop::AssumedContext and Scop::InvalidContext, these do not\n  /// need to be checked at runtime.\n  ///\n  /// Scop::Context on the other side is an overapproximation and does not\n  /// include all requirements, but is always defined. However, there is still\n  /// no guarantee that there is no undefined behavior in\n  /// DefinedBehaviorContext.\n  isl::set DefinedBehaviorContext;\n\n  /// The schedule of the SCoP\n  ///\n  /// The schedule of the SCoP describes the execution order of the statements\n  /// in the scop by assigning each statement instance a possibly\n  /// multi-dimensional execution time. The schedule is stored as a tree of\n  /// schedule nodes.\n  ///\n  /// The most common nodes in a schedule tree are so-called band nodes. Band\n  /// nodes map statement instances into a multi dimensional schedule space.\n  /// This space can be seen as a multi-dimensional clock.\n  ///\n  /// Example:\n  ///\n  /// <S,(5,4)>  may be mapped to (5,4) by this schedule:\n  ///\n  /// s0 = i (Year of execution)\n  /// s1 = j (Day of execution)\n  ///\n  /// or to (9, 20) by this schedule:\n  ///\n  /// s0 = i + j (Year of execution)\n  /// s1 = 20 (Day of execution)\n  ///\n  /// The order statement instances are executed is defined by the\n  /// schedule vectors they are mapped to. A statement instance\n  /// <A, (i, j, ..)> is executed before a statement instance <B, (i', ..)>, if\n  /// the schedule vector of A is lexicographic smaller than the schedule\n  /// vector of B.\n  ///\n  /// Besides band nodes, schedule trees contain additional nodes that specify\n  /// a textual ordering between two subtrees or filter nodes that filter the\n  /// set of statement instances that will be scheduled in a subtree. There\n  /// are also several other nodes. A full description of the different nodes\n  /// in a schedule tree is given in the isl manual.\n  isl::schedule Schedule = nullptr;\n\n  /// Whether the schedule has been modified after derived from the CFG by\n  /// ScopBuilder.\n  bool ScheduleModified = false;\n\n  /// The set of minimal/maximal accesses for each alias group.\n  ///\n  /// When building runtime alias checks we look at all memory instructions and\n  /// build so called alias groups. Each group contains a set of accesses to\n  /// different base arrays which might alias with each other. However, between\n  /// alias groups there is no aliasing possible.\n  ///\n  /// In a program with int and float pointers annotated with tbaa information\n  /// we would probably generate two alias groups, one for the int pointers and\n  /// one for the float pointers.\n  ///\n  /// During code generation we will create a runtime alias check for each alias\n  /// group to ensure the SCoP is executed in an alias free environment.\n  MinMaxVectorPairVectorTy MinMaxAliasGroups;\n\n  /// Mapping from invariant loads to the representing invariant load of\n  ///        their equivalence class.\n  ValueToValueMap InvEquivClassVMap;\n\n  /// List of invariant accesses.\n  InvariantEquivClassesTy InvariantEquivClasses;\n\n  /// The smallest array index not yet assigned.\n  long ArrayIdx = 0;\n\n  /// The smallest statement index not yet assigned.\n  long StmtIdx = 0;\n\n  /// A number that uniquely represents a Scop within its function\n  const int ID;\n\n  /// Map of values to the MemoryAccess that writes its definition.\n  ///\n  /// There must be at most one definition per llvm::Instruction in a SCoP.\n  DenseMap<Value *, MemoryAccess *> ValueDefAccs;\n\n  /// Map of values to the MemoryAccess that reads a PHI.\n  DenseMap<PHINode *, MemoryAccess *> PHIReadAccs;\n\n  /// List of all uses (i.e. read MemoryAccesses) for a MemoryKind::Value\n  /// scalar.\n  DenseMap<const ScopArrayInfo *, SmallVector<MemoryAccess *, 4>> ValueUseAccs;\n\n  /// List of all incoming values (write MemoryAccess) of a MemoryKind::PHI or\n  /// MemoryKind::ExitPHI scalar.\n  DenseMap<const ScopArrayInfo *, SmallVector<MemoryAccess *, 4>>\n      PHIIncomingAccs;\n\n  /// Scop constructor; invoked from ScopBuilder::buildScop.\n  Scop(Region &R, ScalarEvolution &SE, LoopInfo &LI, DominatorTree &DT,\n       ScopDetection::DetectionContext &DC, OptimizationRemarkEmitter &ORE,\n       int ID);\n\n  //@}\n\n  /// Initialize this ScopBuilder.\n  void init(AAResults &AA, AssumptionCache &AC, DominatorTree &DT,\n            LoopInfo &LI);\n\n  /// Return the access for the base ptr of @p MA if any.\n  MemoryAccess *lookupBasePtrAccess(MemoryAccess *MA);\n\n  /// Create an id for @p Param and store it in the ParameterIds map.\n  void createParameterId(const SCEV *Param);\n\n  /// Build the Context of the Scop.\n  void buildContext();\n\n  /// Add the bounds of the parameters to the context.\n  void addParameterBounds();\n\n  /// Simplify the assumed and invalid context.\n  void simplifyContexts();\n\n  /// Create a new SCoP statement for @p BB.\n  ///\n  /// A new statement for @p BB will be created and added to the statement\n  /// vector\n  /// and map.\n  ///\n  /// @param BB              The basic block we build the statement for.\n  /// @param Name            The name of the new statement.\n  /// @param SurroundingLoop The loop the created statement is contained in.\n  /// @param Instructions    The instructions in the statement.\n  void addScopStmt(BasicBlock *BB, StringRef Name, Loop *SurroundingLoop,\n                   std::vector<Instruction *> Instructions);\n\n  /// Create a new SCoP statement for @p R.\n  ///\n  /// A new statement for @p R will be created and added to the statement vector\n  /// and map.\n  ///\n  /// @param R                      The region we build the statement for.\n  /// @param Name                   The name of the new statement.\n  /// @param SurroundingLoop        The loop the created statement is contained\n  ///                               in.\n  /// @param EntryBlockInstructions The (interesting) instructions in the\n  ///                               entry block of the region statement.\n  void addScopStmt(Region *R, StringRef Name, Loop *SurroundingLoop,\n                   std::vector<Instruction *> EntryBlockInstructions);\n\n  /// Removes @p Stmt from the StmtMap.\n  void removeFromStmtMap(ScopStmt &Stmt);\n\n  /// Removes all statements where the entry block of the statement does not\n  /// have a corresponding domain in the domain map (or it is empty).\n  void removeStmtNotInDomainMap();\n\n  /// Collect all memory access relations of a given type.\n  ///\n  /// @param Predicate A predicate function that returns true if an access is\n  ///                  of a given type.\n  ///\n  /// @returns The set of memory accesses in the scop that match the predicate.\n  isl::union_map\n  getAccessesOfType(std::function<bool(MemoryAccess &)> Predicate);\n\n  /// @name Helper functions for printing the Scop.\n  ///\n  //@{\n  void printContext(raw_ostream &OS) const;\n  void printArrayInfo(raw_ostream &OS) const;\n  void printStatements(raw_ostream &OS, bool PrintInstructions) const;\n  void printAliasAssumptions(raw_ostream &OS) const;\n  //@}\n\npublic:\n  Scop(const Scop &) = delete;\n  Scop &operator=(const Scop &) = delete;\n  ~Scop();\n\n  /// Increment actual number of aliasing assumptions taken\n  ///\n  /// @param Step    Number of new aliasing assumptions which should be added to\n  /// the number of already taken assumptions.\n  static void incrementNumberOfAliasingAssumptions(unsigned Step);\n\n  /// Get the count of copy statements added to this Scop.\n  ///\n  /// @return The count of copy statements added to this Scop.\n  unsigned getCopyStmtsNum() { return CopyStmtsNum; }\n\n  /// Create a new copy statement.\n  ///\n  /// A new statement will be created and added to the statement vector.\n  ///\n  /// @param Stmt       The parent statement.\n  /// @param SourceRel  The source location.\n  /// @param TargetRel  The target location.\n  /// @param Domain     The original domain under which the copy statement would\n  ///                   be executed.\n  ScopStmt *addScopStmt(isl::map SourceRel, isl::map TargetRel,\n                        isl::set Domain);\n\n  /// Add the access function to all MemoryAccess objects of the Scop\n  ///        created in this pass.\n  void addAccessFunction(MemoryAccess *Access) {\n    AccessFunctions.emplace_back(Access);\n\n    // Register value definitions.\n    if (Access->isWrite() && Access->isOriginalValueKind()) {\n      assert(!ValueDefAccs.count(Access->getAccessValue()) &&\n             \"there can be just one definition per value\");\n      ValueDefAccs[Access->getAccessValue()] = Access;\n    } else if (Access->isRead() && Access->isOriginalPHIKind()) {\n      PHINode *PHI = cast<PHINode>(Access->getAccessInstruction());\n      assert(!PHIReadAccs.count(PHI) &&\n             \"there can be just one PHI read per PHINode\");\n      PHIReadAccs[PHI] = Access;\n    }\n  }\n\n  /// Add metadata for @p Access.\n  void addAccessData(MemoryAccess *Access);\n\n  /// Add new invariant access equivalence class\n  void\n  addInvariantEquivClass(const InvariantEquivClassTy &InvariantEquivClass) {\n    InvariantEquivClasses.emplace_back(InvariantEquivClass);\n  }\n\n  /// Add mapping from invariant loads to the representing invariant load of\n  ///        their equivalence class.\n  void addInvariantLoadMapping(const Value *LoadInst, Value *ClassRep) {\n    InvEquivClassVMap[LoadInst] = ClassRep;\n  }\n\n  /// Remove the metadata stored for @p Access.\n  void removeAccessData(MemoryAccess *Access);\n\n  /// Return the scalar evolution.\n  ScalarEvolution *getSE() const;\n\n  /// Return the dominator tree.\n  DominatorTree *getDT() const { return DT; }\n\n  /// Return the LoopInfo used for this Scop.\n  LoopInfo *getLI() const { return Affinator.getLI(); }\n\n  /// Get the count of parameters used in this Scop.\n  ///\n  /// @return The count of parameters used in this Scop.\n  size_t getNumParams() const { return Parameters.size(); }\n\n  /// Return whether given SCEV is used as the parameter in this Scop.\n  bool isParam(const SCEV *Param) const { return Parameters.count(Param); }\n\n  /// Take a list of parameters and add the new ones to the scop.\n  void addParams(const ParameterSetTy &NewParameters);\n\n  /// Return an iterator range containing the scop parameters.\n  iterator_range<ParameterSetTy::iterator> parameters() const {\n    return make_range(Parameters.begin(), Parameters.end());\n  }\n\n  /// Return an iterator range containing invariant accesses.\n  iterator_range<InvariantEquivClassesTy::iterator> invariantEquivClasses() {\n    return make_range(InvariantEquivClasses.begin(),\n                      InvariantEquivClasses.end());\n  }\n\n  /// Return an iterator range containing all the MemoryAccess objects of the\n  /// Scop.\n  iterator_range<AccFuncVector::iterator> access_functions() {\n    return make_range(AccessFunctions.begin(), AccessFunctions.end());\n  }\n\n  /// Return whether this scop is empty, i.e. contains no statements that\n  /// could be executed.\n  bool isEmpty() const { return Stmts.empty(); }\n\n  StringRef getName() {\n    if (!name)\n      name = R.getNameStr();\n    return *name;\n  }\n\n  using array_iterator = ArrayInfoSetTy::iterator;\n  using const_array_iterator = ArrayInfoSetTy::const_iterator;\n  using array_range = iterator_range<ArrayInfoSetTy::iterator>;\n  using const_array_range = iterator_range<ArrayInfoSetTy::const_iterator>;\n\n  inline array_iterator array_begin() { return ScopArrayInfoSet.begin(); }\n\n  inline array_iterator array_end() { return ScopArrayInfoSet.end(); }\n\n  inline const_array_iterator array_begin() const {\n    return ScopArrayInfoSet.begin();\n  }\n\n  inline const_array_iterator array_end() const {\n    return ScopArrayInfoSet.end();\n  }\n\n  inline array_range arrays() {\n    return array_range(array_begin(), array_end());\n  }\n\n  inline const_array_range arrays() const {\n    return const_array_range(array_begin(), array_end());\n  }\n\n  /// Return the isl_id that represents a certain parameter.\n  ///\n  /// @param Parameter A SCEV that was recognized as a Parameter.\n  ///\n  /// @return The corresponding isl_id or NULL otherwise.\n  isl::id getIdForParam(const SCEV *Parameter) const;\n\n  /// Get the maximum region of this static control part.\n  ///\n  /// @return The maximum region of this static control part.\n  inline const Region &getRegion() const { return R; }\n  inline Region &getRegion() { return R; }\n\n  /// Return the function this SCoP is in.\n  Function &getFunction() const { return *R.getEntry()->getParent(); }\n\n  /// Check if @p L is contained in the SCoP.\n  bool contains(const Loop *L) const { return R.contains(L); }\n\n  /// Check if @p BB is contained in the SCoP.\n  bool contains(const BasicBlock *BB) const { return R.contains(BB); }\n\n  /// Check if @p I is contained in the SCoP.\n  bool contains(const Instruction *I) const { return R.contains(I); }\n\n  /// Return the unique exit block of the SCoP.\n  BasicBlock *getExit() const { return R.getExit(); }\n\n  /// Return the unique exiting block of the SCoP if any.\n  BasicBlock *getExitingBlock() const { return R.getExitingBlock(); }\n\n  /// Return the unique entry block of the SCoP.\n  BasicBlock *getEntry() const { return R.getEntry(); }\n\n  /// Return the unique entering block of the SCoP if any.\n  BasicBlock *getEnteringBlock() const { return R.getEnteringBlock(); }\n\n  /// Return true if @p BB is the exit block of the SCoP.\n  bool isExit(BasicBlock *BB) const { return getExit() == BB; }\n\n  /// Return a range of all basic blocks in the SCoP.\n  Region::block_range blocks() const { return R.blocks(); }\n\n  /// Return true if and only if @p BB dominates the SCoP.\n  bool isDominatedBy(const DominatorTree &DT, BasicBlock *BB) const;\n\n  /// Get the maximum depth of the loop.\n  ///\n  /// @return The maximum depth of the loop.\n  inline unsigned getMaxLoopDepth() const { return MaxLoopDepth; }\n\n  /// Return the invariant equivalence class for @p Val if any.\n  InvariantEquivClassTy *lookupInvariantEquivClass(Value *Val);\n\n  /// Return the set of invariant accesses.\n  InvariantEquivClassesTy &getInvariantAccesses() {\n    return InvariantEquivClasses;\n  }\n\n  /// Check if the scop has any invariant access.\n  bool hasInvariantAccesses() { return !InvariantEquivClasses.empty(); }\n\n  /// Mark the SCoP as optimized by the scheduler.\n  void markAsOptimized() { IsOptimized = true; }\n\n  /// Check if the SCoP has been optimized by the scheduler.\n  bool isOptimized() const { return IsOptimized; }\n\n  /// Mark the SCoP to be skipped by ScopPass passes.\n  void markAsToBeSkipped() { SkipScop = true; }\n\n  /// Check if the SCoP is to be skipped by ScopPass passes.\n  bool isToBeSkipped() const { return SkipScop; }\n\n  /// Return the ID of the Scop\n  int getID() const { return ID; }\n\n  /// Get the name of the entry and exit blocks of this Scop.\n  ///\n  /// These along with the function name can uniquely identify a Scop.\n  ///\n  /// @return std::pair whose first element is the entry name & second element\n  ///         is the exit name.\n  std::pair<std::string, std::string> getEntryExitStr() const;\n\n  /// Get the name of this Scop.\n  std::string getNameStr() const;\n\n  /// Get the constraint on parameter of this Scop.\n  ///\n  /// @return The constraint on parameter of this Scop.\n  isl::set getContext() const;\n\n  /// Return the context where execution behavior is defined. Might return\n  /// nullptr.\n  isl::set getDefinedBehaviorContext() const { return DefinedBehaviorContext; }\n\n  /// Return the define behavior context, or if not available, its approximation\n  /// from all other contexts.\n  isl::set getBestKnownDefinedBehaviorContext() const {\n    if (DefinedBehaviorContext)\n      return DefinedBehaviorContext;\n\n    return Context.intersect_params(AssumedContext).subtract(InvalidContext);\n  }\n\n  /// Return space of isl context parameters.\n  ///\n  /// Returns the set of context parameters that are currently constrained. In\n  /// case the full set of parameters is needed, see @getFullParamSpace.\n  isl::space getParamSpace() const;\n\n  /// Return the full space of parameters.\n  ///\n  /// getParamSpace will only return the parameters of the context that are\n  /// actually constrained, whereas getFullParamSpace will return all\n  //  parameters. This is useful in cases, where we need to ensure all\n  //  parameters are available, as certain isl functions will abort if this is\n  //  not the case.\n  isl::space getFullParamSpace() const;\n\n  /// Get the assumed context for this Scop.\n  ///\n  /// @return The assumed context of this Scop.\n  isl::set getAssumedContext() const;\n\n  /// Return true if the optimized SCoP can be executed.\n  ///\n  /// In addition to the runtime check context this will also utilize the domain\n  /// constraints to decide it the optimized version can actually be executed.\n  ///\n  /// @returns True if the optimized SCoP can be executed.\n  bool hasFeasibleRuntimeContext() const;\n\n  /// Check if the assumption in @p Set is trivial or not.\n  ///\n  /// @param Set  The relations between parameters that are assumed to hold.\n  /// @param Sign Enum to indicate if the assumptions in @p Set are positive\n  ///             (needed/assumptions) or negative (invalid/restrictions).\n  ///\n  /// @returns True if the assumption @p Set is not trivial.\n  bool isEffectiveAssumption(isl::set Set, AssumptionSign Sign);\n\n  /// Track and report an assumption.\n  ///\n  /// Use 'clang -Rpass-analysis=polly-scops' or 'opt\n  /// -pass-remarks-analysis=polly-scops' to output the assumptions.\n  ///\n  /// @param Kind The assumption kind describing the underlying cause.\n  /// @param Set  The relations between parameters that are assumed to hold.\n  /// @param Loc  The location in the source that caused this assumption.\n  /// @param Sign Enum to indicate if the assumptions in @p Set are positive\n  ///             (needed/assumptions) or negative (invalid/restrictions).\n  /// @param BB   The block in which this assumption was taken. Used to\n  ///             calculate hotness when emitting remark.\n  ///\n  /// @returns True if the assumption is not trivial.\n  bool trackAssumption(AssumptionKind Kind, isl::set Set, DebugLoc Loc,\n                       AssumptionSign Sign, BasicBlock *BB);\n\n  /// Add the conditions from @p Set (or subtract them if @p Sign is\n  /// AS_RESTRICTION) to the defined behaviour context.\n  void intersectDefinedBehavior(isl::set Set, AssumptionSign Sign);\n\n  /// Add assumptions to assumed context.\n  ///\n  /// The assumptions added will be assumed to hold during the execution of the\n  /// scop. However, as they are generally not statically provable, at code\n  /// generation time run-time checks will be generated that ensure the\n  /// assumptions hold.\n  ///\n  /// WARNING: We currently exploit in simplifyAssumedContext the knowledge\n  ///          that assumptions do not change the set of statement instances\n  ///          executed.\n  ///\n  /// @param Kind The assumption kind describing the underlying cause.\n  /// @param Set  The relations between parameters that are assumed to hold.\n  /// @param Loc  The location in the source that caused this assumption.\n  /// @param Sign Enum to indicate if the assumptions in @p Set are positive\n  ///             (needed/assumptions) or negative (invalid/restrictions).\n  /// @param BB   The block in which this assumption was taken. Used to\n  ///             calculate hotness when emitting remark.\n  /// @param RTC  Does the assumption require a runtime check?\n  void addAssumption(AssumptionKind Kind, isl::set Set, DebugLoc Loc,\n                     AssumptionSign Sign, BasicBlock *BB, bool RTC = true);\n\n  /// Mark the scop as invalid.\n  ///\n  /// This method adds an assumption to the scop that is always invalid. As a\n  /// result, the scop will not be optimized later on. This function is commonly\n  /// called when a condition makes it impossible (or too compile time\n  /// expensive) to process this scop any further.\n  ///\n  /// @param Kind The assumption kind describing the underlying cause.\n  /// @param Loc  The location in the source that triggered .\n  /// @param BB   The BasicBlock where it was triggered.\n  void invalidate(AssumptionKind Kind, DebugLoc Loc, BasicBlock *BB = nullptr);\n\n  /// Get the invalid context for this Scop.\n  ///\n  /// @return The invalid context of this Scop.\n  isl::set getInvalidContext() const;\n\n  /// Return true if and only if the InvalidContext is trivial (=empty).\n  bool hasTrivialInvalidContext() const { return InvalidContext.is_empty(); }\n\n  /// Return all alias groups for this SCoP.\n  const MinMaxVectorPairVectorTy &getAliasGroups() const {\n    return MinMaxAliasGroups;\n  }\n\n  void addAliasGroup(MinMaxVectorTy &MinMaxAccessesReadWrite,\n                     MinMaxVectorTy &MinMaxAccessesReadOnly) {\n    MinMaxAliasGroups.emplace_back();\n    MinMaxAliasGroups.back().first = MinMaxAccessesReadWrite;\n    MinMaxAliasGroups.back().second = MinMaxAccessesReadOnly;\n  }\n\n  /// Remove statements from the list of scop statements.\n  ///\n  /// @param ShouldDelete  A function that returns true if the statement passed\n  ///                      to it should be deleted.\n  /// @param AfterHoisting If true, also remove from data access lists.\n  ///                      These lists are filled during\n  ///                      ScopBuilder::buildAccessRelations. Therefore, if this\n  ///                      method is called before buildAccessRelations, false\n  ///                      must be passed.\n  void removeStmts(function_ref<bool(ScopStmt &)> ShouldDelete,\n                   bool AfterHoisting = true);\n\n  /// Get an isl string representing the context.\n  std::string getContextStr() const;\n\n  /// Get an isl string representing the assumed context.\n  std::string getAssumedContextStr() const;\n\n  /// Get an isl string representing the invalid context.\n  std::string getInvalidContextStr() const;\n\n  /// Return the list of ScopStmts that represent the given @p BB.\n  ArrayRef<ScopStmt *> getStmtListFor(BasicBlock *BB) const;\n\n  /// Get the statement to put a PHI WRITE into.\n  ///\n  /// @param U The operand of a PHINode.\n  ScopStmt *getIncomingStmtFor(const Use &U) const;\n\n  /// Return the last statement representing @p BB.\n  ///\n  /// Of the sequence of statements that represent a @p BB, this is the last one\n  /// to be executed. It is typically used to determine which instruction to add\n  /// a MemoryKind::PHI WRITE to. For this purpose, it is not strictly required\n  /// to be executed last, only that the incoming value is available in it.\n  ScopStmt *getLastStmtFor(BasicBlock *BB) const;\n\n  /// Return the ScopStmts that represents the Region @p R, or nullptr if\n  ///        it is not represented by any statement in this Scop.\n  ArrayRef<ScopStmt *> getStmtListFor(Region *R) const;\n\n  /// Return the ScopStmts that represents @p RN; can return nullptr if\n  ///        the RegionNode is not within the SCoP or has been removed due to\n  ///        simplifications.\n  ArrayRef<ScopStmt *> getStmtListFor(RegionNode *RN) const;\n\n  /// Return the ScopStmt an instruction belongs to, or nullptr if it\n  ///        does not belong to any statement in this Scop.\n  ScopStmt *getStmtFor(Instruction *Inst) const {\n    return InstStmtMap.lookup(Inst);\n  }\n\n  /// Return the number of statements in the SCoP.\n  size_t getSize() const { return Stmts.size(); }\n\n  /// @name Statements Iterators\n  ///\n  /// These iterators iterate over all statements of this Scop.\n  //@{\n  using iterator = StmtSet::iterator;\n  using const_iterator = StmtSet::const_iterator;\n\n  iterator begin() { return Stmts.begin(); }\n  iterator end() { return Stmts.end(); }\n  const_iterator begin() const { return Stmts.begin(); }\n  const_iterator end() const { return Stmts.end(); }\n\n  using reverse_iterator = StmtSet::reverse_iterator;\n  using const_reverse_iterator = StmtSet::const_reverse_iterator;\n\n  reverse_iterator rbegin() { return Stmts.rbegin(); }\n  reverse_iterator rend() { return Stmts.rend(); }\n  const_reverse_iterator rbegin() const { return Stmts.rbegin(); }\n  const_reverse_iterator rend() const { return Stmts.rend(); }\n  //@}\n\n  /// Return the set of required invariant loads.\n  const InvariantLoadsSetTy &getRequiredInvariantLoads() const {\n    return DC.RequiredILS;\n  }\n\n  /// Add @p LI to the set of required invariant loads.\n  void addRequiredInvariantLoad(LoadInst *LI) { DC.RequiredILS.insert(LI); }\n\n  /// Return the set of boxed (thus overapproximated) loops.\n  const BoxedLoopsSetTy &getBoxedLoops() const { return DC.BoxedLoopsSet; }\n\n  /// Return true if and only if @p R is a non-affine subregion.\n  bool isNonAffineSubRegion(const Region *R) {\n    return DC.NonAffineSubRegionSet.count(R);\n  }\n\n  const MapInsnToMemAcc &getInsnToMemAccMap() const { return DC.InsnToMemAcc; }\n\n  /// Return the (possibly new) ScopArrayInfo object for @p Access.\n  ///\n  /// @param ElementType The type of the elements stored in this array.\n  /// @param Kind        The kind of the array info object.\n  /// @param BaseName    The optional name of this memory reference.\n  ScopArrayInfo *getOrCreateScopArrayInfo(Value *BasePtr, Type *ElementType,\n                                          ArrayRef<const SCEV *> Sizes,\n                                          MemoryKind Kind,\n                                          const char *BaseName = nullptr);\n\n  /// Create an array and return the corresponding ScopArrayInfo object.\n  ///\n  /// @param ElementType The type of the elements stored in this array.\n  /// @param BaseName    The name of this memory reference.\n  /// @param Sizes       The sizes of dimensions.\n  ScopArrayInfo *createScopArrayInfo(Type *ElementType,\n                                     const std::string &BaseName,\n                                     const std::vector<unsigned> &Sizes);\n\n  /// Return the cached ScopArrayInfo object for @p BasePtr.\n  ///\n  /// @param BasePtr   The base pointer the object has been stored for.\n  /// @param Kind      The kind of array info object.\n  ///\n  /// @returns The ScopArrayInfo pointer or NULL if no such pointer is\n  ///          available.\n  ScopArrayInfo *getScopArrayInfoOrNull(Value *BasePtr, MemoryKind Kind);\n\n  /// Return the cached ScopArrayInfo object for @p BasePtr.\n  ///\n  /// @param BasePtr   The base pointer the object has been stored for.\n  /// @param Kind      The kind of array info object.\n  ///\n  /// @returns The ScopArrayInfo pointer (may assert if no such pointer is\n  ///          available).\n  ScopArrayInfo *getScopArrayInfo(Value *BasePtr, MemoryKind Kind);\n\n  /// Invalidate ScopArrayInfo object for base address.\n  ///\n  /// @param BasePtr The base pointer of the ScopArrayInfo object to invalidate.\n  /// @param Kind    The Kind of the ScopArrayInfo object.\n  void invalidateScopArrayInfo(Value *BasePtr, MemoryKind Kind) {\n    auto It = ScopArrayInfoMap.find(std::make_pair(BasePtr, Kind));\n    if (It == ScopArrayInfoMap.end())\n      return;\n    ScopArrayInfoSet.remove(It->second.get());\n    ScopArrayInfoMap.erase(It);\n  }\n\n  /// Set new isl context.\n  void setContext(isl::set NewContext);\n\n  /// Update maximal loop depth. If @p Depth is smaller than current value,\n  /// then maximal loop depth is not updated.\n  void updateMaxLoopDepth(unsigned Depth) {\n    MaxLoopDepth = std::max(MaxLoopDepth, Depth);\n  }\n\n  /// Align the parameters in the statement to the scop context\n  void realignParams();\n\n  /// Return true if this SCoP can be profitably optimized.\n  ///\n  /// @param ScalarsAreUnprofitable Never consider statements with scalar writes\n  ///                               as profitably optimizable.\n  ///\n  /// @return Whether this SCoP can be profitably optimized.\n  bool isProfitable(bool ScalarsAreUnprofitable) const;\n\n  /// Return true if the SCoP contained at least one error block.\n  bool hasErrorBlock() const { return HasErrorBlock; }\n\n  /// Notify SCoP that it contains an error block\n  void notifyErrorBlock() { HasErrorBlock = true; }\n\n  /// Return true if the underlying region has a single exiting block.\n  bool hasSingleExitEdge() const { return HasSingleExitEdge; }\n\n  /// Print the static control part.\n  ///\n  /// @param OS The output stream the static control part is printed to.\n  /// @param PrintInstructions Whether to print the statement's instructions as\n  ///                          well.\n  void print(raw_ostream &OS, bool PrintInstructions) const;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print the ScopStmt to stderr.\n  void dump() const;\n#endif\n\n  /// Get the isl context of this static control part.\n  ///\n  /// @return The isl context of this static control part.\n  isl::ctx getIslCtx() const;\n\n  /// Directly return the shared_ptr of the context.\n  const std::shared_ptr<isl_ctx> &getSharedIslCtx() const { return IslCtx; }\n\n  /// Compute the isl representation for the SCEV @p E\n  ///\n  /// @param E  The SCEV that should be translated.\n  /// @param BB An (optional) basic block in which the isl_pw_aff is computed.\n  ///           SCEVs known to not reference any loops in the SCoP can be\n  ///           passed without a @p BB.\n  /// @param NonNegative Flag to indicate the @p E has to be non-negative.\n  ///\n  /// Note that this function will always return a valid isl_pw_aff. However, if\n  /// the translation of @p E was deemed to complex the SCoP is invalidated and\n  /// a dummy value of appropriate dimension is returned. This allows to bail\n  /// for complex cases without \"error handling code\" needed on the users side.\n  PWACtx getPwAff(const SCEV *E, BasicBlock *BB = nullptr,\n                  bool NonNegative = false,\n                  RecordedAssumptionsTy *RecordedAssumptions = nullptr);\n\n  /// Compute the isl representation for the SCEV @p E\n  ///\n  /// This function is like @see Scop::getPwAff() but strips away the invalid\n  /// domain part associated with the piecewise affine function.\n  isl::pw_aff\n  getPwAffOnly(const SCEV *E, BasicBlock *BB = nullptr,\n               RecordedAssumptionsTy *RecordedAssumptions = nullptr);\n\n  /// Check if an <nsw> AddRec for the loop L is cached.\n  bool hasNSWAddRecForLoop(Loop *L) { return Affinator.hasNSWAddRecForLoop(L); }\n\n  /// Return the domain of @p Stmt.\n  ///\n  /// @param Stmt The statement for which the conditions should be returned.\n  isl::set getDomainConditions(const ScopStmt *Stmt) const;\n\n  /// Return the domain of @p BB.\n  ///\n  /// @param BB The block for which the conditions should be returned.\n  isl::set getDomainConditions(BasicBlock *BB) const;\n\n  /// Return the domain of @p BB. If it does not exist, create an empty one.\n  isl::set &getOrInitEmptyDomain(BasicBlock *BB) { return DomainMap[BB]; }\n\n  /// Check if domain is determined for @p BB.\n  bool isDomainDefined(BasicBlock *BB) const { return DomainMap.count(BB) > 0; }\n\n  /// Set domain for @p BB.\n  void setDomain(BasicBlock *BB, isl::set &Domain) { DomainMap[BB] = Domain; }\n\n  /// Get a union set containing the iteration domains of all statements.\n  isl::union_set getDomains() const;\n\n  /// Get a union map of all may-writes performed in the SCoP.\n  isl::union_map getMayWrites();\n\n  /// Get a union map of all must-writes performed in the SCoP.\n  isl::union_map getMustWrites();\n\n  /// Get a union map of all writes performed in the SCoP.\n  isl::union_map getWrites();\n\n  /// Get a union map of all reads performed in the SCoP.\n  isl::union_map getReads();\n\n  /// Get a union map of all memory accesses performed in the SCoP.\n  isl::union_map getAccesses();\n\n  /// Get a union map of all memory accesses performed in the SCoP.\n  ///\n  /// @param Array The array to which the accesses should belong.\n  isl::union_map getAccesses(ScopArrayInfo *Array);\n\n  /// Get the schedule of all the statements in the SCoP.\n  ///\n  /// @return The schedule of all the statements in the SCoP, if the schedule of\n  /// the Scop does not contain extension nodes, and nullptr, otherwise.\n  isl::union_map getSchedule() const;\n\n  /// Get a schedule tree describing the schedule of all statements.\n  isl::schedule getScheduleTree() const;\n\n  /// Update the current schedule\n  ///\n  /// NewSchedule The new schedule (given as a flat union-map).\n  void setSchedule(isl::union_map NewSchedule);\n\n  /// Update the current schedule\n  ///\n  /// NewSchedule The new schedule (given as schedule tree).\n  void setScheduleTree(isl::schedule NewSchedule);\n\n  /// Whether the schedule is the original schedule as derived from the CFG by\n  /// ScopBuilder.\n  bool isOriginalSchedule() const { return !ScheduleModified; }\n\n  /// Intersects the domains of all statements in the SCoP.\n  ///\n  /// @return true if a change was made\n  bool restrictDomains(isl::union_set Domain);\n\n  /// Get the depth of a loop relative to the outermost loop in the Scop.\n  ///\n  /// This will return\n  ///    0 if @p L is an outermost loop in the SCoP\n  ///   >0 for other loops in the SCoP\n  ///   -1 if @p L is nullptr or there is no outermost loop in the SCoP\n  int getRelativeLoopDepth(const Loop *L) const;\n\n  /// Find the ScopArrayInfo associated with an isl Id\n  ///        that has name @p Name.\n  ScopArrayInfo *getArrayInfoByName(const std::string BaseName);\n\n  /// Simplify the SCoP representation.\n  ///\n  /// @param AfterHoisting Whether it is called after invariant load hoisting.\n  ///                      When true, also removes statements without\n  ///                      side-effects.\n  void simplifySCoP(bool AfterHoisting);\n\n  /// Get the next free array index.\n  ///\n  /// This function returns a unique index which can be used to identify an\n  /// array.\n  long getNextArrayIdx() { return ArrayIdx++; }\n\n  /// Get the next free statement index.\n  ///\n  /// This function returns a unique index which can be used to identify a\n  /// statement.\n  long getNextStmtIdx() { return StmtIdx++; }\n\n  /// Get the representing SCEV for @p S if applicable, otherwise @p S.\n  ///\n  /// Invariant loads of the same location are put in an equivalence class and\n  /// only one of them is chosen as a representing element that will be\n  /// modeled as a parameter. The others have to be normalized, i.e.,\n  /// replaced by the representing element of their equivalence class, in order\n  /// to get the correct parameter value, e.g., in the SCEVAffinator.\n  ///\n  /// @param S The SCEV to normalize.\n  ///\n  /// @return The representing SCEV for invariant loads or @p S if none.\n  const SCEV *getRepresentingInvariantLoadSCEV(const SCEV *S) const;\n\n  /// Return the MemoryAccess that writes an llvm::Value, represented by a\n  /// ScopArrayInfo.\n  ///\n  /// There can be at most one such MemoryAccess per llvm::Value in the SCoP.\n  /// Zero is possible for read-only values.\n  MemoryAccess *getValueDef(const ScopArrayInfo *SAI) const;\n\n  /// Return all MemoryAccesses that us an llvm::Value, represented by a\n  /// ScopArrayInfo.\n  ArrayRef<MemoryAccess *> getValueUses(const ScopArrayInfo *SAI) const;\n\n  /// Return the MemoryAccess that represents an llvm::PHINode.\n  ///\n  /// ExitPHIs's PHINode is not within the SCoPs. This function returns nullptr\n  /// for them.\n  MemoryAccess *getPHIRead(const ScopArrayInfo *SAI) const;\n\n  /// Return all MemoryAccesses for all incoming statements of a PHINode,\n  /// represented by a ScopArrayInfo.\n  ArrayRef<MemoryAccess *> getPHIIncomings(const ScopArrayInfo *SAI) const;\n\n  /// Return whether @p Inst has a use outside of this SCoP.\n  bool isEscaping(Instruction *Inst);\n\n  struct ScopStatistics {\n    int NumAffineLoops = 0;\n    int NumBoxedLoops = 0;\n\n    int NumValueWrites = 0;\n    int NumValueWritesInLoops = 0;\n    int NumPHIWrites = 0;\n    int NumPHIWritesInLoops = 0;\n    int NumSingletonWrites = 0;\n    int NumSingletonWritesInLoops = 0;\n  };\n\n  /// Collect statistic about this SCoP.\n  ///\n  /// These are most commonly used for LLVM's static counters (Statistic.h) in\n  /// various places. If statistics are disabled, only zeros are returned to\n  /// avoid the overhead.\n  ScopStatistics getStatistics() const;\n};\n\n/// Print Scop scop to raw_ostream OS.\nraw_ostream &operator<<(raw_ostream &OS, const Scop &scop);\n\n/// The legacy pass manager's analysis pass to compute scop information\n///        for a region.\nclass ScopInfoRegionPass : public RegionPass {\n  /// The Scop pointer which is used to construct a Scop.\n  std::unique_ptr<Scop> S;\n\npublic:\n  static char ID; // Pass identification, replacement for typeid\n\n  ScopInfoRegionPass() : RegionPass(ID) {}\n  ~ScopInfoRegionPass() override = default;\n\n  /// Build Scop object, the Polly IR of static control\n  ///        part for the current SESE-Region.\n  ///\n  /// @return If the current region is a valid for a static control part,\n  ///         return the Polly IR representing this static control part,\n  ///         return null otherwise.\n  Scop *getScop() { return S.get(); }\n  const Scop *getScop() const { return S.get(); }\n\n  /// Calculate the polyhedral scop information for a given Region.\n  bool runOnRegion(Region *R, RGPassManager &RGM) override;\n\n  void releaseMemory() override { S.reset(); }\n\n  void print(raw_ostream &O, const Module *M = nullptr) const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\nclass ScopInfo {\npublic:\n  using RegionToScopMapTy = MapVector<Region *, std::unique_ptr<Scop>>;\n  using reverse_iterator = RegionToScopMapTy::reverse_iterator;\n  using const_reverse_iterator = RegionToScopMapTy::const_reverse_iterator;\n  using iterator = RegionToScopMapTy::iterator;\n  using const_iterator = RegionToScopMapTy::const_iterator;\n\nprivate:\n  /// A map of Region to its Scop object containing\n  ///        Polly IR of static control part.\n  RegionToScopMapTy RegionToScopMap;\n  const DataLayout &DL;\n  ScopDetection &SD;\n  ScalarEvolution &SE;\n  LoopInfo &LI;\n  AAResults &AA;\n  DominatorTree &DT;\n  AssumptionCache &AC;\n  OptimizationRemarkEmitter &ORE;\n\npublic:\n  ScopInfo(const DataLayout &DL, ScopDetection &SD, ScalarEvolution &SE,\n           LoopInfo &LI, AAResults &AA, DominatorTree &DT, AssumptionCache &AC,\n           OptimizationRemarkEmitter &ORE);\n\n  /// Get the Scop object for the given Region.\n  ///\n  /// @return If the given region is the maximal region within a scop, return\n  ///         the scop object. If the given region is a subregion, return a\n  ///         nullptr. Top level region containing the entry block of a function\n  ///         is not considered in the scop creation.\n  Scop *getScop(Region *R) const {\n    auto MapIt = RegionToScopMap.find(R);\n    if (MapIt != RegionToScopMap.end())\n      return MapIt->second.get();\n    return nullptr;\n  }\n\n  /// Recompute the Scop-Information for a function.\n  ///\n  /// This invalidates any iterators.\n  void recompute();\n\n  /// Handle invalidation explicitly\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\n  iterator begin() { return RegionToScopMap.begin(); }\n  iterator end() { return RegionToScopMap.end(); }\n  const_iterator begin() const { return RegionToScopMap.begin(); }\n  const_iterator end() const { return RegionToScopMap.end(); }\n  reverse_iterator rbegin() { return RegionToScopMap.rbegin(); }\n  reverse_iterator rend() { return RegionToScopMap.rend(); }\n  const_reverse_iterator rbegin() const { return RegionToScopMap.rbegin(); }\n  const_reverse_iterator rend() const { return RegionToScopMap.rend(); }\n  bool empty() const { return RegionToScopMap.empty(); }\n};\n\nstruct ScopInfoAnalysis : public AnalysisInfoMixin<ScopInfoAnalysis> {\n  static AnalysisKey Key;\n\n  using Result = ScopInfo;\n\n  Result run(Function &, FunctionAnalysisManager &);\n};\n\nstruct ScopInfoPrinterPass : public PassInfoMixin<ScopInfoPrinterPass> {\n  ScopInfoPrinterPass(raw_ostream &OS) : Stream(OS) {}\n\n  PreservedAnalyses run(Function &, FunctionAnalysisManager &);\n\n  raw_ostream &Stream;\n};\n\n//===----------------------------------------------------------------------===//\n/// The legacy pass manager's analysis pass to compute scop information\n///        for the whole function.\n///\n/// This pass will maintain a map of the maximal region within a scop to its\n/// scop object for all the feasible scops present in a function.\n/// This pass is an alternative to the ScopInfoRegionPass in order to avoid a\n/// region pass manager.\nclass ScopInfoWrapperPass : public FunctionPass {\n  std::unique_ptr<ScopInfo> Result;\n\npublic:\n  ScopInfoWrapperPass() : FunctionPass(ID) {}\n  ~ScopInfoWrapperPass() override = default;\n\n  static char ID; // Pass identification, replacement for typeid\n\n  ScopInfo *getSI() { return Result.get(); }\n  const ScopInfo *getSI() const { return Result.get(); }\n\n  /// Calculate all the polyhedral scops for a given function.\n  bool runOnFunction(Function &F) override;\n\n  void releaseMemory() override { Result.reset(); }\n\n  void print(raw_ostream &O, const Module *M = nullptr) const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n} // end namespace polly\n\n#endif // POLLY_SCOPINFO_H\n"}, "85": {"id": 85, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopPass.h", "content": "//===--------- ScopPass.h - Pass for Static Control Parts --------*-C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the ScopPass class.  ScopPasses are just RegionPasses,\n// except they operate on Polly IR (Scop and ScopStmt) built by ScopInfo Pass.\n// Because they operate on Polly IR, not the LLVM IR, ScopPasses are not allowed\n// to modify the LLVM IR. Due to this limitation, the ScopPass class takes\n// care of declaring that no LLVM passes are invalidated.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_SCOP_PASS_H\n#define POLLY_SCOP_PASS_H\n\n#include \"polly/ScopInfo.h\"\n#include \"llvm/ADT/PriorityWorklist.h\"\n#include \"llvm/Analysis/RegionPass.h\"\n#include \"llvm/Analysis/TargetTransformInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/PassManagerImpl.h\"\n\nnamespace polly {\nusing llvm::AllAnalysesOn;\nusing llvm::AnalysisManager;\nusing llvm::DominatorTreeAnalysis;\nusing llvm::InnerAnalysisManagerProxy;\nusing llvm::LoopAnalysis;\nusing llvm::OuterAnalysisManagerProxy;\nusing llvm::PassManager;\nusing llvm::RegionInfoAnalysis;\nusing llvm::ScalarEvolutionAnalysis;\nusing llvm::SmallPriorityWorklist;\nusing llvm::TargetIRAnalysis;\nusing llvm::TargetTransformInfo;\n\nclass Scop;\nclass SPMUpdater;\nstruct ScopStandardAnalysisResults;\n\nusing ScopAnalysisManager =\n    AnalysisManager<Scop, ScopStandardAnalysisResults &>;\nusing ScopAnalysisManagerFunctionProxy =\n    InnerAnalysisManagerProxy<ScopAnalysisManager, Function>;\nusing FunctionAnalysisManagerScopProxy =\n    OuterAnalysisManagerProxy<FunctionAnalysisManager, Scop,\n                              ScopStandardAnalysisResults &>;\n} // namespace polly\n\nnamespace llvm {\nusing polly::Scop;\nusing polly::ScopAnalysisManager;\nusing polly::ScopAnalysisManagerFunctionProxy;\nusing polly::ScopInfo;\nusing polly::ScopStandardAnalysisResults;\nusing polly::SPMUpdater;\n\ntemplate <>\nclass InnerAnalysisManagerProxy<ScopAnalysisManager, Function>::Result {\npublic:\n  explicit Result(ScopAnalysisManager &InnerAM, ScopInfo &SI)\n      : InnerAM(&InnerAM), SI(&SI) {}\n  Result(Result &&R) : InnerAM(std::move(R.InnerAM)), SI(R.SI) {\n    R.InnerAM = nullptr;\n  }\n  Result &operator=(Result &&RHS) {\n    InnerAM = RHS.InnerAM;\n    SI = RHS.SI;\n    RHS.InnerAM = nullptr;\n    return *this;\n  }\n  ~Result() {\n    if (!InnerAM)\n      return;\n    InnerAM->clear();\n  }\n\n  ScopAnalysisManager &getManager() { return *InnerAM; }\n\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\nprivate:\n  ScopAnalysisManager *InnerAM;\n  ScopInfo *SI;\n};\n\n// A partial specialization of the require analysis template pass to handle\n// extra parameters\ntemplate <typename AnalysisT>\nstruct RequireAnalysisPass<AnalysisT, Scop, ScopAnalysisManager,\n                           ScopStandardAnalysisResults &, SPMUpdater &>\n    : PassInfoMixin<\n          RequireAnalysisPass<AnalysisT, Scop, ScopAnalysisManager,\n                              ScopStandardAnalysisResults &, SPMUpdater &>> {\n  PreservedAnalyses run(Scop &L, ScopAnalysisManager &AM,\n                        ScopStandardAnalysisResults &AR, SPMUpdater &) {\n    (void)AM.template getResult<AnalysisT>(L, AR);\n    return PreservedAnalyses::all();\n  }\n};\n\ntemplate <>\nInnerAnalysisManagerProxy<ScopAnalysisManager, Function>::Result\nInnerAnalysisManagerProxy<ScopAnalysisManager, Function>::run(\n    Function &F, FunctionAnalysisManager &FAM);\n\ntemplate <>\nPreservedAnalyses\nPassManager<Scop, ScopAnalysisManager, ScopStandardAnalysisResults &,\n            SPMUpdater &>::run(Scop &InitialS, ScopAnalysisManager &AM,\n                               ScopStandardAnalysisResults &, SPMUpdater &);\nextern template class PassManager<Scop, ScopAnalysisManager,\n                                  ScopStandardAnalysisResults &, SPMUpdater &>;\nextern template class InnerAnalysisManagerProxy<ScopAnalysisManager, Function>;\nextern template class OuterAnalysisManagerProxy<FunctionAnalysisManager, Scop,\n                                                ScopStandardAnalysisResults &>;\n} // namespace llvm\n\nnamespace polly {\n\ntemplate <typename AnalysisManagerT, typename IRUnitT, typename... ExtraArgTs>\nclass OwningInnerAnalysisManagerProxy\n    : public InnerAnalysisManagerProxy<AnalysisManagerT, IRUnitT> {\npublic:\n  OwningInnerAnalysisManagerProxy()\n      : InnerAnalysisManagerProxy<AnalysisManagerT, IRUnitT>(InnerAM) {}\n  using Result = typename InnerAnalysisManagerProxy<AnalysisManagerT, IRUnitT,\n                                                    ExtraArgTs...>::Result;\n  Result run(IRUnitT &IR, AnalysisManager<IRUnitT, ExtraArgTs...> &AM,\n             ExtraArgTs...) {\n    return Result(InnerAM);\n  }\n\n  AnalysisManagerT &getManager() { return InnerAM; }\n\nprivate:\n  AnalysisManagerT InnerAM;\n};\n\ntemplate <>\nOwningInnerAnalysisManagerProxy<ScopAnalysisManager, Function>::Result\nOwningInnerAnalysisManagerProxy<ScopAnalysisManager, Function>::run(\n    Function &F, FunctionAnalysisManager &FAM);\nextern template class OwningInnerAnalysisManagerProxy<ScopAnalysisManager,\n                                                      Function>;\n\nusing OwningScopAnalysisManagerFunctionProxy =\n    OwningInnerAnalysisManagerProxy<ScopAnalysisManager, Function>;\nusing ScopPassManager =\n    PassManager<Scop, ScopAnalysisManager, ScopStandardAnalysisResults &,\n                SPMUpdater &>;\n\n/// ScopPass - This class adapts the RegionPass interface to allow convenient\n/// creation of passes that operate on the Polly IR. Instead of overriding\n/// runOnRegion, subclasses override runOnScop.\nclass ScopPass : public RegionPass {\n  Scop *S;\n\nprotected:\n  explicit ScopPass(char &ID) : RegionPass(ID), S(0) {}\n\n  /// runOnScop - This method must be overloaded to perform the\n  /// desired Polyhedral transformation or analysis.\n  ///\n  virtual bool runOnScop(Scop &S) = 0;\n\n  /// Print method for SCoPs.\n  virtual void printScop(raw_ostream &OS, Scop &S) const {}\n\n  /// getAnalysisUsage - Subclasses that override getAnalysisUsage\n  /// must call this.\n  ///\n  virtual void getAnalysisUsage(AnalysisUsage &AU) const override;\n\nprivate:\n  bool runOnRegion(Region *R, RGPassManager &RGM) override;\n  void print(raw_ostream &OS, const Module *) const override;\n};\n\nstruct ScopStandardAnalysisResults {\n  DominatorTree &DT;\n  ScopInfo &SI;\n  ScalarEvolution &SE;\n  LoopInfo &LI;\n  RegionInfo &RI;\n  TargetTransformInfo &TTI;\n};\n\nclass SPMUpdater {\npublic:\n  SPMUpdater(SmallPriorityWorklist<Region *, 4> &Worklist,\n             ScopAnalysisManager &SAM)\n      : InvalidateCurrentScop(false), Worklist(Worklist), SAM(SAM) {}\n\n  bool invalidateCurrentScop() const { return InvalidateCurrentScop; }\n\n  void invalidateScop(Scop &S) {\n    if (&S == CurrentScop)\n      InvalidateCurrentScop = true;\n\n    Worklist.erase(&S.getRegion());\n    SAM.clear(S, S.getName());\n  }\n\nprivate:\n  Scop *CurrentScop;\n  bool InvalidateCurrentScop;\n  SmallPriorityWorklist<Region *, 4> &Worklist;\n  ScopAnalysisManager &SAM;\n  template <typename ScopPassT> friend class FunctionToScopPassAdaptor;\n};\n\ntemplate <typename ScopPassT>\nclass FunctionToScopPassAdaptor\n    : public PassInfoMixin<FunctionToScopPassAdaptor<ScopPassT>> {\npublic:\n  explicit FunctionToScopPassAdaptor(ScopPassT Pass) : Pass(std::move(Pass)) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM) {\n    ScopDetection &SD = AM.getResult<ScopAnalysis>(F);\n    ScopInfo &SI = AM.getResult<ScopInfoAnalysis>(F);\n    if (SI.empty()) {\n      // With no scops having been detected, no IR changes have been made and\n      // therefore all analyses are preserved. However, we must still free the\n      // Scop analysis results which may hold AssertingVH that cause an error\n      // if its value is destroyed.\n      AM.invalidate<ScopInfoAnalysis>(F);\n      AM.invalidate<ScopAnalysis>(F);\n      return PreservedAnalyses::all();\n    }\n\n    SmallPriorityWorklist<Region *, 4> Worklist;\n    for (auto &S : SI)\n      if (S.second)\n        Worklist.insert(S.first);\n\n    ScopStandardAnalysisResults AR = {AM.getResult<DominatorTreeAnalysis>(F),\n                                      AM.getResult<ScopInfoAnalysis>(F),\n                                      AM.getResult<ScalarEvolutionAnalysis>(F),\n                                      AM.getResult<LoopAnalysis>(F),\n                                      AM.getResult<RegionInfoAnalysis>(F),\n                                      AM.getResult<TargetIRAnalysis>(F)};\n\n    ScopAnalysisManager &SAM =\n        AM.getResult<ScopAnalysisManagerFunctionProxy>(F).getManager();\n\n    SPMUpdater Updater{Worklist, SAM};\n\n    while (!Worklist.empty()) {\n      Region *R = Worklist.pop_back_val();\n      if (!SD.isMaxRegionInScop(*R, /*Verifying=*/false))\n        continue;\n      Scop *scop = SI.getScop(R);\n      if (!scop)\n        continue;\n      Updater.CurrentScop = scop;\n      Updater.InvalidateCurrentScop = false;\n      PreservedAnalyses PassPA = Pass.run(*scop, SAM, AR, Updater);\n\n      SAM.invalidate(*scop, PassPA);\n      if (Updater.invalidateCurrentScop())\n        SI.recompute();\n    };\n\n    // FIXME: For the same reason as we add a BarrierNoopPass in the legacy pass\n    // manager, do not preserve any analyses. While CodeGeneration may preserve\n    // IR analyses sufficiently to process another Scop in the same function (it\n    // has to, otherwise the ScopDetection result itself would need to be\n    // invalidated), it is not sufficient for other purposes. For instance,\n    // CodeGeneration does not inform LoopInfo about new loops in the\n    // Polly-generated IR.\n    return PreservedAnalyses::none();\n  }\n\nprivate:\n  ScopPassT Pass;\n};\n\ntemplate <typename ScopPassT>\nFunctionToScopPassAdaptor<ScopPassT>\ncreateFunctionToScopPassAdaptor(ScopPassT Pass) {\n  return FunctionToScopPassAdaptor<ScopPassT>(std::move(Pass));\n}\n} // namespace polly\n\n#endif\n"}, "86": {"id": 86, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/Support/GICHelper.h", "content": "//===- Support/GICHelper.h -- Helper functions for ISL --------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Helper functions for isl objects.\n//\n//===----------------------------------------------------------------------===//\n//\n#ifndef POLLY_SUPPORT_GIC_HELPER_H\n#define POLLY_SUPPORT_GIC_HELPER_H\n\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/IR/DiagnosticInfo.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"isl/ctx.h\"\n#include \"isl/isl-noexceptions.h\"\n#include \"isl/options.h\"\n\nnamespace polly {\n\n/// Translate an llvm::APInt to an isl_val.\n///\n/// Translate the bitsequence without sign information as provided by APInt into\n/// a signed isl_val type. Depending on the value of @p IsSigned @p Int is\n/// interpreted as unsigned value or as signed value in two's complement\n/// representation.\n///\n/// Input IsSigned                 Output\n///\n///     0        0           ->    0\n///     1        0           ->    1\n///    00        0           ->    0\n///    01        0           ->    1\n///    10        0           ->    2\n///    11        0           ->    3\n///\n///     0        1           ->    0\n///     1        1           ->   -1\n///    00        1           ->    0\n///    01        1           ->    1\n///    10        1           ->   -2\n///    11        1           ->   -1\n///\n/// @param Ctx      The isl_ctx to create the isl_val in.\n/// @param Int      The integer value to translate.\n/// @param IsSigned If the APInt should be interpreted as signed or unsigned\n///                 value.\n///\n/// @return The isl_val corresponding to @p Int.\n__isl_give isl_val *isl_valFromAPInt(isl_ctx *Ctx, const llvm::APInt Int,\n                                     bool IsSigned);\n\n/// Translate an llvm::APInt to an isl::val.\n///\n/// Translate the bitsequence without sign information as provided by APInt into\n/// a signed isl::val type. Depending on the value of @p IsSigned @p Int is\n/// interpreted as unsigned value or as signed value in two's complement\n/// representation.\n///\n/// Input IsSigned                 Output\n///\n///     0        0           ->    0\n///     1        0           ->    1\n///    00        0           ->    0\n///    01        0           ->    1\n///    10        0           ->    2\n///    11        0           ->    3\n///\n///     0        1           ->    0\n///     1        1           ->   -1\n///    00        1           ->    0\n///    01        1           ->    1\n///    10        1           ->   -2\n///    11        1           ->   -1\n///\n/// @param Ctx      The isl_ctx to create the isl::val in.\n/// @param Int      The integer value to translate.\n/// @param IsSigned If the APInt should be interpreted as signed or unsigned\n///                 value.\n///\n/// @return The isl::val corresponding to @p Int.\ninline isl::val valFromAPInt(isl_ctx *Ctx, const llvm::APInt Int,\n                             bool IsSigned) {\n  return isl::manage(isl_valFromAPInt(Ctx, Int, IsSigned));\n}\n\n/// Translate isl_val to llvm::APInt.\n///\n/// This function can only be called on isl_val values which are integers.\n/// Calling this function with a non-integral rational, NaN or infinity value\n/// is not allowed.\n///\n/// As the input isl_val may be negative, the APInt that this function returns\n/// must always be interpreted as signed two's complement value. The bitwidth of\n/// the generated APInt is always the minimal bitwidth necessary to model the\n/// provided integer when interpreting the bit pattern as signed value.\n///\n/// Some example conversions are:\n///\n///   Input      Bits    Signed  Bitwidth\n///       0 ->      0         0         1\n///      -1 ->      1        -1         1\n///       1 ->     01         1         2\n///      -2 ->     10        -2         2\n///       2 ->    010         2         3\n///      -3 ->    101        -3         3\n///       3 ->    011         3         3\n///      -4 ->    100        -4         3\n///       4 ->   0100         4         4\n///\n/// @param Val The isl val to translate.\n///\n/// @return The APInt value corresponding to @p Val.\nllvm::APInt APIntFromVal(__isl_take isl_val *Val);\n\n/// Translate isl::val to llvm::APInt.\n///\n/// This function can only be called on isl::val values which are integers.\n/// Calling this function with a non-integral rational, NaN or infinity value\n/// is not allowed.\n///\n/// As the input isl::val may be negative, the APInt that this function returns\n/// must always be interpreted as signed two's complement value. The bitwidth of\n/// the generated APInt is always the minimal bitwidth necessary to model the\n/// provided integer when interpreting the bit pattern as signed value.\n///\n/// Some example conversions are:\n///\n///   Input      Bits    Signed  Bitwidth\n///       0 ->      0         0         1\n///      -1 ->      1        -1         1\n///       1 ->     01         1         2\n///      -2 ->     10        -2         2\n///       2 ->    010         2         3\n///      -3 ->    101        -3         3\n///       3 ->    011         3         3\n///      -4 ->    100        -4         3\n///       4 ->   0100         4         4\n///\n/// @param Val The isl val to translate.\n///\n/// @return The APInt value corresponding to @p Val.\ninline llvm::APInt APIntFromVal(isl::val V) {\n  return APIntFromVal(V.release());\n}\n\n/// Get c++ string from Isl objects.\n//@{\nstd::string stringFromIslObj(__isl_keep isl_map *map);\nstd::string stringFromIslObj(__isl_keep isl_union_map *umap);\nstd::string stringFromIslObj(__isl_keep isl_set *set);\nstd::string stringFromIslObj(__isl_keep isl_union_set *uset);\nstd::string stringFromIslObj(__isl_keep isl_schedule *schedule);\nstd::string stringFromIslObj(__isl_keep isl_multi_aff *maff);\nstd::string stringFromIslObj(__isl_keep isl_pw_multi_aff *pma);\nstd::string stringFromIslObj(__isl_keep isl_multi_pw_aff *mpa);\nstd::string stringFromIslObj(__isl_keep isl_union_pw_multi_aff *upma);\nstd::string stringFromIslObj(__isl_keep isl_aff *aff);\nstd::string stringFromIslObj(__isl_keep isl_pw_aff *pwaff);\nstd::string stringFromIslObj(__isl_keep isl_space *space);\n//@}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_union_map *Map) {\n  OS << polly::stringFromIslObj(Map);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_map *Map) {\n  OS << polly::stringFromIslObj(Map);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_set *Set) {\n  OS << polly::stringFromIslObj(Set);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_pw_aff *Map) {\n  OS << polly::stringFromIslObj(Map);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_pw_multi_aff *PMA) {\n  OS << polly::stringFromIslObj(PMA);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_multi_aff *MA) {\n  OS << polly::stringFromIslObj(MA);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_union_pw_multi_aff *UPMA) {\n  OS << polly::stringFromIslObj(UPMA);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_schedule *Schedule) {\n  OS << polly::stringFromIslObj(Schedule);\n  return OS;\n}\n\ninline llvm::raw_ostream &operator<<(llvm::raw_ostream &OS,\n                                     __isl_keep isl_space *Space) {\n  OS << polly::stringFromIslObj(Space);\n  return OS;\n}\n\n/// Combine Prefix, Val (or Number) and Suffix to an isl-compatible name.\n///\n/// In case @p UseInstructionNames is set, this function returns:\n///\n/// @p Prefix + \"_\" + @p Val->getName() + @p Suffix\n///\n/// otherwise\n///\n/// @p Prefix + to_string(Number) + @p Suffix\n///\n/// We ignore the value names by default, as they may change between release\n/// and debug mode and can consequently not be used when aiming for reproducible\n/// builds. However, for debugging named statements are often helpful, hence\n/// we allow their optional use.\nstd::string getIslCompatibleName(const std::string &Prefix,\n                                 const llvm::Value *Val, long Number,\n                                 const std::string &Suffix,\n                                 bool UseInstructionNames);\n\n/// Combine Prefix, Name (or Number) and Suffix to an isl-compatible name.\n///\n/// In case @p UseInstructionNames is set, this function returns:\n///\n/// @p Prefix + \"_\" + Name + @p Suffix\n///\n/// otherwise\n///\n/// @p Prefix + to_string(Number) + @p Suffix\n///\n/// We ignore @p Name by default, as they may change between release\n/// and debug mode and can consequently not be used when aiming for reproducible\n/// builds. However, for debugging named statements are often helpful, hence\n/// we allow their optional use.\nstd::string getIslCompatibleName(const std::string &Prefix,\n                                 const std::string &Middle, long Number,\n                                 const std::string &Suffix,\n                                 bool UseInstructionNames);\n\nstd::string getIslCompatibleName(const std::string &Prefix,\n                                 const std::string &Middle,\n                                 const std::string &Suffix);\n\ninline llvm::DiagnosticInfoOptimizationBase &\noperator<<(llvm::DiagnosticInfoOptimizationBase &OS,\n           const isl::union_map &Obj) {\n  OS << Obj.to_str();\n  return OS;\n}\n\n/// Scope guard for code that allows arbitrary isl function to return an error\n/// if the max-operations quota exceeds.\n///\n/// This allows to opt-in code sections that have known long executions times.\n/// code not in a hot path can continue to assume that no unexpected error\n/// occurs.\n///\n/// This is typically used inside a nested IslMaxOperationsGuard scope. The\n/// IslMaxOperationsGuard defines the number of allowed base operations for some\n/// code, IslQuotaScope defines where it is allowed to return an error result.\nclass IslQuotaScope {\n  isl_ctx *IslCtx;\n  int OldOnError;\n\npublic:\n  IslQuotaScope() : IslCtx(nullptr) {}\n  IslQuotaScope(const IslQuotaScope &) = delete;\n  IslQuotaScope(IslQuotaScope &&Other)\n      : IslCtx(Other.IslCtx), OldOnError(Other.OldOnError) {\n    Other.IslCtx = nullptr;\n  }\n  const IslQuotaScope &operator=(IslQuotaScope &&Other) {\n    std::swap(this->IslCtx, Other.IslCtx);\n    std::swap(this->OldOnError, Other.OldOnError);\n    return *this;\n  }\n\n  /// Enter a quota-aware scope.\n  ///\n  /// Should not be used directly. Use IslMaxOperationsGuard::enter() instead.\n  explicit IslQuotaScope(isl_ctx *IslCtx, unsigned long LocalMaxOps)\n      : IslCtx(IslCtx) {\n    assert(IslCtx);\n    assert(isl_ctx_get_max_operations(IslCtx) == 0 && \"Incorrect nesting\");\n    if (LocalMaxOps == 0) {\n      this->IslCtx = nullptr;\n      return;\n    }\n\n    OldOnError = isl_options_get_on_error(IslCtx);\n    isl_options_set_on_error(IslCtx, ISL_ON_ERROR_CONTINUE);\n    isl_ctx_reset_error(IslCtx);\n    isl_ctx_set_max_operations(IslCtx, LocalMaxOps);\n  }\n\n  ~IslQuotaScope() {\n    if (!IslCtx)\n      return;\n\n    assert(isl_ctx_get_max_operations(IslCtx) > 0 && \"Incorrect nesting\");\n    assert(isl_options_get_on_error(IslCtx) == ISL_ON_ERROR_CONTINUE &&\n           \"Incorrect nesting\");\n    isl_ctx_set_max_operations(IslCtx, 0);\n    isl_options_set_on_error(IslCtx, OldOnError);\n  }\n\n  /// Return whether the current quota has exceeded.\n  bool hasQuotaExceeded() const {\n    if (!IslCtx)\n      return false;\n\n    return isl_ctx_last_error(IslCtx) == isl_error_quota;\n  }\n};\n\n/// Scoped limit of ISL operations.\n///\n/// Limits the number of ISL operations during the lifetime of this object. The\n/// idea is to use this as an RAII guard for the scope where the code is aware\n/// that ISL can return errors even when all input is valid. After leaving the\n/// scope, it will return to the error setting as it was before. That also means\n/// that the error setting should not be changed while in that scope.\n///\n/// Such scopes are not allowed to be nested because the previous operations\n/// counter cannot be reset to the previous state, or one that adds the\n/// operations while being in the nested scope. Use therefore is only allowed\n/// while currently a no operations-limit is active.\nclass IslMaxOperationsGuard {\nprivate:\n  /// The ISL context to set the operations limit.\n  ///\n  /// If set to nullptr, there is no need for any action at the end of the\n  /// scope.\n  isl_ctx *IslCtx;\n\n  /// Maximum number of operations for the scope.\n  unsigned long LocalMaxOps;\n\n  /// When AutoEnter is enabled, holds the IslQuotaScope object.\n  IslQuotaScope TopLevelScope;\n\npublic:\n  /// Enter a max operations scope.\n  ///\n  /// @param IslCtx      The ISL context to set the operations limit for.\n  /// @param LocalMaxOps Maximum number of operations allowed in the\n  ///                    scope. If set to zero, no operations limit is enforced.\n  /// @param AutoEnter   If true, automatically enters an IslQuotaScope such\n  ///                    that isl operations may return quota errors\n  ///                    immediately. If false, only starts the operations\n  ///                    counter, but isl does not return quota errors before\n  ///                    calling enter().\n  IslMaxOperationsGuard(isl_ctx *IslCtx, unsigned long LocalMaxOps,\n                        bool AutoEnter = true)\n      : IslCtx(IslCtx), LocalMaxOps(LocalMaxOps) {\n    assert(IslCtx);\n    assert(isl_ctx_get_max_operations(IslCtx) == 0 &&\n           \"Nested max operations not supported\");\n\n    // Users of this guard may check whether the last error was isl_error_quota.\n    // Reset the last error such that a previous out-of-quota error is not\n    // mistaken to have occurred in the in this quota, even if the max number of\n    // operations is set to infinite (LocalMaxOps == 0).\n    isl_ctx_reset_error(IslCtx);\n\n    if (LocalMaxOps == 0) {\n      // No limit on operations; also disable restoring on_error/max_operations.\n      this->IslCtx = nullptr;\n      return;\n    }\n\n    isl_ctx_reset_operations(IslCtx);\n    TopLevelScope = enter(AutoEnter);\n  }\n\n  /// Enter a scope that can handle out-of-quota errors.\n  ///\n  /// @param AllowReturnNull Whether the scoped code can handle out-of-quota\n  ///                        errors. If false, returns a dummy scope object that\n  ///                        does nothing.\n  IslQuotaScope enter(bool AllowReturnNull = true) {\n    return AllowReturnNull && IslCtx ? IslQuotaScope(IslCtx, LocalMaxOps)\n                                     : IslQuotaScope();\n  }\n\n  /// Return whether the current quota has exceeded.\n  bool hasQuotaExceeded() const {\n    if (!IslCtx)\n      return false;\n\n    return isl_ctx_last_error(IslCtx) == isl_error_quota;\n  }\n};\n} // end namespace polly\n\n#endif\n"}, "87": {"id": 87, "path": "/home/vsts/work/1/llvm-project/polly/include/polly/Support/ScopHelper.h", "content": "//===------ Support/ScopHelper.h -- Some Helper Functions for Scop. -------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Small functions that help with LLVM-IR.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef POLLY_SUPPORT_IRHELPER_H\n#define POLLY_SUPPORT_IRHELPER_H\n\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/IntrinsicInst.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"isl/isl-noexceptions.h\"\n\nnamespace llvm {\nclass LoopInfo;\nclass Loop;\nclass ScalarEvolution;\nclass SCEV;\nclass Region;\nclass Pass;\nclass DominatorTree;\nclass RegionInfo;\nclass RegionNode;\n} // namespace llvm\n\nnamespace polly {\nclass Scop;\nclass ScopStmt;\n\n/// Enumeration of assumptions Polly can take.\nenum AssumptionKind {\n  ALIASING,\n  INBOUNDS,\n  WRAPPING,\n  UNSIGNED,\n  PROFITABLE,\n  ERRORBLOCK,\n  COMPLEXITY,\n  INFINITELOOP,\n  INVARIANTLOAD,\n  DELINEARIZATION,\n};\n\n/// Enum to distinguish between assumptions and restrictions.\nenum AssumptionSign { AS_ASSUMPTION, AS_RESTRICTION };\n\n/// Helper struct to remember assumptions.\nstruct Assumption {\n  /// The kind of the assumption (e.g., WRAPPING).\n  AssumptionKind Kind;\n\n  /// Flag to distinguish assumptions and restrictions.\n  AssumptionSign Sign;\n\n  /// The valid/invalid context if this is an assumption/restriction.\n  isl::set Set;\n\n  /// The location that caused this assumption.\n  llvm::DebugLoc Loc;\n\n  /// An optional block whose domain can simplify the assumption.\n  llvm::BasicBlock *BB;\n\n  // Whether the assumption must be checked at runtime.\n  bool RequiresRTC;\n};\n\nusing RecordedAssumptionsTy = llvm::SmallVector<Assumption, 8>;\n\n/// Record an assumption for later addition to the assumed context.\n///\n/// This function will add the assumption to the RecordedAssumptions. This\n/// collection will be added (@see addAssumption) to the assumed context once\n/// all paramaters are known and the context is fully built.\n///\n/// @param RecordedAssumption container which keeps all recorded assumptions.\n/// @param Kind The assumption kind describing the underlying cause.\n/// @param Set  The relations between parameters that are assumed to hold.\n/// @param Loc  The location in the source that caused this assumption.\n/// @param Sign Enum to indicate if the assumptions in @p Set are positive\n///             (needed/assumptions) or negative (invalid/restrictions).\n/// @param BB   The block in which this assumption was taken. If it is\n///             set, the domain of that block will be used to simplify the\n///             actual assumption in @p Set once it is added. This is useful\n///             if the assumption was created prior to the domain.\n/// @param RTC  Does the assumption require a runtime check?\nvoid recordAssumption(RecordedAssumptionsTy *RecordedAssumptions,\n                      AssumptionKind Kind, isl::set Set, llvm::DebugLoc Loc,\n                      AssumptionSign Sign, llvm::BasicBlock *BB = nullptr,\n                      bool RTC = true);\n\n/// Type to remap values.\nusing ValueMapT = llvm::DenseMap<llvm::AssertingVH<llvm::Value>,\n                                 llvm::AssertingVH<llvm::Value>>;\n\n/// Type for a set of invariant loads.\nusing InvariantLoadsSetTy = llvm::SetVector<llvm::AssertingVH<llvm::LoadInst>>;\n\n/// Set type for parameters.\nusing ParameterSetTy = llvm::SetVector<const llvm::SCEV *>;\n\n/// Set of loops (used to remember loops in non-affine subregions).\nusing BoxedLoopsSetTy = llvm::SetVector<const llvm::Loop *>;\n\n/// Utility proxy to wrap the common members of LoadInst and StoreInst.\n///\n/// This works like the LLVM utility class CallSite, ie. it forwards all calls\n/// to either a LoadInst, StoreInst, MemIntrinsic or MemTransferInst.\n/// It is similar to LLVM's utility classes IntrinsicInst, MemIntrinsic,\n/// MemTransferInst, etc. in that it offers a common interface, but does not act\n/// as a fake base class.\n/// It is similar to StringRef and ArrayRef in that it holds a pointer to the\n/// referenced object and should be passed by-value as it is small enough.\n///\n/// This proxy can either represent a LoadInst instance, a StoreInst instance,\n/// a MemIntrinsic instance (memset, memmove, memcpy), a CallInst instance or a\n/// nullptr (only creatable using the default constructor); never an Instruction\n/// that is neither of the above mentioned. When representing a nullptr, only\n/// the following methods are defined:\n/// isNull(), isInstruction(), isLoad(), isStore(), ..., isMemTransferInst(),\n/// operator bool(), operator!()\n///\n/// The functions isa, cast, cast_or_null, dyn_cast are modeled te resemble\n/// those from llvm/Support/Casting.h. Partial template function specialization\n/// is currently not supported in C++ such that those cannot be used directly.\n/// (llvm::isa could, but then llvm:cast etc. would not have the expected\n/// behavior)\nclass MemAccInst {\nprivate:\n  llvm::Instruction *I;\n\npublic:\n  MemAccInst() : I(nullptr) {}\n  MemAccInst(const MemAccInst &Inst) : I(Inst.I) {}\n  /* implicit */ MemAccInst(llvm::LoadInst &LI) : I(&LI) {}\n  /* implicit */ MemAccInst(llvm::LoadInst *LI) : I(LI) {}\n  /* implicit */ MemAccInst(llvm::StoreInst &SI) : I(&SI) {}\n  /* implicit */ MemAccInst(llvm::StoreInst *SI) : I(SI) {}\n  /* implicit */ MemAccInst(llvm::MemIntrinsic *MI) : I(MI) {}\n  /* implicit */ MemAccInst(llvm::CallInst *CI) : I(CI) {}\n  explicit MemAccInst(llvm::Instruction &I) : I(&I) { assert(isa(I)); }\n  explicit MemAccInst(llvm::Instruction *I) : I(I) { assert(isa(I)); }\n\n  static bool isa(const llvm::Value &V) {\n    return llvm::isa<llvm::LoadInst>(V) || llvm::isa<llvm::StoreInst>(V) ||\n           llvm::isa<llvm::CallInst>(V) || llvm::isa<llvm::MemIntrinsic>(V);\n  }\n  static bool isa(const llvm::Value *V) {\n    return llvm::isa<llvm::LoadInst>(V) || llvm::isa<llvm::StoreInst>(V) ||\n           llvm::isa<llvm::CallInst>(V) || llvm::isa<llvm::MemIntrinsic>(V);\n  }\n  static MemAccInst cast(llvm::Value &V) {\n    return MemAccInst(llvm::cast<llvm::Instruction>(V));\n  }\n  static MemAccInst cast(llvm::Value *V) {\n    return MemAccInst(llvm::cast<llvm::Instruction>(V));\n  }\n  static MemAccInst cast_or_null(llvm::Value &V) {\n    return MemAccInst(llvm::cast<llvm::Instruction>(V));\n  }\n  static MemAccInst cast_or_null(llvm::Value *V) {\n    if (!V)\n      return MemAccInst();\n    return MemAccInst(llvm::cast<llvm::Instruction>(V));\n  }\n  static MemAccInst dyn_cast(llvm::Value &V) {\n    if (isa(V))\n      return MemAccInst(llvm::cast<llvm::Instruction>(V));\n    return MemAccInst();\n  }\n  static MemAccInst dyn_cast(llvm::Value *V) {\n    assert(V);\n    if (isa(V))\n      return MemAccInst(llvm::cast<llvm::Instruction>(V));\n    return MemAccInst();\n  }\n\n  MemAccInst &operator=(const MemAccInst &Inst) {\n    I = Inst.I;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::LoadInst &LI) {\n    I = &LI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::LoadInst *LI) {\n    I = LI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::StoreInst &SI) {\n    I = &SI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::StoreInst *SI) {\n    I = SI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::MemIntrinsic &MI) {\n    I = &MI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::MemIntrinsic *MI) {\n    I = MI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::CallInst &CI) {\n    I = &CI;\n    return *this;\n  }\n  MemAccInst &operator=(llvm::CallInst *CI) {\n    I = CI;\n    return *this;\n  }\n\n  llvm::Instruction *get() const {\n    assert(I && \"Unexpected nullptr!\");\n    return I;\n  }\n  operator llvm::Instruction *() const { return asInstruction(); }\n  llvm::Instruction *operator->() const { return get(); }\n\n  explicit operator bool() const { return isInstruction(); }\n  bool operator!() const { return isNull(); }\n\n  llvm::Value *getValueOperand() const {\n    if (isLoad())\n      return asLoad();\n    if (isStore())\n      return asStore()->getValueOperand();\n    if (isMemIntrinsic())\n      return nullptr;\n    if (isCallInst())\n      return nullptr;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n  llvm::Value *getPointerOperand() const {\n    if (isLoad())\n      return asLoad()->getPointerOperand();\n    if (isStore())\n      return asStore()->getPointerOperand();\n    if (isMemIntrinsic())\n      return asMemIntrinsic()->getRawDest();\n    if (isCallInst())\n      return nullptr;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n\n  unsigned getAlignment() const {\n    if (isLoad())\n      return asLoad()->getAlignment();\n    if (isStore())\n      return asStore()->getAlignment();\n    if (isMemTransferInst())\n      return std::min(asMemTransferInst()->getDestAlignment(),\n                      asMemTransferInst()->getSourceAlignment());\n    if (isMemIntrinsic())\n      return asMemIntrinsic()->getDestAlignment();\n    if (isCallInst())\n      return 0;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n  bool isVolatile() const {\n    if (isLoad())\n      return asLoad()->isVolatile();\n    if (isStore())\n      return asStore()->isVolatile();\n    if (isMemIntrinsic())\n      return asMemIntrinsic()->isVolatile();\n    if (isCallInst())\n      return false;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n  bool isSimple() const {\n    if (isLoad())\n      return asLoad()->isSimple();\n    if (isStore())\n      return asStore()->isSimple();\n    if (isMemIntrinsic())\n      return !asMemIntrinsic()->isVolatile();\n    if (isCallInst())\n      return true;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n  llvm::AtomicOrdering getOrdering() const {\n    if (isLoad())\n      return asLoad()->getOrdering();\n    if (isStore())\n      return asStore()->getOrdering();\n    if (isMemIntrinsic())\n      return llvm::AtomicOrdering::NotAtomic;\n    if (isCallInst())\n      return llvm::AtomicOrdering::NotAtomic;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n  bool isUnordered() const {\n    if (isLoad())\n      return asLoad()->isUnordered();\n    if (isStore())\n      return asStore()->isUnordered();\n    // Copied from the Load/Store implementation of isUnordered:\n    if (isMemIntrinsic())\n      return !asMemIntrinsic()->isVolatile();\n    if (isCallInst())\n      return true;\n    llvm_unreachable(\"Operation not supported on nullptr\");\n  }\n\n  bool isNull() const { return !I; }\n  bool isInstruction() const { return I; }\n\n  llvm::Instruction *asInstruction() const { return I; }\n\nprivate:\n  bool isLoad() const { return I && llvm::isa<llvm::LoadInst>(I); }\n  bool isStore() const { return I && llvm::isa<llvm::StoreInst>(I); }\n  bool isCallInst() const { return I && llvm::isa<llvm::CallInst>(I); }\n  bool isMemIntrinsic() const { return I && llvm::isa<llvm::MemIntrinsic>(I); }\n  bool isMemSetInst() const { return I && llvm::isa<llvm::MemSetInst>(I); }\n  bool isMemTransferInst() const {\n    return I && llvm::isa<llvm::MemTransferInst>(I);\n  }\n\n  llvm::LoadInst *asLoad() const { return llvm::cast<llvm::LoadInst>(I); }\n  llvm::StoreInst *asStore() const { return llvm::cast<llvm::StoreInst>(I); }\n  llvm::CallInst *asCallInst() const { return llvm::cast<llvm::CallInst>(I); }\n  llvm::MemIntrinsic *asMemIntrinsic() const {\n    return llvm::cast<llvm::MemIntrinsic>(I);\n  }\n  llvm::MemSetInst *asMemSetInst() const {\n    return llvm::cast<llvm::MemSetInst>(I);\n  }\n  llvm::MemTransferInst *asMemTransferInst() const {\n    return llvm::cast<llvm::MemTransferInst>(I);\n  }\n};\n} // namespace polly\n\nnamespace llvm {\n/// Specialize simplify_type for MemAccInst to enable dyn_cast and cast\n///        from a MemAccInst object.\ntemplate <> struct simplify_type<polly::MemAccInst> {\n  typedef Instruction *SimpleType;\n  static SimpleType getSimplifiedValue(polly::MemAccInst &I) {\n    return I.asInstruction();\n  }\n};\n} // namespace llvm\n\nnamespace polly {\n\n/// Simplify the region to have a single unconditional entry edge and a\n/// single exit edge.\n///\n/// Although this function allows DT and RI to be null, regions only work\n/// properly if the DominatorTree (for Region::contains) and RegionInfo are kept\n/// up-to-date.\n///\n/// @param R  The region to be simplified\n/// @param DT DominatorTree to be updated.\n/// @param LI LoopInfo to be updated.\n/// @param RI RegionInfo to be updated.\nvoid simplifyRegion(llvm::Region *R, llvm::DominatorTree *DT,\n                    llvm::LoopInfo *LI, llvm::RegionInfo *RI);\n\n/// Split the entry block of a function to store the newly inserted\n///        allocations outside of all Scops.\n///\n/// @param EntryBlock The entry block of the current function.\n/// @param P          The pass that currently running.\n///\nvoid splitEntryBlockForAlloca(llvm::BasicBlock *EntryBlock, llvm::Pass *P);\n\n/// Split the entry block of a function to store the newly inserted\n///        allocations outside of all Scops.\n///\n/// @param DT DominatorTree to be updated.\n/// @param LI LoopInfo to be updated.\n/// @param RI RegionInfo to be updated.\nvoid splitEntryBlockForAlloca(llvm::BasicBlock *EntryBlock,\n                              llvm::DominatorTree *DT, llvm::LoopInfo *LI,\n                              llvm::RegionInfo *RI);\n\n/// Wrapper for SCEVExpander extended to all Polly features.\n///\n/// This wrapper will internally call the SCEVExpander but also makes sure that\n/// all additional features not represented in SCEV (e.g., SDiv/SRem are not\n/// black boxes but can be part of the function) will be expanded correctly.\n///\n/// The parameters are the same as for the creation of a SCEVExpander as well\n/// as the call to SCEVExpander::expandCodeFor:\n///\n/// @param S     The current Scop.\n/// @param SE    The Scalar Evolution pass.\n/// @param DL    The module data layout.\n/// @param Name  The suffix added to the new instruction names.\n/// @param E     The expression for which code is actually generated.\n/// @param Ty    The type of the resulting code.\n/// @param IP    The insertion point for the new code.\n/// @param VMap  A remapping of values used in @p E.\n/// @param RTCBB The last block of the RTC. Used to insert loop-invariant\n///              instructions in rare cases.\nllvm::Value *expandCodeFor(Scop &S, llvm::ScalarEvolution &SE,\n                           const llvm::DataLayout &DL, const char *Name,\n                           const llvm::SCEV *E, llvm::Type *Ty,\n                           llvm::Instruction *IP, ValueMapT *VMap,\n                           llvm::BasicBlock *RTCBB);\n\n/// Check if the block is a error block.\n///\n/// A error block is currently any block that fulfills at least one of\n/// the following conditions:\n///\n///  - It is terminated by an unreachable instruction\n///  - It contains a call to a non-pure function that is not immediately\n///    dominated by a loop header and that does not dominate the region exit.\n///    This is a heuristic to pick only error blocks that are conditionally\n///    executed and can be assumed to be not executed at all without the domains\n///    being available.\n///\n/// @param BB The block to check.\n/// @param R  The analyzed region.\n/// @param LI The loop info analysis.\n/// @param DT The dominator tree of the function.\n///\n/// @return True if the block is a error block, false otherwise.\nbool isErrorBlock(llvm::BasicBlock &BB, const llvm::Region &R,\n                  llvm::LoopInfo &LI, const llvm::DominatorTree &DT);\n\n/// Return the condition for the terminator @p TI.\n///\n/// For unconditional branches the \"i1 true\" condition will be returned.\n///\n/// @param TI The terminator to get the condition from.\n///\n/// @return The condition of @p TI and nullptr if none could be extracted.\nllvm::Value *getConditionFromTerminator(llvm::Instruction *TI);\n\n/// Get the smallest loop that contains @p S but is not in @p S.\nllvm::Loop *getLoopSurroundingScop(Scop &S, llvm::LoopInfo &LI);\n\n/// Get the number of blocks in @p L.\n///\n/// The number of blocks in a loop are the number of basic blocks actually\n/// belonging to the loop, as well as all single basic blocks that the loop\n/// exits to and which terminate in an unreachable instruction. We do not\n/// allow such basic blocks in the exit of a scop, hence they belong to the\n/// scop and represent run-time conditions which we want to model and\n/// subsequently speculate away.\n///\n/// @see getRegionNodeLoop for additional details.\nunsigned getNumBlocksInLoop(llvm::Loop *L);\n\n/// Get the number of blocks in @p RN.\nunsigned getNumBlocksInRegionNode(llvm::RegionNode *RN);\n\n/// Return the smallest loop surrounding @p RN.\nllvm::Loop *getRegionNodeLoop(llvm::RegionNode *RN, llvm::LoopInfo &LI);\n\n/// Check if @p LInst can be hoisted in @p R.\n///\n/// @param LInst The load to check.\n/// @param R     The analyzed region.\n/// @param LI    The loop info.\n/// @param SE    The scalar evolution analysis.\n/// @param DT    The dominator tree of the function.\n/// @param KnownInvariantLoads The invariant load set.\n///\n/// @return True if @p LInst can be hoisted in @p R.\nbool isHoistableLoad(llvm::LoadInst *LInst, llvm::Region &R, llvm::LoopInfo &LI,\n                     llvm::ScalarEvolution &SE, const llvm::DominatorTree &DT,\n                     const InvariantLoadsSetTy &KnownInvariantLoads);\n\n/// Return true iff @p V is an intrinsic that we ignore during code\n///        generation.\nbool isIgnoredIntrinsic(const llvm::Value *V);\n\n/// Check whether a value an be synthesized by the code generator.\n///\n/// Some value will be recalculated only from information that is code generated\n/// from the polyhedral representation. For such instructions we do not need to\n/// ensure that their operands are available during code generation.\n///\n/// @param V The value to check.\n/// @param S The current SCoP.\n/// @param SE The scalar evolution database.\n/// @param Scope Location where the value would by synthesized.\n/// @return If the instruction I can be regenerated from its\n///         scalar evolution representation, return true,\n///         otherwise return false.\nbool canSynthesize(const llvm::Value *V, const Scop &S,\n                   llvm::ScalarEvolution *SE, llvm::Loop *Scope);\n\n/// Return the block in which a value is used.\n///\n/// For normal instructions, this is the instruction's parent block. For PHI\n/// nodes, this is the incoming block of that use, because this is where the\n/// operand must be defined (i.e. its definition dominates this block).\n/// Non-instructions do not use operands at a specific point such that in this\n/// case this function returns nullptr.\nllvm::BasicBlock *getUseBlock(const llvm::Use &U);\n\n// If the loop is nonaffine/boxed, return the first non-boxed surrounding loop\n// for Polly. If the loop is affine, return the loop itself.\n//\n// @param L             Pointer to the Loop object to analyze.\n// @param LI            Reference to the LoopInfo.\n// @param BoxedLoops    Set of Boxed Loops we get from the SCoP.\nllvm::Loop *getFirstNonBoxedLoopFor(llvm::Loop *L, llvm::LoopInfo &LI,\n                                    const BoxedLoopsSetTy &BoxedLoops);\n\n// If the Basic Block belongs to a loop that is nonaffine/boxed, return the\n// first non-boxed surrounding loop for Polly. If the loop is affine, return\n// the loop itself.\n//\n// @param BB            Pointer to the Basic Block to analyze.\n// @param LI            Reference to the LoopInfo.\n// @param BoxedLoops    Set of Boxed Loops we get from the SCoP.\nllvm::Loop *getFirstNonBoxedLoopFor(llvm::BasicBlock *BB, llvm::LoopInfo &LI,\n                                    const BoxedLoopsSetTy &BoxedLoops);\n\n/// Is the given instruction a call to a debug function?\n///\n/// A debug function can be used to insert output in Polly-optimized code which\n/// normally does not allow function calls with side-effects. For instance, a\n/// printf can be inserted to check whether a value still has the expected value\n/// after Polly generated code:\n///\n///     int sum = 0;\n///     for (int i = 0; i < 16; i+=1) {\n///       sum += i;\n///       printf(\"The value of sum at i=%d is %d\\n\", sum, i);\n///     }\nbool isDebugCall(llvm::Instruction *Inst);\n\n/// Does the statement contain a call to a debug function?\n///\n/// Such a statement must not be removed, even if has no side-effects.\nbool hasDebugCall(ScopStmt *Stmt);\n} // namespace polly\n#endif\n"}}, "reports": [{"events": [{"location": {"col": 9, "file": 25, "line": 55}, "message": "'PointerRec' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AliasSetTracker.h", "reportHash": "d579f694bc74a87480698b24d5d7b955", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 25, "line": 330}, "message": "'ASTCallbackVH' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AliasSetTracker.h", "reportHash": "32565e1bda2c5215309817493dbed844", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 26, "line": 899}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 26, "line": 899}, "message": "'LoopInfoBase<N, M>' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "reportHash": "f7ff6b86f2f1f4c01a0c62755bfc31d6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 26, "line": 1091}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 26, "line": 1091}, "message": "'LoopInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "reportHash": "e0eb50c8bf8d6c12286405d3176bb61c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 26, "line": 1249}, "message": "'LoopInfoWrapperPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "reportHash": "13ad0763a26f31cb16b4a5e0e2d10464", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 27, "line": 696}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 27, "line": 696}, "message": "'RegionInfoBase<RegionTr>' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "reportHash": "49e5a764e678cbec4072c8e79edb9635", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 27, "line": 906}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 27, "line": 906}, "message": "'RegionInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "reportHash": "5acdb95ed66da36dfe7e06eb1b9102db", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 28, "line": 31}, "message": "'RegionPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionPass.h", "reportHash": "8b7a2d61580d1cea062f7beea2179fe1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 28, "line": 86}, "message": "'RGPassManager' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionPass.h", "reportHash": "57d5c30a1b1d080d62bd4c2be4456826", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 29, "line": 191}, "message": "'SCEVCouldNotCompute' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "ee9f7b346ebdb812850f1fb030dec5d2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 29, "line": 267}, "message": "'SCEVEqualPredicate' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "fcc0a27399bd7e4c71c2ce7deed2f4f9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 29, "line": 304}, "message": "'SCEVWrapPredicate' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "adb32296102bd90b73825268e8b76753", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 29, "line": 399}, "message": "'SCEVUnionPredicate' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "5bf878f7207058c423411b5b698e4e54", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 29, "line": 478}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 29, "line": 478}, "message": "'ScalarEvolution' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "5d11eaa5a829a1c44809d245fa75bfe2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 29, "line": 1186}, "message": "'SCEVCallbackVH' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "27ce46d61baa48e7df133208d8ca102a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 5, "file": 29, "line": 1387}, "message": "mark 'noexcept'"}, {"location": {"col": 5, "file": 29, "line": 1387}, "message": "'BackedgeTakenInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "abdb9e46f5281eb3a74d1c254cda4d5f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 29, "line": 2088}, "message": "'ScalarEvolutionWrapperPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "1eafb4ea2a03f84d8e8253851a04e321", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 47}, "message": "'SCEVConstant' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "30a05f713ce0635bcf973958c71e6529", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 75}, "message": "'SCEVCastExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "a858e785692e903b06d53af9cf706bec", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 182}, "message": "'SCEVNAryExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "c66f8590aeb901380a3647ea349dc2ad", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 241}, "message": "'SCEVCommutativeExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "89f46e6bb61c3b4ab7ef7bcf244b0ec8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 262}, "message": "'SCEVAddExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "230fb102686d2c9f3c7ebf424ed30ef4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 288}, "message": "'SCEVMulExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "239ab40aeb69b39ff84fbaa12c5f845f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 303}, "message": "'SCEVUDivExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "c3bc7e90a37295e34f2de0109db428e4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 352}, "message": "'SCEVAddRecExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "60289faa812f512aa27c53e5216c04c8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 424}, "message": "'SCEVMinMaxExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "36791f55f6a464e1e7e0d8a6ce577ff3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 464}, "message": "'SCEVSMaxExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "67a357184c4944389851e7d01eda6a1c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 478}, "message": "'SCEVUMaxExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "ce547a8da8f29825ce87d5637cce9c80", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 492}, "message": "'SCEVSMinExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "97a4e9cee4ddbc3b63c95fe126fb3dc5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 506}, "message": "'SCEVUMinExpr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "b6166a935a188492bf0d0e822c02a9c0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 30, "line": 522}, "message": "'SCEVUnknown' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionExpressions.h", "reportHash": "fff6151152e6f81ed5714412b8e71eb5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 31, "line": 184}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 31, "line": 184}, "message": "'TargetTransformInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h", "reportHash": "6b7882848593fc9207dd39cfce4a50e4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 31, "line": 2244}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 31, "line": 2244}, "message": "'TargetIRAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h", "reportHash": "9c08d4203896ff630fb365c16d7ae5f2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 31, "line": 2281}, "message": "'TargetTransformInfoWrapperPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/TargetTransformInfo.h", "reportHash": "329937393b4ff0285e204b466e1c5602", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 14, "file": 33, "line": 75}, "message": "'llvm/IR/Attributes.inc' file not found"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Attributes.h", "reportHash": "028601b7c3bb82de45631257f6da885e", "checkerName": "clang-diagnostic-error", "reviewStatus": null, "severity": "CRITICAL"}, {"events": [{"location": {"col": 22, "file": 35, "line": 47}, "message": "'ConstantRange' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/ConstantRange.h", "reportHash": "4207b629073290c9e96823f6a4825bac", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 33}, "message": "'DebugLoc' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DebugLoc.h", "reportHash": "d2295c6560849908d6da35ed0ce79d34", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 40, "line": 164}, "message": "'FunctionCallee' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DerivedTypes.h", "reportHash": "1fa947cba366bbbdacc370dcdddac73a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 131}, "message": "'DiagnosticInfoInlineAsm' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "729187dde8bfe21aa496783687fce246", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 179}, "message": "'DiagnosticInfoResourceLimit' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "9ba262144797ffdaaf27cfe086bcc817", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 236}, "message": "'DiagnosticInfoDebugMetadataVersion' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "f19ba3ac0b8f725bf9498664c219626b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 263}, "message": "'DiagnosticInfoIgnoringInvalidDebugMetadata' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "e06c50458eb77bc449e79427e2171c9d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 285}, "message": "'DiagnosticInfoSampleProfile' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "8718e9bbbdacc0de16240aa37f70f5c2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 324}, "message": "'DiagnosticInfoPGOProfile' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "4cdf95a38359f288eb59842aaf621822", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 348}, "message": "'DiagnosticLocation' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "b2c42a28b781536f0abb7e6d6187a160", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 368}, "message": "'DiagnosticInfoWithLocationBase' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "919c98e83a0428b66b1359616e475f2e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 408}, "message": "'DiagnosticInfoOptimizationBase' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "9af19f0f0863708c06ec86af96aa7a95", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 41, "line": 421}, "message": "'Argument' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "b6ed0d081dbee1ebdb5b07efaabe597f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 617}, "message": "'DiagnosticInfoIROptimization' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "03669f945a1e9a9825fa806ea32d25ff", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 770}, "message": "'OptimizationRemarkAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "c2c9a608ee40ebe9125e721178d1ee87", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 921}, "message": "'DiagnosticInfoMIRParser' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "83b1696700ada7702c1660068d8e2261", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 939}, "message": "'DiagnosticInfoISelFallback' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "9ca635ed5653bc7f0a40b06386ff5190", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 993}, "message": "'DiagnosticInfoUnsupported' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "682bfe6f96d991ef84d21c3453b24375", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 41, "line": 1039}, "message": "'DiagnosticInfoSrcMgr' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/DiagnosticInfo.h", "reportHash": "06229725f9450fe9c505d30a4a6a9dec", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 42, "line": 281}, "message": "'DominatorTreeWrapperPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Dominators.h", "reportHash": "e68050d0d4de166276924eb1cada969c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 43, "line": 57}, "message": "'UnaryInstruction' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/InstrTypes.h", "reportHash": "7afdb338ba23c0b5771e8da962429046", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 43, "line": 190}, "message": "'BinaryOperator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/InstrTypes.h", "reportHash": "3e893a12b32dee46fd8d53f15961655e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 43, "line": 712}, "message": "'CmpInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/InstrTypes.h", "reportHash": "1713ec94b68449513368dfa4eabcc92b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 43, "line": 1164}, "message": "'CallBase' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/InstrTypes.h", "reportHash": "55cb03a233e77c6ffcefb6d1d5952029", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 303}, "message": "'StoreInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "44232f8032555d73caa33b33bf60cc42", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 444}, "message": "'FenceInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "98efc0a2a473b3b94195f4d648c15a35", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 522}, "message": "'AtomicCmpXchgInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "9fe713f6a601c948ce666a6ac8c4b705", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 702}, "message": "'AtomicRMWInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "bb5a521388f32cb8712af562f38e0b02", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 1715}, "message": "'SelectInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "36197abca8d2a05803edb5f2ae39e978", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 1850}, "message": "'ExtractElementInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "96faa712cefd2df597d029ae856cdc83", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 1914}, "message": "'InsertElementInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "47b56c5f7299bd191ba60b1e29a542dd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 1986}, "message": "'ShuffleVectorInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "062aaa4f5a59e281f43ffba1e1ff63da", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 4369}, "message": "'CleanupPadInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "76a621ac9a03b6075daa640a65ce996d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 4410}, "message": "'CatchPadInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "3fdae1e4c2a13f4c501a27cfb803af60", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 4650}, "message": "'UnreachableInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Instructions.h", "reportHash": "190ff7d4250caed68dc1f4e8f8362e0c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 134}, "message": "'DbgInfoIntrinsic' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "67be7d74e8dfe207a2aa9aff3f7c35f3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 378}, "message": "'VPIntrinsic' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "52421bd8cc8db343947fe644d0f52ec4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 420}, "message": "'ConstrainedFPIntrinsic' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "1b158893192f23a51c31428e95b51a61", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 456}, "message": "'BinaryOpIntrinsic' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "6850aeb793ec69eef7c7f2d258ec053d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 991}, "message": "'VAStartInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "cbb22684e30d566497e255aef3452979", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 1004}, "message": "'VAEndInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "eacb7f8959e018b7efb0fdfc46c20f22", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 1017}, "message": "'VACopyInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "afef57b0926dc5f112861f64759c34b7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 1031}, "message": "'InstrProfIncrementInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "ee173ab561f3b158af8a5c2b407b5795", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 1071}, "message": "'InstrProfValueProfileInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "e6cc2c2cbd4a7eafa9e35bbfe71deb30", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 1103}, "message": "'PseudoProbeInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "62be5c6877f2bd7dd0a3a7e5376232dd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 1130}, "message": "'NoAliasScopeDeclInst' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IntrinsicInst.h", "reportHash": "0b6ac1ba8c944e4b3158c17ddb0efc63", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 46, "line": 110}, "message": "'PassManagerPrettyStackEntry' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/LegacyPassManagers.h", "reportHash": "d3dbef88ab1ca8165360e2bcd29bdc00", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 46, "line": 460}, "message": "'FPPassManager' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/LegacyPassManagers.h", "reportHash": "e7cf6b8dc7b3effdc90c043e4875291d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 48, "line": 66}, "message": "'OverflowingBinaryOperator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Operator.h", "reportHash": "352380876067f13086c43ac4ce40f43c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 48, "line": 120}, "message": "'PossiblyExactOperator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Operator.h", "reportHash": "c1d8083a56a4bbc2fb2ff96159873b2e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 48, "line": 249}, "message": "'FPMathOperator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Operator.h", "reportHash": "133d54c0bb0719125558749b63332615", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 49, "file": 50, "line": 28}, "message": "mark 'noexcept'"}, {"location": {"col": 49, "file": 50, "line": 28}, "message": "'AnalysisManager<IRUnitT, ExtraArgTs...>' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/PassManagerImpl.h", "reportHash": "e5b928b44a3ea7186556f6f62e767905", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 55, "line": 47}, "message": "'AnalysisUsage' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/PassAnalysisSupport.h", "reportHash": "574ede11082deccfa90ec192d10b4adb", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 55, "line": 157}, "message": "'AnalysisResolver' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/PassAnalysisSupport.h", "reportHash": "181bc1a1481672c7e7366cf89755a4f7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 59, "line": 462}, "message": "'cat' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Support/CommandLine.h", "reportHash": "23d2febf1fe4dd9d8aac75e007d5ca7b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 65, "line": 265}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 65, "line": 265}, "message": "'DominatorTreeBase<N, IsPostDom>' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Support/GenericDomTree.h", "reportHash": "823432cff7a870787ef46238204e6baf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 80, "line": 221}, "message": "'DependenceInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/DependenceInfo.h", "reportHash": "7ea1b722e115891549e7fcb14df0441d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 80, "line": 262}, "message": "'DependenceInfoWrapperPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/DependenceInfo.h", "reportHash": "694784d6c9d64fb98f1ebdda9656262d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 81, "line": 68}, "message": "'PollyForcePassLinking' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/LinkAllPasses.h", "reportHash": "5bfd7355f4997ee2c2cbe0cbf1605ef9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 82, "line": 640}, "message": "'ScopDetectionWrapperPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetection.h", "reportHash": "0d28779eb95ce511970f9a7143dd9e3e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 194}, "message": "'ReportCFG' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "c1dfd8e510110f0cd35a597030cbf256", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 283}, "message": "'ReportAffFunc' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "03d4d966abe476c1026c7a6b49418698", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 530}, "message": "'ReportLoopBound' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "3900137077786ec68a8fe21734720bf9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 562}, "message": "'ReportLoopHasNoExit' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "58a7b1d8c28013bde249984cdd63dc62", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 590}, "message": "'ReportLoopHasMultipleExits' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "66d7024a06923a2c5015cae51440c62b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 618}, "message": "'ReportLoopOnlySomeLatches' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "f839277f658a1a00235475d7132373d3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 646}, "message": "'ReportFuncCall' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "addd55157c6027ce2be895259dc8dca5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 670}, "message": "'ReportAlias' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "677fbc1aba9dfe72def3e7d2badb643c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 83, "line": 709}, "message": "'ReportOther' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopDetectionDiagnostic.h", "reportHash": "cc44bd3dbe7e2cf12bf5eb8ad139fc28", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 84, "line": 1126}, "message": "'InvariantAccess' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopInfo.h", "reportHash": "97bbf8a9ec569d87e7b98c8b02eca3cf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 84, "line": 1138}, "message": "'InvariantEquivClassTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopInfo.h", "reportHash": "38e109efb8700543a4b8c0644fe66987", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 85, "line": 161}, "message": "'ScopPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/ScopPass.h", "reportHash": "71189d3ce4388879c324a7ae9cb7ff53", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 86, "line": 287}, "message": "mark 'noexcept'"}, {"location": {"col": 3, "file": 86, "line": 287}, "message": "'IslQuotaScope' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/Support/GICHelper.h", "reportHash": "efd1ce6c37e13081393f602218998782", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 86, "line": 347}, "message": "'IslMaxOperationsGuard' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/Support/GICHelper.h", "reportHash": "e5c1d6abaad00b014f170fc71c95a8ba", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 87, "line": 56}, "message": "'Assumption' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/polly/include/polly/Support/ScopHelper.h", "reportHash": "01e2df0323194394bb4a4b9f2e5143ce", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
