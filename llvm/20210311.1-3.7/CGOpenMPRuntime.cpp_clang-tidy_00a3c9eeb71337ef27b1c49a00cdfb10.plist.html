<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"4": {"id": 4, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Decl.h", "content": "//===- Decl.h - Classes for representing declarations -----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n//  This file defines the Decl subclasses.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_DECL_H\n#define LLVM_CLANG_AST_DECL_H\n\n#include \"clang/AST/APValue.h\"\n#include \"clang/AST/ASTContextAllocate.h\"\n#include \"clang/AST/DeclAccessPair.h\"\n#include \"clang/AST/DeclBase.h\"\n#include \"clang/AST/DeclarationName.h\"\n#include \"clang/AST/ExternalASTSource.h\"\n#include \"clang/AST/NestedNameSpecifier.h\"\n#include \"clang/AST/Redeclarable.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/AddressSpaces.h\"\n#include \"clang/Basic/Diagnostic.h\"\n#include \"clang/Basic/IdentifierTable.h\"\n#include \"clang/Basic/LLVM.h\"\n#include \"clang/Basic/Linkage.h\"\n#include \"clang/Basic/OperatorKinds.h\"\n#include \"clang/Basic/PartialDiagnostic.h\"\n#include \"clang/Basic/PragmaKinds.h\"\n#include \"clang/Basic/SourceLocation.h\"\n#include \"clang/Basic/Specifiers.h\"\n#include \"clang/Basic/Visibility.h\"\n#include \"llvm/ADT/APSInt.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/PointerUnion.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/Compiler.h\"\n#include \"llvm/Support/TrailingObjects.h\"\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <utility>\n\nnamespace clang {\n\nclass ASTContext;\nstruct ASTTemplateArgumentListInfo;\nclass Attr;\nclass CompoundStmt;\nclass DependentFunctionTemplateSpecializationInfo;\nclass EnumDecl;\nclass Expr;\nclass FunctionTemplateDecl;\nclass FunctionTemplateSpecializationInfo;\nclass FunctionTypeLoc;\nclass LabelStmt;\nclass MemberSpecializationInfo;\nclass Module;\nclass NamespaceDecl;\nclass ParmVarDecl;\nclass RecordDecl;\nclass Stmt;\nclass StringLiteral;\nclass TagDecl;\nclass TemplateArgumentList;\nclass TemplateArgumentListInfo;\nclass TemplateParameterList;\nclass TypeAliasTemplateDecl;\nclass TypeLoc;\nclass UnresolvedSetImpl;\nclass VarTemplateDecl;\n\n/// The top declaration context.\nclass TranslationUnitDecl : public Decl, public DeclContext {\n  ASTContext &Ctx;\n\n  /// The (most recently entered) anonymous namespace for this\n  /// translation unit, if one has been created.\n  NamespaceDecl *AnonymousNamespace = nullptr;\n\n  explicit TranslationUnitDecl(ASTContext &ctx);\n\n  virtual void anchor();\n\npublic:\n  ASTContext &getASTContext() const { return Ctx; }\n\n  NamespaceDecl *getAnonymousNamespace() const { return AnonymousNamespace; }\n  void setAnonymousNamespace(NamespaceDecl *D) { AnonymousNamespace = D; }\n\n  static TranslationUnitDecl *Create(ASTContext &C);\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == TranslationUnit; }\n  static DeclContext *castToDeclContext(const TranslationUnitDecl *D) {\n    return static_cast<DeclContext *>(const_cast<TranslationUnitDecl*>(D));\n  }\n  static TranslationUnitDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<TranslationUnitDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// Represents a `#pragma comment` line. Always a child of\n/// TranslationUnitDecl.\nclass PragmaCommentDecl final\n    : public Decl,\n      private llvm::TrailingObjects<PragmaCommentDecl, char> {\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n  friend TrailingObjects;\n\n  PragmaMSCommentKind CommentKind;\n\n  PragmaCommentDecl(TranslationUnitDecl *TU, SourceLocation CommentLoc,\n                    PragmaMSCommentKind CommentKind)\n      : Decl(PragmaComment, TU, CommentLoc), CommentKind(CommentKind) {}\n\n  virtual void anchor();\n\npublic:\n  static PragmaCommentDecl *Create(const ASTContext &C, TranslationUnitDecl *DC,\n                                   SourceLocation CommentLoc,\n                                   PragmaMSCommentKind CommentKind,\n                                   StringRef Arg);\n  static PragmaCommentDecl *CreateDeserialized(ASTContext &C, unsigned ID,\n                                               unsigned ArgSize);\n\n  PragmaMSCommentKind getCommentKind() const { return CommentKind; }\n\n  StringRef getArg() const { return getTrailingObjects<char>(); }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == PragmaComment; }\n};\n\n/// Represents a `#pragma detect_mismatch` line. Always a child of\n/// TranslationUnitDecl.\nclass PragmaDetectMismatchDecl final\n    : public Decl,\n      private llvm::TrailingObjects<PragmaDetectMismatchDecl, char> {\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n  friend TrailingObjects;\n\n  size_t ValueStart;\n\n  PragmaDetectMismatchDecl(TranslationUnitDecl *TU, SourceLocation Loc,\n                           size_t ValueStart)\n      : Decl(PragmaDetectMismatch, TU, Loc), ValueStart(ValueStart) {}\n\n  virtual void anchor();\n\npublic:\n  static PragmaDetectMismatchDecl *Create(const ASTContext &C,\n                                          TranslationUnitDecl *DC,\n                                          SourceLocation Loc, StringRef Name,\n                                          StringRef Value);\n  static PragmaDetectMismatchDecl *\n  CreateDeserialized(ASTContext &C, unsigned ID, unsigned NameValueSize);\n\n  StringRef getName() const { return getTrailingObjects<char>(); }\n  StringRef getValue() const { return getTrailingObjects<char>() + ValueStart; }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == PragmaDetectMismatch; }\n};\n\n/// Declaration context for names declared as extern \"C\" in C++. This\n/// is neither the semantic nor lexical context for such declarations, but is\n/// used to check for conflicts with other extern \"C\" declarations. Example:\n///\n/// \\code\n///   namespace N { extern \"C\" void f(); } // #1\n///   void N::f() {}                       // #2\n///   namespace M { extern \"C\" void f(); } // #3\n/// \\endcode\n///\n/// The semantic context of #1 is namespace N and its lexical context is the\n/// LinkageSpecDecl; the semantic context of #2 is namespace N and its lexical\n/// context is the TU. However, both declarations are also visible in the\n/// extern \"C\" context.\n///\n/// The declaration at #3 finds it is a redeclaration of \\c N::f through\n/// lookup in the extern \"C\" context.\nclass ExternCContextDecl : public Decl, public DeclContext {\n  explicit ExternCContextDecl(TranslationUnitDecl *TU)\n    : Decl(ExternCContext, TU, SourceLocation()),\n      DeclContext(ExternCContext) {}\n\n  virtual void anchor();\n\npublic:\n  static ExternCContextDecl *Create(const ASTContext &C,\n                                    TranslationUnitDecl *TU);\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == ExternCContext; }\n  static DeclContext *castToDeclContext(const ExternCContextDecl *D) {\n    return static_cast<DeclContext *>(const_cast<ExternCContextDecl*>(D));\n  }\n  static ExternCContextDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<ExternCContextDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// This represents a decl that may have a name.  Many decls have names such\n/// as ObjCMethodDecl, but not \\@class, etc.\n///\n/// Note that not every NamedDecl is actually named (e.g., a struct might\n/// be anonymous), and not every name is an identifier.\nclass NamedDecl : public Decl {\n  /// The name of this declaration, which is typically a normal\n  /// identifier but may also be a special kind of name (C++\n  /// constructor, Objective-C selector, etc.)\n  DeclarationName Name;\n\n  virtual void anchor();\n\nprivate:\n  NamedDecl *getUnderlyingDeclImpl() LLVM_READONLY;\n\nprotected:\n  NamedDecl(Kind DK, DeclContext *DC, SourceLocation L, DeclarationName N)\n      : Decl(DK, DC, L), Name(N) {}\n\npublic:\n  /// Get the identifier that names this declaration, if there is one.\n  ///\n  /// This will return NULL if this declaration has no name (e.g., for\n  /// an unnamed class) or if the name is a special name (C++ constructor,\n  /// Objective-C selector, etc.).\n  IdentifierInfo *getIdentifier() const { return Name.getAsIdentifierInfo(); }\n\n  /// Get the name of identifier for this declaration as a StringRef.\n  ///\n  /// This requires that the declaration have a name and that it be a simple\n  /// identifier.\n  StringRef getName() const {\n    assert(Name.isIdentifier() && \"Name is not a simple identifier\");\n    return getIdentifier() ? getIdentifier()->getName() : \"\";\n  }\n\n  /// Get a human-readable name for the declaration, even if it is one of the\n  /// special kinds of names (C++ constructor, Objective-C selector, etc).\n  ///\n  /// Creating this name requires expensive string manipulation, so it should\n  /// be called only when performance doesn't matter. For simple declarations,\n  /// getNameAsCString() should suffice.\n  //\n  // FIXME: This function should be renamed to indicate that it is not just an\n  // alternate form of getName(), and clients should move as appropriate.\n  //\n  // FIXME: Deprecated, move clients to getName().\n  std::string getNameAsString() const { return Name.getAsString(); }\n\n  /// Pretty-print the unqualified name of this declaration. Can be overloaded\n  /// by derived classes to provide a more user-friendly name when appropriate.\n  virtual void printName(raw_ostream &os) const;\n\n  /// Get the actual, stored name of the declaration, which may be a special\n  /// name.\n  ///\n  /// Note that generally in diagnostics, the non-null \\p NamedDecl* itself\n  /// should be sent into the diagnostic instead of using the result of\n  /// \\p getDeclName().\n  ///\n  /// A \\p DeclarationName in a diagnostic will just be streamed to the output,\n  /// which will directly result in a call to \\p DeclarationName::print.\n  ///\n  /// A \\p NamedDecl* in a diagnostic will also ultimately result in a call to\n  /// \\p DeclarationName::print, but with two customisation points along the\n  /// way (\\p getNameForDiagnostic and \\p printName). These are used to print\n  /// the template arguments if any, and to provide a user-friendly name for\n  /// some entities (such as unnamed variables and anonymous records).\n  DeclarationName getDeclName() const { return Name; }\n\n  /// Set the name of this declaration.\n  void setDeclName(DeclarationName N) { Name = N; }\n\n  /// Returns a human-readable qualified name for this declaration, like\n  /// A::B::i, for i being member of namespace A::B.\n  ///\n  /// If the declaration is not a member of context which can be named (record,\n  /// namespace), it will return the same result as printName().\n  ///\n  /// Creating this name is expensive, so it should be called only when\n  /// performance doesn't matter.\n  void printQualifiedName(raw_ostream &OS) const;\n  void printQualifiedName(raw_ostream &OS, const PrintingPolicy &Policy) const;\n\n  /// Print only the nested name specifier part of a fully-qualified name,\n  /// including the '::' at the end. E.g.\n  ///    when `printQualifiedName(D)` prints \"A::B::i\",\n  ///    this function prints \"A::B::\".\n  void printNestedNameSpecifier(raw_ostream &OS) const;\n  void printNestedNameSpecifier(raw_ostream &OS,\n                                const PrintingPolicy &Policy) const;\n\n  // FIXME: Remove string version.\n  std::string getQualifiedNameAsString() const;\n\n  /// Appends a human-readable name for this declaration into the given stream.\n  ///\n  /// This is the method invoked by Sema when displaying a NamedDecl\n  /// in a diagnostic.  It does not necessarily produce the same\n  /// result as printName(); for example, class template\n  /// specializations are printed with their template arguments.\n  virtual void getNameForDiagnostic(raw_ostream &OS,\n                                    const PrintingPolicy &Policy,\n                                    bool Qualified) const;\n\n  /// Determine whether this declaration, if known to be well-formed within\n  /// its context, will replace the declaration OldD if introduced into scope.\n  ///\n  /// A declaration will replace another declaration if, for example, it is\n  /// a redeclaration of the same variable or function, but not if it is a\n  /// declaration of a different kind (function vs. class) or an overloaded\n  /// function.\n  ///\n  /// \\param IsKnownNewer \\c true if this declaration is known to be newer\n  /// than \\p OldD (for instance, if this declaration is newly-created).\n  bool declarationReplaces(NamedDecl *OldD, bool IsKnownNewer = true) const;\n\n  /// Determine whether this declaration has linkage.\n  bool hasLinkage() const;\n\n  using Decl::isModulePrivate;\n  using Decl::setModulePrivate;\n\n  /// Determine whether this declaration is a C++ class member.\n  bool isCXXClassMember() const {\n    const DeclContext *DC = getDeclContext();\n\n    // C++0x [class.mem]p1:\n    //   The enumerators of an unscoped enumeration defined in\n    //   the class are members of the class.\n    if (isa<EnumDecl>(DC))\n      DC = DC->getRedeclContext();\n\n    return DC->isRecord();\n  }\n\n  /// Determine whether the given declaration is an instance member of\n  /// a C++ class.\n  bool isCXXInstanceMember() const;\n\n  /// Determine what kind of linkage this entity has.\n  ///\n  /// This is not the linkage as defined by the standard or the codegen notion\n  /// of linkage. It is just an implementation detail that is used to compute\n  /// those.\n  Linkage getLinkageInternal() const;\n\n  /// Get the linkage from a semantic point of view. Entities in\n  /// anonymous namespaces are external (in c++98).\n  Linkage getFormalLinkage() const {\n    return clang::getFormalLinkage(getLinkageInternal());\n  }\n\n  /// True if this decl has external linkage.\n  bool hasExternalFormalLinkage() const {\n    return isExternalFormalLinkage(getLinkageInternal());\n  }\n\n  bool isExternallyVisible() const {\n    return clang::isExternallyVisible(getLinkageInternal());\n  }\n\n  /// Determine whether this declaration can be redeclared in a\n  /// different translation unit.\n  bool isExternallyDeclarable() const {\n    return isExternallyVisible() && !getOwningModuleForLinkage();\n  }\n\n  /// Determines the visibility of this entity.\n  Visibility getVisibility() const {\n    return getLinkageAndVisibility().getVisibility();\n  }\n\n  /// Determines the linkage and visibility of this entity.\n  LinkageInfo getLinkageAndVisibility() const;\n\n  /// Kinds of explicit visibility.\n  enum ExplicitVisibilityKind {\n    /// Do an LV computation for, ultimately, a type.\n    /// Visibility may be restricted by type visibility settings and\n    /// the visibility of template arguments.\n    VisibilityForType,\n\n    /// Do an LV computation for, ultimately, a non-type declaration.\n    /// Visibility may be restricted by value visibility settings and\n    /// the visibility of template arguments.\n    VisibilityForValue\n  };\n\n  /// If visibility was explicitly specified for this\n  /// declaration, return that visibility.\n  Optional<Visibility>\n  getExplicitVisibility(ExplicitVisibilityKind kind) const;\n\n  /// True if the computed linkage is valid. Used for consistency\n  /// checking. Should always return true.\n  bool isLinkageValid() const;\n\n  /// True if something has required us to compute the linkage\n  /// of this declaration.\n  ///\n  /// Language features which can retroactively change linkage (like a\n  /// typedef name for linkage purposes) may need to consider this,\n  /// but hopefully only in transitory ways during parsing.\n  bool hasLinkageBeenComputed() const {\n    return hasCachedLinkage();\n  }\n\n  /// Looks through UsingDecls and ObjCCompatibleAliasDecls for\n  /// the underlying named decl.\n  NamedDecl *getUnderlyingDecl() {\n    // Fast-path the common case.\n    if (this->getKind() != UsingShadow &&\n        this->getKind() != ConstructorUsingShadow &&\n        this->getKind() != ObjCCompatibleAlias &&\n        this->getKind() != NamespaceAlias)\n      return this;\n\n    return getUnderlyingDeclImpl();\n  }\n  const NamedDecl *getUnderlyingDecl() const {\n    return const_cast<NamedDecl*>(this)->getUnderlyingDecl();\n  }\n\n  NamedDecl *getMostRecentDecl() {\n    return cast<NamedDecl>(static_cast<Decl *>(this)->getMostRecentDecl());\n  }\n  const NamedDecl *getMostRecentDecl() const {\n    return const_cast<NamedDecl*>(this)->getMostRecentDecl();\n  }\n\n  ObjCStringFormatFamily getObjCFStringFormattingFamily() const;\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K >= firstNamed && K <= lastNamed; }\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const NamedDecl &ND) {\n  ND.printName(OS);\n  return OS;\n}\n\n/// Represents the declaration of a label.  Labels also have a\n/// corresponding LabelStmt, which indicates the position that the label was\n/// defined at.  For normal labels, the location of the decl is the same as the\n/// location of the statement.  For GNU local labels (__label__), the decl\n/// location is where the __label__ is.\nclass LabelDecl : public NamedDecl {\n  LabelStmt *TheStmt;\n  StringRef MSAsmName;\n  bool MSAsmNameResolved = false;\n\n  /// For normal labels, this is the same as the main declaration\n  /// label, i.e., the location of the identifier; for GNU local labels,\n  /// this is the location of the __label__ keyword.\n  SourceLocation LocStart;\n\n  LabelDecl(DeclContext *DC, SourceLocation IdentL, IdentifierInfo *II,\n            LabelStmt *S, SourceLocation StartL)\n      : NamedDecl(Label, DC, IdentL, II), TheStmt(S), LocStart(StartL) {}\n\n  void anchor() override;\n\npublic:\n  static LabelDecl *Create(ASTContext &C, DeclContext *DC,\n                           SourceLocation IdentL, IdentifierInfo *II);\n  static LabelDecl *Create(ASTContext &C, DeclContext *DC,\n                           SourceLocation IdentL, IdentifierInfo *II,\n                           SourceLocation GnuLabelL);\n  static LabelDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  LabelStmt *getStmt() const { return TheStmt; }\n  void setStmt(LabelStmt *T) { TheStmt = T; }\n\n  bool isGnuLocal() const { return LocStart != getLocation(); }\n  void setLocStart(SourceLocation L) { LocStart = L; }\n\n  SourceRange getSourceRange() const override LLVM_READONLY {\n    return SourceRange(LocStart, getLocation());\n  }\n\n  bool isMSAsmLabel() const { return !MSAsmName.empty(); }\n  bool isResolvedMSAsmLabel() const { return isMSAsmLabel() && MSAsmNameResolved; }\n  void setMSAsmLabel(StringRef Name);\n  StringRef getMSAsmLabel() const { return MSAsmName; }\n  void setMSAsmLabelResolved() { MSAsmNameResolved = true; }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Label; }\n};\n\n/// Represent a C++ namespace.\nclass NamespaceDecl : public NamedDecl, public DeclContext,\n                      public Redeclarable<NamespaceDecl>\n{\n  /// The starting location of the source range, pointing\n  /// to either the namespace or the inline keyword.\n  SourceLocation LocStart;\n\n  /// The ending location of the source range.\n  SourceLocation RBraceLoc;\n\n  /// A pointer to either the anonymous namespace that lives just inside\n  /// this namespace or to the first namespace in the chain (the latter case\n  /// only when this is not the first in the chain), along with a\n  /// boolean value indicating whether this is an inline namespace.\n  llvm::PointerIntPair<NamespaceDecl *, 1, bool> AnonOrFirstNamespaceAndInline;\n\n  NamespaceDecl(ASTContext &C, DeclContext *DC, bool Inline,\n                SourceLocation StartLoc, SourceLocation IdLoc,\n                IdentifierInfo *Id, NamespaceDecl *PrevDecl);\n\n  using redeclarable_base = Redeclarable<NamespaceDecl>;\n\n  NamespaceDecl *getNextRedeclarationImpl() override;\n  NamespaceDecl *getPreviousDeclImpl() override;\n  NamespaceDecl *getMostRecentDeclImpl() override;\n\npublic:\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n\n  static NamespaceDecl *Create(ASTContext &C, DeclContext *DC,\n                               bool Inline, SourceLocation StartLoc,\n                               SourceLocation IdLoc, IdentifierInfo *Id,\n                               NamespaceDecl *PrevDecl);\n\n  static NamespaceDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  using redecl_range = redeclarable_base::redecl_range;\n  using redecl_iterator = redeclarable_base::redecl_iterator;\n\n  using redeclarable_base::redecls_begin;\n  using redeclarable_base::redecls_end;\n  using redeclarable_base::redecls;\n  using redeclarable_base::getPreviousDecl;\n  using redeclarable_base::getMostRecentDecl;\n  using redeclarable_base::isFirstDecl;\n\n  /// Returns true if this is an anonymous namespace declaration.\n  ///\n  /// For example:\n  /// \\code\n  ///   namespace {\n  ///     ...\n  ///   };\n  /// \\endcode\n  /// q.v. C++ [namespace.unnamed]\n  bool isAnonymousNamespace() const {\n    return !getIdentifier();\n  }\n\n  /// Returns true if this is an inline namespace declaration.\n  bool isInline() const {\n    return AnonOrFirstNamespaceAndInline.getInt();\n  }\n\n  /// Set whether this is an inline namespace declaration.\n  void setInline(bool Inline) {\n    AnonOrFirstNamespaceAndInline.setInt(Inline);\n  }\n\n  /// Get the original (first) namespace declaration.\n  NamespaceDecl *getOriginalNamespace();\n\n  /// Get the original (first) namespace declaration.\n  const NamespaceDecl *getOriginalNamespace() const;\n\n  /// Return true if this declaration is an original (first) declaration\n  /// of the namespace. This is false for non-original (subsequent) namespace\n  /// declarations and anonymous namespaces.\n  bool isOriginalNamespace() const;\n\n  /// Retrieve the anonymous namespace nested inside this namespace,\n  /// if any.\n  NamespaceDecl *getAnonymousNamespace() const {\n    return getOriginalNamespace()->AnonOrFirstNamespaceAndInline.getPointer();\n  }\n\n  void setAnonymousNamespace(NamespaceDecl *D) {\n    getOriginalNamespace()->AnonOrFirstNamespaceAndInline.setPointer(D);\n  }\n\n  /// Retrieves the canonical declaration of this namespace.\n  NamespaceDecl *getCanonicalDecl() override {\n    return getOriginalNamespace();\n  }\n  const NamespaceDecl *getCanonicalDecl() const {\n    return getOriginalNamespace();\n  }\n\n  SourceRange getSourceRange() const override LLVM_READONLY {\n    return SourceRange(LocStart, RBraceLoc);\n  }\n\n  SourceLocation getBeginLoc() const LLVM_READONLY { return LocStart; }\n  SourceLocation getRBraceLoc() const { return RBraceLoc; }\n  void setLocStart(SourceLocation L) { LocStart = L; }\n  void setRBraceLoc(SourceLocation L) { RBraceLoc = L; }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Namespace; }\n  static DeclContext *castToDeclContext(const NamespaceDecl *D) {\n    return static_cast<DeclContext *>(const_cast<NamespaceDecl*>(D));\n  }\n  static NamespaceDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<NamespaceDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// Represent the declaration of a variable (in which case it is\n/// an lvalue) a function (in which case it is a function designator) or\n/// an enum constant.\nclass ValueDecl : public NamedDecl {\n  QualType DeclType;\n\n  void anchor() override;\n\nprotected:\n  ValueDecl(Kind DK, DeclContext *DC, SourceLocation L,\n            DeclarationName N, QualType T)\n    : NamedDecl(DK, DC, L, N), DeclType(T) {}\n\npublic:\n  QualType getType() const { return DeclType; }\n  void setType(QualType newType) { DeclType = newType; }\n\n  /// Determine whether this symbol is weakly-imported,\n  ///        or declared with the weak or weak-ref attr.\n  bool isWeak() const;\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K >= firstValue && K <= lastValue; }\n};\n\n/// A struct with extended info about a syntactic\n/// name qualifier, to be used for the case of out-of-line declarations.\nstruct QualifierInfo {\n  NestedNameSpecifierLoc QualifierLoc;\n\n  /// The number of \"outer\" template parameter lists.\n  /// The count includes all of the template parameter lists that were matched\n  /// against the template-ids occurring into the NNS and possibly (in the\n  /// case of an explicit specialization) a final \"template <>\".\n  unsigned NumTemplParamLists = 0;\n\n  /// A new-allocated array of size NumTemplParamLists,\n  /// containing pointers to the \"outer\" template parameter lists.\n  /// It includes all of the template parameter lists that were matched\n  /// against the template-ids occurring into the NNS and possibly (in the\n  /// case of an explicit specialization) a final \"template <>\".\n  TemplateParameterList** TemplParamLists = nullptr;\n\n  QualifierInfo() = default;\n  QualifierInfo(const QualifierInfo &) = delete;\n  QualifierInfo& operator=(const QualifierInfo &) = delete;\n\n  /// Sets info about \"outer\" template parameter lists.\n  void setTemplateParameterListsInfo(ASTContext &Context,\n                                     ArrayRef<TemplateParameterList *> TPLists);\n};\n\n/// Represents a ValueDecl that came out of a declarator.\n/// Contains type source information through TypeSourceInfo.\nclass DeclaratorDecl : public ValueDecl {\n  // A struct representing a TInfo, a trailing requires-clause and a syntactic\n  // qualifier, to be used for the (uncommon) case of out-of-line declarations\n  // and constrained function decls.\n  struct ExtInfo : public QualifierInfo {\n    TypeSourceInfo *TInfo;\n    Expr *TrailingRequiresClause = nullptr;\n  };\n\n  llvm::PointerUnion<TypeSourceInfo *, ExtInfo *> DeclInfo;\n\n  /// The start of the source range for this declaration,\n  /// ignoring outer template declarations.\n  SourceLocation InnerLocStart;\n\n  bool hasExtInfo() const { return DeclInfo.is<ExtInfo*>(); }\n  ExtInfo *getExtInfo() { return DeclInfo.get<ExtInfo*>(); }\n  const ExtInfo *getExtInfo() const { return DeclInfo.get<ExtInfo*>(); }\n\nprotected:\n  DeclaratorDecl(Kind DK, DeclContext *DC, SourceLocation L,\n                 DeclarationName N, QualType T, TypeSourceInfo *TInfo,\n                 SourceLocation StartL)\n      : ValueDecl(DK, DC, L, N, T), DeclInfo(TInfo), InnerLocStart(StartL) {}\n\npublic:\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n\n  TypeSourceInfo *getTypeSourceInfo() const {\n    return hasExtInfo()\n      ? getExtInfo()->TInfo\n      : DeclInfo.get<TypeSourceInfo*>();\n  }\n\n  void setTypeSourceInfo(TypeSourceInfo *TI) {\n    if (hasExtInfo())\n      getExtInfo()->TInfo = TI;\n    else\n      DeclInfo = TI;\n  }\n\n  /// Return start of source range ignoring outer template declarations.\n  SourceLocation getInnerLocStart() const { return InnerLocStart; }\n  void setInnerLocStart(SourceLocation L) { InnerLocStart = L; }\n\n  /// Return start of source range taking into account any outer template\n  /// declarations.\n  SourceLocation getOuterLocStart() const;\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  SourceLocation getBeginLoc() const LLVM_READONLY {\n    return getOuterLocStart();\n  }\n\n  /// Retrieve the nested-name-specifier that qualifies the name of this\n  /// declaration, if it was present in the source.\n  NestedNameSpecifier *getQualifier() const {\n    return hasExtInfo() ? getExtInfo()->QualifierLoc.getNestedNameSpecifier()\n                        : nullptr;\n  }\n\n  /// Retrieve the nested-name-specifier (with source-location\n  /// information) that qualifies the name of this declaration, if it was\n  /// present in the source.\n  NestedNameSpecifierLoc getQualifierLoc() const {\n    return hasExtInfo() ? getExtInfo()->QualifierLoc\n                        : NestedNameSpecifierLoc();\n  }\n\n  void setQualifierInfo(NestedNameSpecifierLoc QualifierLoc);\n\n  /// \\brief Get the constraint-expression introduced by the trailing\n  /// requires-clause in the function/member declaration, or null if no\n  /// requires-clause was provided.\n  Expr *getTrailingRequiresClause() {\n    return hasExtInfo() ? getExtInfo()->TrailingRequiresClause\n                        : nullptr;\n  }\n\n  const Expr *getTrailingRequiresClause() const {\n    return hasExtInfo() ? getExtInfo()->TrailingRequiresClause\n                        : nullptr;\n  }\n\n  void setTrailingRequiresClause(Expr *TrailingRequiresClause);\n\n  unsigned getNumTemplateParameterLists() const {\n    return hasExtInfo() ? getExtInfo()->NumTemplParamLists : 0;\n  }\n\n  TemplateParameterList *getTemplateParameterList(unsigned index) const {\n    assert(index < getNumTemplateParameterLists());\n    return getExtInfo()->TemplParamLists[index];\n  }\n\n  void setTemplateParameterListsInfo(ASTContext &Context,\n                                     ArrayRef<TemplateParameterList *> TPLists);\n\n  SourceLocation getTypeSpecStartLoc() const;\n  SourceLocation getTypeSpecEndLoc() const;\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) {\n    return K >= firstDeclarator && K <= lastDeclarator;\n  }\n};\n\n/// Structure used to store a statement, the constant value to\n/// which it was evaluated (if any), and whether or not the statement\n/// is an integral constant expression (if known).\nstruct EvaluatedStmt {\n  /// Whether this statement was already evaluated.\n  bool WasEvaluated : 1;\n\n  /// Whether this statement is being evaluated.\n  bool IsEvaluating : 1;\n\n  /// Whether this variable is known to have constant initialization. This is\n  /// currently only computed in C++, for static / thread storage duration\n  /// variables that might have constant initialization and for variables that\n  /// are usable in constant expressions.\n  bool HasConstantInitialization : 1;\n\n  /// Whether this variable is known to have constant destruction. That is,\n  /// whether running the destructor on the initial value is a side-effect\n  /// (and doesn't inspect any state that might have changed during program\n  /// execution). This is currently only computed if the destructor is\n  /// non-trivial.\n  bool HasConstantDestruction : 1;\n\n  /// In C++98, whether the initializer is an ICE. This affects whether the\n  /// variable is usable in constant expressions.\n  bool HasICEInit : 1;\n  bool CheckedForICEInit : 1;\n\n  Stmt *Value;\n  APValue Evaluated;\n\n  EvaluatedStmt()\n      : WasEvaluated(false), IsEvaluating(false),\n        HasConstantInitialization(false), HasConstantDestruction(false),\n        HasICEInit(false), CheckedForICEInit(false) {}\n};\n\n/// Represents a variable declaration or definition.\nclass VarDecl : public DeclaratorDecl, public Redeclarable<VarDecl> {\npublic:\n  /// Initialization styles.\n  enum InitializationStyle {\n    /// C-style initialization with assignment\n    CInit,\n\n    /// Call-style initialization (C++98)\n    CallInit,\n\n    /// Direct list-initialization (C++11)\n    ListInit\n  };\n\n  /// Kinds of thread-local storage.\n  enum TLSKind {\n    /// Not a TLS variable.\n    TLS_None,\n\n    /// TLS with a known-constant initializer.\n    TLS_Static,\n\n    /// TLS with a dynamic initializer.\n    TLS_Dynamic\n  };\n\n  /// Return the string used to specify the storage class \\p SC.\n  ///\n  /// It is illegal to call this function with SC == None.\n  static const char *getStorageClassSpecifierString(StorageClass SC);\n\nprotected:\n  // A pointer union of Stmt * and EvaluatedStmt *. When an EvaluatedStmt, we\n  // have allocated the auxiliary struct of information there.\n  //\n  // TODO: It is a bit unfortunate to use a PointerUnion inside the VarDecl for\n  // this as *many* VarDecls are ParmVarDecls that don't have default\n  // arguments. We could save some space by moving this pointer union to be\n  // allocated in trailing space when necessary.\n  using InitType = llvm::PointerUnion<Stmt *, EvaluatedStmt *>;\n\n  /// The initializer for this variable or, for a ParmVarDecl, the\n  /// C++ default argument.\n  mutable InitType Init;\n\nprivate:\n  friend class ASTDeclReader;\n  friend class ASTNodeImporter;\n  friend class StmtIteratorBase;\n\n  class VarDeclBitfields {\n    friend class ASTDeclReader;\n    friend class VarDecl;\n\n    unsigned SClass : 3;\n    unsigned TSCSpec : 2;\n    unsigned InitStyle : 2;\n\n    /// Whether this variable is an ARC pseudo-__strong variable; see\n    /// isARCPseudoStrong() for details.\n    unsigned ARCPseudoStrong : 1;\n  };\n  enum { NumVarDeclBits = 8 };\n\nprotected:\n  enum { NumParameterIndexBits = 8 };\n\n  enum DefaultArgKind {\n    DAK_None,\n    DAK_Unparsed,\n    DAK_Uninstantiated,\n    DAK_Normal\n  };\n\n  enum { NumScopeDepthOrObjCQualsBits = 7 };\n\n  class ParmVarDeclBitfields {\n    friend class ASTDeclReader;\n    friend class ParmVarDecl;\n\n    unsigned : NumVarDeclBits;\n\n    /// Whether this parameter inherits a default argument from a\n    /// prior declaration.\n    unsigned HasInheritedDefaultArg : 1;\n\n    /// Describes the kind of default argument for this parameter. By default\n    /// this is none. If this is normal, then the default argument is stored in\n    /// the \\c VarDecl initializer expression unless we were unable to parse\n    /// (even an invalid) expression for the default argument.\n    unsigned DefaultArgKind : 2;\n\n    /// Whether this parameter undergoes K&R argument promotion.\n    unsigned IsKNRPromoted : 1;\n\n    /// Whether this parameter is an ObjC method parameter or not.\n    unsigned IsObjCMethodParam : 1;\n\n    /// If IsObjCMethodParam, a Decl::ObjCDeclQualifier.\n    /// Otherwise, the number of function parameter scopes enclosing\n    /// the function parameter scope in which this parameter was\n    /// declared.\n    unsigned ScopeDepthOrObjCQuals : NumScopeDepthOrObjCQualsBits;\n\n    /// The number of parameters preceding this parameter in the\n    /// function parameter scope in which it was declared.\n    unsigned ParameterIndex : NumParameterIndexBits;\n  };\n\n  class NonParmVarDeclBitfields {\n    friend class ASTDeclReader;\n    friend class ImplicitParamDecl;\n    friend class VarDecl;\n\n    unsigned : NumVarDeclBits;\n\n    // FIXME: We need something similar to CXXRecordDecl::DefinitionData.\n    /// Whether this variable is a definition which was demoted due to\n    /// module merge.\n    unsigned IsThisDeclarationADemotedDefinition : 1;\n\n    /// Whether this variable is the exception variable in a C++ catch\n    /// or an Objective-C @catch statement.\n    unsigned ExceptionVar : 1;\n\n    /// Whether this local variable could be allocated in the return\n    /// slot of its function, enabling the named return value optimization\n    /// (NRVO).\n    unsigned NRVOVariable : 1;\n\n    /// Whether this variable is the for-range-declaration in a C++0x\n    /// for-range statement.\n    unsigned CXXForRangeDecl : 1;\n\n    /// Whether this variable is the for-in loop declaration in Objective-C.\n    unsigned ObjCForDecl : 1;\n\n    /// Whether this variable is (C++1z) inline.\n    unsigned IsInline : 1;\n\n    /// Whether this variable has (C++1z) inline explicitly specified.\n    unsigned IsInlineSpecified : 1;\n\n    /// Whether this variable is (C++0x) constexpr.\n    unsigned IsConstexpr : 1;\n\n    /// Whether this variable is the implicit variable for a lambda\n    /// init-capture.\n    unsigned IsInitCapture : 1;\n\n    /// Whether this local extern variable's previous declaration was\n    /// declared in the same block scope. This controls whether we should merge\n    /// the type of this declaration with its previous declaration.\n    unsigned PreviousDeclInSameBlockScope : 1;\n\n    /// Defines kind of the ImplicitParamDecl: 'this', 'self', 'vtt', '_cmd' or\n    /// something else.\n    unsigned ImplicitParamKind : 3;\n\n    unsigned EscapingByref : 1;\n  };\n\n  union {\n    unsigned AllBits;\n    VarDeclBitfields VarDeclBits;\n    ParmVarDeclBitfields ParmVarDeclBits;\n    NonParmVarDeclBitfields NonParmVarDeclBits;\n  };\n\n  VarDecl(Kind DK, ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n          SourceLocation IdLoc, IdentifierInfo *Id, QualType T,\n          TypeSourceInfo *TInfo, StorageClass SC);\n\n  using redeclarable_base = Redeclarable<VarDecl>;\n\n  VarDecl *getNextRedeclarationImpl() override {\n    return getNextRedeclaration();\n  }\n\n  VarDecl *getPreviousDeclImpl() override {\n    return getPreviousDecl();\n  }\n\n  VarDecl *getMostRecentDeclImpl() override {\n    return getMostRecentDecl();\n  }\n\npublic:\n  using redecl_range = redeclarable_base::redecl_range;\n  using redecl_iterator = redeclarable_base::redecl_iterator;\n\n  using redeclarable_base::redecls_begin;\n  using redeclarable_base::redecls_end;\n  using redeclarable_base::redecls;\n  using redeclarable_base::getPreviousDecl;\n  using redeclarable_base::getMostRecentDecl;\n  using redeclarable_base::isFirstDecl;\n\n  static VarDecl *Create(ASTContext &C, DeclContext *DC,\n                         SourceLocation StartLoc, SourceLocation IdLoc,\n                         IdentifierInfo *Id, QualType T, TypeSourceInfo *TInfo,\n                         StorageClass S);\n\n  static VarDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  /// Returns the storage class as written in the source. For the\n  /// computed linkage of symbol, see getLinkage.\n  StorageClass getStorageClass() const {\n    return (StorageClass) VarDeclBits.SClass;\n  }\n  void setStorageClass(StorageClass SC);\n\n  void setTSCSpec(ThreadStorageClassSpecifier TSC) {\n    VarDeclBits.TSCSpec = TSC;\n    assert(VarDeclBits.TSCSpec == TSC && \"truncation\");\n  }\n  ThreadStorageClassSpecifier getTSCSpec() const {\n    return static_cast<ThreadStorageClassSpecifier>(VarDeclBits.TSCSpec);\n  }\n  TLSKind getTLSKind() const;\n\n  /// Returns true if a variable with function scope is a non-static local\n  /// variable.\n  bool hasLocalStorage() const {\n    if (getStorageClass() == SC_None) {\n      // OpenCL v1.2 s6.5.3: The __constant or constant address space name is\n      // used to describe variables allocated in global memory and which are\n      // accessed inside a kernel(s) as read-only variables. As such, variables\n      // in constant address space cannot have local storage.\n      if (getType().getAddressSpace() == LangAS::opencl_constant)\n        return false;\n      // Second check is for C++11 [dcl.stc]p4.\n      return !isFileVarDecl() && getTSCSpec() == TSCS_unspecified;\n    }\n\n    // Global Named Register (GNU extension)\n    if (getStorageClass() == SC_Register && !isLocalVarDeclOrParm())\n      return false;\n\n    // Return true for:  Auto, Register.\n    // Return false for: Extern, Static, PrivateExtern, OpenCLWorkGroupLocal.\n\n    return getStorageClass() >= SC_Auto;\n  }\n\n  /// Returns true if a variable with function scope is a static local\n  /// variable.\n  bool isStaticLocal() const {\n    return (getStorageClass() == SC_Static ||\n            // C++11 [dcl.stc]p4\n            (getStorageClass() == SC_None && getTSCSpec() == TSCS_thread_local))\n      && !isFileVarDecl();\n  }\n\n  /// Returns true if a variable has extern or __private_extern__\n  /// storage.\n  bool hasExternalStorage() const {\n    return getStorageClass() == SC_Extern ||\n           getStorageClass() == SC_PrivateExtern;\n  }\n\n  /// Returns true for all variables that do not have local storage.\n  ///\n  /// This includes all global variables as well as static variables declared\n  /// within a function.\n  bool hasGlobalStorage() const { return !hasLocalStorage(); }\n\n  /// Get the storage duration of this variable, per C++ [basic.stc].\n  StorageDuration getStorageDuration() const {\n    return hasLocalStorage() ? SD_Automatic :\n           getTSCSpec() ? SD_Thread : SD_Static;\n  }\n\n  /// Compute the language linkage.\n  LanguageLinkage getLanguageLinkage() const;\n\n  /// Determines whether this variable is a variable with external, C linkage.\n  bool isExternC() const;\n\n  /// Determines whether this variable's context is, or is nested within,\n  /// a C++ extern \"C\" linkage spec.\n  bool isInExternCContext() const;\n\n  /// Determines whether this variable's context is, or is nested within,\n  /// a C++ extern \"C++\" linkage spec.\n  bool isInExternCXXContext() const;\n\n  /// Returns true for local variable declarations other than parameters.\n  /// Note that this includes static variables inside of functions. It also\n  /// includes variables inside blocks.\n  ///\n  ///   void foo() { int x; static int y; extern int z; }\n  bool isLocalVarDecl() const {\n    if (getKind() != Decl::Var && getKind() != Decl::Decomposition)\n      return false;\n    if (const DeclContext *DC = getLexicalDeclContext())\n      return DC->getRedeclContext()->isFunctionOrMethod();\n    return false;\n  }\n\n  /// Similar to isLocalVarDecl but also includes parameters.\n  bool isLocalVarDeclOrParm() const {\n    return isLocalVarDecl() || getKind() == Decl::ParmVar;\n  }\n\n  /// Similar to isLocalVarDecl, but excludes variables declared in blocks.\n  bool isFunctionOrMethodVarDecl() const {\n    if (getKind() != Decl::Var && getKind() != Decl::Decomposition)\n      return false;\n    const DeclContext *DC = getLexicalDeclContext()->getRedeclContext();\n    return DC->isFunctionOrMethod() && DC->getDeclKind() != Decl::Block;\n  }\n\n  /// Determines whether this is a static data member.\n  ///\n  /// This will only be true in C++, and applies to, e.g., the\n  /// variable 'x' in:\n  /// \\code\n  /// struct S {\n  ///   static int x;\n  /// };\n  /// \\endcode\n  bool isStaticDataMember() const {\n    // If it wasn't static, it would be a FieldDecl.\n    return getKind() != Decl::ParmVar && getDeclContext()->isRecord();\n  }\n\n  VarDecl *getCanonicalDecl() override;\n  const VarDecl *getCanonicalDecl() const {\n    return const_cast<VarDecl*>(this)->getCanonicalDecl();\n  }\n\n  enum DefinitionKind {\n    /// This declaration is only a declaration.\n    DeclarationOnly,\n\n    /// This declaration is a tentative definition.\n    TentativeDefinition,\n\n    /// This declaration is definitely a definition.\n    Definition\n  };\n\n  /// Check whether this declaration is a definition. If this could be\n  /// a tentative definition (in C), don't check whether there's an overriding\n  /// definition.\n  DefinitionKind isThisDeclarationADefinition(ASTContext &) const;\n  DefinitionKind isThisDeclarationADefinition() const {\n    return isThisDeclarationADefinition(getASTContext());\n  }\n\n  /// Check whether this variable is defined in this translation unit.\n  DefinitionKind hasDefinition(ASTContext &) const;\n  DefinitionKind hasDefinition() const {\n    return hasDefinition(getASTContext());\n  }\n\n  /// Get the tentative definition that acts as the real definition in a TU.\n  /// Returns null if there is a proper definition available.\n  VarDecl *getActingDefinition();\n  const VarDecl *getActingDefinition() const {\n    return const_cast<VarDecl*>(this)->getActingDefinition();\n  }\n\n  /// Get the real (not just tentative) definition for this declaration.\n  VarDecl *getDefinition(ASTContext &);\n  const VarDecl *getDefinition(ASTContext &C) const {\n    return const_cast<VarDecl*>(this)->getDefinition(C);\n  }\n  VarDecl *getDefinition() {\n    return getDefinition(getASTContext());\n  }\n  const VarDecl *getDefinition() const {\n    return const_cast<VarDecl*>(this)->getDefinition();\n  }\n\n  /// Determine whether this is or was instantiated from an out-of-line\n  /// definition of a static data member.\n  bool isOutOfLine() const override;\n\n  /// Returns true for file scoped variable declaration.\n  bool isFileVarDecl() const {\n    Kind K = getKind();\n    if (K == ParmVar || K == ImplicitParam)\n      return false;\n\n    if (getLexicalDeclContext()->getRedeclContext()->isFileContext())\n      return true;\n\n    if (isStaticDataMember())\n      return true;\n\n    return false;\n  }\n\n  /// Get the initializer for this variable, no matter which\n  /// declaration it is attached to.\n  const Expr *getAnyInitializer() const {\n    const VarDecl *D;\n    return getAnyInitializer(D);\n  }\n\n  /// Get the initializer for this variable, no matter which\n  /// declaration it is attached to. Also get that declaration.\n  const Expr *getAnyInitializer(const VarDecl *&D) const;\n\n  bool hasInit() const;\n  const Expr *getInit() const {\n    return const_cast<VarDecl *>(this)->getInit();\n  }\n  Expr *getInit();\n\n  /// Retrieve the address of the initializer expression.\n  Stmt **getInitAddress();\n\n  void setInit(Expr *I);\n\n  /// Get the initializing declaration of this variable, if any. This is\n  /// usually the definition, except that for a static data member it can be\n  /// the in-class declaration.\n  VarDecl *getInitializingDeclaration();\n  const VarDecl *getInitializingDeclaration() const {\n    return const_cast<VarDecl *>(this)->getInitializingDeclaration();\n  }\n\n  /// Determine whether this variable's value might be usable in a\n  /// constant expression, according to the relevant language standard.\n  /// This only checks properties of the declaration, and does not check\n  /// whether the initializer is in fact a constant expression.\n  ///\n  /// This corresponds to C++20 [expr.const]p3's notion of a\n  /// \"potentially-constant\" variable.\n  bool mightBeUsableInConstantExpressions(const ASTContext &C) const;\n\n  /// Determine whether this variable's value can be used in a\n  /// constant expression, according to the relevant language standard,\n  /// including checking whether it was initialized by a constant expression.\n  bool isUsableInConstantExpressions(const ASTContext &C) const;\n\n  EvaluatedStmt *ensureEvaluatedStmt() const;\n  EvaluatedStmt *getEvaluatedStmt() const;\n\n  /// Attempt to evaluate the value of the initializer attached to this\n  /// declaration, and produce notes explaining why it cannot be evaluated.\n  /// Returns a pointer to the value if evaluation succeeded, 0 otherwise.\n  APValue *evaluateValue() const;\n\nprivate:\n  APValue *evaluateValueImpl(SmallVectorImpl<PartialDiagnosticAt> &Notes,\n                             bool IsConstantInitialization) const;\n\npublic:\n  /// Return the already-evaluated value of this variable's\n  /// initializer, or NULL if the value is not yet known. Returns pointer\n  /// to untyped APValue if the value could not be evaluated.\n  APValue *getEvaluatedValue() const;\n\n  /// Evaluate the destruction of this variable to determine if it constitutes\n  /// constant destruction.\n  ///\n  /// \\pre hasConstantInitialization()\n  /// \\return \\c true if this variable has constant destruction, \\c false if\n  ///         not.\n  bool evaluateDestruction(SmallVectorImpl<PartialDiagnosticAt> &Notes) const;\n\n  /// Determine whether this variable has constant initialization.\n  ///\n  /// This is only set in two cases: when the language semantics require\n  /// constant initialization (globals in C and some globals in C++), and when\n  /// the variable is usable in constant expressions (constexpr, const int, and\n  /// reference variables in C++).\n  bool hasConstantInitialization() const;\n\n  /// Determine whether the initializer of this variable is an integer constant\n  /// expression. For use in C++98, where this affects whether the variable is\n  /// usable in constant expressions.\n  bool hasICEInitializer(const ASTContext &Context) const;\n\n  /// Evaluate the initializer of this variable to determine whether it's a\n  /// constant initializer. Should only be called once, after completing the\n  /// definition of the variable.\n  bool checkForConstantInitialization(\n      SmallVectorImpl<PartialDiagnosticAt> &Notes) const;\n\n  void setInitStyle(InitializationStyle Style) {\n    VarDeclBits.InitStyle = Style;\n  }\n\n  /// The style of initialization for this declaration.\n  ///\n  /// C-style initialization is \"int x = 1;\". Call-style initialization is\n  /// a C++98 direct-initializer, e.g. \"int x(1);\". The Init expression will be\n  /// the expression inside the parens or a \"ClassType(a,b,c)\" class constructor\n  /// expression for class types. List-style initialization is C++11 syntax,\n  /// e.g. \"int x{1};\". Clients can distinguish between different forms of\n  /// initialization by checking this value. In particular, \"int x = {1};\" is\n  /// C-style, \"int x({1})\" is call-style, and \"int x{1};\" is list-style; the\n  /// Init expression in all three cases is an InitListExpr.\n  InitializationStyle getInitStyle() const {\n    return static_cast<InitializationStyle>(VarDeclBits.InitStyle);\n  }\n\n  /// Whether the initializer is a direct-initializer (list or call).\n  bool isDirectInit() const {\n    return getInitStyle() != CInit;\n  }\n\n  /// If this definition should pretend to be a declaration.\n  bool isThisDeclarationADemotedDefinition() const {\n    return isa<ParmVarDecl>(this) ? false :\n      NonParmVarDeclBits.IsThisDeclarationADemotedDefinition;\n  }\n\n  /// This is a definition which should be demoted to a declaration.\n  ///\n  /// In some cases (mostly module merging) we can end up with two visible\n  /// definitions one of which needs to be demoted to a declaration to keep\n  /// the AST invariants.\n  void demoteThisDefinitionToDeclaration() {\n    assert(isThisDeclarationADefinition() && \"Not a definition!\");\n    assert(!isa<ParmVarDecl>(this) && \"Cannot demote ParmVarDecls!\");\n    NonParmVarDeclBits.IsThisDeclarationADemotedDefinition = 1;\n  }\n\n  /// Determine whether this variable is the exception variable in a\n  /// C++ catch statememt or an Objective-C \\@catch statement.\n  bool isExceptionVariable() const {\n    return isa<ParmVarDecl>(this) ? false : NonParmVarDeclBits.ExceptionVar;\n  }\n  void setExceptionVariable(bool EV) {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.ExceptionVar = EV;\n  }\n\n  /// Determine whether this local variable can be used with the named\n  /// return value optimization (NRVO).\n  ///\n  /// The named return value optimization (NRVO) works by marking certain\n  /// non-volatile local variables of class type as NRVO objects. These\n  /// locals can be allocated within the return slot of their containing\n  /// function, in which case there is no need to copy the object to the\n  /// return slot when returning from the function. Within the function body,\n  /// each return that returns the NRVO object will have this variable as its\n  /// NRVO candidate.\n  bool isNRVOVariable() const {\n    return isa<ParmVarDecl>(this) ? false : NonParmVarDeclBits.NRVOVariable;\n  }\n  void setNRVOVariable(bool NRVO) {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.NRVOVariable = NRVO;\n  }\n\n  /// Determine whether this variable is the for-range-declaration in\n  /// a C++0x for-range statement.\n  bool isCXXForRangeDecl() const {\n    return isa<ParmVarDecl>(this) ? false : NonParmVarDeclBits.CXXForRangeDecl;\n  }\n  void setCXXForRangeDecl(bool FRD) {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.CXXForRangeDecl = FRD;\n  }\n\n  /// Determine whether this variable is a for-loop declaration for a\n  /// for-in statement in Objective-C.\n  bool isObjCForDecl() const {\n    return NonParmVarDeclBits.ObjCForDecl;\n  }\n\n  void setObjCForDecl(bool FRD) {\n    NonParmVarDeclBits.ObjCForDecl = FRD;\n  }\n\n  /// Determine whether this variable is an ARC pseudo-__strong variable. A\n  /// pseudo-__strong variable has a __strong-qualified type but does not\n  /// actually retain the object written into it. Generally such variables are\n  /// also 'const' for safety. There are 3 cases where this will be set, 1) if\n  /// the variable is annotated with the objc_externally_retained attribute, 2)\n  /// if its 'self' in a non-init method, or 3) if its the variable in an for-in\n  /// loop.\n  bool isARCPseudoStrong() const { return VarDeclBits.ARCPseudoStrong; }\n  void setARCPseudoStrong(bool PS) { VarDeclBits.ARCPseudoStrong = PS; }\n\n  /// Whether this variable is (C++1z) inline.\n  bool isInline() const {\n    return isa<ParmVarDecl>(this) ? false : NonParmVarDeclBits.IsInline;\n  }\n  bool isInlineSpecified() const {\n    return isa<ParmVarDecl>(this) ? false\n                                  : NonParmVarDeclBits.IsInlineSpecified;\n  }\n  void setInlineSpecified() {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.IsInline = true;\n    NonParmVarDeclBits.IsInlineSpecified = true;\n  }\n  void setImplicitlyInline() {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.IsInline = true;\n  }\n\n  /// Whether this variable is (C++11) constexpr.\n  bool isConstexpr() const {\n    return isa<ParmVarDecl>(this) ? false : NonParmVarDeclBits.IsConstexpr;\n  }\n  void setConstexpr(bool IC) {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.IsConstexpr = IC;\n  }\n\n  /// Whether this variable is the implicit variable for a lambda init-capture.\n  bool isInitCapture() const {\n    return isa<ParmVarDecl>(this) ? false : NonParmVarDeclBits.IsInitCapture;\n  }\n  void setInitCapture(bool IC) {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.IsInitCapture = IC;\n  }\n\n  /// Determine whether this variable is actually a function parameter pack or\n  /// init-capture pack.\n  bool isParameterPack() const;\n\n  /// Whether this local extern variable declaration's previous declaration\n  /// was declared in the same block scope. Only correct in C++.\n  bool isPreviousDeclInSameBlockScope() const {\n    return isa<ParmVarDecl>(this)\n               ? false\n               : NonParmVarDeclBits.PreviousDeclInSameBlockScope;\n  }\n  void setPreviousDeclInSameBlockScope(bool Same) {\n    assert(!isa<ParmVarDecl>(this));\n    NonParmVarDeclBits.PreviousDeclInSameBlockScope = Same;\n  }\n\n  /// Indicates the capture is a __block variable that is captured by a block\n  /// that can potentially escape (a block for which BlockDecl::doesNotEscape\n  /// returns false).\n  bool isEscapingByref() const;\n\n  /// Indicates the capture is a __block variable that is never captured by an\n  /// escaping block.\n  bool isNonEscapingByref() const;\n\n  void setEscapingByref() {\n    NonParmVarDeclBits.EscapingByref = true;\n  }\n\n  /// Retrieve the variable declaration from which this variable could\n  /// be instantiated, if it is an instantiation (rather than a non-template).\n  VarDecl *getTemplateInstantiationPattern() const;\n\n  /// If this variable is an instantiated static data member of a\n  /// class template specialization, returns the templated static data member\n  /// from which it was instantiated.\n  VarDecl *getInstantiatedFromStaticDataMember() const;\n\n  /// If this variable is an instantiation of a variable template or a\n  /// static data member of a class template, determine what kind of\n  /// template specialization or instantiation this is.\n  TemplateSpecializationKind getTemplateSpecializationKind() const;\n\n  /// Get the template specialization kind of this variable for the purposes of\n  /// template instantiation. This differs from getTemplateSpecializationKind()\n  /// for an instantiation of a class-scope explicit specialization.\n  TemplateSpecializationKind\n  getTemplateSpecializationKindForInstantiation() const;\n\n  /// If this variable is an instantiation of a variable template or a\n  /// static data member of a class template, determine its point of\n  /// instantiation.\n  SourceLocation getPointOfInstantiation() const;\n\n  /// If this variable is an instantiation of a static data member of a\n  /// class template specialization, retrieves the member specialization\n  /// information.\n  MemberSpecializationInfo *getMemberSpecializationInfo() const;\n\n  /// For a static data member that was instantiated from a static\n  /// data member of a class template, set the template specialiation kind.\n  void setTemplateSpecializationKind(TemplateSpecializationKind TSK,\n                        SourceLocation PointOfInstantiation = SourceLocation());\n\n  /// Specify that this variable is an instantiation of the\n  /// static data member VD.\n  void setInstantiationOfStaticDataMember(VarDecl *VD,\n                                          TemplateSpecializationKind TSK);\n\n  /// Retrieves the variable template that is described by this\n  /// variable declaration.\n  ///\n  /// Every variable template is represented as a VarTemplateDecl and a\n  /// VarDecl. The former contains template properties (such as\n  /// the template parameter lists) while the latter contains the\n  /// actual description of the template's\n  /// contents. VarTemplateDecl::getTemplatedDecl() retrieves the\n  /// VarDecl that from a VarTemplateDecl, while\n  /// getDescribedVarTemplate() retrieves the VarTemplateDecl from\n  /// a VarDecl.\n  VarTemplateDecl *getDescribedVarTemplate() const;\n\n  void setDescribedVarTemplate(VarTemplateDecl *Template);\n\n  // Is this variable known to have a definition somewhere in the complete\n  // program? This may be true even if the declaration has internal linkage and\n  // has no definition within this source file.\n  bool isKnownToBeDefined() const;\n\n  /// Is destruction of this variable entirely suppressed? If so, the variable\n  /// need not have a usable destructor at all.\n  bool isNoDestroy(const ASTContext &) const;\n\n  /// Would the destruction of this variable have any effect, and if so, what\n  /// kind?\n  QualType::DestructionKind needsDestruction(const ASTContext &Ctx) const;\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K >= firstVar && K <= lastVar; }\n};\n\nclass ImplicitParamDecl : public VarDecl {\n  void anchor() override;\n\npublic:\n  /// Defines the kind of the implicit parameter: is this an implicit parameter\n  /// with pointer to 'this', 'self', '_cmd', virtual table pointers, captured\n  /// context or something else.\n  enum ImplicitParamKind : unsigned {\n    /// Parameter for Objective-C 'self' argument\n    ObjCSelf,\n\n    /// Parameter for Objective-C '_cmd' argument\n    ObjCCmd,\n\n    /// Parameter for C++ 'this' argument\n    CXXThis,\n\n    /// Parameter for C++ virtual table pointers\n    CXXVTT,\n\n    /// Parameter for captured context\n    CapturedContext,\n\n    /// Other implicit parameter\n    Other,\n  };\n\n  /// Create implicit parameter.\n  static ImplicitParamDecl *Create(ASTContext &C, DeclContext *DC,\n                                   SourceLocation IdLoc, IdentifierInfo *Id,\n                                   QualType T, ImplicitParamKind ParamKind);\n  static ImplicitParamDecl *Create(ASTContext &C, QualType T,\n                                   ImplicitParamKind ParamKind);\n\n  static ImplicitParamDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  ImplicitParamDecl(ASTContext &C, DeclContext *DC, SourceLocation IdLoc,\n                    IdentifierInfo *Id, QualType Type,\n                    ImplicitParamKind ParamKind)\n      : VarDecl(ImplicitParam, C, DC, IdLoc, IdLoc, Id, Type,\n                /*TInfo=*/nullptr, SC_None) {\n    NonParmVarDeclBits.ImplicitParamKind = ParamKind;\n    setImplicit();\n  }\n\n  ImplicitParamDecl(ASTContext &C, QualType Type, ImplicitParamKind ParamKind)\n      : VarDecl(ImplicitParam, C, /*DC=*/nullptr, SourceLocation(),\n                SourceLocation(), /*Id=*/nullptr, Type,\n                /*TInfo=*/nullptr, SC_None) {\n    NonParmVarDeclBits.ImplicitParamKind = ParamKind;\n    setImplicit();\n  }\n\n  /// Returns the implicit parameter kind.\n  ImplicitParamKind getParameterKind() const {\n    return static_cast<ImplicitParamKind>(NonParmVarDeclBits.ImplicitParamKind);\n  }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == ImplicitParam; }\n};\n\n/// Represents a parameter to a function.\nclass ParmVarDecl : public VarDecl {\npublic:\n  enum { MaxFunctionScopeDepth = 255 };\n  enum { MaxFunctionScopeIndex = 255 };\n\nprotected:\n  ParmVarDecl(Kind DK, ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n              SourceLocation IdLoc, IdentifierInfo *Id, QualType T,\n              TypeSourceInfo *TInfo, StorageClass S, Expr *DefArg)\n      : VarDecl(DK, C, DC, StartLoc, IdLoc, Id, T, TInfo, S) {\n    assert(ParmVarDeclBits.HasInheritedDefaultArg == false);\n    assert(ParmVarDeclBits.DefaultArgKind == DAK_None);\n    assert(ParmVarDeclBits.IsKNRPromoted == false);\n    assert(ParmVarDeclBits.IsObjCMethodParam == false);\n    setDefaultArg(DefArg);\n  }\n\npublic:\n  static ParmVarDecl *Create(ASTContext &C, DeclContext *DC,\n                             SourceLocation StartLoc,\n                             SourceLocation IdLoc, IdentifierInfo *Id,\n                             QualType T, TypeSourceInfo *TInfo,\n                             StorageClass S, Expr *DefArg);\n\n  static ParmVarDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  void setObjCMethodScopeInfo(unsigned parameterIndex) {\n    ParmVarDeclBits.IsObjCMethodParam = true;\n    setParameterIndex(parameterIndex);\n  }\n\n  void setScopeInfo(unsigned scopeDepth, unsigned parameterIndex) {\n    assert(!ParmVarDeclBits.IsObjCMethodParam);\n\n    ParmVarDeclBits.ScopeDepthOrObjCQuals = scopeDepth;\n    assert(ParmVarDeclBits.ScopeDepthOrObjCQuals == scopeDepth\n           && \"truncation!\");\n\n    setParameterIndex(parameterIndex);\n  }\n\n  bool isObjCMethodParameter() const {\n    return ParmVarDeclBits.IsObjCMethodParam;\n  }\n\n  /// Determines whether this parameter is destroyed in the callee function.\n  bool isDestroyedInCallee() const;\n\n  unsigned getFunctionScopeDepth() const {\n    if (ParmVarDeclBits.IsObjCMethodParam) return 0;\n    return ParmVarDeclBits.ScopeDepthOrObjCQuals;\n  }\n\n  static constexpr unsigned getMaxFunctionScopeDepth() {\n    return (1u << NumScopeDepthOrObjCQualsBits) - 1;\n  }\n\n  /// Returns the index of this parameter in its prototype or method scope.\n  unsigned getFunctionScopeIndex() const {\n    return getParameterIndex();\n  }\n\n  ObjCDeclQualifier getObjCDeclQualifier() const {\n    if (!ParmVarDeclBits.IsObjCMethodParam) return OBJC_TQ_None;\n    return ObjCDeclQualifier(ParmVarDeclBits.ScopeDepthOrObjCQuals);\n  }\n  void setObjCDeclQualifier(ObjCDeclQualifier QTVal) {\n    assert(ParmVarDeclBits.IsObjCMethodParam);\n    ParmVarDeclBits.ScopeDepthOrObjCQuals = QTVal;\n  }\n\n  /// True if the value passed to this parameter must undergo\n  /// K&R-style default argument promotion:\n  ///\n  /// C99 6.5.2.2.\n  ///   If the expression that denotes the called function has a type\n  ///   that does not include a prototype, the integer promotions are\n  ///   performed on each argument, and arguments that have type float\n  ///   are promoted to double.\n  bool isKNRPromoted() const {\n    return ParmVarDeclBits.IsKNRPromoted;\n  }\n  void setKNRPromoted(bool promoted) {\n    ParmVarDeclBits.IsKNRPromoted = promoted;\n  }\n\n  Expr *getDefaultArg();\n  const Expr *getDefaultArg() const {\n    return const_cast<ParmVarDecl *>(this)->getDefaultArg();\n  }\n\n  void setDefaultArg(Expr *defarg);\n\n  /// Retrieve the source range that covers the entire default\n  /// argument.\n  SourceRange getDefaultArgRange() const;\n  void setUninstantiatedDefaultArg(Expr *arg);\n  Expr *getUninstantiatedDefaultArg();\n  const Expr *getUninstantiatedDefaultArg() const {\n    return const_cast<ParmVarDecl *>(this)->getUninstantiatedDefaultArg();\n  }\n\n  /// Determines whether this parameter has a default argument,\n  /// either parsed or not.\n  bool hasDefaultArg() const;\n\n  /// Determines whether this parameter has a default argument that has not\n  /// yet been parsed. This will occur during the processing of a C++ class\n  /// whose member functions have default arguments, e.g.,\n  /// @code\n  ///   class X {\n  ///   public:\n  ///     void f(int x = 17); // x has an unparsed default argument now\n  ///   }; // x has a regular default argument now\n  /// @endcode\n  bool hasUnparsedDefaultArg() const {\n    return ParmVarDeclBits.DefaultArgKind == DAK_Unparsed;\n  }\n\n  bool hasUninstantiatedDefaultArg() const {\n    return ParmVarDeclBits.DefaultArgKind == DAK_Uninstantiated;\n  }\n\n  /// Specify that this parameter has an unparsed default argument.\n  /// The argument will be replaced with a real default argument via\n  /// setDefaultArg when the class definition enclosing the function\n  /// declaration that owns this default argument is completed.\n  void setUnparsedDefaultArg() {\n    ParmVarDeclBits.DefaultArgKind = DAK_Unparsed;\n  }\n\n  bool hasInheritedDefaultArg() const {\n    return ParmVarDeclBits.HasInheritedDefaultArg;\n  }\n\n  void setHasInheritedDefaultArg(bool I = true) {\n    ParmVarDeclBits.HasInheritedDefaultArg = I;\n  }\n\n  QualType getOriginalType() const;\n\n  /// Sets the function declaration that owns this\n  /// ParmVarDecl. Since ParmVarDecls are often created before the\n  /// FunctionDecls that own them, this routine is required to update\n  /// the DeclContext appropriately.\n  void setOwningFunction(DeclContext *FD) { setDeclContext(FD); }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == ParmVar; }\n\nprivate:\n  enum { ParameterIndexSentinel = (1 << NumParameterIndexBits) - 1 };\n\n  void setParameterIndex(unsigned parameterIndex) {\n    if (parameterIndex >= ParameterIndexSentinel) {\n      setParameterIndexLarge(parameterIndex);\n      return;\n    }\n\n    ParmVarDeclBits.ParameterIndex = parameterIndex;\n    assert(ParmVarDeclBits.ParameterIndex == parameterIndex && \"truncation!\");\n  }\n  unsigned getParameterIndex() const {\n    unsigned d = ParmVarDeclBits.ParameterIndex;\n    return d == ParameterIndexSentinel ? getParameterIndexLarge() : d;\n  }\n\n  void setParameterIndexLarge(unsigned parameterIndex);\n  unsigned getParameterIndexLarge() const;\n};\n\nenum class MultiVersionKind {\n  None,\n  Target,\n  CPUSpecific,\n  CPUDispatch\n};\n\n/// Represents a function declaration or definition.\n///\n/// Since a given function can be declared several times in a program,\n/// there may be several FunctionDecls that correspond to that\n/// function. Only one of those FunctionDecls will be found when\n/// traversing the list of declarations in the context of the\n/// FunctionDecl (e.g., the translation unit); this FunctionDecl\n/// contains all of the information known about the function. Other,\n/// previous declarations of the function are available via the\n/// getPreviousDecl() chain.\nclass FunctionDecl : public DeclaratorDecl,\n                     public DeclContext,\n                     public Redeclarable<FunctionDecl> {\n  // This class stores some data in DeclContext::FunctionDeclBits\n  // to save some space. Use the provided accessors to access it.\npublic:\n  /// The kind of templated function a FunctionDecl can be.\n  enum TemplatedKind {\n    // Not templated.\n    TK_NonTemplate,\n    // The pattern in a function template declaration.\n    TK_FunctionTemplate,\n    // A non-template function that is an instantiation or explicit\n    // specialization of a member of a templated class.\n    TK_MemberSpecialization,\n    // An instantiation or explicit specialization of a function template.\n    // Note: this might have been instantiated from a templated class if it\n    // is a class-scope explicit specialization.\n    TK_FunctionTemplateSpecialization,\n    // A function template specialization that hasn't yet been resolved to a\n    // particular specialized function template.\n    TK_DependentFunctionTemplateSpecialization\n  };\n\n  /// Stashed information about a defaulted function definition whose body has\n  /// not yet been lazily generated.\n  class DefaultedFunctionInfo final\n      : llvm::TrailingObjects<DefaultedFunctionInfo, DeclAccessPair> {\n    friend TrailingObjects;\n    unsigned NumLookups;\n\n  public:\n    static DefaultedFunctionInfo *Create(ASTContext &Context,\n                                         ArrayRef<DeclAccessPair> Lookups);\n    /// Get the unqualified lookup results that should be used in this\n    /// defaulted function definition.\n    ArrayRef<DeclAccessPair> getUnqualifiedLookups() const {\n      return {getTrailingObjects<DeclAccessPair>(), NumLookups};\n    }\n  };\n\nprivate:\n  /// A new[]'d array of pointers to VarDecls for the formal\n  /// parameters of this function.  This is null if a prototype or if there are\n  /// no formals.\n  ParmVarDecl **ParamInfo = nullptr;\n\n  /// The active member of this union is determined by\n  /// FunctionDeclBits.HasDefaultedFunctionInfo.\n  union {\n    /// The body of the function.\n    LazyDeclStmtPtr Body;\n    /// Information about a future defaulted function definition.\n    DefaultedFunctionInfo *DefaultedInfo;\n  };\n\n  unsigned ODRHash;\n\n  /// End part of this FunctionDecl's source range.\n  ///\n  /// We could compute the full range in getSourceRange(). However, when we're\n  /// dealing with a function definition deserialized from a PCH/AST file,\n  /// we can only compute the full range once the function body has been\n  /// de-serialized, so it's far better to have the (sometimes-redundant)\n  /// EndRangeLoc.\n  SourceLocation EndRangeLoc;\n\n  /// The template or declaration that this declaration\n  /// describes or was instantiated from, respectively.\n  ///\n  /// For non-templates, this value will be NULL. For function\n  /// declarations that describe a function template, this will be a\n  /// pointer to a FunctionTemplateDecl. For member functions\n  /// of class template specializations, this will be a MemberSpecializationInfo\n  /// pointer containing information about the specialization.\n  /// For function template specializations, this will be a\n  /// FunctionTemplateSpecializationInfo, which contains information about\n  /// the template being specialized and the template arguments involved in\n  /// that specialization.\n  llvm::PointerUnion<FunctionTemplateDecl *,\n                     MemberSpecializationInfo *,\n                     FunctionTemplateSpecializationInfo *,\n                     DependentFunctionTemplateSpecializationInfo *>\n    TemplateOrSpecialization;\n\n  /// Provides source/type location info for the declaration name embedded in\n  /// the DeclaratorDecl base class.\n  DeclarationNameLoc DNLoc;\n\n  /// Specify that this function declaration is actually a function\n  /// template specialization.\n  ///\n  /// \\param C the ASTContext.\n  ///\n  /// \\param Template the function template that this function template\n  /// specialization specializes.\n  ///\n  /// \\param TemplateArgs the template arguments that produced this\n  /// function template specialization from the template.\n  ///\n  /// \\param InsertPos If non-NULL, the position in the function template\n  /// specialization set where the function template specialization data will\n  /// be inserted.\n  ///\n  /// \\param TSK the kind of template specialization this is.\n  ///\n  /// \\param TemplateArgsAsWritten location info of template arguments.\n  ///\n  /// \\param PointOfInstantiation point at which the function template\n  /// specialization was first instantiated.\n  void setFunctionTemplateSpecialization(ASTContext &C,\n                                         FunctionTemplateDecl *Template,\n                                       const TemplateArgumentList *TemplateArgs,\n                                         void *InsertPos,\n                                         TemplateSpecializationKind TSK,\n                          const TemplateArgumentListInfo *TemplateArgsAsWritten,\n                                         SourceLocation PointOfInstantiation);\n\n  /// Specify that this record is an instantiation of the\n  /// member function FD.\n  void setInstantiationOfMemberFunction(ASTContext &C, FunctionDecl *FD,\n                                        TemplateSpecializationKind TSK);\n\n  void setParams(ASTContext &C, ArrayRef<ParmVarDecl *> NewParamInfo);\n\n  // This is unfortunately needed because ASTDeclWriter::VisitFunctionDecl\n  // need to access this bit but we want to avoid making ASTDeclWriter\n  // a friend of FunctionDeclBitfields just for this.\n  bool isDeletedBit() const { return FunctionDeclBits.IsDeleted; }\n\n  /// Whether an ODRHash has been stored.\n  bool hasODRHash() const { return FunctionDeclBits.HasODRHash; }\n\n  /// State that an ODRHash has been stored.\n  void setHasODRHash(bool B = true) { FunctionDeclBits.HasODRHash = B; }\n\nprotected:\n  FunctionDecl(Kind DK, ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n               const DeclarationNameInfo &NameInfo, QualType T,\n               TypeSourceInfo *TInfo, StorageClass S, bool isInlineSpecified,\n               ConstexprSpecKind ConstexprKind,\n               Expr *TrailingRequiresClause = nullptr);\n\n  using redeclarable_base = Redeclarable<FunctionDecl>;\n\n  FunctionDecl *getNextRedeclarationImpl() override {\n    return getNextRedeclaration();\n  }\n\n  FunctionDecl *getPreviousDeclImpl() override {\n    return getPreviousDecl();\n  }\n\n  FunctionDecl *getMostRecentDeclImpl() override {\n    return getMostRecentDecl();\n  }\n\npublic:\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n\n  using redecl_range = redeclarable_base::redecl_range;\n  using redecl_iterator = redeclarable_base::redecl_iterator;\n\n  using redeclarable_base::redecls_begin;\n  using redeclarable_base::redecls_end;\n  using redeclarable_base::redecls;\n  using redeclarable_base::getPreviousDecl;\n  using redeclarable_base::getMostRecentDecl;\n  using redeclarable_base::isFirstDecl;\n\n  static FunctionDecl *\n  Create(ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n         SourceLocation NLoc, DeclarationName N, QualType T,\n         TypeSourceInfo *TInfo, StorageClass SC, bool isInlineSpecified = false,\n         bool hasWrittenPrototype = true,\n         ConstexprSpecKind ConstexprKind = ConstexprSpecKind::Unspecified,\n         Expr *TrailingRequiresClause = nullptr) {\n    DeclarationNameInfo NameInfo(N, NLoc);\n    return FunctionDecl::Create(C, DC, StartLoc, NameInfo, T, TInfo, SC,\n                                isInlineSpecified, hasWrittenPrototype,\n                                ConstexprKind, TrailingRequiresClause);\n  }\n\n  static FunctionDecl *Create(ASTContext &C, DeclContext *DC,\n                              SourceLocation StartLoc,\n                              const DeclarationNameInfo &NameInfo, QualType T,\n                              TypeSourceInfo *TInfo, StorageClass SC,\n                              bool isInlineSpecified, bool hasWrittenPrototype,\n                              ConstexprSpecKind ConstexprKind,\n                              Expr *TrailingRequiresClause);\n\n  static FunctionDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  DeclarationNameInfo getNameInfo() const {\n    return DeclarationNameInfo(getDeclName(), getLocation(), DNLoc);\n  }\n\n  void getNameForDiagnostic(raw_ostream &OS, const PrintingPolicy &Policy,\n                            bool Qualified) const override;\n\n  void setRangeEnd(SourceLocation E) { EndRangeLoc = E; }\n\n  /// Returns the location of the ellipsis of a variadic function.\n  SourceLocation getEllipsisLoc() const {\n    const auto *FPT = getType()->getAs<FunctionProtoType>();\n    if (FPT && FPT->isVariadic())\n      return FPT->getEllipsisLoc();\n    return SourceLocation();\n  }\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  // Function definitions.\n  //\n  // A function declaration may be:\n  // - a non defining declaration,\n  // - a definition. A function may be defined because:\n  //   - it has a body, or will have it in the case of late parsing.\n  //   - it has an uninstantiated body. The body does not exist because the\n  //     function is not used yet, but the declaration is considered a\n  //     definition and does not allow other definition of this function.\n  //   - it does not have a user specified body, but it does not allow\n  //     redefinition, because it is deleted/defaulted or is defined through\n  //     some other mechanism (alias, ifunc).\n\n  /// Returns true if the function has a body.\n  ///\n  /// The function body might be in any of the (re-)declarations of this\n  /// function. The variant that accepts a FunctionDecl pointer will set that\n  /// function declaration to the actual declaration containing the body (if\n  /// there is one).\n  bool hasBody(const FunctionDecl *&Definition) const;\n\n  bool hasBody() const override {\n    const FunctionDecl* Definition;\n    return hasBody(Definition);\n  }\n\n  /// Returns whether the function has a trivial body that does not require any\n  /// specific codegen.\n  bool hasTrivialBody() const;\n\n  /// Returns true if the function has a definition that does not need to be\n  /// instantiated.\n  ///\n  /// The variant that accepts a FunctionDecl pointer will set that function\n  /// declaration to the declaration that is a definition (if there is one).\n  ///\n  /// \\param CheckForPendingFriendDefinition If \\c true, also check for friend\n  ///        declarations that were instantiataed from function definitions.\n  ///        Such a declaration behaves as if it is a definition for the\n  ///        purpose of redefinition checking, but isn't actually a \"real\"\n  ///        definition until its body is instantiated.\n  bool isDefined(const FunctionDecl *&Definition,\n                 bool CheckForPendingFriendDefinition = false) const;\n\n  bool isDefined() const {\n    const FunctionDecl* Definition;\n    return isDefined(Definition);\n  }\n\n  /// Get the definition for this declaration.\n  FunctionDecl *getDefinition() {\n    const FunctionDecl *Definition;\n    if (isDefined(Definition))\n      return const_cast<FunctionDecl *>(Definition);\n    return nullptr;\n  }\n  const FunctionDecl *getDefinition() const {\n    return const_cast<FunctionDecl *>(this)->getDefinition();\n  }\n\n  /// Retrieve the body (definition) of the function. The function body might be\n  /// in any of the (re-)declarations of this function. The variant that accepts\n  /// a FunctionDecl pointer will set that function declaration to the actual\n  /// declaration containing the body (if there is one).\n  /// NOTE: For checking if there is a body, use hasBody() instead, to avoid\n  /// unnecessary AST de-serialization of the body.\n  Stmt *getBody(const FunctionDecl *&Definition) const;\n\n  Stmt *getBody() const override {\n    const FunctionDecl* Definition;\n    return getBody(Definition);\n  }\n\n  /// Returns whether this specific declaration of the function is also a\n  /// definition that does not contain uninstantiated body.\n  ///\n  /// This does not determine whether the function has been defined (e.g., in a\n  /// previous definition); for that information, use isDefined.\n  ///\n  /// Note: the function declaration does not become a definition until the\n  /// parser reaches the definition, if called before, this function will return\n  /// `false`.\n  bool isThisDeclarationADefinition() const {\n    return isDeletedAsWritten() || isDefaulted() ||\n           doesThisDeclarationHaveABody() || hasSkippedBody() ||\n           willHaveBody() || hasDefiningAttr();\n  }\n\n  /// Determine whether this specific declaration of the function is a friend\n  /// declaration that was instantiated from a function definition. Such\n  /// declarations behave like definitions in some contexts.\n  bool isThisDeclarationInstantiatedFromAFriendDefinition() const;\n\n  /// Returns whether this specific declaration of the function has a body.\n  bool doesThisDeclarationHaveABody() const {\n    return (!FunctionDeclBits.HasDefaultedFunctionInfo && Body) ||\n           isLateTemplateParsed();\n  }\n\n  void setBody(Stmt *B);\n  void setLazyBody(uint64_t Offset) {\n    FunctionDeclBits.HasDefaultedFunctionInfo = false;\n    Body = LazyDeclStmtPtr(Offset);\n  }\n\n  void setDefaultedFunctionInfo(DefaultedFunctionInfo *Info);\n  DefaultedFunctionInfo *getDefaultedFunctionInfo() const;\n\n  /// Whether this function is variadic.\n  bool isVariadic() const;\n\n  /// Whether this function is marked as virtual explicitly.\n  bool isVirtualAsWritten() const {\n    return FunctionDeclBits.IsVirtualAsWritten;\n  }\n\n  /// State that this function is marked as virtual explicitly.\n  void setVirtualAsWritten(bool V) { FunctionDeclBits.IsVirtualAsWritten = V; }\n\n  /// Whether this virtual function is pure, i.e. makes the containing class\n  /// abstract.\n  bool isPure() const { return FunctionDeclBits.IsPure; }\n  void setPure(bool P = true);\n\n  /// Whether this templated function will be late parsed.\n  bool isLateTemplateParsed() const {\n    return FunctionDeclBits.IsLateTemplateParsed;\n  }\n\n  /// State that this templated function will be late parsed.\n  void setLateTemplateParsed(bool ILT = true) {\n    FunctionDeclBits.IsLateTemplateParsed = ILT;\n  }\n\n  /// Whether this function is \"trivial\" in some specialized C++ senses.\n  /// Can only be true for default constructors, copy constructors,\n  /// copy assignment operators, and destructors.  Not meaningful until\n  /// the class has been fully built by Sema.\n  bool isTrivial() const { return FunctionDeclBits.IsTrivial; }\n  void setTrivial(bool IT) { FunctionDeclBits.IsTrivial = IT; }\n\n  bool isTrivialForCall() const { return FunctionDeclBits.IsTrivialForCall; }\n  void setTrivialForCall(bool IT) { FunctionDeclBits.IsTrivialForCall = IT; }\n\n  /// Whether this function is defaulted. Valid for e.g.\n  /// special member functions, defaulted comparisions (not methods!).\n  bool isDefaulted() const { return FunctionDeclBits.IsDefaulted; }\n  void setDefaulted(bool D = true) { FunctionDeclBits.IsDefaulted = D; }\n\n  /// Whether this function is explicitly defaulted.\n  bool isExplicitlyDefaulted() const {\n    return FunctionDeclBits.IsExplicitlyDefaulted;\n  }\n\n  /// State that this function is explicitly defaulted.\n  void setExplicitlyDefaulted(bool ED = true) {\n    FunctionDeclBits.IsExplicitlyDefaulted = ED;\n  }\n\n  /// True if this method is user-declared and was not\n  /// deleted or defaulted on its first declaration.\n  bool isUserProvided() const {\n    auto *DeclAsWritten = this;\n    if (FunctionDecl *Pattern = getTemplateInstantiationPattern())\n      DeclAsWritten = Pattern;\n    return !(DeclAsWritten->isDeleted() ||\n             DeclAsWritten->getCanonicalDecl()->isDefaulted());\n  }\n\n  /// Whether falling off this function implicitly returns null/zero.\n  /// If a more specific implicit return value is required, front-ends\n  /// should synthesize the appropriate return statements.\n  bool hasImplicitReturnZero() const {\n    return FunctionDeclBits.HasImplicitReturnZero;\n  }\n\n  /// State that falling off this function implicitly returns null/zero.\n  /// If a more specific implicit return value is required, front-ends\n  /// should synthesize the appropriate return statements.\n  void setHasImplicitReturnZero(bool IRZ) {\n    FunctionDeclBits.HasImplicitReturnZero = IRZ;\n  }\n\n  /// Whether this function has a prototype, either because one\n  /// was explicitly written or because it was \"inherited\" by merging\n  /// a declaration without a prototype with a declaration that has a\n  /// prototype.\n  bool hasPrototype() const {\n    return hasWrittenPrototype() || hasInheritedPrototype();\n  }\n\n  /// Whether this function has a written prototype.\n  bool hasWrittenPrototype() const {\n    return FunctionDeclBits.HasWrittenPrototype;\n  }\n\n  /// State that this function has a written prototype.\n  void setHasWrittenPrototype(bool P = true) {\n    FunctionDeclBits.HasWrittenPrototype = P;\n  }\n\n  /// Whether this function inherited its prototype from a\n  /// previous declaration.\n  bool hasInheritedPrototype() const {\n    return FunctionDeclBits.HasInheritedPrototype;\n  }\n\n  /// State that this function inherited its prototype from a\n  /// previous declaration.\n  void setHasInheritedPrototype(bool P = true) {\n    FunctionDeclBits.HasInheritedPrototype = P;\n  }\n\n  /// Whether this is a (C++11) constexpr function or constexpr constructor.\n  bool isConstexpr() const {\n    return getConstexprKind() != ConstexprSpecKind::Unspecified;\n  }\n  void setConstexprKind(ConstexprSpecKind CSK) {\n    FunctionDeclBits.ConstexprKind = static_cast<uint64_t>(CSK);\n  }\n  ConstexprSpecKind getConstexprKind() const {\n    return static_cast<ConstexprSpecKind>(FunctionDeclBits.ConstexprKind);\n  }\n  bool isConstexprSpecified() const {\n    return getConstexprKind() == ConstexprSpecKind::Constexpr;\n  }\n  bool isConsteval() const {\n    return getConstexprKind() == ConstexprSpecKind::Consteval;\n  }\n\n  /// Whether the instantiation of this function is pending.\n  /// This bit is set when the decision to instantiate this function is made\n  /// and unset if and when the function body is created. That leaves out\n  /// cases where instantiation did not happen because the template definition\n  /// was not seen in this TU. This bit remains set in those cases, under the\n  /// assumption that the instantiation will happen in some other TU.\n  bool instantiationIsPending() const {\n    return FunctionDeclBits.InstantiationIsPending;\n  }\n\n  /// State that the instantiation of this function is pending.\n  /// (see instantiationIsPending)\n  void setInstantiationIsPending(bool IC) {\n    FunctionDeclBits.InstantiationIsPending = IC;\n  }\n\n  /// Indicates the function uses __try.\n  bool usesSEHTry() const { return FunctionDeclBits.UsesSEHTry; }\n  void setUsesSEHTry(bool UST) { FunctionDeclBits.UsesSEHTry = UST; }\n\n  /// Whether this function has been deleted.\n  ///\n  /// A function that is \"deleted\" (via the C++0x \"= delete\" syntax)\n  /// acts like a normal function, except that it cannot actually be\n  /// called or have its address taken. Deleted functions are\n  /// typically used in C++ overload resolution to attract arguments\n  /// whose type or lvalue/rvalue-ness would permit the use of a\n  /// different overload that would behave incorrectly. For example,\n  /// one might use deleted functions to ban implicit conversion from\n  /// a floating-point number to an Integer type:\n  ///\n  /// @code\n  /// struct Integer {\n  ///   Integer(long); // construct from a long\n  ///   Integer(double) = delete; // no construction from float or double\n  ///   Integer(long double) = delete; // no construction from long double\n  /// };\n  /// @endcode\n  // If a function is deleted, its first declaration must be.\n  bool isDeleted() const {\n    return getCanonicalDecl()->FunctionDeclBits.IsDeleted;\n  }\n\n  bool isDeletedAsWritten() const {\n    return FunctionDeclBits.IsDeleted && !isDefaulted();\n  }\n\n  void setDeletedAsWritten(bool D = true) { FunctionDeclBits.IsDeleted = D; }\n\n  /// Determines whether this function is \"main\", which is the\n  /// entry point into an executable program.\n  bool isMain() const;\n\n  /// Determines whether this function is a MSVCRT user defined entry\n  /// point.\n  bool isMSVCRTEntryPoint() const;\n\n  /// Determines whether this operator new or delete is one\n  /// of the reserved global placement operators:\n  ///    void *operator new(size_t, void *);\n  ///    void *operator new[](size_t, void *);\n  ///    void operator delete(void *, void *);\n  ///    void operator delete[](void *, void *);\n  /// These functions have special behavior under [new.delete.placement]:\n  ///    These functions are reserved, a C++ program may not define\n  ///    functions that displace the versions in the Standard C++ library.\n  ///    The provisions of [basic.stc.dynamic] do not apply to these\n  ///    reserved placement forms of operator new and operator delete.\n  ///\n  /// This function must be an allocation or deallocation function.\n  bool isReservedGlobalPlacementOperator() const;\n\n  /// Determines whether this function is one of the replaceable\n  /// global allocation functions:\n  ///    void *operator new(size_t);\n  ///    void *operator new(size_t, const std::nothrow_t &) noexcept;\n  ///    void *operator new[](size_t);\n  ///    void *operator new[](size_t, const std::nothrow_t &) noexcept;\n  ///    void operator delete(void *) noexcept;\n  ///    void operator delete(void *, std::size_t) noexcept;      [C++1y]\n  ///    void operator delete(void *, const std::nothrow_t &) noexcept;\n  ///    void operator delete[](void *) noexcept;\n  ///    void operator delete[](void *, std::size_t) noexcept;    [C++1y]\n  ///    void operator delete[](void *, const std::nothrow_t &) noexcept;\n  /// These functions have special behavior under C++1y [expr.new]:\n  ///    An implementation is allowed to omit a call to a replaceable global\n  ///    allocation function. [...]\n  ///\n  /// If this function is an aligned allocation/deallocation function, return\n  /// the parameter number of the requested alignment through AlignmentParam.\n  ///\n  /// If this function is an allocation/deallocation function that takes\n  /// the `std::nothrow_t` tag, return true through IsNothrow,\n  bool isReplaceableGlobalAllocationFunction(\n      Optional<unsigned> *AlignmentParam = nullptr,\n      bool *IsNothrow = nullptr) const;\n\n  /// Determine if this function provides an inline implementation of a builtin.\n  bool isInlineBuiltinDeclaration() const;\n\n  /// Determine whether this is a destroying operator delete.\n  bool isDestroyingOperatorDelete() const;\n\n  /// Compute the language linkage.\n  LanguageLinkage getLanguageLinkage() const;\n\n  /// Determines whether this function is a function with\n  /// external, C linkage.\n  bool isExternC() const;\n\n  /// Determines whether this function's context is, or is nested within,\n  /// a C++ extern \"C\" linkage spec.\n  bool isInExternCContext() const;\n\n  /// Determines whether this function's context is, or is nested within,\n  /// a C++ extern \"C++\" linkage spec.\n  bool isInExternCXXContext() const;\n\n  /// Determines whether this is a global function.\n  bool isGlobal() const;\n\n  /// Determines whether this function is known to be 'noreturn', through\n  /// an attribute on its declaration or its type.\n  bool isNoReturn() const;\n\n  /// True if the function was a definition but its body was skipped.\n  bool hasSkippedBody() const { return FunctionDeclBits.HasSkippedBody; }\n  void setHasSkippedBody(bool Skipped = true) {\n    FunctionDeclBits.HasSkippedBody = Skipped;\n  }\n\n  /// True if this function will eventually have a body, once it's fully parsed.\n  bool willHaveBody() const { return FunctionDeclBits.WillHaveBody; }\n  void setWillHaveBody(bool V = true) { FunctionDeclBits.WillHaveBody = V; }\n\n  /// True if this function is considered a multiversioned function.\n  bool isMultiVersion() const {\n    return getCanonicalDecl()->FunctionDeclBits.IsMultiVersion;\n  }\n\n  /// Sets the multiversion state for this declaration and all of its\n  /// redeclarations.\n  void setIsMultiVersion(bool V = true) {\n    getCanonicalDecl()->FunctionDeclBits.IsMultiVersion = V;\n  }\n\n  /// Gets the kind of multiversioning attribute this declaration has. Note that\n  /// this can return a value even if the function is not multiversion, such as\n  /// the case of 'target'.\n  MultiVersionKind getMultiVersionKind() const;\n\n\n  /// True if this function is a multiversioned dispatch function as a part of\n  /// the cpu_specific/cpu_dispatch functionality.\n  bool isCPUDispatchMultiVersion() const;\n  /// True if this function is a multiversioned processor specific function as a\n  /// part of the cpu_specific/cpu_dispatch functionality.\n  bool isCPUSpecificMultiVersion() const;\n\n  /// True if this function is a multiversioned dispatch function as a part of\n  /// the target functionality.\n  bool isTargetMultiVersion() const;\n\n  /// \\brief Get the associated-constraints of this function declaration.\n  /// Currently, this will either be a vector of size 1 containing the\n  /// trailing-requires-clause or an empty vector.\n  ///\n  /// Use this instead of getTrailingRequiresClause for concepts APIs that\n  /// accept an ArrayRef of constraint expressions.\n  void getAssociatedConstraints(SmallVectorImpl<const Expr *> &AC) const {\n    if (auto *TRC = getTrailingRequiresClause())\n      AC.push_back(TRC);\n  }\n\n  void setPreviousDeclaration(FunctionDecl * PrevDecl);\n\n  FunctionDecl *getCanonicalDecl() override;\n  const FunctionDecl *getCanonicalDecl() const {\n    return const_cast<FunctionDecl*>(this)->getCanonicalDecl();\n  }\n\n  unsigned getBuiltinID(bool ConsiderWrapperFunctions = false) const;\n\n  // ArrayRef interface to parameters.\n  ArrayRef<ParmVarDecl *> parameters() const {\n    return {ParamInfo, getNumParams()};\n  }\n  MutableArrayRef<ParmVarDecl *> parameters() {\n    return {ParamInfo, getNumParams()};\n  }\n\n  // Iterator access to formal parameters.\n  using param_iterator = MutableArrayRef<ParmVarDecl *>::iterator;\n  using param_const_iterator = ArrayRef<ParmVarDecl *>::const_iterator;\n\n  bool param_empty() const { return parameters().empty(); }\n  param_iterator param_begin() { return parameters().begin(); }\n  param_iterator param_end() { return parameters().end(); }\n  param_const_iterator param_begin() const { return parameters().begin(); }\n  param_const_iterator param_end() const { return parameters().end(); }\n  size_t param_size() const { return parameters().size(); }\n\n  /// Return the number of parameters this function must have based on its\n  /// FunctionType.  This is the length of the ParamInfo array after it has been\n  /// created.\n  unsigned getNumParams() const;\n\n  const ParmVarDecl *getParamDecl(unsigned i) const {\n    assert(i < getNumParams() && \"Illegal param #\");\n    return ParamInfo[i];\n  }\n  ParmVarDecl *getParamDecl(unsigned i) {\n    assert(i < getNumParams() && \"Illegal param #\");\n    return ParamInfo[i];\n  }\n  void setParams(ArrayRef<ParmVarDecl *> NewParamInfo) {\n    setParams(getASTContext(), NewParamInfo);\n  }\n\n  /// Returns the minimum number of arguments needed to call this function. This\n  /// may be fewer than the number of function parameters, if some of the\n  /// parameters have default arguments (in C++).\n  unsigned getMinRequiredArguments() const;\n\n  /// Determine whether this function has a single parameter, or multiple\n  /// parameters where all but the first have default arguments.\n  ///\n  /// This notion is used in the definition of copy/move constructors and\n  /// initializer list constructors. Note that, unlike getMinRequiredArguments,\n  /// parameter packs are not treated specially here.\n  bool hasOneParamOrDefaultArgs() const;\n\n  /// Find the source location information for how the type of this function\n  /// was written. May be absent (for example if the function was declared via\n  /// a typedef) and may contain a different type from that of the function\n  /// (for example if the function type was adjusted by an attribute).\n  FunctionTypeLoc getFunctionTypeLoc() const;\n\n  QualType getReturnType() const {\n    return getType()->castAs<FunctionType>()->getReturnType();\n  }\n\n  /// Attempt to compute an informative source range covering the\n  /// function return type. This may omit qualifiers and other information with\n  /// limited representation in the AST.\n  SourceRange getReturnTypeSourceRange() const;\n\n  /// Attempt to compute an informative source range covering the\n  /// function parameters, including the ellipsis of a variadic function.\n  /// The source range excludes the parentheses, and is invalid if there are\n  /// no parameters and no ellipsis.\n  SourceRange getParametersSourceRange() const;\n\n  /// Get the declared return type, which may differ from the actual return\n  /// type if the return type is deduced.\n  QualType getDeclaredReturnType() const {\n    auto *TSI = getTypeSourceInfo();\n    QualType T = TSI ? TSI->getType() : getType();\n    return T->castAs<FunctionType>()->getReturnType();\n  }\n\n  /// Gets the ExceptionSpecificationType as declared.\n  ExceptionSpecificationType getExceptionSpecType() const {\n    auto *TSI = getTypeSourceInfo();\n    QualType T = TSI ? TSI->getType() : getType();\n    const auto *FPT = T->getAs<FunctionProtoType>();\n    return FPT ? FPT->getExceptionSpecType() : EST_None;\n  }\n\n  /// Attempt to compute an informative source range covering the\n  /// function exception specification, if any.\n  SourceRange getExceptionSpecSourceRange() const;\n\n  /// Determine the type of an expression that calls this function.\n  QualType getCallResultType() const {\n    return getType()->castAs<FunctionType>()->getCallResultType(\n        getASTContext());\n  }\n\n  /// Returns the storage class as written in the source. For the\n  /// computed linkage of symbol, see getLinkage.\n  StorageClass getStorageClass() const {\n    return static_cast<StorageClass>(FunctionDeclBits.SClass);\n  }\n\n  /// Sets the storage class as written in the source.\n  void setStorageClass(StorageClass SClass) {\n    FunctionDeclBits.SClass = SClass;\n  }\n\n  /// Determine whether the \"inline\" keyword was specified for this\n  /// function.\n  bool isInlineSpecified() const { return FunctionDeclBits.IsInlineSpecified; }\n\n  /// Set whether the \"inline\" keyword was specified for this function.\n  void setInlineSpecified(bool I) {\n    FunctionDeclBits.IsInlineSpecified = I;\n    FunctionDeclBits.IsInline = I;\n  }\n\n  /// Flag that this function is implicitly inline.\n  void setImplicitlyInline(bool I = true) { FunctionDeclBits.IsInline = I; }\n\n  /// Determine whether this function should be inlined, because it is\n  /// either marked \"inline\" or \"constexpr\" or is a member function of a class\n  /// that was defined in the class body.\n  bool isInlined() const { return FunctionDeclBits.IsInline; }\n\n  bool isInlineDefinitionExternallyVisible() const;\n\n  bool isMSExternInline() const;\n\n  bool doesDeclarationForceExternallyVisibleDefinition() const;\n\n  bool isStatic() const { return getStorageClass() == SC_Static; }\n\n  /// Whether this function declaration represents an C++ overloaded\n  /// operator, e.g., \"operator+\".\n  bool isOverloadedOperator() const {\n    return getOverloadedOperator() != OO_None;\n  }\n\n  OverloadedOperatorKind getOverloadedOperator() const;\n\n  const IdentifierInfo *getLiteralIdentifier() const;\n\n  /// If this function is an instantiation of a member function\n  /// of a class template specialization, retrieves the function from\n  /// which it was instantiated.\n  ///\n  /// This routine will return non-NULL for (non-templated) member\n  /// functions of class templates and for instantiations of function\n  /// templates. For example, given:\n  ///\n  /// \\code\n  /// template<typename T>\n  /// struct X {\n  ///   void f(T);\n  /// };\n  /// \\endcode\n  ///\n  /// The declaration for X<int>::f is a (non-templated) FunctionDecl\n  /// whose parent is the class template specialization X<int>. For\n  /// this declaration, getInstantiatedFromFunction() will return\n  /// the FunctionDecl X<T>::A. When a complete definition of\n  /// X<int>::A is required, it will be instantiated from the\n  /// declaration returned by getInstantiatedFromMemberFunction().\n  FunctionDecl *getInstantiatedFromMemberFunction() const;\n\n  /// What kind of templated function this is.\n  TemplatedKind getTemplatedKind() const;\n\n  /// If this function is an instantiation of a member function of a\n  /// class template specialization, retrieves the member specialization\n  /// information.\n  MemberSpecializationInfo *getMemberSpecializationInfo() const;\n\n  /// Specify that this record is an instantiation of the\n  /// member function FD.\n  void setInstantiationOfMemberFunction(FunctionDecl *FD,\n                                        TemplateSpecializationKind TSK) {\n    setInstantiationOfMemberFunction(getASTContext(), FD, TSK);\n  }\n\n  /// Retrieves the function template that is described by this\n  /// function declaration.\n  ///\n  /// Every function template is represented as a FunctionTemplateDecl\n  /// and a FunctionDecl (or something derived from FunctionDecl). The\n  /// former contains template properties (such as the template\n  /// parameter lists) while the latter contains the actual\n  /// description of the template's\n  /// contents. FunctionTemplateDecl::getTemplatedDecl() retrieves the\n  /// FunctionDecl that describes the function template,\n  /// getDescribedFunctionTemplate() retrieves the\n  /// FunctionTemplateDecl from a FunctionDecl.\n  FunctionTemplateDecl *getDescribedFunctionTemplate() const;\n\n  void setDescribedFunctionTemplate(FunctionTemplateDecl *Template);\n\n  /// Determine whether this function is a function template\n  /// specialization.\n  bool isFunctionTemplateSpecialization() const {\n    return getPrimaryTemplate() != nullptr;\n  }\n\n  /// If this function is actually a function template specialization,\n  /// retrieve information about this function template specialization.\n  /// Otherwise, returns NULL.\n  FunctionTemplateSpecializationInfo *getTemplateSpecializationInfo() const;\n\n  /// Determines whether this function is a function template\n  /// specialization or a member of a class template specialization that can\n  /// be implicitly instantiated.\n  bool isImplicitlyInstantiable() const;\n\n  /// Determines if the given function was instantiated from a\n  /// function template.\n  bool isTemplateInstantiation() const;\n\n  /// Retrieve the function declaration from which this function could\n  /// be instantiated, if it is an instantiation (rather than a non-template\n  /// or a specialization, for example).\n  ///\n  /// If \\p ForDefinition is \\c false, explicit specializations will be treated\n  /// as if they were implicit instantiations. This will then find the pattern\n  /// corresponding to non-definition portions of the declaration, such as\n  /// default arguments and the exception specification.\n  FunctionDecl *\n  getTemplateInstantiationPattern(bool ForDefinition = true) const;\n\n  /// Retrieve the primary template that this function template\n  /// specialization either specializes or was instantiated from.\n  ///\n  /// If this function declaration is not a function template specialization,\n  /// returns NULL.\n  FunctionTemplateDecl *getPrimaryTemplate() const;\n\n  /// Retrieve the template arguments used to produce this function\n  /// template specialization from the primary template.\n  ///\n  /// If this function declaration is not a function template specialization,\n  /// returns NULL.\n  const TemplateArgumentList *getTemplateSpecializationArgs() const;\n\n  /// Retrieve the template argument list as written in the sources,\n  /// if any.\n  ///\n  /// If this function declaration is not a function template specialization\n  /// or if it had no explicit template argument list, returns NULL.\n  /// Note that it an explicit template argument list may be written empty,\n  /// e.g., template<> void foo<>(char* s);\n  const ASTTemplateArgumentListInfo*\n  getTemplateSpecializationArgsAsWritten() const;\n\n  /// Specify that this function declaration is actually a function\n  /// template specialization.\n  ///\n  /// \\param Template the function template that this function template\n  /// specialization specializes.\n  ///\n  /// \\param TemplateArgs the template arguments that produced this\n  /// function template specialization from the template.\n  ///\n  /// \\param InsertPos If non-NULL, the position in the function template\n  /// specialization set where the function template specialization data will\n  /// be inserted.\n  ///\n  /// \\param TSK the kind of template specialization this is.\n  ///\n  /// \\param TemplateArgsAsWritten location info of template arguments.\n  ///\n  /// \\param PointOfInstantiation point at which the function template\n  /// specialization was first instantiated.\n  void setFunctionTemplateSpecialization(FunctionTemplateDecl *Template,\n                const TemplateArgumentList *TemplateArgs,\n                void *InsertPos,\n                TemplateSpecializationKind TSK = TSK_ImplicitInstantiation,\n                const TemplateArgumentListInfo *TemplateArgsAsWritten = nullptr,\n                SourceLocation PointOfInstantiation = SourceLocation()) {\n    setFunctionTemplateSpecialization(getASTContext(), Template, TemplateArgs,\n                                      InsertPos, TSK, TemplateArgsAsWritten,\n                                      PointOfInstantiation);\n  }\n\n  /// Specifies that this function declaration is actually a\n  /// dependent function template specialization.\n  void setDependentTemplateSpecialization(ASTContext &Context,\n                             const UnresolvedSetImpl &Templates,\n                      const TemplateArgumentListInfo &TemplateArgs);\n\n  DependentFunctionTemplateSpecializationInfo *\n  getDependentSpecializationInfo() const;\n\n  /// Determine what kind of template instantiation this function\n  /// represents.\n  TemplateSpecializationKind getTemplateSpecializationKind() const;\n\n  /// Determine the kind of template specialization this function represents\n  /// for the purpose of template instantiation.\n  TemplateSpecializationKind\n  getTemplateSpecializationKindForInstantiation() const;\n\n  /// Determine what kind of template instantiation this function\n  /// represents.\n  void setTemplateSpecializationKind(TemplateSpecializationKind TSK,\n                        SourceLocation PointOfInstantiation = SourceLocation());\n\n  /// Retrieve the (first) point of instantiation of a function template\n  /// specialization or a member of a class template specialization.\n  ///\n  /// \\returns the first point of instantiation, if this function was\n  /// instantiated from a template; otherwise, returns an invalid source\n  /// location.\n  SourceLocation getPointOfInstantiation() const;\n\n  /// Determine whether this is or was instantiated from an out-of-line\n  /// definition of a member function.\n  bool isOutOfLine() const override;\n\n  /// Identify a memory copying or setting function.\n  /// If the given function is a memory copy or setting function, returns\n  /// the corresponding Builtin ID. If the function is not a memory function,\n  /// returns 0.\n  unsigned getMemoryFunctionKind() const;\n\n  /// Returns ODRHash of the function.  This value is calculated and\n  /// stored on first call, then the stored value returned on the other calls.\n  unsigned getODRHash();\n\n  /// Returns cached ODRHash of the function.  This must have been previously\n  /// computed and stored.\n  unsigned getODRHash() const;\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) {\n    return K >= firstFunction && K <= lastFunction;\n  }\n  static DeclContext *castToDeclContext(const FunctionDecl *D) {\n    return static_cast<DeclContext *>(const_cast<FunctionDecl*>(D));\n  }\n  static FunctionDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<FunctionDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// Represents a member of a struct/union/class.\nclass FieldDecl : public DeclaratorDecl, public Mergeable<FieldDecl> {\n  unsigned BitField : 1;\n  unsigned Mutable : 1;\n  mutable unsigned CachedFieldIndex : 30;\n\n  /// The kinds of value we can store in InitializerOrBitWidth.\n  ///\n  /// Note that this is compatible with InClassInitStyle except for\n  /// ISK_CapturedVLAType.\n  enum InitStorageKind {\n    /// If the pointer is null, there's nothing special.  Otherwise,\n    /// this is a bitfield and the pointer is the Expr* storing the\n    /// bit-width.\n    ISK_NoInit = (unsigned) ICIS_NoInit,\n\n    /// The pointer is an (optional due to delayed parsing) Expr*\n    /// holding the copy-initializer.\n    ISK_InClassCopyInit = (unsigned) ICIS_CopyInit,\n\n    /// The pointer is an (optional due to delayed parsing) Expr*\n    /// holding the list-initializer.\n    ISK_InClassListInit = (unsigned) ICIS_ListInit,\n\n    /// The pointer is a VariableArrayType* that's been captured;\n    /// the enclosing context is a lambda or captured statement.\n    ISK_CapturedVLAType,\n  };\n\n  /// If this is a bitfield with a default member initializer, this\n  /// structure is used to represent the two expressions.\n  struct InitAndBitWidth {\n    Expr *Init;\n    Expr *BitWidth;\n  };\n\n  /// Storage for either the bit-width, the in-class initializer, or\n  /// both (via InitAndBitWidth), or the captured variable length array bound.\n  ///\n  /// If the storage kind is ISK_InClassCopyInit or\n  /// ISK_InClassListInit, but the initializer is null, then this\n  /// field has an in-class initializer that has not yet been parsed\n  /// and attached.\n  // FIXME: Tail-allocate this to reduce the size of FieldDecl in the\n  // overwhelmingly common case that we have none of these things.\n  llvm::PointerIntPair<void *, 2, InitStorageKind> InitStorage;\n\nprotected:\n  FieldDecl(Kind DK, DeclContext *DC, SourceLocation StartLoc,\n            SourceLocation IdLoc, IdentifierInfo *Id,\n            QualType T, TypeSourceInfo *TInfo, Expr *BW, bool Mutable,\n            InClassInitStyle InitStyle)\n    : DeclaratorDecl(DK, DC, IdLoc, Id, T, TInfo, StartLoc),\n      BitField(false), Mutable(Mutable), CachedFieldIndex(0),\n      InitStorage(nullptr, (InitStorageKind) InitStyle) {\n    if (BW)\n      setBitWidth(BW);\n  }\n\npublic:\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n\n  static FieldDecl *Create(const ASTContext &C, DeclContext *DC,\n                           SourceLocation StartLoc, SourceLocation IdLoc,\n                           IdentifierInfo *Id, QualType T,\n                           TypeSourceInfo *TInfo, Expr *BW, bool Mutable,\n                           InClassInitStyle InitStyle);\n\n  static FieldDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  /// Returns the index of this field within its record,\n  /// as appropriate for passing to ASTRecordLayout::getFieldOffset.\n  unsigned getFieldIndex() const;\n\n  /// Determines whether this field is mutable (C++ only).\n  bool isMutable() const { return Mutable; }\n\n  /// Determines whether this field is a bitfield.\n  bool isBitField() const { return BitField; }\n\n  /// Determines whether this is an unnamed bitfield.\n  bool isUnnamedBitfield() const { return isBitField() && !getDeclName(); }\n\n  /// Determines whether this field is a\n  /// representative for an anonymous struct or union. Such fields are\n  /// unnamed and are implicitly generated by the implementation to\n  /// store the data for the anonymous union or struct.\n  bool isAnonymousStructOrUnion() const;\n\n  Expr *getBitWidth() const {\n    if (!BitField)\n      return nullptr;\n    void *Ptr = InitStorage.getPointer();\n    if (getInClassInitStyle())\n      return static_cast<InitAndBitWidth*>(Ptr)->BitWidth;\n    return static_cast<Expr*>(Ptr);\n  }\n\n  unsigned getBitWidthValue(const ASTContext &Ctx) const;\n\n  /// Set the bit-field width for this member.\n  // Note: used by some clients (i.e., do not remove it).\n  void setBitWidth(Expr *Width) {\n    assert(!hasCapturedVLAType() && !BitField &&\n           \"bit width or captured type already set\");\n    assert(Width && \"no bit width specified\");\n    InitStorage.setPointer(\n        InitStorage.getInt()\n            ? new (getASTContext())\n                  InitAndBitWidth{getInClassInitializer(), Width}\n            : static_cast<void*>(Width));\n    BitField = true;\n  }\n\n  /// Remove the bit-field width from this member.\n  // Note: used by some clients (i.e., do not remove it).\n  void removeBitWidth() {\n    assert(isBitField() && \"no bitfield width to remove\");\n    InitStorage.setPointer(getInClassInitializer());\n    BitField = false;\n  }\n\n  /// Is this a zero-length bit-field? Such bit-fields aren't really bit-fields\n  /// at all and instead act as a separator between contiguous runs of other\n  /// bit-fields.\n  bool isZeroLengthBitField(const ASTContext &Ctx) const;\n\n  /// Determine if this field is a subobject of zero size, that is, either a\n  /// zero-length bit-field or a field of empty class type with the\n  /// [[no_unique_address]] attribute.\n  bool isZeroSize(const ASTContext &Ctx) const;\n\n  /// Get the kind of (C++11) default member initializer that this field has.\n  InClassInitStyle getInClassInitStyle() const {\n    InitStorageKind storageKind = InitStorage.getInt();\n    return (storageKind == ISK_CapturedVLAType\n              ? ICIS_NoInit : (InClassInitStyle) storageKind);\n  }\n\n  /// Determine whether this member has a C++11 default member initializer.\n  bool hasInClassInitializer() const {\n    return getInClassInitStyle() != ICIS_NoInit;\n  }\n\n  /// Get the C++11 default member initializer for this member, or null if one\n  /// has not been set. If a valid declaration has a default member initializer,\n  /// but this returns null, then we have not parsed and attached it yet.\n  Expr *getInClassInitializer() const {\n    if (!hasInClassInitializer())\n      return nullptr;\n    void *Ptr = InitStorage.getPointer();\n    if (BitField)\n      return static_cast<InitAndBitWidth*>(Ptr)->Init;\n    return static_cast<Expr*>(Ptr);\n  }\n\n  /// Set the C++11 in-class initializer for this member.\n  void setInClassInitializer(Expr *Init) {\n    assert(hasInClassInitializer() && !getInClassInitializer());\n    if (BitField)\n      static_cast<InitAndBitWidth*>(InitStorage.getPointer())->Init = Init;\n    else\n      InitStorage.setPointer(Init);\n  }\n\n  /// Remove the C++11 in-class initializer from this member.\n  void removeInClassInitializer() {\n    assert(hasInClassInitializer() && \"no initializer to remove\");\n    InitStorage.setPointerAndInt(getBitWidth(), ISK_NoInit);\n  }\n\n  /// Determine whether this member captures the variable length array\n  /// type.\n  bool hasCapturedVLAType() const {\n    return InitStorage.getInt() == ISK_CapturedVLAType;\n  }\n\n  /// Get the captured variable length array type.\n  const VariableArrayType *getCapturedVLAType() const {\n    return hasCapturedVLAType() ? static_cast<const VariableArrayType *>(\n                                      InitStorage.getPointer())\n                                : nullptr;\n  }\n\n  /// Set the captured variable length array type for this field.\n  void setCapturedVLAType(const VariableArrayType *VLAType);\n\n  /// Returns the parent of this field declaration, which\n  /// is the struct in which this field is defined.\n  ///\n  /// Returns null if this is not a normal class/struct field declaration, e.g.\n  /// ObjCAtDefsFieldDecl, ObjCIvarDecl.\n  const RecordDecl *getParent() const {\n    return dyn_cast<RecordDecl>(getDeclContext());\n  }\n\n  RecordDecl *getParent() {\n    return dyn_cast<RecordDecl>(getDeclContext());\n  }\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  /// Retrieves the canonical declaration of this field.\n  FieldDecl *getCanonicalDecl() override { return getFirstDecl(); }\n  const FieldDecl *getCanonicalDecl() const { return getFirstDecl(); }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K >= firstField && K <= lastField; }\n};\n\n/// An instance of this object exists for each enum constant\n/// that is defined.  For example, in \"enum X {a,b}\", each of a/b are\n/// EnumConstantDecl's, X is an instance of EnumDecl, and the type of a/b is a\n/// TagType for the X EnumDecl.\nclass EnumConstantDecl : public ValueDecl, public Mergeable<EnumConstantDecl> {\n  Stmt *Init; // an integer constant expression\n  llvm::APSInt Val; // The value.\n\nprotected:\n  EnumConstantDecl(DeclContext *DC, SourceLocation L,\n                   IdentifierInfo *Id, QualType T, Expr *E,\n                   const llvm::APSInt &V)\n    : ValueDecl(EnumConstant, DC, L, Id, T), Init((Stmt*)E), Val(V) {}\n\npublic:\n  friend class StmtIteratorBase;\n\n  static EnumConstantDecl *Create(ASTContext &C, EnumDecl *DC,\n                                  SourceLocation L, IdentifierInfo *Id,\n                                  QualType T, Expr *E,\n                                  const llvm::APSInt &V);\n  static EnumConstantDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  const Expr *getInitExpr() const { return (const Expr*) Init; }\n  Expr *getInitExpr() { return (Expr*) Init; }\n  const llvm::APSInt &getInitVal() const { return Val; }\n\n  void setInitExpr(Expr *E) { Init = (Stmt*) E; }\n  void setInitVal(const llvm::APSInt &V) { Val = V; }\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  /// Retrieves the canonical declaration of this enumerator.\n  EnumConstantDecl *getCanonicalDecl() override { return getFirstDecl(); }\n  const EnumConstantDecl *getCanonicalDecl() const { return getFirstDecl(); }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == EnumConstant; }\n};\n\n/// Represents a field injected from an anonymous union/struct into the parent\n/// scope. These are always implicit.\nclass IndirectFieldDecl : public ValueDecl,\n                          public Mergeable<IndirectFieldDecl> {\n  NamedDecl **Chaining;\n  unsigned ChainingSize;\n\n  IndirectFieldDecl(ASTContext &C, DeclContext *DC, SourceLocation L,\n                    DeclarationName N, QualType T,\n                    MutableArrayRef<NamedDecl *> CH);\n\n  void anchor() override;\n\npublic:\n  friend class ASTDeclReader;\n\n  static IndirectFieldDecl *Create(ASTContext &C, DeclContext *DC,\n                                   SourceLocation L, IdentifierInfo *Id,\n                                   QualType T, llvm::MutableArrayRef<NamedDecl *> CH);\n\n  static IndirectFieldDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  using chain_iterator = ArrayRef<NamedDecl *>::const_iterator;\n\n  ArrayRef<NamedDecl *> chain() const {\n    return llvm::makeArrayRef(Chaining, ChainingSize);\n  }\n  chain_iterator chain_begin() const { return chain().begin(); }\n  chain_iterator chain_end() const { return chain().end(); }\n\n  unsigned getChainingSize() const { return ChainingSize; }\n\n  FieldDecl *getAnonField() const {\n    assert(chain().size() >= 2);\n    return cast<FieldDecl>(chain().back());\n  }\n\n  VarDecl *getVarDecl() const {\n    assert(chain().size() >= 2);\n    return dyn_cast<VarDecl>(chain().front());\n  }\n\n  IndirectFieldDecl *getCanonicalDecl() override { return getFirstDecl(); }\n  const IndirectFieldDecl *getCanonicalDecl() const { return getFirstDecl(); }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == IndirectField; }\n};\n\n/// Represents a declaration of a type.\nclass TypeDecl : public NamedDecl {\n  friend class ASTContext;\n\n  /// This indicates the Type object that represents\n  /// this TypeDecl.  It is a cache maintained by\n  /// ASTContext::getTypedefType, ASTContext::getTagDeclType, and\n  /// ASTContext::getTemplateTypeParmType, and TemplateTypeParmDecl.\n  mutable const Type *TypeForDecl = nullptr;\n\n  /// The start of the source range for this declaration.\n  SourceLocation LocStart;\n\n  void anchor() override;\n\nprotected:\n  TypeDecl(Kind DK, DeclContext *DC, SourceLocation L, IdentifierInfo *Id,\n           SourceLocation StartL = SourceLocation())\n    : NamedDecl(DK, DC, L, Id), LocStart(StartL) {}\n\npublic:\n  // Low-level accessor. If you just want the type defined by this node,\n  // check out ASTContext::getTypeDeclType or one of\n  // ASTContext::getTypedefType, ASTContext::getRecordType, etc. if you\n  // already know the specific kind of node this is.\n  const Type *getTypeForDecl() const { return TypeForDecl; }\n  void setTypeForDecl(const Type *TD) { TypeForDecl = TD; }\n\n  SourceLocation getBeginLoc() const LLVM_READONLY { return LocStart; }\n  void setLocStart(SourceLocation L) { LocStart = L; }\n  SourceRange getSourceRange() const override LLVM_READONLY {\n    if (LocStart.isValid())\n      return SourceRange(LocStart, getLocation());\n    else\n      return SourceRange(getLocation());\n  }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K >= firstType && K <= lastType; }\n};\n\n/// Base class for declarations which introduce a typedef-name.\nclass TypedefNameDecl : public TypeDecl, public Redeclarable<TypedefNameDecl> {\n  struct alignas(8) ModedTInfo {\n    TypeSourceInfo *first;\n    QualType second;\n  };\n\n  /// If int part is 0, we have not computed IsTransparentTag.\n  /// Otherwise, IsTransparentTag is (getInt() >> 1).\n  mutable llvm::PointerIntPair<\n      llvm::PointerUnion<TypeSourceInfo *, ModedTInfo *>, 2>\n      MaybeModedTInfo;\n\n  void anchor() override;\n\nprotected:\n  TypedefNameDecl(Kind DK, ASTContext &C, DeclContext *DC,\n                  SourceLocation StartLoc, SourceLocation IdLoc,\n                  IdentifierInfo *Id, TypeSourceInfo *TInfo)\n      : TypeDecl(DK, DC, IdLoc, Id, StartLoc), redeclarable_base(C),\n        MaybeModedTInfo(TInfo, 0) {}\n\n  using redeclarable_base = Redeclarable<TypedefNameDecl>;\n\n  TypedefNameDecl *getNextRedeclarationImpl() override {\n    return getNextRedeclaration();\n  }\n\n  TypedefNameDecl *getPreviousDeclImpl() override {\n    return getPreviousDecl();\n  }\n\n  TypedefNameDecl *getMostRecentDeclImpl() override {\n    return getMostRecentDecl();\n  }\n\npublic:\n  using redecl_range = redeclarable_base::redecl_range;\n  using redecl_iterator = redeclarable_base::redecl_iterator;\n\n  using redeclarable_base::redecls_begin;\n  using redeclarable_base::redecls_end;\n  using redeclarable_base::redecls;\n  using redeclarable_base::getPreviousDecl;\n  using redeclarable_base::getMostRecentDecl;\n  using redeclarable_base::isFirstDecl;\n\n  bool isModed() const {\n    return MaybeModedTInfo.getPointer().is<ModedTInfo *>();\n  }\n\n  TypeSourceInfo *getTypeSourceInfo() const {\n    return isModed() ? MaybeModedTInfo.getPointer().get<ModedTInfo *>()->first\n                     : MaybeModedTInfo.getPointer().get<TypeSourceInfo *>();\n  }\n\n  QualType getUnderlyingType() const {\n    return isModed() ? MaybeModedTInfo.getPointer().get<ModedTInfo *>()->second\n                     : MaybeModedTInfo.getPointer()\n                           .get<TypeSourceInfo *>()\n                           ->getType();\n  }\n\n  void setTypeSourceInfo(TypeSourceInfo *newType) {\n    MaybeModedTInfo.setPointer(newType);\n  }\n\n  void setModedTypeSourceInfo(TypeSourceInfo *unmodedTSI, QualType modedTy) {\n    MaybeModedTInfo.setPointer(new (getASTContext(), 8)\n                                   ModedTInfo({unmodedTSI, modedTy}));\n  }\n\n  /// Retrieves the canonical declaration of this typedef-name.\n  TypedefNameDecl *getCanonicalDecl() override { return getFirstDecl(); }\n  const TypedefNameDecl *getCanonicalDecl() const { return getFirstDecl(); }\n\n  /// Retrieves the tag declaration for which this is the typedef name for\n  /// linkage purposes, if any.\n  ///\n  /// \\param AnyRedecl Look for the tag declaration in any redeclaration of\n  /// this typedef declaration.\n  TagDecl *getAnonDeclWithTypedefName(bool AnyRedecl = false) const;\n\n  /// Determines if this typedef shares a name and spelling location with its\n  /// underlying tag type, as is the case with the NS_ENUM macro.\n  bool isTransparentTag() const {\n    if (MaybeModedTInfo.getInt())\n      return MaybeModedTInfo.getInt() & 0x2;\n    return isTransparentTagSlow();\n  }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) {\n    return K >= firstTypedefName && K <= lastTypedefName;\n  }\n\nprivate:\n  bool isTransparentTagSlow() const;\n};\n\n/// Represents the declaration of a typedef-name via the 'typedef'\n/// type specifier.\nclass TypedefDecl : public TypedefNameDecl {\n  TypedefDecl(ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n              SourceLocation IdLoc, IdentifierInfo *Id, TypeSourceInfo *TInfo)\n      : TypedefNameDecl(Typedef, C, DC, StartLoc, IdLoc, Id, TInfo) {}\n\npublic:\n  static TypedefDecl *Create(ASTContext &C, DeclContext *DC,\n                             SourceLocation StartLoc, SourceLocation IdLoc,\n                             IdentifierInfo *Id, TypeSourceInfo *TInfo);\n  static TypedefDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Typedef; }\n};\n\n/// Represents the declaration of a typedef-name via a C++11\n/// alias-declaration.\nclass TypeAliasDecl : public TypedefNameDecl {\n  /// The template for which this is the pattern, if any.\n  TypeAliasTemplateDecl *Template;\n\n  TypeAliasDecl(ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n                SourceLocation IdLoc, IdentifierInfo *Id, TypeSourceInfo *TInfo)\n      : TypedefNameDecl(TypeAlias, C, DC, StartLoc, IdLoc, Id, TInfo),\n        Template(nullptr) {}\n\npublic:\n  static TypeAliasDecl *Create(ASTContext &C, DeclContext *DC,\n                               SourceLocation StartLoc, SourceLocation IdLoc,\n                               IdentifierInfo *Id, TypeSourceInfo *TInfo);\n  static TypeAliasDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  TypeAliasTemplateDecl *getDescribedAliasTemplate() const { return Template; }\n  void setDescribedAliasTemplate(TypeAliasTemplateDecl *TAT) { Template = TAT; }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == TypeAlias; }\n};\n\n/// Represents the declaration of a struct/union/class/enum.\nclass TagDecl : public TypeDecl,\n                public DeclContext,\n                public Redeclarable<TagDecl> {\n  // This class stores some data in DeclContext::TagDeclBits\n  // to save some space. Use the provided accessors to access it.\npublic:\n  // This is really ugly.\n  using TagKind = TagTypeKind;\n\nprivate:\n  SourceRange BraceRange;\n\n  // A struct representing syntactic qualifier info,\n  // to be used for the (uncommon) case of out-of-line declarations.\n  using ExtInfo = QualifierInfo;\n\n  /// If the (out-of-line) tag declaration name\n  /// is qualified, it points to the qualifier info (nns and range);\n  /// otherwise, if the tag declaration is anonymous and it is part of\n  /// a typedef or alias, it points to the TypedefNameDecl (used for mangling);\n  /// otherwise, if the tag declaration is anonymous and it is used as a\n  /// declaration specifier for variables, it points to the first VarDecl (used\n  /// for mangling);\n  /// otherwise, it is a null (TypedefNameDecl) pointer.\n  llvm::PointerUnion<TypedefNameDecl *, ExtInfo *> TypedefNameDeclOrQualifier;\n\n  bool hasExtInfo() const { return TypedefNameDeclOrQualifier.is<ExtInfo *>(); }\n  ExtInfo *getExtInfo() { return TypedefNameDeclOrQualifier.get<ExtInfo *>(); }\n  const ExtInfo *getExtInfo() const {\n    return TypedefNameDeclOrQualifier.get<ExtInfo *>();\n  }\n\nprotected:\n  TagDecl(Kind DK, TagKind TK, const ASTContext &C, DeclContext *DC,\n          SourceLocation L, IdentifierInfo *Id, TagDecl *PrevDecl,\n          SourceLocation StartL);\n\n  using redeclarable_base = Redeclarable<TagDecl>;\n\n  TagDecl *getNextRedeclarationImpl() override {\n    return getNextRedeclaration();\n  }\n\n  TagDecl *getPreviousDeclImpl() override {\n    return getPreviousDecl();\n  }\n\n  TagDecl *getMostRecentDeclImpl() override {\n    return getMostRecentDecl();\n  }\n\n  /// Completes the definition of this tag declaration.\n  ///\n  /// This is a helper function for derived classes.\n  void completeDefinition();\n\n  /// True if this decl is currently being defined.\n  void setBeingDefined(bool V = true) { TagDeclBits.IsBeingDefined = V; }\n\n  /// Indicates whether it is possible for declarations of this kind\n  /// to have an out-of-date definition.\n  ///\n  /// This option is only enabled when modules are enabled.\n  void setMayHaveOutOfDateDef(bool V = true) {\n    TagDeclBits.MayHaveOutOfDateDef = V;\n  }\n\npublic:\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n\n  using redecl_range = redeclarable_base::redecl_range;\n  using redecl_iterator = redeclarable_base::redecl_iterator;\n\n  using redeclarable_base::redecls_begin;\n  using redeclarable_base::redecls_end;\n  using redeclarable_base::redecls;\n  using redeclarable_base::getPreviousDecl;\n  using redeclarable_base::getMostRecentDecl;\n  using redeclarable_base::isFirstDecl;\n\n  SourceRange getBraceRange() const { return BraceRange; }\n  void setBraceRange(SourceRange R) { BraceRange = R; }\n\n  /// Return SourceLocation representing start of source\n  /// range ignoring outer template declarations.\n  SourceLocation getInnerLocStart() const { return getBeginLoc(); }\n\n  /// Return SourceLocation representing start of source\n  /// range taking into account any outer template declarations.\n  SourceLocation getOuterLocStart() const;\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  TagDecl *getCanonicalDecl() override;\n  const TagDecl *getCanonicalDecl() const {\n    return const_cast<TagDecl*>(this)->getCanonicalDecl();\n  }\n\n  /// Return true if this declaration is a completion definition of the type.\n  /// Provided for consistency.\n  bool isThisDeclarationADefinition() const {\n    return isCompleteDefinition();\n  }\n\n  /// Return true if this decl has its body fully specified.\n  bool isCompleteDefinition() const { return TagDeclBits.IsCompleteDefinition; }\n\n  /// True if this decl has its body fully specified.\n  void setCompleteDefinition(bool V = true) {\n    TagDeclBits.IsCompleteDefinition = V;\n  }\n\n  /// Return true if this complete decl is\n  /// required to be complete for some existing use.\n  bool isCompleteDefinitionRequired() const {\n    return TagDeclBits.IsCompleteDefinitionRequired;\n  }\n\n  /// True if this complete decl is\n  /// required to be complete for some existing use.\n  void setCompleteDefinitionRequired(bool V = true) {\n    TagDeclBits.IsCompleteDefinitionRequired = V;\n  }\n\n  /// Return true if this decl is currently being defined.\n  bool isBeingDefined() const { return TagDeclBits.IsBeingDefined; }\n\n  /// True if this tag declaration is \"embedded\" (i.e., defined or declared\n  /// for the very first time) in the syntax of a declarator.\n  bool isEmbeddedInDeclarator() const {\n    return TagDeclBits.IsEmbeddedInDeclarator;\n  }\n\n  /// True if this tag declaration is \"embedded\" (i.e., defined or declared\n  /// for the very first time) in the syntax of a declarator.\n  void setEmbeddedInDeclarator(bool isInDeclarator) {\n    TagDeclBits.IsEmbeddedInDeclarator = isInDeclarator;\n  }\n\n  /// True if this tag is free standing, e.g. \"struct foo;\".\n  bool isFreeStanding() const { return TagDeclBits.IsFreeStanding; }\n\n  /// True if this tag is free standing, e.g. \"struct foo;\".\n  void setFreeStanding(bool isFreeStanding = true) {\n    TagDeclBits.IsFreeStanding = isFreeStanding;\n  }\n\n  /// Indicates whether it is possible for declarations of this kind\n  /// to have an out-of-date definition.\n  ///\n  /// This option is only enabled when modules are enabled.\n  bool mayHaveOutOfDateDef() const { return TagDeclBits.MayHaveOutOfDateDef; }\n\n  /// Whether this declaration declares a type that is\n  /// dependent, i.e., a type that somehow depends on template\n  /// parameters.\n  bool isDependentType() const { return isDependentContext(); }\n\n  /// Starts the definition of this tag declaration.\n  ///\n  /// This method should be invoked at the beginning of the definition\n  /// of this tag declaration. It will set the tag type into a state\n  /// where it is in the process of being defined.\n  void startDefinition();\n\n  /// Returns the TagDecl that actually defines this\n  ///  struct/union/class/enum.  When determining whether or not a\n  ///  struct/union/class/enum has a definition, one should use this\n  ///  method as opposed to 'isDefinition'.  'isDefinition' indicates\n  ///  whether or not a specific TagDecl is defining declaration, not\n  ///  whether or not the struct/union/class/enum type is defined.\n  ///  This method returns NULL if there is no TagDecl that defines\n  ///  the struct/union/class/enum.\n  TagDecl *getDefinition() const;\n\n  StringRef getKindName() const {\n    return TypeWithKeyword::getTagTypeKindName(getTagKind());\n  }\n\n  TagKind getTagKind() const {\n    return static_cast<TagKind>(TagDeclBits.TagDeclKind);\n  }\n\n  void setTagKind(TagKind TK) { TagDeclBits.TagDeclKind = TK; }\n\n  bool isStruct() const { return getTagKind() == TTK_Struct; }\n  bool isInterface() const { return getTagKind() == TTK_Interface; }\n  bool isClass()  const { return getTagKind() == TTK_Class; }\n  bool isUnion()  const { return getTagKind() == TTK_Union; }\n  bool isEnum()   const { return getTagKind() == TTK_Enum; }\n\n  /// Is this tag type named, either directly or via being defined in\n  /// a typedef of this type?\n  ///\n  /// C++11 [basic.link]p8:\n  ///   A type is said to have linkage if and only if:\n  ///     - it is a class or enumeration type that is named (or has a\n  ///       name for linkage purposes) and the name has linkage; ...\n  /// C++11 [dcl.typedef]p9:\n  ///   If the typedef declaration defines an unnamed class (or enum),\n  ///   the first typedef-name declared by the declaration to be that\n  ///   class type (or enum type) is used to denote the class type (or\n  ///   enum type) for linkage purposes only.\n  ///\n  /// C does not have an analogous rule, but the same concept is\n  /// nonetheless useful in some places.\n  bool hasNameForLinkage() const {\n    return (getDeclName() || getTypedefNameForAnonDecl());\n  }\n\n  TypedefNameDecl *getTypedefNameForAnonDecl() const {\n    return hasExtInfo() ? nullptr\n                        : TypedefNameDeclOrQualifier.get<TypedefNameDecl *>();\n  }\n\n  void setTypedefNameForAnonDecl(TypedefNameDecl *TDD);\n\n  /// Retrieve the nested-name-specifier that qualifies the name of this\n  /// declaration, if it was present in the source.\n  NestedNameSpecifier *getQualifier() const {\n    return hasExtInfo() ? getExtInfo()->QualifierLoc.getNestedNameSpecifier()\n                        : nullptr;\n  }\n\n  /// Retrieve the nested-name-specifier (with source-location\n  /// information) that qualifies the name of this declaration, if it was\n  /// present in the source.\n  NestedNameSpecifierLoc getQualifierLoc() const {\n    return hasExtInfo() ? getExtInfo()->QualifierLoc\n                        : NestedNameSpecifierLoc();\n  }\n\n  void setQualifierInfo(NestedNameSpecifierLoc QualifierLoc);\n\n  unsigned getNumTemplateParameterLists() const {\n    return hasExtInfo() ? getExtInfo()->NumTemplParamLists : 0;\n  }\n\n  TemplateParameterList *getTemplateParameterList(unsigned i) const {\n    assert(i < getNumTemplateParameterLists());\n    return getExtInfo()->TemplParamLists[i];\n  }\n\n  void setTemplateParameterListsInfo(ASTContext &Context,\n                                     ArrayRef<TemplateParameterList *> TPLists);\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K >= firstTag && K <= lastTag; }\n\n  static DeclContext *castToDeclContext(const TagDecl *D) {\n    return static_cast<DeclContext *>(const_cast<TagDecl*>(D));\n  }\n\n  static TagDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<TagDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// Represents an enum.  In C++11, enums can be forward-declared\n/// with a fixed underlying type, and in C we allow them to be forward-declared\n/// with no underlying type as an extension.\nclass EnumDecl : public TagDecl {\n  // This class stores some data in DeclContext::EnumDeclBits\n  // to save some space. Use the provided accessors to access it.\n\n  /// This represent the integer type that the enum corresponds\n  /// to for code generation purposes.  Note that the enumerator constants may\n  /// have a different type than this does.\n  ///\n  /// If the underlying integer type was explicitly stated in the source\n  /// code, this is a TypeSourceInfo* for that type. Otherwise this type\n  /// was automatically deduced somehow, and this is a Type*.\n  ///\n  /// Normally if IsFixed(), this would contain a TypeSourceInfo*, but in\n  /// some cases it won't.\n  ///\n  /// The underlying type of an enumeration never has any qualifiers, so\n  /// we can get away with just storing a raw Type*, and thus save an\n  /// extra pointer when TypeSourceInfo is needed.\n  llvm::PointerUnion<const Type *, TypeSourceInfo *> IntegerType;\n\n  /// The integer type that values of this type should\n  /// promote to.  In C, enumerators are generally of an integer type\n  /// directly, but gcc-style large enumerators (and all enumerators\n  /// in C++) are of the enum type instead.\n  QualType PromotionType;\n\n  /// If this enumeration is an instantiation of a member enumeration\n  /// of a class template specialization, this is the member specialization\n  /// information.\n  MemberSpecializationInfo *SpecializationInfo = nullptr;\n\n  /// Store the ODRHash after first calculation.\n  /// The corresponding flag HasODRHash is in EnumDeclBits\n  /// and can be accessed with the provided accessors.\n  unsigned ODRHash;\n\n  EnumDecl(ASTContext &C, DeclContext *DC, SourceLocation StartLoc,\n           SourceLocation IdLoc, IdentifierInfo *Id, EnumDecl *PrevDecl,\n           bool Scoped, bool ScopedUsingClassTag, bool Fixed);\n\n  void anchor() override;\n\n  void setInstantiationOfMemberEnum(ASTContext &C, EnumDecl *ED,\n                                    TemplateSpecializationKind TSK);\n\n  /// Sets the width in bits required to store all the\n  /// non-negative enumerators of this enum.\n  void setNumPositiveBits(unsigned Num) {\n    EnumDeclBits.NumPositiveBits = Num;\n    assert(EnumDeclBits.NumPositiveBits == Num && \"can't store this bitcount\");\n  }\n\n  /// Returns the width in bits required to store all the\n  /// negative enumerators of this enum. (see getNumNegativeBits)\n  void setNumNegativeBits(unsigned Num) { EnumDeclBits.NumNegativeBits = Num; }\n\npublic:\n  /// True if this tag declaration is a scoped enumeration. Only\n  /// possible in C++11 mode.\n  void setScoped(bool Scoped = true) { EnumDeclBits.IsScoped = Scoped; }\n\n  /// If this tag declaration is a scoped enum,\n  /// then this is true if the scoped enum was declared using the class\n  /// tag, false if it was declared with the struct tag. No meaning is\n  /// associated if this tag declaration is not a scoped enum.\n  void setScopedUsingClassTag(bool ScopedUCT = true) {\n    EnumDeclBits.IsScopedUsingClassTag = ScopedUCT;\n  }\n\n  /// True if this is an Objective-C, C++11, or\n  /// Microsoft-style enumeration with a fixed underlying type.\n  void setFixed(bool Fixed = true) { EnumDeclBits.IsFixed = Fixed; }\n\nprivate:\n  /// True if a valid hash is stored in ODRHash.\n  bool hasODRHash() const { return EnumDeclBits.HasODRHash; }\n  void setHasODRHash(bool Hash = true) { EnumDeclBits.HasODRHash = Hash; }\n\npublic:\n  friend class ASTDeclReader;\n\n  EnumDecl *getCanonicalDecl() override {\n    return cast<EnumDecl>(TagDecl::getCanonicalDecl());\n  }\n  const EnumDecl *getCanonicalDecl() const {\n    return const_cast<EnumDecl*>(this)->getCanonicalDecl();\n  }\n\n  EnumDecl *getPreviousDecl() {\n    return cast_or_null<EnumDecl>(\n            static_cast<TagDecl *>(this)->getPreviousDecl());\n  }\n  const EnumDecl *getPreviousDecl() const {\n    return const_cast<EnumDecl*>(this)->getPreviousDecl();\n  }\n\n  EnumDecl *getMostRecentDecl() {\n    return cast<EnumDecl>(static_cast<TagDecl *>(this)->getMostRecentDecl());\n  }\n  const EnumDecl *getMostRecentDecl() const {\n    return const_cast<EnumDecl*>(this)->getMostRecentDecl();\n  }\n\n  EnumDecl *getDefinition() const {\n    return cast_or_null<EnumDecl>(TagDecl::getDefinition());\n  }\n\n  static EnumDecl *Create(ASTContext &C, DeclContext *DC,\n                          SourceLocation StartLoc, SourceLocation IdLoc,\n                          IdentifierInfo *Id, EnumDecl *PrevDecl,\n                          bool IsScoped, bool IsScopedUsingClassTag,\n                          bool IsFixed);\n  static EnumDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  /// When created, the EnumDecl corresponds to a\n  /// forward-declared enum. This method is used to mark the\n  /// declaration as being defined; its enumerators have already been\n  /// added (via DeclContext::addDecl). NewType is the new underlying\n  /// type of the enumeration type.\n  void completeDefinition(QualType NewType,\n                          QualType PromotionType,\n                          unsigned NumPositiveBits,\n                          unsigned NumNegativeBits);\n\n  // Iterates through the enumerators of this enumeration.\n  using enumerator_iterator = specific_decl_iterator<EnumConstantDecl>;\n  using enumerator_range =\n      llvm::iterator_range<specific_decl_iterator<EnumConstantDecl>>;\n\n  enumerator_range enumerators() const {\n    return enumerator_range(enumerator_begin(), enumerator_end());\n  }\n\n  enumerator_iterator enumerator_begin() const {\n    const EnumDecl *E = getDefinition();\n    if (!E)\n      E = this;\n    return enumerator_iterator(E->decls_begin());\n  }\n\n  enumerator_iterator enumerator_end() const {\n    const EnumDecl *E = getDefinition();\n    if (!E)\n      E = this;\n    return enumerator_iterator(E->decls_end());\n  }\n\n  /// Return the integer type that enumerators should promote to.\n  QualType getPromotionType() const { return PromotionType; }\n\n  /// Set the promotion type.\n  void setPromotionType(QualType T) { PromotionType = T; }\n\n  /// Return the integer type this enum decl corresponds to.\n  /// This returns a null QualType for an enum forward definition with no fixed\n  /// underlying type.\n  QualType getIntegerType() const {\n    if (!IntegerType)\n      return QualType();\n    if (const Type *T = IntegerType.dyn_cast<const Type*>())\n      return QualType(T, 0);\n    return IntegerType.get<TypeSourceInfo*>()->getType().getUnqualifiedType();\n  }\n\n  /// Set the underlying integer type.\n  void setIntegerType(QualType T) { IntegerType = T.getTypePtrOrNull(); }\n\n  /// Set the underlying integer type source info.\n  void setIntegerTypeSourceInfo(TypeSourceInfo *TInfo) { IntegerType = TInfo; }\n\n  /// Return the type source info for the underlying integer type,\n  /// if no type source info exists, return 0.\n  TypeSourceInfo *getIntegerTypeSourceInfo() const {\n    return IntegerType.dyn_cast<TypeSourceInfo*>();\n  }\n\n  /// Retrieve the source range that covers the underlying type if\n  /// specified.\n  SourceRange getIntegerTypeRange() const LLVM_READONLY;\n\n  /// Returns the width in bits required to store all the\n  /// non-negative enumerators of this enum.\n  unsigned getNumPositiveBits() const { return EnumDeclBits.NumPositiveBits; }\n\n  /// Returns the width in bits required to store all the\n  /// negative enumerators of this enum.  These widths include\n  /// the rightmost leading 1;  that is:\n  ///\n  /// MOST NEGATIVE ENUMERATOR     PATTERN     NUM NEGATIVE BITS\n  /// ------------------------     -------     -----------------\n  ///                       -1     1111111                     1\n  ///                      -10     1110110                     5\n  ///                     -101     1001011                     8\n  unsigned getNumNegativeBits() const { return EnumDeclBits.NumNegativeBits; }\n\n  /// Returns true if this is a C++11 scoped enumeration.\n  bool isScoped() const { return EnumDeclBits.IsScoped; }\n\n  /// Returns true if this is a C++11 scoped enumeration.\n  bool isScopedUsingClassTag() const {\n    return EnumDeclBits.IsScopedUsingClassTag;\n  }\n\n  /// Returns true if this is an Objective-C, C++11, or\n  /// Microsoft-style enumeration with a fixed underlying type.\n  bool isFixed() const { return EnumDeclBits.IsFixed; }\n\n  unsigned getODRHash();\n\n  /// Returns true if this can be considered a complete type.\n  bool isComplete() const {\n    // IntegerType is set for fixed type enums and non-fixed but implicitly\n    // int-sized Microsoft enums.\n    return isCompleteDefinition() || IntegerType;\n  }\n\n  /// Returns true if this enum is either annotated with\n  /// enum_extensibility(closed) or isn't annotated with enum_extensibility.\n  bool isClosed() const;\n\n  /// Returns true if this enum is annotated with flag_enum and isn't annotated\n  /// with enum_extensibility(open).\n  bool isClosedFlag() const;\n\n  /// Returns true if this enum is annotated with neither flag_enum nor\n  /// enum_extensibility(open).\n  bool isClosedNonFlag() const;\n\n  /// Retrieve the enum definition from which this enumeration could\n  /// be instantiated, if it is an instantiation (rather than a non-template).\n  EnumDecl *getTemplateInstantiationPattern() const;\n\n  /// Returns the enumeration (declared within the template)\n  /// from which this enumeration type was instantiated, or NULL if\n  /// this enumeration was not instantiated from any template.\n  EnumDecl *getInstantiatedFromMemberEnum() const;\n\n  /// If this enumeration is a member of a specialization of a\n  /// templated class, determine what kind of template specialization\n  /// or instantiation this is.\n  TemplateSpecializationKind getTemplateSpecializationKind() const;\n\n  /// For an enumeration member that was instantiated from a member\n  /// enumeration of a templated class, set the template specialiation kind.\n  void setTemplateSpecializationKind(TemplateSpecializationKind TSK,\n                        SourceLocation PointOfInstantiation = SourceLocation());\n\n  /// If this enumeration is an instantiation of a member enumeration of\n  /// a class template specialization, retrieves the member specialization\n  /// information.\n  MemberSpecializationInfo *getMemberSpecializationInfo() const {\n    return SpecializationInfo;\n  }\n\n  /// Specify that this enumeration is an instantiation of the\n  /// member enumeration ED.\n  void setInstantiationOfMemberEnum(EnumDecl *ED,\n                                    TemplateSpecializationKind TSK) {\n    setInstantiationOfMemberEnum(getASTContext(), ED, TSK);\n  }\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Enum; }\n};\n\n/// Represents a struct/union/class.  For example:\n///   struct X;                  // Forward declaration, no \"body\".\n///   union Y { int A, B; };     // Has body with members A and B (FieldDecls).\n/// This decl will be marked invalid if *any* members are invalid.\nclass RecordDecl : public TagDecl {\n  // This class stores some data in DeclContext::RecordDeclBits\n  // to save some space. Use the provided accessors to access it.\npublic:\n  friend class DeclContext;\n  /// Enum that represents the different ways arguments are passed to and\n  /// returned from function calls. This takes into account the target-specific\n  /// and version-specific rules along with the rules determined by the\n  /// language.\n  enum ArgPassingKind : unsigned {\n    /// The argument of this type can be passed directly in registers.\n    APK_CanPassInRegs,\n\n    /// The argument of this type cannot be passed directly in registers.\n    /// Records containing this type as a subobject are not forced to be passed\n    /// indirectly. This value is used only in C++. This value is required by\n    /// C++ because, in uncommon situations, it is possible for a class to have\n    /// only trivial copy/move constructors even when one of its subobjects has\n    /// a non-trivial copy/move constructor (if e.g. the corresponding copy/move\n    /// constructor in the derived class is deleted).\n    APK_CannotPassInRegs,\n\n    /// The argument of this type cannot be passed directly in registers.\n    /// Records containing this type as a subobject are forced to be passed\n    /// indirectly.\n    APK_CanNeverPassInRegs\n  };\n\nprotected:\n  RecordDecl(Kind DK, TagKind TK, const ASTContext &C, DeclContext *DC,\n             SourceLocation StartLoc, SourceLocation IdLoc,\n             IdentifierInfo *Id, RecordDecl *PrevDecl);\n\npublic:\n  static RecordDecl *Create(const ASTContext &C, TagKind TK, DeclContext *DC,\n                            SourceLocation StartLoc, SourceLocation IdLoc,\n                            IdentifierInfo *Id, RecordDecl* PrevDecl = nullptr);\n  static RecordDecl *CreateDeserialized(const ASTContext &C, unsigned ID);\n\n  RecordDecl *getPreviousDecl() {\n    return cast_or_null<RecordDecl>(\n            static_cast<TagDecl *>(this)->getPreviousDecl());\n  }\n  const RecordDecl *getPreviousDecl() const {\n    return const_cast<RecordDecl*>(this)->getPreviousDecl();\n  }\n\n  RecordDecl *getMostRecentDecl() {\n    return cast<RecordDecl>(static_cast<TagDecl *>(this)->getMostRecentDecl());\n  }\n  const RecordDecl *getMostRecentDecl() const {\n    return const_cast<RecordDecl*>(this)->getMostRecentDecl();\n  }\n\n  bool hasFlexibleArrayMember() const {\n    return RecordDeclBits.HasFlexibleArrayMember;\n  }\n\n  void setHasFlexibleArrayMember(bool V) {\n    RecordDeclBits.HasFlexibleArrayMember = V;\n  }\n\n  /// Whether this is an anonymous struct or union. To be an anonymous\n  /// struct or union, it must have been declared without a name and\n  /// there must be no objects of this type declared, e.g.,\n  /// @code\n  ///   union { int i; float f; };\n  /// @endcode\n  /// is an anonymous union but neither of the following are:\n  /// @code\n  ///  union X { int i; float f; };\n  ///  union { int i; float f; } obj;\n  /// @endcode\n  bool isAnonymousStructOrUnion() const {\n    return RecordDeclBits.AnonymousStructOrUnion;\n  }\n\n  void setAnonymousStructOrUnion(bool Anon) {\n    RecordDeclBits.AnonymousStructOrUnion = Anon;\n  }\n\n  bool hasObjectMember() const { return RecordDeclBits.HasObjectMember; }\n  void setHasObjectMember(bool val) { RecordDeclBits.HasObjectMember = val; }\n\n  bool hasVolatileMember() const { return RecordDeclBits.HasVolatileMember; }\n\n  void setHasVolatileMember(bool val) {\n    RecordDeclBits.HasVolatileMember = val;\n  }\n\n  bool hasLoadedFieldsFromExternalStorage() const {\n    return RecordDeclBits.LoadedFieldsFromExternalStorage;\n  }\n\n  void setHasLoadedFieldsFromExternalStorage(bool val) const {\n    RecordDeclBits.LoadedFieldsFromExternalStorage = val;\n  }\n\n  /// Functions to query basic properties of non-trivial C structs.\n  bool isNonTrivialToPrimitiveDefaultInitialize() const {\n    return RecordDeclBits.NonTrivialToPrimitiveDefaultInitialize;\n  }\n\n  void setNonTrivialToPrimitiveDefaultInitialize(bool V) {\n    RecordDeclBits.NonTrivialToPrimitiveDefaultInitialize = V;\n  }\n\n  bool isNonTrivialToPrimitiveCopy() const {\n    return RecordDeclBits.NonTrivialToPrimitiveCopy;\n  }\n\n  void setNonTrivialToPrimitiveCopy(bool V) {\n    RecordDeclBits.NonTrivialToPrimitiveCopy = V;\n  }\n\n  bool isNonTrivialToPrimitiveDestroy() const {\n    return RecordDeclBits.NonTrivialToPrimitiveDestroy;\n  }\n\n  void setNonTrivialToPrimitiveDestroy(bool V) {\n    RecordDeclBits.NonTrivialToPrimitiveDestroy = V;\n  }\n\n  bool hasNonTrivialToPrimitiveDefaultInitializeCUnion() const {\n    return RecordDeclBits.HasNonTrivialToPrimitiveDefaultInitializeCUnion;\n  }\n\n  void setHasNonTrivialToPrimitiveDefaultInitializeCUnion(bool V) {\n    RecordDeclBits.HasNonTrivialToPrimitiveDefaultInitializeCUnion = V;\n  }\n\n  bool hasNonTrivialToPrimitiveDestructCUnion() const {\n    return RecordDeclBits.HasNonTrivialToPrimitiveDestructCUnion;\n  }\n\n  void setHasNonTrivialToPrimitiveDestructCUnion(bool V) {\n    RecordDeclBits.HasNonTrivialToPrimitiveDestructCUnion = V;\n  }\n\n  bool hasNonTrivialToPrimitiveCopyCUnion() const {\n    return RecordDeclBits.HasNonTrivialToPrimitiveCopyCUnion;\n  }\n\n  void setHasNonTrivialToPrimitiveCopyCUnion(bool V) {\n    RecordDeclBits.HasNonTrivialToPrimitiveCopyCUnion = V;\n  }\n\n  /// Determine whether this class can be passed in registers. In C++ mode,\n  /// it must have at least one trivial, non-deleted copy or move constructor.\n  /// FIXME: This should be set as part of completeDefinition.\n  bool canPassInRegisters() const {\n    return getArgPassingRestrictions() == APK_CanPassInRegs;\n  }\n\n  ArgPassingKind getArgPassingRestrictions() const {\n    return static_cast<ArgPassingKind>(RecordDeclBits.ArgPassingRestrictions);\n  }\n\n  void setArgPassingRestrictions(ArgPassingKind Kind) {\n    RecordDeclBits.ArgPassingRestrictions = Kind;\n  }\n\n  bool isParamDestroyedInCallee() const {\n    return RecordDeclBits.ParamDestroyedInCallee;\n  }\n\n  void setParamDestroyedInCallee(bool V) {\n    RecordDeclBits.ParamDestroyedInCallee = V;\n  }\n\n  /// Determines whether this declaration represents the\n  /// injected class name.\n  ///\n  /// The injected class name in C++ is the name of the class that\n  /// appears inside the class itself. For example:\n  ///\n  /// \\code\n  /// struct C {\n  ///   // C is implicitly declared here as a synonym for the class name.\n  /// };\n  ///\n  /// C::C c; // same as \"C c;\"\n  /// \\endcode\n  bool isInjectedClassName() const;\n\n  /// Determine whether this record is a class describing a lambda\n  /// function object.\n  bool isLambda() const;\n\n  /// Determine whether this record is a record for captured variables in\n  /// CapturedStmt construct.\n  bool isCapturedRecord() const;\n\n  /// Mark the record as a record for captured variables in CapturedStmt\n  /// construct.\n  void setCapturedRecord();\n\n  /// Returns the RecordDecl that actually defines\n  ///  this struct/union/class.  When determining whether or not a\n  ///  struct/union/class is completely defined, one should use this\n  ///  method as opposed to 'isCompleteDefinition'.\n  ///  'isCompleteDefinition' indicates whether or not a specific\n  ///  RecordDecl is a completed definition, not whether or not the\n  ///  record type is defined.  This method returns NULL if there is\n  ///  no RecordDecl that defines the struct/union/tag.\n  RecordDecl *getDefinition() const {\n    return cast_or_null<RecordDecl>(TagDecl::getDefinition());\n  }\n\n  /// Returns whether this record is a union, or contains (at any nesting level)\n  /// a union member. This is used by CMSE to warn about possible information\n  /// leaks.\n  bool isOrContainsUnion() const;\n\n  // Iterator access to field members. The field iterator only visits\n  // the non-static data members of this class, ignoring any static\n  // data members, functions, constructors, destructors, etc.\n  using field_iterator = specific_decl_iterator<FieldDecl>;\n  using field_range = llvm::iterator_range<specific_decl_iterator<FieldDecl>>;\n\n  field_range fields() const { return field_range(field_begin(), field_end()); }\n  field_iterator field_begin() const;\n\n  field_iterator field_end() const {\n    return field_iterator(decl_iterator());\n  }\n\n  // Whether there are any fields (non-static data members) in this record.\n  bool field_empty() const {\n    return field_begin() == field_end();\n  }\n\n  /// Note that the definition of this type is now complete.\n  virtual void completeDefinition();\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) {\n    return K >= firstRecord && K <= lastRecord;\n  }\n\n  /// Get whether or not this is an ms_struct which can\n  /// be turned on with an attribute, pragma, or -mms-bitfields\n  /// commandline option.\n  bool isMsStruct(const ASTContext &C) const;\n\n  /// Whether we are allowed to insert extra padding between fields.\n  /// These padding are added to help AddressSanitizer detect\n  /// intra-object-overflow bugs.\n  bool mayInsertExtraPadding(bool EmitRemark = false) const;\n\n  /// Finds the first data member which has a name.\n  /// nullptr is returned if no named data member exists.\n  const FieldDecl *findFirstNamedDataMember() const;\n\nprivate:\n  /// Deserialize just the fields.\n  void LoadFieldsFromExternalStorage() const;\n};\n\nclass FileScopeAsmDecl : public Decl {\n  StringLiteral *AsmString;\n  SourceLocation RParenLoc;\n\n  FileScopeAsmDecl(DeclContext *DC, StringLiteral *asmstring,\n                   SourceLocation StartL, SourceLocation EndL)\n    : Decl(FileScopeAsm, DC, StartL), AsmString(asmstring), RParenLoc(EndL) {}\n\n  virtual void anchor();\n\npublic:\n  static FileScopeAsmDecl *Create(ASTContext &C, DeclContext *DC,\n                                  StringLiteral *Str, SourceLocation AsmLoc,\n                                  SourceLocation RParenLoc);\n\n  static FileScopeAsmDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceLocation getAsmLoc() const { return getLocation(); }\n  SourceLocation getRParenLoc() const { return RParenLoc; }\n  void setRParenLoc(SourceLocation L) { RParenLoc = L; }\n  SourceRange getSourceRange() const override LLVM_READONLY {\n    return SourceRange(getAsmLoc(), getRParenLoc());\n  }\n\n  const StringLiteral *getAsmString() const { return AsmString; }\n  StringLiteral *getAsmString() { return AsmString; }\n  void setAsmString(StringLiteral *Asm) { AsmString = Asm; }\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == FileScopeAsm; }\n};\n\n/// Represents a block literal declaration, which is like an\n/// unnamed FunctionDecl.  For example:\n/// ^{ statement-body }   or   ^(int arg1, float arg2){ statement-body }\nclass BlockDecl : public Decl, public DeclContext {\n  // This class stores some data in DeclContext::BlockDeclBits\n  // to save some space. Use the provided accessors to access it.\npublic:\n  /// A class which contains all the information about a particular\n  /// captured value.\n  class Capture {\n    enum {\n      flag_isByRef = 0x1,\n      flag_isNested = 0x2\n    };\n\n    /// The variable being captured.\n    llvm::PointerIntPair<VarDecl*, 2> VariableAndFlags;\n\n    /// The copy expression, expressed in terms of a DeclRef (or\n    /// BlockDeclRef) to the captured variable.  Only required if the\n    /// variable has a C++ class type.\n    Expr *CopyExpr;\n\n  public:\n    Capture(VarDecl *variable, bool byRef, bool nested, Expr *copy)\n      : VariableAndFlags(variable,\n                  (byRef ? flag_isByRef : 0) | (nested ? flag_isNested : 0)),\n        CopyExpr(copy) {}\n\n    /// The variable being captured.\n    VarDecl *getVariable() const { return VariableAndFlags.getPointer(); }\n\n    /// Whether this is a \"by ref\" capture, i.e. a capture of a __block\n    /// variable.\n    bool isByRef() const { return VariableAndFlags.getInt() & flag_isByRef; }\n\n    bool isEscapingByref() const {\n      return getVariable()->isEscapingByref();\n    }\n\n    bool isNonEscapingByref() const {\n      return getVariable()->isNonEscapingByref();\n    }\n\n    /// Whether this is a nested capture, i.e. the variable captured\n    /// is not from outside the immediately enclosing function/block.\n    bool isNested() const { return VariableAndFlags.getInt() & flag_isNested; }\n\n    bool hasCopyExpr() const { return CopyExpr != nullptr; }\n    Expr *getCopyExpr() const { return CopyExpr; }\n    void setCopyExpr(Expr *e) { CopyExpr = e; }\n  };\n\nprivate:\n  /// A new[]'d array of pointers to ParmVarDecls for the formal\n  /// parameters of this function.  This is null if a prototype or if there are\n  /// no formals.\n  ParmVarDecl **ParamInfo = nullptr;\n  unsigned NumParams = 0;\n\n  Stmt *Body = nullptr;\n  TypeSourceInfo *SignatureAsWritten = nullptr;\n\n  const Capture *Captures = nullptr;\n  unsigned NumCaptures = 0;\n\n  unsigned ManglingNumber = 0;\n  Decl *ManglingContextDecl = nullptr;\n\nprotected:\n  BlockDecl(DeclContext *DC, SourceLocation CaretLoc);\n\npublic:\n  static BlockDecl *Create(ASTContext &C, DeclContext *DC, SourceLocation L);\n  static BlockDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceLocation getCaretLocation() const { return getLocation(); }\n\n  bool isVariadic() const { return BlockDeclBits.IsVariadic; }\n  void setIsVariadic(bool value) { BlockDeclBits.IsVariadic = value; }\n\n  CompoundStmt *getCompoundBody() const { return (CompoundStmt*) Body; }\n  Stmt *getBody() const override { return (Stmt*) Body; }\n  void setBody(CompoundStmt *B) { Body = (Stmt*) B; }\n\n  void setSignatureAsWritten(TypeSourceInfo *Sig) { SignatureAsWritten = Sig; }\n  TypeSourceInfo *getSignatureAsWritten() const { return SignatureAsWritten; }\n\n  // ArrayRef access to formal parameters.\n  ArrayRef<ParmVarDecl *> parameters() const {\n    return {ParamInfo, getNumParams()};\n  }\n  MutableArrayRef<ParmVarDecl *> parameters() {\n    return {ParamInfo, getNumParams()};\n  }\n\n  // Iterator access to formal parameters.\n  using param_iterator = MutableArrayRef<ParmVarDecl *>::iterator;\n  using param_const_iterator = ArrayRef<ParmVarDecl *>::const_iterator;\n\n  bool param_empty() const { return parameters().empty(); }\n  param_iterator param_begin() { return parameters().begin(); }\n  param_iterator param_end() { return parameters().end(); }\n  param_const_iterator param_begin() const { return parameters().begin(); }\n  param_const_iterator param_end() const { return parameters().end(); }\n  size_t param_size() const { return parameters().size(); }\n\n  unsigned getNumParams() const { return NumParams; }\n\n  const ParmVarDecl *getParamDecl(unsigned i) const {\n    assert(i < getNumParams() && \"Illegal param #\");\n    return ParamInfo[i];\n  }\n  ParmVarDecl *getParamDecl(unsigned i) {\n    assert(i < getNumParams() && \"Illegal param #\");\n    return ParamInfo[i];\n  }\n\n  void setParams(ArrayRef<ParmVarDecl *> NewParamInfo);\n\n  /// True if this block (or its nested blocks) captures\n  /// anything of local storage from its enclosing scopes.\n  bool hasCaptures() const { return NumCaptures || capturesCXXThis(); }\n\n  /// Returns the number of captured variables.\n  /// Does not include an entry for 'this'.\n  unsigned getNumCaptures() const { return NumCaptures; }\n\n  using capture_const_iterator = ArrayRef<Capture>::const_iterator;\n\n  ArrayRef<Capture> captures() const { return {Captures, NumCaptures}; }\n\n  capture_const_iterator capture_begin() const { return captures().begin(); }\n  capture_const_iterator capture_end() const { return captures().end(); }\n\n  bool capturesCXXThis() const { return BlockDeclBits.CapturesCXXThis; }\n  void setCapturesCXXThis(bool B = true) { BlockDeclBits.CapturesCXXThis = B; }\n\n  bool blockMissingReturnType() const {\n    return BlockDeclBits.BlockMissingReturnType;\n  }\n\n  void setBlockMissingReturnType(bool val = true) {\n    BlockDeclBits.BlockMissingReturnType = val;\n  }\n\n  bool isConversionFromLambda() const {\n    return BlockDeclBits.IsConversionFromLambda;\n  }\n\n  void setIsConversionFromLambda(bool val = true) {\n    BlockDeclBits.IsConversionFromLambda = val;\n  }\n\n  bool doesNotEscape() const { return BlockDeclBits.DoesNotEscape; }\n  void setDoesNotEscape(bool B = true) { BlockDeclBits.DoesNotEscape = B; }\n\n  bool canAvoidCopyToHeap() const {\n    return BlockDeclBits.CanAvoidCopyToHeap;\n  }\n  void setCanAvoidCopyToHeap(bool B = true) {\n    BlockDeclBits.CanAvoidCopyToHeap = B;\n  }\n\n  bool capturesVariable(const VarDecl *var) const;\n\n  void setCaptures(ASTContext &Context, ArrayRef<Capture> Captures,\n                   bool CapturesCXXThis);\n\n  unsigned getBlockManglingNumber() const { return ManglingNumber; }\n\n  Decl *getBlockManglingContextDecl() const { return ManglingContextDecl; }\n\n  void setBlockMangling(unsigned Number, Decl *Ctx) {\n    ManglingNumber = Number;\n    ManglingContextDecl = Ctx;\n  }\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Block; }\n  static DeclContext *castToDeclContext(const BlockDecl *D) {\n    return static_cast<DeclContext *>(const_cast<BlockDecl*>(D));\n  }\n  static BlockDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<BlockDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// Represents the body of a CapturedStmt, and serves as its DeclContext.\nclass CapturedDecl final\n    : public Decl,\n      public DeclContext,\n      private llvm::TrailingObjects<CapturedDecl, ImplicitParamDecl *> {\nprotected:\n  size_t numTrailingObjects(OverloadToken<ImplicitParamDecl>) {\n    return NumParams;\n  }\n\nprivate:\n  /// The number of parameters to the outlined function.\n  unsigned NumParams;\n\n  /// The position of context parameter in list of parameters.\n  unsigned ContextParam;\n\n  /// The body of the outlined function.\n  llvm::PointerIntPair<Stmt *, 1, bool> BodyAndNothrow;\n\n  explicit CapturedDecl(DeclContext *DC, unsigned NumParams);\n\n  ImplicitParamDecl *const *getParams() const {\n    return getTrailingObjects<ImplicitParamDecl *>();\n  }\n\n  ImplicitParamDecl **getParams() {\n    return getTrailingObjects<ImplicitParamDecl *>();\n  }\n\npublic:\n  friend class ASTDeclReader;\n  friend class ASTDeclWriter;\n  friend TrailingObjects;\n\n  static CapturedDecl *Create(ASTContext &C, DeclContext *DC,\n                              unsigned NumParams);\n  static CapturedDecl *CreateDeserialized(ASTContext &C, unsigned ID,\n                                          unsigned NumParams);\n\n  Stmt *getBody() const override;\n  void setBody(Stmt *B);\n\n  bool isNothrow() const;\n  void setNothrow(bool Nothrow = true);\n\n  unsigned getNumParams() const { return NumParams; }\n\n  ImplicitParamDecl *getParam(unsigned i) const {\n    assert(i < NumParams);\n    return getParams()[i];\n  }\n  void setParam(unsigned i, ImplicitParamDecl *P) {\n    assert(i < NumParams);\n    getParams()[i] = P;\n  }\n\n  // ArrayRef interface to parameters.\n  ArrayRef<ImplicitParamDecl *> parameters() const {\n    return {getParams(), getNumParams()};\n  }\n  MutableArrayRef<ImplicitParamDecl *> parameters() {\n    return {getParams(), getNumParams()};\n  }\n\n  /// Retrieve the parameter containing captured variables.\n  ImplicitParamDecl *getContextParam() const {\n    assert(ContextParam < NumParams);\n    return getParam(ContextParam);\n  }\n  void setContextParam(unsigned i, ImplicitParamDecl *P) {\n    assert(i < NumParams);\n    ContextParam = i;\n    setParam(i, P);\n  }\n  unsigned getContextParamPosition() const { return ContextParam; }\n\n  using param_iterator = ImplicitParamDecl *const *;\n  using param_range = llvm::iterator_range<param_iterator>;\n\n  /// Retrieve an iterator pointing to the first parameter decl.\n  param_iterator param_begin() const { return getParams(); }\n  /// Retrieve an iterator one past the last parameter decl.\n  param_iterator param_end() const { return getParams() + NumParams; }\n\n  // Implement isa/cast/dyncast/etc.\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Captured; }\n  static DeclContext *castToDeclContext(const CapturedDecl *D) {\n    return static_cast<DeclContext *>(const_cast<CapturedDecl *>(D));\n  }\n  static CapturedDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<CapturedDecl *>(const_cast<DeclContext *>(DC));\n  }\n};\n\n/// Describes a module import declaration, which makes the contents\n/// of the named module visible in the current translation unit.\n///\n/// An import declaration imports the named module (or submodule). For example:\n/// \\code\n///   @import std.vector;\n/// \\endcode\n///\n/// Import declarations can also be implicitly generated from\n/// \\#include/\\#import directives.\nclass ImportDecl final : public Decl,\n                         llvm::TrailingObjects<ImportDecl, SourceLocation> {\n  friend class ASTContext;\n  friend class ASTDeclReader;\n  friend class ASTReader;\n  friend TrailingObjects;\n\n  /// The imported module.\n  Module *ImportedModule = nullptr;\n\n  /// The next import in the list of imports local to the translation\n  /// unit being parsed (not loaded from an AST file).\n  ///\n  /// Includes a bit that indicates whether we have source-location information\n  /// for each identifier in the module name.\n  ///\n  /// When the bit is false, we only have a single source location for the\n  /// end of the import declaration.\n  llvm::PointerIntPair<ImportDecl *, 1, bool> NextLocalImportAndComplete;\n\n  ImportDecl(DeclContext *DC, SourceLocation StartLoc, Module *Imported,\n             ArrayRef<SourceLocation> IdentifierLocs);\n\n  ImportDecl(DeclContext *DC, SourceLocation StartLoc, Module *Imported,\n             SourceLocation EndLoc);\n\n  ImportDecl(EmptyShell Empty) : Decl(Import, Empty) {}\n\n  bool isImportComplete() const { return NextLocalImportAndComplete.getInt(); }\n\n  void setImportComplete(bool C) { NextLocalImportAndComplete.setInt(C); }\n\n  /// The next import in the list of imports local to the translation\n  /// unit being parsed (not loaded from an AST file).\n  ImportDecl *getNextLocalImport() const {\n    return NextLocalImportAndComplete.getPointer();\n  }\n\n  void setNextLocalImport(ImportDecl *Import) {\n    NextLocalImportAndComplete.setPointer(Import);\n  }\n\npublic:\n  /// Create a new module import declaration.\n  static ImportDecl *Create(ASTContext &C, DeclContext *DC,\n                            SourceLocation StartLoc, Module *Imported,\n                            ArrayRef<SourceLocation> IdentifierLocs);\n\n  /// Create a new module import declaration for an implicitly-generated\n  /// import.\n  static ImportDecl *CreateImplicit(ASTContext &C, DeclContext *DC,\n                                    SourceLocation StartLoc, Module *Imported,\n                                    SourceLocation EndLoc);\n\n  /// Create a new, deserialized module import declaration.\n  static ImportDecl *CreateDeserialized(ASTContext &C, unsigned ID,\n                                        unsigned NumLocations);\n\n  /// Retrieve the module that was imported by the import declaration.\n  Module *getImportedModule() const { return ImportedModule; }\n\n  /// Retrieves the locations of each of the identifiers that make up\n  /// the complete module name in the import declaration.\n  ///\n  /// This will return an empty array if the locations of the individual\n  /// identifiers aren't available.\n  ArrayRef<SourceLocation> getIdentifierLocs() const;\n\n  SourceRange getSourceRange() const override LLVM_READONLY;\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Import; }\n};\n\n/// Represents a C++ Modules TS module export declaration.\n///\n/// For example:\n/// \\code\n///   export void foo();\n/// \\endcode\nclass ExportDecl final : public Decl, public DeclContext {\n  virtual void anchor();\n\nprivate:\n  friend class ASTDeclReader;\n\n  /// The source location for the right brace (if valid).\n  SourceLocation RBraceLoc;\n\n  ExportDecl(DeclContext *DC, SourceLocation ExportLoc)\n      : Decl(Export, DC, ExportLoc), DeclContext(Export),\n        RBraceLoc(SourceLocation()) {}\n\npublic:\n  static ExportDecl *Create(ASTContext &C, DeclContext *DC,\n                            SourceLocation ExportLoc);\n  static ExportDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  SourceLocation getExportLoc() const { return getLocation(); }\n  SourceLocation getRBraceLoc() const { return RBraceLoc; }\n  void setRBraceLoc(SourceLocation L) { RBraceLoc = L; }\n\n  bool hasBraces() const { return RBraceLoc.isValid(); }\n\n  SourceLocation getEndLoc() const LLVM_READONLY {\n    if (hasBraces())\n      return RBraceLoc;\n    // No braces: get the end location of the (only) declaration in context\n    // (if present).\n    return decls_empty() ? getLocation() : decls_begin()->getEndLoc();\n  }\n\n  SourceRange getSourceRange() const override LLVM_READONLY {\n    return SourceRange(getLocation(), getEndLoc());\n  }\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Export; }\n  static DeclContext *castToDeclContext(const ExportDecl *D) {\n    return static_cast<DeclContext *>(const_cast<ExportDecl*>(D));\n  }\n  static ExportDecl *castFromDeclContext(const DeclContext *DC) {\n    return static_cast<ExportDecl *>(const_cast<DeclContext*>(DC));\n  }\n};\n\n/// Represents an empty-declaration.\nclass EmptyDecl : public Decl {\n  EmptyDecl(DeclContext *DC, SourceLocation L) : Decl(Empty, DC, L) {}\n\n  virtual void anchor();\n\npublic:\n  static EmptyDecl *Create(ASTContext &C, DeclContext *DC,\n                           SourceLocation L);\n  static EmptyDecl *CreateDeserialized(ASTContext &C, unsigned ID);\n\n  static bool classof(const Decl *D) { return classofKind(D->getKind()); }\n  static bool classofKind(Kind K) { return K == Empty; }\n};\n\n/// Insertion operator for diagnostics.  This allows sending NamedDecl's\n/// into a diagnostic with <<.\ninline const StreamingDiagnostic &operator<<(const StreamingDiagnostic &PD,\n                                             const NamedDecl *ND) {\n  PD.AddTaggedVal(reinterpret_cast<intptr_t>(ND),\n                  DiagnosticsEngine::ak_nameddecl);\n  return PD;\n}\n\ntemplate<typename decl_type>\nvoid Redeclarable<decl_type>::setPreviousDecl(decl_type *PrevDecl) {\n  // Note: This routine is implemented here because we need both NamedDecl\n  // and Redeclarable to be defined.\n  assert(RedeclLink.isFirst() &&\n         \"setPreviousDecl on a decl already in a redeclaration chain\");\n\n  if (PrevDecl) {\n    // Point to previous. Make sure that this is actually the most recent\n    // redeclaration, or we can build invalid chains. If the most recent\n    // redeclaration is invalid, it won't be PrevDecl, but we want it anyway.\n    First = PrevDecl->getFirstDecl();\n    assert(First->RedeclLink.isFirst() && \"Expected first\");\n    decl_type *MostRecent = First->getNextRedeclaration();\n    RedeclLink = PreviousDeclLink(cast<decl_type>(MostRecent));\n\n    // If the declaration was previously visible, a redeclaration of it remains\n    // visible even if it wouldn't be visible by itself.\n    static_cast<decl_type*>(this)->IdentifierNamespace |=\n      MostRecent->getIdentifierNamespace() &\n      (Decl::IDNS_Ordinary | Decl::IDNS_Tag | Decl::IDNS_Type);\n  } else {\n    // Make this first.\n    First = static_cast<decl_type*>(this);\n  }\n\n  // First one will point to this one as latest.\n  First->RedeclLink.setLatest(static_cast<decl_type*>(this));\n\n  assert(!isa<NamedDecl>(static_cast<decl_type*>(this)) ||\n         cast<NamedDecl>(static_cast<decl_type*>(this))->isLinkageValid());\n}\n\n// Inline function definitions.\n\n/// Check if the given decl is complete.\n///\n/// We use this function to break a cycle between the inline definitions in\n/// Type.h and Decl.h.\ninline bool IsEnumDeclComplete(EnumDecl *ED) {\n  return ED->isComplete();\n}\n\n/// Check if the given decl is scoped.\n///\n/// We use this function to break a cycle between the inline definitions in\n/// Type.h and Decl.h.\ninline bool IsEnumDeclScoped(EnumDecl *ED) {\n  return ED->isScoped();\n}\n\n/// OpenMP variants are mangled early based on their OpenMP context selector.\n/// The new name looks likes this:\n///  <name> + OpenMPVariantManglingSeparatorStr + <mangled OpenMP context>\nstatic constexpr StringRef getOpenMPVariantManglingSeparatorStr() {\n  return \"$ompvariant\";\n}\n\n} // namespace clang\n\n#endif // LLVM_CLANG_AST_DECL_H\n"}, "35": {"id": 35, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "content": "//===----- CGOpenMPRuntime.cpp - Interface to OpenMP Runtimes -------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This provides a class for OpenMP runtime code generation.\n//\n//===----------------------------------------------------------------------===//\n\n#include \"CGOpenMPRuntime.h\"\n#include \"CGCXXABI.h\"\n#include \"CGCleanup.h\"\n#include \"CGRecordLayout.h\"\n#include \"CodeGenFunction.h\"\n#include \"clang/AST/Attr.h\"\n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/OpenMPClause.h\"\n#include \"clang/AST/StmtOpenMP.h\"\n#include \"clang/AST/StmtVisitor.h\"\n#include \"clang/Basic/BitmaskEnum.h\"\n#include \"clang/Basic/FileManager.h\"\n#include \"clang/Basic/OpenMPKinds.h\"\n#include \"clang/Basic/SourceManager.h\"\n#include \"clang/CodeGen/ConstantInitBuilder.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/SetOperations.h\"\n#include \"llvm/ADT/StringExtras.h\"\n#include \"llvm/Bitcode/BitcodeReader.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/IR/GlobalValue.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/Support/AtomicOrdering.h\"\n#include \"llvm/Support/Format.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <cassert>\n#include <numeric>\n\nusing namespace clang;\nusing namespace CodeGen;\nusing namespace llvm::omp;\n\nnamespace {\n/// Base class for handling code generation inside OpenMP regions.\nclass CGOpenMPRegionInfo : public CodeGenFunction::CGCapturedStmtInfo {\npublic:\n  /// Kinds of OpenMP regions used in codegen.\n  enum CGOpenMPRegionKind {\n    /// Region with outlined function for standalone 'parallel'\n    /// directive.\n    ParallelOutlinedRegion,\n    /// Region with outlined function for standalone 'task' directive.\n    TaskOutlinedRegion,\n    /// Region for constructs that do not require function outlining,\n    /// like 'for', 'sections', 'atomic' etc. directives.\n    InlinedRegion,\n    /// Region with outlined function for standalone 'target' directive.\n    TargetRegion,\n  };\n\n  CGOpenMPRegionInfo(const CapturedStmt &CS,\n                     const CGOpenMPRegionKind RegionKind,\n                     const RegionCodeGenTy &CodeGen, OpenMPDirectiveKind Kind,\n                     bool HasCancel)\n      : CGCapturedStmtInfo(CS, CR_OpenMP), RegionKind(RegionKind),\n        CodeGen(CodeGen), Kind(Kind), HasCancel(HasCancel) {}\n\n  CGOpenMPRegionInfo(const CGOpenMPRegionKind RegionKind,\n                     const RegionCodeGenTy &CodeGen, OpenMPDirectiveKind Kind,\n                     bool HasCancel)\n      : CGCapturedStmtInfo(CR_OpenMP), RegionKind(RegionKind), CodeGen(CodeGen),\n        Kind(Kind), HasCancel(HasCancel) {}\n\n  /// Get a variable or parameter for storing global thread id\n  /// inside OpenMP construct.\n  virtual const VarDecl *getThreadIDVariable() const = 0;\n\n  /// Emit the captured statement body.\n  void EmitBody(CodeGenFunction &CGF, const Stmt *S) override;\n\n  /// Get an LValue for the current ThreadID variable.\n  /// \\return LValue for thread id variable. This LValue always has type int32*.\n  virtual LValue getThreadIDVariableLValue(CodeGenFunction &CGF);\n\n  virtual void emitUntiedSwitch(CodeGenFunction & /*CGF*/) {}\n\n  CGOpenMPRegionKind getRegionKind() const { return RegionKind; }\n\n  OpenMPDirectiveKind getDirectiveKind() const { return Kind; }\n\n  bool hasCancel() const { return HasCancel; }\n\n  static bool classof(const CGCapturedStmtInfo *Info) {\n    return Info->getKind() == CR_OpenMP;\n  }\n\n  ~CGOpenMPRegionInfo() override = default;\n\nprotected:\n  CGOpenMPRegionKind RegionKind;\n  RegionCodeGenTy CodeGen;\n  OpenMPDirectiveKind Kind;\n  bool HasCancel;\n};\n\n/// API for captured statement code generation in OpenMP constructs.\nclass CGOpenMPOutlinedRegionInfo final : public CGOpenMPRegionInfo {\npublic:\n  CGOpenMPOutlinedRegionInfo(const CapturedStmt &CS, const VarDecl *ThreadIDVar,\n                             const RegionCodeGenTy &CodeGen,\n                             OpenMPDirectiveKind Kind, bool HasCancel,\n                             StringRef HelperName)\n      : CGOpenMPRegionInfo(CS, ParallelOutlinedRegion, CodeGen, Kind,\n                           HasCancel),\n        ThreadIDVar(ThreadIDVar), HelperName(HelperName) {\n    assert(ThreadIDVar != nullptr && \"No ThreadID in OpenMP region.\");\n  }\n\n  /// Get a variable or parameter for storing global thread id\n  /// inside OpenMP construct.\n  const VarDecl *getThreadIDVariable() const override { return ThreadIDVar; }\n\n  /// Get the name of the capture helper.\n  StringRef getHelperName() const override { return HelperName; }\n\n  static bool classof(const CGCapturedStmtInfo *Info) {\n    return CGOpenMPRegionInfo::classof(Info) &&\n           cast<CGOpenMPRegionInfo>(Info)->getRegionKind() ==\n               ParallelOutlinedRegion;\n  }\n\nprivate:\n  /// A variable or parameter storing global thread id for OpenMP\n  /// constructs.\n  const VarDecl *ThreadIDVar;\n  StringRef HelperName;\n};\n\n/// API for captured statement code generation in OpenMP constructs.\nclass CGOpenMPTaskOutlinedRegionInfo final : public CGOpenMPRegionInfo {\npublic:\n  class UntiedTaskActionTy final : public PrePostActionTy {\n    bool Untied;\n    const VarDecl *PartIDVar;\n    const RegionCodeGenTy UntiedCodeGen;\n    llvm::SwitchInst *UntiedSwitch = nullptr;\n\n  public:\n    UntiedTaskActionTy(bool Tied, const VarDecl *PartIDVar,\n                       const RegionCodeGenTy &UntiedCodeGen)\n        : Untied(!Tied), PartIDVar(PartIDVar), UntiedCodeGen(UntiedCodeGen) {}\n    void Enter(CodeGenFunction &CGF) override {\n      if (Untied) {\n        // Emit task switching point.\n        LValue PartIdLVal = CGF.EmitLoadOfPointerLValue(\n            CGF.GetAddrOfLocalVar(PartIDVar),\n            PartIDVar->getType()->castAs<PointerType>());\n        llvm::Value *Res =\n            CGF.EmitLoadOfScalar(PartIdLVal, PartIDVar->getLocation());\n        llvm::BasicBlock *DoneBB = CGF.createBasicBlock(\".untied.done.\");\n        UntiedSwitch = CGF.Builder.CreateSwitch(Res, DoneBB);\n        CGF.EmitBlock(DoneBB);\n        CGF.EmitBranchThroughCleanup(CGF.ReturnBlock);\n        CGF.EmitBlock(CGF.createBasicBlock(\".untied.jmp.\"));\n        UntiedSwitch->addCase(CGF.Builder.getInt32(0),\n                              CGF.Builder.GetInsertBlock());\n        emitUntiedSwitch(CGF);\n      }\n    }\n    void emitUntiedSwitch(CodeGenFunction &CGF) const {\n      if (Untied) {\n        LValue PartIdLVal = CGF.EmitLoadOfPointerLValue(\n            CGF.GetAddrOfLocalVar(PartIDVar),\n            PartIDVar->getType()->castAs<PointerType>());\n        CGF.EmitStoreOfScalar(CGF.Builder.getInt32(UntiedSwitch->getNumCases()),\n                              PartIdLVal);\n        UntiedCodeGen(CGF);\n        CodeGenFunction::JumpDest CurPoint =\n            CGF.getJumpDestInCurrentScope(\".untied.next.\");\n        CGF.EmitBranch(CGF.ReturnBlock.getBlock());\n        CGF.EmitBlock(CGF.createBasicBlock(\".untied.jmp.\"));\n        UntiedSwitch->addCase(CGF.Builder.getInt32(UntiedSwitch->getNumCases()),\n                              CGF.Builder.GetInsertBlock());\n        CGF.EmitBranchThroughCleanup(CurPoint);\n        CGF.EmitBlock(CurPoint.getBlock());\n      }\n    }\n    unsigned getNumberOfParts() const { return UntiedSwitch->getNumCases(); }\n  };\n  CGOpenMPTaskOutlinedRegionInfo(const CapturedStmt &CS,\n                                 const VarDecl *ThreadIDVar,\n                                 const RegionCodeGenTy &CodeGen,\n                                 OpenMPDirectiveKind Kind, bool HasCancel,\n                                 const UntiedTaskActionTy &Action)\n      : CGOpenMPRegionInfo(CS, TaskOutlinedRegion, CodeGen, Kind, HasCancel),\n        ThreadIDVar(ThreadIDVar), Action(Action) {\n    assert(ThreadIDVar != nullptr && \"No ThreadID in OpenMP region.\");\n  }\n\n  /// Get a variable or parameter for storing global thread id\n  /// inside OpenMP construct.\n  const VarDecl *getThreadIDVariable() const override { return ThreadIDVar; }\n\n  /// Get an LValue for the current ThreadID variable.\n  LValue getThreadIDVariableLValue(CodeGenFunction &CGF) override;\n\n  /// Get the name of the capture helper.\n  StringRef getHelperName() const override { return \".omp_outlined.\"; }\n\n  void emitUntiedSwitch(CodeGenFunction &CGF) override {\n    Action.emitUntiedSwitch(CGF);\n  }\n\n  static bool classof(const CGCapturedStmtInfo *Info) {\n    return CGOpenMPRegionInfo::classof(Info) &&\n           cast<CGOpenMPRegionInfo>(Info)->getRegionKind() ==\n               TaskOutlinedRegion;\n  }\n\nprivate:\n  /// A variable or parameter storing global thread id for OpenMP\n  /// constructs.\n  const VarDecl *ThreadIDVar;\n  /// Action for emitting code for untied tasks.\n  const UntiedTaskActionTy &Action;\n};\n\n/// API for inlined captured statement code generation in OpenMP\n/// constructs.\nclass CGOpenMPInlinedRegionInfo : public CGOpenMPRegionInfo {\npublic:\n  CGOpenMPInlinedRegionInfo(CodeGenFunction::CGCapturedStmtInfo *OldCSI,\n                            const RegionCodeGenTy &CodeGen,\n                            OpenMPDirectiveKind Kind, bool HasCancel)\n      : CGOpenMPRegionInfo(InlinedRegion, CodeGen, Kind, HasCancel),\n        OldCSI(OldCSI),\n        OuterRegionInfo(dyn_cast_or_null<CGOpenMPRegionInfo>(OldCSI)) {}\n\n  // Retrieve the value of the context parameter.\n  llvm::Value *getContextValue() const override {\n    if (OuterRegionInfo)\n      return OuterRegionInfo->getContextValue();\n    llvm_unreachable(\"No context value for inlined OpenMP region\");\n  }\n\n  void setContextValue(llvm::Value *V) override {\n    if (OuterRegionInfo) {\n      OuterRegionInfo->setContextValue(V);\n      return;\n    }\n    llvm_unreachable(\"No context value for inlined OpenMP region\");\n  }\n\n  /// Lookup the captured field decl for a variable.\n  const FieldDecl *lookup(const VarDecl *VD) const override {\n    if (OuterRegionInfo)\n      return OuterRegionInfo->lookup(VD);\n    // If there is no outer outlined region,no need to lookup in a list of\n    // captured variables, we can use the original one.\n    return nullptr;\n  }\n\n  FieldDecl *getThisFieldDecl() const override {\n    if (OuterRegionInfo)\n      return OuterRegionInfo->getThisFieldDecl();\n    return nullptr;\n  }\n\n  /// Get a variable or parameter for storing global thread id\n  /// inside OpenMP construct.\n  const VarDecl *getThreadIDVariable() const override {\n    if (OuterRegionInfo)\n      return OuterRegionInfo->getThreadIDVariable();\n    return nullptr;\n  }\n\n  /// Get an LValue for the current ThreadID variable.\n  LValue getThreadIDVariableLValue(CodeGenFunction &CGF) override {\n    if (OuterRegionInfo)\n      return OuterRegionInfo->getThreadIDVariableLValue(CGF);\n    llvm_unreachable(\"No LValue for inlined OpenMP construct\");\n  }\n\n  /// Get the name of the capture helper.\n  StringRef getHelperName() const override {\n    if (auto *OuterRegionInfo = getOldCSI())\n      return OuterRegionInfo->getHelperName();\n    llvm_unreachable(\"No helper name for inlined OpenMP construct\");\n  }\n\n  void emitUntiedSwitch(CodeGenFunction &CGF) override {\n    if (OuterRegionInfo)\n      OuterRegionInfo->emitUntiedSwitch(CGF);\n  }\n\n  CodeGenFunction::CGCapturedStmtInfo *getOldCSI() const { return OldCSI; }\n\n  static bool classof(const CGCapturedStmtInfo *Info) {\n    return CGOpenMPRegionInfo::classof(Info) &&\n           cast<CGOpenMPRegionInfo>(Info)->getRegionKind() == InlinedRegion;\n  }\n\n  ~CGOpenMPInlinedRegionInfo() override = default;\n\nprivate:\n  /// CodeGen info about outer OpenMP region.\n  CodeGenFunction::CGCapturedStmtInfo *OldCSI;\n  CGOpenMPRegionInfo *OuterRegionInfo;\n};\n\n/// API for captured statement code generation in OpenMP target\n/// constructs. For this captures, implicit parameters are used instead of the\n/// captured fields. The name of the target region has to be unique in a given\n/// application so it is provided by the client, because only the client has\n/// the information to generate that.\nclass CGOpenMPTargetRegionInfo final : public CGOpenMPRegionInfo {\npublic:\n  CGOpenMPTargetRegionInfo(const CapturedStmt &CS,\n                           const RegionCodeGenTy &CodeGen, StringRef HelperName)\n      : CGOpenMPRegionInfo(CS, TargetRegion, CodeGen, OMPD_target,\n                           /*HasCancel=*/false),\n        HelperName(HelperName) {}\n\n  /// This is unused for target regions because each starts executing\n  /// with a single thread.\n  const VarDecl *getThreadIDVariable() const override { return nullptr; }\n\n  /// Get the name of the capture helper.\n  StringRef getHelperName() const override { return HelperName; }\n\n  static bool classof(const CGCapturedStmtInfo *Info) {\n    return CGOpenMPRegionInfo::classof(Info) &&\n           cast<CGOpenMPRegionInfo>(Info)->getRegionKind() == TargetRegion;\n  }\n\nprivate:\n  StringRef HelperName;\n};\n\nstatic void EmptyCodeGen(CodeGenFunction &, PrePostActionTy &) {\n  llvm_unreachable(\"No codegen for expressions\");\n}\n/// API for generation of expressions captured in a innermost OpenMP\n/// region.\nclass CGOpenMPInnerExprInfo final : public CGOpenMPInlinedRegionInfo {\npublic:\n  CGOpenMPInnerExprInfo(CodeGenFunction &CGF, const CapturedStmt &CS)\n      : CGOpenMPInlinedRegionInfo(CGF.CapturedStmtInfo, EmptyCodeGen,\n                                  OMPD_unknown,\n                                  /*HasCancel=*/false),\n        PrivScope(CGF) {\n    // Make sure the globals captured in the provided statement are local by\n    // using the privatization logic. We assume the same variable is not\n    // captured more than once.\n    for (const auto &C : CS.captures()) {\n      if (!C.capturesVariable() && !C.capturesVariableByCopy())\n        continue;\n\n      const VarDecl *VD = C.getCapturedVar();\n      if (VD->isLocalVarDeclOrParm())\n        continue;\n\n      DeclRefExpr DRE(CGF.getContext(), const_cast<VarDecl *>(VD),\n                      /*RefersToEnclosingVariableOrCapture=*/false,\n                      VD->getType().getNonReferenceType(), VK_LValue,\n                      C.getLocation());\n      PrivScope.addPrivate(\n          VD, [&CGF, &DRE]() { return CGF.EmitLValue(&DRE).getAddress(CGF); });\n    }\n    (void)PrivScope.Privatize();\n  }\n\n  /// Lookup the captured field decl for a variable.\n  const FieldDecl *lookup(const VarDecl *VD) const override {\n    if (const FieldDecl *FD = CGOpenMPInlinedRegionInfo::lookup(VD))\n      return FD;\n    return nullptr;\n  }\n\n  /// Emit the captured statement body.\n  void EmitBody(CodeGenFunction &CGF, const Stmt *S) override {\n    llvm_unreachable(\"No body for expressions\");\n  }\n\n  /// Get a variable or parameter for storing global thread id\n  /// inside OpenMP construct.\n  const VarDecl *getThreadIDVariable() const override {\n    llvm_unreachable(\"No thread id for expressions\");\n  }\n\n  /// Get the name of the capture helper.\n  StringRef getHelperName() const override {\n    llvm_unreachable(\"No helper name for expressions\");\n  }\n\n  static bool classof(const CGCapturedStmtInfo *Info) { return false; }\n\nprivate:\n  /// Private scope to capture global variables.\n  CodeGenFunction::OMPPrivateScope PrivScope;\n};\n\n/// RAII for emitting code of OpenMP constructs.\nclass InlinedOpenMPRegionRAII {\n  CodeGenFunction &CGF;\n  llvm::DenseMap<const VarDecl *, FieldDecl *> LambdaCaptureFields;\n  FieldDecl *LambdaThisCaptureField = nullptr;\n  const CodeGen::CGBlockInfo *BlockInfo = nullptr;\n\npublic:\n  /// Constructs region for combined constructs.\n  /// \\param CodeGen Code generation sequence for combined directives. Includes\n  /// a list of functions used for code generation of implicitly inlined\n  /// regions.\n  InlinedOpenMPRegionRAII(CodeGenFunction &CGF, const RegionCodeGenTy &CodeGen,\n                          OpenMPDirectiveKind Kind, bool HasCancel)\n      : CGF(CGF) {\n    // Start emission for the construct.\n    CGF.CapturedStmtInfo = new CGOpenMPInlinedRegionInfo(\n        CGF.CapturedStmtInfo, CodeGen, Kind, HasCancel);\n    std::swap(CGF.LambdaCaptureFields, LambdaCaptureFields);\n    LambdaThisCaptureField = CGF.LambdaThisCaptureField;\n    CGF.LambdaThisCaptureField = nullptr;\n    BlockInfo = CGF.BlockInfo;\n    CGF.BlockInfo = nullptr;\n  }\n\n  ~InlinedOpenMPRegionRAII() {\n    // Restore original CapturedStmtInfo only if we're done with code emission.\n    auto *OldCSI =\n        cast<CGOpenMPInlinedRegionInfo>(CGF.CapturedStmtInfo)->getOldCSI();\n    delete CGF.CapturedStmtInfo;\n    CGF.CapturedStmtInfo = OldCSI;\n    std::swap(CGF.LambdaCaptureFields, LambdaCaptureFields);\n    CGF.LambdaThisCaptureField = LambdaThisCaptureField;\n    CGF.BlockInfo = BlockInfo;\n  }\n};\n\n/// Values for bit flags used in the ident_t to describe the fields.\n/// All enumeric elements are named and described in accordance with the code\n/// from https://github.com/llvm/llvm-project/blob/main/openmp/runtime/src/kmp.h\nenum OpenMPLocationFlags : unsigned {\n  /// Use trampoline for internal microtask.\n  OMP_IDENT_IMD = 0x01,\n  /// Use c-style ident structure.\n  OMP_IDENT_KMPC = 0x02,\n  /// Atomic reduction option for kmpc_reduce.\n  OMP_ATOMIC_REDUCE = 0x10,\n  /// Explicit 'barrier' directive.\n  OMP_IDENT_BARRIER_EXPL = 0x20,\n  /// Implicit barrier in code.\n  OMP_IDENT_BARRIER_IMPL = 0x40,\n  /// Implicit barrier in 'for' directive.\n  OMP_IDENT_BARRIER_IMPL_FOR = 0x40,\n  /// Implicit barrier in 'sections' directive.\n  OMP_IDENT_BARRIER_IMPL_SECTIONS = 0xC0,\n  /// Implicit barrier in 'single' directive.\n  OMP_IDENT_BARRIER_IMPL_SINGLE = 0x140,\n  /// Call of __kmp_for_static_init for static loop.\n  OMP_IDENT_WORK_LOOP = 0x200,\n  /// Call of __kmp_for_static_init for sections.\n  OMP_IDENT_WORK_SECTIONS = 0x400,\n  /// Call of __kmp_for_static_init for distribute.\n  OMP_IDENT_WORK_DISTRIBUTE = 0x800,\n  LLVM_MARK_AS_BITMASK_ENUM(/*LargestValue=*/OMP_IDENT_WORK_DISTRIBUTE)\n};\n\nnamespace {\nLLVM_ENABLE_BITMASK_ENUMS_IN_NAMESPACE();\n/// Values for bit flags for marking which requires clauses have been used.\nenum OpenMPOffloadingRequiresDirFlags : int64_t {\n  /// flag undefined.\n  OMP_REQ_UNDEFINED               = 0x000,\n  /// no requires clause present.\n  OMP_REQ_NONE                    = 0x001,\n  /// reverse_offload clause.\n  OMP_REQ_REVERSE_OFFLOAD         = 0x002,\n  /// unified_address clause.\n  OMP_REQ_UNIFIED_ADDRESS         = 0x004,\n  /// unified_shared_memory clause.\n  OMP_REQ_UNIFIED_SHARED_MEMORY   = 0x008,\n  /// dynamic_allocators clause.\n  OMP_REQ_DYNAMIC_ALLOCATORS      = 0x010,\n  LLVM_MARK_AS_BITMASK_ENUM(/*LargestValue=*/OMP_REQ_DYNAMIC_ALLOCATORS)\n};\n\nenum OpenMPOffloadingReservedDeviceIDs {\n  /// Device ID if the device was not defined, runtime should get it\n  /// from environment variables in the spec.\n  OMP_DEVICEID_UNDEF = -1,\n};\n} // anonymous namespace\n\n/// Describes ident structure that describes a source location.\n/// All descriptions are taken from\n/// https://github.com/llvm/llvm-project/blob/main/openmp/runtime/src/kmp.h\n/// Original structure:\n/// typedef struct ident {\n///    kmp_int32 reserved_1;   /**<  might be used in Fortran;\n///                                  see above  */\n///    kmp_int32 flags;        /**<  also f.flags; KMP_IDENT_xxx flags;\n///                                  KMP_IDENT_KMPC identifies this union\n///                                  member  */\n///    kmp_int32 reserved_2;   /**<  not really used in Fortran any more;\n///                                  see above */\n///#if USE_ITT_BUILD\n///                            /*  but currently used for storing\n///                                region-specific ITT */\n///                            /*  contextual information. */\n///#endif /* USE_ITT_BUILD */\n///    kmp_int32 reserved_3;   /**< source[4] in Fortran, do not use for\n///                                 C++  */\n///    char const *psource;    /**< String describing the source location.\n///                            The string is composed of semi-colon separated\n//                             fields which describe the source file,\n///                            the function and a pair of line numbers that\n///                            delimit the construct.\n///                             */\n/// } ident_t;\nenum IdentFieldIndex {\n  /// might be used in Fortran\n  IdentField_Reserved_1,\n  /// OMP_IDENT_xxx flags; OMP_IDENT_KMPC identifies this union member.\n  IdentField_Flags,\n  /// Not really used in Fortran any more\n  IdentField_Reserved_2,\n  /// Source[4] in Fortran, do not use for C++\n  IdentField_Reserved_3,\n  /// String describing the source location. The string is composed of\n  /// semi-colon separated fields which describe the source file, the function\n  /// and a pair of line numbers that delimit the construct.\n  IdentField_PSource\n};\n\n/// Schedule types for 'omp for' loops (these enumerators are taken from\n/// the enum sched_type in kmp.h).\nenum OpenMPSchedType {\n  /// Lower bound for default (unordered) versions.\n  OMP_sch_lower = 32,\n  OMP_sch_static_chunked = 33,\n  OMP_sch_static = 34,\n  OMP_sch_dynamic_chunked = 35,\n  OMP_sch_guided_chunked = 36,\n  OMP_sch_runtime = 37,\n  OMP_sch_auto = 38,\n  /// static with chunk adjustment (e.g., simd)\n  OMP_sch_static_balanced_chunked = 45,\n  /// Lower bound for 'ordered' versions.\n  OMP_ord_lower = 64,\n  OMP_ord_static_chunked = 65,\n  OMP_ord_static = 66,\n  OMP_ord_dynamic_chunked = 67,\n  OMP_ord_guided_chunked = 68,\n  OMP_ord_runtime = 69,\n  OMP_ord_auto = 70,\n  OMP_sch_default = OMP_sch_static,\n  /// dist_schedule types\n  OMP_dist_sch_static_chunked = 91,\n  OMP_dist_sch_static = 92,\n  /// Support for OpenMP 4.5 monotonic and nonmonotonic schedule modifiers.\n  /// Set if the monotonic schedule modifier was present.\n  OMP_sch_modifier_monotonic = (1 << 29),\n  /// Set if the nonmonotonic schedule modifier was present.\n  OMP_sch_modifier_nonmonotonic = (1 << 30),\n};\n\n/// A basic class for pre|post-action for advanced codegen sequence for OpenMP\n/// region.\nclass CleanupTy final : public EHScopeStack::Cleanup {\n  PrePostActionTy *Action;\n\npublic:\n  explicit CleanupTy(PrePostActionTy *Action) : Action(Action) {}\n  void Emit(CodeGenFunction &CGF, Flags /*flags*/) override {\n    if (!CGF.HaveInsertPoint())\n      return;\n    Action->Exit(CGF);\n  }\n};\n\n} // anonymous namespace\n\nvoid RegionCodeGenTy::operator()(CodeGenFunction &CGF) const {\n  CodeGenFunction::RunCleanupsScope Scope(CGF);\n  if (PrePostAction) {\n    CGF.EHStack.pushCleanup<CleanupTy>(NormalAndEHCleanup, PrePostAction);\n    Callback(CodeGen, CGF, *PrePostAction);\n  } else {\n    PrePostActionTy Action;\n    Callback(CodeGen, CGF, Action);\n  }\n}\n\n/// Check if the combiner is a call to UDR combiner and if it is so return the\n/// UDR decl used for reduction.\nstatic const OMPDeclareReductionDecl *\ngetReductionInit(const Expr *ReductionOp) {\n  if (const auto *CE = dyn_cast<CallExpr>(ReductionOp))\n    if (const auto *OVE = dyn_cast<OpaqueValueExpr>(CE->getCallee()))\n      if (const auto *DRE =\n              dyn_cast<DeclRefExpr>(OVE->getSourceExpr()->IgnoreImpCasts()))\n        if (const auto *DRD = dyn_cast<OMPDeclareReductionDecl>(DRE->getDecl()))\n          return DRD;\n  return nullptr;\n}\n\nstatic void emitInitWithReductionInitializer(CodeGenFunction &CGF,\n                                             const OMPDeclareReductionDecl *DRD,\n                                             const Expr *InitOp,\n                                             Address Private, Address Original,\n                                             QualType Ty) {\n  if (DRD->getInitializer()) {\n    std::pair<llvm::Function *, llvm::Function *> Reduction =\n        CGF.CGM.getOpenMPRuntime().getUserDefinedReduction(DRD);\n    const auto *CE = cast<CallExpr>(InitOp);\n    const auto *OVE = cast<OpaqueValueExpr>(CE->getCallee());\n    const Expr *LHS = CE->getArg(/*Arg=*/0)->IgnoreParenImpCasts();\n    const Expr *RHS = CE->getArg(/*Arg=*/1)->IgnoreParenImpCasts();\n    const auto *LHSDRE =\n        cast<DeclRefExpr>(cast<UnaryOperator>(LHS)->getSubExpr());\n    const auto *RHSDRE =\n        cast<DeclRefExpr>(cast<UnaryOperator>(RHS)->getSubExpr());\n    CodeGenFunction::OMPPrivateScope PrivateScope(CGF);\n    PrivateScope.addPrivate(cast<VarDecl>(LHSDRE->getDecl()),\n                            [=]() { return Private; });\n    PrivateScope.addPrivate(cast<VarDecl>(RHSDRE->getDecl()),\n                            [=]() { return Original; });\n    (void)PrivateScope.Privatize();\n    RValue Func = RValue::get(Reduction.second);\n    CodeGenFunction::OpaqueValueMapping Map(CGF, OVE, Func);\n    CGF.EmitIgnoredExpr(InitOp);\n  } else {\n    llvm::Constant *Init = CGF.CGM.EmitNullConstant(Ty);\n    std::string Name = CGF.CGM.getOpenMPRuntime().getName({\"init\"});\n    auto *GV = new llvm::GlobalVariable(\n        CGF.CGM.getModule(), Init->getType(), /*isConstant=*/true,\n        llvm::GlobalValue::PrivateLinkage, Init, Name);\n    LValue LV = CGF.MakeNaturalAlignAddrLValue(GV, Ty);\n    RValue InitRVal;\n    switch (CGF.getEvaluationKind(Ty)) {\n    case TEK_Scalar:\n      InitRVal = CGF.EmitLoadOfLValue(LV, DRD->getLocation());\n      break;\n    case TEK_Complex:\n      InitRVal =\n          RValue::getComplex(CGF.EmitLoadOfComplex(LV, DRD->getLocation()));\n      break;\n    case TEK_Aggregate:\n      InitRVal = RValue::getAggregate(LV.getAddress(CGF));\n      break;\n    }\n    OpaqueValueExpr OVE(DRD->getLocation(), Ty, VK_RValue);\n    CodeGenFunction::OpaqueValueMapping OpaqueMap(CGF, &OVE, InitRVal);\n    CGF.EmitAnyExprToMem(&OVE, Private, Ty.getQualifiers(),\n                         /*IsInitializer=*/false);\n  }\n}\n\n/// Emit initialization of arrays of complex types.\n/// \\param DestAddr Address of the array.\n/// \\param Type Type of array.\n/// \\param Init Initial expression of array.\n/// \\param SrcAddr Address of the original array.\nstatic void EmitOMPAggregateInit(CodeGenFunction &CGF, Address DestAddr,\n                                 QualType Type, bool EmitDeclareReductionInit,\n                                 const Expr *Init,\n                                 const OMPDeclareReductionDecl *DRD,\n                                 Address SrcAddr = Address::invalid()) {\n  // Perform element-by-element initialization.\n  QualType ElementTy;\n\n  // Drill down to the base element type on both arrays.\n  const ArrayType *ArrayTy = Type->getAsArrayTypeUnsafe();\n  llvm::Value *NumElements = CGF.emitArrayLength(ArrayTy, ElementTy, DestAddr);\n  DestAddr =\n      CGF.Builder.CreateElementBitCast(DestAddr, DestAddr.getElementType());\n  if (DRD)\n    SrcAddr =\n        CGF.Builder.CreateElementBitCast(SrcAddr, DestAddr.getElementType());\n\n  llvm::Value *SrcBegin = nullptr;\n  if (DRD)\n    SrcBegin = SrcAddr.getPointer();\n  llvm::Value *DestBegin = DestAddr.getPointer();\n  // Cast from pointer to array type to pointer to single element.\n  llvm::Value *DestEnd = CGF.Builder.CreateGEP(DestBegin, NumElements);\n  // The basic structure here is a while-do loop.\n  llvm::BasicBlock *BodyBB = CGF.createBasicBlock(\"omp.arrayinit.body\");\n  llvm::BasicBlock *DoneBB = CGF.createBasicBlock(\"omp.arrayinit.done\");\n  llvm::Value *IsEmpty =\n      CGF.Builder.CreateICmpEQ(DestBegin, DestEnd, \"omp.arrayinit.isempty\");\n  CGF.Builder.CreateCondBr(IsEmpty, DoneBB, BodyBB);\n\n  // Enter the loop body, making that address the current address.\n  llvm::BasicBlock *EntryBB = CGF.Builder.GetInsertBlock();\n  CGF.EmitBlock(BodyBB);\n\n  CharUnits ElementSize = CGF.getContext().getTypeSizeInChars(ElementTy);\n\n  llvm::PHINode *SrcElementPHI = nullptr;\n  Address SrcElementCurrent = Address::invalid();\n  if (DRD) {\n    SrcElementPHI = CGF.Builder.CreatePHI(SrcBegin->getType(), 2,\n                                          \"omp.arraycpy.srcElementPast\");\n    SrcElementPHI->addIncoming(SrcBegin, EntryBB);\n    SrcElementCurrent =\n        Address(SrcElementPHI,\n                SrcAddr.getAlignment().alignmentOfArrayElement(ElementSize));\n  }\n  llvm::PHINode *DestElementPHI = CGF.Builder.CreatePHI(\n      DestBegin->getType(), 2, \"omp.arraycpy.destElementPast\");\n  DestElementPHI->addIncoming(DestBegin, EntryBB);\n  Address DestElementCurrent =\n      Address(DestElementPHI,\n              DestAddr.getAlignment().alignmentOfArrayElement(ElementSize));\n\n  // Emit copy.\n  {\n    CodeGenFunction::RunCleanupsScope InitScope(CGF);\n    if (EmitDeclareReductionInit) {\n      emitInitWithReductionInitializer(CGF, DRD, Init, DestElementCurrent,\n                                       SrcElementCurrent, ElementTy);\n    } else\n      CGF.EmitAnyExprToMem(Init, DestElementCurrent, ElementTy.getQualifiers(),\n                           /*IsInitializer=*/false);\n  }\n\n  if (DRD) {\n    // Shift the address forward by one element.\n    llvm::Value *SrcElementNext = CGF.Builder.CreateConstGEP1_32(\n        SrcElementPHI, /*Idx0=*/1, \"omp.arraycpy.dest.element\");\n    SrcElementPHI->addIncoming(SrcElementNext, CGF.Builder.GetInsertBlock());\n  }\n\n  // Shift the address forward by one element.\n  llvm::Value *DestElementNext = CGF.Builder.CreateConstGEP1_32(\n      DestElementPHI, /*Idx0=*/1, \"omp.arraycpy.dest.element\");\n  // Check whether we've reached the end.\n  llvm::Value *Done =\n      CGF.Builder.CreateICmpEQ(DestElementNext, DestEnd, \"omp.arraycpy.done\");\n  CGF.Builder.CreateCondBr(Done, DoneBB, BodyBB);\n  DestElementPHI->addIncoming(DestElementNext, CGF.Builder.GetInsertBlock());\n\n  // Done.\n  CGF.EmitBlock(DoneBB, /*IsFinished=*/true);\n}\n\nLValue ReductionCodeGen::emitSharedLValue(CodeGenFunction &CGF, const Expr *E) {\n  return CGF.EmitOMPSharedLValue(E);\n}\n\nLValue ReductionCodeGen::emitSharedLValueUB(CodeGenFunction &CGF,\n                                            const Expr *E) {\n  if (const auto *OASE = dyn_cast<OMPArraySectionExpr>(E))\n    return CGF.EmitOMPArraySectionExpr(OASE, /*IsLowerBound=*/false);\n  return LValue();\n}\n\nvoid ReductionCodeGen::emitAggregateInitialization(\n    CodeGenFunction &CGF, unsigned N, Address PrivateAddr, LValue SharedLVal,\n    const OMPDeclareReductionDecl *DRD) {\n  // Emit VarDecl with copy init for arrays.\n  // Get the address of the original variable captured in current\n  // captured region.\n  const auto *PrivateVD =\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Private)->getDecl());\n  bool EmitDeclareReductionInit =\n      DRD && (DRD->getInitializer() || !PrivateVD->hasInit());\n  EmitOMPAggregateInit(CGF, PrivateAddr, PrivateVD->getType(),\n                       EmitDeclareReductionInit,\n                       EmitDeclareReductionInit ? ClausesData[N].ReductionOp\n                                                : PrivateVD->getInit(),\n                       DRD, SharedLVal.getAddress(CGF));\n}\n\nReductionCodeGen::ReductionCodeGen(ArrayRef<const Expr *> Shareds,\n                                   ArrayRef<const Expr *> Origs,\n                                   ArrayRef<const Expr *> Privates,\n                                   ArrayRef<const Expr *> ReductionOps) {\n  ClausesData.reserve(Shareds.size());\n  SharedAddresses.reserve(Shareds.size());\n  Sizes.reserve(Shareds.size());\n  BaseDecls.reserve(Shareds.size());\n  const auto *IOrig = Origs.begin();\n  const auto *IPriv = Privates.begin();\n  const auto *IRed = ReductionOps.begin();\n  for (const Expr *Ref : Shareds) {\n    ClausesData.emplace_back(Ref, *IOrig, *IPriv, *IRed);\n    std::advance(IOrig, 1);\n    std::advance(IPriv, 1);\n    std::advance(IRed, 1);\n  }\n}\n\nvoid ReductionCodeGen::emitSharedOrigLValue(CodeGenFunction &CGF, unsigned N) {\n  assert(SharedAddresses.size() == N && OrigAddresses.size() == N &&\n         \"Number of generated lvalues must be exactly N.\");\n  LValue First = emitSharedLValue(CGF, ClausesData[N].Shared);\n  LValue Second = emitSharedLValueUB(CGF, ClausesData[N].Shared);\n  SharedAddresses.emplace_back(First, Second);\n  if (ClausesData[N].Shared == ClausesData[N].Ref) {\n    OrigAddresses.emplace_back(First, Second);\n  } else {\n    LValue First = emitSharedLValue(CGF, ClausesData[N].Ref);\n    LValue Second = emitSharedLValueUB(CGF, ClausesData[N].Ref);\n    OrigAddresses.emplace_back(First, Second);\n  }\n}\n\nvoid ReductionCodeGen::emitAggregateType(CodeGenFunction &CGF, unsigned N) {\n  const auto *PrivateVD =\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Private)->getDecl());\n  QualType PrivateType = PrivateVD->getType();\n  bool AsArraySection = isa<OMPArraySectionExpr>(ClausesData[N].Ref);\n  if (!PrivateType->isVariablyModifiedType()) {\n    Sizes.emplace_back(\n        CGF.getTypeSize(OrigAddresses[N].first.getType().getNonReferenceType()),\n        nullptr);\n    return;\n  }\n  llvm::Value *Size;\n  llvm::Value *SizeInChars;\n  auto *ElemType =\n      cast<llvm::PointerType>(OrigAddresses[N].first.getPointer(CGF)->getType())\n          ->getElementType();\n  auto *ElemSizeOf = llvm::ConstantExpr::getSizeOf(ElemType);\n  if (AsArraySection) {\n    Size = CGF.Builder.CreatePtrDiff(OrigAddresses[N].second.getPointer(CGF),\n                                     OrigAddresses[N].first.getPointer(CGF));\n    Size = CGF.Builder.CreateNUWAdd(\n        Size, llvm::ConstantInt::get(Size->getType(), /*V=*/1));\n    SizeInChars = CGF.Builder.CreateNUWMul(Size, ElemSizeOf);\n  } else {\n    SizeInChars =\n        CGF.getTypeSize(OrigAddresses[N].first.getType().getNonReferenceType());\n    Size = CGF.Builder.CreateExactUDiv(SizeInChars, ElemSizeOf);\n  }\n  Sizes.emplace_back(SizeInChars, Size);\n  CodeGenFunction::OpaqueValueMapping OpaqueMap(\n      CGF,\n      cast<OpaqueValueExpr>(\n          CGF.getContext().getAsVariableArrayType(PrivateType)->getSizeExpr()),\n      RValue::get(Size));\n  CGF.EmitVariablyModifiedType(PrivateType);\n}\n\nvoid ReductionCodeGen::emitAggregateType(CodeGenFunction &CGF, unsigned N,\n                                         llvm::Value *Size) {\n  const auto *PrivateVD =\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Private)->getDecl());\n  QualType PrivateType = PrivateVD->getType();\n  if (!PrivateType->isVariablyModifiedType()) {\n    assert(!Size && !Sizes[N].second &&\n           \"Size should be nullptr for non-variably modified reduction \"\n           \"items.\");\n    return;\n  }\n  CodeGenFunction::OpaqueValueMapping OpaqueMap(\n      CGF,\n      cast<OpaqueValueExpr>(\n          CGF.getContext().getAsVariableArrayType(PrivateType)->getSizeExpr()),\n      RValue::get(Size));\n  CGF.EmitVariablyModifiedType(PrivateType);\n}\n\nvoid ReductionCodeGen::emitInitialization(\n    CodeGenFunction &CGF, unsigned N, Address PrivateAddr, LValue SharedLVal,\n    llvm::function_ref<bool(CodeGenFunction &)> DefaultInit) {\n  assert(SharedAddresses.size() > N && \"No variable was generated\");\n  const auto *PrivateVD =\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Private)->getDecl());\n  const OMPDeclareReductionDecl *DRD =\n      getReductionInit(ClausesData[N].ReductionOp);\n  QualType PrivateType = PrivateVD->getType();\n  PrivateAddr = CGF.Builder.CreateElementBitCast(\n      PrivateAddr, CGF.ConvertTypeForMem(PrivateType));\n  QualType SharedType = SharedAddresses[N].first.getType();\n  SharedLVal = CGF.MakeAddrLValue(\n      CGF.Builder.CreateElementBitCast(SharedLVal.getAddress(CGF),\n                                       CGF.ConvertTypeForMem(SharedType)),\n      SharedType, SharedAddresses[N].first.getBaseInfo(),\n      CGF.CGM.getTBAAInfoForSubobject(SharedAddresses[N].first, SharedType));\n  if (CGF.getContext().getAsArrayType(PrivateVD->getType())) {\n    if (DRD && DRD->getInitializer())\n      (void)DefaultInit(CGF);\n    emitAggregateInitialization(CGF, N, PrivateAddr, SharedLVal, DRD);\n  } else if (DRD && (DRD->getInitializer() || !PrivateVD->hasInit())) {\n    (void)DefaultInit(CGF);\n    emitInitWithReductionInitializer(CGF, DRD, ClausesData[N].ReductionOp,\n                                     PrivateAddr, SharedLVal.getAddress(CGF),\n                                     SharedLVal.getType());\n  } else if (!DefaultInit(CGF) && PrivateVD->hasInit() &&\n             !CGF.isTrivialInitializer(PrivateVD->getInit())) {\n    CGF.EmitAnyExprToMem(PrivateVD->getInit(), PrivateAddr,\n                         PrivateVD->getType().getQualifiers(),\n                         /*IsInitializer=*/false);\n  }\n}\n\nbool ReductionCodeGen::needCleanups(unsigned N) {\n  const auto *PrivateVD =\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Private)->getDecl());\n  QualType PrivateType = PrivateVD->getType();\n  QualType::DestructionKind DTorKind = PrivateType.isDestructedType();\n  return DTorKind != QualType::DK_none;\n}\n\nvoid ReductionCodeGen::emitCleanups(CodeGenFunction &CGF, unsigned N,\n                                    Address PrivateAddr) {\n  const auto *PrivateVD =\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Private)->getDecl());\n  QualType PrivateType = PrivateVD->getType();\n  QualType::DestructionKind DTorKind = PrivateType.isDestructedType();\n  if (needCleanups(N)) {\n    PrivateAddr = CGF.Builder.CreateElementBitCast(\n        PrivateAddr, CGF.ConvertTypeForMem(PrivateType));\n    CGF.pushDestroy(DTorKind, PrivateAddr, PrivateType);\n  }\n}\n\nstatic LValue loadToBegin(CodeGenFunction &CGF, QualType BaseTy, QualType ElTy,\n                          LValue BaseLV) {\n  BaseTy = BaseTy.getNonReferenceType();\n  while ((BaseTy->isPointerType() || BaseTy->isReferenceType()) &&\n         !CGF.getContext().hasSameType(BaseTy, ElTy)) {\n    if (const auto *PtrTy = BaseTy->getAs<PointerType>()) {\n      BaseLV = CGF.EmitLoadOfPointerLValue(BaseLV.getAddress(CGF), PtrTy);\n    } else {\n      LValue RefLVal = CGF.MakeAddrLValue(BaseLV.getAddress(CGF), BaseTy);\n      BaseLV = CGF.EmitLoadOfReferenceLValue(RefLVal);\n    }\n    BaseTy = BaseTy->getPointeeType();\n  }\n  return CGF.MakeAddrLValue(\n      CGF.Builder.CreateElementBitCast(BaseLV.getAddress(CGF),\n                                       CGF.ConvertTypeForMem(ElTy)),\n      BaseLV.getType(), BaseLV.getBaseInfo(),\n      CGF.CGM.getTBAAInfoForSubobject(BaseLV, BaseLV.getType()));\n}\n\nstatic Address castToBase(CodeGenFunction &CGF, QualType BaseTy, QualType ElTy,\n                          llvm::Type *BaseLVType, CharUnits BaseLVAlignment,\n                          llvm::Value *Addr) {\n  Address Tmp = Address::invalid();\n  Address TopTmp = Address::invalid();\n  Address MostTopTmp = Address::invalid();\n  BaseTy = BaseTy.getNonReferenceType();\n  while ((BaseTy->isPointerType() || BaseTy->isReferenceType()) &&\n         !CGF.getContext().hasSameType(BaseTy, ElTy)) {\n    Tmp = CGF.CreateMemTemp(BaseTy);\n    if (TopTmp.isValid())\n      CGF.Builder.CreateStore(Tmp.getPointer(), TopTmp);\n    else\n      MostTopTmp = Tmp;\n    TopTmp = Tmp;\n    BaseTy = BaseTy->getPointeeType();\n  }\n  llvm::Type *Ty = BaseLVType;\n  if (Tmp.isValid())\n    Ty = Tmp.getElementType();\n  Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(Addr, Ty);\n  if (Tmp.isValid()) {\n    CGF.Builder.CreateStore(Addr, Tmp);\n    return MostTopTmp;\n  }\n  return Address(Addr, BaseLVAlignment);\n}\n\nstatic const VarDecl *getBaseDecl(const Expr *Ref, const DeclRefExpr *&DE) {\n  const VarDecl *OrigVD = nullptr;\n  if (const auto *OASE = dyn_cast<OMPArraySectionExpr>(Ref)) {\n    const Expr *Base = OASE->getBase()->IgnoreParenImpCasts();\n    while (const auto *TempOASE = dyn_cast<OMPArraySectionExpr>(Base))\n      Base = TempOASE->getBase()->IgnoreParenImpCasts();\n    while (const auto *TempASE = dyn_cast<ArraySubscriptExpr>(Base))\n      Base = TempASE->getBase()->IgnoreParenImpCasts();\n    DE = cast<DeclRefExpr>(Base);\n    OrigVD = cast<VarDecl>(DE->getDecl());\n  } else if (const auto *ASE = dyn_cast<ArraySubscriptExpr>(Ref)) {\n    const Expr *Base = ASE->getBase()->IgnoreParenImpCasts();\n    while (const auto *TempASE = dyn_cast<ArraySubscriptExpr>(Base))\n      Base = TempASE->getBase()->IgnoreParenImpCasts();\n    DE = cast<DeclRefExpr>(Base);\n    OrigVD = cast<VarDecl>(DE->getDecl());\n  }\n  return OrigVD;\n}\n\nAddress ReductionCodeGen::adjustPrivateAddress(CodeGenFunction &CGF, unsigned N,\n                                               Address PrivateAddr) {\n  const DeclRefExpr *DE;\n  if (const VarDecl *OrigVD = ::getBaseDecl(ClausesData[N].Ref, DE)) {\n    BaseDecls.emplace_back(OrigVD);\n    LValue OriginalBaseLValue = CGF.EmitLValue(DE);\n    LValue BaseLValue =\n        loadToBegin(CGF, OrigVD->getType(), SharedAddresses[N].first.getType(),\n                    OriginalBaseLValue);\n    llvm::Value *Adjustment = CGF.Builder.CreatePtrDiff(\n        BaseLValue.getPointer(CGF), SharedAddresses[N].first.getPointer(CGF));\n    llvm::Value *PrivatePointer =\n        CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n            PrivateAddr.getPointer(),\n            SharedAddresses[N].first.getAddress(CGF).getType());\n    llvm::Value *Ptr = CGF.Builder.CreateGEP(PrivatePointer, Adjustment);\n    return castToBase(CGF, OrigVD->getType(),\n                      SharedAddresses[N].first.getType(),\n                      OriginalBaseLValue.getAddress(CGF).getType(),\n                      OriginalBaseLValue.getAlignment(), Ptr);\n  }\n  BaseDecls.emplace_back(\n      cast<VarDecl>(cast<DeclRefExpr>(ClausesData[N].Ref)->getDecl()));\n  return PrivateAddr;\n}\n\nbool ReductionCodeGen::usesReductionInitializer(unsigned N) const {\n  const OMPDeclareReductionDecl *DRD =\n      getReductionInit(ClausesData[N].ReductionOp);\n  return DRD && DRD->getInitializer();\n}\n\nLValue CGOpenMPRegionInfo::getThreadIDVariableLValue(CodeGenFunction &CGF) {\n  return CGF.EmitLoadOfPointerLValue(\n      CGF.GetAddrOfLocalVar(getThreadIDVariable()),\n      getThreadIDVariable()->getType()->castAs<PointerType>());\n}\n\nvoid CGOpenMPRegionInfo::EmitBody(CodeGenFunction &CGF, const Stmt * /*S*/) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // 1.2.2 OpenMP Language Terminology\n  // Structured block - An executable statement with a single entry at the\n  // top and a single exit at the bottom.\n  // The point of exit cannot be a branch out of the structured block.\n  // longjmp() and throw() must not violate the entry/exit criteria.\n  CGF.EHStack.pushTerminate();\n  CodeGen(CGF);\n  CGF.EHStack.popTerminate();\n}\n\nLValue CGOpenMPTaskOutlinedRegionInfo::getThreadIDVariableLValue(\n    CodeGenFunction &CGF) {\n  return CGF.MakeAddrLValue(CGF.GetAddrOfLocalVar(getThreadIDVariable()),\n                            getThreadIDVariable()->getType(),\n                            AlignmentSource::Decl);\n}\n\nstatic FieldDecl *addFieldToRecordDecl(ASTContext &C, DeclContext *DC,\n                                       QualType FieldTy) {\n  auto *Field = FieldDecl::Create(\n      C, DC, SourceLocation(), SourceLocation(), /*Id=*/nullptr, FieldTy,\n      C.getTrivialTypeSourceInfo(FieldTy, SourceLocation()),\n      /*BW=*/nullptr, /*Mutable=*/false, /*InitStyle=*/ICIS_NoInit);\n  Field->setAccess(AS_public);\n  DC->addDecl(Field);\n  return Field;\n}\n\nCGOpenMPRuntime::CGOpenMPRuntime(CodeGenModule &CGM, StringRef FirstSeparator,\n                                 StringRef Separator)\n    : CGM(CGM), FirstSeparator(FirstSeparator), Separator(Separator),\n      OMPBuilder(CGM.getModule()), OffloadEntriesInfoManager(CGM) {\n  KmpCriticalNameTy = llvm::ArrayType::get(CGM.Int32Ty, /*NumElements*/ 8);\n\n  // Initialize Types used in OpenMPIRBuilder from OMPKinds.def\n  OMPBuilder.initialize();\n  loadOffloadInfoMetadata();\n}\n\nvoid CGOpenMPRuntime::clear() {\n  InternalVars.clear();\n  // Clean non-target variable declarations possibly used only in debug info.\n  for (const auto &Data : EmittedNonTargetVariables) {\n    if (!Data.getValue().pointsToAliveValue())\n      continue;\n    auto *GV = dyn_cast<llvm::GlobalVariable>(Data.getValue());\n    if (!GV)\n      continue;\n    if (!GV->isDeclaration() || GV->getNumUses() > 0)\n      continue;\n    GV->eraseFromParent();\n  }\n}\n\nstd::string CGOpenMPRuntime::getName(ArrayRef<StringRef> Parts) const {\n  SmallString<128> Buffer;\n  llvm::raw_svector_ostream OS(Buffer);\n  StringRef Sep = FirstSeparator;\n  for (StringRef Part : Parts) {\n    OS << Sep << Part;\n    Sep = Separator;\n  }\n  return std::string(OS.str());\n}\n\nstatic llvm::Function *\nemitCombinerOrInitializer(CodeGenModule &CGM, QualType Ty,\n                          const Expr *CombinerInitializer, const VarDecl *In,\n                          const VarDecl *Out, bool IsCombiner) {\n  // void .omp_combiner.(Ty *in, Ty *out);\n  ASTContext &C = CGM.getContext();\n  QualType PtrTy = C.getPointerType(Ty).withRestrict();\n  FunctionArgList Args;\n  ImplicitParamDecl OmpOutParm(C, /*DC=*/nullptr, Out->getLocation(),\n                               /*Id=*/nullptr, PtrTy, ImplicitParamDecl::Other);\n  ImplicitParamDecl OmpInParm(C, /*DC=*/nullptr, In->getLocation(),\n                              /*Id=*/nullptr, PtrTy, ImplicitParamDecl::Other);\n  Args.push_back(&OmpOutParm);\n  Args.push_back(&OmpInParm);\n  const CGFunctionInfo &FnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *FnTy = CGM.getTypes().GetFunctionType(FnInfo);\n  std::string Name = CGM.getOpenMPRuntime().getName(\n      {IsCombiner ? \"omp_combiner\" : \"omp_initializer\", \"\"});\n  auto *Fn = llvm::Function::Create(FnTy, llvm::GlobalValue::InternalLinkage,\n                                    Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, FnInfo);\n  if (CGM.getLangOpts().Optimize) {\n    Fn->removeFnAttr(llvm::Attribute::NoInline);\n    Fn->removeFnAttr(llvm::Attribute::OptimizeNone);\n    Fn->addFnAttr(llvm::Attribute::AlwaysInline);\n  }\n  CodeGenFunction CGF(CGM);\n  // Map \"T omp_in;\" variable to \"*omp_in_parm\" value in all expressions.\n  // Map \"T omp_out;\" variable to \"*omp_out_parm\" value in all expressions.\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, FnInfo, Args, In->getLocation(),\n                    Out->getLocation());\n  CodeGenFunction::OMPPrivateScope Scope(CGF);\n  Address AddrIn = CGF.GetAddrOfLocalVar(&OmpInParm);\n  Scope.addPrivate(In, [&CGF, AddrIn, PtrTy]() {\n    return CGF.EmitLoadOfPointerLValue(AddrIn, PtrTy->castAs<PointerType>())\n        .getAddress(CGF);\n  });\n  Address AddrOut = CGF.GetAddrOfLocalVar(&OmpOutParm);\n  Scope.addPrivate(Out, [&CGF, AddrOut, PtrTy]() {\n    return CGF.EmitLoadOfPointerLValue(AddrOut, PtrTy->castAs<PointerType>())\n        .getAddress(CGF);\n  });\n  (void)Scope.Privatize();\n  if (!IsCombiner && Out->hasInit() &&\n      !CGF.isTrivialInitializer(Out->getInit())) {\n    CGF.EmitAnyExprToMem(Out->getInit(), CGF.GetAddrOfLocalVar(Out),\n                         Out->getType().getQualifiers(),\n                         /*IsInitializer=*/true);\n  }\n  if (CombinerInitializer)\n    CGF.EmitIgnoredExpr(CombinerInitializer);\n  Scope.ForceCleanup();\n  CGF.FinishFunction();\n  return Fn;\n}\n\nvoid CGOpenMPRuntime::emitUserDefinedReduction(\n    CodeGenFunction *CGF, const OMPDeclareReductionDecl *D) {\n  if (UDRMap.count(D) > 0)\n    return;\n  llvm::Function *Combiner = emitCombinerOrInitializer(\n      CGM, D->getType(), D->getCombiner(),\n      cast<VarDecl>(cast<DeclRefExpr>(D->getCombinerIn())->getDecl()),\n      cast<VarDecl>(cast<DeclRefExpr>(D->getCombinerOut())->getDecl()),\n      /*IsCombiner=*/true);\n  llvm::Function *Initializer = nullptr;\n  if (const Expr *Init = D->getInitializer()) {\n    Initializer = emitCombinerOrInitializer(\n        CGM, D->getType(),\n        D->getInitializerKind() == OMPDeclareReductionDecl::CallInit ? Init\n                                                                     : nullptr,\n        cast<VarDecl>(cast<DeclRefExpr>(D->getInitOrig())->getDecl()),\n        cast<VarDecl>(cast<DeclRefExpr>(D->getInitPriv())->getDecl()),\n        /*IsCombiner=*/false);\n  }\n  UDRMap.try_emplace(D, Combiner, Initializer);\n  if (CGF) {\n    auto &Decls = FunctionUDRMap.FindAndConstruct(CGF->CurFn);\n    Decls.second.push_back(D);\n  }\n}\n\nstd::pair<llvm::Function *, llvm::Function *>\nCGOpenMPRuntime::getUserDefinedReduction(const OMPDeclareReductionDecl *D) {\n  auto I = UDRMap.find(D);\n  if (I != UDRMap.end())\n    return I->second;\n  emitUserDefinedReduction(/*CGF=*/nullptr, D);\n  return UDRMap.lookup(D);\n}\n\nnamespace {\n// Temporary RAII solution to perform a push/pop stack event on the OpenMP IR\n// Builder if one is present.\nstruct PushAndPopStackRAII {\n  PushAndPopStackRAII(llvm::OpenMPIRBuilder *OMPBuilder, CodeGenFunction &CGF,\n                      bool HasCancel)\n      : OMPBuilder(OMPBuilder) {\n    if (!OMPBuilder)\n      return;\n\n    // The following callback is the crucial part of clangs cleanup process.\n    //\n    // NOTE:\n    // Once the OpenMPIRBuilder is used to create parallel regions (and\n    // similar), the cancellation destination (Dest below) is determined via\n    // IP. That means if we have variables to finalize we split the block at IP,\n    // use the new block (=BB) as destination to build a JumpDest (via\n    // getJumpDestInCurrentScope(BB)) which then is fed to\n    // EmitBranchThroughCleanup. Furthermore, there will not be the need\n    // to push & pop an FinalizationInfo object.\n    // The FiniCB will still be needed but at the point where the\n    // OpenMPIRBuilder is asked to construct a parallel (or similar) construct.\n    auto FiniCB = [&CGF](llvm::OpenMPIRBuilder::InsertPointTy IP) {\n      assert(IP.getBlock()->end() == IP.getPoint() &&\n             \"Clang CG should cause non-terminated block!\");\n      CGBuilderTy::InsertPointGuard IPG(CGF.Builder);\n      CGF.Builder.restoreIP(IP);\n      CodeGenFunction::JumpDest Dest =\n          CGF.getOMPCancelDestination(OMPD_parallel);\n      CGF.EmitBranchThroughCleanup(Dest);\n    };\n\n    // TODO: Remove this once we emit parallel regions through the\n    //       OpenMPIRBuilder as it can do this setup internally.\n    llvm::OpenMPIRBuilder::FinalizationInfo FI(\n        {FiniCB, OMPD_parallel, HasCancel});\n    OMPBuilder->pushFinalizationCB(std::move(FI));\n  }\n  ~PushAndPopStackRAII() {\n    if (OMPBuilder)\n      OMPBuilder->popFinalizationCB();\n  }\n  llvm::OpenMPIRBuilder *OMPBuilder;\n};\n} // namespace\n\nstatic llvm::Function *emitParallelOrTeamsOutlinedFunction(\n    CodeGenModule &CGM, const OMPExecutableDirective &D, const CapturedStmt *CS,\n    const VarDecl *ThreadIDVar, OpenMPDirectiveKind InnermostKind,\n    const StringRef OutlinedHelperName, const RegionCodeGenTy &CodeGen) {\n  assert(ThreadIDVar->getType()->isPointerType() &&\n         \"thread id variable must be of type kmp_int32 *\");\n  CodeGenFunction CGF(CGM, true);\n  bool HasCancel = false;\n  if (const auto *OPD = dyn_cast<OMPParallelDirective>(&D))\n    HasCancel = OPD->hasCancel();\n  else if (const auto *OPD = dyn_cast<OMPTargetParallelDirective>(&D))\n    HasCancel = OPD->hasCancel();\n  else if (const auto *OPSD = dyn_cast<OMPParallelSectionsDirective>(&D))\n    HasCancel = OPSD->hasCancel();\n  else if (const auto *OPFD = dyn_cast<OMPParallelForDirective>(&D))\n    HasCancel = OPFD->hasCancel();\n  else if (const auto *OPFD = dyn_cast<OMPTargetParallelForDirective>(&D))\n    HasCancel = OPFD->hasCancel();\n  else if (const auto *OPFD = dyn_cast<OMPDistributeParallelForDirective>(&D))\n    HasCancel = OPFD->hasCancel();\n  else if (const auto *OPFD =\n               dyn_cast<OMPTeamsDistributeParallelForDirective>(&D))\n    HasCancel = OPFD->hasCancel();\n  else if (const auto *OPFD =\n               dyn_cast<OMPTargetTeamsDistributeParallelForDirective>(&D))\n    HasCancel = OPFD->hasCancel();\n\n  // TODO: Temporarily inform the OpenMPIRBuilder, if any, about the new\n  //       parallel region to make cancellation barriers work properly.\n  llvm::OpenMPIRBuilder &OMPBuilder = CGM.getOpenMPRuntime().getOMPBuilder();\n  PushAndPopStackRAII PSR(&OMPBuilder, CGF, HasCancel);\n  CGOpenMPOutlinedRegionInfo CGInfo(*CS, ThreadIDVar, CodeGen, InnermostKind,\n                                    HasCancel, OutlinedHelperName);\n  CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n  return CGF.GenerateOpenMPCapturedStmtFunction(*CS, D.getBeginLoc());\n}\n\nllvm::Function *CGOpenMPRuntime::emitParallelOutlinedFunction(\n    const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n    OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen) {\n  const CapturedStmt *CS = D.getCapturedStmt(OMPD_parallel);\n  return emitParallelOrTeamsOutlinedFunction(\n      CGM, D, CS, ThreadIDVar, InnermostKind, getOutlinedHelperName(), CodeGen);\n}\n\nllvm::Function *CGOpenMPRuntime::emitTeamsOutlinedFunction(\n    const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n    OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen) {\n  const CapturedStmt *CS = D.getCapturedStmt(OMPD_teams);\n  return emitParallelOrTeamsOutlinedFunction(\n      CGM, D, CS, ThreadIDVar, InnermostKind, getOutlinedHelperName(), CodeGen);\n}\n\nllvm::Function *CGOpenMPRuntime::emitTaskOutlinedFunction(\n    const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n    const VarDecl *PartIDVar, const VarDecl *TaskTVar,\n    OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen,\n    bool Tied, unsigned &NumberOfParts) {\n  auto &&UntiedCodeGen = [this, &D, TaskTVar](CodeGenFunction &CGF,\n                                              PrePostActionTy &) {\n    llvm::Value *ThreadID = getThreadID(CGF, D.getBeginLoc());\n    llvm::Value *UpLoc = emitUpdateLocation(CGF, D.getBeginLoc());\n    llvm::Value *TaskArgs[] = {\n        UpLoc, ThreadID,\n        CGF.EmitLoadOfPointerLValue(CGF.GetAddrOfLocalVar(TaskTVar),\n                                    TaskTVar->getType()->castAs<PointerType>())\n            .getPointer(CGF)};\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_omp_task),\n                        TaskArgs);\n  };\n  CGOpenMPTaskOutlinedRegionInfo::UntiedTaskActionTy Action(Tied, PartIDVar,\n                                                            UntiedCodeGen);\n  CodeGen.setAction(Action);\n  assert(!ThreadIDVar->getType()->isPointerType() &&\n         \"thread id variable must be of type kmp_int32 for tasks\");\n  const OpenMPDirectiveKind Region =\n      isOpenMPTaskLoopDirective(D.getDirectiveKind()) ? OMPD_taskloop\n                                                      : OMPD_task;\n  const CapturedStmt *CS = D.getCapturedStmt(Region);\n  bool HasCancel = false;\n  if (const auto *TD = dyn_cast<OMPTaskDirective>(&D))\n    HasCancel = TD->hasCancel();\n  else if (const auto *TD = dyn_cast<OMPTaskLoopDirective>(&D))\n    HasCancel = TD->hasCancel();\n  else if (const auto *TD = dyn_cast<OMPMasterTaskLoopDirective>(&D))\n    HasCancel = TD->hasCancel();\n  else if (const auto *TD = dyn_cast<OMPParallelMasterTaskLoopDirective>(&D))\n    HasCancel = TD->hasCancel();\n\n  CodeGenFunction CGF(CGM, true);\n  CGOpenMPTaskOutlinedRegionInfo CGInfo(*CS, ThreadIDVar, CodeGen,\n                                        InnermostKind, HasCancel, Action);\n  CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n  llvm::Function *Res = CGF.GenerateCapturedStmtFunction(*CS);\n  if (!Tied)\n    NumberOfParts = Action.getNumberOfParts();\n  return Res;\n}\n\nstatic void buildStructValue(ConstantStructBuilder &Fields, CodeGenModule &CGM,\n                             const RecordDecl *RD, const CGRecordLayout &RL,\n                             ArrayRef<llvm::Constant *> Data) {\n  llvm::StructType *StructTy = RL.getLLVMType();\n  unsigned PrevIdx = 0;\n  ConstantInitBuilder CIBuilder(CGM);\n  auto DI = Data.begin();\n  for (const FieldDecl *FD : RD->fields()) {\n    unsigned Idx = RL.getLLVMFieldNo(FD);\n    // Fill the alignment.\n    for (unsigned I = PrevIdx; I < Idx; ++I)\n      Fields.add(llvm::Constant::getNullValue(StructTy->getElementType(I)));\n    PrevIdx = Idx + 1;\n    Fields.add(*DI);\n    ++DI;\n  }\n}\n\ntemplate <class... As>\nstatic llvm::GlobalVariable *\ncreateGlobalStruct(CodeGenModule &CGM, QualType Ty, bool IsConstant,\n                   ArrayRef<llvm::Constant *> Data, const Twine &Name,\n                   As &&... Args) {\n  const auto *RD = cast<RecordDecl>(Ty->getAsTagDecl());\n  const CGRecordLayout &RL = CGM.getTypes().getCGRecordLayout(RD);\n  ConstantInitBuilder CIBuilder(CGM);\n  ConstantStructBuilder Fields = CIBuilder.beginStruct(RL.getLLVMType());\n  buildStructValue(Fields, CGM, RD, RL, Data);\n  return Fields.finishAndCreateGlobal(\n      Name, CGM.getContext().getAlignOfGlobalVarInChars(Ty), IsConstant,\n      std::forward<As>(Args)...);\n}\n\ntemplate <typename T>\nstatic void\ncreateConstantGlobalStructAndAddToParent(CodeGenModule &CGM, QualType Ty,\n                                         ArrayRef<llvm::Constant *> Data,\n                                         T &Parent) {\n  const auto *RD = cast<RecordDecl>(Ty->getAsTagDecl());\n  const CGRecordLayout &RL = CGM.getTypes().getCGRecordLayout(RD);\n  ConstantStructBuilder Fields = Parent.beginStruct(RL.getLLVMType());\n  buildStructValue(Fields, CGM, RD, RL, Data);\n  Fields.finishAndAddTo(Parent);\n}\n\nvoid CGOpenMPRuntime::setLocThreadIdInsertPt(CodeGenFunction &CGF,\n                                             bool AtCurrentPoint) {\n  auto &Elem = OpenMPLocThreadIDMap.FindAndConstruct(CGF.CurFn);\n  assert(!Elem.second.ServiceInsertPt && \"Insert point is set already.\");\n\n  llvm::Value *Undef = llvm::UndefValue::get(CGF.Int32Ty);\n  if (AtCurrentPoint) {\n    Elem.second.ServiceInsertPt = new llvm::BitCastInst(\n        Undef, CGF.Int32Ty, \"svcpt\", CGF.Builder.GetInsertBlock());\n  } else {\n    Elem.second.ServiceInsertPt =\n        new llvm::BitCastInst(Undef, CGF.Int32Ty, \"svcpt\");\n    Elem.second.ServiceInsertPt->insertAfter(CGF.AllocaInsertPt);\n  }\n}\n\nvoid CGOpenMPRuntime::clearLocThreadIdInsertPt(CodeGenFunction &CGF) {\n  auto &Elem = OpenMPLocThreadIDMap.FindAndConstruct(CGF.CurFn);\n  if (Elem.second.ServiceInsertPt) {\n    llvm::Instruction *Ptr = Elem.second.ServiceInsertPt;\n    Elem.second.ServiceInsertPt = nullptr;\n    Ptr->eraseFromParent();\n  }\n}\n\nstatic StringRef getIdentStringFromSourceLocation(CodeGenFunction &CGF,\n                                                  SourceLocation Loc,\n                                                  SmallString<128> &Buffer) {\n  llvm::raw_svector_ostream OS(Buffer);\n  // Build debug location\n  PresumedLoc PLoc = CGF.getContext().getSourceManager().getPresumedLoc(Loc);\n  OS << \";\" << PLoc.getFilename() << \";\";\n  if (const auto *FD = dyn_cast_or_null<FunctionDecl>(CGF.CurFuncDecl))\n    OS << FD->getQualifiedNameAsString();\n  OS << \";\" << PLoc.getLine() << \";\" << PLoc.getColumn() << \";;\";\n  return OS.str();\n}\n\nllvm::Value *CGOpenMPRuntime::emitUpdateLocation(CodeGenFunction &CGF,\n                                                 SourceLocation Loc,\n                                                 unsigned Flags) {\n  llvm::Constant *SrcLocStr;\n  if (CGM.getCodeGenOpts().getDebugInfo() == codegenoptions::NoDebugInfo ||\n      Loc.isInvalid()) {\n    SrcLocStr = OMPBuilder.getOrCreateDefaultSrcLocStr();\n  } else {\n    std::string FunctionName = \"\";\n    if (const auto *FD = dyn_cast_or_null<FunctionDecl>(CGF.CurFuncDecl))\n      FunctionName = FD->getQualifiedNameAsString();\n    PresumedLoc PLoc = CGF.getContext().getSourceManager().getPresumedLoc(Loc);\n    const char *FileName = PLoc.getFilename();\n    unsigned Line = PLoc.getLine();\n    unsigned Column = PLoc.getColumn();\n    SrcLocStr = OMPBuilder.getOrCreateSrcLocStr(FunctionName.c_str(), FileName,\n                                                Line, Column);\n  }\n  unsigned Reserved2Flags = getDefaultLocationReserved2Flags();\n  return OMPBuilder.getOrCreateIdent(SrcLocStr, llvm::omp::IdentFlag(Flags),\n                                     Reserved2Flags);\n}\n\nllvm::Value *CGOpenMPRuntime::getThreadID(CodeGenFunction &CGF,\n                                          SourceLocation Loc) {\n  assert(CGF.CurFn && \"No function in current CodeGenFunction.\");\n  // If the OpenMPIRBuilder is used we need to use it for all thread id calls as\n  // the clang invariants used below might be broken.\n  if (CGM.getLangOpts().OpenMPIRBuilder) {\n    SmallString<128> Buffer;\n    OMPBuilder.updateToLocation(CGF.Builder.saveIP());\n    auto *SrcLocStr = OMPBuilder.getOrCreateSrcLocStr(\n        getIdentStringFromSourceLocation(CGF, Loc, Buffer));\n    return OMPBuilder.getOrCreateThreadID(\n        OMPBuilder.getOrCreateIdent(SrcLocStr));\n  }\n\n  llvm::Value *ThreadID = nullptr;\n  // Check whether we've already cached a load of the thread id in this\n  // function.\n  auto I = OpenMPLocThreadIDMap.find(CGF.CurFn);\n  if (I != OpenMPLocThreadIDMap.end()) {\n    ThreadID = I->second.ThreadID;\n    if (ThreadID != nullptr)\n      return ThreadID;\n  }\n  // If exceptions are enabled, do not use parameter to avoid possible crash.\n  if (auto *OMPRegionInfo =\n          dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo)) {\n    if (OMPRegionInfo->getThreadIDVariable()) {\n      // Check if this an outlined function with thread id passed as argument.\n      LValue LVal = OMPRegionInfo->getThreadIDVariableLValue(CGF);\n      llvm::BasicBlock *TopBlock = CGF.AllocaInsertPt->getParent();\n      if (!CGF.EHStack.requiresLandingPad() || !CGF.getLangOpts().Exceptions ||\n          !CGF.getLangOpts().CXXExceptions ||\n          CGF.Builder.GetInsertBlock() == TopBlock ||\n          !isa<llvm::Instruction>(LVal.getPointer(CGF)) ||\n          cast<llvm::Instruction>(LVal.getPointer(CGF))->getParent() ==\n              TopBlock ||\n          cast<llvm::Instruction>(LVal.getPointer(CGF))->getParent() ==\n              CGF.Builder.GetInsertBlock()) {\n        ThreadID = CGF.EmitLoadOfScalar(LVal, Loc);\n        // If value loaded in entry block, cache it and use it everywhere in\n        // function.\n        if (CGF.Builder.GetInsertBlock() == TopBlock) {\n          auto &Elem = OpenMPLocThreadIDMap.FindAndConstruct(CGF.CurFn);\n          Elem.second.ThreadID = ThreadID;\n        }\n        return ThreadID;\n      }\n    }\n  }\n\n  // This is not an outlined function region - need to call __kmpc_int32\n  // kmpc_global_thread_num(ident_t *loc).\n  // Generate thread id value and cache this value for use across the\n  // function.\n  auto &Elem = OpenMPLocThreadIDMap.FindAndConstruct(CGF.CurFn);\n  if (!Elem.second.ServiceInsertPt)\n    setLocThreadIdInsertPt(CGF);\n  CGBuilderTy::InsertPointGuard IPG(CGF.Builder);\n  CGF.Builder.SetInsertPoint(Elem.second.ServiceInsertPt);\n  llvm::CallInst *Call = CGF.Builder.CreateCall(\n      OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                            OMPRTL___kmpc_global_thread_num),\n      emitUpdateLocation(CGF, Loc));\n  Call->setCallingConv(CGF.getRuntimeCC());\n  Elem.second.ThreadID = Call;\n  return Call;\n}\n\nvoid CGOpenMPRuntime::functionFinished(CodeGenFunction &CGF) {\n  assert(CGF.CurFn && \"No function in current CodeGenFunction.\");\n  if (OpenMPLocThreadIDMap.count(CGF.CurFn)) {\n    clearLocThreadIdInsertPt(CGF);\n    OpenMPLocThreadIDMap.erase(CGF.CurFn);\n  }\n  if (FunctionUDRMap.count(CGF.CurFn) > 0) {\n    for(const auto *D : FunctionUDRMap[CGF.CurFn])\n      UDRMap.erase(D);\n    FunctionUDRMap.erase(CGF.CurFn);\n  }\n  auto I = FunctionUDMMap.find(CGF.CurFn);\n  if (I != FunctionUDMMap.end()) {\n    for(const auto *D : I->second)\n      UDMMap.erase(D);\n    FunctionUDMMap.erase(I);\n  }\n  LastprivateConditionalToTypes.erase(CGF.CurFn);\n  FunctionToUntiedTaskStackMap.erase(CGF.CurFn);\n}\n\nllvm::Type *CGOpenMPRuntime::getIdentTyPointerTy() {\n  return OMPBuilder.IdentPtr;\n}\n\nllvm::Type *CGOpenMPRuntime::getKmpc_MicroPointerTy() {\n  if (!Kmpc_MicroTy) {\n    // Build void (*kmpc_micro)(kmp_int32 *global_tid, kmp_int32 *bound_tid,...)\n    llvm::Type *MicroParams[] = {llvm::PointerType::getUnqual(CGM.Int32Ty),\n                                 llvm::PointerType::getUnqual(CGM.Int32Ty)};\n    Kmpc_MicroTy = llvm::FunctionType::get(CGM.VoidTy, MicroParams, true);\n  }\n  return llvm::PointerType::getUnqual(Kmpc_MicroTy);\n}\n\nllvm::FunctionCallee\nCGOpenMPRuntime::createForStaticInitFunction(unsigned IVSize, bool IVSigned) {\n  assert((IVSize == 32 || IVSize == 64) &&\n         \"IV size is not compatible with the omp runtime\");\n  StringRef Name = IVSize == 32 ? (IVSigned ? \"__kmpc_for_static_init_4\"\n                                            : \"__kmpc_for_static_init_4u\")\n                                : (IVSigned ? \"__kmpc_for_static_init_8\"\n                                            : \"__kmpc_for_static_init_8u\");\n  llvm::Type *ITy = IVSize == 32 ? CGM.Int32Ty : CGM.Int64Ty;\n  auto *PtrTy = llvm::PointerType::getUnqual(ITy);\n  llvm::Type *TypeParams[] = {\n    getIdentTyPointerTy(),                     // loc\n    CGM.Int32Ty,                               // tid\n    CGM.Int32Ty,                               // schedtype\n    llvm::PointerType::getUnqual(CGM.Int32Ty), // p_lastiter\n    PtrTy,                                     // p_lower\n    PtrTy,                                     // p_upper\n    PtrTy,                                     // p_stride\n    ITy,                                       // incr\n    ITy                                        // chunk\n  };\n  auto *FnTy =\n      llvm::FunctionType::get(CGM.VoidTy, TypeParams, /*isVarArg*/ false);\n  return CGM.CreateRuntimeFunction(FnTy, Name);\n}\n\nllvm::FunctionCallee\nCGOpenMPRuntime::createDispatchInitFunction(unsigned IVSize, bool IVSigned) {\n  assert((IVSize == 32 || IVSize == 64) &&\n         \"IV size is not compatible with the omp runtime\");\n  StringRef Name =\n      IVSize == 32\n          ? (IVSigned ? \"__kmpc_dispatch_init_4\" : \"__kmpc_dispatch_init_4u\")\n          : (IVSigned ? \"__kmpc_dispatch_init_8\" : \"__kmpc_dispatch_init_8u\");\n  llvm::Type *ITy = IVSize == 32 ? CGM.Int32Ty : CGM.Int64Ty;\n  llvm::Type *TypeParams[] = { getIdentTyPointerTy(), // loc\n                               CGM.Int32Ty,           // tid\n                               CGM.Int32Ty,           // schedtype\n                               ITy,                   // lower\n                               ITy,                   // upper\n                               ITy,                   // stride\n                               ITy                    // chunk\n  };\n  auto *FnTy =\n      llvm::FunctionType::get(CGM.VoidTy, TypeParams, /*isVarArg*/ false);\n  return CGM.CreateRuntimeFunction(FnTy, Name);\n}\n\nllvm::FunctionCallee\nCGOpenMPRuntime::createDispatchFiniFunction(unsigned IVSize, bool IVSigned) {\n  assert((IVSize == 32 || IVSize == 64) &&\n         \"IV size is not compatible with the omp runtime\");\n  StringRef Name =\n      IVSize == 32\n          ? (IVSigned ? \"__kmpc_dispatch_fini_4\" : \"__kmpc_dispatch_fini_4u\")\n          : (IVSigned ? \"__kmpc_dispatch_fini_8\" : \"__kmpc_dispatch_fini_8u\");\n  llvm::Type *TypeParams[] = {\n      getIdentTyPointerTy(), // loc\n      CGM.Int32Ty,           // tid\n  };\n  auto *FnTy =\n      llvm::FunctionType::get(CGM.VoidTy, TypeParams, /*isVarArg=*/false);\n  return CGM.CreateRuntimeFunction(FnTy, Name);\n}\n\nllvm::FunctionCallee\nCGOpenMPRuntime::createDispatchNextFunction(unsigned IVSize, bool IVSigned) {\n  assert((IVSize == 32 || IVSize == 64) &&\n         \"IV size is not compatible with the omp runtime\");\n  StringRef Name =\n      IVSize == 32\n          ? (IVSigned ? \"__kmpc_dispatch_next_4\" : \"__kmpc_dispatch_next_4u\")\n          : (IVSigned ? \"__kmpc_dispatch_next_8\" : \"__kmpc_dispatch_next_8u\");\n  llvm::Type *ITy = IVSize == 32 ? CGM.Int32Ty : CGM.Int64Ty;\n  auto *PtrTy = llvm::PointerType::getUnqual(ITy);\n  llvm::Type *TypeParams[] = {\n    getIdentTyPointerTy(),                     // loc\n    CGM.Int32Ty,                               // tid\n    llvm::PointerType::getUnqual(CGM.Int32Ty), // p_lastiter\n    PtrTy,                                     // p_lower\n    PtrTy,                                     // p_upper\n    PtrTy                                      // p_stride\n  };\n  auto *FnTy =\n      llvm::FunctionType::get(CGM.Int32Ty, TypeParams, /*isVarArg*/ false);\n  return CGM.CreateRuntimeFunction(FnTy, Name);\n}\n\n/// Obtain information that uniquely identifies a target entry. This\n/// consists of the file and device IDs as well as line number associated with\n/// the relevant entry source location.\nstatic void getTargetEntryUniqueInfo(ASTContext &C, SourceLocation Loc,\n                                     unsigned &DeviceID, unsigned &FileID,\n                                     unsigned &LineNum) {\n  SourceManager &SM = C.getSourceManager();\n\n  // The loc should be always valid and have a file ID (the user cannot use\n  // #pragma directives in macros)\n\n  assert(Loc.isValid() && \"Source location is expected to be always valid.\");\n\n  PresumedLoc PLoc = SM.getPresumedLoc(Loc);\n  assert(PLoc.isValid() && \"Source location is expected to be always valid.\");\n\n  llvm::sys::fs::UniqueID ID;\n  if (auto EC = llvm::sys::fs::getUniqueID(PLoc.getFilename(), ID)) {\n    PLoc = SM.getPresumedLoc(Loc, /*UseLineDirectives=*/false);\n    assert(PLoc.isValid() && \"Source location is expected to be always valid.\");\n    if (auto EC = llvm::sys::fs::getUniqueID(PLoc.getFilename(), ID))\n      SM.getDiagnostics().Report(diag::err_cannot_open_file)\n          << PLoc.getFilename() << EC.message();\n  }\n\n  DeviceID = ID.getDevice();\n  FileID = ID.getFile();\n  LineNum = PLoc.getLine();\n}\n\nAddress CGOpenMPRuntime::getAddrOfDeclareTargetVar(const VarDecl *VD) {\n  if (CGM.getLangOpts().OpenMPSimd)\n    return Address::invalid();\n  llvm::Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n      OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD);\n  if (Res && (*Res == OMPDeclareTargetDeclAttr::MT_Link ||\n              (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n               HasRequiresUnifiedSharedMemory))) {\n    SmallString<64> PtrName;\n    {\n      llvm::raw_svector_ostream OS(PtrName);\n      OS << CGM.getMangledName(GlobalDecl(VD));\n      if (!VD->isExternallyVisible()) {\n        unsigned DeviceID, FileID, Line;\n        getTargetEntryUniqueInfo(CGM.getContext(),\n                                 VD->getCanonicalDecl()->getBeginLoc(),\n                                 DeviceID, FileID, Line);\n        OS << llvm::format(\"_%x\", FileID);\n      }\n      OS << \"_decl_tgt_ref_ptr\";\n    }\n    llvm::Value *Ptr = CGM.getModule().getNamedValue(PtrName);\n    if (!Ptr) {\n      QualType PtrTy = CGM.getContext().getPointerType(VD->getType());\n      Ptr = getOrCreateInternalVariable(CGM.getTypes().ConvertTypeForMem(PtrTy),\n                                        PtrName);\n\n      auto *GV = cast<llvm::GlobalVariable>(Ptr);\n      GV->setLinkage(llvm::GlobalValue::WeakAnyLinkage);\n\n      if (!CGM.getLangOpts().OpenMPIsDevice)\n        GV->setInitializer(CGM.GetAddrOfGlobal(VD));\n      registerTargetGlobalVariable(VD, cast<llvm::Constant>(Ptr));\n    }\n    return Address(Ptr, CGM.getContext().getDeclAlign(VD));\n  }\n  return Address::invalid();\n}\n\nllvm::Constant *\nCGOpenMPRuntime::getOrCreateThreadPrivateCache(const VarDecl *VD) {\n  assert(!CGM.getLangOpts().OpenMPUseTLS ||\n         !CGM.getContext().getTargetInfo().isTLSSupported());\n  // Lookup the entry, lazily creating it if necessary.\n  std::string Suffix = getName({\"cache\", \"\"});\n  return getOrCreateInternalVariable(\n      CGM.Int8PtrPtrTy, Twine(CGM.getMangledName(VD)).concat(Suffix));\n}\n\nAddress CGOpenMPRuntime::getAddrOfThreadPrivate(CodeGenFunction &CGF,\n                                                const VarDecl *VD,\n                                                Address VDAddr,\n                                                SourceLocation Loc) {\n  if (CGM.getLangOpts().OpenMPUseTLS &&\n      CGM.getContext().getTargetInfo().isTLSSupported())\n    return VDAddr;\n\n  llvm::Type *VarTy = VDAddr.getElementType();\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc),\n                         CGF.Builder.CreatePointerCast(VDAddr.getPointer(),\n                                                       CGM.Int8PtrTy),\n                         CGM.getSize(CGM.GetTargetTypeStoreSize(VarTy)),\n                         getOrCreateThreadPrivateCache(VD)};\n  return Address(CGF.EmitRuntimeCall(\n                     OMPBuilder.getOrCreateRuntimeFunction(\n                         CGM.getModule(), OMPRTL___kmpc_threadprivate_cached),\n                     Args),\n                 VDAddr.getAlignment());\n}\n\nvoid CGOpenMPRuntime::emitThreadPrivateVarInit(\n    CodeGenFunction &CGF, Address VDAddr, llvm::Value *Ctor,\n    llvm::Value *CopyCtor, llvm::Value *Dtor, SourceLocation Loc) {\n  // Call kmp_int32 __kmpc_global_thread_num(&loc) to init OpenMP runtime\n  // library.\n  llvm::Value *OMPLoc = emitUpdateLocation(CGF, Loc);\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_global_thread_num),\n                      OMPLoc);\n  // Call __kmpc_threadprivate_register(&loc, &var, ctor, cctor/*NULL*/, dtor)\n  // to register constructor/destructor for variable.\n  llvm::Value *Args[] = {\n      OMPLoc, CGF.Builder.CreatePointerCast(VDAddr.getPointer(), CGM.VoidPtrTy),\n      Ctor, CopyCtor, Dtor};\n  CGF.EmitRuntimeCall(\n      OMPBuilder.getOrCreateRuntimeFunction(\n          CGM.getModule(), OMPRTL___kmpc_threadprivate_register),\n      Args);\n}\n\nllvm::Function *CGOpenMPRuntime::emitThreadPrivateVarDefinition(\n    const VarDecl *VD, Address VDAddr, SourceLocation Loc,\n    bool PerformInit, CodeGenFunction *CGF) {\n  if (CGM.getLangOpts().OpenMPUseTLS &&\n      CGM.getContext().getTargetInfo().isTLSSupported())\n    return nullptr;\n\n  VD = VD->getDefinition(CGM.getContext());\n  if (VD && ThreadPrivateWithDefinition.insert(CGM.getMangledName(VD)).second) {\n    QualType ASTTy = VD->getType();\n\n    llvm::Value *Ctor = nullptr, *CopyCtor = nullptr, *Dtor = nullptr;\n    const Expr *Init = VD->getAnyInitializer();\n    if (CGM.getLangOpts().CPlusPlus && PerformInit) {\n      // Generate function that re-emits the declaration's initializer into the\n      // threadprivate copy of the variable VD\n      CodeGenFunction CtorCGF(CGM);\n      FunctionArgList Args;\n      ImplicitParamDecl Dst(CGM.getContext(), /*DC=*/nullptr, Loc,\n                            /*Id=*/nullptr, CGM.getContext().VoidPtrTy,\n                            ImplicitParamDecl::Other);\n      Args.push_back(&Dst);\n\n      const auto &FI = CGM.getTypes().arrangeBuiltinFunctionDeclaration(\n          CGM.getContext().VoidPtrTy, Args);\n      llvm::FunctionType *FTy = CGM.getTypes().GetFunctionType(FI);\n      std::string Name = getName({\"__kmpc_global_ctor_\", \"\"});\n      llvm::Function *Fn =\n          CGM.CreateGlobalInitOrCleanUpFunction(FTy, Name, FI, Loc);\n      CtorCGF.StartFunction(GlobalDecl(), CGM.getContext().VoidPtrTy, Fn, FI,\n                            Args, Loc, Loc);\n      llvm::Value *ArgVal = CtorCGF.EmitLoadOfScalar(\n          CtorCGF.GetAddrOfLocalVar(&Dst), /*Volatile=*/false,\n          CGM.getContext().VoidPtrTy, Dst.getLocation());\n      Address Arg = Address(ArgVal, VDAddr.getAlignment());\n      Arg = CtorCGF.Builder.CreateElementBitCast(\n          Arg, CtorCGF.ConvertTypeForMem(ASTTy));\n      CtorCGF.EmitAnyExprToMem(Init, Arg, Init->getType().getQualifiers(),\n                               /*IsInitializer=*/true);\n      ArgVal = CtorCGF.EmitLoadOfScalar(\n          CtorCGF.GetAddrOfLocalVar(&Dst), /*Volatile=*/false,\n          CGM.getContext().VoidPtrTy, Dst.getLocation());\n      CtorCGF.Builder.CreateStore(ArgVal, CtorCGF.ReturnValue);\n      CtorCGF.FinishFunction();\n      Ctor = Fn;\n    }\n    if (VD->getType().isDestructedType() != QualType::DK_none) {\n      // Generate function that emits destructor call for the threadprivate copy\n      // of the variable VD\n      CodeGenFunction DtorCGF(CGM);\n      FunctionArgList Args;\n      ImplicitParamDecl Dst(CGM.getContext(), /*DC=*/nullptr, Loc,\n                            /*Id=*/nullptr, CGM.getContext().VoidPtrTy,\n                            ImplicitParamDecl::Other);\n      Args.push_back(&Dst);\n\n      const auto &FI = CGM.getTypes().arrangeBuiltinFunctionDeclaration(\n          CGM.getContext().VoidTy, Args);\n      llvm::FunctionType *FTy = CGM.getTypes().GetFunctionType(FI);\n      std::string Name = getName({\"__kmpc_global_dtor_\", \"\"});\n      llvm::Function *Fn =\n          CGM.CreateGlobalInitOrCleanUpFunction(FTy, Name, FI, Loc);\n      auto NL = ApplyDebugLocation::CreateEmpty(DtorCGF);\n      DtorCGF.StartFunction(GlobalDecl(), CGM.getContext().VoidTy, Fn, FI, Args,\n                            Loc, Loc);\n      // Create a scope with an artificial location for the body of this function.\n      auto AL = ApplyDebugLocation::CreateArtificial(DtorCGF);\n      llvm::Value *ArgVal = DtorCGF.EmitLoadOfScalar(\n          DtorCGF.GetAddrOfLocalVar(&Dst),\n          /*Volatile=*/false, CGM.getContext().VoidPtrTy, Dst.getLocation());\n      DtorCGF.emitDestroy(Address(ArgVal, VDAddr.getAlignment()), ASTTy,\n                          DtorCGF.getDestroyer(ASTTy.isDestructedType()),\n                          DtorCGF.needsEHCleanup(ASTTy.isDestructedType()));\n      DtorCGF.FinishFunction();\n      Dtor = Fn;\n    }\n    // Do not emit init function if it is not required.\n    if (!Ctor && !Dtor)\n      return nullptr;\n\n    llvm::Type *CopyCtorTyArgs[] = {CGM.VoidPtrTy, CGM.VoidPtrTy};\n    auto *CopyCtorTy = llvm::FunctionType::get(CGM.VoidPtrTy, CopyCtorTyArgs,\n                                               /*isVarArg=*/false)\n                           ->getPointerTo();\n    // Copying constructor for the threadprivate variable.\n    // Must be NULL - reserved by runtime, but currently it requires that this\n    // parameter is always NULL. Otherwise it fires assertion.\n    CopyCtor = llvm::Constant::getNullValue(CopyCtorTy);\n    if (Ctor == nullptr) {\n      auto *CtorTy = llvm::FunctionType::get(CGM.VoidPtrTy, CGM.VoidPtrTy,\n                                             /*isVarArg=*/false)\n                         ->getPointerTo();\n      Ctor = llvm::Constant::getNullValue(CtorTy);\n    }\n    if (Dtor == nullptr) {\n      auto *DtorTy = llvm::FunctionType::get(CGM.VoidTy, CGM.VoidPtrTy,\n                                             /*isVarArg=*/false)\n                         ->getPointerTo();\n      Dtor = llvm::Constant::getNullValue(DtorTy);\n    }\n    if (!CGF) {\n      auto *InitFunctionTy =\n          llvm::FunctionType::get(CGM.VoidTy, /*isVarArg*/ false);\n      std::string Name = getName({\"__omp_threadprivate_init_\", \"\"});\n      llvm::Function *InitFunction = CGM.CreateGlobalInitOrCleanUpFunction(\n          InitFunctionTy, Name, CGM.getTypes().arrangeNullaryFunction());\n      CodeGenFunction InitCGF(CGM);\n      FunctionArgList ArgList;\n      InitCGF.StartFunction(GlobalDecl(), CGM.getContext().VoidTy, InitFunction,\n                            CGM.getTypes().arrangeNullaryFunction(), ArgList,\n                            Loc, Loc);\n      emitThreadPrivateVarInit(InitCGF, VDAddr, Ctor, CopyCtor, Dtor, Loc);\n      InitCGF.FinishFunction();\n      return InitFunction;\n    }\n    emitThreadPrivateVarInit(*CGF, VDAddr, Ctor, CopyCtor, Dtor, Loc);\n  }\n  return nullptr;\n}\n\nbool CGOpenMPRuntime::emitDeclareTargetVarDefinition(const VarDecl *VD,\n                                                     llvm::GlobalVariable *Addr,\n                                                     bool PerformInit) {\n  if (CGM.getLangOpts().OMPTargetTriples.empty() &&\n      !CGM.getLangOpts().OpenMPIsDevice)\n    return false;\n  Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n      OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD);\n  if (!Res || *Res == OMPDeclareTargetDeclAttr::MT_Link ||\n      (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n       HasRequiresUnifiedSharedMemory))\n    return CGM.getLangOpts().OpenMPIsDevice;\n  VD = VD->getDefinition(CGM.getContext());\n  assert(VD && \"Unknown VarDecl\");\n\n  if (!DeclareTargetWithDefinition.insert(CGM.getMangledName(VD)).second)\n    return CGM.getLangOpts().OpenMPIsDevice;\n\n  QualType ASTTy = VD->getType();\n  SourceLocation Loc = VD->getCanonicalDecl()->getBeginLoc();\n\n  // Produce the unique prefix to identify the new target regions. We use\n  // the source location of the variable declaration which we know to not\n  // conflict with any target region.\n  unsigned DeviceID;\n  unsigned FileID;\n  unsigned Line;\n  getTargetEntryUniqueInfo(CGM.getContext(), Loc, DeviceID, FileID, Line);\n  SmallString<128> Buffer, Out;\n  {\n    llvm::raw_svector_ostream OS(Buffer);\n    OS << \"__omp_offloading_\" << llvm::format(\"_%x\", DeviceID)\n       << llvm::format(\"_%x_\", FileID) << VD->getName() << \"_l\" << Line;\n  }\n\n  const Expr *Init = VD->getAnyInitializer();\n  if (CGM.getLangOpts().CPlusPlus && PerformInit) {\n    llvm::Constant *Ctor;\n    llvm::Constant *ID;\n    if (CGM.getLangOpts().OpenMPIsDevice) {\n      // Generate function that re-emits the declaration's initializer into\n      // the threadprivate copy of the variable VD\n      CodeGenFunction CtorCGF(CGM);\n\n      const CGFunctionInfo &FI = CGM.getTypes().arrangeNullaryFunction();\n      llvm::FunctionType *FTy = CGM.getTypes().GetFunctionType(FI);\n      llvm::Function *Fn = CGM.CreateGlobalInitOrCleanUpFunction(\n          FTy, Twine(Buffer, \"_ctor\"), FI, Loc);\n      auto NL = ApplyDebugLocation::CreateEmpty(CtorCGF);\n      CtorCGF.StartFunction(GlobalDecl(), CGM.getContext().VoidTy, Fn, FI,\n                            FunctionArgList(), Loc, Loc);\n      auto AL = ApplyDebugLocation::CreateArtificial(CtorCGF);\n      CtorCGF.EmitAnyExprToMem(Init,\n                               Address(Addr, CGM.getContext().getDeclAlign(VD)),\n                               Init->getType().getQualifiers(),\n                               /*IsInitializer=*/true);\n      CtorCGF.FinishFunction();\n      Ctor = Fn;\n      ID = llvm::ConstantExpr::getBitCast(Fn, CGM.Int8PtrTy);\n      CGM.addUsedGlobal(cast<llvm::GlobalValue>(Ctor));\n    } else {\n      Ctor = new llvm::GlobalVariable(\n          CGM.getModule(), CGM.Int8Ty, /*isConstant=*/true,\n          llvm::GlobalValue::PrivateLinkage,\n          llvm::Constant::getNullValue(CGM.Int8Ty), Twine(Buffer, \"_ctor\"));\n      ID = Ctor;\n    }\n\n    // Register the information for the entry associated with the constructor.\n    Out.clear();\n    OffloadEntriesInfoManager.registerTargetRegionEntryInfo(\n        DeviceID, FileID, Twine(Buffer, \"_ctor\").toStringRef(Out), Line, Ctor,\n        ID, OffloadEntriesInfoManagerTy::OMPTargetRegionEntryCtor);\n  }\n  if (VD->getType().isDestructedType() != QualType::DK_none) {\n    llvm::Constant *Dtor;\n    llvm::Constant *ID;\n    if (CGM.getLangOpts().OpenMPIsDevice) {\n      // Generate function that emits destructor call for the threadprivate\n      // copy of the variable VD\n      CodeGenFunction DtorCGF(CGM);\n\n      const CGFunctionInfo &FI = CGM.getTypes().arrangeNullaryFunction();\n      llvm::FunctionType *FTy = CGM.getTypes().GetFunctionType(FI);\n      llvm::Function *Fn = CGM.CreateGlobalInitOrCleanUpFunction(\n          FTy, Twine(Buffer, \"_dtor\"), FI, Loc);\n      auto NL = ApplyDebugLocation::CreateEmpty(DtorCGF);\n      DtorCGF.StartFunction(GlobalDecl(), CGM.getContext().VoidTy, Fn, FI,\n                            FunctionArgList(), Loc, Loc);\n      // Create a scope with an artificial location for the body of this\n      // function.\n      auto AL = ApplyDebugLocation::CreateArtificial(DtorCGF);\n      DtorCGF.emitDestroy(Address(Addr, CGM.getContext().getDeclAlign(VD)),\n                          ASTTy, DtorCGF.getDestroyer(ASTTy.isDestructedType()),\n                          DtorCGF.needsEHCleanup(ASTTy.isDestructedType()));\n      DtorCGF.FinishFunction();\n      Dtor = Fn;\n      ID = llvm::ConstantExpr::getBitCast(Fn, CGM.Int8PtrTy);\n      CGM.addUsedGlobal(cast<llvm::GlobalValue>(Dtor));\n    } else {\n      Dtor = new llvm::GlobalVariable(\n          CGM.getModule(), CGM.Int8Ty, /*isConstant=*/true,\n          llvm::GlobalValue::PrivateLinkage,\n          llvm::Constant::getNullValue(CGM.Int8Ty), Twine(Buffer, \"_dtor\"));\n      ID = Dtor;\n    }\n    // Register the information for the entry associated with the destructor.\n    Out.clear();\n    OffloadEntriesInfoManager.registerTargetRegionEntryInfo(\n        DeviceID, FileID, Twine(Buffer, \"_dtor\").toStringRef(Out), Line, Dtor,\n        ID, OffloadEntriesInfoManagerTy::OMPTargetRegionEntryDtor);\n  }\n  return CGM.getLangOpts().OpenMPIsDevice;\n}\n\nAddress CGOpenMPRuntime::getAddrOfArtificialThreadPrivate(CodeGenFunction &CGF,\n                                                          QualType VarType,\n                                                          StringRef Name) {\n  std::string Suffix = getName({\"artificial\", \"\"});\n  llvm::Type *VarLVType = CGF.ConvertTypeForMem(VarType);\n  llvm::Value *GAddr =\n      getOrCreateInternalVariable(VarLVType, Twine(Name).concat(Suffix));\n  if (CGM.getLangOpts().OpenMP && CGM.getLangOpts().OpenMPUseTLS &&\n      CGM.getTarget().isTLSSupported()) {\n    cast<llvm::GlobalVariable>(GAddr)->setThreadLocal(/*Val=*/true);\n    return Address(GAddr, CGM.getContext().getTypeAlignInChars(VarType));\n  }\n  std::string CacheSuffix = getName({\"cache\", \"\"});\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, SourceLocation()),\n      getThreadID(CGF, SourceLocation()),\n      CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(GAddr, CGM.VoidPtrTy),\n      CGF.Builder.CreateIntCast(CGF.getTypeSize(VarType), CGM.SizeTy,\n                                /*isSigned=*/false),\n      getOrCreateInternalVariable(\n          CGM.VoidPtrPtrTy, Twine(Name).concat(Suffix).concat(CacheSuffix))};\n  return Address(\n      CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          CGF.EmitRuntimeCall(\n              OMPBuilder.getOrCreateRuntimeFunction(\n                  CGM.getModule(), OMPRTL___kmpc_threadprivate_cached),\n              Args),\n          VarLVType->getPointerTo(/*AddrSpace=*/0)),\n      CGM.getContext().getTypeAlignInChars(VarType));\n}\n\nvoid CGOpenMPRuntime::emitIfClause(CodeGenFunction &CGF, const Expr *Cond,\n                                   const RegionCodeGenTy &ThenGen,\n                                   const RegionCodeGenTy &ElseGen) {\n  CodeGenFunction::LexicalScope ConditionScope(CGF, Cond->getSourceRange());\n\n  // If the condition constant folds and can be elided, try to avoid emitting\n  // the condition and the dead arm of the if/else.\n  bool CondConstant;\n  if (CGF.ConstantFoldsToSimpleInteger(Cond, CondConstant)) {\n    if (CondConstant)\n      ThenGen(CGF);\n    else\n      ElseGen(CGF);\n    return;\n  }\n\n  // Otherwise, the condition did not fold, or we couldn't elide it.  Just\n  // emit the conditional branch.\n  llvm::BasicBlock *ThenBlock = CGF.createBasicBlock(\"omp_if.then\");\n  llvm::BasicBlock *ElseBlock = CGF.createBasicBlock(\"omp_if.else\");\n  llvm::BasicBlock *ContBlock = CGF.createBasicBlock(\"omp_if.end\");\n  CGF.EmitBranchOnBoolExpr(Cond, ThenBlock, ElseBlock, /*TrueCount=*/0);\n\n  // Emit the 'then' code.\n  CGF.EmitBlock(ThenBlock);\n  ThenGen(CGF);\n  CGF.EmitBranch(ContBlock);\n  // Emit the 'else' code if present.\n  // There is no need to emit line number for unconditional branch.\n  (void)ApplyDebugLocation::CreateEmpty(CGF);\n  CGF.EmitBlock(ElseBlock);\n  ElseGen(CGF);\n  // There is no need to emit line number for unconditional branch.\n  (void)ApplyDebugLocation::CreateEmpty(CGF);\n  CGF.EmitBranch(ContBlock);\n  // Emit the continuation block for code after the if.\n  CGF.EmitBlock(ContBlock, /*IsFinished=*/true);\n}\n\nvoid CGOpenMPRuntime::emitParallelCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                       llvm::Function *OutlinedFn,\n                                       ArrayRef<llvm::Value *> CapturedVars,\n                                       const Expr *IfCond) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  llvm::Value *RTLoc = emitUpdateLocation(CGF, Loc);\n  auto &M = CGM.getModule();\n  auto &&ThenGen = [&M, OutlinedFn, CapturedVars, RTLoc,\n                    this](CodeGenFunction &CGF, PrePostActionTy &) {\n    // Build call __kmpc_fork_call(loc, n, microtask, var1, .., varn);\n    CGOpenMPRuntime &RT = CGF.CGM.getOpenMPRuntime();\n    llvm::Value *Args[] = {\n        RTLoc,\n        CGF.Builder.getInt32(CapturedVars.size()), // Number of captured vars\n        CGF.Builder.CreateBitCast(OutlinedFn, RT.getKmpc_MicroPointerTy())};\n    llvm::SmallVector<llvm::Value *, 16> RealArgs;\n    RealArgs.append(std::begin(Args), std::end(Args));\n    RealArgs.append(CapturedVars.begin(), CapturedVars.end());\n\n    llvm::FunctionCallee RTLFn =\n        OMPBuilder.getOrCreateRuntimeFunction(M, OMPRTL___kmpc_fork_call);\n    CGF.EmitRuntimeCall(RTLFn, RealArgs);\n  };\n  auto &&ElseGen = [&M, OutlinedFn, CapturedVars, RTLoc, Loc,\n                    this](CodeGenFunction &CGF, PrePostActionTy &) {\n    CGOpenMPRuntime &RT = CGF.CGM.getOpenMPRuntime();\n    llvm::Value *ThreadID = RT.getThreadID(CGF, Loc);\n    // Build calls:\n    // __kmpc_serialized_parallel(&Loc, GTid);\n    llvm::Value *Args[] = {RTLoc, ThreadID};\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            M, OMPRTL___kmpc_serialized_parallel),\n                        Args);\n\n    // OutlinedFn(&GTid, &zero_bound, CapturedStruct);\n    Address ThreadIDAddr = RT.emitThreadIDAddress(CGF, Loc);\n    Address ZeroAddrBound =\n        CGF.CreateDefaultAlignTempAlloca(CGF.Int32Ty,\n                                         /*Name=*/\".bound.zero.addr\");\n    CGF.InitTempAlloca(ZeroAddrBound, CGF.Builder.getInt32(/*C*/ 0));\n    llvm::SmallVector<llvm::Value *, 16> OutlinedFnArgs;\n    // ThreadId for serialized parallels is 0.\n    OutlinedFnArgs.push_back(ThreadIDAddr.getPointer());\n    OutlinedFnArgs.push_back(ZeroAddrBound.getPointer());\n    OutlinedFnArgs.append(CapturedVars.begin(), CapturedVars.end());\n\n    // Ensure we do not inline the function. This is trivially true for the ones\n    // passed to __kmpc_fork_call but the ones calles in serialized regions\n    // could be inlined. This is not a perfect but it is closer to the invariant\n    // we want, namely, every data environment starts with a new function.\n    // TODO: We should pass the if condition to the runtime function and do the\n    //       handling there. Much cleaner code.\n    OutlinedFn->addFnAttr(llvm::Attribute::NoInline);\n    RT.emitOutlinedFunctionCall(CGF, Loc, OutlinedFn, OutlinedFnArgs);\n\n    // __kmpc_end_serialized_parallel(&Loc, GTid);\n    llvm::Value *EndArgs[] = {RT.emitUpdateLocation(CGF, Loc), ThreadID};\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            M, OMPRTL___kmpc_end_serialized_parallel),\n                        EndArgs);\n  };\n  if (IfCond) {\n    emitIfClause(CGF, IfCond, ThenGen, ElseGen);\n  } else {\n    RegionCodeGenTy ThenRCG(ThenGen);\n    ThenRCG(CGF);\n  }\n}\n\n// If we're inside an (outlined) parallel region, use the region info's\n// thread-ID variable (it is passed in a first argument of the outlined function\n// as \"kmp_int32 *gtid\"). Otherwise, if we're not inside parallel region, but in\n// regular serial code region, get thread ID by calling kmp_int32\n// kmpc_global_thread_num(ident_t *loc), stash this thread ID in a temporary and\n// return the address of that temp.\nAddress CGOpenMPRuntime::emitThreadIDAddress(CodeGenFunction &CGF,\n                                             SourceLocation Loc) {\n  if (auto *OMPRegionInfo =\n          dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo))\n    if (OMPRegionInfo->getThreadIDVariable())\n      return OMPRegionInfo->getThreadIDVariableLValue(CGF).getAddress(CGF);\n\n  llvm::Value *ThreadID = getThreadID(CGF, Loc);\n  QualType Int32Ty =\n      CGF.getContext().getIntTypeForBitwidth(/*DestWidth*/ 32, /*Signed*/ true);\n  Address ThreadIDTemp = CGF.CreateMemTemp(Int32Ty, /*Name*/ \".threadid_temp.\");\n  CGF.EmitStoreOfScalar(ThreadID,\n                        CGF.MakeAddrLValue(ThreadIDTemp, Int32Ty));\n\n  return ThreadIDTemp;\n}\n\nllvm::Constant *CGOpenMPRuntime::getOrCreateInternalVariable(\n    llvm::Type *Ty, const llvm::Twine &Name, unsigned AddressSpace) {\n  SmallString<256> Buffer;\n  llvm::raw_svector_ostream Out(Buffer);\n  Out << Name;\n  StringRef RuntimeName = Out.str();\n  auto &Elem = *InternalVars.try_emplace(RuntimeName, nullptr).first;\n  if (Elem.second) {\n    assert(Elem.second->getType()->getPointerElementType() == Ty &&\n           \"OMP internal variable has different type than requested\");\n    return &*Elem.second;\n  }\n\n  return Elem.second = new llvm::GlobalVariable(\n             CGM.getModule(), Ty, /*IsConstant*/ false,\n             llvm::GlobalValue::CommonLinkage, llvm::Constant::getNullValue(Ty),\n             Elem.first(), /*InsertBefore=*/nullptr,\n             llvm::GlobalValue::NotThreadLocal, AddressSpace);\n}\n\nllvm::Value *CGOpenMPRuntime::getCriticalRegionLock(StringRef CriticalName) {\n  std::string Prefix = Twine(\"gomp_critical_user_\", CriticalName).str();\n  std::string Name = getName({Prefix, \"var\"});\n  return getOrCreateInternalVariable(KmpCriticalNameTy, Name);\n}\n\nnamespace {\n/// Common pre(post)-action for different OpenMP constructs.\nclass CommonActionTy final : public PrePostActionTy {\n  llvm::FunctionCallee EnterCallee;\n  ArrayRef<llvm::Value *> EnterArgs;\n  llvm::FunctionCallee ExitCallee;\n  ArrayRef<llvm::Value *> ExitArgs;\n  bool Conditional;\n  llvm::BasicBlock *ContBlock = nullptr;\n\npublic:\n  CommonActionTy(llvm::FunctionCallee EnterCallee,\n                 ArrayRef<llvm::Value *> EnterArgs,\n                 llvm::FunctionCallee ExitCallee,\n                 ArrayRef<llvm::Value *> ExitArgs, bool Conditional = false)\n      : EnterCallee(EnterCallee), EnterArgs(EnterArgs), ExitCallee(ExitCallee),\n        ExitArgs(ExitArgs), Conditional(Conditional) {}\n  void Enter(CodeGenFunction &CGF) override {\n    llvm::Value *EnterRes = CGF.EmitRuntimeCall(EnterCallee, EnterArgs);\n    if (Conditional) {\n      llvm::Value *CallBool = CGF.Builder.CreateIsNotNull(EnterRes);\n      auto *ThenBlock = CGF.createBasicBlock(\"omp_if.then\");\n      ContBlock = CGF.createBasicBlock(\"omp_if.end\");\n      // Generate the branch (If-stmt)\n      CGF.Builder.CreateCondBr(CallBool, ThenBlock, ContBlock);\n      CGF.EmitBlock(ThenBlock);\n    }\n  }\n  void Done(CodeGenFunction &CGF) {\n    // Emit the rest of blocks/branches\n    CGF.EmitBranch(ContBlock);\n    CGF.EmitBlock(ContBlock, true);\n  }\n  void Exit(CodeGenFunction &CGF) override {\n    CGF.EmitRuntimeCall(ExitCallee, ExitArgs);\n  }\n};\n} // anonymous namespace\n\nvoid CGOpenMPRuntime::emitCriticalRegion(CodeGenFunction &CGF,\n                                         StringRef CriticalName,\n                                         const RegionCodeGenTy &CriticalOpGen,\n                                         SourceLocation Loc, const Expr *Hint) {\n  // __kmpc_critical[_with_hint](ident_t *, gtid, Lock[, hint]);\n  // CriticalOpGen();\n  // __kmpc_end_critical(ident_t *, gtid, Lock);\n  // Prepare arguments and build a call to __kmpc_critical\n  if (!CGF.HaveInsertPoint())\n    return;\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc),\n                         getCriticalRegionLock(CriticalName)};\n  llvm::SmallVector<llvm::Value *, 4> EnterArgs(std::begin(Args),\n                                                std::end(Args));\n  if (Hint) {\n    EnterArgs.push_back(CGF.Builder.CreateIntCast(\n        CGF.EmitScalarExpr(Hint), CGM.Int32Ty, /*isSigned=*/false));\n  }\n  CommonActionTy Action(\n      OMPBuilder.getOrCreateRuntimeFunction(\n          CGM.getModule(),\n          Hint ? OMPRTL___kmpc_critical_with_hint : OMPRTL___kmpc_critical),\n      EnterArgs,\n      OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                            OMPRTL___kmpc_end_critical),\n      Args);\n  CriticalOpGen.setAction(Action);\n  emitInlinedDirective(CGF, OMPD_critical, CriticalOpGen);\n}\n\nvoid CGOpenMPRuntime::emitMasterRegion(CodeGenFunction &CGF,\n                                       const RegionCodeGenTy &MasterOpGen,\n                                       SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // if(__kmpc_master(ident_t *, gtid)) {\n  //   MasterOpGen();\n  //   __kmpc_end_master(ident_t *, gtid);\n  // }\n  // Prepare arguments and build a call to __kmpc_master\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc)};\n  CommonActionTy Action(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_master),\n                        Args,\n                        OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_end_master),\n                        Args,\n                        /*Conditional=*/true);\n  MasterOpGen.setAction(Action);\n  emitInlinedDirective(CGF, OMPD_master, MasterOpGen);\n  Action.Done(CGF);\n}\n\nvoid CGOpenMPRuntime::emitTaskyieldCall(CodeGenFunction &CGF,\n                                        SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  if (CGF.CGM.getLangOpts().OpenMPIRBuilder) {\n    OMPBuilder.createTaskyield(CGF.Builder);\n  } else {\n    // Build call __kmpc_omp_taskyield(loc, thread_id, 0);\n    llvm::Value *Args[] = {\n        emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc),\n        llvm::ConstantInt::get(CGM.IntTy, /*V=*/0, /*isSigned=*/true)};\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_omp_taskyield),\n                        Args);\n  }\n\n  if (auto *Region = dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo))\n    Region->emitUntiedSwitch(CGF);\n}\n\nvoid CGOpenMPRuntime::emitTaskgroupRegion(CodeGenFunction &CGF,\n                                          const RegionCodeGenTy &TaskgroupOpGen,\n                                          SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // __kmpc_taskgroup(ident_t *, gtid);\n  // TaskgroupOpGen();\n  // __kmpc_end_taskgroup(ident_t *, gtid);\n  // Prepare arguments and build a call to __kmpc_taskgroup\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc)};\n  CommonActionTy Action(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_taskgroup),\n                        Args,\n                        OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_end_taskgroup),\n                        Args);\n  TaskgroupOpGen.setAction(Action);\n  emitInlinedDirective(CGF, OMPD_taskgroup, TaskgroupOpGen);\n}\n\n/// Given an array of pointers to variables, project the address of a\n/// given variable.\nstatic Address emitAddrOfVarFromArray(CodeGenFunction &CGF, Address Array,\n                                      unsigned Index, const VarDecl *Var) {\n  // Pull out the pointer to the variable.\n  Address PtrAddr = CGF.Builder.CreateConstArrayGEP(Array, Index);\n  llvm::Value *Ptr = CGF.Builder.CreateLoad(PtrAddr);\n\n  Address Addr = Address(Ptr, CGF.getContext().getDeclAlign(Var));\n  Addr = CGF.Builder.CreateElementBitCast(\n      Addr, CGF.ConvertTypeForMem(Var->getType()));\n  return Addr;\n}\n\nstatic llvm::Value *emitCopyprivateCopyFunction(\n    CodeGenModule &CGM, llvm::Type *ArgsType,\n    ArrayRef<const Expr *> CopyprivateVars, ArrayRef<const Expr *> DestExprs,\n    ArrayRef<const Expr *> SrcExprs, ArrayRef<const Expr *> AssignmentOps,\n    SourceLocation Loc) {\n  ASTContext &C = CGM.getContext();\n  // void copy_func(void *LHSArg, void *RHSArg);\n  FunctionArgList Args;\n  ImplicitParamDecl LHSArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                           ImplicitParamDecl::Other);\n  ImplicitParamDecl RHSArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                           ImplicitParamDecl::Other);\n  Args.push_back(&LHSArg);\n  Args.push_back(&RHSArg);\n  const auto &CGFI =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  std::string Name =\n      CGM.getOpenMPRuntime().getName({\"omp\", \"copyprivate\", \"copy_func\"});\n  auto *Fn = llvm::Function::Create(CGM.getTypes().GetFunctionType(CGFI),\n                                    llvm::GlobalValue::InternalLinkage, Name,\n                                    &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, CGFI);\n  Fn->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, CGFI, Args, Loc, Loc);\n  // Dest = (void*[n])(LHSArg);\n  // Src = (void*[n])(RHSArg);\n  Address LHS(CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      CGF.Builder.CreateLoad(CGF.GetAddrOfLocalVar(&LHSArg)),\n      ArgsType), CGF.getPointerAlign());\n  Address RHS(CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      CGF.Builder.CreateLoad(CGF.GetAddrOfLocalVar(&RHSArg)),\n      ArgsType), CGF.getPointerAlign());\n  // *(Type0*)Dst[0] = *(Type0*)Src[0];\n  // *(Type1*)Dst[1] = *(Type1*)Src[1];\n  // ...\n  // *(Typen*)Dst[n] = *(Typen*)Src[n];\n  for (unsigned I = 0, E = AssignmentOps.size(); I < E; ++I) {\n    const auto *DestVar =\n        cast<VarDecl>(cast<DeclRefExpr>(DestExprs[I])->getDecl());\n    Address DestAddr = emitAddrOfVarFromArray(CGF, LHS, I, DestVar);\n\n    const auto *SrcVar =\n        cast<VarDecl>(cast<DeclRefExpr>(SrcExprs[I])->getDecl());\n    Address SrcAddr = emitAddrOfVarFromArray(CGF, RHS, I, SrcVar);\n\n    const auto *VD = cast<DeclRefExpr>(CopyprivateVars[I])->getDecl();\n    QualType Type = VD->getType();\n    CGF.EmitOMPCopy(Type, DestAddr, SrcAddr, DestVar, SrcVar, AssignmentOps[I]);\n  }\n  CGF.FinishFunction();\n  return Fn;\n}\n\nvoid CGOpenMPRuntime::emitSingleRegion(CodeGenFunction &CGF,\n                                       const RegionCodeGenTy &SingleOpGen,\n                                       SourceLocation Loc,\n                                       ArrayRef<const Expr *> CopyprivateVars,\n                                       ArrayRef<const Expr *> SrcExprs,\n                                       ArrayRef<const Expr *> DstExprs,\n                                       ArrayRef<const Expr *> AssignmentOps) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  assert(CopyprivateVars.size() == SrcExprs.size() &&\n         CopyprivateVars.size() == DstExprs.size() &&\n         CopyprivateVars.size() == AssignmentOps.size());\n  ASTContext &C = CGM.getContext();\n  // int32 did_it = 0;\n  // if(__kmpc_single(ident_t *, gtid)) {\n  //   SingleOpGen();\n  //   __kmpc_end_single(ident_t *, gtid);\n  //   did_it = 1;\n  // }\n  // call __kmpc_copyprivate(ident_t *, gtid, <buf_size>, <copyprivate list>,\n  // <copy_func>, did_it);\n\n  Address DidIt = Address::invalid();\n  if (!CopyprivateVars.empty()) {\n    // int32 did_it = 0;\n    QualType KmpInt32Ty =\n        C.getIntTypeForBitwidth(/*DestWidth=*/32, /*Signed=*/1);\n    DidIt = CGF.CreateMemTemp(KmpInt32Ty, \".omp.copyprivate.did_it\");\n    CGF.Builder.CreateStore(CGF.Builder.getInt32(0), DidIt);\n  }\n  // Prepare arguments and build a call to __kmpc_single\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc)};\n  CommonActionTy Action(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_single),\n                        Args,\n                        OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_end_single),\n                        Args,\n                        /*Conditional=*/true);\n  SingleOpGen.setAction(Action);\n  emitInlinedDirective(CGF, OMPD_single, SingleOpGen);\n  if (DidIt.isValid()) {\n    // did_it = 1;\n    CGF.Builder.CreateStore(CGF.Builder.getInt32(1), DidIt);\n  }\n  Action.Done(CGF);\n  // call __kmpc_copyprivate(ident_t *, gtid, <buf_size>, <copyprivate list>,\n  // <copy_func>, did_it);\n  if (DidIt.isValid()) {\n    llvm::APInt ArraySize(/*unsigned int numBits=*/32, CopyprivateVars.size());\n    QualType CopyprivateArrayTy = C.getConstantArrayType(\n        C.VoidPtrTy, ArraySize, nullptr, ArrayType::Normal,\n        /*IndexTypeQuals=*/0);\n    // Create a list of all private variables for copyprivate.\n    Address CopyprivateList =\n        CGF.CreateMemTemp(CopyprivateArrayTy, \".omp.copyprivate.cpr_list\");\n    for (unsigned I = 0, E = CopyprivateVars.size(); I < E; ++I) {\n      Address Elem = CGF.Builder.CreateConstArrayGEP(CopyprivateList, I);\n      CGF.Builder.CreateStore(\n          CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n              CGF.EmitLValue(CopyprivateVars[I]).getPointer(CGF),\n              CGF.VoidPtrTy),\n          Elem);\n    }\n    // Build function that copies private values from single region to all other\n    // threads in the corresponding parallel region.\n    llvm::Value *CpyFn = emitCopyprivateCopyFunction(\n        CGM, CGF.ConvertTypeForMem(CopyprivateArrayTy)->getPointerTo(),\n        CopyprivateVars, SrcExprs, DstExprs, AssignmentOps, Loc);\n    llvm::Value *BufSize = CGF.getTypeSize(CopyprivateArrayTy);\n    Address CL =\n      CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(CopyprivateList,\n                                                      CGF.VoidPtrTy);\n    llvm::Value *DidItVal = CGF.Builder.CreateLoad(DidIt);\n    llvm::Value *Args[] = {\n        emitUpdateLocation(CGF, Loc), // ident_t *<loc>\n        getThreadID(CGF, Loc),        // i32 <gtid>\n        BufSize,                      // size_t <buf_size>\n        CL.getPointer(),              // void *<copyprivate list>\n        CpyFn,                        // void (*) (void *, void *) <copy_func>\n        DidItVal                      // i32 did_it\n    };\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_copyprivate),\n                        Args);\n  }\n}\n\nvoid CGOpenMPRuntime::emitOrderedRegion(CodeGenFunction &CGF,\n                                        const RegionCodeGenTy &OrderedOpGen,\n                                        SourceLocation Loc, bool IsThreads) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // __kmpc_ordered(ident_t *, gtid);\n  // OrderedOpGen();\n  // __kmpc_end_ordered(ident_t *, gtid);\n  // Prepare arguments and build a call to __kmpc_ordered\n  if (IsThreads) {\n    llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc)};\n    CommonActionTy Action(OMPBuilder.getOrCreateRuntimeFunction(\n                              CGM.getModule(), OMPRTL___kmpc_ordered),\n                          Args,\n                          OMPBuilder.getOrCreateRuntimeFunction(\n                              CGM.getModule(), OMPRTL___kmpc_end_ordered),\n                          Args);\n    OrderedOpGen.setAction(Action);\n    emitInlinedDirective(CGF, OMPD_ordered, OrderedOpGen);\n    return;\n  }\n  emitInlinedDirective(CGF, OMPD_ordered, OrderedOpGen);\n}\n\nunsigned CGOpenMPRuntime::getDefaultFlagsForBarriers(OpenMPDirectiveKind Kind) {\n  unsigned Flags;\n  if (Kind == OMPD_for)\n    Flags = OMP_IDENT_BARRIER_IMPL_FOR;\n  else if (Kind == OMPD_sections)\n    Flags = OMP_IDENT_BARRIER_IMPL_SECTIONS;\n  else if (Kind == OMPD_single)\n    Flags = OMP_IDENT_BARRIER_IMPL_SINGLE;\n  else if (Kind == OMPD_barrier)\n    Flags = OMP_IDENT_BARRIER_EXPL;\n  else\n    Flags = OMP_IDENT_BARRIER_IMPL;\n  return Flags;\n}\n\nvoid CGOpenMPRuntime::getDefaultScheduleAndChunk(\n    CodeGenFunction &CGF, const OMPLoopDirective &S,\n    OpenMPScheduleClauseKind &ScheduleKind, const Expr *&ChunkExpr) const {\n  // Check if the loop directive is actually a doacross loop directive. In this\n  // case choose static, 1 schedule.\n  if (llvm::any_of(\n          S.getClausesOfKind<OMPOrderedClause>(),\n          [](const OMPOrderedClause *C) { return C->getNumForLoops(); })) {\n    ScheduleKind = OMPC_SCHEDULE_static;\n    // Chunk size is 1 in this case.\n    llvm::APInt ChunkSize(32, 1);\n    ChunkExpr = IntegerLiteral::Create(\n        CGF.getContext(), ChunkSize,\n        CGF.getContext().getIntTypeForBitwidth(32, /*Signed=*/0),\n        SourceLocation());\n  }\n}\n\nvoid CGOpenMPRuntime::emitBarrierCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                      OpenMPDirectiveKind Kind, bool EmitChecks,\n                                      bool ForceSimpleCall) {\n  // Check if we should use the OMPBuilder\n  auto *OMPRegionInfo =\n      dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo);\n  if (CGF.CGM.getLangOpts().OpenMPIRBuilder) {\n    CGF.Builder.restoreIP(OMPBuilder.createBarrier(\n        CGF.Builder, Kind, ForceSimpleCall, EmitChecks));\n    return;\n  }\n\n  if (!CGF.HaveInsertPoint())\n    return;\n  // Build call __kmpc_cancel_barrier(loc, thread_id);\n  // Build call __kmpc_barrier(loc, thread_id);\n  unsigned Flags = getDefaultFlagsForBarriers(Kind);\n  // Build call __kmpc_cancel_barrier(loc, thread_id) or __kmpc_barrier(loc,\n  // thread_id);\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc, Flags),\n                         getThreadID(CGF, Loc)};\n  if (OMPRegionInfo) {\n    if (!ForceSimpleCall && OMPRegionInfo->hasCancel()) {\n      llvm::Value *Result = CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                                OMPRTL___kmpc_cancel_barrier),\n          Args);\n      if (EmitChecks) {\n        // if (__kmpc_cancel_barrier()) {\n        //   exit from construct;\n        // }\n        llvm::BasicBlock *ExitBB = CGF.createBasicBlock(\".cancel.exit\");\n        llvm::BasicBlock *ContBB = CGF.createBasicBlock(\".cancel.continue\");\n        llvm::Value *Cmp = CGF.Builder.CreateIsNotNull(Result);\n        CGF.Builder.CreateCondBr(Cmp, ExitBB, ContBB);\n        CGF.EmitBlock(ExitBB);\n        //   exit from construct;\n        CodeGenFunction::JumpDest CancelDestination =\n            CGF.getOMPCancelDestination(OMPRegionInfo->getDirectiveKind());\n        CGF.EmitBranchThroughCleanup(CancelDestination);\n        CGF.EmitBlock(ContBB, /*IsFinished=*/true);\n      }\n      return;\n    }\n  }\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_barrier),\n                      Args);\n}\n\n/// Map the OpenMP loop schedule to the runtime enumeration.\nstatic OpenMPSchedType getRuntimeSchedule(OpenMPScheduleClauseKind ScheduleKind,\n                                          bool Chunked, bool Ordered) {\n  switch (ScheduleKind) {\n  case OMPC_SCHEDULE_static:\n    return Chunked ? (Ordered ? OMP_ord_static_chunked : OMP_sch_static_chunked)\n                   : (Ordered ? OMP_ord_static : OMP_sch_static);\n  case OMPC_SCHEDULE_dynamic:\n    return Ordered ? OMP_ord_dynamic_chunked : OMP_sch_dynamic_chunked;\n  case OMPC_SCHEDULE_guided:\n    return Ordered ? OMP_ord_guided_chunked : OMP_sch_guided_chunked;\n  case OMPC_SCHEDULE_runtime:\n    return Ordered ? OMP_ord_runtime : OMP_sch_runtime;\n  case OMPC_SCHEDULE_auto:\n    return Ordered ? OMP_ord_auto : OMP_sch_auto;\n  case OMPC_SCHEDULE_unknown:\n    assert(!Chunked && \"chunk was specified but schedule kind not known\");\n    return Ordered ? OMP_ord_static : OMP_sch_static;\n  }\n  llvm_unreachable(\"Unexpected runtime schedule\");\n}\n\n/// Map the OpenMP distribute schedule to the runtime enumeration.\nstatic OpenMPSchedType\ngetRuntimeSchedule(OpenMPDistScheduleClauseKind ScheduleKind, bool Chunked) {\n  // only static is allowed for dist_schedule\n  return Chunked ? OMP_dist_sch_static_chunked : OMP_dist_sch_static;\n}\n\nbool CGOpenMPRuntime::isStaticNonchunked(OpenMPScheduleClauseKind ScheduleKind,\n                                         bool Chunked) const {\n  OpenMPSchedType Schedule =\n      getRuntimeSchedule(ScheduleKind, Chunked, /*Ordered=*/false);\n  return Schedule == OMP_sch_static;\n}\n\nbool CGOpenMPRuntime::isStaticNonchunked(\n    OpenMPDistScheduleClauseKind ScheduleKind, bool Chunked) const {\n  OpenMPSchedType Schedule = getRuntimeSchedule(ScheduleKind, Chunked);\n  return Schedule == OMP_dist_sch_static;\n}\n\nbool CGOpenMPRuntime::isStaticChunked(OpenMPScheduleClauseKind ScheduleKind,\n                                      bool Chunked) const {\n  OpenMPSchedType Schedule =\n      getRuntimeSchedule(ScheduleKind, Chunked, /*Ordered=*/false);\n  return Schedule == OMP_sch_static_chunked;\n}\n\nbool CGOpenMPRuntime::isStaticChunked(\n    OpenMPDistScheduleClauseKind ScheduleKind, bool Chunked) const {\n  OpenMPSchedType Schedule = getRuntimeSchedule(ScheduleKind, Chunked);\n  return Schedule == OMP_dist_sch_static_chunked;\n}\n\nbool CGOpenMPRuntime::isDynamic(OpenMPScheduleClauseKind ScheduleKind) const {\n  OpenMPSchedType Schedule =\n      getRuntimeSchedule(ScheduleKind, /*Chunked=*/false, /*Ordered=*/false);\n  assert(Schedule != OMP_sch_static_chunked && \"cannot be chunked here\");\n  return Schedule != OMP_sch_static;\n}\n\nstatic int addMonoNonMonoModifier(CodeGenModule &CGM, OpenMPSchedType Schedule,\n                                  OpenMPScheduleClauseModifier M1,\n                                  OpenMPScheduleClauseModifier M2) {\n  int Modifier = 0;\n  switch (M1) {\n  case OMPC_SCHEDULE_MODIFIER_monotonic:\n    Modifier = OMP_sch_modifier_monotonic;\n    break;\n  case OMPC_SCHEDULE_MODIFIER_nonmonotonic:\n    Modifier = OMP_sch_modifier_nonmonotonic;\n    break;\n  case OMPC_SCHEDULE_MODIFIER_simd:\n    if (Schedule == OMP_sch_static_chunked)\n      Schedule = OMP_sch_static_balanced_chunked;\n    break;\n  case OMPC_SCHEDULE_MODIFIER_last:\n  case OMPC_SCHEDULE_MODIFIER_unknown:\n    break;\n  }\n  switch (M2) {\n  case OMPC_SCHEDULE_MODIFIER_monotonic:\n    Modifier = OMP_sch_modifier_monotonic;\n    break;\n  case OMPC_SCHEDULE_MODIFIER_nonmonotonic:\n    Modifier = OMP_sch_modifier_nonmonotonic;\n    break;\n  case OMPC_SCHEDULE_MODIFIER_simd:\n    if (Schedule == OMP_sch_static_chunked)\n      Schedule = OMP_sch_static_balanced_chunked;\n    break;\n  case OMPC_SCHEDULE_MODIFIER_last:\n  case OMPC_SCHEDULE_MODIFIER_unknown:\n    break;\n  }\n  // OpenMP 5.0, 2.9.2 Worksharing-Loop Construct, Desription.\n  // If the static schedule kind is specified or if the ordered clause is\n  // specified, and if the nonmonotonic modifier is not specified, the effect is\n  // as if the monotonic modifier is specified. Otherwise, unless the monotonic\n  // modifier is specified, the effect is as if the nonmonotonic modifier is\n  // specified.\n  if (CGM.getLangOpts().OpenMP >= 50 && Modifier == 0) {\n    if (!(Schedule == OMP_sch_static_chunked || Schedule == OMP_sch_static ||\n          Schedule == OMP_sch_static_balanced_chunked ||\n          Schedule == OMP_ord_static_chunked || Schedule == OMP_ord_static ||\n          Schedule == OMP_dist_sch_static_chunked ||\n          Schedule == OMP_dist_sch_static))\n      Modifier = OMP_sch_modifier_nonmonotonic;\n  }\n  return Schedule | Modifier;\n}\n\nvoid CGOpenMPRuntime::emitForDispatchInit(\n    CodeGenFunction &CGF, SourceLocation Loc,\n    const OpenMPScheduleTy &ScheduleKind, unsigned IVSize, bool IVSigned,\n    bool Ordered, const DispatchRTInput &DispatchValues) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  OpenMPSchedType Schedule = getRuntimeSchedule(\n      ScheduleKind.Schedule, DispatchValues.Chunk != nullptr, Ordered);\n  assert(Ordered ||\n         (Schedule != OMP_sch_static && Schedule != OMP_sch_static_chunked &&\n          Schedule != OMP_ord_static && Schedule != OMP_ord_static_chunked &&\n          Schedule != OMP_sch_static_balanced_chunked));\n  // Call __kmpc_dispatch_init(\n  //          ident_t *loc, kmp_int32 tid, kmp_int32 schedule,\n  //          kmp_int[32|64] lower, kmp_int[32|64] upper,\n  //          kmp_int[32|64] stride, kmp_int[32|64] chunk);\n\n  // If the Chunk was not specified in the clause - use default value 1.\n  llvm::Value *Chunk = DispatchValues.Chunk ? DispatchValues.Chunk\n                                            : CGF.Builder.getIntN(IVSize, 1);\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, Loc),\n      getThreadID(CGF, Loc),\n      CGF.Builder.getInt32(addMonoNonMonoModifier(\n          CGM, Schedule, ScheduleKind.M1, ScheduleKind.M2)), // Schedule type\n      DispatchValues.LB,                                     // Lower\n      DispatchValues.UB,                                     // Upper\n      CGF.Builder.getIntN(IVSize, 1),                        // Stride\n      Chunk                                                  // Chunk\n  };\n  CGF.EmitRuntimeCall(createDispatchInitFunction(IVSize, IVSigned), Args);\n}\n\nstatic void emitForStaticInitCall(\n    CodeGenFunction &CGF, llvm::Value *UpdateLocation, llvm::Value *ThreadId,\n    llvm::FunctionCallee ForStaticInitFunction, OpenMPSchedType Schedule,\n    OpenMPScheduleClauseModifier M1, OpenMPScheduleClauseModifier M2,\n    const CGOpenMPRuntime::StaticRTInput &Values) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  assert(!Values.Ordered);\n  assert(Schedule == OMP_sch_static || Schedule == OMP_sch_static_chunked ||\n         Schedule == OMP_sch_static_balanced_chunked ||\n         Schedule == OMP_ord_static || Schedule == OMP_ord_static_chunked ||\n         Schedule == OMP_dist_sch_static ||\n         Schedule == OMP_dist_sch_static_chunked);\n\n  // Call __kmpc_for_static_init(\n  //          ident_t *loc, kmp_int32 tid, kmp_int32 schedtype,\n  //          kmp_int32 *p_lastiter, kmp_int[32|64] *p_lower,\n  //          kmp_int[32|64] *p_upper, kmp_int[32|64] *p_stride,\n  //          kmp_int[32|64] incr, kmp_int[32|64] chunk);\n  llvm::Value *Chunk = Values.Chunk;\n  if (Chunk == nullptr) {\n    assert((Schedule == OMP_sch_static || Schedule == OMP_ord_static ||\n            Schedule == OMP_dist_sch_static) &&\n           \"expected static non-chunked schedule\");\n    // If the Chunk was not specified in the clause - use default value 1.\n    Chunk = CGF.Builder.getIntN(Values.IVSize, 1);\n  } else {\n    assert((Schedule == OMP_sch_static_chunked ||\n            Schedule == OMP_sch_static_balanced_chunked ||\n            Schedule == OMP_ord_static_chunked ||\n            Schedule == OMP_dist_sch_static_chunked) &&\n           \"expected static chunked schedule\");\n  }\n  llvm::Value *Args[] = {\n      UpdateLocation,\n      ThreadId,\n      CGF.Builder.getInt32(addMonoNonMonoModifier(CGF.CGM, Schedule, M1,\n                                                  M2)), // Schedule type\n      Values.IL.getPointer(),                           // &isLastIter\n      Values.LB.getPointer(),                           // &LB\n      Values.UB.getPointer(),                           // &UB\n      Values.ST.getPointer(),                           // &Stride\n      CGF.Builder.getIntN(Values.IVSize, 1),            // Incr\n      Chunk                                             // Chunk\n  };\n  CGF.EmitRuntimeCall(ForStaticInitFunction, Args);\n}\n\nvoid CGOpenMPRuntime::emitForStaticInit(CodeGenFunction &CGF,\n                                        SourceLocation Loc,\n                                        OpenMPDirectiveKind DKind,\n                                        const OpenMPScheduleTy &ScheduleKind,\n                                        const StaticRTInput &Values) {\n  OpenMPSchedType ScheduleNum = getRuntimeSchedule(\n      ScheduleKind.Schedule, Values.Chunk != nullptr, Values.Ordered);\n  assert(isOpenMPWorksharingDirective(DKind) &&\n         \"Expected loop-based or sections-based directive.\");\n  llvm::Value *UpdatedLocation = emitUpdateLocation(CGF, Loc,\n                                             isOpenMPLoopDirective(DKind)\n                                                 ? OMP_IDENT_WORK_LOOP\n                                                 : OMP_IDENT_WORK_SECTIONS);\n  llvm::Value *ThreadId = getThreadID(CGF, Loc);\n  llvm::FunctionCallee StaticInitFunction =\n      createForStaticInitFunction(Values.IVSize, Values.IVSigned);\n  auto DL = ApplyDebugLocation::CreateDefaultArtificial(CGF, Loc);\n  emitForStaticInitCall(CGF, UpdatedLocation, ThreadId, StaticInitFunction,\n                        ScheduleNum, ScheduleKind.M1, ScheduleKind.M2, Values);\n}\n\nvoid CGOpenMPRuntime::emitDistributeStaticInit(\n    CodeGenFunction &CGF, SourceLocation Loc,\n    OpenMPDistScheduleClauseKind SchedKind,\n    const CGOpenMPRuntime::StaticRTInput &Values) {\n  OpenMPSchedType ScheduleNum =\n      getRuntimeSchedule(SchedKind, Values.Chunk != nullptr);\n  llvm::Value *UpdatedLocation =\n      emitUpdateLocation(CGF, Loc, OMP_IDENT_WORK_DISTRIBUTE);\n  llvm::Value *ThreadId = getThreadID(CGF, Loc);\n  llvm::FunctionCallee StaticInitFunction =\n      createForStaticInitFunction(Values.IVSize, Values.IVSigned);\n  emitForStaticInitCall(CGF, UpdatedLocation, ThreadId, StaticInitFunction,\n                        ScheduleNum, OMPC_SCHEDULE_MODIFIER_unknown,\n                        OMPC_SCHEDULE_MODIFIER_unknown, Values);\n}\n\nvoid CGOpenMPRuntime::emitForStaticFinish(CodeGenFunction &CGF,\n                                          SourceLocation Loc,\n                                          OpenMPDirectiveKind DKind) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // Call __kmpc_for_static_fini(ident_t *loc, kmp_int32 tid);\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, Loc,\n                         isOpenMPDistributeDirective(DKind)\n                             ? OMP_IDENT_WORK_DISTRIBUTE\n                             : isOpenMPLoopDirective(DKind)\n                                   ? OMP_IDENT_WORK_LOOP\n                                   : OMP_IDENT_WORK_SECTIONS),\n      getThreadID(CGF, Loc)};\n  auto DL = ApplyDebugLocation::CreateDefaultArtificial(CGF, Loc);\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_for_static_fini),\n                      Args);\n}\n\nvoid CGOpenMPRuntime::emitForOrderedIterationEnd(CodeGenFunction &CGF,\n                                                 SourceLocation Loc,\n                                                 unsigned IVSize,\n                                                 bool IVSigned) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // Call __kmpc_for_dynamic_fini_(4|8)[u](ident_t *loc, kmp_int32 tid);\n  llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc)};\n  CGF.EmitRuntimeCall(createDispatchFiniFunction(IVSize, IVSigned), Args);\n}\n\nllvm::Value *CGOpenMPRuntime::emitForNext(CodeGenFunction &CGF,\n                                          SourceLocation Loc, unsigned IVSize,\n                                          bool IVSigned, Address IL,\n                                          Address LB, Address UB,\n                                          Address ST) {\n  // Call __kmpc_dispatch_next(\n  //          ident_t *loc, kmp_int32 tid, kmp_int32 *p_lastiter,\n  //          kmp_int[32|64] *p_lower, kmp_int[32|64] *p_upper,\n  //          kmp_int[32|64] *p_stride);\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, Loc),\n      getThreadID(CGF, Loc),\n      IL.getPointer(), // &isLastIter\n      LB.getPointer(), // &Lower\n      UB.getPointer(), // &Upper\n      ST.getPointer()  // &Stride\n  };\n  llvm::Value *Call =\n      CGF.EmitRuntimeCall(createDispatchNextFunction(IVSize, IVSigned), Args);\n  return CGF.EmitScalarConversion(\n      Call, CGF.getContext().getIntTypeForBitwidth(32, /*Signed=*/1),\n      CGF.getContext().BoolTy, Loc);\n}\n\nvoid CGOpenMPRuntime::emitNumThreadsClause(CodeGenFunction &CGF,\n                                           llvm::Value *NumThreads,\n                                           SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // Build call __kmpc_push_num_threads(&loc, global_tid, num_threads)\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc),\n      CGF.Builder.CreateIntCast(NumThreads, CGF.Int32Ty, /*isSigned*/ true)};\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_push_num_threads),\n                      Args);\n}\n\nvoid CGOpenMPRuntime::emitProcBindClause(CodeGenFunction &CGF,\n                                         ProcBindKind ProcBind,\n                                         SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  assert(ProcBind != OMP_PROC_BIND_unknown && \"Unsupported proc_bind value.\");\n  // Build call __kmpc_push_proc_bind(&loc, global_tid, proc_bind)\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc),\n      llvm::ConstantInt::get(CGM.IntTy, unsigned(ProcBind), /*isSigned=*/true)};\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_push_proc_bind),\n                      Args);\n}\n\nvoid CGOpenMPRuntime::emitFlush(CodeGenFunction &CGF, ArrayRef<const Expr *>,\n                                SourceLocation Loc, llvm::AtomicOrdering AO) {\n  if (CGF.CGM.getLangOpts().OpenMPIRBuilder) {\n    OMPBuilder.createFlush(CGF.Builder);\n  } else {\n    if (!CGF.HaveInsertPoint())\n      return;\n    // Build call void __kmpc_flush(ident_t *loc)\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_flush),\n                        emitUpdateLocation(CGF, Loc));\n  }\n}\n\nnamespace {\n/// Indexes of fields for type kmp_task_t.\nenum KmpTaskTFields {\n  /// List of shared variables.\n  KmpTaskTShareds,\n  /// Task routine.\n  KmpTaskTRoutine,\n  /// Partition id for the untied tasks.\n  KmpTaskTPartId,\n  /// Function with call of destructors for private variables.\n  Data1,\n  /// Task priority.\n  Data2,\n  /// (Taskloops only) Lower bound.\n  KmpTaskTLowerBound,\n  /// (Taskloops only) Upper bound.\n  KmpTaskTUpperBound,\n  /// (Taskloops only) Stride.\n  KmpTaskTStride,\n  /// (Taskloops only) Is last iteration flag.\n  KmpTaskTLastIter,\n  /// (Taskloops only) Reduction data.\n  KmpTaskTReductions,\n};\n} // anonymous namespace\n\nbool CGOpenMPRuntime::OffloadEntriesInfoManagerTy::empty() const {\n  return OffloadEntriesTargetRegion.empty() &&\n         OffloadEntriesDeviceGlobalVar.empty();\n}\n\n/// Initialize target region entry.\nvoid CGOpenMPRuntime::OffloadEntriesInfoManagerTy::\n    initializeTargetRegionEntryInfo(unsigned DeviceID, unsigned FileID,\n                                    StringRef ParentName, unsigned LineNum,\n                                    unsigned Order) {\n  assert(CGM.getLangOpts().OpenMPIsDevice && \"Initialization of entries is \"\n                                             \"only required for the device \"\n                                             \"code generation.\");\n  OffloadEntriesTargetRegion[DeviceID][FileID][ParentName][LineNum] =\n      OffloadEntryInfoTargetRegion(Order, /*Addr=*/nullptr, /*ID=*/nullptr,\n                                   OMPTargetRegionEntryTargetRegion);\n  ++OffloadingEntriesNum;\n}\n\nvoid CGOpenMPRuntime::OffloadEntriesInfoManagerTy::\n    registerTargetRegionEntryInfo(unsigned DeviceID, unsigned FileID,\n                                  StringRef ParentName, unsigned LineNum,\n                                  llvm::Constant *Addr, llvm::Constant *ID,\n                                  OMPTargetRegionEntryKind Flags) {\n  // If we are emitting code for a target, the entry is already initialized,\n  // only has to be registered.\n  if (CGM.getLangOpts().OpenMPIsDevice) {\n    // This could happen if the device compilation is invoked standalone.\n    if (!hasTargetRegionEntryInfo(DeviceID, FileID, ParentName, LineNum))\n      initializeTargetRegionEntryInfo(DeviceID, FileID, ParentName, LineNum,\n                                      OffloadingEntriesNum);\n    auto &Entry =\n        OffloadEntriesTargetRegion[DeviceID][FileID][ParentName][LineNum];\n    Entry.setAddress(Addr);\n    Entry.setID(ID);\n    Entry.setFlags(Flags);\n  } else {\n    if (Flags ==\n            OffloadEntriesInfoManagerTy::OMPTargetRegionEntryTargetRegion &&\n        hasTargetRegionEntryInfo(DeviceID, FileID, ParentName, LineNum,\n                                 /*IgnoreAddressId*/ true))\n      return;\n    assert(!hasTargetRegionEntryInfo(DeviceID, FileID, ParentName, LineNum) &&\n           \"Target region entry already registered!\");\n    OffloadEntryInfoTargetRegion Entry(OffloadingEntriesNum, Addr, ID, Flags);\n    OffloadEntriesTargetRegion[DeviceID][FileID][ParentName][LineNum] = Entry;\n    ++OffloadingEntriesNum;\n  }\n}\n\nbool CGOpenMPRuntime::OffloadEntriesInfoManagerTy::hasTargetRegionEntryInfo(\n    unsigned DeviceID, unsigned FileID, StringRef ParentName, unsigned LineNum,\n    bool IgnoreAddressId) const {\n  auto PerDevice = OffloadEntriesTargetRegion.find(DeviceID);\n  if (PerDevice == OffloadEntriesTargetRegion.end())\n    return false;\n  auto PerFile = PerDevice->second.find(FileID);\n  if (PerFile == PerDevice->second.end())\n    return false;\n  auto PerParentName = PerFile->second.find(ParentName);\n  if (PerParentName == PerFile->second.end())\n    return false;\n  auto PerLine = PerParentName->second.find(LineNum);\n  if (PerLine == PerParentName->second.end())\n    return false;\n  // Fail if this entry is already registered.\n  if (!IgnoreAddressId &&\n      (PerLine->second.getAddress() || PerLine->second.getID()))\n    return false;\n  return true;\n}\n\nvoid CGOpenMPRuntime::OffloadEntriesInfoManagerTy::actOnTargetRegionEntriesInfo(\n    const OffloadTargetRegionEntryInfoActTy &Action) {\n  // Scan all target region entries and perform the provided action.\n  for (const auto &D : OffloadEntriesTargetRegion)\n    for (const auto &F : D.second)\n      for (const auto &P : F.second)\n        for (const auto &L : P.second)\n          Action(D.first, F.first, P.first(), L.first, L.second);\n}\n\nvoid CGOpenMPRuntime::OffloadEntriesInfoManagerTy::\n    initializeDeviceGlobalVarEntryInfo(StringRef Name,\n                                       OMPTargetGlobalVarEntryKind Flags,\n                                       unsigned Order) {\n  assert(CGM.getLangOpts().OpenMPIsDevice && \"Initialization of entries is \"\n                                             \"only required for the device \"\n                                             \"code generation.\");\n  OffloadEntriesDeviceGlobalVar.try_emplace(Name, Order, Flags);\n  ++OffloadingEntriesNum;\n}\n\nvoid CGOpenMPRuntime::OffloadEntriesInfoManagerTy::\n    registerDeviceGlobalVarEntryInfo(StringRef VarName, llvm::Constant *Addr,\n                                     CharUnits VarSize,\n                                     OMPTargetGlobalVarEntryKind Flags,\n                                     llvm::GlobalValue::LinkageTypes Linkage) {\n  if (CGM.getLangOpts().OpenMPIsDevice) {\n    // This could happen if the device compilation is invoked standalone.\n    if (!hasDeviceGlobalVarEntryInfo(VarName))\n      initializeDeviceGlobalVarEntryInfo(VarName, Flags, OffloadingEntriesNum);\n    auto &Entry = OffloadEntriesDeviceGlobalVar[VarName];\n    assert((!Entry.getAddress() || Entry.getAddress() == Addr) &&\n           \"Resetting with the new address.\");\n    if (Entry.getAddress() && hasDeviceGlobalVarEntryInfo(VarName)) {\n      if (Entry.getVarSize().isZero()) {\n        Entry.setVarSize(VarSize);\n        Entry.setLinkage(Linkage);\n      }\n      return;\n    }\n    Entry.setVarSize(VarSize);\n    Entry.setLinkage(Linkage);\n    Entry.setAddress(Addr);\n  } else {\n    if (hasDeviceGlobalVarEntryInfo(VarName)) {\n      auto &Entry = OffloadEntriesDeviceGlobalVar[VarName];\n      assert(Entry.isValid() && Entry.getFlags() == Flags &&\n             \"Entry not initialized!\");\n      assert((!Entry.getAddress() || Entry.getAddress() == Addr) &&\n             \"Resetting with the new address.\");\n      if (Entry.getVarSize().isZero()) {\n        Entry.setVarSize(VarSize);\n        Entry.setLinkage(Linkage);\n      }\n      return;\n    }\n    OffloadEntriesDeviceGlobalVar.try_emplace(\n        VarName, OffloadingEntriesNum, Addr, VarSize, Flags, Linkage);\n    ++OffloadingEntriesNum;\n  }\n}\n\nvoid CGOpenMPRuntime::OffloadEntriesInfoManagerTy::\n    actOnDeviceGlobalVarEntriesInfo(\n        const OffloadDeviceGlobalVarEntryInfoActTy &Action) {\n  // Scan all target region entries and perform the provided action.\n  for (const auto &E : OffloadEntriesDeviceGlobalVar)\n    Action(E.getKey(), E.getValue());\n}\n\nvoid CGOpenMPRuntime::createOffloadEntry(\n    llvm::Constant *ID, llvm::Constant *Addr, uint64_t Size, int32_t Flags,\n    llvm::GlobalValue::LinkageTypes Linkage) {\n  StringRef Name = Addr->getName();\n  llvm::Module &M = CGM.getModule();\n  llvm::LLVMContext &C = M.getContext();\n\n  // Create constant string with the name.\n  llvm::Constant *StrPtrInit = llvm::ConstantDataArray::getString(C, Name);\n\n  std::string StringName = getName({\"omp_offloading\", \"entry_name\"});\n  auto *Str = new llvm::GlobalVariable(\n      M, StrPtrInit->getType(), /*isConstant=*/true,\n      llvm::GlobalValue::InternalLinkage, StrPtrInit, StringName);\n  Str->setUnnamedAddr(llvm::GlobalValue::UnnamedAddr::Global);\n\n  llvm::Constant *Data[] = {\n      llvm::ConstantExpr::getPointerBitCastOrAddrSpaceCast(ID, CGM.VoidPtrTy),\n      llvm::ConstantExpr::getPointerBitCastOrAddrSpaceCast(Str, CGM.Int8PtrTy),\n      llvm::ConstantInt::get(CGM.SizeTy, Size),\n      llvm::ConstantInt::get(CGM.Int32Ty, Flags),\n      llvm::ConstantInt::get(CGM.Int32Ty, 0)};\n  std::string EntryName = getName({\"omp_offloading\", \"entry\", \"\"});\n  llvm::GlobalVariable *Entry = createGlobalStruct(\n      CGM, getTgtOffloadEntryQTy(), /*IsConstant=*/true, Data,\n      Twine(EntryName).concat(Name), llvm::GlobalValue::WeakAnyLinkage);\n\n  // The entry has to be created in the section the linker expects it to be.\n  Entry->setSection(\"omp_offloading_entries\");\n}\n\nvoid CGOpenMPRuntime::createOffloadEntriesAndInfoMetadata() {\n  // Emit the offloading entries and metadata so that the device codegen side\n  // can easily figure out what to emit. The produced metadata looks like\n  // this:\n  //\n  // !omp_offload.info = !{!1, ...}\n  //\n  // Right now we only generate metadata for function that contain target\n  // regions.\n\n  // If we are in simd mode or there are no entries, we don't need to do\n  // anything.\n  if (CGM.getLangOpts().OpenMPSimd || OffloadEntriesInfoManager.empty())\n    return;\n\n  llvm::Module &M = CGM.getModule();\n  llvm::LLVMContext &C = M.getContext();\n  SmallVector<std::tuple<const OffloadEntriesInfoManagerTy::OffloadEntryInfo *,\n                         SourceLocation, StringRef>,\n              16>\n      OrderedEntries(OffloadEntriesInfoManager.size());\n  llvm::SmallVector<StringRef, 16> ParentFunctions(\n      OffloadEntriesInfoManager.size());\n\n  // Auxiliary methods to create metadata values and strings.\n  auto &&GetMDInt = [this](unsigned V) {\n    return llvm::ConstantAsMetadata::get(\n        llvm::ConstantInt::get(CGM.Int32Ty, V));\n  };\n\n  auto &&GetMDString = [&C](StringRef V) { return llvm::MDString::get(C, V); };\n\n  // Create the offloading info metadata node.\n  llvm::NamedMDNode *MD = M.getOrInsertNamedMetadata(\"omp_offload.info\");\n\n  // Create function that emits metadata for each target region entry;\n  auto &&TargetRegionMetadataEmitter =\n      [this, &C, MD, &OrderedEntries, &ParentFunctions, &GetMDInt,\n       &GetMDString](\n          unsigned DeviceID, unsigned FileID, StringRef ParentName,\n          unsigned Line,\n          const OffloadEntriesInfoManagerTy::OffloadEntryInfoTargetRegion &E) {\n        // Generate metadata for target regions. Each entry of this metadata\n        // contains:\n        // - Entry 0 -> Kind of this type of metadata (0).\n        // - Entry 1 -> Device ID of the file where the entry was identified.\n        // - Entry 2 -> File ID of the file where the entry was identified.\n        // - Entry 3 -> Mangled name of the function where the entry was\n        // identified.\n        // - Entry 4 -> Line in the file where the entry was identified.\n        // - Entry 5 -> Order the entry was created.\n        // The first element of the metadata node is the kind.\n        llvm::Metadata *Ops[] = {GetMDInt(E.getKind()), GetMDInt(DeviceID),\n                                 GetMDInt(FileID),      GetMDString(ParentName),\n                                 GetMDInt(Line),        GetMDInt(E.getOrder())};\n\n        SourceLocation Loc;\n        for (auto I = CGM.getContext().getSourceManager().fileinfo_begin(),\n                  E = CGM.getContext().getSourceManager().fileinfo_end();\n             I != E; ++I) {\n          if (I->getFirst()->getUniqueID().getDevice() == DeviceID &&\n              I->getFirst()->getUniqueID().getFile() == FileID) {\n            Loc = CGM.getContext().getSourceManager().translateFileLineCol(\n                I->getFirst(), Line, 1);\n            break;\n          }\n        }\n        // Save this entry in the right position of the ordered entries array.\n        OrderedEntries[E.getOrder()] = std::make_tuple(&E, Loc, ParentName);\n        ParentFunctions[E.getOrder()] = ParentName;\n\n        // Add metadata to the named metadata node.\n        MD->addOperand(llvm::MDNode::get(C, Ops));\n      };\n\n  OffloadEntriesInfoManager.actOnTargetRegionEntriesInfo(\n      TargetRegionMetadataEmitter);\n\n  // Create function that emits metadata for each device global variable entry;\n  auto &&DeviceGlobalVarMetadataEmitter =\n      [&C, &OrderedEntries, &GetMDInt, &GetMDString,\n       MD](StringRef MangledName,\n           const OffloadEntriesInfoManagerTy::OffloadEntryInfoDeviceGlobalVar\n               &E) {\n        // Generate metadata for global variables. Each entry of this metadata\n        // contains:\n        // - Entry 0 -> Kind of this type of metadata (1).\n        // - Entry 1 -> Mangled name of the variable.\n        // - Entry 2 -> Declare target kind.\n        // - Entry 3 -> Order the entry was created.\n        // The first element of the metadata node is the kind.\n        llvm::Metadata *Ops[] = {\n            GetMDInt(E.getKind()), GetMDString(MangledName),\n            GetMDInt(E.getFlags()), GetMDInt(E.getOrder())};\n\n        // Save this entry in the right position of the ordered entries array.\n        OrderedEntries[E.getOrder()] =\n            std::make_tuple(&E, SourceLocation(), MangledName);\n\n        // Add metadata to the named metadata node.\n        MD->addOperand(llvm::MDNode::get(C, Ops));\n      };\n\n  OffloadEntriesInfoManager.actOnDeviceGlobalVarEntriesInfo(\n      DeviceGlobalVarMetadataEmitter);\n\n  for (const auto &E : OrderedEntries) {\n    assert(std::get<0>(E) && \"All ordered entries must exist!\");\n    if (const auto *CE =\n            dyn_cast<OffloadEntriesInfoManagerTy::OffloadEntryInfoTargetRegion>(\n                std::get<0>(E))) {\n      if (!CE->getID() || !CE->getAddress()) {\n        // Do not blame the entry if the parent funtion is not emitted.\n        StringRef FnName = ParentFunctions[CE->getOrder()];\n        if (!CGM.GetGlobalValue(FnName))\n          continue;\n        unsigned DiagID = CGM.getDiags().getCustomDiagID(\n            DiagnosticsEngine::Error,\n            \"Offloading entry for target region in %0 is incorrect: either the \"\n            \"address or the ID is invalid.\");\n        CGM.getDiags().Report(std::get<1>(E), DiagID) << FnName;\n        continue;\n      }\n      createOffloadEntry(CE->getID(), CE->getAddress(), /*Size=*/0,\n                         CE->getFlags(), llvm::GlobalValue::WeakAnyLinkage);\n    } else if (const auto *CE = dyn_cast<OffloadEntriesInfoManagerTy::\n                                             OffloadEntryInfoDeviceGlobalVar>(\n                   std::get<0>(E))) {\n      OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryKind Flags =\n          static_cast<OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryKind>(\n              CE->getFlags());\n      switch (Flags) {\n      case OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryTo: {\n        if (CGM.getLangOpts().OpenMPIsDevice &&\n            CGM.getOpenMPRuntime().hasRequiresUnifiedSharedMemory())\n          continue;\n        if (!CE->getAddress()) {\n          unsigned DiagID = CGM.getDiags().getCustomDiagID(\n              DiagnosticsEngine::Error, \"Offloading entry for declare target \"\n                                        \"variable %0 is incorrect: the \"\n                                        \"address is invalid.\");\n          CGM.getDiags().Report(std::get<1>(E), DiagID) << std::get<2>(E);\n          continue;\n        }\n        // The vaiable has no definition - no need to add the entry.\n        if (CE->getVarSize().isZero())\n          continue;\n        break;\n      }\n      case OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryLink:\n        assert(((CGM.getLangOpts().OpenMPIsDevice && !CE->getAddress()) ||\n                (!CGM.getLangOpts().OpenMPIsDevice && CE->getAddress())) &&\n               \"Declaret target link address is set.\");\n        if (CGM.getLangOpts().OpenMPIsDevice)\n          continue;\n        if (!CE->getAddress()) {\n          unsigned DiagID = CGM.getDiags().getCustomDiagID(\n              DiagnosticsEngine::Error,\n              \"Offloading entry for declare target variable is incorrect: the \"\n              \"address is invalid.\");\n          CGM.getDiags().Report(DiagID);\n          continue;\n        }\n        break;\n      }\n      createOffloadEntry(CE->getAddress(), CE->getAddress(),\n                         CE->getVarSize().getQuantity(), Flags,\n                         CE->getLinkage());\n    } else {\n      llvm_unreachable(\"Unsupported entry kind.\");\n    }\n  }\n}\n\n/// Loads all the offload entries information from the host IR\n/// metadata.\nvoid CGOpenMPRuntime::loadOffloadInfoMetadata() {\n  // If we are in target mode, load the metadata from the host IR. This code has\n  // to match the metadaata creation in createOffloadEntriesAndInfoMetadata().\n\n  if (!CGM.getLangOpts().OpenMPIsDevice)\n    return;\n\n  if (CGM.getLangOpts().OMPHostIRFile.empty())\n    return;\n\n  auto Buf = llvm::MemoryBuffer::getFile(CGM.getLangOpts().OMPHostIRFile);\n  if (auto EC = Buf.getError()) {\n    CGM.getDiags().Report(diag::err_cannot_open_file)\n        << CGM.getLangOpts().OMPHostIRFile << EC.message();\n    return;\n  }\n\n  llvm::LLVMContext C;\n  auto ME = expectedToErrorOrAndEmitErrors(\n      C, llvm::parseBitcodeFile(Buf.get()->getMemBufferRef(), C));\n\n  if (auto EC = ME.getError()) {\n    unsigned DiagID = CGM.getDiags().getCustomDiagID(\n        DiagnosticsEngine::Error, \"Unable to parse host IR file '%0':'%1'\");\n    CGM.getDiags().Report(DiagID)\n        << CGM.getLangOpts().OMPHostIRFile << EC.message();\n    return;\n  }\n\n  llvm::NamedMDNode *MD = ME.get()->getNamedMetadata(\"omp_offload.info\");\n  if (!MD)\n    return;\n\n  for (llvm::MDNode *MN : MD->operands()) {\n    auto &&GetMDInt = [MN](unsigned Idx) {\n      auto *V = cast<llvm::ConstantAsMetadata>(MN->getOperand(Idx));\n      return cast<llvm::ConstantInt>(V->getValue())->getZExtValue();\n    };\n\n    auto &&GetMDString = [MN](unsigned Idx) {\n      auto *V = cast<llvm::MDString>(MN->getOperand(Idx));\n      return V->getString();\n    };\n\n    switch (GetMDInt(0)) {\n    default:\n      llvm_unreachable(\"Unexpected metadata!\");\n      break;\n    case OffloadEntriesInfoManagerTy::OffloadEntryInfo::\n        OffloadingEntryInfoTargetRegion:\n      OffloadEntriesInfoManager.initializeTargetRegionEntryInfo(\n          /*DeviceID=*/GetMDInt(1), /*FileID=*/GetMDInt(2),\n          /*ParentName=*/GetMDString(3), /*Line=*/GetMDInt(4),\n          /*Order=*/GetMDInt(5));\n      break;\n    case OffloadEntriesInfoManagerTy::OffloadEntryInfo::\n        OffloadingEntryInfoDeviceGlobalVar:\n      OffloadEntriesInfoManager.initializeDeviceGlobalVarEntryInfo(\n          /*MangledName=*/GetMDString(1),\n          static_cast<OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryKind>(\n              /*Flags=*/GetMDInt(2)),\n          /*Order=*/GetMDInt(3));\n      break;\n    }\n  }\n}\n\nvoid CGOpenMPRuntime::emitKmpRoutineEntryT(QualType KmpInt32Ty) {\n  if (!KmpRoutineEntryPtrTy) {\n    // Build typedef kmp_int32 (* kmp_routine_entry_t)(kmp_int32, void *); type.\n    ASTContext &C = CGM.getContext();\n    QualType KmpRoutineEntryTyArgs[] = {KmpInt32Ty, C.VoidPtrTy};\n    FunctionProtoType::ExtProtoInfo EPI;\n    KmpRoutineEntryPtrQTy = C.getPointerType(\n        C.getFunctionType(KmpInt32Ty, KmpRoutineEntryTyArgs, EPI));\n    KmpRoutineEntryPtrTy = CGM.getTypes().ConvertType(KmpRoutineEntryPtrQTy);\n  }\n}\n\nQualType CGOpenMPRuntime::getTgtOffloadEntryQTy() {\n  // Make sure the type of the entry is already created. This is the type we\n  // have to create:\n  // struct __tgt_offload_entry{\n  //   void      *addr;       // Pointer to the offload entry info.\n  //                          // (function or global)\n  //   char      *name;       // Name of the function or global.\n  //   size_t     size;       // Size of the entry info (0 if it a function).\n  //   int32_t    flags;      // Flags associated with the entry, e.g. 'link'.\n  //   int32_t    reserved;   // Reserved, to use by the runtime library.\n  // };\n  if (TgtOffloadEntryQTy.isNull()) {\n    ASTContext &C = CGM.getContext();\n    RecordDecl *RD = C.buildImplicitRecord(\"__tgt_offload_entry\");\n    RD->startDefinition();\n    addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n    addFieldToRecordDecl(C, RD, C.getPointerType(C.CharTy));\n    addFieldToRecordDecl(C, RD, C.getSizeType());\n    addFieldToRecordDecl(\n        C, RD, C.getIntTypeForBitwidth(/*DestWidth=*/32, /*Signed=*/true));\n    addFieldToRecordDecl(\n        C, RD, C.getIntTypeForBitwidth(/*DestWidth=*/32, /*Signed=*/true));\n    RD->completeDefinition();\n    RD->addAttr(PackedAttr::CreateImplicit(C));\n    TgtOffloadEntryQTy = C.getRecordType(RD);\n  }\n  return TgtOffloadEntryQTy;\n}\n\nnamespace {\nstruct PrivateHelpersTy {\n  PrivateHelpersTy(const Expr *OriginalRef, const VarDecl *Original,\n                   const VarDecl *PrivateCopy, const VarDecl *PrivateElemInit)\n      : OriginalRef(OriginalRef), Original(Original), PrivateCopy(PrivateCopy),\n        PrivateElemInit(PrivateElemInit) {}\n  PrivateHelpersTy(const VarDecl *Original) : Original(Original) {}\n  const Expr *OriginalRef = nullptr;\n  const VarDecl *Original = nullptr;\n  const VarDecl *PrivateCopy = nullptr;\n  const VarDecl *PrivateElemInit = nullptr;\n  bool isLocalPrivate() const {\n    return !OriginalRef && !PrivateCopy && !PrivateElemInit;\n  }\n};\ntypedef std::pair<CharUnits /*Align*/, PrivateHelpersTy> PrivateDataTy;\n} // anonymous namespace\n\nstatic bool isAllocatableDecl(const VarDecl *VD) {\n  const VarDecl *CVD = VD->getCanonicalDecl();\n  if (!CVD->hasAttr<OMPAllocateDeclAttr>())\n    return false;\n  const auto *AA = CVD->getAttr<OMPAllocateDeclAttr>();\n  // Use the default allocation.\n  return !((AA->getAllocatorType() == OMPAllocateDeclAttr::OMPDefaultMemAlloc ||\n            AA->getAllocatorType() == OMPAllocateDeclAttr::OMPNullMemAlloc) &&\n           !AA->getAllocator());\n}\n\nstatic RecordDecl *\ncreatePrivatesRecordDecl(CodeGenModule &CGM, ArrayRef<PrivateDataTy> Privates) {\n  if (!Privates.empty()) {\n    ASTContext &C = CGM.getContext();\n    // Build struct .kmp_privates_t. {\n    //         /*  private vars  */\n    //       };\n    RecordDecl *RD = C.buildImplicitRecord(\".kmp_privates.t\");\n    RD->startDefinition();\n    for (const auto &Pair : Privates) {\n      const VarDecl *VD = Pair.second.Original;\n      QualType Type = VD->getType().getNonReferenceType();\n      // If the private variable is a local variable with lvalue ref type,\n      // allocate the pointer instead of the pointee type.\n      if (Pair.second.isLocalPrivate()) {\n        if (VD->getType()->isLValueReferenceType())\n          Type = C.getPointerType(Type);\n        if (isAllocatableDecl(VD))\n          Type = C.getPointerType(Type);\n      }\n      FieldDecl *FD = addFieldToRecordDecl(C, RD, Type);\n      if (VD->hasAttrs()) {\n        for (specific_attr_iterator<AlignedAttr> I(VD->getAttrs().begin()),\n             E(VD->getAttrs().end());\n             I != E; ++I)\n          FD->addAttr(*I);\n      }\n    }\n    RD->completeDefinition();\n    return RD;\n  }\n  return nullptr;\n}\n\nstatic RecordDecl *\ncreateKmpTaskTRecordDecl(CodeGenModule &CGM, OpenMPDirectiveKind Kind,\n                         QualType KmpInt32Ty,\n                         QualType KmpRoutineEntryPointerQTy) {\n  ASTContext &C = CGM.getContext();\n  // Build struct kmp_task_t {\n  //         void *              shareds;\n  //         kmp_routine_entry_t routine;\n  //         kmp_int32           part_id;\n  //         kmp_cmplrdata_t data1;\n  //         kmp_cmplrdata_t data2;\n  // For taskloops additional fields:\n  //         kmp_uint64          lb;\n  //         kmp_uint64          ub;\n  //         kmp_int64           st;\n  //         kmp_int32           liter;\n  //         void *              reductions;\n  //       };\n  RecordDecl *UD = C.buildImplicitRecord(\"kmp_cmplrdata_t\", TTK_Union);\n  UD->startDefinition();\n  addFieldToRecordDecl(C, UD, KmpInt32Ty);\n  addFieldToRecordDecl(C, UD, KmpRoutineEntryPointerQTy);\n  UD->completeDefinition();\n  QualType KmpCmplrdataTy = C.getRecordType(UD);\n  RecordDecl *RD = C.buildImplicitRecord(\"kmp_task_t\");\n  RD->startDefinition();\n  addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  addFieldToRecordDecl(C, RD, KmpRoutineEntryPointerQTy);\n  addFieldToRecordDecl(C, RD, KmpInt32Ty);\n  addFieldToRecordDecl(C, RD, KmpCmplrdataTy);\n  addFieldToRecordDecl(C, RD, KmpCmplrdataTy);\n  if (isOpenMPTaskLoopDirective(Kind)) {\n    QualType KmpUInt64Ty =\n        CGM.getContext().getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/0);\n    QualType KmpInt64Ty =\n        CGM.getContext().getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/1);\n    addFieldToRecordDecl(C, RD, KmpUInt64Ty);\n    addFieldToRecordDecl(C, RD, KmpUInt64Ty);\n    addFieldToRecordDecl(C, RD, KmpInt64Ty);\n    addFieldToRecordDecl(C, RD, KmpInt32Ty);\n    addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  }\n  RD->completeDefinition();\n  return RD;\n}\n\nstatic RecordDecl *\ncreateKmpTaskTWithPrivatesRecordDecl(CodeGenModule &CGM, QualType KmpTaskTQTy,\n                                     ArrayRef<PrivateDataTy> Privates) {\n  ASTContext &C = CGM.getContext();\n  // Build struct kmp_task_t_with_privates {\n  //         kmp_task_t task_data;\n  //         .kmp_privates_t. privates;\n  //       };\n  RecordDecl *RD = C.buildImplicitRecord(\"kmp_task_t_with_privates\");\n  RD->startDefinition();\n  addFieldToRecordDecl(C, RD, KmpTaskTQTy);\n  if (const RecordDecl *PrivateRD = createPrivatesRecordDecl(CGM, Privates))\n    addFieldToRecordDecl(C, RD, C.getRecordType(PrivateRD));\n  RD->completeDefinition();\n  return RD;\n}\n\n/// Emit a proxy function which accepts kmp_task_t as the second\n/// argument.\n/// \\code\n/// kmp_int32 .omp_task_entry.(kmp_int32 gtid, kmp_task_t *tt) {\n///   TaskFunction(gtid, tt->part_id, &tt->privates, task_privates_map, tt,\n///   For taskloops:\n///   tt->task_data.lb, tt->task_data.ub, tt->task_data.st, tt->task_data.liter,\n///   tt->reductions, tt->shareds);\n///   return 0;\n/// }\n/// \\endcode\nstatic llvm::Function *\nemitProxyTaskFunction(CodeGenModule &CGM, SourceLocation Loc,\n                      OpenMPDirectiveKind Kind, QualType KmpInt32Ty,\n                      QualType KmpTaskTWithPrivatesPtrQTy,\n                      QualType KmpTaskTWithPrivatesQTy, QualType KmpTaskTQTy,\n                      QualType SharedsPtrTy, llvm::Function *TaskFunction,\n                      llvm::Value *TaskPrivatesMap) {\n  ASTContext &C = CGM.getContext();\n  FunctionArgList Args;\n  ImplicitParamDecl GtidArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, KmpInt32Ty,\n                            ImplicitParamDecl::Other);\n  ImplicitParamDecl TaskTypeArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                                KmpTaskTWithPrivatesPtrQTy.withRestrict(),\n                                ImplicitParamDecl::Other);\n  Args.push_back(&GtidArg);\n  Args.push_back(&TaskTypeArg);\n  const auto &TaskEntryFnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(KmpInt32Ty, Args);\n  llvm::FunctionType *TaskEntryTy =\n      CGM.getTypes().GetFunctionType(TaskEntryFnInfo);\n  std::string Name = CGM.getOpenMPRuntime().getName({\"omp_task_entry\", \"\"});\n  auto *TaskEntry = llvm::Function::Create(\n      TaskEntryTy, llvm::GlobalValue::InternalLinkage, Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), TaskEntry, TaskEntryFnInfo);\n  TaskEntry->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), KmpInt32Ty, TaskEntry, TaskEntryFnInfo, Args,\n                    Loc, Loc);\n\n  // TaskFunction(gtid, tt->task_data.part_id, &tt->privates, task_privates_map,\n  // tt,\n  // For taskloops:\n  // tt->task_data.lb, tt->task_data.ub, tt->task_data.st, tt->task_data.liter,\n  // tt->task_data.shareds);\n  llvm::Value *GtidParam = CGF.EmitLoadOfScalar(\n      CGF.GetAddrOfLocalVar(&GtidArg), /*Volatile=*/false, KmpInt32Ty, Loc);\n  LValue TDBase = CGF.EmitLoadOfPointerLValue(\n      CGF.GetAddrOfLocalVar(&TaskTypeArg),\n      KmpTaskTWithPrivatesPtrQTy->castAs<PointerType>());\n  const auto *KmpTaskTWithPrivatesQTyRD =\n      cast<RecordDecl>(KmpTaskTWithPrivatesQTy->getAsTagDecl());\n  LValue Base =\n      CGF.EmitLValueForField(TDBase, *KmpTaskTWithPrivatesQTyRD->field_begin());\n  const auto *KmpTaskTQTyRD = cast<RecordDecl>(KmpTaskTQTy->getAsTagDecl());\n  auto PartIdFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTPartId);\n  LValue PartIdLVal = CGF.EmitLValueForField(Base, *PartIdFI);\n  llvm::Value *PartidParam = PartIdLVal.getPointer(CGF);\n\n  auto SharedsFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTShareds);\n  LValue SharedsLVal = CGF.EmitLValueForField(Base, *SharedsFI);\n  llvm::Value *SharedsParam = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      CGF.EmitLoadOfScalar(SharedsLVal, Loc),\n      CGF.ConvertTypeForMem(SharedsPtrTy));\n\n  auto PrivatesFI = std::next(KmpTaskTWithPrivatesQTyRD->field_begin(), 1);\n  llvm::Value *PrivatesParam;\n  if (PrivatesFI != KmpTaskTWithPrivatesQTyRD->field_end()) {\n    LValue PrivatesLVal = CGF.EmitLValueForField(TDBase, *PrivatesFI);\n    PrivatesParam = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n        PrivatesLVal.getPointer(CGF), CGF.VoidPtrTy);\n  } else {\n    PrivatesParam = llvm::ConstantPointerNull::get(CGF.VoidPtrTy);\n  }\n\n  llvm::Value *CommonArgs[] = {GtidParam, PartidParam, PrivatesParam,\n                               TaskPrivatesMap,\n                               CGF.Builder\n                                   .CreatePointerBitCastOrAddrSpaceCast(\n                                       TDBase.getAddress(CGF), CGF.VoidPtrTy)\n                                   .getPointer()};\n  SmallVector<llvm::Value *, 16> CallArgs(std::begin(CommonArgs),\n                                          std::end(CommonArgs));\n  if (isOpenMPTaskLoopDirective(Kind)) {\n    auto LBFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTLowerBound);\n    LValue LBLVal = CGF.EmitLValueForField(Base, *LBFI);\n    llvm::Value *LBParam = CGF.EmitLoadOfScalar(LBLVal, Loc);\n    auto UBFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTUpperBound);\n    LValue UBLVal = CGF.EmitLValueForField(Base, *UBFI);\n    llvm::Value *UBParam = CGF.EmitLoadOfScalar(UBLVal, Loc);\n    auto StFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTStride);\n    LValue StLVal = CGF.EmitLValueForField(Base, *StFI);\n    llvm::Value *StParam = CGF.EmitLoadOfScalar(StLVal, Loc);\n    auto LIFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTLastIter);\n    LValue LILVal = CGF.EmitLValueForField(Base, *LIFI);\n    llvm::Value *LIParam = CGF.EmitLoadOfScalar(LILVal, Loc);\n    auto RFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTReductions);\n    LValue RLVal = CGF.EmitLValueForField(Base, *RFI);\n    llvm::Value *RParam = CGF.EmitLoadOfScalar(RLVal, Loc);\n    CallArgs.push_back(LBParam);\n    CallArgs.push_back(UBParam);\n    CallArgs.push_back(StParam);\n    CallArgs.push_back(LIParam);\n    CallArgs.push_back(RParam);\n  }\n  CallArgs.push_back(SharedsParam);\n\n  CGM.getOpenMPRuntime().emitOutlinedFunctionCall(CGF, Loc, TaskFunction,\n                                                  CallArgs);\n  CGF.EmitStoreThroughLValue(RValue::get(CGF.Builder.getInt32(/*C=*/0)),\n                             CGF.MakeAddrLValue(CGF.ReturnValue, KmpInt32Ty));\n  CGF.FinishFunction();\n  return TaskEntry;\n}\n\nstatic llvm::Value *emitDestructorsFunction(CodeGenModule &CGM,\n                                            SourceLocation Loc,\n                                            QualType KmpInt32Ty,\n                                            QualType KmpTaskTWithPrivatesPtrQTy,\n                                            QualType KmpTaskTWithPrivatesQTy) {\n  ASTContext &C = CGM.getContext();\n  FunctionArgList Args;\n  ImplicitParamDecl GtidArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, KmpInt32Ty,\n                            ImplicitParamDecl::Other);\n  ImplicitParamDecl TaskTypeArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                                KmpTaskTWithPrivatesPtrQTy.withRestrict(),\n                                ImplicitParamDecl::Other);\n  Args.push_back(&GtidArg);\n  Args.push_back(&TaskTypeArg);\n  const auto &DestructorFnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(KmpInt32Ty, Args);\n  llvm::FunctionType *DestructorFnTy =\n      CGM.getTypes().GetFunctionType(DestructorFnInfo);\n  std::string Name =\n      CGM.getOpenMPRuntime().getName({\"omp_task_destructor\", \"\"});\n  auto *DestructorFn =\n      llvm::Function::Create(DestructorFnTy, llvm::GlobalValue::InternalLinkage,\n                             Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), DestructorFn,\n                                    DestructorFnInfo);\n  DestructorFn->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), KmpInt32Ty, DestructorFn, DestructorFnInfo,\n                    Args, Loc, Loc);\n\n  LValue Base = CGF.EmitLoadOfPointerLValue(\n      CGF.GetAddrOfLocalVar(&TaskTypeArg),\n      KmpTaskTWithPrivatesPtrQTy->castAs<PointerType>());\n  const auto *KmpTaskTWithPrivatesQTyRD =\n      cast<RecordDecl>(KmpTaskTWithPrivatesQTy->getAsTagDecl());\n  auto FI = std::next(KmpTaskTWithPrivatesQTyRD->field_begin());\n  Base = CGF.EmitLValueForField(Base, *FI);\n  for (const auto *Field :\n       cast<RecordDecl>(FI->getType()->getAsTagDecl())->fields()) {\n    if (QualType::DestructionKind DtorKind =\n            Field->getType().isDestructedType()) {\n      LValue FieldLValue = CGF.EmitLValueForField(Base, Field);\n      CGF.pushDestroy(DtorKind, FieldLValue.getAddress(CGF), Field->getType());\n    }\n  }\n  CGF.FinishFunction();\n  return DestructorFn;\n}\n\n/// Emit a privates mapping function for correct handling of private and\n/// firstprivate variables.\n/// \\code\n/// void .omp_task_privates_map.(const .privates. *noalias privs, <ty1>\n/// **noalias priv1,...,  <tyn> **noalias privn) {\n///   *priv1 = &.privates.priv1;\n///   ...;\n///   *privn = &.privates.privn;\n/// }\n/// \\endcode\nstatic llvm::Value *\nemitTaskPrivateMappingFunction(CodeGenModule &CGM, SourceLocation Loc,\n                               const OMPTaskDataTy &Data, QualType PrivatesQTy,\n                               ArrayRef<PrivateDataTy> Privates) {\n  ASTContext &C = CGM.getContext();\n  FunctionArgList Args;\n  ImplicitParamDecl TaskPrivatesArg(\n      C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n      C.getPointerType(PrivatesQTy).withConst().withRestrict(),\n      ImplicitParamDecl::Other);\n  Args.push_back(&TaskPrivatesArg);\n  llvm::DenseMap<CanonicalDeclPtr<const VarDecl>, unsigned> PrivateVarsPos;\n  unsigned Counter = 1;\n  for (const Expr *E : Data.PrivateVars) {\n    Args.push_back(ImplicitParamDecl::Create(\n        C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n        C.getPointerType(C.getPointerType(E->getType()))\n            .withConst()\n            .withRestrict(),\n        ImplicitParamDecl::Other));\n    const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(E)->getDecl());\n    PrivateVarsPos[VD] = Counter;\n    ++Counter;\n  }\n  for (const Expr *E : Data.FirstprivateVars) {\n    Args.push_back(ImplicitParamDecl::Create(\n        C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n        C.getPointerType(C.getPointerType(E->getType()))\n            .withConst()\n            .withRestrict(),\n        ImplicitParamDecl::Other));\n    const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(E)->getDecl());\n    PrivateVarsPos[VD] = Counter;\n    ++Counter;\n  }\n  for (const Expr *E : Data.LastprivateVars) {\n    Args.push_back(ImplicitParamDecl::Create(\n        C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n        C.getPointerType(C.getPointerType(E->getType()))\n            .withConst()\n            .withRestrict(),\n        ImplicitParamDecl::Other));\n    const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(E)->getDecl());\n    PrivateVarsPos[VD] = Counter;\n    ++Counter;\n  }\n  for (const VarDecl *VD : Data.PrivateLocals) {\n    QualType Ty = VD->getType().getNonReferenceType();\n    if (VD->getType()->isLValueReferenceType())\n      Ty = C.getPointerType(Ty);\n    if (isAllocatableDecl(VD))\n      Ty = C.getPointerType(Ty);\n    Args.push_back(ImplicitParamDecl::Create(\n        C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n        C.getPointerType(C.getPointerType(Ty)).withConst().withRestrict(),\n        ImplicitParamDecl::Other));\n    PrivateVarsPos[VD] = Counter;\n    ++Counter;\n  }\n  const auto &TaskPrivatesMapFnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *TaskPrivatesMapTy =\n      CGM.getTypes().GetFunctionType(TaskPrivatesMapFnInfo);\n  std::string Name =\n      CGM.getOpenMPRuntime().getName({\"omp_task_privates_map\", \"\"});\n  auto *TaskPrivatesMap = llvm::Function::Create(\n      TaskPrivatesMapTy, llvm::GlobalValue::InternalLinkage, Name,\n      &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), TaskPrivatesMap,\n                                    TaskPrivatesMapFnInfo);\n  if (CGM.getLangOpts().Optimize) {\n    TaskPrivatesMap->removeFnAttr(llvm::Attribute::NoInline);\n    TaskPrivatesMap->removeFnAttr(llvm::Attribute::OptimizeNone);\n    TaskPrivatesMap->addFnAttr(llvm::Attribute::AlwaysInline);\n  }\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, TaskPrivatesMap,\n                    TaskPrivatesMapFnInfo, Args, Loc, Loc);\n\n  // *privi = &.privates.privi;\n  LValue Base = CGF.EmitLoadOfPointerLValue(\n      CGF.GetAddrOfLocalVar(&TaskPrivatesArg),\n      TaskPrivatesArg.getType()->castAs<PointerType>());\n  const auto *PrivatesQTyRD = cast<RecordDecl>(PrivatesQTy->getAsTagDecl());\n  Counter = 0;\n  for (const FieldDecl *Field : PrivatesQTyRD->fields()) {\n    LValue FieldLVal = CGF.EmitLValueForField(Base, Field);\n    const VarDecl *VD = Args[PrivateVarsPos[Privates[Counter].second.Original]];\n    LValue RefLVal =\n        CGF.MakeAddrLValue(CGF.GetAddrOfLocalVar(VD), VD->getType());\n    LValue RefLoadLVal = CGF.EmitLoadOfPointerLValue(\n        RefLVal.getAddress(CGF), RefLVal.getType()->castAs<PointerType>());\n    CGF.EmitStoreOfScalar(FieldLVal.getPointer(CGF), RefLoadLVal);\n    ++Counter;\n  }\n  CGF.FinishFunction();\n  return TaskPrivatesMap;\n}\n\n/// Emit initialization for private variables in task-based directives.\nstatic void emitPrivatesInit(CodeGenFunction &CGF,\n                             const OMPExecutableDirective &D,\n                             Address KmpTaskSharedsPtr, LValue TDBase,\n                             const RecordDecl *KmpTaskTWithPrivatesQTyRD,\n                             QualType SharedsTy, QualType SharedsPtrTy,\n                             const OMPTaskDataTy &Data,\n                             ArrayRef<PrivateDataTy> Privates, bool ForDup) {\n  ASTContext &C = CGF.getContext();\n  auto FI = std::next(KmpTaskTWithPrivatesQTyRD->field_begin());\n  LValue PrivatesBase = CGF.EmitLValueForField(TDBase, *FI);\n  OpenMPDirectiveKind Kind = isOpenMPTaskLoopDirective(D.getDirectiveKind())\n                                 ? OMPD_taskloop\n                                 : OMPD_task;\n  const CapturedStmt &CS = *D.getCapturedStmt(Kind);\n  CodeGenFunction::CGCapturedStmtInfo CapturesInfo(CS);\n  LValue SrcBase;\n  bool IsTargetTask =\n      isOpenMPTargetDataManagementDirective(D.getDirectiveKind()) ||\n      isOpenMPTargetExecutionDirective(D.getDirectiveKind());\n  // For target-based directives skip 4 firstprivate arrays BasePointersArray,\n  // PointersArray, SizesArray, and MappersArray. The original variables for\n  // these arrays are not captured and we get their addresses explicitly.\n  if ((!IsTargetTask && !Data.FirstprivateVars.empty() && ForDup) ||\n      (IsTargetTask && KmpTaskSharedsPtr.isValid())) {\n    SrcBase = CGF.MakeAddrLValue(\n        CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n            KmpTaskSharedsPtr, CGF.ConvertTypeForMem(SharedsPtrTy)),\n        SharedsTy);\n  }\n  FI = cast<RecordDecl>(FI->getType()->getAsTagDecl())->field_begin();\n  for (const PrivateDataTy &Pair : Privates) {\n    // Do not initialize private locals.\n    if (Pair.second.isLocalPrivate()) {\n      ++FI;\n      continue;\n    }\n    const VarDecl *VD = Pair.second.PrivateCopy;\n    const Expr *Init = VD->getAnyInitializer();\n    if (Init && (!ForDup || (isa<CXXConstructExpr>(Init) &&\n                             !CGF.isTrivialInitializer(Init)))) {\n      LValue PrivateLValue = CGF.EmitLValueForField(PrivatesBase, *FI);\n      if (const VarDecl *Elem = Pair.second.PrivateElemInit) {\n        const VarDecl *OriginalVD = Pair.second.Original;\n        // Check if the variable is the target-based BasePointersArray,\n        // PointersArray, SizesArray, or MappersArray.\n        LValue SharedRefLValue;\n        QualType Type = PrivateLValue.getType();\n        const FieldDecl *SharedField = CapturesInfo.lookup(OriginalVD);\n        if (IsTargetTask && !SharedField) {\n          assert(isa<ImplicitParamDecl>(OriginalVD) &&\n                 isa<CapturedDecl>(OriginalVD->getDeclContext()) &&\n                 cast<CapturedDecl>(OriginalVD->getDeclContext())\n                         ->getNumParams() == 0 &&\n                 isa<TranslationUnitDecl>(\n                     cast<CapturedDecl>(OriginalVD->getDeclContext())\n                         ->getDeclContext()) &&\n                 \"Expected artificial target data variable.\");\n          SharedRefLValue =\n              CGF.MakeAddrLValue(CGF.GetAddrOfLocalVar(OriginalVD), Type);\n        } else if (ForDup) {\n          SharedRefLValue = CGF.EmitLValueForField(SrcBase, SharedField);\n          SharedRefLValue = CGF.MakeAddrLValue(\n              Address(SharedRefLValue.getPointer(CGF),\n                      C.getDeclAlign(OriginalVD)),\n              SharedRefLValue.getType(), LValueBaseInfo(AlignmentSource::Decl),\n              SharedRefLValue.getTBAAInfo());\n        } else if (CGF.LambdaCaptureFields.count(\n                       Pair.second.Original->getCanonicalDecl()) > 0 ||\n                   dyn_cast_or_null<BlockDecl>(CGF.CurCodeDecl)) {\n          SharedRefLValue = CGF.EmitLValue(Pair.second.OriginalRef);\n        } else {\n          // Processing for implicitly captured variables.\n          InlinedOpenMPRegionRAII Region(\n              CGF, [](CodeGenFunction &, PrePostActionTy &) {}, OMPD_unknown,\n              /*HasCancel=*/false);\n          SharedRefLValue = CGF.EmitLValue(Pair.second.OriginalRef);\n        }\n        if (Type->isArrayType()) {\n          // Initialize firstprivate array.\n          if (!isa<CXXConstructExpr>(Init) || CGF.isTrivialInitializer(Init)) {\n            // Perform simple memcpy.\n            CGF.EmitAggregateAssign(PrivateLValue, SharedRefLValue, Type);\n          } else {\n            // Initialize firstprivate array using element-by-element\n            // initialization.\n            CGF.EmitOMPAggregateAssign(\n                PrivateLValue.getAddress(CGF), SharedRefLValue.getAddress(CGF),\n                Type,\n                [&CGF, Elem, Init, &CapturesInfo](Address DestElement,\n                                                  Address SrcElement) {\n                  // Clean up any temporaries needed by the initialization.\n                  CodeGenFunction::OMPPrivateScope InitScope(CGF);\n                  InitScope.addPrivate(\n                      Elem, [SrcElement]() -> Address { return SrcElement; });\n                  (void)InitScope.Privatize();\n                  // Emit initialization for single element.\n                  CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(\n                      CGF, &CapturesInfo);\n                  CGF.EmitAnyExprToMem(Init, DestElement,\n                                       Init->getType().getQualifiers(),\n                                       /*IsInitializer=*/false);\n                });\n          }\n        } else {\n          CodeGenFunction::OMPPrivateScope InitScope(CGF);\n          InitScope.addPrivate(Elem, [SharedRefLValue, &CGF]() -> Address {\n            return SharedRefLValue.getAddress(CGF);\n          });\n          (void)InitScope.Privatize();\n          CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CapturesInfo);\n          CGF.EmitExprAsInit(Init, VD, PrivateLValue,\n                             /*capturedByInit=*/false);\n        }\n      } else {\n        CGF.EmitExprAsInit(Init, VD, PrivateLValue, /*capturedByInit=*/false);\n      }\n    }\n    ++FI;\n  }\n}\n\n/// Check if duplication function is required for taskloops.\nstatic bool checkInitIsRequired(CodeGenFunction &CGF,\n                                ArrayRef<PrivateDataTy> Privates) {\n  bool InitRequired = false;\n  for (const PrivateDataTy &Pair : Privates) {\n    if (Pair.second.isLocalPrivate())\n      continue;\n    const VarDecl *VD = Pair.second.PrivateCopy;\n    const Expr *Init = VD->getAnyInitializer();\n    InitRequired = InitRequired || (Init && isa<CXXConstructExpr>(Init) &&\n                                    !CGF.isTrivialInitializer(Init));\n    if (InitRequired)\n      break;\n  }\n  return InitRequired;\n}\n\n\n/// Emit task_dup function (for initialization of\n/// private/firstprivate/lastprivate vars and last_iter flag)\n/// \\code\n/// void __task_dup_entry(kmp_task_t *task_dst, const kmp_task_t *task_src, int\n/// lastpriv) {\n/// // setup lastprivate flag\n///    task_dst->last = lastpriv;\n/// // could be constructor calls here...\n/// }\n/// \\endcode\nstatic llvm::Value *\nemitTaskDupFunction(CodeGenModule &CGM, SourceLocation Loc,\n                    const OMPExecutableDirective &D,\n                    QualType KmpTaskTWithPrivatesPtrQTy,\n                    const RecordDecl *KmpTaskTWithPrivatesQTyRD,\n                    const RecordDecl *KmpTaskTQTyRD, QualType SharedsTy,\n                    QualType SharedsPtrTy, const OMPTaskDataTy &Data,\n                    ArrayRef<PrivateDataTy> Privates, bool WithLastIter) {\n  ASTContext &C = CGM.getContext();\n  FunctionArgList Args;\n  ImplicitParamDecl DstArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                           KmpTaskTWithPrivatesPtrQTy,\n                           ImplicitParamDecl::Other);\n  ImplicitParamDecl SrcArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                           KmpTaskTWithPrivatesPtrQTy,\n                           ImplicitParamDecl::Other);\n  ImplicitParamDecl LastprivArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.IntTy,\n                                ImplicitParamDecl::Other);\n  Args.push_back(&DstArg);\n  Args.push_back(&SrcArg);\n  Args.push_back(&LastprivArg);\n  const auto &TaskDupFnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *TaskDupTy = CGM.getTypes().GetFunctionType(TaskDupFnInfo);\n  std::string Name = CGM.getOpenMPRuntime().getName({\"omp_task_dup\", \"\"});\n  auto *TaskDup = llvm::Function::Create(\n      TaskDupTy, llvm::GlobalValue::InternalLinkage, Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), TaskDup, TaskDupFnInfo);\n  TaskDup->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, TaskDup, TaskDupFnInfo, Args, Loc,\n                    Loc);\n\n  LValue TDBase = CGF.EmitLoadOfPointerLValue(\n      CGF.GetAddrOfLocalVar(&DstArg),\n      KmpTaskTWithPrivatesPtrQTy->castAs<PointerType>());\n  // task_dst->liter = lastpriv;\n  if (WithLastIter) {\n    auto LIFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTLastIter);\n    LValue Base = CGF.EmitLValueForField(\n        TDBase, *KmpTaskTWithPrivatesQTyRD->field_begin());\n    LValue LILVal = CGF.EmitLValueForField(Base, *LIFI);\n    llvm::Value *Lastpriv = CGF.EmitLoadOfScalar(\n        CGF.GetAddrOfLocalVar(&LastprivArg), /*Volatile=*/false, C.IntTy, Loc);\n    CGF.EmitStoreOfScalar(Lastpriv, LILVal);\n  }\n\n  // Emit initial values for private copies (if any).\n  assert(!Privates.empty());\n  Address KmpTaskSharedsPtr = Address::invalid();\n  if (!Data.FirstprivateVars.empty()) {\n    LValue TDBase = CGF.EmitLoadOfPointerLValue(\n        CGF.GetAddrOfLocalVar(&SrcArg),\n        KmpTaskTWithPrivatesPtrQTy->castAs<PointerType>());\n    LValue Base = CGF.EmitLValueForField(\n        TDBase, *KmpTaskTWithPrivatesQTyRD->field_begin());\n    KmpTaskSharedsPtr = Address(\n        CGF.EmitLoadOfScalar(CGF.EmitLValueForField(\n                                 Base, *std::next(KmpTaskTQTyRD->field_begin(),\n                                                  KmpTaskTShareds)),\n                             Loc),\n        CGM.getNaturalTypeAlignment(SharedsTy));\n  }\n  emitPrivatesInit(CGF, D, KmpTaskSharedsPtr, TDBase, KmpTaskTWithPrivatesQTyRD,\n                   SharedsTy, SharedsPtrTy, Data, Privates, /*ForDup=*/true);\n  CGF.FinishFunction();\n  return TaskDup;\n}\n\n/// Checks if destructor function is required to be generated.\n/// \\return true if cleanups are required, false otherwise.\nstatic bool\ncheckDestructorsRequired(const RecordDecl *KmpTaskTWithPrivatesQTyRD,\n                         ArrayRef<PrivateDataTy> Privates) {\n  for (const PrivateDataTy &P : Privates) {\n    if (P.second.isLocalPrivate())\n      continue;\n    QualType Ty = P.second.Original->getType().getNonReferenceType();\n    if (Ty.isDestructedType())\n      return true;\n  }\n  return false;\n}\n\nnamespace {\n/// Loop generator for OpenMP iterator expression.\nclass OMPIteratorGeneratorScope final\n    : public CodeGenFunction::OMPPrivateScope {\n  CodeGenFunction &CGF;\n  const OMPIteratorExpr *E = nullptr;\n  SmallVector<CodeGenFunction::JumpDest, 4> ContDests;\n  SmallVector<CodeGenFunction::JumpDest, 4> ExitDests;\n  OMPIteratorGeneratorScope() = delete;\n  OMPIteratorGeneratorScope(OMPIteratorGeneratorScope &) = delete;\n\npublic:\n  OMPIteratorGeneratorScope(CodeGenFunction &CGF, const OMPIteratorExpr *E)\n      : CodeGenFunction::OMPPrivateScope(CGF), CGF(CGF), E(E) {\n    if (!E)\n      return;\n    SmallVector<llvm::Value *, 4> Uppers;\n    for (unsigned I = 0, End = E->numOfIterators(); I < End; ++I) {\n      Uppers.push_back(CGF.EmitScalarExpr(E->getHelper(I).Upper));\n      const auto *VD = cast<VarDecl>(E->getIteratorDecl(I));\n      addPrivate(VD, [&CGF, VD]() {\n        return CGF.CreateMemTemp(VD->getType(), VD->getName());\n      });\n      const OMPIteratorHelperData &HelperData = E->getHelper(I);\n      addPrivate(HelperData.CounterVD, [&CGF, &HelperData]() {\n        return CGF.CreateMemTemp(HelperData.CounterVD->getType(),\n                                 \"counter.addr\");\n      });\n    }\n    Privatize();\n\n    for (unsigned I = 0, End = E->numOfIterators(); I < End; ++I) {\n      const OMPIteratorHelperData &HelperData = E->getHelper(I);\n      LValue CLVal =\n          CGF.MakeAddrLValue(CGF.GetAddrOfLocalVar(HelperData.CounterVD),\n                             HelperData.CounterVD->getType());\n      // Counter = 0;\n      CGF.EmitStoreOfScalar(\n          llvm::ConstantInt::get(CLVal.getAddress(CGF).getElementType(), 0),\n          CLVal);\n      CodeGenFunction::JumpDest &ContDest =\n          ContDests.emplace_back(CGF.getJumpDestInCurrentScope(\"iter.cont\"));\n      CodeGenFunction::JumpDest &ExitDest =\n          ExitDests.emplace_back(CGF.getJumpDestInCurrentScope(\"iter.exit\"));\n      // N = <number-of_iterations>;\n      llvm::Value *N = Uppers[I];\n      // cont:\n      // if (Counter < N) goto body; else goto exit;\n      CGF.EmitBlock(ContDest.getBlock());\n      auto *CVal =\n          CGF.EmitLoadOfScalar(CLVal, HelperData.CounterVD->getLocation());\n      llvm::Value *Cmp =\n          HelperData.CounterVD->getType()->isSignedIntegerOrEnumerationType()\n              ? CGF.Builder.CreateICmpSLT(CVal, N)\n              : CGF.Builder.CreateICmpULT(CVal, N);\n      llvm::BasicBlock *BodyBB = CGF.createBasicBlock(\"iter.body\");\n      CGF.Builder.CreateCondBr(Cmp, BodyBB, ExitDest.getBlock());\n      // body:\n      CGF.EmitBlock(BodyBB);\n      // Iteri = Begini + Counter * Stepi;\n      CGF.EmitIgnoredExpr(HelperData.Update);\n    }\n  }\n  ~OMPIteratorGeneratorScope() {\n    if (!E)\n      return;\n    for (unsigned I = E->numOfIterators(); I > 0; --I) {\n      // Counter = Counter + 1;\n      const OMPIteratorHelperData &HelperData = E->getHelper(I - 1);\n      CGF.EmitIgnoredExpr(HelperData.CounterUpdate);\n      // goto cont;\n      CGF.EmitBranchThroughCleanup(ContDests[I - 1]);\n      // exit:\n      CGF.EmitBlock(ExitDests[I - 1].getBlock(), /*IsFinished=*/I == 1);\n    }\n  }\n};\n} // namespace\n\nstatic std::pair<llvm::Value *, llvm::Value *>\ngetPointerAndSize(CodeGenFunction &CGF, const Expr *E) {\n  const auto *OASE = dyn_cast<OMPArrayShapingExpr>(E);\n  llvm::Value *Addr;\n  if (OASE) {\n    const Expr *Base = OASE->getBase();\n    Addr = CGF.EmitScalarExpr(Base);\n  } else {\n    Addr = CGF.EmitLValue(E).getPointer(CGF);\n  }\n  llvm::Value *SizeVal;\n  QualType Ty = E->getType();\n  if (OASE) {\n    SizeVal = CGF.getTypeSize(OASE->getBase()->getType()->getPointeeType());\n    for (const Expr *SE : OASE->getDimensions()) {\n      llvm::Value *Sz = CGF.EmitScalarExpr(SE);\n      Sz = CGF.EmitScalarConversion(\n          Sz, SE->getType(), CGF.getContext().getSizeType(), SE->getExprLoc());\n      SizeVal = CGF.Builder.CreateNUWMul(SizeVal, Sz);\n    }\n  } else if (const auto *ASE =\n                 dyn_cast<OMPArraySectionExpr>(E->IgnoreParenImpCasts())) {\n    LValue UpAddrLVal =\n        CGF.EmitOMPArraySectionExpr(ASE, /*IsLowerBound=*/false);\n    llvm::Value *UpAddr =\n        CGF.Builder.CreateConstGEP1_32(UpAddrLVal.getPointer(CGF), /*Idx0=*/1);\n    llvm::Value *LowIntPtr = CGF.Builder.CreatePtrToInt(Addr, CGF.SizeTy);\n    llvm::Value *UpIntPtr = CGF.Builder.CreatePtrToInt(UpAddr, CGF.SizeTy);\n    SizeVal = CGF.Builder.CreateNUWSub(UpIntPtr, LowIntPtr);\n  } else {\n    SizeVal = CGF.getTypeSize(Ty);\n  }\n  return std::make_pair(Addr, SizeVal);\n}\n\n/// Builds kmp_depend_info, if it is not built yet, and builds flags type.\nstatic void getKmpAffinityType(ASTContext &C, QualType &KmpTaskAffinityInfoTy) {\n  QualType FlagsTy = C.getIntTypeForBitwidth(32, /*Signed=*/false);\n  if (KmpTaskAffinityInfoTy.isNull()) {\n    RecordDecl *KmpAffinityInfoRD =\n        C.buildImplicitRecord(\"kmp_task_affinity_info_t\");\n    KmpAffinityInfoRD->startDefinition();\n    addFieldToRecordDecl(C, KmpAffinityInfoRD, C.getIntPtrType());\n    addFieldToRecordDecl(C, KmpAffinityInfoRD, C.getSizeType());\n    addFieldToRecordDecl(C, KmpAffinityInfoRD, FlagsTy);\n    KmpAffinityInfoRD->completeDefinition();\n    KmpTaskAffinityInfoTy = C.getRecordType(KmpAffinityInfoRD);\n  }\n}\n\nCGOpenMPRuntime::TaskResultTy\nCGOpenMPRuntime::emitTaskInit(CodeGenFunction &CGF, SourceLocation Loc,\n                              const OMPExecutableDirective &D,\n                              llvm::Function *TaskFunction, QualType SharedsTy,\n                              Address Shareds, const OMPTaskDataTy &Data) {\n  ASTContext &C = CGM.getContext();\n  llvm::SmallVector<PrivateDataTy, 4> Privates;\n  // Aggregate privates and sort them by the alignment.\n  const auto *I = Data.PrivateCopies.begin();\n  for (const Expr *E : Data.PrivateVars) {\n    const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(E)->getDecl());\n    Privates.emplace_back(\n        C.getDeclAlign(VD),\n        PrivateHelpersTy(E, VD, cast<VarDecl>(cast<DeclRefExpr>(*I)->getDecl()),\n                         /*PrivateElemInit=*/nullptr));\n    ++I;\n  }\n  I = Data.FirstprivateCopies.begin();\n  const auto *IElemInitRef = Data.FirstprivateInits.begin();\n  for (const Expr *E : Data.FirstprivateVars) {\n    const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(E)->getDecl());\n    Privates.emplace_back(\n        C.getDeclAlign(VD),\n        PrivateHelpersTy(\n            E, VD, cast<VarDecl>(cast<DeclRefExpr>(*I)->getDecl()),\n            cast<VarDecl>(cast<DeclRefExpr>(*IElemInitRef)->getDecl())));\n    ++I;\n    ++IElemInitRef;\n  }\n  I = Data.LastprivateCopies.begin();\n  for (const Expr *E : Data.LastprivateVars) {\n    const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(E)->getDecl());\n    Privates.emplace_back(\n        C.getDeclAlign(VD),\n        PrivateHelpersTy(E, VD, cast<VarDecl>(cast<DeclRefExpr>(*I)->getDecl()),\n                         /*PrivateElemInit=*/nullptr));\n    ++I;\n  }\n  for (const VarDecl *VD : Data.PrivateLocals) {\n    if (isAllocatableDecl(VD))\n      Privates.emplace_back(CGM.getPointerAlign(), PrivateHelpersTy(VD));\n    else\n      Privates.emplace_back(C.getDeclAlign(VD), PrivateHelpersTy(VD));\n  }\n  llvm::stable_sort(Privates,\n                    [](const PrivateDataTy &L, const PrivateDataTy &R) {\n                      return L.first > R.first;\n                    });\n  QualType KmpInt32Ty = C.getIntTypeForBitwidth(/*DestWidth=*/32, /*Signed=*/1);\n  // Build type kmp_routine_entry_t (if not built yet).\n  emitKmpRoutineEntryT(KmpInt32Ty);\n  // Build type kmp_task_t (if not built yet).\n  if (isOpenMPTaskLoopDirective(D.getDirectiveKind())) {\n    if (SavedKmpTaskloopTQTy.isNull()) {\n      SavedKmpTaskloopTQTy = C.getRecordType(createKmpTaskTRecordDecl(\n          CGM, D.getDirectiveKind(), KmpInt32Ty, KmpRoutineEntryPtrQTy));\n    }\n    KmpTaskTQTy = SavedKmpTaskloopTQTy;\n  } else {\n    assert((D.getDirectiveKind() == OMPD_task ||\n            isOpenMPTargetExecutionDirective(D.getDirectiveKind()) ||\n            isOpenMPTargetDataManagementDirective(D.getDirectiveKind())) &&\n           \"Expected taskloop, task or target directive\");\n    if (SavedKmpTaskTQTy.isNull()) {\n      SavedKmpTaskTQTy = C.getRecordType(createKmpTaskTRecordDecl(\n          CGM, D.getDirectiveKind(), KmpInt32Ty, KmpRoutineEntryPtrQTy));\n    }\n    KmpTaskTQTy = SavedKmpTaskTQTy;\n  }\n  const auto *KmpTaskTQTyRD = cast<RecordDecl>(KmpTaskTQTy->getAsTagDecl());\n  // Build particular struct kmp_task_t for the given task.\n  const RecordDecl *KmpTaskTWithPrivatesQTyRD =\n      createKmpTaskTWithPrivatesRecordDecl(CGM, KmpTaskTQTy, Privates);\n  QualType KmpTaskTWithPrivatesQTy = C.getRecordType(KmpTaskTWithPrivatesQTyRD);\n  QualType KmpTaskTWithPrivatesPtrQTy =\n      C.getPointerType(KmpTaskTWithPrivatesQTy);\n  llvm::Type *KmpTaskTWithPrivatesTy = CGF.ConvertType(KmpTaskTWithPrivatesQTy);\n  llvm::Type *KmpTaskTWithPrivatesPtrTy =\n      KmpTaskTWithPrivatesTy->getPointerTo();\n  llvm::Value *KmpTaskTWithPrivatesTySize =\n      CGF.getTypeSize(KmpTaskTWithPrivatesQTy);\n  QualType SharedsPtrTy = C.getPointerType(SharedsTy);\n\n  // Emit initial values for private copies (if any).\n  llvm::Value *TaskPrivatesMap = nullptr;\n  llvm::Type *TaskPrivatesMapTy =\n      std::next(TaskFunction->arg_begin(), 3)->getType();\n  if (!Privates.empty()) {\n    auto FI = std::next(KmpTaskTWithPrivatesQTyRD->field_begin());\n    TaskPrivatesMap =\n        emitTaskPrivateMappingFunction(CGM, Loc, Data, FI->getType(), Privates);\n    TaskPrivatesMap = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n        TaskPrivatesMap, TaskPrivatesMapTy);\n  } else {\n    TaskPrivatesMap = llvm::ConstantPointerNull::get(\n        cast<llvm::PointerType>(TaskPrivatesMapTy));\n  }\n  // Build a proxy function kmp_int32 .omp_task_entry.(kmp_int32 gtid,\n  // kmp_task_t *tt);\n  llvm::Function *TaskEntry = emitProxyTaskFunction(\n      CGM, Loc, D.getDirectiveKind(), KmpInt32Ty, KmpTaskTWithPrivatesPtrQTy,\n      KmpTaskTWithPrivatesQTy, KmpTaskTQTy, SharedsPtrTy, TaskFunction,\n      TaskPrivatesMap);\n\n  // Build call kmp_task_t * __kmpc_omp_task_alloc(ident_t *, kmp_int32 gtid,\n  // kmp_int32 flags, size_t sizeof_kmp_task_t, size_t sizeof_shareds,\n  // kmp_routine_entry_t *task_entry);\n  // Task flags. Format is taken from\n  // https://github.com/llvm/llvm-project/blob/main/openmp/runtime/src/kmp.h,\n  // description of kmp_tasking_flags struct.\n  enum {\n    TiedFlag = 0x1,\n    FinalFlag = 0x2,\n    DestructorsFlag = 0x8,\n    PriorityFlag = 0x20,\n    DetachableFlag = 0x40,\n  };\n  unsigned Flags = Data.Tied ? TiedFlag : 0;\n  bool NeedsCleanup = false;\n  if (!Privates.empty()) {\n    NeedsCleanup =\n        checkDestructorsRequired(KmpTaskTWithPrivatesQTyRD, Privates);\n    if (NeedsCleanup)\n      Flags = Flags | DestructorsFlag;\n  }\n  if (Data.Priority.getInt())\n    Flags = Flags | PriorityFlag;\n  if (D.hasClausesOfKind<OMPDetachClause>())\n    Flags = Flags | DetachableFlag;\n  llvm::Value *TaskFlags =\n      Data.Final.getPointer()\n          ? CGF.Builder.CreateSelect(Data.Final.getPointer(),\n                                     CGF.Builder.getInt32(FinalFlag),\n                                     CGF.Builder.getInt32(/*C=*/0))\n          : CGF.Builder.getInt32(Data.Final.getInt() ? FinalFlag : 0);\n  TaskFlags = CGF.Builder.CreateOr(TaskFlags, CGF.Builder.getInt32(Flags));\n  llvm::Value *SharedsSize = CGM.getSize(C.getTypeSizeInChars(SharedsTy));\n  SmallVector<llvm::Value *, 8> AllocArgs = {emitUpdateLocation(CGF, Loc),\n      getThreadID(CGF, Loc), TaskFlags, KmpTaskTWithPrivatesTySize,\n      SharedsSize, CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          TaskEntry, KmpRoutineEntryPtrTy)};\n  llvm::Value *NewTask;\n  if (D.hasClausesOfKind<OMPNowaitClause>()) {\n    // Check if we have any device clause associated with the directive.\n    const Expr *Device = nullptr;\n    if (auto *C = D.getSingleClause<OMPDeviceClause>())\n      Device = C->getDevice();\n    // Emit device ID if any otherwise use default value.\n    llvm::Value *DeviceID;\n    if (Device)\n      DeviceID = CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(Device),\n                                           CGF.Int64Ty, /*isSigned=*/true);\n    else\n      DeviceID = CGF.Builder.getInt64(OMP_DEVICEID_UNDEF);\n    AllocArgs.push_back(DeviceID);\n    NewTask = CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(\n            CGM.getModule(), OMPRTL___kmpc_omp_target_task_alloc),\n        AllocArgs);\n  } else {\n    NewTask =\n        CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                                CGM.getModule(), OMPRTL___kmpc_omp_task_alloc),\n                            AllocArgs);\n  }\n  // Emit detach clause initialization.\n  // evt = (typeof(evt))__kmpc_task_allow_completion_event(loc, tid,\n  // task_descriptor);\n  if (const auto *DC = D.getSingleClause<OMPDetachClause>()) {\n    const Expr *Evt = DC->getEventHandler()->IgnoreParenImpCasts();\n    LValue EvtLVal = CGF.EmitLValue(Evt);\n\n    // Build kmp_event_t *__kmpc_task_allow_completion_event(ident_t *loc_ref,\n    // int gtid, kmp_task_t *task);\n    llvm::Value *Loc = emitUpdateLocation(CGF, DC->getBeginLoc());\n    llvm::Value *Tid = getThreadID(CGF, DC->getBeginLoc());\n    Tid = CGF.Builder.CreateIntCast(Tid, CGF.IntTy, /*isSigned=*/false);\n    llvm::Value *EvtVal = CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(\n            CGM.getModule(), OMPRTL___kmpc_task_allow_completion_event),\n        {Loc, Tid, NewTask});\n    EvtVal = CGF.EmitScalarConversion(EvtVal, C.VoidPtrTy, Evt->getType(),\n                                      Evt->getExprLoc());\n    CGF.EmitStoreOfScalar(EvtVal, EvtLVal);\n  }\n  // Process affinity clauses.\n  if (D.hasClausesOfKind<OMPAffinityClause>()) {\n    // Process list of affinity data.\n    ASTContext &C = CGM.getContext();\n    Address AffinitiesArray = Address::invalid();\n    // Calculate number of elements to form the array of affinity data.\n    llvm::Value *NumOfElements = nullptr;\n    unsigned NumAffinities = 0;\n    for (const auto *C : D.getClausesOfKind<OMPAffinityClause>()) {\n      if (const Expr *Modifier = C->getModifier()) {\n        const auto *IE = cast<OMPIteratorExpr>(Modifier->IgnoreParenImpCasts());\n        for (unsigned I = 0, E = IE->numOfIterators(); I < E; ++I) {\n          llvm::Value *Sz = CGF.EmitScalarExpr(IE->getHelper(I).Upper);\n          Sz = CGF.Builder.CreateIntCast(Sz, CGF.SizeTy, /*isSigned=*/false);\n          NumOfElements =\n              NumOfElements ? CGF.Builder.CreateNUWMul(NumOfElements, Sz) : Sz;\n        }\n      } else {\n        NumAffinities += C->varlist_size();\n      }\n    }\n    getKmpAffinityType(CGM.getContext(), KmpTaskAffinityInfoTy);\n    // Fields ids in kmp_task_affinity_info record.\n    enum RTLAffinityInfoFieldsTy { BaseAddr, Len, Flags };\n\n    QualType KmpTaskAffinityInfoArrayTy;\n    if (NumOfElements) {\n      NumOfElements = CGF.Builder.CreateNUWAdd(\n          llvm::ConstantInt::get(CGF.SizeTy, NumAffinities), NumOfElements);\n      OpaqueValueExpr OVE(\n          Loc,\n          C.getIntTypeForBitwidth(C.getTypeSize(C.getSizeType()), /*Signed=*/0),\n          VK_RValue);\n      CodeGenFunction::OpaqueValueMapping OpaqueMap(CGF, &OVE,\n                                                    RValue::get(NumOfElements));\n      KmpTaskAffinityInfoArrayTy =\n          C.getVariableArrayType(KmpTaskAffinityInfoTy, &OVE, ArrayType::Normal,\n                                 /*IndexTypeQuals=*/0, SourceRange(Loc, Loc));\n      // Properly emit variable-sized array.\n      auto *PD = ImplicitParamDecl::Create(C, KmpTaskAffinityInfoArrayTy,\n                                           ImplicitParamDecl::Other);\n      CGF.EmitVarDecl(*PD);\n      AffinitiesArray = CGF.GetAddrOfLocalVar(PD);\n      NumOfElements = CGF.Builder.CreateIntCast(NumOfElements, CGF.Int32Ty,\n                                                /*isSigned=*/false);\n    } else {\n      KmpTaskAffinityInfoArrayTy = C.getConstantArrayType(\n          KmpTaskAffinityInfoTy,\n          llvm::APInt(C.getTypeSize(C.getSizeType()), NumAffinities), nullptr,\n          ArrayType::Normal, /*IndexTypeQuals=*/0);\n      AffinitiesArray =\n          CGF.CreateMemTemp(KmpTaskAffinityInfoArrayTy, \".affs.arr.addr\");\n      AffinitiesArray = CGF.Builder.CreateConstArrayGEP(AffinitiesArray, 0);\n      NumOfElements = llvm::ConstantInt::get(CGM.Int32Ty, NumAffinities,\n                                             /*isSigned=*/false);\n    }\n\n    const auto *KmpAffinityInfoRD = KmpTaskAffinityInfoTy->getAsRecordDecl();\n    // Fill array by elements without iterators.\n    unsigned Pos = 0;\n    bool HasIterator = false;\n    for (const auto *C : D.getClausesOfKind<OMPAffinityClause>()) {\n      if (C->getModifier()) {\n        HasIterator = true;\n        continue;\n      }\n      for (const Expr *E : C->varlists()) {\n        llvm::Value *Addr;\n        llvm::Value *Size;\n        std::tie(Addr, Size) = getPointerAndSize(CGF, E);\n        LValue Base =\n            CGF.MakeAddrLValue(CGF.Builder.CreateConstGEP(AffinitiesArray, Pos),\n                               KmpTaskAffinityInfoTy);\n        // affs[i].base_addr = &<Affinities[i].second>;\n        LValue BaseAddrLVal = CGF.EmitLValueForField(\n            Base, *std::next(KmpAffinityInfoRD->field_begin(), BaseAddr));\n        CGF.EmitStoreOfScalar(CGF.Builder.CreatePtrToInt(Addr, CGF.IntPtrTy),\n                              BaseAddrLVal);\n        // affs[i].len = sizeof(<Affinities[i].second>);\n        LValue LenLVal = CGF.EmitLValueForField(\n            Base, *std::next(KmpAffinityInfoRD->field_begin(), Len));\n        CGF.EmitStoreOfScalar(Size, LenLVal);\n        ++Pos;\n      }\n    }\n    LValue PosLVal;\n    if (HasIterator) {\n      PosLVal = CGF.MakeAddrLValue(\n          CGF.CreateMemTemp(C.getSizeType(), \"affs.counter.addr\"),\n          C.getSizeType());\n      CGF.EmitStoreOfScalar(llvm::ConstantInt::get(CGF.SizeTy, Pos), PosLVal);\n    }\n    // Process elements with iterators.\n    for (const auto *C : D.getClausesOfKind<OMPAffinityClause>()) {\n      const Expr *Modifier = C->getModifier();\n      if (!Modifier)\n        continue;\n      OMPIteratorGeneratorScope IteratorScope(\n          CGF, cast_or_null<OMPIteratorExpr>(Modifier->IgnoreParenImpCasts()));\n      for (const Expr *E : C->varlists()) {\n        llvm::Value *Addr;\n        llvm::Value *Size;\n        std::tie(Addr, Size) = getPointerAndSize(CGF, E);\n        llvm::Value *Idx = CGF.EmitLoadOfScalar(PosLVal, E->getExprLoc());\n        LValue Base = CGF.MakeAddrLValue(\n            Address(CGF.Builder.CreateGEP(AffinitiesArray.getPointer(), Idx),\n                    AffinitiesArray.getAlignment()),\n            KmpTaskAffinityInfoTy);\n        // affs[i].base_addr = &<Affinities[i].second>;\n        LValue BaseAddrLVal = CGF.EmitLValueForField(\n            Base, *std::next(KmpAffinityInfoRD->field_begin(), BaseAddr));\n        CGF.EmitStoreOfScalar(CGF.Builder.CreatePtrToInt(Addr, CGF.IntPtrTy),\n                              BaseAddrLVal);\n        // affs[i].len = sizeof(<Affinities[i].second>);\n        LValue LenLVal = CGF.EmitLValueForField(\n            Base, *std::next(KmpAffinityInfoRD->field_begin(), Len));\n        CGF.EmitStoreOfScalar(Size, LenLVal);\n        Idx = CGF.Builder.CreateNUWAdd(\n            Idx, llvm::ConstantInt::get(Idx->getType(), 1));\n        CGF.EmitStoreOfScalar(Idx, PosLVal);\n      }\n    }\n    // Call to kmp_int32 __kmpc_omp_reg_task_with_affinity(ident_t *loc_ref,\n    // kmp_int32 gtid, kmp_task_t *new_task, kmp_int32\n    // naffins, kmp_task_affinity_info_t *affin_list);\n    llvm::Value *LocRef = emitUpdateLocation(CGF, Loc);\n    llvm::Value *GTid = getThreadID(CGF, Loc);\n    llvm::Value *AffinListPtr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n        AffinitiesArray.getPointer(), CGM.VoidPtrTy);\n    // FIXME: Emit the function and ignore its result for now unless the\n    // runtime function is properly implemented.\n    (void)CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(\n            CGM.getModule(), OMPRTL___kmpc_omp_reg_task_with_affinity),\n        {LocRef, GTid, NewTask, NumOfElements, AffinListPtr});\n  }\n  llvm::Value *NewTaskNewTaskTTy =\n      CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          NewTask, KmpTaskTWithPrivatesPtrTy);\n  LValue Base = CGF.MakeNaturalAlignAddrLValue(NewTaskNewTaskTTy,\n                                               KmpTaskTWithPrivatesQTy);\n  LValue TDBase =\n      CGF.EmitLValueForField(Base, *KmpTaskTWithPrivatesQTyRD->field_begin());\n  // Fill the data in the resulting kmp_task_t record.\n  // Copy shareds if there are any.\n  Address KmpTaskSharedsPtr = Address::invalid();\n  if (!SharedsTy->getAsStructureType()->getDecl()->field_empty()) {\n    KmpTaskSharedsPtr =\n        Address(CGF.EmitLoadOfScalar(\n                    CGF.EmitLValueForField(\n                        TDBase, *std::next(KmpTaskTQTyRD->field_begin(),\n                                           KmpTaskTShareds)),\n                    Loc),\n                CGM.getNaturalTypeAlignment(SharedsTy));\n    LValue Dest = CGF.MakeAddrLValue(KmpTaskSharedsPtr, SharedsTy);\n    LValue Src = CGF.MakeAddrLValue(Shareds, SharedsTy);\n    CGF.EmitAggregateCopy(Dest, Src, SharedsTy, AggValueSlot::DoesNotOverlap);\n  }\n  // Emit initial values for private copies (if any).\n  TaskResultTy Result;\n  if (!Privates.empty()) {\n    emitPrivatesInit(CGF, D, KmpTaskSharedsPtr, Base, KmpTaskTWithPrivatesQTyRD,\n                     SharedsTy, SharedsPtrTy, Data, Privates,\n                     /*ForDup=*/false);\n    if (isOpenMPTaskLoopDirective(D.getDirectiveKind()) &&\n        (!Data.LastprivateVars.empty() || checkInitIsRequired(CGF, Privates))) {\n      Result.TaskDupFn = emitTaskDupFunction(\n          CGM, Loc, D, KmpTaskTWithPrivatesPtrQTy, KmpTaskTWithPrivatesQTyRD,\n          KmpTaskTQTyRD, SharedsTy, SharedsPtrTy, Data, Privates,\n          /*WithLastIter=*/!Data.LastprivateVars.empty());\n    }\n  }\n  // Fields of union \"kmp_cmplrdata_t\" for destructors and priority.\n  enum { Priority = 0, Destructors = 1 };\n  // Provide pointer to function with destructors for privates.\n  auto FI = std::next(KmpTaskTQTyRD->field_begin(), Data1);\n  const RecordDecl *KmpCmplrdataUD =\n      (*FI)->getType()->getAsUnionType()->getDecl();\n  if (NeedsCleanup) {\n    llvm::Value *DestructorFn = emitDestructorsFunction(\n        CGM, Loc, KmpInt32Ty, KmpTaskTWithPrivatesPtrQTy,\n        KmpTaskTWithPrivatesQTy);\n    LValue Data1LV = CGF.EmitLValueForField(TDBase, *FI);\n    LValue DestructorsLV = CGF.EmitLValueForField(\n        Data1LV, *std::next(KmpCmplrdataUD->field_begin(), Destructors));\n    CGF.EmitStoreOfScalar(CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n                              DestructorFn, KmpRoutineEntryPtrTy),\n                          DestructorsLV);\n  }\n  // Set priority.\n  if (Data.Priority.getInt()) {\n    LValue Data2LV = CGF.EmitLValueForField(\n        TDBase, *std::next(KmpTaskTQTyRD->field_begin(), Data2));\n    LValue PriorityLV = CGF.EmitLValueForField(\n        Data2LV, *std::next(KmpCmplrdataUD->field_begin(), Priority));\n    CGF.EmitStoreOfScalar(Data.Priority.getPointer(), PriorityLV);\n  }\n  Result.NewTask = NewTask;\n  Result.TaskEntry = TaskEntry;\n  Result.NewTaskNewTaskTTy = NewTaskNewTaskTTy;\n  Result.TDBase = TDBase;\n  Result.KmpTaskTQTyRD = KmpTaskTQTyRD;\n  return Result;\n}\n\nnamespace {\n/// Dependence kind for RTL.\nenum RTLDependenceKindTy {\n  DepIn = 0x01,\n  DepInOut = 0x3,\n  DepMutexInOutSet = 0x4\n};\n/// Fields ids in kmp_depend_info record.\nenum RTLDependInfoFieldsTy { BaseAddr, Len, Flags };\n} // namespace\n\n/// Translates internal dependency kind into the runtime kind.\nstatic RTLDependenceKindTy translateDependencyKind(OpenMPDependClauseKind K) {\n  RTLDependenceKindTy DepKind;\n  switch (K) {\n  case OMPC_DEPEND_in:\n    DepKind = DepIn;\n    break;\n  // Out and InOut dependencies must use the same code.\n  case OMPC_DEPEND_out:\n  case OMPC_DEPEND_inout:\n    DepKind = DepInOut;\n    break;\n  case OMPC_DEPEND_mutexinoutset:\n    DepKind = DepMutexInOutSet;\n    break;\n  case OMPC_DEPEND_source:\n  case OMPC_DEPEND_sink:\n  case OMPC_DEPEND_depobj:\n  case OMPC_DEPEND_unknown:\n    llvm_unreachable(\"Unknown task dependence type\");\n  }\n  return DepKind;\n}\n\n/// Builds kmp_depend_info, if it is not built yet, and builds flags type.\nstatic void getDependTypes(ASTContext &C, QualType &KmpDependInfoTy,\n                           QualType &FlagsTy) {\n  FlagsTy = C.getIntTypeForBitwidth(C.getTypeSize(C.BoolTy), /*Signed=*/false);\n  if (KmpDependInfoTy.isNull()) {\n    RecordDecl *KmpDependInfoRD = C.buildImplicitRecord(\"kmp_depend_info\");\n    KmpDependInfoRD->startDefinition();\n    addFieldToRecordDecl(C, KmpDependInfoRD, C.getIntPtrType());\n    addFieldToRecordDecl(C, KmpDependInfoRD, C.getSizeType());\n    addFieldToRecordDecl(C, KmpDependInfoRD, FlagsTy);\n    KmpDependInfoRD->completeDefinition();\n    KmpDependInfoTy = C.getRecordType(KmpDependInfoRD);\n  }\n}\n\nstd::pair<llvm::Value *, LValue>\nCGOpenMPRuntime::getDepobjElements(CodeGenFunction &CGF, LValue DepobjLVal,\n                                   SourceLocation Loc) {\n  ASTContext &C = CGM.getContext();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  RecordDecl *KmpDependInfoRD =\n      cast<RecordDecl>(KmpDependInfoTy->getAsTagDecl());\n  LValue Base = CGF.EmitLoadOfPointerLValue(\n      DepobjLVal.getAddress(CGF),\n      C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n  QualType KmpDependInfoPtrTy = C.getPointerType(KmpDependInfoTy);\n  Address Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          Base.getAddress(CGF), CGF.ConvertTypeForMem(KmpDependInfoPtrTy));\n  Base = CGF.MakeAddrLValue(Addr, KmpDependInfoTy, Base.getBaseInfo(),\n                            Base.getTBAAInfo());\n  llvm::Value *DepObjAddr = CGF.Builder.CreateGEP(\n      Addr.getPointer(),\n      llvm::ConstantInt::get(CGF.IntPtrTy, -1, /*isSigned=*/true));\n  LValue NumDepsBase = CGF.MakeAddrLValue(\n      Address(DepObjAddr, Addr.getAlignment()), KmpDependInfoTy,\n      Base.getBaseInfo(), Base.getTBAAInfo());\n  // NumDeps = deps[i].base_addr;\n  LValue BaseAddrLVal = CGF.EmitLValueForField(\n      NumDepsBase, *std::next(KmpDependInfoRD->field_begin(), BaseAddr));\n  llvm::Value *NumDeps = CGF.EmitLoadOfScalar(BaseAddrLVal, Loc);\n  return std::make_pair(NumDeps, Base);\n}\n\nstatic void emitDependData(CodeGenFunction &CGF, QualType &KmpDependInfoTy,\n                           llvm::PointerUnion<unsigned *, LValue *> Pos,\n                           const OMPTaskDataTy::DependData &Data,\n                           Address DependenciesArray) {\n  CodeGenModule &CGM = CGF.CGM;\n  ASTContext &C = CGM.getContext();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  RecordDecl *KmpDependInfoRD =\n      cast<RecordDecl>(KmpDependInfoTy->getAsTagDecl());\n  llvm::Type *LLVMFlagsTy = CGF.ConvertTypeForMem(FlagsTy);\n\n  OMPIteratorGeneratorScope IteratorScope(\n      CGF, cast_or_null<OMPIteratorExpr>(\n               Data.IteratorExpr ? Data.IteratorExpr->IgnoreParenImpCasts()\n                                 : nullptr));\n  for (const Expr *E : Data.DepExprs) {\n    llvm::Value *Addr;\n    llvm::Value *Size;\n    std::tie(Addr, Size) = getPointerAndSize(CGF, E);\n    LValue Base;\n    if (unsigned *P = Pos.dyn_cast<unsigned *>()) {\n      Base = CGF.MakeAddrLValue(\n          CGF.Builder.CreateConstGEP(DependenciesArray, *P), KmpDependInfoTy);\n    } else {\n      LValue &PosLVal = *Pos.get<LValue *>();\n      llvm::Value *Idx = CGF.EmitLoadOfScalar(PosLVal, E->getExprLoc());\n      Base = CGF.MakeAddrLValue(\n          Address(CGF.Builder.CreateGEP(DependenciesArray.getPointer(), Idx),\n                  DependenciesArray.getAlignment()),\n          KmpDependInfoTy);\n    }\n    // deps[i].base_addr = &<Dependencies[i].second>;\n    LValue BaseAddrLVal = CGF.EmitLValueForField(\n        Base, *std::next(KmpDependInfoRD->field_begin(), BaseAddr));\n    CGF.EmitStoreOfScalar(CGF.Builder.CreatePtrToInt(Addr, CGF.IntPtrTy),\n                          BaseAddrLVal);\n    // deps[i].len = sizeof(<Dependencies[i].second>);\n    LValue LenLVal = CGF.EmitLValueForField(\n        Base, *std::next(KmpDependInfoRD->field_begin(), Len));\n    CGF.EmitStoreOfScalar(Size, LenLVal);\n    // deps[i].flags = <Dependencies[i].first>;\n    RTLDependenceKindTy DepKind = translateDependencyKind(Data.DepKind);\n    LValue FlagsLVal = CGF.EmitLValueForField(\n        Base, *std::next(KmpDependInfoRD->field_begin(), Flags));\n    CGF.EmitStoreOfScalar(llvm::ConstantInt::get(LLVMFlagsTy, DepKind),\n                          FlagsLVal);\n    if (unsigned *P = Pos.dyn_cast<unsigned *>()) {\n      ++(*P);\n    } else {\n      LValue &PosLVal = *Pos.get<LValue *>();\n      llvm::Value *Idx = CGF.EmitLoadOfScalar(PosLVal, E->getExprLoc());\n      Idx = CGF.Builder.CreateNUWAdd(Idx,\n                                     llvm::ConstantInt::get(Idx->getType(), 1));\n      CGF.EmitStoreOfScalar(Idx, PosLVal);\n    }\n  }\n}\n\nstatic SmallVector<llvm::Value *, 4>\nemitDepobjElementsSizes(CodeGenFunction &CGF, QualType &KmpDependInfoTy,\n                        const OMPTaskDataTy::DependData &Data) {\n  assert(Data.DepKind == OMPC_DEPEND_depobj &&\n         \"Expected depobj dependecy kind.\");\n  SmallVector<llvm::Value *, 4> Sizes;\n  SmallVector<LValue, 4> SizeLVals;\n  ASTContext &C = CGF.getContext();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  RecordDecl *KmpDependInfoRD =\n      cast<RecordDecl>(KmpDependInfoTy->getAsTagDecl());\n  QualType KmpDependInfoPtrTy = C.getPointerType(KmpDependInfoTy);\n  llvm::Type *KmpDependInfoPtrT = CGF.ConvertTypeForMem(KmpDependInfoPtrTy);\n  {\n    OMPIteratorGeneratorScope IteratorScope(\n        CGF, cast_or_null<OMPIteratorExpr>(\n                 Data.IteratorExpr ? Data.IteratorExpr->IgnoreParenImpCasts()\n                                   : nullptr));\n    for (const Expr *E : Data.DepExprs) {\n      LValue DepobjLVal = CGF.EmitLValue(E->IgnoreParenImpCasts());\n      LValue Base = CGF.EmitLoadOfPointerLValue(\n          DepobjLVal.getAddress(CGF),\n          C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n      Address Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          Base.getAddress(CGF), KmpDependInfoPtrT);\n      Base = CGF.MakeAddrLValue(Addr, KmpDependInfoTy, Base.getBaseInfo(),\n                                Base.getTBAAInfo());\n      llvm::Value *DepObjAddr = CGF.Builder.CreateGEP(\n          Addr.getPointer(),\n          llvm::ConstantInt::get(CGF.IntPtrTy, -1, /*isSigned=*/true));\n      LValue NumDepsBase = CGF.MakeAddrLValue(\n          Address(DepObjAddr, Addr.getAlignment()), KmpDependInfoTy,\n          Base.getBaseInfo(), Base.getTBAAInfo());\n      // NumDeps = deps[i].base_addr;\n      LValue BaseAddrLVal = CGF.EmitLValueForField(\n          NumDepsBase, *std::next(KmpDependInfoRD->field_begin(), BaseAddr));\n      llvm::Value *NumDeps =\n          CGF.EmitLoadOfScalar(BaseAddrLVal, E->getExprLoc());\n      LValue NumLVal = CGF.MakeAddrLValue(\n          CGF.CreateMemTemp(C.getUIntPtrType(), \"depobj.size.addr\"),\n          C.getUIntPtrType());\n      CGF.InitTempAlloca(NumLVal.getAddress(CGF),\n                         llvm::ConstantInt::get(CGF.IntPtrTy, 0));\n      llvm::Value *PrevVal = CGF.EmitLoadOfScalar(NumLVal, E->getExprLoc());\n      llvm::Value *Add = CGF.Builder.CreateNUWAdd(PrevVal, NumDeps);\n      CGF.EmitStoreOfScalar(Add, NumLVal);\n      SizeLVals.push_back(NumLVal);\n    }\n  }\n  for (unsigned I = 0, E = SizeLVals.size(); I < E; ++I) {\n    llvm::Value *Size =\n        CGF.EmitLoadOfScalar(SizeLVals[I], Data.DepExprs[I]->getExprLoc());\n    Sizes.push_back(Size);\n  }\n  return Sizes;\n}\n\nstatic void emitDepobjElements(CodeGenFunction &CGF, QualType &KmpDependInfoTy,\n                               LValue PosLVal,\n                               const OMPTaskDataTy::DependData &Data,\n                               Address DependenciesArray) {\n  assert(Data.DepKind == OMPC_DEPEND_depobj &&\n         \"Expected depobj dependecy kind.\");\n  ASTContext &C = CGF.getContext();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  RecordDecl *KmpDependInfoRD =\n      cast<RecordDecl>(KmpDependInfoTy->getAsTagDecl());\n  QualType KmpDependInfoPtrTy = C.getPointerType(KmpDependInfoTy);\n  llvm::Type *KmpDependInfoPtrT = CGF.ConvertTypeForMem(KmpDependInfoPtrTy);\n  llvm::Value *ElSize = CGF.getTypeSize(KmpDependInfoTy);\n  {\n    OMPIteratorGeneratorScope IteratorScope(\n        CGF, cast_or_null<OMPIteratorExpr>(\n                 Data.IteratorExpr ? Data.IteratorExpr->IgnoreParenImpCasts()\n                                   : nullptr));\n    for (unsigned I = 0, End = Data.DepExprs.size(); I < End; ++I) {\n      const Expr *E = Data.DepExprs[I];\n      LValue DepobjLVal = CGF.EmitLValue(E->IgnoreParenImpCasts());\n      LValue Base = CGF.EmitLoadOfPointerLValue(\n          DepobjLVal.getAddress(CGF),\n          C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n      Address Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          Base.getAddress(CGF), KmpDependInfoPtrT);\n      Base = CGF.MakeAddrLValue(Addr, KmpDependInfoTy, Base.getBaseInfo(),\n                                Base.getTBAAInfo());\n\n      // Get number of elements in a single depobj.\n      llvm::Value *DepObjAddr = CGF.Builder.CreateGEP(\n          Addr.getPointer(),\n          llvm::ConstantInt::get(CGF.IntPtrTy, -1, /*isSigned=*/true));\n      LValue NumDepsBase = CGF.MakeAddrLValue(\n          Address(DepObjAddr, Addr.getAlignment()), KmpDependInfoTy,\n          Base.getBaseInfo(), Base.getTBAAInfo());\n      // NumDeps = deps[i].base_addr;\n      LValue BaseAddrLVal = CGF.EmitLValueForField(\n          NumDepsBase, *std::next(KmpDependInfoRD->field_begin(), BaseAddr));\n      llvm::Value *NumDeps =\n          CGF.EmitLoadOfScalar(BaseAddrLVal, E->getExprLoc());\n\n      // memcopy dependency data.\n      llvm::Value *Size = CGF.Builder.CreateNUWMul(\n          ElSize,\n          CGF.Builder.CreateIntCast(NumDeps, CGF.SizeTy, /*isSigned=*/false));\n      llvm::Value *Pos = CGF.EmitLoadOfScalar(PosLVal, E->getExprLoc());\n      Address DepAddr =\n          Address(CGF.Builder.CreateGEP(DependenciesArray.getPointer(), Pos),\n                  DependenciesArray.getAlignment());\n      CGF.Builder.CreateMemCpy(DepAddr, Base.getAddress(CGF), Size);\n\n      // Increase pos.\n      // pos += size;\n      llvm::Value *Add = CGF.Builder.CreateNUWAdd(Pos, NumDeps);\n      CGF.EmitStoreOfScalar(Add, PosLVal);\n    }\n  }\n}\n\nstd::pair<llvm::Value *, Address> CGOpenMPRuntime::emitDependClause(\n    CodeGenFunction &CGF, ArrayRef<OMPTaskDataTy::DependData> Dependencies,\n    SourceLocation Loc) {\n  if (llvm::all_of(Dependencies, [](const OMPTaskDataTy::DependData &D) {\n        return D.DepExprs.empty();\n      }))\n    return std::make_pair(nullptr, Address::invalid());\n  // Process list of dependencies.\n  ASTContext &C = CGM.getContext();\n  Address DependenciesArray = Address::invalid();\n  llvm::Value *NumOfElements = nullptr;\n  unsigned NumDependencies = std::accumulate(\n      Dependencies.begin(), Dependencies.end(), 0,\n      [](unsigned V, const OMPTaskDataTy::DependData &D) {\n        return D.DepKind == OMPC_DEPEND_depobj\n                   ? V\n                   : (V + (D.IteratorExpr ? 0 : D.DepExprs.size()));\n      });\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  bool HasDepobjDeps = false;\n  bool HasRegularWithIterators = false;\n  llvm::Value *NumOfDepobjElements = llvm::ConstantInt::get(CGF.IntPtrTy, 0);\n  llvm::Value *NumOfRegularWithIterators =\n      llvm::ConstantInt::get(CGF.IntPtrTy, 1);\n  // Calculate number of depobj dependecies and regular deps with the iterators.\n  for (const OMPTaskDataTy::DependData &D : Dependencies) {\n    if (D.DepKind == OMPC_DEPEND_depobj) {\n      SmallVector<llvm::Value *, 4> Sizes =\n          emitDepobjElementsSizes(CGF, KmpDependInfoTy, D);\n      for (llvm::Value *Size : Sizes) {\n        NumOfDepobjElements =\n            CGF.Builder.CreateNUWAdd(NumOfDepobjElements, Size);\n      }\n      HasDepobjDeps = true;\n      continue;\n    }\n    // Include number of iterations, if any.\n    if (const auto *IE = cast_or_null<OMPIteratorExpr>(D.IteratorExpr)) {\n      for (unsigned I = 0, E = IE->numOfIterators(); I < E; ++I) {\n        llvm::Value *Sz = CGF.EmitScalarExpr(IE->getHelper(I).Upper);\n        Sz = CGF.Builder.CreateIntCast(Sz, CGF.IntPtrTy, /*isSigned=*/false);\n        NumOfRegularWithIterators =\n            CGF.Builder.CreateNUWMul(NumOfRegularWithIterators, Sz);\n      }\n      HasRegularWithIterators = true;\n      continue;\n    }\n  }\n\n  QualType KmpDependInfoArrayTy;\n  if (HasDepobjDeps || HasRegularWithIterators) {\n    NumOfElements = llvm::ConstantInt::get(CGM.IntPtrTy, NumDependencies,\n                                           /*isSigned=*/false);\n    if (HasDepobjDeps) {\n      NumOfElements =\n          CGF.Builder.CreateNUWAdd(NumOfDepobjElements, NumOfElements);\n    }\n    if (HasRegularWithIterators) {\n      NumOfElements =\n          CGF.Builder.CreateNUWAdd(NumOfRegularWithIterators, NumOfElements);\n    }\n    OpaqueValueExpr OVE(Loc,\n                        C.getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/0),\n                        VK_RValue);\n    CodeGenFunction::OpaqueValueMapping OpaqueMap(CGF, &OVE,\n                                                  RValue::get(NumOfElements));\n    KmpDependInfoArrayTy =\n        C.getVariableArrayType(KmpDependInfoTy, &OVE, ArrayType::Normal,\n                               /*IndexTypeQuals=*/0, SourceRange(Loc, Loc));\n    // CGF.EmitVariablyModifiedType(KmpDependInfoArrayTy);\n    // Properly emit variable-sized array.\n    auto *PD = ImplicitParamDecl::Create(C, KmpDependInfoArrayTy,\n                                         ImplicitParamDecl::Other);\n    CGF.EmitVarDecl(*PD);\n    DependenciesArray = CGF.GetAddrOfLocalVar(PD);\n    NumOfElements = CGF.Builder.CreateIntCast(NumOfElements, CGF.Int32Ty,\n                                              /*isSigned=*/false);\n  } else {\n    KmpDependInfoArrayTy = C.getConstantArrayType(\n        KmpDependInfoTy, llvm::APInt(/*numBits=*/64, NumDependencies), nullptr,\n        ArrayType::Normal, /*IndexTypeQuals=*/0);\n    DependenciesArray =\n        CGF.CreateMemTemp(KmpDependInfoArrayTy, \".dep.arr.addr\");\n    DependenciesArray = CGF.Builder.CreateConstArrayGEP(DependenciesArray, 0);\n    NumOfElements = llvm::ConstantInt::get(CGM.Int32Ty, NumDependencies,\n                                           /*isSigned=*/false);\n  }\n  unsigned Pos = 0;\n  for (unsigned I = 0, End = Dependencies.size(); I < End; ++I) {\n    if (Dependencies[I].DepKind == OMPC_DEPEND_depobj ||\n        Dependencies[I].IteratorExpr)\n      continue;\n    emitDependData(CGF, KmpDependInfoTy, &Pos, Dependencies[I],\n                   DependenciesArray);\n  }\n  // Copy regular dependecies with iterators.\n  LValue PosLVal = CGF.MakeAddrLValue(\n      CGF.CreateMemTemp(C.getSizeType(), \"dep.counter.addr\"), C.getSizeType());\n  CGF.EmitStoreOfScalar(llvm::ConstantInt::get(CGF.SizeTy, Pos), PosLVal);\n  for (unsigned I = 0, End = Dependencies.size(); I < End; ++I) {\n    if (Dependencies[I].DepKind == OMPC_DEPEND_depobj ||\n        !Dependencies[I].IteratorExpr)\n      continue;\n    emitDependData(CGF, KmpDependInfoTy, &PosLVal, Dependencies[I],\n                   DependenciesArray);\n  }\n  // Copy final depobj arrays without iterators.\n  if (HasDepobjDeps) {\n    for (unsigned I = 0, End = Dependencies.size(); I < End; ++I) {\n      if (Dependencies[I].DepKind != OMPC_DEPEND_depobj)\n        continue;\n      emitDepobjElements(CGF, KmpDependInfoTy, PosLVal, Dependencies[I],\n                         DependenciesArray);\n    }\n  }\n  DependenciesArray = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      DependenciesArray, CGF.VoidPtrTy);\n  return std::make_pair(NumOfElements, DependenciesArray);\n}\n\nAddress CGOpenMPRuntime::emitDepobjDependClause(\n    CodeGenFunction &CGF, const OMPTaskDataTy::DependData &Dependencies,\n    SourceLocation Loc) {\n  if (Dependencies.DepExprs.empty())\n    return Address::invalid();\n  // Process list of dependencies.\n  ASTContext &C = CGM.getContext();\n  Address DependenciesArray = Address::invalid();\n  unsigned NumDependencies = Dependencies.DepExprs.size();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  RecordDecl *KmpDependInfoRD =\n      cast<RecordDecl>(KmpDependInfoTy->getAsTagDecl());\n\n  llvm::Value *Size;\n  // Define type kmp_depend_info[<Dependencies.size()>];\n  // For depobj reserve one extra element to store the number of elements.\n  // It is required to handle depobj(x) update(in) construct.\n  // kmp_depend_info[<Dependencies.size()>] deps;\n  llvm::Value *NumDepsVal;\n  CharUnits Align = C.getTypeAlignInChars(KmpDependInfoTy);\n  if (const auto *IE =\n          cast_or_null<OMPIteratorExpr>(Dependencies.IteratorExpr)) {\n    NumDepsVal = llvm::ConstantInt::get(CGF.SizeTy, 1);\n    for (unsigned I = 0, E = IE->numOfIterators(); I < E; ++I) {\n      llvm::Value *Sz = CGF.EmitScalarExpr(IE->getHelper(I).Upper);\n      Sz = CGF.Builder.CreateIntCast(Sz, CGF.SizeTy, /*isSigned=*/false);\n      NumDepsVal = CGF.Builder.CreateNUWMul(NumDepsVal, Sz);\n    }\n    Size = CGF.Builder.CreateNUWAdd(llvm::ConstantInt::get(CGF.SizeTy, 1),\n                                    NumDepsVal);\n    CharUnits SizeInBytes =\n        C.getTypeSizeInChars(KmpDependInfoTy).alignTo(Align);\n    llvm::Value *RecSize = CGM.getSize(SizeInBytes);\n    Size = CGF.Builder.CreateNUWMul(Size, RecSize);\n    NumDepsVal =\n        CGF.Builder.CreateIntCast(NumDepsVal, CGF.IntPtrTy, /*isSigned=*/false);\n  } else {\n    QualType KmpDependInfoArrayTy = C.getConstantArrayType(\n        KmpDependInfoTy, llvm::APInt(/*numBits=*/64, NumDependencies + 1),\n        nullptr, ArrayType::Normal, /*IndexTypeQuals=*/0);\n    CharUnits Sz = C.getTypeSizeInChars(KmpDependInfoArrayTy);\n    Size = CGM.getSize(Sz.alignTo(Align));\n    NumDepsVal = llvm::ConstantInt::get(CGF.IntPtrTy, NumDependencies);\n  }\n  // Need to allocate on the dynamic memory.\n  llvm::Value *ThreadID = getThreadID(CGF, Loc);\n  // Use default allocator.\n  llvm::Value *Allocator = llvm::ConstantPointerNull::get(CGF.VoidPtrTy);\n  llvm::Value *Args[] = {ThreadID, Size, Allocator};\n\n  llvm::Value *Addr =\n      CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                              CGM.getModule(), OMPRTL___kmpc_alloc),\n                          Args, \".dep.arr.addr\");\n  Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      Addr, CGF.ConvertTypeForMem(KmpDependInfoTy)->getPointerTo());\n  DependenciesArray = Address(Addr, Align);\n  // Write number of elements in the first element of array for depobj.\n  LValue Base = CGF.MakeAddrLValue(DependenciesArray, KmpDependInfoTy);\n  // deps[i].base_addr = NumDependencies;\n  LValue BaseAddrLVal = CGF.EmitLValueForField(\n      Base, *std::next(KmpDependInfoRD->field_begin(), BaseAddr));\n  CGF.EmitStoreOfScalar(NumDepsVal, BaseAddrLVal);\n  llvm::PointerUnion<unsigned *, LValue *> Pos;\n  unsigned Idx = 1;\n  LValue PosLVal;\n  if (Dependencies.IteratorExpr) {\n    PosLVal = CGF.MakeAddrLValue(\n        CGF.CreateMemTemp(C.getSizeType(), \"iterator.counter.addr\"),\n        C.getSizeType());\n    CGF.EmitStoreOfScalar(llvm::ConstantInt::get(CGF.SizeTy, Idx), PosLVal,\n                          /*IsInit=*/true);\n    Pos = &PosLVal;\n  } else {\n    Pos = &Idx;\n  }\n  emitDependData(CGF, KmpDependInfoTy, Pos, Dependencies, DependenciesArray);\n  DependenciesArray = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      CGF.Builder.CreateConstGEP(DependenciesArray, 1), CGF.VoidPtrTy);\n  return DependenciesArray;\n}\n\nvoid CGOpenMPRuntime::emitDestroyClause(CodeGenFunction &CGF, LValue DepobjLVal,\n                                        SourceLocation Loc) {\n  ASTContext &C = CGM.getContext();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  LValue Base = CGF.EmitLoadOfPointerLValue(\n      DepobjLVal.getAddress(CGF),\n      C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n  QualType KmpDependInfoPtrTy = C.getPointerType(KmpDependInfoTy);\n  Address Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      Base.getAddress(CGF), CGF.ConvertTypeForMem(KmpDependInfoPtrTy));\n  llvm::Value *DepObjAddr = CGF.Builder.CreateGEP(\n      Addr.getPointer(),\n      llvm::ConstantInt::get(CGF.IntPtrTy, -1, /*isSigned=*/true));\n  DepObjAddr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(DepObjAddr,\n                                                               CGF.VoidPtrTy);\n  llvm::Value *ThreadID = getThreadID(CGF, Loc);\n  // Use default allocator.\n  llvm::Value *Allocator = llvm::ConstantPointerNull::get(CGF.VoidPtrTy);\n  llvm::Value *Args[] = {ThreadID, DepObjAddr, Allocator};\n\n  // _kmpc_free(gtid, addr, nullptr);\n  (void)CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                                CGM.getModule(), OMPRTL___kmpc_free),\n                            Args);\n}\n\nvoid CGOpenMPRuntime::emitUpdateClause(CodeGenFunction &CGF, LValue DepobjLVal,\n                                       OpenMPDependClauseKind NewDepKind,\n                                       SourceLocation Loc) {\n  ASTContext &C = CGM.getContext();\n  QualType FlagsTy;\n  getDependTypes(C, KmpDependInfoTy, FlagsTy);\n  RecordDecl *KmpDependInfoRD =\n      cast<RecordDecl>(KmpDependInfoTy->getAsTagDecl());\n  llvm::Type *LLVMFlagsTy = CGF.ConvertTypeForMem(FlagsTy);\n  llvm::Value *NumDeps;\n  LValue Base;\n  std::tie(NumDeps, Base) = getDepobjElements(CGF, DepobjLVal, Loc);\n\n  Address Begin = Base.getAddress(CGF);\n  // Cast from pointer to array type to pointer to single element.\n  llvm::Value *End = CGF.Builder.CreateGEP(Begin.getPointer(), NumDeps);\n  // The basic structure here is a while-do loop.\n  llvm::BasicBlock *BodyBB = CGF.createBasicBlock(\"omp.body\");\n  llvm::BasicBlock *DoneBB = CGF.createBasicBlock(\"omp.done\");\n  llvm::BasicBlock *EntryBB = CGF.Builder.GetInsertBlock();\n  CGF.EmitBlock(BodyBB);\n  llvm::PHINode *ElementPHI =\n      CGF.Builder.CreatePHI(Begin.getType(), 2, \"omp.elementPast\");\n  ElementPHI->addIncoming(Begin.getPointer(), EntryBB);\n  Begin = Address(ElementPHI, Begin.getAlignment());\n  Base = CGF.MakeAddrLValue(Begin, KmpDependInfoTy, Base.getBaseInfo(),\n                            Base.getTBAAInfo());\n  // deps[i].flags = NewDepKind;\n  RTLDependenceKindTy DepKind = translateDependencyKind(NewDepKind);\n  LValue FlagsLVal = CGF.EmitLValueForField(\n      Base, *std::next(KmpDependInfoRD->field_begin(), Flags));\n  CGF.EmitStoreOfScalar(llvm::ConstantInt::get(LLVMFlagsTy, DepKind),\n                        FlagsLVal);\n\n  // Shift the address forward by one element.\n  Address ElementNext =\n      CGF.Builder.CreateConstGEP(Begin, /*Index=*/1, \"omp.elementNext\");\n  ElementPHI->addIncoming(ElementNext.getPointer(),\n                          CGF.Builder.GetInsertBlock());\n  llvm::Value *IsEmpty =\n      CGF.Builder.CreateICmpEQ(ElementNext.getPointer(), End, \"omp.isempty\");\n  CGF.Builder.CreateCondBr(IsEmpty, DoneBB, BodyBB);\n  // Done.\n  CGF.EmitBlock(DoneBB, /*IsFinished=*/true);\n}\n\nvoid CGOpenMPRuntime::emitTaskCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                   const OMPExecutableDirective &D,\n                                   llvm::Function *TaskFunction,\n                                   QualType SharedsTy, Address Shareds,\n                                   const Expr *IfCond,\n                                   const OMPTaskDataTy &Data) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  TaskResultTy Result =\n      emitTaskInit(CGF, Loc, D, TaskFunction, SharedsTy, Shareds, Data);\n  llvm::Value *NewTask = Result.NewTask;\n  llvm::Function *TaskEntry = Result.TaskEntry;\n  llvm::Value *NewTaskNewTaskTTy = Result.NewTaskNewTaskTTy;\n  LValue TDBase = Result.TDBase;\n  const RecordDecl *KmpTaskTQTyRD = Result.KmpTaskTQTyRD;\n  // Process list of dependences.\n  Address DependenciesArray = Address::invalid();\n  llvm::Value *NumOfElements;\n  std::tie(NumOfElements, DependenciesArray) =\n      emitDependClause(CGF, Data.Dependences, Loc);\n\n  // NOTE: routine and part_id fields are initialized by __kmpc_omp_task_alloc()\n  // libcall.\n  // Build kmp_int32 __kmpc_omp_task_with_deps(ident_t *, kmp_int32 gtid,\n  // kmp_task_t *new_task, kmp_int32 ndeps, kmp_depend_info_t *dep_list,\n  // kmp_int32 ndeps_noalias, kmp_depend_info_t *noalias_dep_list) if dependence\n  // list is not empty\n  llvm::Value *ThreadID = getThreadID(CGF, Loc);\n  llvm::Value *UpLoc = emitUpdateLocation(CGF, Loc);\n  llvm::Value *TaskArgs[] = { UpLoc, ThreadID, NewTask };\n  llvm::Value *DepTaskArgs[7];\n  if (!Data.Dependences.empty()) {\n    DepTaskArgs[0] = UpLoc;\n    DepTaskArgs[1] = ThreadID;\n    DepTaskArgs[2] = NewTask;\n    DepTaskArgs[3] = NumOfElements;\n    DepTaskArgs[4] = DependenciesArray.getPointer();\n    DepTaskArgs[5] = CGF.Builder.getInt32(0);\n    DepTaskArgs[6] = llvm::ConstantPointerNull::get(CGF.VoidPtrTy);\n  }\n  auto &&ThenCodeGen = [this, &Data, TDBase, KmpTaskTQTyRD, &TaskArgs,\n                        &DepTaskArgs](CodeGenFunction &CGF, PrePostActionTy &) {\n    if (!Data.Tied) {\n      auto PartIdFI = std::next(KmpTaskTQTyRD->field_begin(), KmpTaskTPartId);\n      LValue PartIdLVal = CGF.EmitLValueForField(TDBase, *PartIdFI);\n      CGF.EmitStoreOfScalar(CGF.Builder.getInt32(0), PartIdLVal);\n    }\n    if (!Data.Dependences.empty()) {\n      CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), OMPRTL___kmpc_omp_task_with_deps),\n          DepTaskArgs);\n    } else {\n      CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                              CGM.getModule(), OMPRTL___kmpc_omp_task),\n                          TaskArgs);\n    }\n    // Check if parent region is untied and build return for untied task;\n    if (auto *Region =\n            dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo))\n      Region->emitUntiedSwitch(CGF);\n  };\n\n  llvm::Value *DepWaitTaskArgs[6];\n  if (!Data.Dependences.empty()) {\n    DepWaitTaskArgs[0] = UpLoc;\n    DepWaitTaskArgs[1] = ThreadID;\n    DepWaitTaskArgs[2] = NumOfElements;\n    DepWaitTaskArgs[3] = DependenciesArray.getPointer();\n    DepWaitTaskArgs[4] = CGF.Builder.getInt32(0);\n    DepWaitTaskArgs[5] = llvm::ConstantPointerNull::get(CGF.VoidPtrTy);\n  }\n  auto &M = CGM.getModule();\n  auto &&ElseCodeGen = [this, &M, &TaskArgs, ThreadID, NewTaskNewTaskTTy,\n                        TaskEntry, &Data, &DepWaitTaskArgs,\n                        Loc](CodeGenFunction &CGF, PrePostActionTy &) {\n    CodeGenFunction::RunCleanupsScope LocalScope(CGF);\n    // Build void __kmpc_omp_wait_deps(ident_t *, kmp_int32 gtid,\n    // kmp_int32 ndeps, kmp_depend_info_t *dep_list, kmp_int32\n    // ndeps_noalias, kmp_depend_info_t *noalias_dep_list); if dependence info\n    // is specified.\n    if (!Data.Dependences.empty())\n      CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(M, OMPRTL___kmpc_omp_wait_deps),\n          DepWaitTaskArgs);\n    // Call proxy_task_entry(gtid, new_task);\n    auto &&CodeGen = [TaskEntry, ThreadID, NewTaskNewTaskTTy,\n                      Loc](CodeGenFunction &CGF, PrePostActionTy &Action) {\n      Action.Enter(CGF);\n      llvm::Value *OutlinedFnArgs[] = {ThreadID, NewTaskNewTaskTTy};\n      CGF.CGM.getOpenMPRuntime().emitOutlinedFunctionCall(CGF, Loc, TaskEntry,\n                                                          OutlinedFnArgs);\n    };\n\n    // Build void __kmpc_omp_task_begin_if0(ident_t *, kmp_int32 gtid,\n    // kmp_task_t *new_task);\n    // Build void __kmpc_omp_task_complete_if0(ident_t *, kmp_int32 gtid,\n    // kmp_task_t *new_task);\n    RegionCodeGenTy RCG(CodeGen);\n    CommonActionTy Action(OMPBuilder.getOrCreateRuntimeFunction(\n                              M, OMPRTL___kmpc_omp_task_begin_if0),\n                          TaskArgs,\n                          OMPBuilder.getOrCreateRuntimeFunction(\n                              M, OMPRTL___kmpc_omp_task_complete_if0),\n                          TaskArgs);\n    RCG.setAction(Action);\n    RCG(CGF);\n  };\n\n  if (IfCond) {\n    emitIfClause(CGF, IfCond, ThenCodeGen, ElseCodeGen);\n  } else {\n    RegionCodeGenTy ThenRCG(ThenCodeGen);\n    ThenRCG(CGF);\n  }\n}\n\nvoid CGOpenMPRuntime::emitTaskLoopCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                       const OMPLoopDirective &D,\n                                       llvm::Function *TaskFunction,\n                                       QualType SharedsTy, Address Shareds,\n                                       const Expr *IfCond,\n                                       const OMPTaskDataTy &Data) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  TaskResultTy Result =\n      emitTaskInit(CGF, Loc, D, TaskFunction, SharedsTy, Shareds, Data);\n  // NOTE: routine and part_id fields are initialized by __kmpc_omp_task_alloc()\n  // libcall.\n  // Call to void __kmpc_taskloop(ident_t *loc, int gtid, kmp_task_t *task, int\n  // if_val, kmp_uint64 *lb, kmp_uint64 *ub, kmp_int64 st, int nogroup, int\n  // sched, kmp_uint64 grainsize, void *task_dup);\n  llvm::Value *ThreadID = getThreadID(CGF, Loc);\n  llvm::Value *UpLoc = emitUpdateLocation(CGF, Loc);\n  llvm::Value *IfVal;\n  if (IfCond) {\n    IfVal = CGF.Builder.CreateIntCast(CGF.EvaluateExprAsBool(IfCond), CGF.IntTy,\n                                      /*isSigned=*/true);\n  } else {\n    IfVal = llvm::ConstantInt::getSigned(CGF.IntTy, /*V=*/1);\n  }\n\n  LValue LBLVal = CGF.EmitLValueForField(\n      Result.TDBase,\n      *std::next(Result.KmpTaskTQTyRD->field_begin(), KmpTaskTLowerBound));\n  const auto *LBVar =\n      cast<VarDecl>(cast<DeclRefExpr>(D.getLowerBoundVariable())->getDecl());\n  CGF.EmitAnyExprToMem(LBVar->getInit(), LBLVal.getAddress(CGF),\n                       LBLVal.getQuals(),\n                       /*IsInitializer=*/true);\n  LValue UBLVal = CGF.EmitLValueForField(\n      Result.TDBase,\n      *std::next(Result.KmpTaskTQTyRD->field_begin(), KmpTaskTUpperBound));\n  const auto *UBVar =\n      cast<VarDecl>(cast<DeclRefExpr>(D.getUpperBoundVariable())->getDecl());\n  CGF.EmitAnyExprToMem(UBVar->getInit(), UBLVal.getAddress(CGF),\n                       UBLVal.getQuals(),\n                       /*IsInitializer=*/true);\n  LValue StLVal = CGF.EmitLValueForField(\n      Result.TDBase,\n      *std::next(Result.KmpTaskTQTyRD->field_begin(), KmpTaskTStride));\n  const auto *StVar =\n      cast<VarDecl>(cast<DeclRefExpr>(D.getStrideVariable())->getDecl());\n  CGF.EmitAnyExprToMem(StVar->getInit(), StLVal.getAddress(CGF),\n                       StLVal.getQuals(),\n                       /*IsInitializer=*/true);\n  // Store reductions address.\n  LValue RedLVal = CGF.EmitLValueForField(\n      Result.TDBase,\n      *std::next(Result.KmpTaskTQTyRD->field_begin(), KmpTaskTReductions));\n  if (Data.Reductions) {\n    CGF.EmitStoreOfScalar(Data.Reductions, RedLVal);\n  } else {\n    CGF.EmitNullInitialization(RedLVal.getAddress(CGF),\n                               CGF.getContext().VoidPtrTy);\n  }\n  enum { NoSchedule = 0, Grainsize = 1, NumTasks = 2 };\n  llvm::Value *TaskArgs[] = {\n      UpLoc,\n      ThreadID,\n      Result.NewTask,\n      IfVal,\n      LBLVal.getPointer(CGF),\n      UBLVal.getPointer(CGF),\n      CGF.EmitLoadOfScalar(StLVal, Loc),\n      llvm::ConstantInt::getSigned(\n          CGF.IntTy, 1), // Always 1 because taskgroup emitted by the compiler\n      llvm::ConstantInt::getSigned(\n          CGF.IntTy, Data.Schedule.getPointer()\n                         ? Data.Schedule.getInt() ? NumTasks : Grainsize\n                         : NoSchedule),\n      Data.Schedule.getPointer()\n          ? CGF.Builder.CreateIntCast(Data.Schedule.getPointer(), CGF.Int64Ty,\n                                      /*isSigned=*/false)\n          : llvm::ConstantInt::get(CGF.Int64Ty, /*V=*/0),\n      Result.TaskDupFn ? CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n                             Result.TaskDupFn, CGF.VoidPtrTy)\n                       : llvm::ConstantPointerNull::get(CGF.VoidPtrTy)};\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_taskloop),\n                      TaskArgs);\n}\n\n/// Emit reduction operation for each element of array (required for\n/// array sections) LHS op = RHS.\n/// \\param Type Type of array.\n/// \\param LHSVar Variable on the left side of the reduction operation\n/// (references element of array in original variable).\n/// \\param RHSVar Variable on the right side of the reduction operation\n/// (references element of array in original variable).\n/// \\param RedOpGen Generator of reduction operation with use of LHSVar and\n/// RHSVar.\nstatic void EmitOMPAggregateReduction(\n    CodeGenFunction &CGF, QualType Type, const VarDecl *LHSVar,\n    const VarDecl *RHSVar,\n    const llvm::function_ref<void(CodeGenFunction &CGF, const Expr *,\n                                  const Expr *, const Expr *)> &RedOpGen,\n    const Expr *XExpr = nullptr, const Expr *EExpr = nullptr,\n    const Expr *UpExpr = nullptr) {\n  // Perform element-by-element initialization.\n  QualType ElementTy;\n  Address LHSAddr = CGF.GetAddrOfLocalVar(LHSVar);\n  Address RHSAddr = CGF.GetAddrOfLocalVar(RHSVar);\n\n  // Drill down to the base element type on both arrays.\n  const ArrayType *ArrayTy = Type->getAsArrayTypeUnsafe();\n  llvm::Value *NumElements = CGF.emitArrayLength(ArrayTy, ElementTy, LHSAddr);\n\n  llvm::Value *RHSBegin = RHSAddr.getPointer();\n  llvm::Value *LHSBegin = LHSAddr.getPointer();\n  // Cast from pointer to array type to pointer to single element.\n  llvm::Value *LHSEnd = CGF.Builder.CreateGEP(LHSBegin, NumElements);\n  // The basic structure here is a while-do loop.\n  llvm::BasicBlock *BodyBB = CGF.createBasicBlock(\"omp.arraycpy.body\");\n  llvm::BasicBlock *DoneBB = CGF.createBasicBlock(\"omp.arraycpy.done\");\n  llvm::Value *IsEmpty =\n      CGF.Builder.CreateICmpEQ(LHSBegin, LHSEnd, \"omp.arraycpy.isempty\");\n  CGF.Builder.CreateCondBr(IsEmpty, DoneBB, BodyBB);\n\n  // Enter the loop body, making that address the current address.\n  llvm::BasicBlock *EntryBB = CGF.Builder.GetInsertBlock();\n  CGF.EmitBlock(BodyBB);\n\n  CharUnits ElementSize = CGF.getContext().getTypeSizeInChars(ElementTy);\n\n  llvm::PHINode *RHSElementPHI = CGF.Builder.CreatePHI(\n      RHSBegin->getType(), 2, \"omp.arraycpy.srcElementPast\");\n  RHSElementPHI->addIncoming(RHSBegin, EntryBB);\n  Address RHSElementCurrent =\n      Address(RHSElementPHI,\n              RHSAddr.getAlignment().alignmentOfArrayElement(ElementSize));\n\n  llvm::PHINode *LHSElementPHI = CGF.Builder.CreatePHI(\n      LHSBegin->getType(), 2, \"omp.arraycpy.destElementPast\");\n  LHSElementPHI->addIncoming(LHSBegin, EntryBB);\n  Address LHSElementCurrent =\n      Address(LHSElementPHI,\n              LHSAddr.getAlignment().alignmentOfArrayElement(ElementSize));\n\n  // Emit copy.\n  CodeGenFunction::OMPPrivateScope Scope(CGF);\n  Scope.addPrivate(LHSVar, [=]() { return LHSElementCurrent; });\n  Scope.addPrivate(RHSVar, [=]() { return RHSElementCurrent; });\n  Scope.Privatize();\n  RedOpGen(CGF, XExpr, EExpr, UpExpr);\n  Scope.ForceCleanup();\n\n  // Shift the address forward by one element.\n  llvm::Value *LHSElementNext = CGF.Builder.CreateConstGEP1_32(\n      LHSElementPHI, /*Idx0=*/1, \"omp.arraycpy.dest.element\");\n  llvm::Value *RHSElementNext = CGF.Builder.CreateConstGEP1_32(\n      RHSElementPHI, /*Idx0=*/1, \"omp.arraycpy.src.element\");\n  // Check whether we've reached the end.\n  llvm::Value *Done =\n      CGF.Builder.CreateICmpEQ(LHSElementNext, LHSEnd, \"omp.arraycpy.done\");\n  CGF.Builder.CreateCondBr(Done, DoneBB, BodyBB);\n  LHSElementPHI->addIncoming(LHSElementNext, CGF.Builder.GetInsertBlock());\n  RHSElementPHI->addIncoming(RHSElementNext, CGF.Builder.GetInsertBlock());\n\n  // Done.\n  CGF.EmitBlock(DoneBB, /*IsFinished=*/true);\n}\n\n/// Emit reduction combiner. If the combiner is a simple expression emit it as\n/// is, otherwise consider it as combiner of UDR decl and emit it as a call of\n/// UDR combiner function.\nstatic void emitReductionCombiner(CodeGenFunction &CGF,\n                                  const Expr *ReductionOp) {\n  if (const auto *CE = dyn_cast<CallExpr>(ReductionOp))\n    if (const auto *OVE = dyn_cast<OpaqueValueExpr>(CE->getCallee()))\n      if (const auto *DRE =\n              dyn_cast<DeclRefExpr>(OVE->getSourceExpr()->IgnoreImpCasts()))\n        if (const auto *DRD =\n                dyn_cast<OMPDeclareReductionDecl>(DRE->getDecl())) {\n          std::pair<llvm::Function *, llvm::Function *> Reduction =\n              CGF.CGM.getOpenMPRuntime().getUserDefinedReduction(DRD);\n          RValue Func = RValue::get(Reduction.first);\n          CodeGenFunction::OpaqueValueMapping Map(CGF, OVE, Func);\n          CGF.EmitIgnoredExpr(ReductionOp);\n          return;\n        }\n  CGF.EmitIgnoredExpr(ReductionOp);\n}\n\nllvm::Function *CGOpenMPRuntime::emitReductionFunction(\n    SourceLocation Loc, llvm::Type *ArgsType, ArrayRef<const Expr *> Privates,\n    ArrayRef<const Expr *> LHSExprs, ArrayRef<const Expr *> RHSExprs,\n    ArrayRef<const Expr *> ReductionOps) {\n  ASTContext &C = CGM.getContext();\n\n  // void reduction_func(void *LHSArg, void *RHSArg);\n  FunctionArgList Args;\n  ImplicitParamDecl LHSArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                           ImplicitParamDecl::Other);\n  ImplicitParamDecl RHSArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                           ImplicitParamDecl::Other);\n  Args.push_back(&LHSArg);\n  Args.push_back(&RHSArg);\n  const auto &CGFI =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  std::string Name = getName({\"omp\", \"reduction\", \"reduction_func\"});\n  auto *Fn = llvm::Function::Create(CGM.getTypes().GetFunctionType(CGFI),\n                                    llvm::GlobalValue::InternalLinkage, Name,\n                                    &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, CGFI);\n  Fn->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, CGFI, Args, Loc, Loc);\n\n  // Dst = (void*[n])(LHSArg);\n  // Src = (void*[n])(RHSArg);\n  Address LHS(CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      CGF.Builder.CreateLoad(CGF.GetAddrOfLocalVar(&LHSArg)),\n      ArgsType), CGF.getPointerAlign());\n  Address RHS(CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      CGF.Builder.CreateLoad(CGF.GetAddrOfLocalVar(&RHSArg)),\n      ArgsType), CGF.getPointerAlign());\n\n  //  ...\n  //  *(Type<i>*)lhs[i] = RedOp<i>(*(Type<i>*)lhs[i], *(Type<i>*)rhs[i]);\n  //  ...\n  CodeGenFunction::OMPPrivateScope Scope(CGF);\n  auto IPriv = Privates.begin();\n  unsigned Idx = 0;\n  for (unsigned I = 0, E = ReductionOps.size(); I < E; ++I, ++IPriv, ++Idx) {\n    const auto *RHSVar =\n        cast<VarDecl>(cast<DeclRefExpr>(RHSExprs[I])->getDecl());\n    Scope.addPrivate(RHSVar, [&CGF, RHS, Idx, RHSVar]() {\n      return emitAddrOfVarFromArray(CGF, RHS, Idx, RHSVar);\n    });\n    const auto *LHSVar =\n        cast<VarDecl>(cast<DeclRefExpr>(LHSExprs[I])->getDecl());\n    Scope.addPrivate(LHSVar, [&CGF, LHS, Idx, LHSVar]() {\n      return emitAddrOfVarFromArray(CGF, LHS, Idx, LHSVar);\n    });\n    QualType PrivTy = (*IPriv)->getType();\n    if (PrivTy->isVariablyModifiedType()) {\n      // Get array size and emit VLA type.\n      ++Idx;\n      Address Elem = CGF.Builder.CreateConstArrayGEP(LHS, Idx);\n      llvm::Value *Ptr = CGF.Builder.CreateLoad(Elem);\n      const VariableArrayType *VLA =\n          CGF.getContext().getAsVariableArrayType(PrivTy);\n      const auto *OVE = cast<OpaqueValueExpr>(VLA->getSizeExpr());\n      CodeGenFunction::OpaqueValueMapping OpaqueMap(\n          CGF, OVE, RValue::get(CGF.Builder.CreatePtrToInt(Ptr, CGF.SizeTy)));\n      CGF.EmitVariablyModifiedType(PrivTy);\n    }\n  }\n  Scope.Privatize();\n  IPriv = Privates.begin();\n  auto ILHS = LHSExprs.begin();\n  auto IRHS = RHSExprs.begin();\n  for (const Expr *E : ReductionOps) {\n    if ((*IPriv)->getType()->isArrayType()) {\n      // Emit reduction for array section.\n      const auto *LHSVar = cast<VarDecl>(cast<DeclRefExpr>(*ILHS)->getDecl());\n      const auto *RHSVar = cast<VarDecl>(cast<DeclRefExpr>(*IRHS)->getDecl());\n      EmitOMPAggregateReduction(\n          CGF, (*IPriv)->getType(), LHSVar, RHSVar,\n          [=](CodeGenFunction &CGF, const Expr *, const Expr *, const Expr *) {\n            emitReductionCombiner(CGF, E);\n          });\n    } else {\n      // Emit reduction for array subscript or single variable.\n      emitReductionCombiner(CGF, E);\n    }\n    ++IPriv;\n    ++ILHS;\n    ++IRHS;\n  }\n  Scope.ForceCleanup();\n  CGF.FinishFunction();\n  return Fn;\n}\n\nvoid CGOpenMPRuntime::emitSingleReductionCombiner(CodeGenFunction &CGF,\n                                                  const Expr *ReductionOp,\n                                                  const Expr *PrivateRef,\n                                                  const DeclRefExpr *LHS,\n                                                  const DeclRefExpr *RHS) {\n  if (PrivateRef->getType()->isArrayType()) {\n    // Emit reduction for array section.\n    const auto *LHSVar = cast<VarDecl>(LHS->getDecl());\n    const auto *RHSVar = cast<VarDecl>(RHS->getDecl());\n    EmitOMPAggregateReduction(\n        CGF, PrivateRef->getType(), LHSVar, RHSVar,\n        [=](CodeGenFunction &CGF, const Expr *, const Expr *, const Expr *) {\n          emitReductionCombiner(CGF, ReductionOp);\n        });\n  } else {\n    // Emit reduction for array subscript or single variable.\n    emitReductionCombiner(CGF, ReductionOp);\n  }\n}\n\nvoid CGOpenMPRuntime::emitReduction(CodeGenFunction &CGF, SourceLocation Loc,\n                                    ArrayRef<const Expr *> Privates,\n                                    ArrayRef<const Expr *> LHSExprs,\n                                    ArrayRef<const Expr *> RHSExprs,\n                                    ArrayRef<const Expr *> ReductionOps,\n                                    ReductionOptionsTy Options) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  bool WithNowait = Options.WithNowait;\n  bool SimpleReduction = Options.SimpleReduction;\n\n  // Next code should be emitted for reduction:\n  //\n  // static kmp_critical_name lock = { 0 };\n  //\n  // void reduce_func(void *lhs[<n>], void *rhs[<n>]) {\n  //  *(Type0*)lhs[0] = ReductionOperation0(*(Type0*)lhs[0], *(Type0*)rhs[0]);\n  //  ...\n  //  *(Type<n>-1*)lhs[<n>-1] = ReductionOperation<n>-1(*(Type<n>-1*)lhs[<n>-1],\n  //  *(Type<n>-1*)rhs[<n>-1]);\n  // }\n  //\n  // ...\n  // void *RedList[<n>] = {&<RHSExprs>[0], ..., &<RHSExprs>[<n>-1]};\n  // switch (__kmpc_reduce{_nowait}(<loc>, <gtid>, <n>, sizeof(RedList),\n  // RedList, reduce_func, &<lock>)) {\n  // case 1:\n  //  ...\n  //  <LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]);\n  //  ...\n  // __kmpc_end_reduce{_nowait}(<loc>, <gtid>, &<lock>);\n  // break;\n  // case 2:\n  //  ...\n  //  Atomic(<LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]));\n  //  ...\n  // [__kmpc_end_reduce(<loc>, <gtid>, &<lock>);]\n  // break;\n  // default:;\n  // }\n  //\n  // if SimpleReduction is true, only the next code is generated:\n  //  ...\n  //  <LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]);\n  //  ...\n\n  ASTContext &C = CGM.getContext();\n\n  if (SimpleReduction) {\n    CodeGenFunction::RunCleanupsScope Scope(CGF);\n    auto IPriv = Privates.begin();\n    auto ILHS = LHSExprs.begin();\n    auto IRHS = RHSExprs.begin();\n    for (const Expr *E : ReductionOps) {\n      emitSingleReductionCombiner(CGF, E, *IPriv, cast<DeclRefExpr>(*ILHS),\n                                  cast<DeclRefExpr>(*IRHS));\n      ++IPriv;\n      ++ILHS;\n      ++IRHS;\n    }\n    return;\n  }\n\n  // 1. Build a list of reduction variables.\n  // void *RedList[<n>] = {<ReductionVars>[0], ..., <ReductionVars>[<n>-1]};\n  auto Size = RHSExprs.size();\n  for (const Expr *E : Privates) {\n    if (E->getType()->isVariablyModifiedType())\n      // Reserve place for array size.\n      ++Size;\n  }\n  llvm::APInt ArraySize(/*unsigned int numBits=*/32, Size);\n  QualType ReductionArrayTy =\n      C.getConstantArrayType(C.VoidPtrTy, ArraySize, nullptr, ArrayType::Normal,\n                             /*IndexTypeQuals=*/0);\n  Address ReductionList =\n      CGF.CreateMemTemp(ReductionArrayTy, \".omp.reduction.red_list\");\n  auto IPriv = Privates.begin();\n  unsigned Idx = 0;\n  for (unsigned I = 0, E = RHSExprs.size(); I < E; ++I, ++IPriv, ++Idx) {\n    Address Elem = CGF.Builder.CreateConstArrayGEP(ReductionList, Idx);\n    CGF.Builder.CreateStore(\n        CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n            CGF.EmitLValue(RHSExprs[I]).getPointer(CGF), CGF.VoidPtrTy),\n        Elem);\n    if ((*IPriv)->getType()->isVariablyModifiedType()) {\n      // Store array size.\n      ++Idx;\n      Elem = CGF.Builder.CreateConstArrayGEP(ReductionList, Idx);\n      llvm::Value *Size = CGF.Builder.CreateIntCast(\n          CGF.getVLASize(\n                 CGF.getContext().getAsVariableArrayType((*IPriv)->getType()))\n              .NumElts,\n          CGF.SizeTy, /*isSigned=*/false);\n      CGF.Builder.CreateStore(CGF.Builder.CreateIntToPtr(Size, CGF.VoidPtrTy),\n                              Elem);\n    }\n  }\n\n  // 2. Emit reduce_func().\n  llvm::Function *ReductionFn = emitReductionFunction(\n      Loc, CGF.ConvertTypeForMem(ReductionArrayTy)->getPointerTo(), Privates,\n      LHSExprs, RHSExprs, ReductionOps);\n\n  // 3. Create static kmp_critical_name lock = { 0 };\n  std::string Name = getName({\"reduction\"});\n  llvm::Value *Lock = getCriticalRegionLock(Name);\n\n  // 4. Build res = __kmpc_reduce{_nowait}(<loc>, <gtid>, <n>, sizeof(RedList),\n  // RedList, reduce_func, &<lock>);\n  llvm::Value *IdentTLoc = emitUpdateLocation(CGF, Loc, OMP_ATOMIC_REDUCE);\n  llvm::Value *ThreadId = getThreadID(CGF, Loc);\n  llvm::Value *ReductionArrayTySize = CGF.getTypeSize(ReductionArrayTy);\n  llvm::Value *RL = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      ReductionList.getPointer(), CGF.VoidPtrTy);\n  llvm::Value *Args[] = {\n      IdentTLoc,                             // ident_t *<loc>\n      ThreadId,                              // i32 <gtid>\n      CGF.Builder.getInt32(RHSExprs.size()), // i32 <n>\n      ReductionArrayTySize,                  // size_type sizeof(RedList)\n      RL,                                    // void *RedList\n      ReductionFn, // void (*) (void *, void *) <reduce_func>\n      Lock         // kmp_critical_name *&<lock>\n  };\n  llvm::Value *Res = CGF.EmitRuntimeCall(\n      OMPBuilder.getOrCreateRuntimeFunction(\n          CGM.getModule(),\n          WithNowait ? OMPRTL___kmpc_reduce_nowait : OMPRTL___kmpc_reduce),\n      Args);\n\n  // 5. Build switch(res)\n  llvm::BasicBlock *DefaultBB = CGF.createBasicBlock(\".omp.reduction.default\");\n  llvm::SwitchInst *SwInst =\n      CGF.Builder.CreateSwitch(Res, DefaultBB, /*NumCases=*/2);\n\n  // 6. Build case 1:\n  //  ...\n  //  <LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]);\n  //  ...\n  // __kmpc_end_reduce{_nowait}(<loc>, <gtid>, &<lock>);\n  // break;\n  llvm::BasicBlock *Case1BB = CGF.createBasicBlock(\".omp.reduction.case1\");\n  SwInst->addCase(CGF.Builder.getInt32(1), Case1BB);\n  CGF.EmitBlock(Case1BB);\n\n  // Add emission of __kmpc_end_reduce{_nowait}(<loc>, <gtid>, &<lock>);\n  llvm::Value *EndArgs[] = {\n      IdentTLoc, // ident_t *<loc>\n      ThreadId,  // i32 <gtid>\n      Lock       // kmp_critical_name *&<lock>\n  };\n  auto &&CodeGen = [Privates, LHSExprs, RHSExprs, ReductionOps](\n                       CodeGenFunction &CGF, PrePostActionTy &Action) {\n    CGOpenMPRuntime &RT = CGF.CGM.getOpenMPRuntime();\n    auto IPriv = Privates.begin();\n    auto ILHS = LHSExprs.begin();\n    auto IRHS = RHSExprs.begin();\n    for (const Expr *E : ReductionOps) {\n      RT.emitSingleReductionCombiner(CGF, E, *IPriv, cast<DeclRefExpr>(*ILHS),\n                                     cast<DeclRefExpr>(*IRHS));\n      ++IPriv;\n      ++ILHS;\n      ++IRHS;\n    }\n  };\n  RegionCodeGenTy RCG(CodeGen);\n  CommonActionTy Action(\n      nullptr, llvm::None,\n      OMPBuilder.getOrCreateRuntimeFunction(\n          CGM.getModule(), WithNowait ? OMPRTL___kmpc_end_reduce_nowait\n                                      : OMPRTL___kmpc_end_reduce),\n      EndArgs);\n  RCG.setAction(Action);\n  RCG(CGF);\n\n  CGF.EmitBranch(DefaultBB);\n\n  // 7. Build case 2:\n  //  ...\n  //  Atomic(<LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]));\n  //  ...\n  // break;\n  llvm::BasicBlock *Case2BB = CGF.createBasicBlock(\".omp.reduction.case2\");\n  SwInst->addCase(CGF.Builder.getInt32(2), Case2BB);\n  CGF.EmitBlock(Case2BB);\n\n  auto &&AtomicCodeGen = [Loc, Privates, LHSExprs, RHSExprs, ReductionOps](\n                             CodeGenFunction &CGF, PrePostActionTy &Action) {\n    auto ILHS = LHSExprs.begin();\n    auto IRHS = RHSExprs.begin();\n    auto IPriv = Privates.begin();\n    for (const Expr *E : ReductionOps) {\n      const Expr *XExpr = nullptr;\n      const Expr *EExpr = nullptr;\n      const Expr *UpExpr = nullptr;\n      BinaryOperatorKind BO = BO_Comma;\n      if (const auto *BO = dyn_cast<BinaryOperator>(E)) {\n        if (BO->getOpcode() == BO_Assign) {\n          XExpr = BO->getLHS();\n          UpExpr = BO->getRHS();\n        }\n      }\n      // Try to emit update expression as a simple atomic.\n      const Expr *RHSExpr = UpExpr;\n      if (RHSExpr) {\n        // Analyze RHS part of the whole expression.\n        if (const auto *ACO = dyn_cast<AbstractConditionalOperator>(\n                RHSExpr->IgnoreParenImpCasts())) {\n          // If this is a conditional operator, analyze its condition for\n          // min/max reduction operator.\n          RHSExpr = ACO->getCond();\n        }\n        if (const auto *BORHS =\n                dyn_cast<BinaryOperator>(RHSExpr->IgnoreParenImpCasts())) {\n          EExpr = BORHS->getRHS();\n          BO = BORHS->getOpcode();\n        }\n      }\n      if (XExpr) {\n        const auto *VD = cast<VarDecl>(cast<DeclRefExpr>(*ILHS)->getDecl());\n        auto &&AtomicRedGen = [BO, VD,\n                               Loc](CodeGenFunction &CGF, const Expr *XExpr,\n                                    const Expr *EExpr, const Expr *UpExpr) {\n          LValue X = CGF.EmitLValue(XExpr);\n          RValue E;\n          if (EExpr)\n            E = CGF.EmitAnyExpr(EExpr);\n          CGF.EmitOMPAtomicSimpleUpdateExpr(\n              X, E, BO, /*IsXLHSInRHSPart=*/true,\n              llvm::AtomicOrdering::Monotonic, Loc,\n              [&CGF, UpExpr, VD, Loc](RValue XRValue) {\n                CodeGenFunction::OMPPrivateScope PrivateScope(CGF);\n                PrivateScope.addPrivate(\n                    VD, [&CGF, VD, XRValue, Loc]() {\n                      Address LHSTemp = CGF.CreateMemTemp(VD->getType());\n                      CGF.emitOMPSimpleStore(\n                          CGF.MakeAddrLValue(LHSTemp, VD->getType()), XRValue,\n                          VD->getType().getNonReferenceType(), Loc);\n                      return LHSTemp;\n                    });\n                (void)PrivateScope.Privatize();\n                return CGF.EmitAnyExpr(UpExpr);\n              });\n        };\n        if ((*IPriv)->getType()->isArrayType()) {\n          // Emit atomic reduction for array section.\n          const auto *RHSVar =\n              cast<VarDecl>(cast<DeclRefExpr>(*IRHS)->getDecl());\n          EmitOMPAggregateReduction(CGF, (*IPriv)->getType(), VD, RHSVar,\n                                    AtomicRedGen, XExpr, EExpr, UpExpr);\n        } else {\n          // Emit atomic reduction for array subscript or single variable.\n          AtomicRedGen(CGF, XExpr, EExpr, UpExpr);\n        }\n      } else {\n        // Emit as a critical region.\n        auto &&CritRedGen = [E, Loc](CodeGenFunction &CGF, const Expr *,\n                                           const Expr *, const Expr *) {\n          CGOpenMPRuntime &RT = CGF.CGM.getOpenMPRuntime();\n          std::string Name = RT.getName({\"atomic_reduction\"});\n          RT.emitCriticalRegion(\n              CGF, Name,\n              [=](CodeGenFunction &CGF, PrePostActionTy &Action) {\n                Action.Enter(CGF);\n                emitReductionCombiner(CGF, E);\n              },\n              Loc);\n        };\n        if ((*IPriv)->getType()->isArrayType()) {\n          const auto *LHSVar =\n              cast<VarDecl>(cast<DeclRefExpr>(*ILHS)->getDecl());\n          const auto *RHSVar =\n              cast<VarDecl>(cast<DeclRefExpr>(*IRHS)->getDecl());\n          EmitOMPAggregateReduction(CGF, (*IPriv)->getType(), LHSVar, RHSVar,\n                                    CritRedGen);\n        } else {\n          CritRedGen(CGF, nullptr, nullptr, nullptr);\n        }\n      }\n      ++ILHS;\n      ++IRHS;\n      ++IPriv;\n    }\n  };\n  RegionCodeGenTy AtomicRCG(AtomicCodeGen);\n  if (!WithNowait) {\n    // Add emission of __kmpc_end_reduce(<loc>, <gtid>, &<lock>);\n    llvm::Value *EndArgs[] = {\n        IdentTLoc, // ident_t *<loc>\n        ThreadId,  // i32 <gtid>\n        Lock       // kmp_critical_name *&<lock>\n    };\n    CommonActionTy Action(nullptr, llvm::None,\n                          OMPBuilder.getOrCreateRuntimeFunction(\n                              CGM.getModule(), OMPRTL___kmpc_end_reduce),\n                          EndArgs);\n    AtomicRCG.setAction(Action);\n    AtomicRCG(CGF);\n  } else {\n    AtomicRCG(CGF);\n  }\n\n  CGF.EmitBranch(DefaultBB);\n  CGF.EmitBlock(DefaultBB, /*IsFinished=*/true);\n}\n\n/// Generates unique name for artificial threadprivate variables.\n/// Format is: <Prefix> \".\" <Decl_mangled_name> \"_\" \"<Decl_start_loc_raw_enc>\"\nstatic std::string generateUniqueName(CodeGenModule &CGM, StringRef Prefix,\n                                      const Expr *Ref) {\n  SmallString<256> Buffer;\n  llvm::raw_svector_ostream Out(Buffer);\n  const clang::DeclRefExpr *DE;\n  const VarDecl *D = ::getBaseDecl(Ref, DE);\n  if (!D)\n    D = cast<VarDecl>(cast<DeclRefExpr>(Ref)->getDecl());\n  D = D->getCanonicalDecl();\n  std::string Name = CGM.getOpenMPRuntime().getName(\n      {D->isLocalVarDeclOrParm() ? D->getName() : CGM.getMangledName(D)});\n  Out << Prefix << Name << \"_\"\n      << D->getCanonicalDecl()->getBeginLoc().getRawEncoding();\n  return std::string(Out.str());\n}\n\n/// Emits reduction initializer function:\n/// \\code\n/// void @.red_init(void* %arg, void* %orig) {\n/// %0 = bitcast void* %arg to <type>*\n/// store <type> <init>, <type>* %0\n/// ret void\n/// }\n/// \\endcode\nstatic llvm::Value *emitReduceInitFunction(CodeGenModule &CGM,\n                                           SourceLocation Loc,\n                                           ReductionCodeGen &RCG, unsigned N) {\n  ASTContext &C = CGM.getContext();\n  QualType VoidPtrTy = C.VoidPtrTy;\n  VoidPtrTy.addRestrict();\n  FunctionArgList Args;\n  ImplicitParamDecl Param(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, VoidPtrTy,\n                          ImplicitParamDecl::Other);\n  ImplicitParamDecl ParamOrig(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, VoidPtrTy,\n                              ImplicitParamDecl::Other);\n  Args.emplace_back(&Param);\n  Args.emplace_back(&ParamOrig);\n  const auto &FnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *FnTy = CGM.getTypes().GetFunctionType(FnInfo);\n  std::string Name = CGM.getOpenMPRuntime().getName({\"red_init\", \"\"});\n  auto *Fn = llvm::Function::Create(FnTy, llvm::GlobalValue::InternalLinkage,\n                                    Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, FnInfo);\n  Fn->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, FnInfo, Args, Loc, Loc);\n  Address PrivateAddr = CGF.EmitLoadOfPointer(\n      CGF.GetAddrOfLocalVar(&Param),\n      C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n  llvm::Value *Size = nullptr;\n  // If the size of the reduction item is non-constant, load it from global\n  // threadprivate variable.\n  if (RCG.getSizes(N).second) {\n    Address SizeAddr = CGM.getOpenMPRuntime().getAddrOfArtificialThreadPrivate(\n        CGF, CGM.getContext().getSizeType(),\n        generateUniqueName(CGM, \"reduction_size\", RCG.getRefExpr(N)));\n    Size = CGF.EmitLoadOfScalar(SizeAddr, /*Volatile=*/false,\n                                CGM.getContext().getSizeType(), Loc);\n  }\n  RCG.emitAggregateType(CGF, N, Size);\n  LValue OrigLVal;\n  // If initializer uses initializer from declare reduction construct, emit a\n  // pointer to the address of the original reduction item (reuired by reduction\n  // initializer)\n  if (RCG.usesReductionInitializer(N)) {\n    Address SharedAddr = CGF.GetAddrOfLocalVar(&ParamOrig);\n    SharedAddr = CGF.EmitLoadOfPointer(\n        SharedAddr,\n        CGM.getContext().VoidPtrTy.castAs<PointerType>()->getTypePtr());\n    OrigLVal = CGF.MakeAddrLValue(SharedAddr, CGM.getContext().VoidPtrTy);\n  } else {\n    OrigLVal = CGF.MakeNaturalAlignAddrLValue(\n        llvm::ConstantPointerNull::get(CGM.VoidPtrTy),\n        CGM.getContext().VoidPtrTy);\n  }\n  // Emit the initializer:\n  // %0 = bitcast void* %arg to <type>*\n  // store <type> <init>, <type>* %0\n  RCG.emitInitialization(CGF, N, PrivateAddr, OrigLVal,\n                         [](CodeGenFunction &) { return false; });\n  CGF.FinishFunction();\n  return Fn;\n}\n\n/// Emits reduction combiner function:\n/// \\code\n/// void @.red_comb(void* %arg0, void* %arg1) {\n/// %lhs = bitcast void* %arg0 to <type>*\n/// %rhs = bitcast void* %arg1 to <type>*\n/// %2 = <ReductionOp>(<type>* %lhs, <type>* %rhs)\n/// store <type> %2, <type>* %lhs\n/// ret void\n/// }\n/// \\endcode\nstatic llvm::Value *emitReduceCombFunction(CodeGenModule &CGM,\n                                           SourceLocation Loc,\n                                           ReductionCodeGen &RCG, unsigned N,\n                                           const Expr *ReductionOp,\n                                           const Expr *LHS, const Expr *RHS,\n                                           const Expr *PrivateRef) {\n  ASTContext &C = CGM.getContext();\n  const auto *LHSVD = cast<VarDecl>(cast<DeclRefExpr>(LHS)->getDecl());\n  const auto *RHSVD = cast<VarDecl>(cast<DeclRefExpr>(RHS)->getDecl());\n  FunctionArgList Args;\n  ImplicitParamDecl ParamInOut(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                               C.VoidPtrTy, ImplicitParamDecl::Other);\n  ImplicitParamDecl ParamIn(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                            ImplicitParamDecl::Other);\n  Args.emplace_back(&ParamInOut);\n  Args.emplace_back(&ParamIn);\n  const auto &FnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *FnTy = CGM.getTypes().GetFunctionType(FnInfo);\n  std::string Name = CGM.getOpenMPRuntime().getName({\"red_comb\", \"\"});\n  auto *Fn = llvm::Function::Create(FnTy, llvm::GlobalValue::InternalLinkage,\n                                    Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, FnInfo);\n  Fn->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, FnInfo, Args, Loc, Loc);\n  llvm::Value *Size = nullptr;\n  // If the size of the reduction item is non-constant, load it from global\n  // threadprivate variable.\n  if (RCG.getSizes(N).second) {\n    Address SizeAddr = CGM.getOpenMPRuntime().getAddrOfArtificialThreadPrivate(\n        CGF, CGM.getContext().getSizeType(),\n        generateUniqueName(CGM, \"reduction_size\", RCG.getRefExpr(N)));\n    Size = CGF.EmitLoadOfScalar(SizeAddr, /*Volatile=*/false,\n                                CGM.getContext().getSizeType(), Loc);\n  }\n  RCG.emitAggregateType(CGF, N, Size);\n  // Remap lhs and rhs variables to the addresses of the function arguments.\n  // %lhs = bitcast void* %arg0 to <type>*\n  // %rhs = bitcast void* %arg1 to <type>*\n  CodeGenFunction::OMPPrivateScope PrivateScope(CGF);\n  PrivateScope.addPrivate(LHSVD, [&C, &CGF, &ParamInOut, LHSVD]() {\n    // Pull out the pointer to the variable.\n    Address PtrAddr = CGF.EmitLoadOfPointer(\n        CGF.GetAddrOfLocalVar(&ParamInOut),\n        C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n    return CGF.Builder.CreateElementBitCast(\n        PtrAddr, CGF.ConvertTypeForMem(LHSVD->getType()));\n  });\n  PrivateScope.addPrivate(RHSVD, [&C, &CGF, &ParamIn, RHSVD]() {\n    // Pull out the pointer to the variable.\n    Address PtrAddr = CGF.EmitLoadOfPointer(\n        CGF.GetAddrOfLocalVar(&ParamIn),\n        C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n    return CGF.Builder.CreateElementBitCast(\n        PtrAddr, CGF.ConvertTypeForMem(RHSVD->getType()));\n  });\n  PrivateScope.Privatize();\n  // Emit the combiner body:\n  // %2 = <ReductionOp>(<type> *%lhs, <type> *%rhs)\n  // store <type> %2, <type>* %lhs\n  CGM.getOpenMPRuntime().emitSingleReductionCombiner(\n      CGF, ReductionOp, PrivateRef, cast<DeclRefExpr>(LHS),\n      cast<DeclRefExpr>(RHS));\n  CGF.FinishFunction();\n  return Fn;\n}\n\n/// Emits reduction finalizer function:\n/// \\code\n/// void @.red_fini(void* %arg) {\n/// %0 = bitcast void* %arg to <type>*\n/// <destroy>(<type>* %0)\n/// ret void\n/// }\n/// \\endcode\nstatic llvm::Value *emitReduceFiniFunction(CodeGenModule &CGM,\n                                           SourceLocation Loc,\n                                           ReductionCodeGen &RCG, unsigned N) {\n  if (!RCG.needCleanups(N))\n    return nullptr;\n  ASTContext &C = CGM.getContext();\n  FunctionArgList Args;\n  ImplicitParamDecl Param(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                          ImplicitParamDecl::Other);\n  Args.emplace_back(&Param);\n  const auto &FnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *FnTy = CGM.getTypes().GetFunctionType(FnInfo);\n  std::string Name = CGM.getOpenMPRuntime().getName({\"red_fini\", \"\"});\n  auto *Fn = llvm::Function::Create(FnTy, llvm::GlobalValue::InternalLinkage,\n                                    Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, FnInfo);\n  Fn->setDoesNotRecurse();\n  CodeGenFunction CGF(CGM);\n  CGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, FnInfo, Args, Loc, Loc);\n  Address PrivateAddr = CGF.EmitLoadOfPointer(\n      CGF.GetAddrOfLocalVar(&Param),\n      C.getPointerType(C.VoidPtrTy).castAs<PointerType>());\n  llvm::Value *Size = nullptr;\n  // If the size of the reduction item is non-constant, load it from global\n  // threadprivate variable.\n  if (RCG.getSizes(N).second) {\n    Address SizeAddr = CGM.getOpenMPRuntime().getAddrOfArtificialThreadPrivate(\n        CGF, CGM.getContext().getSizeType(),\n        generateUniqueName(CGM, \"reduction_size\", RCG.getRefExpr(N)));\n    Size = CGF.EmitLoadOfScalar(SizeAddr, /*Volatile=*/false,\n                                CGM.getContext().getSizeType(), Loc);\n  }\n  RCG.emitAggregateType(CGF, N, Size);\n  // Emit the finalizer body:\n  // <destroy>(<type>* %0)\n  RCG.emitCleanups(CGF, N, PrivateAddr);\n  CGF.FinishFunction(Loc);\n  return Fn;\n}\n\nllvm::Value *CGOpenMPRuntime::emitTaskReductionInit(\n    CodeGenFunction &CGF, SourceLocation Loc, ArrayRef<const Expr *> LHSExprs,\n    ArrayRef<const Expr *> RHSExprs, const OMPTaskDataTy &Data) {\n  if (!CGF.HaveInsertPoint() || Data.ReductionVars.empty())\n    return nullptr;\n\n  // Build typedef struct:\n  // kmp_taskred_input {\n  //   void *reduce_shar; // shared reduction item\n  //   void *reduce_orig; // original reduction item used for initialization\n  //   size_t reduce_size; // size of data item\n  //   void *reduce_init; // data initialization routine\n  //   void *reduce_fini; // data finalization routine\n  //   void *reduce_comb; // data combiner routine\n  //   kmp_task_red_flags_t flags; // flags for additional info from compiler\n  // } kmp_taskred_input_t;\n  ASTContext &C = CGM.getContext();\n  RecordDecl *RD = C.buildImplicitRecord(\"kmp_taskred_input_t\");\n  RD->startDefinition();\n  const FieldDecl *SharedFD = addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  const FieldDecl *OrigFD = addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  const FieldDecl *SizeFD = addFieldToRecordDecl(C, RD, C.getSizeType());\n  const FieldDecl *InitFD  = addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  const FieldDecl *FiniFD = addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  const FieldDecl *CombFD = addFieldToRecordDecl(C, RD, C.VoidPtrTy);\n  const FieldDecl *FlagsFD = addFieldToRecordDecl(\n      C, RD, C.getIntTypeForBitwidth(/*DestWidth=*/32, /*Signed=*/false));\n  RD->completeDefinition();\n  QualType RDType = C.getRecordType(RD);\n  unsigned Size = Data.ReductionVars.size();\n  llvm::APInt ArraySize(/*numBits=*/64, Size);\n  QualType ArrayRDType = C.getConstantArrayType(\n      RDType, ArraySize, nullptr, ArrayType::Normal, /*IndexTypeQuals=*/0);\n  // kmp_task_red_input_t .rd_input.[Size];\n  Address TaskRedInput = CGF.CreateMemTemp(ArrayRDType, \".rd_input.\");\n  ReductionCodeGen RCG(Data.ReductionVars, Data.ReductionOrigs,\n                       Data.ReductionCopies, Data.ReductionOps);\n  for (unsigned Cnt = 0; Cnt < Size; ++Cnt) {\n    // kmp_task_red_input_t &ElemLVal = .rd_input.[Cnt];\n    llvm::Value *Idxs[] = {llvm::ConstantInt::get(CGM.SizeTy, /*V=*/0),\n                           llvm::ConstantInt::get(CGM.SizeTy, Cnt)};\n    llvm::Value *GEP = CGF.EmitCheckedInBoundsGEP(\n        TaskRedInput.getPointer(), Idxs,\n        /*SignedIndices=*/false, /*IsSubtraction=*/false, Loc,\n        \".rd_input.gep.\");\n    LValue ElemLVal = CGF.MakeNaturalAlignAddrLValue(GEP, RDType);\n    // ElemLVal.reduce_shar = &Shareds[Cnt];\n    LValue SharedLVal = CGF.EmitLValueForField(ElemLVal, SharedFD);\n    RCG.emitSharedOrigLValue(CGF, Cnt);\n    llvm::Value *CastedShared =\n        CGF.EmitCastToVoidPtr(RCG.getSharedLValue(Cnt).getPointer(CGF));\n    CGF.EmitStoreOfScalar(CastedShared, SharedLVal);\n    // ElemLVal.reduce_orig = &Origs[Cnt];\n    LValue OrigLVal = CGF.EmitLValueForField(ElemLVal, OrigFD);\n    llvm::Value *CastedOrig =\n        CGF.EmitCastToVoidPtr(RCG.getOrigLValue(Cnt).getPointer(CGF));\n    CGF.EmitStoreOfScalar(CastedOrig, OrigLVal);\n    RCG.emitAggregateType(CGF, Cnt);\n    llvm::Value *SizeValInChars;\n    llvm::Value *SizeVal;\n    std::tie(SizeValInChars, SizeVal) = RCG.getSizes(Cnt);\n    // We use delayed creation/initialization for VLAs and array sections. It is\n    // required because runtime does not provide the way to pass the sizes of\n    // VLAs/array sections to initializer/combiner/finalizer functions. Instead\n    // threadprivate global variables are used to store these values and use\n    // them in the functions.\n    bool DelayedCreation = !!SizeVal;\n    SizeValInChars = CGF.Builder.CreateIntCast(SizeValInChars, CGM.SizeTy,\n                                               /*isSigned=*/false);\n    LValue SizeLVal = CGF.EmitLValueForField(ElemLVal, SizeFD);\n    CGF.EmitStoreOfScalar(SizeValInChars, SizeLVal);\n    // ElemLVal.reduce_init = init;\n    LValue InitLVal = CGF.EmitLValueForField(ElemLVal, InitFD);\n    llvm::Value *InitAddr =\n        CGF.EmitCastToVoidPtr(emitReduceInitFunction(CGM, Loc, RCG, Cnt));\n    CGF.EmitStoreOfScalar(InitAddr, InitLVal);\n    // ElemLVal.reduce_fini = fini;\n    LValue FiniLVal = CGF.EmitLValueForField(ElemLVal, FiniFD);\n    llvm::Value *Fini = emitReduceFiniFunction(CGM, Loc, RCG, Cnt);\n    llvm::Value *FiniAddr = Fini\n                                ? CGF.EmitCastToVoidPtr(Fini)\n                                : llvm::ConstantPointerNull::get(CGM.VoidPtrTy);\n    CGF.EmitStoreOfScalar(FiniAddr, FiniLVal);\n    // ElemLVal.reduce_comb = comb;\n    LValue CombLVal = CGF.EmitLValueForField(ElemLVal, CombFD);\n    llvm::Value *CombAddr = CGF.EmitCastToVoidPtr(emitReduceCombFunction(\n        CGM, Loc, RCG, Cnt, Data.ReductionOps[Cnt], LHSExprs[Cnt],\n        RHSExprs[Cnt], Data.ReductionCopies[Cnt]));\n    CGF.EmitStoreOfScalar(CombAddr, CombLVal);\n    // ElemLVal.flags = 0;\n    LValue FlagsLVal = CGF.EmitLValueForField(ElemLVal, FlagsFD);\n    if (DelayedCreation) {\n      CGF.EmitStoreOfScalar(\n          llvm::ConstantInt::get(CGM.Int32Ty, /*V=*/1, /*isSigned=*/true),\n          FlagsLVal);\n    } else\n      CGF.EmitNullInitialization(FlagsLVal.getAddress(CGF),\n                                 FlagsLVal.getType());\n  }\n  if (Data.IsReductionWithTaskMod) {\n    // Build call void *__kmpc_taskred_modifier_init(ident_t *loc, int gtid, int\n    // is_ws, int num, void *data);\n    llvm::Value *IdentTLoc = emitUpdateLocation(CGF, Loc);\n    llvm::Value *GTid = CGF.Builder.CreateIntCast(getThreadID(CGF, Loc),\n                                                  CGM.IntTy, /*isSigned=*/true);\n    llvm::Value *Args[] = {\n        IdentTLoc, GTid,\n        llvm::ConstantInt::get(CGM.IntTy, Data.IsWorksharingReduction ? 1 : 0,\n                               /*isSigned=*/true),\n        llvm::ConstantInt::get(CGM.IntTy, Size, /*isSigned=*/true),\n        CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n            TaskRedInput.getPointer(), CGM.VoidPtrTy)};\n    return CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(\n            CGM.getModule(), OMPRTL___kmpc_taskred_modifier_init),\n        Args);\n  }\n  // Build call void *__kmpc_taskred_init(int gtid, int num_data, void *data);\n  llvm::Value *Args[] = {\n      CGF.Builder.CreateIntCast(getThreadID(CGF, Loc), CGM.IntTy,\n                                /*isSigned=*/true),\n      llvm::ConstantInt::get(CGM.IntTy, Size, /*isSigned=*/true),\n      CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(TaskRedInput.getPointer(),\n                                                      CGM.VoidPtrTy)};\n  return CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                                 CGM.getModule(), OMPRTL___kmpc_taskred_init),\n                             Args);\n}\n\nvoid CGOpenMPRuntime::emitTaskReductionFini(CodeGenFunction &CGF,\n                                            SourceLocation Loc,\n                                            bool IsWorksharingReduction) {\n  // Build call void *__kmpc_taskred_modifier_init(ident_t *loc, int gtid, int\n  // is_ws, int num, void *data);\n  llvm::Value *IdentTLoc = emitUpdateLocation(CGF, Loc);\n  llvm::Value *GTid = CGF.Builder.CreateIntCast(getThreadID(CGF, Loc),\n                                                CGM.IntTy, /*isSigned=*/true);\n  llvm::Value *Args[] = {IdentTLoc, GTid,\n                         llvm::ConstantInt::get(CGM.IntTy,\n                                                IsWorksharingReduction ? 1 : 0,\n                                                /*isSigned=*/true)};\n  (void)CGF.EmitRuntimeCall(\n      OMPBuilder.getOrCreateRuntimeFunction(\n          CGM.getModule(), OMPRTL___kmpc_task_reduction_modifier_fini),\n      Args);\n}\n\nvoid CGOpenMPRuntime::emitTaskReductionFixups(CodeGenFunction &CGF,\n                                              SourceLocation Loc,\n                                              ReductionCodeGen &RCG,\n                                              unsigned N) {\n  auto Sizes = RCG.getSizes(N);\n  // Emit threadprivate global variable if the type is non-constant\n  // (Sizes.second = nullptr).\n  if (Sizes.second) {\n    llvm::Value *SizeVal = CGF.Builder.CreateIntCast(Sizes.second, CGM.SizeTy,\n                                                     /*isSigned=*/false);\n    Address SizeAddr = getAddrOfArtificialThreadPrivate(\n        CGF, CGM.getContext().getSizeType(),\n        generateUniqueName(CGM, \"reduction_size\", RCG.getRefExpr(N)));\n    CGF.Builder.CreateStore(SizeVal, SizeAddr, /*IsVolatile=*/false);\n  }\n}\n\nAddress CGOpenMPRuntime::getTaskReductionItem(CodeGenFunction &CGF,\n                                              SourceLocation Loc,\n                                              llvm::Value *ReductionsPtr,\n                                              LValue SharedLVal) {\n  // Build call void *__kmpc_task_reduction_get_th_data(int gtid, void *tg, void\n  // *d);\n  llvm::Value *Args[] = {CGF.Builder.CreateIntCast(getThreadID(CGF, Loc),\n                                                   CGM.IntTy,\n                                                   /*isSigned=*/true),\n                         ReductionsPtr,\n                         CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n                             SharedLVal.getPointer(CGF), CGM.VoidPtrTy)};\n  return Address(\n      CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), OMPRTL___kmpc_task_reduction_get_th_data),\n          Args),\n      SharedLVal.getAlignment());\n}\n\nvoid CGOpenMPRuntime::emitTaskwaitCall(CodeGenFunction &CGF,\n                                       SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  if (CGF.CGM.getLangOpts().OpenMPIRBuilder) {\n    OMPBuilder.createTaskwait(CGF.Builder);\n  } else {\n    // Build call kmp_int32 __kmpc_omp_taskwait(ident_t *loc, kmp_int32\n    // global_tid);\n    llvm::Value *Args[] = {emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc)};\n    // Ignore return result until untied tasks are supported.\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___kmpc_omp_taskwait),\n                        Args);\n  }\n\n  if (auto *Region = dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo))\n    Region->emitUntiedSwitch(CGF);\n}\n\nvoid CGOpenMPRuntime::emitInlinedDirective(CodeGenFunction &CGF,\n                                           OpenMPDirectiveKind InnerKind,\n                                           const RegionCodeGenTy &CodeGen,\n                                           bool HasCancel) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  InlinedOpenMPRegionRAII Region(CGF, CodeGen, InnerKind, HasCancel);\n  CGF.CapturedStmtInfo->EmitBody(CGF, /*S=*/nullptr);\n}\n\nnamespace {\nenum RTCancelKind {\n  CancelNoreq = 0,\n  CancelParallel = 1,\n  CancelLoop = 2,\n  CancelSections = 3,\n  CancelTaskgroup = 4\n};\n} // anonymous namespace\n\nstatic RTCancelKind getCancellationKind(OpenMPDirectiveKind CancelRegion) {\n  RTCancelKind CancelKind = CancelNoreq;\n  if (CancelRegion == OMPD_parallel)\n    CancelKind = CancelParallel;\n  else if (CancelRegion == OMPD_for)\n    CancelKind = CancelLoop;\n  else if (CancelRegion == OMPD_sections)\n    CancelKind = CancelSections;\n  else {\n    assert(CancelRegion == OMPD_taskgroup);\n    CancelKind = CancelTaskgroup;\n  }\n  return CancelKind;\n}\n\nvoid CGOpenMPRuntime::emitCancellationPointCall(\n    CodeGenFunction &CGF, SourceLocation Loc,\n    OpenMPDirectiveKind CancelRegion) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // Build call kmp_int32 __kmpc_cancellationpoint(ident_t *loc, kmp_int32\n  // global_tid, kmp_int32 cncl_kind);\n  if (auto *OMPRegionInfo =\n          dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo)) {\n    // For 'cancellation point taskgroup', the task region info may not have a\n    // cancel. This may instead happen in another adjacent task.\n    if (CancelRegion == OMPD_taskgroup || OMPRegionInfo->hasCancel()) {\n      llvm::Value *Args[] = {\n          emitUpdateLocation(CGF, Loc), getThreadID(CGF, Loc),\n          CGF.Builder.getInt32(getCancellationKind(CancelRegion))};\n      // Ignore return result until untied tasks are supported.\n      llvm::Value *Result = CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), OMPRTL___kmpc_cancellationpoint),\n          Args);\n      // if (__kmpc_cancellationpoint()) {\n      //   exit from construct;\n      // }\n      llvm::BasicBlock *ExitBB = CGF.createBasicBlock(\".cancel.exit\");\n      llvm::BasicBlock *ContBB = CGF.createBasicBlock(\".cancel.continue\");\n      llvm::Value *Cmp = CGF.Builder.CreateIsNotNull(Result);\n      CGF.Builder.CreateCondBr(Cmp, ExitBB, ContBB);\n      CGF.EmitBlock(ExitBB);\n      // exit from construct;\n      CodeGenFunction::JumpDest CancelDest =\n          CGF.getOMPCancelDestination(OMPRegionInfo->getDirectiveKind());\n      CGF.EmitBranchThroughCleanup(CancelDest);\n      CGF.EmitBlock(ContBB, /*IsFinished=*/true);\n    }\n  }\n}\n\nvoid CGOpenMPRuntime::emitCancelCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                     const Expr *IfCond,\n                                     OpenMPDirectiveKind CancelRegion) {\n  if (!CGF.HaveInsertPoint())\n    return;\n  // Build call kmp_int32 __kmpc_cancel(ident_t *loc, kmp_int32 global_tid,\n  // kmp_int32 cncl_kind);\n  auto &M = CGM.getModule();\n  if (auto *OMPRegionInfo =\n          dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo)) {\n    auto &&ThenGen = [this, &M, Loc, CancelRegion,\n                      OMPRegionInfo](CodeGenFunction &CGF, PrePostActionTy &) {\n      CGOpenMPRuntime &RT = CGF.CGM.getOpenMPRuntime();\n      llvm::Value *Args[] = {\n          RT.emitUpdateLocation(CGF, Loc), RT.getThreadID(CGF, Loc),\n          CGF.Builder.getInt32(getCancellationKind(CancelRegion))};\n      // Ignore return result until untied tasks are supported.\n      llvm::Value *Result = CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(M, OMPRTL___kmpc_cancel), Args);\n      // if (__kmpc_cancel()) {\n      //   exit from construct;\n      // }\n      llvm::BasicBlock *ExitBB = CGF.createBasicBlock(\".cancel.exit\");\n      llvm::BasicBlock *ContBB = CGF.createBasicBlock(\".cancel.continue\");\n      llvm::Value *Cmp = CGF.Builder.CreateIsNotNull(Result);\n      CGF.Builder.CreateCondBr(Cmp, ExitBB, ContBB);\n      CGF.EmitBlock(ExitBB);\n      // exit from construct;\n      CodeGenFunction::JumpDest CancelDest =\n          CGF.getOMPCancelDestination(OMPRegionInfo->getDirectiveKind());\n      CGF.EmitBranchThroughCleanup(CancelDest);\n      CGF.EmitBlock(ContBB, /*IsFinished=*/true);\n    };\n    if (IfCond) {\n      emitIfClause(CGF, IfCond, ThenGen,\n                   [](CodeGenFunction &, PrePostActionTy &) {});\n    } else {\n      RegionCodeGenTy ThenRCG(ThenGen);\n      ThenRCG(CGF);\n    }\n  }\n}\n\nnamespace {\n/// Cleanup action for uses_allocators support.\nclass OMPUsesAllocatorsActionTy final : public PrePostActionTy {\n  ArrayRef<std::pair<const Expr *, const Expr *>> Allocators;\n\npublic:\n  OMPUsesAllocatorsActionTy(\n      ArrayRef<std::pair<const Expr *, const Expr *>> Allocators)\n      : Allocators(Allocators) {}\n  void Enter(CodeGenFunction &CGF) override {\n    if (!CGF.HaveInsertPoint())\n      return;\n    for (const auto &AllocatorData : Allocators) {\n      CGF.CGM.getOpenMPRuntime().emitUsesAllocatorsInit(\n          CGF, AllocatorData.first, AllocatorData.second);\n    }\n  }\n  void Exit(CodeGenFunction &CGF) override {\n    if (!CGF.HaveInsertPoint())\n      return;\n    for (const auto &AllocatorData : Allocators) {\n      CGF.CGM.getOpenMPRuntime().emitUsesAllocatorsFini(CGF,\n                                                        AllocatorData.first);\n    }\n  }\n};\n} // namespace\n\nvoid CGOpenMPRuntime::emitTargetOutlinedFunction(\n    const OMPExecutableDirective &D, StringRef ParentName,\n    llvm::Function *&OutlinedFn, llvm::Constant *&OutlinedFnID,\n    bool IsOffloadEntry, const RegionCodeGenTy &CodeGen) {\n  assert(!ParentName.empty() && \"Invalid target region parent name!\");\n  HasEmittedTargetRegion = true;\n  SmallVector<std::pair<const Expr *, const Expr *>, 4> Allocators;\n  for (const auto *C : D.getClausesOfKind<OMPUsesAllocatorsClause>()) {\n    for (unsigned I = 0, E = C->getNumberOfAllocators(); I < E; ++I) {\n      const OMPUsesAllocatorsClause::Data D = C->getAllocatorData(I);\n      if (!D.AllocatorTraits)\n        continue;\n      Allocators.emplace_back(D.Allocator, D.AllocatorTraits);\n    }\n  }\n  OMPUsesAllocatorsActionTy UsesAllocatorAction(Allocators);\n  CodeGen.setAction(UsesAllocatorAction);\n  emitTargetOutlinedFunctionHelper(D, ParentName, OutlinedFn, OutlinedFnID,\n                                   IsOffloadEntry, CodeGen);\n}\n\nvoid CGOpenMPRuntime::emitUsesAllocatorsInit(CodeGenFunction &CGF,\n                                             const Expr *Allocator,\n                                             const Expr *AllocatorTraits) {\n  llvm::Value *ThreadId = getThreadID(CGF, Allocator->getExprLoc());\n  ThreadId = CGF.Builder.CreateIntCast(ThreadId, CGF.IntTy, /*isSigned=*/true);\n  // Use default memspace handle.\n  llvm::Value *MemSpaceHandle = llvm::ConstantPointerNull::get(CGF.VoidPtrTy);\n  llvm::Value *NumTraits = llvm::ConstantInt::get(\n      CGF.IntTy, cast<ConstantArrayType>(\n                     AllocatorTraits->getType()->getAsArrayTypeUnsafe())\n                     ->getSize()\n                     .getLimitedValue());\n  LValue AllocatorTraitsLVal = CGF.EmitLValue(AllocatorTraits);\n  Address Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n      AllocatorTraitsLVal.getAddress(CGF), CGF.VoidPtrPtrTy);\n  AllocatorTraitsLVal = CGF.MakeAddrLValue(Addr, CGF.getContext().VoidPtrTy,\n                                           AllocatorTraitsLVal.getBaseInfo(),\n                                           AllocatorTraitsLVal.getTBAAInfo());\n  llvm::Value *Traits =\n      CGF.EmitLoadOfScalar(AllocatorTraitsLVal, AllocatorTraits->getExprLoc());\n\n  llvm::Value *AllocatorVal =\n      CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                              CGM.getModule(), OMPRTL___kmpc_init_allocator),\n                          {ThreadId, MemSpaceHandle, NumTraits, Traits});\n  // Store to allocator.\n  CGF.EmitVarDecl(*cast<VarDecl>(\n      cast<DeclRefExpr>(Allocator->IgnoreParenImpCasts())->getDecl()));\n  LValue AllocatorLVal = CGF.EmitLValue(Allocator->IgnoreParenImpCasts());\n  AllocatorVal =\n      CGF.EmitScalarConversion(AllocatorVal, CGF.getContext().VoidPtrTy,\n                               Allocator->getType(), Allocator->getExprLoc());\n  CGF.EmitStoreOfScalar(AllocatorVal, AllocatorLVal);\n}\n\nvoid CGOpenMPRuntime::emitUsesAllocatorsFini(CodeGenFunction &CGF,\n                                             const Expr *Allocator) {\n  llvm::Value *ThreadId = getThreadID(CGF, Allocator->getExprLoc());\n  ThreadId = CGF.Builder.CreateIntCast(ThreadId, CGF.IntTy, /*isSigned=*/true);\n  LValue AllocatorLVal = CGF.EmitLValue(Allocator->IgnoreParenImpCasts());\n  llvm::Value *AllocatorVal =\n      CGF.EmitLoadOfScalar(AllocatorLVal, Allocator->getExprLoc());\n  AllocatorVal = CGF.EmitScalarConversion(AllocatorVal, Allocator->getType(),\n                                          CGF.getContext().VoidPtrTy,\n                                          Allocator->getExprLoc());\n  (void)CGF.EmitRuntimeCall(\n      OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                            OMPRTL___kmpc_destroy_allocator),\n      {ThreadId, AllocatorVal});\n}\n\nvoid CGOpenMPRuntime::emitTargetOutlinedFunctionHelper(\n    const OMPExecutableDirective &D, StringRef ParentName,\n    llvm::Function *&OutlinedFn, llvm::Constant *&OutlinedFnID,\n    bool IsOffloadEntry, const RegionCodeGenTy &CodeGen) {\n  // Create a unique name for the entry function using the source location\n  // information of the current target region. The name will be something like:\n  //\n  // __omp_offloading_DD_FFFF_PP_lBB\n  //\n  // where DD_FFFF is an ID unique to the file (device and file IDs), PP is the\n  // mangled name of the function that encloses the target region and BB is the\n  // line number of the target region.\n\n  unsigned DeviceID;\n  unsigned FileID;\n  unsigned Line;\n  getTargetEntryUniqueInfo(CGM.getContext(), D.getBeginLoc(), DeviceID, FileID,\n                           Line);\n  SmallString<64> EntryFnName;\n  {\n    llvm::raw_svector_ostream OS(EntryFnName);\n    OS << \"__omp_offloading\" << llvm::format(\"_%x\", DeviceID)\n       << llvm::format(\"_%x_\", FileID) << ParentName << \"_l\" << Line;\n  }\n\n  const CapturedStmt &CS = *D.getCapturedStmt(OMPD_target);\n\n  CodeGenFunction CGF(CGM, true);\n  CGOpenMPTargetRegionInfo CGInfo(CS, CodeGen, EntryFnName);\n  CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n\n  OutlinedFn = CGF.GenerateOpenMPCapturedStmtFunction(CS, D.getBeginLoc());\n\n  // If this target outline function is not an offload entry, we don't need to\n  // register it.\n  if (!IsOffloadEntry)\n    return;\n\n  // The target region ID is used by the runtime library to identify the current\n  // target region, so it only has to be unique and not necessarily point to\n  // anything. It could be the pointer to the outlined function that implements\n  // the target region, but we aren't using that so that the compiler doesn't\n  // need to keep that, and could therefore inline the host function if proven\n  // worthwhile during optimization. In the other hand, if emitting code for the\n  // device, the ID has to be the function address so that it can retrieved from\n  // the offloading entry and launched by the runtime library. We also mark the\n  // outlined function to have external linkage in case we are emitting code for\n  // the device, because these functions will be entry points to the device.\n\n  if (CGM.getLangOpts().OpenMPIsDevice) {\n    OutlinedFnID = llvm::ConstantExpr::getBitCast(OutlinedFn, CGM.Int8PtrTy);\n    OutlinedFn->setLinkage(llvm::GlobalValue::WeakAnyLinkage);\n    OutlinedFn->setDSOLocal(false);\n    if (CGM.getTriple().isAMDGCN())\n      OutlinedFn->setCallingConv(llvm::CallingConv::AMDGPU_KERNEL);\n  } else {\n    std::string Name = getName({EntryFnName, \"region_id\"});\n    OutlinedFnID = new llvm::GlobalVariable(\n        CGM.getModule(), CGM.Int8Ty, /*isConstant=*/true,\n        llvm::GlobalValue::WeakAnyLinkage,\n        llvm::Constant::getNullValue(CGM.Int8Ty), Name);\n  }\n\n  // Register the information for the entry associated with this target region.\n  OffloadEntriesInfoManager.registerTargetRegionEntryInfo(\n      DeviceID, FileID, ParentName, Line, OutlinedFn, OutlinedFnID,\n      OffloadEntriesInfoManagerTy::OMPTargetRegionEntryTargetRegion);\n}\n\n/// Checks if the expression is constant or does not have non-trivial function\n/// calls.\nstatic bool isTrivial(ASTContext &Ctx, const Expr * E) {\n  // We can skip constant expressions.\n  // We can skip expressions with trivial calls or simple expressions.\n  return (E->isEvaluatable(Ctx, Expr::SE_AllowUndefinedBehavior) ||\n          !E->hasNonTrivialCall(Ctx)) &&\n         !E->HasSideEffects(Ctx, /*IncludePossibleEffects=*/true);\n}\n\nconst Stmt *CGOpenMPRuntime::getSingleCompoundChild(ASTContext &Ctx,\n                                                    const Stmt *Body) {\n  const Stmt *Child = Body->IgnoreContainers();\n  while (const auto *C = dyn_cast_or_null<CompoundStmt>(Child)) {\n    Child = nullptr;\n    for (const Stmt *S : C->body()) {\n      if (const auto *E = dyn_cast<Expr>(S)) {\n        if (isTrivial(Ctx, E))\n          continue;\n      }\n      // Some of the statements can be ignored.\n      if (isa<AsmStmt>(S) || isa<NullStmt>(S) || isa<OMPFlushDirective>(S) ||\n          isa<OMPBarrierDirective>(S) || isa<OMPTaskyieldDirective>(S))\n        continue;\n      // Analyze declarations.\n      if (const auto *DS = dyn_cast<DeclStmt>(S)) {\n        if (llvm::all_of(DS->decls(), [&Ctx](const Decl *D) {\n              if (isa<EmptyDecl>(D) || isa<DeclContext>(D) ||\n                  isa<TypeDecl>(D) || isa<PragmaCommentDecl>(D) ||\n                  isa<PragmaDetectMismatchDecl>(D) || isa<UsingDecl>(D) ||\n                  isa<UsingDirectiveDecl>(D) ||\n                  isa<OMPDeclareReductionDecl>(D) ||\n                  isa<OMPThreadPrivateDecl>(D) || isa<OMPAllocateDecl>(D))\n                return true;\n              const auto *VD = dyn_cast<VarDecl>(D);\n              if (!VD)\n                return false;\n              return VD->isConstexpr() ||\n                     ((VD->getType().isTrivialType(Ctx) ||\n                       VD->getType()->isReferenceType()) &&\n                      (!VD->hasInit() || isTrivial(Ctx, VD->getInit())));\n            }))\n          continue;\n      }\n      // Found multiple children - cannot get the one child only.\n      if (Child)\n        return nullptr;\n      Child = S;\n    }\n    if (Child)\n      Child = Child->IgnoreContainers();\n  }\n  return Child;\n}\n\n/// Emit the number of teams for a target directive.  Inspect the num_teams\n/// clause associated with a teams construct combined or closely nested\n/// with the target directive.\n///\n/// Emit a team of size one for directives such as 'target parallel' that\n/// have no associated teams construct.\n///\n/// Otherwise, return nullptr.\nstatic llvm::Value *\nemitNumTeamsForTargetDirective(CodeGenFunction &CGF,\n                               const OMPExecutableDirective &D) {\n  assert(!CGF.getLangOpts().OpenMPIsDevice &&\n         \"Clauses associated with the teams directive expected to be emitted \"\n         \"only for the host!\");\n  OpenMPDirectiveKind DirectiveKind = D.getDirectiveKind();\n  assert(isOpenMPTargetExecutionDirective(DirectiveKind) &&\n         \"Expected target-based executable directive.\");\n  CGBuilderTy &Bld = CGF.Builder;\n  switch (DirectiveKind) {\n  case OMPD_target: {\n    const auto *CS = D.getInnermostCapturedStmt();\n    const auto *Body =\n        CS->getCapturedStmt()->IgnoreContainers(/*IgnoreCaptured=*/true);\n    const Stmt *ChildStmt =\n        CGOpenMPRuntime::getSingleCompoundChild(CGF.getContext(), Body);\n    if (const auto *NestedDir =\n            dyn_cast_or_null<OMPExecutableDirective>(ChildStmt)) {\n      if (isOpenMPTeamsDirective(NestedDir->getDirectiveKind())) {\n        if (NestedDir->hasClausesOfKind<OMPNumTeamsClause>()) {\n          CGOpenMPInnerExprInfo CGInfo(CGF, *CS);\n          CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n          const Expr *NumTeams =\n              NestedDir->getSingleClause<OMPNumTeamsClause>()->getNumTeams();\n          llvm::Value *NumTeamsVal =\n              CGF.EmitScalarExpr(NumTeams,\n                                 /*IgnoreResultAssign*/ true);\n          return Bld.CreateIntCast(NumTeamsVal, CGF.Int32Ty,\n                                   /*isSigned=*/true);\n        }\n        return Bld.getInt32(0);\n      }\n      if (isOpenMPParallelDirective(NestedDir->getDirectiveKind()) ||\n          isOpenMPSimdDirective(NestedDir->getDirectiveKind()))\n        return Bld.getInt32(1);\n      return Bld.getInt32(0);\n    }\n    return nullptr;\n  }\n  case OMPD_target_teams:\n  case OMPD_target_teams_distribute:\n  case OMPD_target_teams_distribute_simd:\n  case OMPD_target_teams_distribute_parallel_for:\n  case OMPD_target_teams_distribute_parallel_for_simd: {\n    if (D.hasClausesOfKind<OMPNumTeamsClause>()) {\n      CodeGenFunction::RunCleanupsScope NumTeamsScope(CGF);\n      const Expr *NumTeams =\n          D.getSingleClause<OMPNumTeamsClause>()->getNumTeams();\n      llvm::Value *NumTeamsVal =\n          CGF.EmitScalarExpr(NumTeams,\n                             /*IgnoreResultAssign*/ true);\n      return Bld.CreateIntCast(NumTeamsVal, CGF.Int32Ty,\n                               /*isSigned=*/true);\n    }\n    return Bld.getInt32(0);\n  }\n  case OMPD_target_parallel:\n  case OMPD_target_parallel_for:\n  case OMPD_target_parallel_for_simd:\n  case OMPD_target_simd:\n    return Bld.getInt32(1);\n  case OMPD_parallel:\n  case OMPD_for:\n  case OMPD_parallel_for:\n  case OMPD_parallel_master:\n  case OMPD_parallel_sections:\n  case OMPD_for_simd:\n  case OMPD_parallel_for_simd:\n  case OMPD_cancel:\n  case OMPD_cancellation_point:\n  case OMPD_ordered:\n  case OMPD_threadprivate:\n  case OMPD_allocate:\n  case OMPD_task:\n  case OMPD_simd:\n  case OMPD_tile:\n  case OMPD_sections:\n  case OMPD_section:\n  case OMPD_single:\n  case OMPD_master:\n  case OMPD_critical:\n  case OMPD_taskyield:\n  case OMPD_barrier:\n  case OMPD_taskwait:\n  case OMPD_taskgroup:\n  case OMPD_atomic:\n  case OMPD_flush:\n  case OMPD_depobj:\n  case OMPD_scan:\n  case OMPD_teams:\n  case OMPD_target_data:\n  case OMPD_target_exit_data:\n  case OMPD_target_enter_data:\n  case OMPD_distribute:\n  case OMPD_distribute_simd:\n  case OMPD_distribute_parallel_for:\n  case OMPD_distribute_parallel_for_simd:\n  case OMPD_teams_distribute:\n  case OMPD_teams_distribute_simd:\n  case OMPD_teams_distribute_parallel_for:\n  case OMPD_teams_distribute_parallel_for_simd:\n  case OMPD_target_update:\n  case OMPD_declare_simd:\n  case OMPD_declare_variant:\n  case OMPD_begin_declare_variant:\n  case OMPD_end_declare_variant:\n  case OMPD_declare_target:\n  case OMPD_end_declare_target:\n  case OMPD_declare_reduction:\n  case OMPD_declare_mapper:\n  case OMPD_taskloop:\n  case OMPD_taskloop_simd:\n  case OMPD_master_taskloop:\n  case OMPD_master_taskloop_simd:\n  case OMPD_parallel_master_taskloop:\n  case OMPD_parallel_master_taskloop_simd:\n  case OMPD_requires:\n  case OMPD_unknown:\n    break;\n  default:\n    break;\n  }\n  llvm_unreachable(\"Unexpected directive kind.\");\n}\n\nstatic llvm::Value *getNumThreads(CodeGenFunction &CGF, const CapturedStmt *CS,\n                                  llvm::Value *DefaultThreadLimitVal) {\n  const Stmt *Child = CGOpenMPRuntime::getSingleCompoundChild(\n      CGF.getContext(), CS->getCapturedStmt());\n  if (const auto *Dir = dyn_cast_or_null<OMPExecutableDirective>(Child)) {\n    if (isOpenMPParallelDirective(Dir->getDirectiveKind())) {\n      llvm::Value *NumThreads = nullptr;\n      llvm::Value *CondVal = nullptr;\n      // Handle if clause. If if clause present, the number of threads is\n      // calculated as <cond> ? (<numthreads> ? <numthreads> : 0 ) : 1.\n      if (Dir->hasClausesOfKind<OMPIfClause>()) {\n        CGOpenMPInnerExprInfo CGInfo(CGF, *CS);\n        CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n        const OMPIfClause *IfClause = nullptr;\n        for (const auto *C : Dir->getClausesOfKind<OMPIfClause>()) {\n          if (C->getNameModifier() == OMPD_unknown ||\n              C->getNameModifier() == OMPD_parallel) {\n            IfClause = C;\n            break;\n          }\n        }\n        if (IfClause) {\n          const Expr *Cond = IfClause->getCondition();\n          bool Result;\n          if (Cond->EvaluateAsBooleanCondition(Result, CGF.getContext())) {\n            if (!Result)\n              return CGF.Builder.getInt32(1);\n          } else {\n            CodeGenFunction::LexicalScope Scope(CGF, Cond->getSourceRange());\n            if (const auto *PreInit =\n                    cast_or_null<DeclStmt>(IfClause->getPreInitStmt())) {\n              for (const auto *I : PreInit->decls()) {\n                if (!I->hasAttr<OMPCaptureNoInitAttr>()) {\n                  CGF.EmitVarDecl(cast<VarDecl>(*I));\n                } else {\n                  CodeGenFunction::AutoVarEmission Emission =\n                      CGF.EmitAutoVarAlloca(cast<VarDecl>(*I));\n                  CGF.EmitAutoVarCleanups(Emission);\n                }\n              }\n            }\n            CondVal = CGF.EvaluateExprAsBool(Cond);\n          }\n        }\n      }\n      // Check the value of num_threads clause iff if clause was not specified\n      // or is not evaluated to false.\n      if (Dir->hasClausesOfKind<OMPNumThreadsClause>()) {\n        CGOpenMPInnerExprInfo CGInfo(CGF, *CS);\n        CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n        const auto *NumThreadsClause =\n            Dir->getSingleClause<OMPNumThreadsClause>();\n        CodeGenFunction::LexicalScope Scope(\n            CGF, NumThreadsClause->getNumThreads()->getSourceRange());\n        if (const auto *PreInit =\n                cast_or_null<DeclStmt>(NumThreadsClause->getPreInitStmt())) {\n          for (const auto *I : PreInit->decls()) {\n            if (!I->hasAttr<OMPCaptureNoInitAttr>()) {\n              CGF.EmitVarDecl(cast<VarDecl>(*I));\n            } else {\n              CodeGenFunction::AutoVarEmission Emission =\n                  CGF.EmitAutoVarAlloca(cast<VarDecl>(*I));\n              CGF.EmitAutoVarCleanups(Emission);\n            }\n          }\n        }\n        NumThreads = CGF.EmitScalarExpr(NumThreadsClause->getNumThreads());\n        NumThreads = CGF.Builder.CreateIntCast(NumThreads, CGF.Int32Ty,\n                                               /*isSigned=*/false);\n        if (DefaultThreadLimitVal)\n          NumThreads = CGF.Builder.CreateSelect(\n              CGF.Builder.CreateICmpULT(DefaultThreadLimitVal, NumThreads),\n              DefaultThreadLimitVal, NumThreads);\n      } else {\n        NumThreads = DefaultThreadLimitVal ? DefaultThreadLimitVal\n                                           : CGF.Builder.getInt32(0);\n      }\n      // Process condition of the if clause.\n      if (CondVal) {\n        NumThreads = CGF.Builder.CreateSelect(CondVal, NumThreads,\n                                              CGF.Builder.getInt32(1));\n      }\n      return NumThreads;\n    }\n    if (isOpenMPSimdDirective(Dir->getDirectiveKind()))\n      return CGF.Builder.getInt32(1);\n    return DefaultThreadLimitVal;\n  }\n  return DefaultThreadLimitVal ? DefaultThreadLimitVal\n                               : CGF.Builder.getInt32(0);\n}\n\n/// Emit the number of threads for a target directive.  Inspect the\n/// thread_limit clause associated with a teams construct combined or closely\n/// nested with the target directive.\n///\n/// Emit the num_threads clause for directives such as 'target parallel' that\n/// have no associated teams construct.\n///\n/// Otherwise, return nullptr.\nstatic llvm::Value *\nemitNumThreadsForTargetDirective(CodeGenFunction &CGF,\n                                 const OMPExecutableDirective &D) {\n  assert(!CGF.getLangOpts().OpenMPIsDevice &&\n         \"Clauses associated with the teams directive expected to be emitted \"\n         \"only for the host!\");\n  OpenMPDirectiveKind DirectiveKind = D.getDirectiveKind();\n  assert(isOpenMPTargetExecutionDirective(DirectiveKind) &&\n         \"Expected target-based executable directive.\");\n  CGBuilderTy &Bld = CGF.Builder;\n  llvm::Value *ThreadLimitVal = nullptr;\n  llvm::Value *NumThreadsVal = nullptr;\n  switch (DirectiveKind) {\n  case OMPD_target: {\n    const CapturedStmt *CS = D.getInnermostCapturedStmt();\n    if (llvm::Value *NumThreads = getNumThreads(CGF, CS, ThreadLimitVal))\n      return NumThreads;\n    const Stmt *Child = CGOpenMPRuntime::getSingleCompoundChild(\n        CGF.getContext(), CS->getCapturedStmt());\n    if (const auto *Dir = dyn_cast_or_null<OMPExecutableDirective>(Child)) {\n      if (Dir->hasClausesOfKind<OMPThreadLimitClause>()) {\n        CGOpenMPInnerExprInfo CGInfo(CGF, *CS);\n        CodeGenFunction::CGCapturedStmtRAII CapInfoRAII(CGF, &CGInfo);\n        const auto *ThreadLimitClause =\n            Dir->getSingleClause<OMPThreadLimitClause>();\n        CodeGenFunction::LexicalScope Scope(\n            CGF, ThreadLimitClause->getThreadLimit()->getSourceRange());\n        if (const auto *PreInit =\n                cast_or_null<DeclStmt>(ThreadLimitClause->getPreInitStmt())) {\n          for (const auto *I : PreInit->decls()) {\n            if (!I->hasAttr<OMPCaptureNoInitAttr>()) {\n              CGF.EmitVarDecl(cast<VarDecl>(*I));\n            } else {\n              CodeGenFunction::AutoVarEmission Emission =\n                  CGF.EmitAutoVarAlloca(cast<VarDecl>(*I));\n              CGF.EmitAutoVarCleanups(Emission);\n            }\n          }\n        }\n        llvm::Value *ThreadLimit = CGF.EmitScalarExpr(\n            ThreadLimitClause->getThreadLimit(), /*IgnoreResultAssign=*/true);\n        ThreadLimitVal =\n            Bld.CreateIntCast(ThreadLimit, CGF.Int32Ty, /*isSigned=*/false);\n      }\n      if (isOpenMPTeamsDirective(Dir->getDirectiveKind()) &&\n          !isOpenMPDistributeDirective(Dir->getDirectiveKind())) {\n        CS = Dir->getInnermostCapturedStmt();\n        const Stmt *Child = CGOpenMPRuntime::getSingleCompoundChild(\n            CGF.getContext(), CS->getCapturedStmt());\n        Dir = dyn_cast_or_null<OMPExecutableDirective>(Child);\n      }\n      if (Dir && isOpenMPDistributeDirective(Dir->getDirectiveKind()) &&\n          !isOpenMPSimdDirective(Dir->getDirectiveKind())) {\n        CS = Dir->getInnermostCapturedStmt();\n        if (llvm::Value *NumThreads = getNumThreads(CGF, CS, ThreadLimitVal))\n          return NumThreads;\n      }\n      if (Dir && isOpenMPSimdDirective(Dir->getDirectiveKind()))\n        return Bld.getInt32(1);\n    }\n    return ThreadLimitVal ? ThreadLimitVal : Bld.getInt32(0);\n  }\n  case OMPD_target_teams: {\n    if (D.hasClausesOfKind<OMPThreadLimitClause>()) {\n      CodeGenFunction::RunCleanupsScope ThreadLimitScope(CGF);\n      const auto *ThreadLimitClause = D.getSingleClause<OMPThreadLimitClause>();\n      llvm::Value *ThreadLimit = CGF.EmitScalarExpr(\n          ThreadLimitClause->getThreadLimit(), /*IgnoreResultAssign=*/true);\n      ThreadLimitVal =\n          Bld.CreateIntCast(ThreadLimit, CGF.Int32Ty, /*isSigned=*/false);\n    }\n    const CapturedStmt *CS = D.getInnermostCapturedStmt();\n    if (llvm::Value *NumThreads = getNumThreads(CGF, CS, ThreadLimitVal))\n      return NumThreads;\n    const Stmt *Child = CGOpenMPRuntime::getSingleCompoundChild(\n        CGF.getContext(), CS->getCapturedStmt());\n    if (const auto *Dir = dyn_cast_or_null<OMPExecutableDirective>(Child)) {\n      if (Dir->getDirectiveKind() == OMPD_distribute) {\n        CS = Dir->getInnermostCapturedStmt();\n        if (llvm::Value *NumThreads = getNumThreads(CGF, CS, ThreadLimitVal))\n          return NumThreads;\n      }\n    }\n    return ThreadLimitVal ? ThreadLimitVal : Bld.getInt32(0);\n  }\n  case OMPD_target_teams_distribute:\n    if (D.hasClausesOfKind<OMPThreadLimitClause>()) {\n      CodeGenFunction::RunCleanupsScope ThreadLimitScope(CGF);\n      const auto *ThreadLimitClause = D.getSingleClause<OMPThreadLimitClause>();\n      llvm::Value *ThreadLimit = CGF.EmitScalarExpr(\n          ThreadLimitClause->getThreadLimit(), /*IgnoreResultAssign=*/true);\n      ThreadLimitVal =\n          Bld.CreateIntCast(ThreadLimit, CGF.Int32Ty, /*isSigned=*/false);\n    }\n    return getNumThreads(CGF, D.getInnermostCapturedStmt(), ThreadLimitVal);\n  case OMPD_target_parallel:\n  case OMPD_target_parallel_for:\n  case OMPD_target_parallel_for_simd:\n  case OMPD_target_teams_distribute_parallel_for:\n  case OMPD_target_teams_distribute_parallel_for_simd: {\n    llvm::Value *CondVal = nullptr;\n    // Handle if clause. If if clause present, the number of threads is\n    // calculated as <cond> ? (<numthreads> ? <numthreads> : 0 ) : 1.\n    if (D.hasClausesOfKind<OMPIfClause>()) {\n      const OMPIfClause *IfClause = nullptr;\n      for (const auto *C : D.getClausesOfKind<OMPIfClause>()) {\n        if (C->getNameModifier() == OMPD_unknown ||\n            C->getNameModifier() == OMPD_parallel) {\n          IfClause = C;\n          break;\n        }\n      }\n      if (IfClause) {\n        const Expr *Cond = IfClause->getCondition();\n        bool Result;\n        if (Cond->EvaluateAsBooleanCondition(Result, CGF.getContext())) {\n          if (!Result)\n            return Bld.getInt32(1);\n        } else {\n          CodeGenFunction::RunCleanupsScope Scope(CGF);\n          CondVal = CGF.EvaluateExprAsBool(Cond);\n        }\n      }\n    }\n    if (D.hasClausesOfKind<OMPThreadLimitClause>()) {\n      CodeGenFunction::RunCleanupsScope ThreadLimitScope(CGF);\n      const auto *ThreadLimitClause = D.getSingleClause<OMPThreadLimitClause>();\n      llvm::Value *ThreadLimit = CGF.EmitScalarExpr(\n          ThreadLimitClause->getThreadLimit(), /*IgnoreResultAssign=*/true);\n      ThreadLimitVal =\n          Bld.CreateIntCast(ThreadLimit, CGF.Int32Ty, /*isSigned=*/false);\n    }\n    if (D.hasClausesOfKind<OMPNumThreadsClause>()) {\n      CodeGenFunction::RunCleanupsScope NumThreadsScope(CGF);\n      const auto *NumThreadsClause = D.getSingleClause<OMPNumThreadsClause>();\n      llvm::Value *NumThreads = CGF.EmitScalarExpr(\n          NumThreadsClause->getNumThreads(), /*IgnoreResultAssign=*/true);\n      NumThreadsVal =\n          Bld.CreateIntCast(NumThreads, CGF.Int32Ty, /*isSigned=*/false);\n      ThreadLimitVal = ThreadLimitVal\n                           ? Bld.CreateSelect(Bld.CreateICmpULT(NumThreadsVal,\n                                                                ThreadLimitVal),\n                                              NumThreadsVal, ThreadLimitVal)\n                           : NumThreadsVal;\n    }\n    if (!ThreadLimitVal)\n      ThreadLimitVal = Bld.getInt32(0);\n    if (CondVal)\n      return Bld.CreateSelect(CondVal, ThreadLimitVal, Bld.getInt32(1));\n    return ThreadLimitVal;\n  }\n  case OMPD_target_teams_distribute_simd:\n  case OMPD_target_simd:\n    return Bld.getInt32(1);\n  case OMPD_parallel:\n  case OMPD_for:\n  case OMPD_parallel_for:\n  case OMPD_parallel_master:\n  case OMPD_parallel_sections:\n  case OMPD_for_simd:\n  case OMPD_parallel_for_simd:\n  case OMPD_cancel:\n  case OMPD_cancellation_point:\n  case OMPD_ordered:\n  case OMPD_threadprivate:\n  case OMPD_allocate:\n  case OMPD_task:\n  case OMPD_simd:\n  case OMPD_tile:\n  case OMPD_sections:\n  case OMPD_section:\n  case OMPD_single:\n  case OMPD_master:\n  case OMPD_critical:\n  case OMPD_taskyield:\n  case OMPD_barrier:\n  case OMPD_taskwait:\n  case OMPD_taskgroup:\n  case OMPD_atomic:\n  case OMPD_flush:\n  case OMPD_depobj:\n  case OMPD_scan:\n  case OMPD_teams:\n  case OMPD_target_data:\n  case OMPD_target_exit_data:\n  case OMPD_target_enter_data:\n  case OMPD_distribute:\n  case OMPD_distribute_simd:\n  case OMPD_distribute_parallel_for:\n  case OMPD_distribute_parallel_for_simd:\n  case OMPD_teams_distribute:\n  case OMPD_teams_distribute_simd:\n  case OMPD_teams_distribute_parallel_for:\n  case OMPD_teams_distribute_parallel_for_simd:\n  case OMPD_target_update:\n  case OMPD_declare_simd:\n  case OMPD_declare_variant:\n  case OMPD_begin_declare_variant:\n  case OMPD_end_declare_variant:\n  case OMPD_declare_target:\n  case OMPD_end_declare_target:\n  case OMPD_declare_reduction:\n  case OMPD_declare_mapper:\n  case OMPD_taskloop:\n  case OMPD_taskloop_simd:\n  case OMPD_master_taskloop:\n  case OMPD_master_taskloop_simd:\n  case OMPD_parallel_master_taskloop:\n  case OMPD_parallel_master_taskloop_simd:\n  case OMPD_requires:\n  case OMPD_unknown:\n    break;\n  default:\n    break;\n  }\n  llvm_unreachable(\"Unsupported directive kind.\");\n}\n\nnamespace {\nLLVM_ENABLE_BITMASK_ENUMS_IN_NAMESPACE();\n\n// Utility to handle information from clauses associated with a given\n// construct that use mappable expressions (e.g. 'map' clause, 'to' clause).\n// It provides a convenient interface to obtain the information and generate\n// code for that information.\nclass MappableExprsHandler {\npublic:\n  /// Values for bit flags used to specify the mapping type for\n  /// offloading.\n  enum OpenMPOffloadMappingFlags : uint64_t {\n    /// No flags\n    OMP_MAP_NONE = 0x0,\n    /// Allocate memory on the device and move data from host to device.\n    OMP_MAP_TO = 0x01,\n    /// Allocate memory on the device and move data from device to host.\n    OMP_MAP_FROM = 0x02,\n    /// Always perform the requested mapping action on the element, even\n    /// if it was already mapped before.\n    OMP_MAP_ALWAYS = 0x04,\n    /// Delete the element from the device environment, ignoring the\n    /// current reference count associated with the element.\n    OMP_MAP_DELETE = 0x08,\n    /// The element being mapped is a pointer-pointee pair; both the\n    /// pointer and the pointee should be mapped.\n    OMP_MAP_PTR_AND_OBJ = 0x10,\n    /// This flags signals that the base address of an entry should be\n    /// passed to the target kernel as an argument.\n    OMP_MAP_TARGET_PARAM = 0x20,\n    /// Signal that the runtime library has to return the device pointer\n    /// in the current position for the data being mapped. Used when we have the\n    /// use_device_ptr or use_device_addr clause.\n    OMP_MAP_RETURN_PARAM = 0x40,\n    /// This flag signals that the reference being passed is a pointer to\n    /// private data.\n    OMP_MAP_PRIVATE = 0x80,\n    /// Pass the element to the device by value.\n    OMP_MAP_LITERAL = 0x100,\n    /// Implicit map\n    OMP_MAP_IMPLICIT = 0x200,\n    /// Close is a hint to the runtime to allocate memory close to\n    /// the target device.\n    OMP_MAP_CLOSE = 0x400,\n    /// 0x800 is reserved for compatibility with XLC.\n    /// Produce a runtime error if the data is not already allocated.\n    OMP_MAP_PRESENT = 0x1000,\n    /// Signal that the runtime library should use args as an array of\n    /// descriptor_dim pointers and use args_size as dims. Used when we have\n    /// non-contiguous list items in target update directive\n    OMP_MAP_NON_CONTIG = 0x100000000000,\n    /// The 16 MSBs of the flags indicate whether the entry is member of some\n    /// struct/class.\n    OMP_MAP_MEMBER_OF = 0xffff000000000000,\n    LLVM_MARK_AS_BITMASK_ENUM(/* LargestFlag = */ OMP_MAP_MEMBER_OF),\n  };\n\n  /// Get the offset of the OMP_MAP_MEMBER_OF field.\n  static unsigned getFlagMemberOffset() {\n    unsigned Offset = 0;\n    for (uint64_t Remain = OMP_MAP_MEMBER_OF; !(Remain & 1);\n         Remain = Remain >> 1)\n      Offset++;\n    return Offset;\n  }\n\n  /// Class that holds debugging information for a data mapping to be passed to\n  /// the runtime library.\n  class MappingExprInfo {\n    /// The variable declaration used for the data mapping.\n    const ValueDecl *MapDecl = nullptr;\n    /// The original expression used in the map clause, or null if there is\n    /// none.\n    const Expr *MapExpr = nullptr;\n\n  public:\n    MappingExprInfo(const ValueDecl *MapDecl, const Expr *MapExpr = nullptr)\n        : MapDecl(MapDecl), MapExpr(MapExpr) {}\n\n    const ValueDecl *getMapDecl() const { return MapDecl; }\n    const Expr *getMapExpr() const { return MapExpr; }\n  };\n\n  /// Class that associates information with a base pointer to be passed to the\n  /// runtime library.\n  class BasePointerInfo {\n    /// The base pointer.\n    llvm::Value *Ptr = nullptr;\n    /// The base declaration that refers to this device pointer, or null if\n    /// there is none.\n    const ValueDecl *DevPtrDecl = nullptr;\n\n  public:\n    BasePointerInfo(llvm::Value *Ptr, const ValueDecl *DevPtrDecl = nullptr)\n        : Ptr(Ptr), DevPtrDecl(DevPtrDecl) {}\n    llvm::Value *operator*() const { return Ptr; }\n    const ValueDecl *getDevicePtrDecl() const { return DevPtrDecl; }\n    void setDevicePtrDecl(const ValueDecl *D) { DevPtrDecl = D; }\n  };\n\n  using MapExprsArrayTy = SmallVector<MappingExprInfo, 4>;\n  using MapBaseValuesArrayTy = SmallVector<BasePointerInfo, 4>;\n  using MapValuesArrayTy = SmallVector<llvm::Value *, 4>;\n  using MapFlagsArrayTy = SmallVector<OpenMPOffloadMappingFlags, 4>;\n  using MapMappersArrayTy = SmallVector<const ValueDecl *, 4>;\n  using MapDimArrayTy = SmallVector<uint64_t, 4>;\n  using MapNonContiguousArrayTy = SmallVector<MapValuesArrayTy, 4>;\n\n  /// This structure contains combined information generated for mappable\n  /// clauses, including base pointers, pointers, sizes, map types, user-defined\n  /// mappers, and non-contiguous information.\n  struct MapCombinedInfoTy {\n    struct StructNonContiguousInfo {\n      bool IsNonContiguous = false;\n      MapDimArrayTy Dims;\n      MapNonContiguousArrayTy Offsets;\n      MapNonContiguousArrayTy Counts;\n      MapNonContiguousArrayTy Strides;\n    };\n    MapExprsArrayTy Exprs;\n    MapBaseValuesArrayTy BasePointers;\n    MapValuesArrayTy Pointers;\n    MapValuesArrayTy Sizes;\n    MapFlagsArrayTy Types;\n    MapMappersArrayTy Mappers;\n    StructNonContiguousInfo NonContigInfo;\n\n    /// Append arrays in \\a CurInfo.\n    void append(MapCombinedInfoTy &CurInfo) {\n      Exprs.append(CurInfo.Exprs.begin(), CurInfo.Exprs.end());\n      BasePointers.append(CurInfo.BasePointers.begin(),\n                          CurInfo.BasePointers.end());\n      Pointers.append(CurInfo.Pointers.begin(), CurInfo.Pointers.end());\n      Sizes.append(CurInfo.Sizes.begin(), CurInfo.Sizes.end());\n      Types.append(CurInfo.Types.begin(), CurInfo.Types.end());\n      Mappers.append(CurInfo.Mappers.begin(), CurInfo.Mappers.end());\n      NonContigInfo.Dims.append(CurInfo.NonContigInfo.Dims.begin(),\n                                 CurInfo.NonContigInfo.Dims.end());\n      NonContigInfo.Offsets.append(CurInfo.NonContigInfo.Offsets.begin(),\n                                    CurInfo.NonContigInfo.Offsets.end());\n      NonContigInfo.Counts.append(CurInfo.NonContigInfo.Counts.begin(),\n                                   CurInfo.NonContigInfo.Counts.end());\n      NonContigInfo.Strides.append(CurInfo.NonContigInfo.Strides.begin(),\n                                    CurInfo.NonContigInfo.Strides.end());\n    }\n  };\n\n  /// Map between a struct and the its lowest & highest elements which have been\n  /// mapped.\n  /// [ValueDecl *] --> {LE(FieldIndex, Pointer),\n  ///                    HE(FieldIndex, Pointer)}\n  struct StructRangeInfoTy {\n    MapCombinedInfoTy PreliminaryMapData;\n    std::pair<unsigned /*FieldIndex*/, Address /*Pointer*/> LowestElem = {\n        0, Address::invalid()};\n    std::pair<unsigned /*FieldIndex*/, Address /*Pointer*/> HighestElem = {\n        0, Address::invalid()};\n    Address Base = Address::invalid();\n    Address LB = Address::invalid();\n    bool IsArraySection = false;\n    bool HasCompleteRecord = false;\n  };\n\nprivate:\n  /// Kind that defines how a device pointer has to be returned.\n  struct MapInfo {\n    OMPClauseMappableExprCommon::MappableExprComponentListRef Components;\n    OpenMPMapClauseKind MapType = OMPC_MAP_unknown;\n    ArrayRef<OpenMPMapModifierKind> MapModifiers;\n    ArrayRef<OpenMPMotionModifierKind> MotionModifiers;\n    bool ReturnDevicePointer = false;\n    bool IsImplicit = false;\n    const ValueDecl *Mapper = nullptr;\n    const Expr *VarRef = nullptr;\n    bool ForDeviceAddr = false;\n\n    MapInfo() = default;\n    MapInfo(\n        OMPClauseMappableExprCommon::MappableExprComponentListRef Components,\n        OpenMPMapClauseKind MapType,\n        ArrayRef<OpenMPMapModifierKind> MapModifiers,\n        ArrayRef<OpenMPMotionModifierKind> MotionModifiers,\n        bool ReturnDevicePointer, bool IsImplicit,\n        const ValueDecl *Mapper = nullptr, const Expr *VarRef = nullptr,\n        bool ForDeviceAddr = false)\n        : Components(Components), MapType(MapType), MapModifiers(MapModifiers),\n          MotionModifiers(MotionModifiers),\n          ReturnDevicePointer(ReturnDevicePointer), IsImplicit(IsImplicit),\n          Mapper(Mapper), VarRef(VarRef), ForDeviceAddr(ForDeviceAddr) {}\n  };\n\n  /// If use_device_ptr or use_device_addr is used on a decl which is a struct\n  /// member and there is no map information about it, then emission of that\n  /// entry is deferred until the whole struct has been processed.\n  struct DeferredDevicePtrEntryTy {\n    const Expr *IE = nullptr;\n    const ValueDecl *VD = nullptr;\n    bool ForDeviceAddr = false;\n\n    DeferredDevicePtrEntryTy(const Expr *IE, const ValueDecl *VD,\n                             bool ForDeviceAddr)\n        : IE(IE), VD(VD), ForDeviceAddr(ForDeviceAddr) {}\n  };\n\n  /// The target directive from where the mappable clauses were extracted. It\n  /// is either a executable directive or a user-defined mapper directive.\n  llvm::PointerUnion<const OMPExecutableDirective *,\n                     const OMPDeclareMapperDecl *>\n      CurDir;\n\n  /// Function the directive is being generated for.\n  CodeGenFunction &CGF;\n\n  /// Set of all first private variables in the current directive.\n  /// bool data is set to true if the variable is implicitly marked as\n  /// firstprivate, false otherwise.\n  llvm::DenseMap<CanonicalDeclPtr<const VarDecl>, bool> FirstPrivateDecls;\n\n  /// Map between device pointer declarations and their expression components.\n  /// The key value for declarations in 'this' is null.\n  llvm::DenseMap<\n      const ValueDecl *,\n      SmallVector<OMPClauseMappableExprCommon::MappableExprComponentListRef, 4>>\n      DevPointersMap;\n\n  llvm::Value *getExprTypeSize(const Expr *E) const {\n    QualType ExprTy = E->getType().getCanonicalType();\n\n    // Calculate the size for array shaping expression.\n    if (const auto *OAE = dyn_cast<OMPArrayShapingExpr>(E)) {\n      llvm::Value *Size =\n          CGF.getTypeSize(OAE->getBase()->getType()->getPointeeType());\n      for (const Expr *SE : OAE->getDimensions()) {\n        llvm::Value *Sz = CGF.EmitScalarExpr(SE);\n        Sz = CGF.EmitScalarConversion(Sz, SE->getType(),\n                                      CGF.getContext().getSizeType(),\n                                      SE->getExprLoc());\n        Size = CGF.Builder.CreateNUWMul(Size, Sz);\n      }\n      return Size;\n    }\n\n    // Reference types are ignored for mapping purposes.\n    if (const auto *RefTy = ExprTy->getAs<ReferenceType>())\n      ExprTy = RefTy->getPointeeType().getCanonicalType();\n\n    // Given that an array section is considered a built-in type, we need to\n    // do the calculation based on the length of the section instead of relying\n    // on CGF.getTypeSize(E->getType()).\n    if (const auto *OAE = dyn_cast<OMPArraySectionExpr>(E)) {\n      QualType BaseTy = OMPArraySectionExpr::getBaseOriginalType(\n                            OAE->getBase()->IgnoreParenImpCasts())\n                            .getCanonicalType();\n\n      // If there is no length associated with the expression and lower bound is\n      // not specified too, that means we are using the whole length of the\n      // base.\n      if (!OAE->getLength() && OAE->getColonLocFirst().isValid() &&\n          !OAE->getLowerBound())\n        return CGF.getTypeSize(BaseTy);\n\n      llvm::Value *ElemSize;\n      if (const auto *PTy = BaseTy->getAs<PointerType>()) {\n        ElemSize = CGF.getTypeSize(PTy->getPointeeType().getCanonicalType());\n      } else {\n        const auto *ATy = cast<ArrayType>(BaseTy.getTypePtr());\n        assert(ATy && \"Expecting array type if not a pointer type.\");\n        ElemSize = CGF.getTypeSize(ATy->getElementType().getCanonicalType());\n      }\n\n      // If we don't have a length at this point, that is because we have an\n      // array section with a single element.\n      if (!OAE->getLength() && OAE->getColonLocFirst().isInvalid())\n        return ElemSize;\n\n      if (const Expr *LenExpr = OAE->getLength()) {\n        llvm::Value *LengthVal = CGF.EmitScalarExpr(LenExpr);\n        LengthVal = CGF.EmitScalarConversion(LengthVal, LenExpr->getType(),\n                                             CGF.getContext().getSizeType(),\n                                             LenExpr->getExprLoc());\n        return CGF.Builder.CreateNUWMul(LengthVal, ElemSize);\n      }\n      assert(!OAE->getLength() && OAE->getColonLocFirst().isValid() &&\n             OAE->getLowerBound() && \"expected array_section[lb:].\");\n      // Size = sizetype - lb * elemtype;\n      llvm::Value *LengthVal = CGF.getTypeSize(BaseTy);\n      llvm::Value *LBVal = CGF.EmitScalarExpr(OAE->getLowerBound());\n      LBVal = CGF.EmitScalarConversion(LBVal, OAE->getLowerBound()->getType(),\n                                       CGF.getContext().getSizeType(),\n                                       OAE->getLowerBound()->getExprLoc());\n      LBVal = CGF.Builder.CreateNUWMul(LBVal, ElemSize);\n      llvm::Value *Cmp = CGF.Builder.CreateICmpUGT(LengthVal, LBVal);\n      llvm::Value *TrueVal = CGF.Builder.CreateNUWSub(LengthVal, LBVal);\n      LengthVal = CGF.Builder.CreateSelect(\n          Cmp, TrueVal, llvm::ConstantInt::get(CGF.SizeTy, 0));\n      return LengthVal;\n    }\n    return CGF.getTypeSize(ExprTy);\n  }\n\n  /// Return the corresponding bits for a given map clause modifier. Add\n  /// a flag marking the map as a pointer if requested. Add a flag marking the\n  /// map as the first one of a series of maps that relate to the same map\n  /// expression.\n  OpenMPOffloadMappingFlags getMapTypeBits(\n      OpenMPMapClauseKind MapType, ArrayRef<OpenMPMapModifierKind> MapModifiers,\n      ArrayRef<OpenMPMotionModifierKind> MotionModifiers, bool IsImplicit,\n      bool AddPtrFlag, bool AddIsTargetParamFlag, bool IsNonContiguous) const {\n    OpenMPOffloadMappingFlags Bits =\n        IsImplicit ? OMP_MAP_IMPLICIT : OMP_MAP_NONE;\n    switch (MapType) {\n    case OMPC_MAP_alloc:\n    case OMPC_MAP_release:\n      // alloc and release is the default behavior in the runtime library,  i.e.\n      // if we don't pass any bits alloc/release that is what the runtime is\n      // going to do. Therefore, we don't need to signal anything for these two\n      // type modifiers.\n      break;\n    case OMPC_MAP_to:\n      Bits |= OMP_MAP_TO;\n      break;\n    case OMPC_MAP_from:\n      Bits |= OMP_MAP_FROM;\n      break;\n    case OMPC_MAP_tofrom:\n      Bits |= OMP_MAP_TO | OMP_MAP_FROM;\n      break;\n    case OMPC_MAP_delete:\n      Bits |= OMP_MAP_DELETE;\n      break;\n    case OMPC_MAP_unknown:\n      llvm_unreachable(\"Unexpected map type!\");\n    }\n    if (AddPtrFlag)\n      Bits |= OMP_MAP_PTR_AND_OBJ;\n    if (AddIsTargetParamFlag)\n      Bits |= OMP_MAP_TARGET_PARAM;\n    if (llvm::find(MapModifiers, OMPC_MAP_MODIFIER_always)\n        != MapModifiers.end())\n      Bits |= OMP_MAP_ALWAYS;\n    if (llvm::find(MapModifiers, OMPC_MAP_MODIFIER_close)\n        != MapModifiers.end())\n      Bits |= OMP_MAP_CLOSE;\n    if (llvm::find(MapModifiers, OMPC_MAP_MODIFIER_present) !=\n            MapModifiers.end() ||\n        llvm::find(MotionModifiers, OMPC_MOTION_MODIFIER_present) !=\n            MotionModifiers.end())\n      Bits |= OMP_MAP_PRESENT;\n    if (IsNonContiguous)\n      Bits |= OMP_MAP_NON_CONTIG;\n    return Bits;\n  }\n\n  /// Return true if the provided expression is a final array section. A\n  /// final array section, is one whose length can't be proved to be one.\n  bool isFinalArraySectionExpression(const Expr *E) const {\n    const auto *OASE = dyn_cast<OMPArraySectionExpr>(E);\n\n    // It is not an array section and therefore not a unity-size one.\n    if (!OASE)\n      return false;\n\n    // An array section with no colon always refer to a single element.\n    if (OASE->getColonLocFirst().isInvalid())\n      return false;\n\n    const Expr *Length = OASE->getLength();\n\n    // If we don't have a length we have to check if the array has size 1\n    // for this dimension. Also, we should always expect a length if the\n    // base type is pointer.\n    if (!Length) {\n      QualType BaseQTy = OMPArraySectionExpr::getBaseOriginalType(\n                             OASE->getBase()->IgnoreParenImpCasts())\n                             .getCanonicalType();\n      if (const auto *ATy = dyn_cast<ConstantArrayType>(BaseQTy.getTypePtr()))\n        return ATy->getSize().getSExtValue() != 1;\n      // If we don't have a constant dimension length, we have to consider\n      // the current section as having any size, so it is not necessarily\n      // unitary. If it happen to be unity size, that's user fault.\n      return true;\n    }\n\n    // Check if the length evaluates to 1.\n    Expr::EvalResult Result;\n    if (!Length->EvaluateAsInt(Result, CGF.getContext()))\n      return true; // Can have more that size 1.\n\n    llvm::APSInt ConstLength = Result.Val.getInt();\n    return ConstLength.getSExtValue() != 1;\n  }\n\n  /// Generate the base pointers, section pointers, sizes, map type bits, and\n  /// user-defined mappers (all included in \\a CombinedInfo) for the provided\n  /// map type, map or motion modifiers, and expression components.\n  /// \\a IsFirstComponent should be set to true if the provided set of\n  /// components is the first associated with a capture.\n  void generateInfoForComponentList(\n      OpenMPMapClauseKind MapType, ArrayRef<OpenMPMapModifierKind> MapModifiers,\n      ArrayRef<OpenMPMotionModifierKind> MotionModifiers,\n      OMPClauseMappableExprCommon::MappableExprComponentListRef Components,\n      MapCombinedInfoTy &CombinedInfo, StructRangeInfoTy &PartialStruct,\n      bool IsFirstComponentList, bool IsImplicit,\n      const ValueDecl *Mapper = nullptr, bool ForDeviceAddr = false,\n      const ValueDecl *BaseDecl = nullptr, const Expr *MapExpr = nullptr,\n      ArrayRef<OMPClauseMappableExprCommon::MappableExprComponentListRef>\n          OverlappedElements = llvm::None) const {\n    // The following summarizes what has to be generated for each map and the\n    // types below. The generated information is expressed in this order:\n    // base pointer, section pointer, size, flags\n    // (to add to the ones that come from the map type and modifier).\n    //\n    // double d;\n    // int i[100];\n    // float *p;\n    //\n    // struct S1 {\n    //   int i;\n    //   float f[50];\n    // }\n    // struct S2 {\n    //   int i;\n    //   float f[50];\n    //   S1 s;\n    //   double *p;\n    //   struct S2 *ps;\n    // }\n    // S2 s;\n    // S2 *ps;\n    //\n    // map(d)\n    // &d, &d, sizeof(double), TARGET_PARAM | TO | FROM\n    //\n    // map(i)\n    // &i, &i, 100*sizeof(int), TARGET_PARAM | TO | FROM\n    //\n    // map(i[1:23])\n    // &i(=&i[0]), &i[1], 23*sizeof(int), TARGET_PARAM | TO | FROM\n    //\n    // map(p)\n    // &p, &p, sizeof(float*), TARGET_PARAM | TO | FROM\n    //\n    // map(p[1:24])\n    // &p, &p[1], 24*sizeof(float), TARGET_PARAM | TO | FROM | PTR_AND_OBJ\n    // in unified shared memory mode or for local pointers\n    // p, &p[1], 24*sizeof(float), TARGET_PARAM | TO | FROM\n    //\n    // map(s)\n    // &s, &s, sizeof(S2), TARGET_PARAM | TO | FROM\n    //\n    // map(s.i)\n    // &s, &(s.i), sizeof(int), TARGET_PARAM | TO | FROM\n    //\n    // map(s.s.f)\n    // &s, &(s.s.f[0]), 50*sizeof(float), TARGET_PARAM | TO | FROM\n    //\n    // map(s.p)\n    // &s, &(s.p), sizeof(double*), TARGET_PARAM | TO | FROM\n    //\n    // map(to: s.p[:22])\n    // &s, &(s.p), sizeof(double*), TARGET_PARAM (*)\n    // &s, &(s.p), sizeof(double*), MEMBER_OF(1) (**)\n    // &(s.p), &(s.p[0]), 22*sizeof(double),\n    //   MEMBER_OF(1) | PTR_AND_OBJ | TO (***)\n    // (*) alloc space for struct members, only this is a target parameter\n    // (**) map the pointer (nothing to be mapped in this example) (the compiler\n    //      optimizes this entry out, same in the examples below)\n    // (***) map the pointee (map: to)\n    //\n    // map(s.ps)\n    // &s, &(s.ps), sizeof(S2*), TARGET_PARAM | TO | FROM\n    //\n    // map(from: s.ps->s.i)\n    // &s, &(s.ps), sizeof(S2*), TARGET_PARAM\n    // &s, &(s.ps), sizeof(S2*), MEMBER_OF(1)\n    // &(s.ps), &(s.ps->s.i), sizeof(int), MEMBER_OF(1) | PTR_AND_OBJ  | FROM\n    //\n    // map(to: s.ps->ps)\n    // &s, &(s.ps), sizeof(S2*), TARGET_PARAM\n    // &s, &(s.ps), sizeof(S2*), MEMBER_OF(1)\n    // &(s.ps), &(s.ps->ps), sizeof(S2*), MEMBER_OF(1) | PTR_AND_OBJ  | TO\n    //\n    // map(s.ps->ps->ps)\n    // &s, &(s.ps), sizeof(S2*), TARGET_PARAM\n    // &s, &(s.ps), sizeof(S2*), MEMBER_OF(1)\n    // &(s.ps), &(s.ps->ps), sizeof(S2*), MEMBER_OF(1) | PTR_AND_OBJ\n    // &(s.ps->ps), &(s.ps->ps->ps), sizeof(S2*), PTR_AND_OBJ | TO | FROM\n    //\n    // map(to: s.ps->ps->s.f[:22])\n    // &s, &(s.ps), sizeof(S2*), TARGET_PARAM\n    // &s, &(s.ps), sizeof(S2*), MEMBER_OF(1)\n    // &(s.ps), &(s.ps->ps), sizeof(S2*), MEMBER_OF(1) | PTR_AND_OBJ\n    // &(s.ps->ps), &(s.ps->ps->s.f[0]), 22*sizeof(float), PTR_AND_OBJ | TO\n    //\n    // map(ps)\n    // &ps, &ps, sizeof(S2*), TARGET_PARAM | TO | FROM\n    //\n    // map(ps->i)\n    // ps, &(ps->i), sizeof(int), TARGET_PARAM | TO | FROM\n    //\n    // map(ps->s.f)\n    // ps, &(ps->s.f[0]), 50*sizeof(float), TARGET_PARAM | TO | FROM\n    //\n    // map(from: ps->p)\n    // ps, &(ps->p), sizeof(double*), TARGET_PARAM | FROM\n    //\n    // map(to: ps->p[:22])\n    // ps, &(ps->p), sizeof(double*), TARGET_PARAM\n    // ps, &(ps->p), sizeof(double*), MEMBER_OF(1)\n    // &(ps->p), &(ps->p[0]), 22*sizeof(double), MEMBER_OF(1) | PTR_AND_OBJ | TO\n    //\n    // map(ps->ps)\n    // ps, &(ps->ps), sizeof(S2*), TARGET_PARAM | TO | FROM\n    //\n    // map(from: ps->ps->s.i)\n    // ps, &(ps->ps), sizeof(S2*), TARGET_PARAM\n    // ps, &(ps->ps), sizeof(S2*), MEMBER_OF(1)\n    // &(ps->ps), &(ps->ps->s.i), sizeof(int), MEMBER_OF(1) | PTR_AND_OBJ | FROM\n    //\n    // map(from: ps->ps->ps)\n    // ps, &(ps->ps), sizeof(S2*), TARGET_PARAM\n    // ps, &(ps->ps), sizeof(S2*), MEMBER_OF(1)\n    // &(ps->ps), &(ps->ps->ps), sizeof(S2*), MEMBER_OF(1) | PTR_AND_OBJ | FROM\n    //\n    // map(ps->ps->ps->ps)\n    // ps, &(ps->ps), sizeof(S2*), TARGET_PARAM\n    // ps, &(ps->ps), sizeof(S2*), MEMBER_OF(1)\n    // &(ps->ps), &(ps->ps->ps), sizeof(S2*), MEMBER_OF(1) | PTR_AND_OBJ\n    // &(ps->ps->ps), &(ps->ps->ps->ps), sizeof(S2*), PTR_AND_OBJ | TO | FROM\n    //\n    // map(to: ps->ps->ps->s.f[:22])\n    // ps, &(ps->ps), sizeof(S2*), TARGET_PARAM\n    // ps, &(ps->ps), sizeof(S2*), MEMBER_OF(1)\n    // &(ps->ps), &(ps->ps->ps), sizeof(S2*), MEMBER_OF(1) | PTR_AND_OBJ\n    // &(ps->ps->ps), &(ps->ps->ps->s.f[0]), 22*sizeof(float), PTR_AND_OBJ | TO\n    //\n    // map(to: s.f[:22]) map(from: s.p[:33])\n    // &s, &(s.f[0]), 50*sizeof(float) + sizeof(struct S1) +\n    //     sizeof(double*) (**), TARGET_PARAM\n    // &s, &(s.f[0]), 22*sizeof(float), MEMBER_OF(1) | TO\n    // &s, &(s.p), sizeof(double*), MEMBER_OF(1)\n    // &(s.p), &(s.p[0]), 33*sizeof(double), MEMBER_OF(1) | PTR_AND_OBJ | FROM\n    // (*) allocate contiguous space needed to fit all mapped members even if\n    //     we allocate space for members not mapped (in this example,\n    //     s.f[22..49] and s.s are not mapped, yet we must allocate space for\n    //     them as well because they fall between &s.f[0] and &s.p)\n    //\n    // map(from: s.f[:22]) map(to: ps->p[:33])\n    // &s, &(s.f[0]), 22*sizeof(float), TARGET_PARAM | FROM\n    // ps, &(ps->p), sizeof(S2*), TARGET_PARAM\n    // ps, &(ps->p), sizeof(double*), MEMBER_OF(2) (*)\n    // &(ps->p), &(ps->p[0]), 33*sizeof(double), MEMBER_OF(2) | PTR_AND_OBJ | TO\n    // (*) the struct this entry pertains to is the 2nd element in the list of\n    //     arguments, hence MEMBER_OF(2)\n    //\n    // map(from: s.f[:22], s.s) map(to: ps->p[:33])\n    // &s, &(s.f[0]), 50*sizeof(float) + sizeof(struct S1), TARGET_PARAM\n    // &s, &(s.f[0]), 22*sizeof(float), MEMBER_OF(1) | FROM\n    // &s, &(s.s), sizeof(struct S1), MEMBER_OF(1) | FROM\n    // ps, &(ps->p), sizeof(S2*), TARGET_PARAM\n    // ps, &(ps->p), sizeof(double*), MEMBER_OF(4) (*)\n    // &(ps->p), &(ps->p[0]), 33*sizeof(double), MEMBER_OF(4) | PTR_AND_OBJ | TO\n    // (*) the struct this entry pertains to is the 4th element in the list\n    //     of arguments, hence MEMBER_OF(4)\n\n    // Track if the map information being generated is the first for a capture.\n    bool IsCaptureFirstInfo = IsFirstComponentList;\n    // When the variable is on a declare target link or in a to clause with\n    // unified memory, a reference is needed to hold the host/device address\n    // of the variable.\n    bool RequiresReference = false;\n\n    // Scan the components from the base to the complete expression.\n    auto CI = Components.rbegin();\n    auto CE = Components.rend();\n    auto I = CI;\n\n    // Track if the map information being generated is the first for a list of\n    // components.\n    bool IsExpressionFirstInfo = true;\n    bool FirstPointerInComplexData = false;\n    Address BP = Address::invalid();\n    const Expr *AssocExpr = I->getAssociatedExpression();\n    const auto *AE = dyn_cast<ArraySubscriptExpr>(AssocExpr);\n    const auto *OASE = dyn_cast<OMPArraySectionExpr>(AssocExpr);\n    const auto *OAShE = dyn_cast<OMPArrayShapingExpr>(AssocExpr);\n\n    if (isa<MemberExpr>(AssocExpr)) {\n      // The base is the 'this' pointer. The content of the pointer is going\n      // to be the base of the field being mapped.\n      BP = CGF.LoadCXXThisAddress();\n    } else if ((AE && isa<CXXThisExpr>(AE->getBase()->IgnoreParenImpCasts())) ||\n               (OASE &&\n                isa<CXXThisExpr>(OASE->getBase()->IgnoreParenImpCasts()))) {\n      BP = CGF.EmitOMPSharedLValue(AssocExpr).getAddress(CGF);\n    } else if (OAShE &&\n               isa<CXXThisExpr>(OAShE->getBase()->IgnoreParenCasts())) {\n      BP = Address(\n          CGF.EmitScalarExpr(OAShE->getBase()),\n          CGF.getContext().getTypeAlignInChars(OAShE->getBase()->getType()));\n    } else {\n      // The base is the reference to the variable.\n      // BP = &Var.\n      BP = CGF.EmitOMPSharedLValue(AssocExpr).getAddress(CGF);\n      if (const auto *VD =\n              dyn_cast_or_null<VarDecl>(I->getAssociatedDeclaration())) {\n        if (llvm::Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n                OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD)) {\n          if ((*Res == OMPDeclareTargetDeclAttr::MT_Link) ||\n              (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n               CGF.CGM.getOpenMPRuntime().hasRequiresUnifiedSharedMemory())) {\n            RequiresReference = true;\n            BP = CGF.CGM.getOpenMPRuntime().getAddrOfDeclareTargetVar(VD);\n          }\n        }\n      }\n\n      // If the variable is a pointer and is being dereferenced (i.e. is not\n      // the last component), the base has to be the pointer itself, not its\n      // reference. References are ignored for mapping purposes.\n      QualType Ty =\n          I->getAssociatedDeclaration()->getType().getNonReferenceType();\n      if (Ty->isAnyPointerType() && std::next(I) != CE) {\n        // No need to generate individual map information for the pointer, it\n        // can be associated with the combined storage if shared memory mode is\n        // active or the base declaration is not global variable.\n        const auto *VD = dyn_cast<VarDecl>(I->getAssociatedDeclaration());\n        if (CGF.CGM.getOpenMPRuntime().hasRequiresUnifiedSharedMemory() ||\n            !VD || VD->hasLocalStorage())\n          BP = CGF.EmitLoadOfPointer(BP, Ty->castAs<PointerType>());\n        else\n          FirstPointerInComplexData = true;\n        ++I;\n      }\n    }\n\n    // Track whether a component of the list should be marked as MEMBER_OF some\n    // combined entry (for partial structs). Only the first PTR_AND_OBJ entry\n    // in a component list should be marked as MEMBER_OF, all subsequent entries\n    // do not belong to the base struct. E.g.\n    // struct S2 s;\n    // s.ps->ps->ps->f[:]\n    //   (1) (2) (3) (4)\n    // ps(1) is a member pointer, ps(2) is a pointee of ps(1), so it is a\n    // PTR_AND_OBJ entry; the PTR is ps(1), so MEMBER_OF the base struct. ps(3)\n    // is the pointee of ps(2) which is not member of struct s, so it should not\n    // be marked as such (it is still PTR_AND_OBJ).\n    // The variable is initialized to false so that PTR_AND_OBJ entries which\n    // are not struct members are not considered (e.g. array of pointers to\n    // data).\n    bool ShouldBeMemberOf = false;\n\n    // Variable keeping track of whether or not we have encountered a component\n    // in the component list which is a member expression. Useful when we have a\n    // pointer or a final array section, in which case it is the previous\n    // component in the list which tells us whether we have a member expression.\n    // E.g. X.f[:]\n    // While processing the final array section \"[:]\" it is \"f\" which tells us\n    // whether we are dealing with a member of a declared struct.\n    const MemberExpr *EncounteredME = nullptr;\n\n    // Track for the total number of dimension. Start from one for the dummy\n    // dimension.\n    uint64_t DimSize = 1;\n\n    bool IsNonContiguous = CombinedInfo.NonContigInfo.IsNonContiguous;\n\n    for (; I != CE; ++I) {\n      // If the current component is member of a struct (parent struct) mark it.\n      if (!EncounteredME) {\n        EncounteredME = dyn_cast<MemberExpr>(I->getAssociatedExpression());\n        // If we encounter a PTR_AND_OBJ entry from now on it should be marked\n        // as MEMBER_OF the parent struct.\n        if (EncounteredME) {\n          ShouldBeMemberOf = true;\n          // Do not emit as complex pointer if this is actually not array-like\n          // expression.\n          if (FirstPointerInComplexData) {\n            QualType Ty = std::prev(I)\n                              ->getAssociatedDeclaration()\n                              ->getType()\n                              .getNonReferenceType();\n            BP = CGF.EmitLoadOfPointer(BP, Ty->castAs<PointerType>());\n            FirstPointerInComplexData = false;\n          }\n        }\n      }\n\n      auto Next = std::next(I);\n\n      // We need to generate the addresses and sizes if this is the last\n      // component, if the component is a pointer or if it is an array section\n      // whose length can't be proved to be one. If this is a pointer, it\n      // becomes the base address for the following components.\n\n      // A final array section, is one whose length can't be proved to be one.\n      // If the map item is non-contiguous then we don't treat any array section\n      // as final array section.\n      bool IsFinalArraySection =\n          !IsNonContiguous &&\n          isFinalArraySectionExpression(I->getAssociatedExpression());\n\n      // If we have a declaration for the mapping use that, otherwise use\n      // the base declaration of the map clause.\n      const ValueDecl *MapDecl = (I->getAssociatedDeclaration())\n                                     ? I->getAssociatedDeclaration()\n                                     : BaseDecl;\n\n      // Get information on whether the element is a pointer. Have to do a\n      // special treatment for array sections given that they are built-in\n      // types.\n      const auto *OASE =\n          dyn_cast<OMPArraySectionExpr>(I->getAssociatedExpression());\n      const auto *OAShE =\n          dyn_cast<OMPArrayShapingExpr>(I->getAssociatedExpression());\n      const auto *UO = dyn_cast<UnaryOperator>(I->getAssociatedExpression());\n      const auto *BO = dyn_cast<BinaryOperator>(I->getAssociatedExpression());\n      bool IsPointer =\n          OAShE ||\n          (OASE && OMPArraySectionExpr::getBaseOriginalType(OASE)\n                       .getCanonicalType()\n                       ->isAnyPointerType()) ||\n          I->getAssociatedExpression()->getType()->isAnyPointerType();\n      bool IsNonDerefPointer = IsPointer && !UO && !BO && !IsNonContiguous;\n\n      if (OASE)\n        ++DimSize;\n\n      if (Next == CE || IsNonDerefPointer || IsFinalArraySection) {\n        // If this is not the last component, we expect the pointer to be\n        // associated with an array expression or member expression.\n        assert((Next == CE ||\n                isa<MemberExpr>(Next->getAssociatedExpression()) ||\n                isa<ArraySubscriptExpr>(Next->getAssociatedExpression()) ||\n                isa<OMPArraySectionExpr>(Next->getAssociatedExpression()) ||\n                isa<OMPArrayShapingExpr>(Next->getAssociatedExpression()) ||\n                isa<UnaryOperator>(Next->getAssociatedExpression()) ||\n                isa<BinaryOperator>(Next->getAssociatedExpression())) &&\n               \"Unexpected expression\");\n\n        Address LB = Address::invalid();\n        if (OAShE) {\n          LB = Address(CGF.EmitScalarExpr(OAShE->getBase()),\n                       CGF.getContext().getTypeAlignInChars(\n                           OAShE->getBase()->getType()));\n        } else {\n          LB = CGF.EmitOMPSharedLValue(I->getAssociatedExpression())\n                   .getAddress(CGF);\n        }\n\n        // If this component is a pointer inside the base struct then we don't\n        // need to create any entry for it - it will be combined with the object\n        // it is pointing to into a single PTR_AND_OBJ entry.\n        bool IsMemberPointerOrAddr =\n            (IsPointer || ForDeviceAddr) && EncounteredME &&\n            (dyn_cast<MemberExpr>(I->getAssociatedExpression()) ==\n             EncounteredME);\n        if (!OverlappedElements.empty() && Next == CE) {\n          // Handle base element with the info for overlapped elements.\n          assert(!PartialStruct.Base.isValid() && \"The base element is set.\");\n          assert(!IsPointer &&\n                 \"Unexpected base element with the pointer type.\");\n          // Mark the whole struct as the struct that requires allocation on the\n          // device.\n          PartialStruct.LowestElem = {0, LB};\n          CharUnits TypeSize = CGF.getContext().getTypeSizeInChars(\n              I->getAssociatedExpression()->getType());\n          Address HB = CGF.Builder.CreateConstGEP(\n              CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(LB,\n                                                              CGF.VoidPtrTy),\n              TypeSize.getQuantity() - 1);\n          PartialStruct.HighestElem = {\n              std::numeric_limits<decltype(\n                  PartialStruct.HighestElem.first)>::max(),\n              HB};\n          PartialStruct.Base = BP;\n          PartialStruct.LB = LB;\n          assert(\n              PartialStruct.PreliminaryMapData.BasePointers.empty() &&\n              \"Overlapped elements must be used only once for the variable.\");\n          std::swap(PartialStruct.PreliminaryMapData, CombinedInfo);\n          // Emit data for non-overlapped data.\n          OpenMPOffloadMappingFlags Flags =\n              OMP_MAP_MEMBER_OF |\n              getMapTypeBits(MapType, MapModifiers, MotionModifiers, IsImplicit,\n                             /*AddPtrFlag=*/false,\n                             /*AddIsTargetParamFlag=*/false, IsNonContiguous);\n          llvm::Value *Size = nullptr;\n          // Do bitcopy of all non-overlapped structure elements.\n          for (OMPClauseMappableExprCommon::MappableExprComponentListRef\n                   Component : OverlappedElements) {\n            Address ComponentLB = Address::invalid();\n            for (const OMPClauseMappableExprCommon::MappableComponent &MC :\n                 Component) {\n              if (MC.getAssociatedDeclaration()) {\n                ComponentLB =\n                    CGF.EmitOMPSharedLValue(MC.getAssociatedExpression())\n                        .getAddress(CGF);\n                Size = CGF.Builder.CreatePtrDiff(\n                    CGF.EmitCastToVoidPtr(ComponentLB.getPointer()),\n                    CGF.EmitCastToVoidPtr(LB.getPointer()));\n                break;\n              }\n            }\n            assert(Size && \"Failed to determine structure size\");\n            CombinedInfo.Exprs.emplace_back(MapDecl, MapExpr);\n            CombinedInfo.BasePointers.push_back(BP.getPointer());\n            CombinedInfo.Pointers.push_back(LB.getPointer());\n            CombinedInfo.Sizes.push_back(CGF.Builder.CreateIntCast(\n                Size, CGF.Int64Ty, /*isSigned=*/true));\n            CombinedInfo.Types.push_back(Flags);\n            CombinedInfo.Mappers.push_back(nullptr);\n            CombinedInfo.NonContigInfo.Dims.push_back(IsNonContiguous ? DimSize\n                                                                      : 1);\n            LB = CGF.Builder.CreateConstGEP(ComponentLB, 1);\n          }\n          CombinedInfo.Exprs.emplace_back(MapDecl, MapExpr);\n          CombinedInfo.BasePointers.push_back(BP.getPointer());\n          CombinedInfo.Pointers.push_back(LB.getPointer());\n          Size = CGF.Builder.CreatePtrDiff(\n              CGF.EmitCastToVoidPtr(\n                  CGF.Builder.CreateConstGEP(HB, 1).getPointer()),\n              CGF.EmitCastToVoidPtr(LB.getPointer()));\n          CombinedInfo.Sizes.push_back(\n              CGF.Builder.CreateIntCast(Size, CGF.Int64Ty, /*isSigned=*/true));\n          CombinedInfo.Types.push_back(Flags);\n          CombinedInfo.Mappers.push_back(nullptr);\n          CombinedInfo.NonContigInfo.Dims.push_back(IsNonContiguous ? DimSize\n                                                                    : 1);\n          break;\n        }\n        llvm::Value *Size = getExprTypeSize(I->getAssociatedExpression());\n        if (!IsMemberPointerOrAddr ||\n            (Next == CE && MapType != OMPC_MAP_unknown)) {\n          CombinedInfo.Exprs.emplace_back(MapDecl, MapExpr);\n          CombinedInfo.BasePointers.push_back(BP.getPointer());\n          CombinedInfo.Pointers.push_back(LB.getPointer());\n          CombinedInfo.Sizes.push_back(\n              CGF.Builder.CreateIntCast(Size, CGF.Int64Ty, /*isSigned=*/true));\n          CombinedInfo.NonContigInfo.Dims.push_back(IsNonContiguous ? DimSize\n                                                                    : 1);\n\n          // If Mapper is valid, the last component inherits the mapper.\n          bool HasMapper = Mapper && Next == CE;\n          CombinedInfo.Mappers.push_back(HasMapper ? Mapper : nullptr);\n\n          // We need to add a pointer flag for each map that comes from the\n          // same expression except for the first one. We also need to signal\n          // this map is the first one that relates with the current capture\n          // (there is a set of entries for each capture).\n          OpenMPOffloadMappingFlags Flags = getMapTypeBits(\n              MapType, MapModifiers, MotionModifiers, IsImplicit,\n              !IsExpressionFirstInfo || RequiresReference ||\n                  FirstPointerInComplexData,\n              IsCaptureFirstInfo && !RequiresReference, IsNonContiguous);\n\n          if (!IsExpressionFirstInfo) {\n            // If we have a PTR_AND_OBJ pair where the OBJ is a pointer as well,\n            // then we reset the TO/FROM/ALWAYS/DELETE/CLOSE flags.\n            if (IsPointer)\n              Flags &= ~(OMP_MAP_TO | OMP_MAP_FROM | OMP_MAP_ALWAYS |\n                         OMP_MAP_DELETE | OMP_MAP_CLOSE);\n\n            if (ShouldBeMemberOf) {\n              // Set placeholder value MEMBER_OF=FFFF to indicate that the flag\n              // should be later updated with the correct value of MEMBER_OF.\n              Flags |= OMP_MAP_MEMBER_OF;\n              // From now on, all subsequent PTR_AND_OBJ entries should not be\n              // marked as MEMBER_OF.\n              ShouldBeMemberOf = false;\n            }\n          }\n\n          CombinedInfo.Types.push_back(Flags);\n        }\n\n        // If we have encountered a member expression so far, keep track of the\n        // mapped member. If the parent is \"*this\", then the value declaration\n        // is nullptr.\n        if (EncounteredME) {\n          const auto *FD = cast<FieldDecl>(EncounteredME->getMemberDecl());\n          unsigned FieldIndex = FD->getFieldIndex();\n\n          // Update info about the lowest and highest elements for this struct\n          if (!PartialStruct.Base.isValid()) {\n            PartialStruct.LowestElem = {FieldIndex, LB};\n            if (IsFinalArraySection) {\n              Address HB =\n                  CGF.EmitOMPArraySectionExpr(OASE, /*IsLowerBound=*/false)\n                      .getAddress(CGF);\n              PartialStruct.HighestElem = {FieldIndex, HB};\n            } else {\n              PartialStruct.HighestElem = {FieldIndex, LB};\n            }\n            PartialStruct.Base = BP;\n            PartialStruct.LB = BP;\n          } else if (FieldIndex < PartialStruct.LowestElem.first) {\n            PartialStruct.LowestElem = {FieldIndex, LB};\n          } else if (FieldIndex > PartialStruct.HighestElem.first) {\n            PartialStruct.HighestElem = {FieldIndex, LB};\n          }\n        }\n\n        // Need to emit combined struct for array sections.\n        if (IsFinalArraySection || IsNonContiguous)\n          PartialStruct.IsArraySection = true;\n\n        // If we have a final array section, we are done with this expression.\n        if (IsFinalArraySection)\n          break;\n\n        // The pointer becomes the base for the next element.\n        if (Next != CE)\n          BP = LB;\n\n        IsExpressionFirstInfo = false;\n        IsCaptureFirstInfo = false;\n        FirstPointerInComplexData = false;\n      } else if (FirstPointerInComplexData) {\n        QualType Ty = Components.rbegin()\n                          ->getAssociatedDeclaration()\n                          ->getType()\n                          .getNonReferenceType();\n        BP = CGF.EmitLoadOfPointer(BP, Ty->castAs<PointerType>());\n        FirstPointerInComplexData = false;\n      }\n    }\n    // If ran into the whole component - allocate the space for the whole\n    // record.\n    if (!EncounteredME)\n      PartialStruct.HasCompleteRecord = true;\n\n    if (!IsNonContiguous)\n      return;\n\n    const ASTContext &Context = CGF.getContext();\n\n    // For supporting stride in array section, we need to initialize the first\n    // dimension size as 1, first offset as 0, and first count as 1\n    MapValuesArrayTy CurOffsets = {llvm::ConstantInt::get(CGF.CGM.Int64Ty, 0)};\n    MapValuesArrayTy CurCounts = {llvm::ConstantInt::get(CGF.CGM.Int64Ty, 1)};\n    MapValuesArrayTy CurStrides;\n    MapValuesArrayTy DimSizes{llvm::ConstantInt::get(CGF.CGM.Int64Ty, 1)};\n    uint64_t ElementTypeSize;\n\n    // Collect Size information for each dimension and get the element size as\n    // the first Stride. For example, for `int arr[10][10]`, the DimSizes\n    // should be [10, 10] and the first stride is 4 btyes.\n    for (const OMPClauseMappableExprCommon::MappableComponent &Component :\n         Components) {\n      const Expr *AssocExpr = Component.getAssociatedExpression();\n      const auto *OASE = dyn_cast<OMPArraySectionExpr>(AssocExpr);\n\n      if (!OASE)\n        continue;\n\n      QualType Ty = OMPArraySectionExpr::getBaseOriginalType(OASE->getBase());\n      auto *CAT = Context.getAsConstantArrayType(Ty);\n      auto *VAT = Context.getAsVariableArrayType(Ty);\n\n      // We need all the dimension size except for the last dimension.\n      assert((VAT || CAT || &Component == &*Components.begin()) &&\n             \"Should be either ConstantArray or VariableArray if not the \"\n             \"first Component\");\n\n      // Get element size if CurStrides is empty.\n      if (CurStrides.empty()) {\n        const Type *ElementType = nullptr;\n        if (CAT)\n          ElementType = CAT->getElementType().getTypePtr();\n        else if (VAT)\n          ElementType = VAT->getElementType().getTypePtr();\n        else\n          assert(&Component == &*Components.begin() &&\n                 \"Only expect pointer (non CAT or VAT) when this is the \"\n                 \"first Component\");\n        // If ElementType is null, then it means the base is a pointer\n        // (neither CAT nor VAT) and we'll attempt to get ElementType again\n        // for next iteration.\n        if (ElementType) {\n          // For the case that having pointer as base, we need to remove one\n          // level of indirection.\n          if (&Component != &*Components.begin())\n            ElementType = ElementType->getPointeeOrArrayElementType();\n          ElementTypeSize =\n              Context.getTypeSizeInChars(ElementType).getQuantity();\n          CurStrides.push_back(\n              llvm::ConstantInt::get(CGF.Int64Ty, ElementTypeSize));\n        }\n      }\n      // Get dimension value except for the last dimension since we don't need\n      // it.\n      if (DimSizes.size() < Components.size() - 1) {\n        if (CAT)\n          DimSizes.push_back(llvm::ConstantInt::get(\n              CGF.Int64Ty, CAT->getSize().getZExtValue()));\n        else if (VAT)\n          DimSizes.push_back(CGF.Builder.CreateIntCast(\n              CGF.EmitScalarExpr(VAT->getSizeExpr()), CGF.Int64Ty,\n              /*IsSigned=*/false));\n      }\n    }\n\n    // Skip the dummy dimension since we have already have its information.\n    auto DI = DimSizes.begin() + 1;\n    // Product of dimension.\n    llvm::Value *DimProd =\n        llvm::ConstantInt::get(CGF.CGM.Int64Ty, ElementTypeSize);\n\n    // Collect info for non-contiguous. Notice that offset, count, and stride\n    // are only meaningful for array-section, so we insert a null for anything\n    // other than array-section.\n    // Also, the size of offset, count, and stride are not the same as\n    // pointers, base_pointers, sizes, or dims. Instead, the size of offset,\n    // count, and stride are the same as the number of non-contiguous\n    // declaration in target update to/from clause.\n    for (const OMPClauseMappableExprCommon::MappableComponent &Component :\n         Components) {\n      const Expr *AssocExpr = Component.getAssociatedExpression();\n\n      if (const auto *AE = dyn_cast<ArraySubscriptExpr>(AssocExpr)) {\n        llvm::Value *Offset = CGF.Builder.CreateIntCast(\n            CGF.EmitScalarExpr(AE->getIdx()), CGF.Int64Ty,\n            /*isSigned=*/false);\n        CurOffsets.push_back(Offset);\n        CurCounts.push_back(llvm::ConstantInt::get(CGF.Int64Ty, /*V=*/1));\n        CurStrides.push_back(CurStrides.back());\n        continue;\n      }\n\n      const auto *OASE = dyn_cast<OMPArraySectionExpr>(AssocExpr);\n\n      if (!OASE)\n        continue;\n\n      // Offset\n      const Expr *OffsetExpr = OASE->getLowerBound();\n      llvm::Value *Offset = nullptr;\n      if (!OffsetExpr) {\n        // If offset is absent, then we just set it to zero.\n        Offset = llvm::ConstantInt::get(CGF.Int64Ty, 0);\n      } else {\n        Offset = CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(OffsetExpr),\n                                           CGF.Int64Ty,\n                                           /*isSigned=*/false);\n      }\n      CurOffsets.push_back(Offset);\n\n      // Count\n      const Expr *CountExpr = OASE->getLength();\n      llvm::Value *Count = nullptr;\n      if (!CountExpr) {\n        // In Clang, once a high dimension is an array section, we construct all\n        // the lower dimension as array section, however, for case like\n        // arr[0:2][2], Clang construct the inner dimension as an array section\n        // but it actually is not in an array section form according to spec.\n        if (!OASE->getColonLocFirst().isValid() &&\n            !OASE->getColonLocSecond().isValid()) {\n          Count = llvm::ConstantInt::get(CGF.Int64Ty, 1);\n        } else {\n          // OpenMP 5.0, 2.1.5 Array Sections, Description.\n          // When the length is absent it defaults to \u2308(size \u2212\n          // lower-bound)/stride\u2309, where size is the size of the array\n          // dimension.\n          const Expr *StrideExpr = OASE->getStride();\n          llvm::Value *Stride =\n              StrideExpr\n                  ? CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(StrideExpr),\n                                              CGF.Int64Ty, /*isSigned=*/false)\n                  : nullptr;\n          if (Stride)\n            Count = CGF.Builder.CreateUDiv(\n                CGF.Builder.CreateNUWSub(*DI, Offset), Stride);\n          else\n            Count = CGF.Builder.CreateNUWSub(*DI, Offset);\n        }\n      } else {\n        Count = CGF.EmitScalarExpr(CountExpr);\n      }\n      Count = CGF.Builder.CreateIntCast(Count, CGF.Int64Ty, /*isSigned=*/false);\n      CurCounts.push_back(Count);\n\n      // Stride_n' = Stride_n * (D_0 * D_1 ... * D_n-1) * Unit size\n      // Take `int arr[5][5][5]` and `arr[0:2:2][1:2:1][0:2:2]` as an example:\n      //              Offset      Count     Stride\n      //    D0          0           1         4    (int)    <- dummy dimension\n      //    D1          0           2         8    (2 * (1) * 4)\n      //    D2          1           2         20   (1 * (1 * 5) * 4)\n      //    D3          0           2         200  (2 * (1 * 5 * 4) * 4)\n      const Expr *StrideExpr = OASE->getStride();\n      llvm::Value *Stride =\n          StrideExpr\n              ? CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(StrideExpr),\n                                          CGF.Int64Ty, /*isSigned=*/false)\n              : nullptr;\n      DimProd = CGF.Builder.CreateNUWMul(DimProd, *(DI - 1));\n      if (Stride)\n        CurStrides.push_back(CGF.Builder.CreateNUWMul(DimProd, Stride));\n      else\n        CurStrides.push_back(DimProd);\n      if (DI != DimSizes.end())\n        ++DI;\n    }\n\n    CombinedInfo.NonContigInfo.Offsets.push_back(CurOffsets);\n    CombinedInfo.NonContigInfo.Counts.push_back(CurCounts);\n    CombinedInfo.NonContigInfo.Strides.push_back(CurStrides);\n  }\n\n  /// Return the adjusted map modifiers if the declaration a capture refers to\n  /// appears in a first-private clause. This is expected to be used only with\n  /// directives that start with 'target'.\n  MappableExprsHandler::OpenMPOffloadMappingFlags\n  getMapModifiersForPrivateClauses(const CapturedStmt::Capture &Cap) const {\n    assert(Cap.capturesVariable() && \"Expected capture by reference only!\");\n\n    // A first private variable captured by reference will use only the\n    // 'private ptr' and 'map to' flag. Return the right flags if the captured\n    // declaration is known as first-private in this handler.\n    if (FirstPrivateDecls.count(Cap.getCapturedVar())) {\n      if (Cap.getCapturedVar()->getType().isConstant(CGF.getContext()) &&\n          Cap.getCaptureKind() == CapturedStmt::VCK_ByRef)\n        return MappableExprsHandler::OMP_MAP_ALWAYS |\n               MappableExprsHandler::OMP_MAP_TO;\n      if (Cap.getCapturedVar()->getType()->isAnyPointerType())\n        return MappableExprsHandler::OMP_MAP_TO |\n               MappableExprsHandler::OMP_MAP_PTR_AND_OBJ;\n      return MappableExprsHandler::OMP_MAP_PRIVATE |\n             MappableExprsHandler::OMP_MAP_TO;\n    }\n    return MappableExprsHandler::OMP_MAP_TO |\n           MappableExprsHandler::OMP_MAP_FROM;\n  }\n\n  static OpenMPOffloadMappingFlags getMemberOfFlag(unsigned Position) {\n    // Rotate by getFlagMemberOffset() bits.\n    return static_cast<OpenMPOffloadMappingFlags>(((uint64_t)Position + 1)\n                                                  << getFlagMemberOffset());\n  }\n\n  static void setCorrectMemberOfFlag(OpenMPOffloadMappingFlags &Flags,\n                                     OpenMPOffloadMappingFlags MemberOfFlag) {\n    // If the entry is PTR_AND_OBJ but has not been marked with the special\n    // placeholder value 0xFFFF in the MEMBER_OF field, then it should not be\n    // marked as MEMBER_OF.\n    if ((Flags & OMP_MAP_PTR_AND_OBJ) &&\n        ((Flags & OMP_MAP_MEMBER_OF) != OMP_MAP_MEMBER_OF))\n      return;\n\n    // Reset the placeholder value to prepare the flag for the assignment of the\n    // proper MEMBER_OF value.\n    Flags &= ~OMP_MAP_MEMBER_OF;\n    Flags |= MemberOfFlag;\n  }\n\n  void getPlainLayout(const CXXRecordDecl *RD,\n                      llvm::SmallVectorImpl<const FieldDecl *> &Layout,\n                      bool AsBase) const {\n    const CGRecordLayout &RL = CGF.getTypes().getCGRecordLayout(RD);\n\n    llvm::StructType *St =\n        AsBase ? RL.getBaseSubobjectLLVMType() : RL.getLLVMType();\n\n    unsigned NumElements = St->getNumElements();\n    llvm::SmallVector<\n        llvm::PointerUnion<const CXXRecordDecl *, const FieldDecl *>, 4>\n        RecordLayout(NumElements);\n\n    // Fill bases.\n    for (const auto &I : RD->bases()) {\n      if (I.isVirtual())\n        continue;\n      const auto *Base = I.getType()->getAsCXXRecordDecl();\n      // Ignore empty bases.\n      if (Base->isEmpty() || CGF.getContext()\n                                 .getASTRecordLayout(Base)\n                                 .getNonVirtualSize()\n                                 .isZero())\n        continue;\n\n      unsigned FieldIndex = RL.getNonVirtualBaseLLVMFieldNo(Base);\n      RecordLayout[FieldIndex] = Base;\n    }\n    // Fill in virtual bases.\n    for (const auto &I : RD->vbases()) {\n      const auto *Base = I.getType()->getAsCXXRecordDecl();\n      // Ignore empty bases.\n      if (Base->isEmpty())\n        continue;\n      unsigned FieldIndex = RL.getVirtualBaseIndex(Base);\n      if (RecordLayout[FieldIndex])\n        continue;\n      RecordLayout[FieldIndex] = Base;\n    }\n    // Fill in all the fields.\n    assert(!RD->isUnion() && \"Unexpected union.\");\n    for (const auto *Field : RD->fields()) {\n      // Fill in non-bitfields. (Bitfields always use a zero pattern, which we\n      // will fill in later.)\n      if (!Field->isBitField() && !Field->isZeroSize(CGF.getContext())) {\n        unsigned FieldIndex = RL.getLLVMFieldNo(Field);\n        RecordLayout[FieldIndex] = Field;\n      }\n    }\n    for (const llvm::PointerUnion<const CXXRecordDecl *, const FieldDecl *>\n             &Data : RecordLayout) {\n      if (Data.isNull())\n        continue;\n      if (const auto *Base = Data.dyn_cast<const CXXRecordDecl *>())\n        getPlainLayout(Base, Layout, /*AsBase=*/true);\n      else\n        Layout.push_back(Data.get<const FieldDecl *>());\n    }\n  }\n\n  /// Generate all the base pointers, section pointers, sizes, map types, and\n  /// mappers for the extracted mappable expressions (all included in \\a\n  /// CombinedInfo). Also, for each item that relates with a device pointer, a\n  /// pair of the relevant declaration and index where it occurs is appended to\n  /// the device pointers info array.\n  void generateAllInfoForClauses(\n      ArrayRef<const OMPClause *> Clauses, MapCombinedInfoTy &CombinedInfo,\n      const llvm::DenseSet<CanonicalDeclPtr<const Decl>> &SkipVarSet =\n          llvm::DenseSet<CanonicalDeclPtr<const Decl>>()) const {\n    // We have to process the component lists that relate with the same\n    // declaration in a single chunk so that we can generate the map flags\n    // correctly. Therefore, we organize all lists in a map.\n    enum MapKind { Present, Allocs, Other, Total };\n    llvm::MapVector<CanonicalDeclPtr<const Decl>,\n                    SmallVector<SmallVector<MapInfo, 8>, 4>>\n        Info;\n\n    // Helper function to fill the information map for the different supported\n    // clauses.\n    auto &&InfoGen =\n        [&Info, &SkipVarSet](\n            const ValueDecl *D, MapKind Kind,\n            OMPClauseMappableExprCommon::MappableExprComponentListRef L,\n            OpenMPMapClauseKind MapType,\n            ArrayRef<OpenMPMapModifierKind> MapModifiers,\n            ArrayRef<OpenMPMotionModifierKind> MotionModifiers,\n            bool ReturnDevicePointer, bool IsImplicit, const ValueDecl *Mapper,\n            const Expr *VarRef = nullptr, bool ForDeviceAddr = false) {\n          if (SkipVarSet.contains(D))\n            return;\n          auto It = Info.find(D);\n          if (It == Info.end())\n            It = Info\n                     .insert(std::make_pair(\n                         D, SmallVector<SmallVector<MapInfo, 8>, 4>(Total)))\n                     .first;\n          It->second[Kind].emplace_back(\n              L, MapType, MapModifiers, MotionModifiers, ReturnDevicePointer,\n              IsImplicit, Mapper, VarRef, ForDeviceAddr);\n        };\n\n    for (const auto *Cl : Clauses) {\n      const auto *C = dyn_cast<OMPMapClause>(Cl);\n      if (!C)\n        continue;\n      MapKind Kind = Other;\n      if (!C->getMapTypeModifiers().empty() &&\n          llvm::any_of(C->getMapTypeModifiers(), [](OpenMPMapModifierKind K) {\n            return K == OMPC_MAP_MODIFIER_present;\n          }))\n        Kind = Present;\n      else if (C->getMapType() == OMPC_MAP_alloc)\n        Kind = Allocs;\n      const auto *EI = C->getVarRefs().begin();\n      for (const auto L : C->component_lists()) {\n        const Expr *E = (C->getMapLoc().isValid()) ? *EI : nullptr;\n        InfoGen(std::get<0>(L), Kind, std::get<1>(L), C->getMapType(),\n                C->getMapTypeModifiers(), llvm::None,\n                /*ReturnDevicePointer=*/false, C->isImplicit(), std::get<2>(L),\n                E);\n        ++EI;\n      }\n    }\n    for (const auto *Cl : Clauses) {\n      const auto *C = dyn_cast<OMPToClause>(Cl);\n      if (!C)\n        continue;\n      MapKind Kind = Other;\n      if (!C->getMotionModifiers().empty() &&\n          llvm::any_of(C->getMotionModifiers(), [](OpenMPMotionModifierKind K) {\n            return K == OMPC_MOTION_MODIFIER_present;\n          }))\n        Kind = Present;\n      const auto *EI = C->getVarRefs().begin();\n      for (const auto L : C->component_lists()) {\n        InfoGen(std::get<0>(L), Kind, std::get<1>(L), OMPC_MAP_to, llvm::None,\n                C->getMotionModifiers(), /*ReturnDevicePointer=*/false,\n                C->isImplicit(), std::get<2>(L), *EI);\n        ++EI;\n      }\n    }\n    for (const auto *Cl : Clauses) {\n      const auto *C = dyn_cast<OMPFromClause>(Cl);\n      if (!C)\n        continue;\n      MapKind Kind = Other;\n      if (!C->getMotionModifiers().empty() &&\n          llvm::any_of(C->getMotionModifiers(), [](OpenMPMotionModifierKind K) {\n            return K == OMPC_MOTION_MODIFIER_present;\n          }))\n        Kind = Present;\n      const auto *EI = C->getVarRefs().begin();\n      for (const auto L : C->component_lists()) {\n        InfoGen(std::get<0>(L), Kind, std::get<1>(L), OMPC_MAP_from, llvm::None,\n                C->getMotionModifiers(), /*ReturnDevicePointer=*/false,\n                C->isImplicit(), std::get<2>(L), *EI);\n        ++EI;\n      }\n    }\n\n    // Look at the use_device_ptr clause information and mark the existing map\n    // entries as such. If there is no map information for an entry in the\n    // use_device_ptr list, we create one with map type 'alloc' and zero size\n    // section. It is the user fault if that was not mapped before. If there is\n    // no map information and the pointer is a struct member, then we defer the\n    // emission of that entry until the whole struct has been processed.\n    llvm::MapVector<CanonicalDeclPtr<const Decl>,\n                    SmallVector<DeferredDevicePtrEntryTy, 4>>\n        DeferredInfo;\n    MapCombinedInfoTy UseDevicePtrCombinedInfo;\n\n    for (const auto *Cl : Clauses) {\n      const auto *C = dyn_cast<OMPUseDevicePtrClause>(Cl);\n      if (!C)\n        continue;\n      for (const auto L : C->component_lists()) {\n        OMPClauseMappableExprCommon::MappableExprComponentListRef Components =\n            std::get<1>(L);\n        assert(!Components.empty() &&\n               \"Not expecting empty list of components!\");\n        const ValueDecl *VD = Components.back().getAssociatedDeclaration();\n        VD = cast<ValueDecl>(VD->getCanonicalDecl());\n        const Expr *IE = Components.back().getAssociatedExpression();\n        // If the first component is a member expression, we have to look into\n        // 'this', which maps to null in the map of map information. Otherwise\n        // look directly for the information.\n        auto It = Info.find(isa<MemberExpr>(IE) ? nullptr : VD);\n\n        // We potentially have map information for this declaration already.\n        // Look for the first set of components that refer to it.\n        if (It != Info.end()) {\n          bool Found = false;\n          for (auto &Data : It->second) {\n            auto *CI = llvm::find_if(Data, [VD](const MapInfo &MI) {\n              return MI.Components.back().getAssociatedDeclaration() == VD;\n            });\n            // If we found a map entry, signal that the pointer has to be\n            // returned and move on to the next declaration. Exclude cases where\n            // the base pointer is mapped as array subscript, array section or\n            // array shaping. The base address is passed as a pointer to base in\n            // this case and cannot be used as a base for use_device_ptr list\n            // item.\n            if (CI != Data.end()) {\n              auto PrevCI = std::next(CI->Components.rbegin());\n              const auto *VarD = dyn_cast<VarDecl>(VD);\n              if (CGF.CGM.getOpenMPRuntime().hasRequiresUnifiedSharedMemory() ||\n                  isa<MemberExpr>(IE) ||\n                  !VD->getType().getNonReferenceType()->isPointerType() ||\n                  PrevCI == CI->Components.rend() ||\n                  isa<MemberExpr>(PrevCI->getAssociatedExpression()) || !VarD ||\n                  VarD->hasLocalStorage()) {\n                CI->ReturnDevicePointer = true;\n                Found = true;\n                break;\n              }\n            }\n          }\n          if (Found)\n            continue;\n        }\n\n        // We didn't find any match in our map information - generate a zero\n        // size array section - if the pointer is a struct member we defer this\n        // action until the whole struct has been processed.\n        if (isa<MemberExpr>(IE)) {\n          // Insert the pointer into Info to be processed by\n          // generateInfoForComponentList. Because it is a member pointer\n          // without a pointee, no entry will be generated for it, therefore\n          // we need to generate one after the whole struct has been processed.\n          // Nonetheless, generateInfoForComponentList must be called to take\n          // the pointer into account for the calculation of the range of the\n          // partial struct.\n          InfoGen(nullptr, Other, Components, OMPC_MAP_unknown, llvm::None,\n                  llvm::None, /*ReturnDevicePointer=*/false, C->isImplicit(),\n                  nullptr);\n          DeferredInfo[nullptr].emplace_back(IE, VD, /*ForDeviceAddr=*/false);\n        } else {\n          llvm::Value *Ptr =\n              CGF.EmitLoadOfScalar(CGF.EmitLValue(IE), IE->getExprLoc());\n          UseDevicePtrCombinedInfo.Exprs.push_back(VD);\n          UseDevicePtrCombinedInfo.BasePointers.emplace_back(Ptr, VD);\n          UseDevicePtrCombinedInfo.Pointers.push_back(Ptr);\n          UseDevicePtrCombinedInfo.Sizes.push_back(\n              llvm::Constant::getNullValue(CGF.Int64Ty));\n          UseDevicePtrCombinedInfo.Types.push_back(OMP_MAP_RETURN_PARAM);\n          UseDevicePtrCombinedInfo.Mappers.push_back(nullptr);\n        }\n      }\n    }\n\n    // Look at the use_device_addr clause information and mark the existing map\n    // entries as such. If there is no map information for an entry in the\n    // use_device_addr list, we create one with map type 'alloc' and zero size\n    // section. It is the user fault if that was not mapped before. If there is\n    // no map information and the pointer is a struct member, then we defer the\n    // emission of that entry until the whole struct has been processed.\n    llvm::SmallDenseSet<CanonicalDeclPtr<const Decl>, 4> Processed;\n    for (const auto *Cl : Clauses) {\n      const auto *C = dyn_cast<OMPUseDeviceAddrClause>(Cl);\n      if (!C)\n        continue;\n      for (const auto L : C->component_lists()) {\n        assert(!std::get<1>(L).empty() &&\n               \"Not expecting empty list of components!\");\n        const ValueDecl *VD = std::get<1>(L).back().getAssociatedDeclaration();\n        if (!Processed.insert(VD).second)\n          continue;\n        VD = cast<ValueDecl>(VD->getCanonicalDecl());\n        const Expr *IE = std::get<1>(L).back().getAssociatedExpression();\n        // If the first component is a member expression, we have to look into\n        // 'this', which maps to null in the map of map information. Otherwise\n        // look directly for the information.\n        auto It = Info.find(isa<MemberExpr>(IE) ? nullptr : VD);\n\n        // We potentially have map information for this declaration already.\n        // Look for the first set of components that refer to it.\n        if (It != Info.end()) {\n          bool Found = false;\n          for (auto &Data : It->second) {\n            auto *CI = llvm::find_if(Data, [VD](const MapInfo &MI) {\n              return MI.Components.back().getAssociatedDeclaration() == VD;\n            });\n            // If we found a map entry, signal that the pointer has to be\n            // returned and move on to the next declaration.\n            if (CI != Data.end()) {\n              CI->ReturnDevicePointer = true;\n              Found = true;\n              break;\n            }\n          }\n          if (Found)\n            continue;\n        }\n\n        // We didn't find any match in our map information - generate a zero\n        // size array section - if the pointer is a struct member we defer this\n        // action until the whole struct has been processed.\n        if (isa<MemberExpr>(IE)) {\n          // Insert the pointer into Info to be processed by\n          // generateInfoForComponentList. Because it is a member pointer\n          // without a pointee, no entry will be generated for it, therefore\n          // we need to generate one after the whole struct has been processed.\n          // Nonetheless, generateInfoForComponentList must be called to take\n          // the pointer into account for the calculation of the range of the\n          // partial struct.\n          InfoGen(nullptr, Other, std::get<1>(L), OMPC_MAP_unknown, llvm::None,\n                  llvm::None, /*ReturnDevicePointer=*/false, C->isImplicit(),\n                  nullptr, nullptr, /*ForDeviceAddr=*/true);\n          DeferredInfo[nullptr].emplace_back(IE, VD, /*ForDeviceAddr=*/true);\n        } else {\n          llvm::Value *Ptr;\n          if (IE->isGLValue())\n            Ptr = CGF.EmitLValue(IE).getPointer(CGF);\n          else\n            Ptr = CGF.EmitScalarExpr(IE);\n          CombinedInfo.Exprs.push_back(VD);\n          CombinedInfo.BasePointers.emplace_back(Ptr, VD);\n          CombinedInfo.Pointers.push_back(Ptr);\n          CombinedInfo.Sizes.push_back(\n              llvm::Constant::getNullValue(CGF.Int64Ty));\n          CombinedInfo.Types.push_back(OMP_MAP_RETURN_PARAM);\n          CombinedInfo.Mappers.push_back(nullptr);\n        }\n      }\n    }\n\n    for (const auto &Data : Info) {\n      StructRangeInfoTy PartialStruct;\n      // Temporary generated information.\n      MapCombinedInfoTy CurInfo;\n      const Decl *D = Data.first;\n      const ValueDecl *VD = cast_or_null<ValueDecl>(D);\n      for (const auto &M : Data.second) {\n        for (const MapInfo &L : M) {\n          assert(!L.Components.empty() &&\n                 \"Not expecting declaration with no component lists.\");\n\n          // Remember the current base pointer index.\n          unsigned CurrentBasePointersIdx = CurInfo.BasePointers.size();\n          CurInfo.NonContigInfo.IsNonContiguous =\n              L.Components.back().isNonContiguous();\n          generateInfoForComponentList(\n              L.MapType, L.MapModifiers, L.MotionModifiers, L.Components,\n              CurInfo, PartialStruct, /*IsFirstComponentList=*/false,\n              L.IsImplicit, L.Mapper, L.ForDeviceAddr, VD, L.VarRef);\n\n          // If this entry relates with a device pointer, set the relevant\n          // declaration and add the 'return pointer' flag.\n          if (L.ReturnDevicePointer) {\n            assert(CurInfo.BasePointers.size() > CurrentBasePointersIdx &&\n                   \"Unexpected number of mapped base pointers.\");\n\n            const ValueDecl *RelevantVD =\n                L.Components.back().getAssociatedDeclaration();\n            assert(RelevantVD &&\n                   \"No relevant declaration related with device pointer??\");\n\n            CurInfo.BasePointers[CurrentBasePointersIdx].setDevicePtrDecl(\n                RelevantVD);\n            CurInfo.Types[CurrentBasePointersIdx] |= OMP_MAP_RETURN_PARAM;\n          }\n        }\n      }\n\n      // Append any pending zero-length pointers which are struct members and\n      // used with use_device_ptr or use_device_addr.\n      auto CI = DeferredInfo.find(Data.first);\n      if (CI != DeferredInfo.end()) {\n        for (const DeferredDevicePtrEntryTy &L : CI->second) {\n          llvm::Value *BasePtr;\n          llvm::Value *Ptr;\n          if (L.ForDeviceAddr) {\n            if (L.IE->isGLValue())\n              Ptr = this->CGF.EmitLValue(L.IE).getPointer(CGF);\n            else\n              Ptr = this->CGF.EmitScalarExpr(L.IE);\n            BasePtr = Ptr;\n            // Entry is RETURN_PARAM. Also, set the placeholder value\n            // MEMBER_OF=FFFF so that the entry is later updated with the\n            // correct value of MEMBER_OF.\n            CurInfo.Types.push_back(OMP_MAP_RETURN_PARAM | OMP_MAP_MEMBER_OF);\n          } else {\n            BasePtr = this->CGF.EmitLValue(L.IE).getPointer(CGF);\n            Ptr = this->CGF.EmitLoadOfScalar(this->CGF.EmitLValue(L.IE),\n                                             L.IE->getExprLoc());\n            // Entry is PTR_AND_OBJ and RETURN_PARAM. Also, set the\n            // placeholder value MEMBER_OF=FFFF so that the entry is later\n            // updated with the correct value of MEMBER_OF.\n            CurInfo.Types.push_back(OMP_MAP_PTR_AND_OBJ | OMP_MAP_RETURN_PARAM |\n                                    OMP_MAP_MEMBER_OF);\n          }\n          CurInfo.Exprs.push_back(L.VD);\n          CurInfo.BasePointers.emplace_back(BasePtr, L.VD);\n          CurInfo.Pointers.push_back(Ptr);\n          CurInfo.Sizes.push_back(\n              llvm::Constant::getNullValue(this->CGF.Int64Ty));\n          CurInfo.Mappers.push_back(nullptr);\n        }\n      }\n      // If there is an entry in PartialStruct it means we have a struct with\n      // individual members mapped. Emit an extra combined entry.\n      if (PartialStruct.Base.isValid()) {\n        CurInfo.NonContigInfo.Dims.push_back(0);\n        emitCombinedEntry(CombinedInfo, CurInfo.Types, PartialStruct, VD);\n      }\n\n      // We need to append the results of this capture to what we already\n      // have.\n      CombinedInfo.append(CurInfo);\n    }\n    // Append data for use_device_ptr clauses.\n    CombinedInfo.append(UseDevicePtrCombinedInfo);\n  }\n\npublic:\n  MappableExprsHandler(const OMPExecutableDirective &Dir, CodeGenFunction &CGF)\n      : CurDir(&Dir), CGF(CGF) {\n    // Extract firstprivate clause information.\n    for (const auto *C : Dir.getClausesOfKind<OMPFirstprivateClause>())\n      for (const auto *D : C->varlists())\n        FirstPrivateDecls.try_emplace(\n            cast<VarDecl>(cast<DeclRefExpr>(D)->getDecl()), C->isImplicit());\n    // Extract implicit firstprivates from uses_allocators clauses.\n    for (const auto *C : Dir.getClausesOfKind<OMPUsesAllocatorsClause>()) {\n      for (unsigned I = 0, E = C->getNumberOfAllocators(); I < E; ++I) {\n        OMPUsesAllocatorsClause::Data D = C->getAllocatorData(I);\n        if (const auto *DRE = dyn_cast_or_null<DeclRefExpr>(D.AllocatorTraits))\n          FirstPrivateDecls.try_emplace(cast<VarDecl>(DRE->getDecl()),\n                                        /*Implicit=*/true);\n        else if (const auto *VD = dyn_cast<VarDecl>(\n                     cast<DeclRefExpr>(D.Allocator->IgnoreParenImpCasts())\n                         ->getDecl()))\n          FirstPrivateDecls.try_emplace(VD, /*Implicit=*/true);\n      }\n    }\n    // Extract device pointer clause information.\n    for (const auto *C : Dir.getClausesOfKind<OMPIsDevicePtrClause>())\n      for (auto L : C->component_lists())\n        DevPointersMap[std::get<0>(L)].push_back(std::get<1>(L));\n  }\n\n  /// Constructor for the declare mapper directive.\n  MappableExprsHandler(const OMPDeclareMapperDecl &Dir, CodeGenFunction &CGF)\n      : CurDir(&Dir), CGF(CGF) {}\n\n  /// Generate code for the combined entry if we have a partially mapped struct\n  /// and take care of the mapping flags of the arguments corresponding to\n  /// individual struct members.\n  void emitCombinedEntry(MapCombinedInfoTy &CombinedInfo,\n                         MapFlagsArrayTy &CurTypes,\n                         const StructRangeInfoTy &PartialStruct,\n                         const ValueDecl *VD = nullptr,\n                         bool NotTargetParams = true) const {\n    if (CurTypes.size() == 1 &&\n        ((CurTypes.back() & OMP_MAP_MEMBER_OF) != OMP_MAP_MEMBER_OF) &&\n        !PartialStruct.IsArraySection)\n      return;\n    Address LBAddr = PartialStruct.LowestElem.second;\n    Address HBAddr = PartialStruct.HighestElem.second;\n    if (PartialStruct.HasCompleteRecord) {\n      LBAddr = PartialStruct.LB;\n      HBAddr = PartialStruct.LB;\n    }\n    CombinedInfo.Exprs.push_back(VD);\n    // Base is the base of the struct\n    CombinedInfo.BasePointers.push_back(PartialStruct.Base.getPointer());\n    // Pointer is the address of the lowest element\n    llvm::Value *LB = LBAddr.getPointer();\n    CombinedInfo.Pointers.push_back(LB);\n    // There should not be a mapper for a combined entry.\n    CombinedInfo.Mappers.push_back(nullptr);\n    // Size is (addr of {highest+1} element) - (addr of lowest element)\n    llvm::Value *HB = HBAddr.getPointer();\n    llvm::Value *HAddr = CGF.Builder.CreateConstGEP1_32(HB, /*Idx0=*/1);\n    llvm::Value *CLAddr = CGF.Builder.CreatePointerCast(LB, CGF.VoidPtrTy);\n    llvm::Value *CHAddr = CGF.Builder.CreatePointerCast(HAddr, CGF.VoidPtrTy);\n    llvm::Value *Diff = CGF.Builder.CreatePtrDiff(CHAddr, CLAddr);\n    llvm::Value *Size = CGF.Builder.CreateIntCast(Diff, CGF.Int64Ty,\n                                                  /*isSigned=*/false);\n    CombinedInfo.Sizes.push_back(Size);\n    // Map type is always TARGET_PARAM, if generate info for captures.\n    CombinedInfo.Types.push_back(NotTargetParams ? OMP_MAP_NONE\n                                                 : OMP_MAP_TARGET_PARAM);\n    // If any element has the present modifier, then make sure the runtime\n    // doesn't attempt to allocate the struct.\n    if (CurTypes.end() !=\n        llvm::find_if(CurTypes, [](OpenMPOffloadMappingFlags Type) {\n          return Type & OMP_MAP_PRESENT;\n        }))\n      CombinedInfo.Types.back() |= OMP_MAP_PRESENT;\n    // Remove TARGET_PARAM flag from the first element\n    (*CurTypes.begin()) &= ~OMP_MAP_TARGET_PARAM;\n\n    // All other current entries will be MEMBER_OF the combined entry\n    // (except for PTR_AND_OBJ entries which do not have a placeholder value\n    // 0xFFFF in the MEMBER_OF field).\n    OpenMPOffloadMappingFlags MemberOfFlag =\n        getMemberOfFlag(CombinedInfo.BasePointers.size() - 1);\n    for (auto &M : CurTypes)\n      setCorrectMemberOfFlag(M, MemberOfFlag);\n  }\n\n  /// Generate all the base pointers, section pointers, sizes, map types, and\n  /// mappers for the extracted mappable expressions (all included in \\a\n  /// CombinedInfo). Also, for each item that relates with a device pointer, a\n  /// pair of the relevant declaration and index where it occurs is appended to\n  /// the device pointers info array.\n  void generateAllInfo(\n      MapCombinedInfoTy &CombinedInfo,\n      const llvm::DenseSet<CanonicalDeclPtr<const Decl>> &SkipVarSet =\n          llvm::DenseSet<CanonicalDeclPtr<const Decl>>()) const {\n    assert(CurDir.is<const OMPExecutableDirective *>() &&\n           \"Expect a executable directive\");\n    const auto *CurExecDir = CurDir.get<const OMPExecutableDirective *>();\n    generateAllInfoForClauses(CurExecDir->clauses(), CombinedInfo, SkipVarSet);\n  }\n\n  /// Generate all the base pointers, section pointers, sizes, map types, and\n  /// mappers for the extracted map clauses of user-defined mapper (all included\n  /// in \\a CombinedInfo).\n  void generateAllInfoForMapper(MapCombinedInfoTy &CombinedInfo) const {\n    assert(CurDir.is<const OMPDeclareMapperDecl *>() &&\n           \"Expect a declare mapper directive\");\n    const auto *CurMapperDir = CurDir.get<const OMPDeclareMapperDecl *>();\n    generateAllInfoForClauses(CurMapperDir->clauses(), CombinedInfo);\n  }\n\n  /// Emit capture info for lambdas for variables captured by reference.\n  void generateInfoForLambdaCaptures(\n      const ValueDecl *VD, llvm::Value *Arg, MapCombinedInfoTy &CombinedInfo,\n      llvm::DenseMap<llvm::Value *, llvm::Value *> &LambdaPointers) const {\n    const auto *RD = VD->getType()\n                         .getCanonicalType()\n                         .getNonReferenceType()\n                         ->getAsCXXRecordDecl();\n    if (!RD || !RD->isLambda())\n      return;\n    Address VDAddr = Address(Arg, CGF.getContext().getDeclAlign(VD));\n    LValue VDLVal = CGF.MakeAddrLValue(\n        VDAddr, VD->getType().getCanonicalType().getNonReferenceType());\n    llvm::DenseMap<const VarDecl *, FieldDecl *> Captures;\n    FieldDecl *ThisCapture = nullptr;\n    RD->getCaptureFields(Captures, ThisCapture);\n    if (ThisCapture) {\n      LValue ThisLVal =\n          CGF.EmitLValueForFieldInitialization(VDLVal, ThisCapture);\n      LValue ThisLValVal = CGF.EmitLValueForField(VDLVal, ThisCapture);\n      LambdaPointers.try_emplace(ThisLVal.getPointer(CGF),\n                                 VDLVal.getPointer(CGF));\n      CombinedInfo.Exprs.push_back(VD);\n      CombinedInfo.BasePointers.push_back(ThisLVal.getPointer(CGF));\n      CombinedInfo.Pointers.push_back(ThisLValVal.getPointer(CGF));\n      CombinedInfo.Sizes.push_back(\n          CGF.Builder.CreateIntCast(CGF.getTypeSize(CGF.getContext().VoidPtrTy),\n                                    CGF.Int64Ty, /*isSigned=*/true));\n      CombinedInfo.Types.push_back(OMP_MAP_PTR_AND_OBJ | OMP_MAP_LITERAL |\n                                   OMP_MAP_MEMBER_OF | OMP_MAP_IMPLICIT);\n      CombinedInfo.Mappers.push_back(nullptr);\n    }\n    for (const LambdaCapture &LC : RD->captures()) {\n      if (!LC.capturesVariable())\n        continue;\n      const VarDecl *VD = LC.getCapturedVar();\n      if (LC.getCaptureKind() != LCK_ByRef && !VD->getType()->isPointerType())\n        continue;\n      auto It = Captures.find(VD);\n      assert(It != Captures.end() && \"Found lambda capture without field.\");\n      LValue VarLVal = CGF.EmitLValueForFieldInitialization(VDLVal, It->second);\n      if (LC.getCaptureKind() == LCK_ByRef) {\n        LValue VarLValVal = CGF.EmitLValueForField(VDLVal, It->second);\n        LambdaPointers.try_emplace(VarLVal.getPointer(CGF),\n                                   VDLVal.getPointer(CGF));\n        CombinedInfo.Exprs.push_back(VD);\n        CombinedInfo.BasePointers.push_back(VarLVal.getPointer(CGF));\n        CombinedInfo.Pointers.push_back(VarLValVal.getPointer(CGF));\n        CombinedInfo.Sizes.push_back(CGF.Builder.CreateIntCast(\n            CGF.getTypeSize(\n                VD->getType().getCanonicalType().getNonReferenceType()),\n            CGF.Int64Ty, /*isSigned=*/true));\n      } else {\n        RValue VarRVal = CGF.EmitLoadOfLValue(VarLVal, RD->getLocation());\n        LambdaPointers.try_emplace(VarLVal.getPointer(CGF),\n                                   VDLVal.getPointer(CGF));\n        CombinedInfo.Exprs.push_back(VD);\n        CombinedInfo.BasePointers.push_back(VarLVal.getPointer(CGF));\n        CombinedInfo.Pointers.push_back(VarRVal.getScalarVal());\n        CombinedInfo.Sizes.push_back(llvm::ConstantInt::get(CGF.Int64Ty, 0));\n      }\n      CombinedInfo.Types.push_back(OMP_MAP_PTR_AND_OBJ | OMP_MAP_LITERAL |\n                                   OMP_MAP_MEMBER_OF | OMP_MAP_IMPLICIT);\n      CombinedInfo.Mappers.push_back(nullptr);\n    }\n  }\n\n  /// Set correct indices for lambdas captures.\n  void adjustMemberOfForLambdaCaptures(\n      const llvm::DenseMap<llvm::Value *, llvm::Value *> &LambdaPointers,\n      MapBaseValuesArrayTy &BasePointers, MapValuesArrayTy &Pointers,\n      MapFlagsArrayTy &Types) const {\n    for (unsigned I = 0, E = Types.size(); I < E; ++I) {\n      // Set correct member_of idx for all implicit lambda captures.\n      if (Types[I] != (OMP_MAP_PTR_AND_OBJ | OMP_MAP_LITERAL |\n                       OMP_MAP_MEMBER_OF | OMP_MAP_IMPLICIT))\n        continue;\n      llvm::Value *BasePtr = LambdaPointers.lookup(*BasePointers[I]);\n      assert(BasePtr && \"Unable to find base lambda address.\");\n      int TgtIdx = -1;\n      for (unsigned J = I; J > 0; --J) {\n        unsigned Idx = J - 1;\n        if (Pointers[Idx] != BasePtr)\n          continue;\n        TgtIdx = Idx;\n        break;\n      }\n      assert(TgtIdx != -1 && \"Unable to find parent lambda.\");\n      // All other current entries will be MEMBER_OF the combined entry\n      // (except for PTR_AND_OBJ entries which do not have a placeholder value\n      // 0xFFFF in the MEMBER_OF field).\n      OpenMPOffloadMappingFlags MemberOfFlag = getMemberOfFlag(TgtIdx);\n      setCorrectMemberOfFlag(Types[I], MemberOfFlag);\n    }\n  }\n\n  /// Generate the base pointers, section pointers, sizes, map types, and\n  /// mappers associated to a given capture (all included in \\a CombinedInfo).\n  void generateInfoForCapture(const CapturedStmt::Capture *Cap,\n                              llvm::Value *Arg, MapCombinedInfoTy &CombinedInfo,\n                              StructRangeInfoTy &PartialStruct) const {\n    assert(!Cap->capturesVariableArrayType() &&\n           \"Not expecting to generate map info for a variable array type!\");\n\n    // We need to know when we generating information for the first component\n    const ValueDecl *VD = Cap->capturesThis()\n                              ? nullptr\n                              : Cap->getCapturedVar()->getCanonicalDecl();\n\n    // If this declaration appears in a is_device_ptr clause we just have to\n    // pass the pointer by value. If it is a reference to a declaration, we just\n    // pass its value.\n    if (DevPointersMap.count(VD)) {\n      CombinedInfo.Exprs.push_back(VD);\n      CombinedInfo.BasePointers.emplace_back(Arg, VD);\n      CombinedInfo.Pointers.push_back(Arg);\n      CombinedInfo.Sizes.push_back(CGF.Builder.CreateIntCast(\n          CGF.getTypeSize(CGF.getContext().VoidPtrTy), CGF.Int64Ty,\n          /*isSigned=*/true));\n      CombinedInfo.Types.push_back(\n          (Cap->capturesVariable() ? OMP_MAP_TO : OMP_MAP_LITERAL) |\n          OMP_MAP_TARGET_PARAM);\n      CombinedInfo.Mappers.push_back(nullptr);\n      return;\n    }\n\n    using MapData =\n        std::tuple<OMPClauseMappableExprCommon::MappableExprComponentListRef,\n                   OpenMPMapClauseKind, ArrayRef<OpenMPMapModifierKind>, bool,\n                   const ValueDecl *, const Expr *>;\n    SmallVector<MapData, 4> DeclComponentLists;\n    assert(CurDir.is<const OMPExecutableDirective *>() &&\n           \"Expect a executable directive\");\n    const auto *CurExecDir = CurDir.get<const OMPExecutableDirective *>();\n    for (const auto *C : CurExecDir->getClausesOfKind<OMPMapClause>()) {\n      const auto *EI = C->getVarRefs().begin();\n      for (const auto L : C->decl_component_lists(VD)) {\n        const ValueDecl *VDecl, *Mapper;\n        // The Expression is not correct if the mapping is implicit\n        const Expr *E = (C->getMapLoc().isValid()) ? *EI : nullptr;\n        OMPClauseMappableExprCommon::MappableExprComponentListRef Components;\n        std::tie(VDecl, Components, Mapper) = L;\n        assert(VDecl == VD && \"We got information for the wrong declaration??\");\n        assert(!Components.empty() &&\n               \"Not expecting declaration with no component lists.\");\n        DeclComponentLists.emplace_back(Components, C->getMapType(),\n                                        C->getMapTypeModifiers(),\n                                        C->isImplicit(), Mapper, E);\n        ++EI;\n      }\n    }\n    llvm::stable_sort(DeclComponentLists, [](const MapData &LHS,\n                                             const MapData &RHS) {\n      ArrayRef<OpenMPMapModifierKind> MapModifiers = std::get<2>(LHS);\n      OpenMPMapClauseKind MapType = std::get<1>(RHS);\n      bool HasPresent = !MapModifiers.empty() &&\n                        llvm::any_of(MapModifiers, [](OpenMPMapModifierKind K) {\n                          return K == clang::OMPC_MAP_MODIFIER_present;\n                        });\n      bool HasAllocs = MapType == OMPC_MAP_alloc;\n      MapModifiers = std::get<2>(RHS);\n      MapType = std::get<1>(LHS);\n      bool HasPresentR =\n          !MapModifiers.empty() &&\n          llvm::any_of(MapModifiers, [](OpenMPMapModifierKind K) {\n            return K == clang::OMPC_MAP_MODIFIER_present;\n          });\n      bool HasAllocsR = MapType == OMPC_MAP_alloc;\n      return (HasPresent && !HasPresentR) || (HasAllocs && !HasAllocsR);\n    });\n\n    // Find overlapping elements (including the offset from the base element).\n    llvm::SmallDenseMap<\n        const MapData *,\n        llvm::SmallVector<\n            OMPClauseMappableExprCommon::MappableExprComponentListRef, 4>,\n        4>\n        OverlappedData;\n    size_t Count = 0;\n    for (const MapData &L : DeclComponentLists) {\n      OMPClauseMappableExprCommon::MappableExprComponentListRef Components;\n      OpenMPMapClauseKind MapType;\n      ArrayRef<OpenMPMapModifierKind> MapModifiers;\n      bool IsImplicit;\n      const ValueDecl *Mapper;\n      const Expr *VarRef;\n      std::tie(Components, MapType, MapModifiers, IsImplicit, Mapper, VarRef) =\n          L;\n      ++Count;\n      for (const MapData &L1 : makeArrayRef(DeclComponentLists).slice(Count)) {\n        OMPClauseMappableExprCommon::MappableExprComponentListRef Components1;\n        std::tie(Components1, MapType, MapModifiers, IsImplicit, Mapper,\n                 VarRef) = L1;\n        auto CI = Components.rbegin();\n        auto CE = Components.rend();\n        auto SI = Components1.rbegin();\n        auto SE = Components1.rend();\n        for (; CI != CE && SI != SE; ++CI, ++SI) {\n          if (CI->getAssociatedExpression()->getStmtClass() !=\n              SI->getAssociatedExpression()->getStmtClass())\n            break;\n          // Are we dealing with different variables/fields?\n          if (CI->getAssociatedDeclaration() != SI->getAssociatedDeclaration())\n            break;\n        }\n        // Found overlapping if, at least for one component, reached the head\n        // of the components list.\n        if (CI == CE || SI == SE) {\n          // Ignore it if it is the same component.\n          if (CI == CE && SI == SE)\n            continue;\n          const auto It = (SI == SE) ? CI : SI;\n          // If one component is a pointer and another one is a kind of\n          // dereference of this pointer (array subscript, section, dereference,\n          // etc.), it is not an overlapping.\n          if (!isa<MemberExpr>(It->getAssociatedExpression()) ||\n              std::prev(It)\n                  ->getAssociatedExpression()\n                  ->getType()\n                  .getNonReferenceType()\n                  ->isPointerType())\n            continue;\n          const MapData &BaseData = CI == CE ? L : L1;\n          OMPClauseMappableExprCommon::MappableExprComponentListRef SubData =\n              SI == SE ? Components : Components1;\n          auto &OverlappedElements = OverlappedData.FindAndConstruct(&BaseData);\n          OverlappedElements.getSecond().push_back(SubData);\n        }\n      }\n    }\n    // Sort the overlapped elements for each item.\n    llvm::SmallVector<const FieldDecl *, 4> Layout;\n    if (!OverlappedData.empty()) {\n      const Type *BaseType = VD->getType().getCanonicalType().getTypePtr();\n      const Type *OrigType = BaseType->getPointeeOrArrayElementType();\n      while (BaseType != OrigType) {\n        BaseType = OrigType->getCanonicalTypeInternal().getTypePtr();\n        OrigType = BaseType->getPointeeOrArrayElementType();\n      }\n\n      if (const auto *CRD = BaseType->getAsCXXRecordDecl())\n        getPlainLayout(CRD, Layout, /*AsBase=*/false);\n      else {\n        const auto *RD = BaseType->getAsRecordDecl();\n        Layout.append(RD->field_begin(), RD->field_end());\n      }\n    }\n    for (auto &Pair : OverlappedData) {\n      llvm::stable_sort(\n          Pair.getSecond(),\n          [&Layout](\n              OMPClauseMappableExprCommon::MappableExprComponentListRef First,\n              OMPClauseMappableExprCommon::MappableExprComponentListRef\n                  Second) {\n            auto CI = First.rbegin();\n            auto CE = First.rend();\n            auto SI = Second.rbegin();\n            auto SE = Second.rend();\n            for (; CI != CE && SI != SE; ++CI, ++SI) {\n              if (CI->getAssociatedExpression()->getStmtClass() !=\n                  SI->getAssociatedExpression()->getStmtClass())\n                break;\n              // Are we dealing with different variables/fields?\n              if (CI->getAssociatedDeclaration() !=\n                  SI->getAssociatedDeclaration())\n                break;\n            }\n\n            // Lists contain the same elements.\n            if (CI == CE && SI == SE)\n              return false;\n\n            // List with less elements is less than list with more elements.\n            if (CI == CE || SI == SE)\n              return CI == CE;\n\n            const auto *FD1 = cast<FieldDecl>(CI->getAssociatedDeclaration());\n            const auto *FD2 = cast<FieldDecl>(SI->getAssociatedDeclaration());\n            if (FD1->getParent() == FD2->getParent())\n              return FD1->getFieldIndex() < FD2->getFieldIndex();\n            const auto It =\n                llvm::find_if(Layout, [FD1, FD2](const FieldDecl *FD) {\n                  return FD == FD1 || FD == FD2;\n                });\n            return *It == FD1;\n          });\n    }\n\n    // Associated with a capture, because the mapping flags depend on it.\n    // Go through all of the elements with the overlapped elements.\n    bool IsFirstComponentList = true;\n    for (const auto &Pair : OverlappedData) {\n      const MapData &L = *Pair.getFirst();\n      OMPClauseMappableExprCommon::MappableExprComponentListRef Components;\n      OpenMPMapClauseKind MapType;\n      ArrayRef<OpenMPMapModifierKind> MapModifiers;\n      bool IsImplicit;\n      const ValueDecl *Mapper;\n      const Expr *VarRef;\n      std::tie(Components, MapType, MapModifiers, IsImplicit, Mapper, VarRef) =\n          L;\n      ArrayRef<OMPClauseMappableExprCommon::MappableExprComponentListRef>\n          OverlappedComponents = Pair.getSecond();\n      generateInfoForComponentList(\n          MapType, MapModifiers, llvm::None, Components, CombinedInfo,\n          PartialStruct, IsFirstComponentList, IsImplicit, Mapper,\n          /*ForDeviceAddr=*/false, VD, VarRef, OverlappedComponents);\n      IsFirstComponentList = false;\n    }\n    // Go through other elements without overlapped elements.\n    for (const MapData &L : DeclComponentLists) {\n      OMPClauseMappableExprCommon::MappableExprComponentListRef Components;\n      OpenMPMapClauseKind MapType;\n      ArrayRef<OpenMPMapModifierKind> MapModifiers;\n      bool IsImplicit;\n      const ValueDecl *Mapper;\n      const Expr *VarRef;\n      std::tie(Components, MapType, MapModifiers, IsImplicit, Mapper, VarRef) =\n          L;\n      auto It = OverlappedData.find(&L);\n      if (It == OverlappedData.end())\n        generateInfoForComponentList(MapType, MapModifiers, llvm::None,\n                                     Components, CombinedInfo, PartialStruct,\n                                     IsFirstComponentList, IsImplicit, Mapper,\n                                     /*ForDeviceAddr=*/false, VD, VarRef);\n      IsFirstComponentList = false;\n    }\n  }\n\n  /// Generate the default map information for a given capture \\a CI,\n  /// record field declaration \\a RI and captured value \\a CV.\n  void generateDefaultMapInfo(const CapturedStmt::Capture &CI,\n                              const FieldDecl &RI, llvm::Value *CV,\n                              MapCombinedInfoTy &CombinedInfo) const {\n    bool IsImplicit = true;\n    // Do the default mapping.\n    if (CI.capturesThis()) {\n      CombinedInfo.Exprs.push_back(nullptr);\n      CombinedInfo.BasePointers.push_back(CV);\n      CombinedInfo.Pointers.push_back(CV);\n      const auto *PtrTy = cast<PointerType>(RI.getType().getTypePtr());\n      CombinedInfo.Sizes.push_back(\n          CGF.Builder.CreateIntCast(CGF.getTypeSize(PtrTy->getPointeeType()),\n                                    CGF.Int64Ty, /*isSigned=*/true));\n      // Default map type.\n      CombinedInfo.Types.push_back(OMP_MAP_TO | OMP_MAP_FROM);\n    } else if (CI.capturesVariableByCopy()) {\n      const VarDecl *VD = CI.getCapturedVar();\n      CombinedInfo.Exprs.push_back(VD->getCanonicalDecl());\n      CombinedInfo.BasePointers.push_back(CV);\n      CombinedInfo.Pointers.push_back(CV);\n      if (!RI.getType()->isAnyPointerType()) {\n        // We have to signal to the runtime captures passed by value that are\n        // not pointers.\n        CombinedInfo.Types.push_back(OMP_MAP_LITERAL);\n        CombinedInfo.Sizes.push_back(CGF.Builder.CreateIntCast(\n            CGF.getTypeSize(RI.getType()), CGF.Int64Ty, /*isSigned=*/true));\n      } else {\n        // Pointers are implicitly mapped with a zero size and no flags\n        // (other than first map that is added for all implicit maps).\n        CombinedInfo.Types.push_back(OMP_MAP_NONE);\n        CombinedInfo.Sizes.push_back(llvm::Constant::getNullValue(CGF.Int64Ty));\n      }\n      auto I = FirstPrivateDecls.find(VD);\n      if (I != FirstPrivateDecls.end())\n        IsImplicit = I->getSecond();\n    } else {\n      assert(CI.capturesVariable() && \"Expected captured reference.\");\n      const auto *PtrTy = cast<ReferenceType>(RI.getType().getTypePtr());\n      QualType ElementType = PtrTy->getPointeeType();\n      CombinedInfo.Sizes.push_back(CGF.Builder.CreateIntCast(\n          CGF.getTypeSize(ElementType), CGF.Int64Ty, /*isSigned=*/true));\n      // The default map type for a scalar/complex type is 'to' because by\n      // default the value doesn't have to be retrieved. For an aggregate\n      // type, the default is 'tofrom'.\n      CombinedInfo.Types.push_back(getMapModifiersForPrivateClauses(CI));\n      const VarDecl *VD = CI.getCapturedVar();\n      auto I = FirstPrivateDecls.find(VD);\n      if (I != FirstPrivateDecls.end() &&\n          VD->getType().isConstant(CGF.getContext())) {\n        llvm::Constant *Addr =\n            CGF.CGM.getOpenMPRuntime().registerTargetFirstprivateCopy(CGF, VD);\n        // Copy the value of the original variable to the new global copy.\n        CGF.Builder.CreateMemCpy(\n            CGF.MakeNaturalAlignAddrLValue(Addr, ElementType).getAddress(CGF),\n            Address(CV, CGF.getContext().getTypeAlignInChars(ElementType)),\n            CombinedInfo.Sizes.back(), /*IsVolatile=*/false);\n        // Use new global variable as the base pointers.\n        CombinedInfo.Exprs.push_back(VD->getCanonicalDecl());\n        CombinedInfo.BasePointers.push_back(Addr);\n        CombinedInfo.Pointers.push_back(Addr);\n      } else {\n        CombinedInfo.Exprs.push_back(VD->getCanonicalDecl());\n        CombinedInfo.BasePointers.push_back(CV);\n        if (I != FirstPrivateDecls.end() && ElementType->isAnyPointerType()) {\n          Address PtrAddr = CGF.EmitLoadOfReference(CGF.MakeAddrLValue(\n              CV, ElementType, CGF.getContext().getDeclAlign(VD),\n              AlignmentSource::Decl));\n          CombinedInfo.Pointers.push_back(PtrAddr.getPointer());\n        } else {\n          CombinedInfo.Pointers.push_back(CV);\n        }\n      }\n      if (I != FirstPrivateDecls.end())\n        IsImplicit = I->getSecond();\n    }\n    // Every default map produces a single argument which is a target parameter.\n    CombinedInfo.Types.back() |= OMP_MAP_TARGET_PARAM;\n\n    // Add flag stating this is an implicit map.\n    if (IsImplicit)\n      CombinedInfo.Types.back() |= OMP_MAP_IMPLICIT;\n\n    // No user-defined mapper for default mapping.\n    CombinedInfo.Mappers.push_back(nullptr);\n  }\n};\n} // anonymous namespace\n\nstatic void emitNonContiguousDescriptor(\n    CodeGenFunction &CGF, MappableExprsHandler::MapCombinedInfoTy &CombinedInfo,\n    CGOpenMPRuntime::TargetDataInfo &Info) {\n  CodeGenModule &CGM = CGF.CGM;\n  MappableExprsHandler::MapCombinedInfoTy::StructNonContiguousInfo\n      &NonContigInfo = CombinedInfo.NonContigInfo;\n\n  // Build an array of struct descriptor_dim and then assign it to\n  // offload_args.\n  //\n  // struct descriptor_dim {\n  //  uint64_t offset;\n  //  uint64_t count;\n  //  uint64_t stride\n  // };\n  ASTContext &C = CGF.getContext();\n  QualType Int64Ty = C.getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/0);\n  RecordDecl *RD;\n  RD = C.buildImplicitRecord(\"descriptor_dim\");\n  RD->startDefinition();\n  addFieldToRecordDecl(C, RD, Int64Ty);\n  addFieldToRecordDecl(C, RD, Int64Ty);\n  addFieldToRecordDecl(C, RD, Int64Ty);\n  RD->completeDefinition();\n  QualType DimTy = C.getRecordType(RD);\n\n  enum { OffsetFD = 0, CountFD, StrideFD };\n  // We need two index variable here since the size of \"Dims\" is the same as the\n  // size of Components, however, the size of offset, count, and stride is equal\n  // to the size of base declaration that is non-contiguous.\n  for (unsigned I = 0, L = 0, E = NonContigInfo.Dims.size(); I < E; ++I) {\n    // Skip emitting ir if dimension size is 1 since it cannot be\n    // non-contiguous.\n    if (NonContigInfo.Dims[I] == 1)\n      continue;\n    llvm::APInt Size(/*numBits=*/32, NonContigInfo.Dims[I]);\n    QualType ArrayTy =\n        C.getConstantArrayType(DimTy, Size, nullptr, ArrayType::Normal, 0);\n    Address DimsAddr = CGF.CreateMemTemp(ArrayTy, \"dims\");\n    for (unsigned II = 0, EE = NonContigInfo.Dims[I]; II < EE; ++II) {\n      unsigned RevIdx = EE - II - 1;\n      LValue DimsLVal = CGF.MakeAddrLValue(\n          CGF.Builder.CreateConstArrayGEP(DimsAddr, II), DimTy);\n      // Offset\n      LValue OffsetLVal = CGF.EmitLValueForField(\n          DimsLVal, *std::next(RD->field_begin(), OffsetFD));\n      CGF.EmitStoreOfScalar(NonContigInfo.Offsets[L][RevIdx], OffsetLVal);\n      // Count\n      LValue CountLVal = CGF.EmitLValueForField(\n          DimsLVal, *std::next(RD->field_begin(), CountFD));\n      CGF.EmitStoreOfScalar(NonContigInfo.Counts[L][RevIdx], CountLVal);\n      // Stride\n      LValue StrideLVal = CGF.EmitLValueForField(\n          DimsLVal, *std::next(RD->field_begin(), StrideFD));\n      CGF.EmitStoreOfScalar(NonContigInfo.Strides[L][RevIdx], StrideLVal);\n    }\n    // args[I] = &dims\n    Address DAddr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n        DimsAddr, CGM.Int8PtrTy);\n    llvm::Value *P = CGF.Builder.CreateConstInBoundsGEP2_32(\n        llvm::ArrayType::get(CGM.VoidPtrTy, Info.NumberOfPtrs),\n        Info.PointersArray, 0, I);\n    Address PAddr(P, CGF.getPointerAlign());\n    CGF.Builder.CreateStore(DAddr.getPointer(), PAddr);\n    ++L;\n  }\n}\n\n/// Emit a string constant containing the names of the values mapped to the\n/// offloading runtime library.\nllvm::Constant *\nemitMappingInformation(CodeGenFunction &CGF, llvm::OpenMPIRBuilder &OMPBuilder,\n                       MappableExprsHandler::MappingExprInfo &MapExprs) {\n  llvm::Constant *SrcLocStr;\n  if (!MapExprs.getMapDecl()) {\n    SrcLocStr = OMPBuilder.getOrCreateDefaultSrcLocStr();\n  } else {\n    std::string ExprName = \"\";\n    if (MapExprs.getMapExpr()) {\n      PrintingPolicy P(CGF.getContext().getLangOpts());\n      llvm::raw_string_ostream OS(ExprName);\n      MapExprs.getMapExpr()->printPretty(OS, nullptr, P);\n      OS.flush();\n    } else {\n      ExprName = MapExprs.getMapDecl()->getNameAsString();\n    }\n\n    SourceLocation Loc = MapExprs.getMapDecl()->getLocation();\n    PresumedLoc PLoc = CGF.getContext().getSourceManager().getPresumedLoc(Loc);\n    const char *FileName = PLoc.getFilename();\n    unsigned Line = PLoc.getLine();\n    unsigned Column = PLoc.getColumn();\n    SrcLocStr = OMPBuilder.getOrCreateSrcLocStr(FileName, ExprName.c_str(),\n                                                Line, Column);\n  }\n\n  return SrcLocStr;\n}\n\n/// Emit the arrays used to pass the captures and map information to the\n/// offloading runtime library. If there is no map or capture information,\n/// return nullptr by reference.\nstatic void emitOffloadingArrays(\n    CodeGenFunction &CGF, MappableExprsHandler::MapCombinedInfoTy &CombinedInfo,\n    CGOpenMPRuntime::TargetDataInfo &Info, llvm::OpenMPIRBuilder &OMPBuilder,\n    bool IsNonContiguous = false) {\n  CodeGenModule &CGM = CGF.CGM;\n  ASTContext &Ctx = CGF.getContext();\n\n  // Reset the array information.\n  Info.clearArrayInfo();\n  Info.NumberOfPtrs = CombinedInfo.BasePointers.size();\n\n  if (Info.NumberOfPtrs) {\n    // Detect if we have any capture size requiring runtime evaluation of the\n    // size so that a constant array could be eventually used.\n    bool hasRuntimeEvaluationCaptureSize = false;\n    for (llvm::Value *S : CombinedInfo.Sizes)\n      if (!isa<llvm::Constant>(S)) {\n        hasRuntimeEvaluationCaptureSize = true;\n        break;\n      }\n\n    llvm::APInt PointerNumAP(32, Info.NumberOfPtrs, /*isSigned=*/true);\n    QualType PointerArrayType = Ctx.getConstantArrayType(\n        Ctx.VoidPtrTy, PointerNumAP, nullptr, ArrayType::Normal,\n        /*IndexTypeQuals=*/0);\n\n    Info.BasePointersArray =\n        CGF.CreateMemTemp(PointerArrayType, \".offload_baseptrs\").getPointer();\n    Info.PointersArray =\n        CGF.CreateMemTemp(PointerArrayType, \".offload_ptrs\").getPointer();\n    Address MappersArray =\n        CGF.CreateMemTemp(PointerArrayType, \".offload_mappers\");\n    Info.MappersArray = MappersArray.getPointer();\n\n    // If we don't have any VLA types or other types that require runtime\n    // evaluation, we can use a constant array for the map sizes, otherwise we\n    // need to fill up the arrays as we do for the pointers.\n    QualType Int64Ty =\n        Ctx.getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/1);\n    if (hasRuntimeEvaluationCaptureSize) {\n      QualType SizeArrayType = Ctx.getConstantArrayType(\n          Int64Ty, PointerNumAP, nullptr, ArrayType::Normal,\n          /*IndexTypeQuals=*/0);\n      Info.SizesArray =\n          CGF.CreateMemTemp(SizeArrayType, \".offload_sizes\").getPointer();\n    } else {\n      // We expect all the sizes to be constant, so we collect them to create\n      // a constant array.\n      SmallVector<llvm::Constant *, 16> ConstSizes;\n      for (unsigned I = 0, E = CombinedInfo.Sizes.size(); I < E; ++I) {\n        if (IsNonContiguous &&\n            (CombinedInfo.Types[I] & MappableExprsHandler::OMP_MAP_NON_CONTIG)) {\n          ConstSizes.push_back(llvm::ConstantInt::get(\n              CGF.Int64Ty, CombinedInfo.NonContigInfo.Dims[I]));\n        } else {\n          ConstSizes.push_back(cast<llvm::Constant>(CombinedInfo.Sizes[I]));\n        }\n      }\n\n      auto *SizesArrayInit = llvm::ConstantArray::get(\n          llvm::ArrayType::get(CGM.Int64Ty, ConstSizes.size()), ConstSizes);\n      std::string Name = CGM.getOpenMPRuntime().getName({\"offload_sizes\"});\n      auto *SizesArrayGbl = new llvm::GlobalVariable(\n          CGM.getModule(), SizesArrayInit->getType(),\n          /*isConstant=*/true, llvm::GlobalValue::PrivateLinkage,\n          SizesArrayInit, Name);\n      SizesArrayGbl->setUnnamedAddr(llvm::GlobalValue::UnnamedAddr::Global);\n      Info.SizesArray = SizesArrayGbl;\n    }\n\n    // The map types are always constant so we don't need to generate code to\n    // fill arrays. Instead, we create an array constant.\n    SmallVector<uint64_t, 4> Mapping(CombinedInfo.Types.size(), 0);\n    llvm::copy(CombinedInfo.Types, Mapping.begin());\n    llvm::Constant *MapTypesArrayInit =\n        llvm::ConstantDataArray::get(CGF.Builder.getContext(), Mapping);\n    std::string MaptypesName =\n        CGM.getOpenMPRuntime().getName({\"offload_maptypes\"});\n    auto *MapTypesArrayGbl = new llvm::GlobalVariable(\n        CGM.getModule(), MapTypesArrayInit->getType(),\n        /*isConstant=*/true, llvm::GlobalValue::PrivateLinkage,\n        MapTypesArrayInit, MaptypesName);\n    MapTypesArrayGbl->setUnnamedAddr(llvm::GlobalValue::UnnamedAddr::Global);\n    Info.MapTypesArray = MapTypesArrayGbl;\n\n    // The information types are only built if there is debug information\n    // requested.\n    if (CGM.getCodeGenOpts().getDebugInfo() == codegenoptions::NoDebugInfo) {\n      Info.MapNamesArray = llvm::Constant::getNullValue(\n          llvm::Type::getInt8Ty(CGF.Builder.getContext())->getPointerTo());\n    } else {\n      auto fillInfoMap = [&](MappableExprsHandler::MappingExprInfo &MapExpr) {\n        return emitMappingInformation(CGF, OMPBuilder, MapExpr);\n      };\n      SmallVector<llvm::Constant *, 4> InfoMap(CombinedInfo.Exprs.size());\n      llvm::transform(CombinedInfo.Exprs, InfoMap.begin(), fillInfoMap);\n\n      llvm::Constant *MapNamesArrayInit = llvm::ConstantArray::get(\n          llvm::ArrayType::get(\n              llvm::Type::getInt8Ty(CGF.Builder.getContext())->getPointerTo(),\n              CombinedInfo.Exprs.size()),\n          InfoMap);\n      auto *MapNamesArrayGbl = new llvm::GlobalVariable(\n          CGM.getModule(), MapNamesArrayInit->getType(),\n          /*isConstant=*/true, llvm::GlobalValue::PrivateLinkage,\n          MapNamesArrayInit,\n          CGM.getOpenMPRuntime().getName({\"offload_mapnames\"}));\n      Info.MapNamesArray = MapNamesArrayGbl;\n    }\n\n    // If there's a present map type modifier, it must not be applied to the end\n    // of a region, so generate a separate map type array in that case.\n    if (Info.separateBeginEndCalls()) {\n      bool EndMapTypesDiffer = false;\n      for (uint64_t &Type : Mapping) {\n        if (Type & MappableExprsHandler::OMP_MAP_PRESENT) {\n          Type &= ~MappableExprsHandler::OMP_MAP_PRESENT;\n          EndMapTypesDiffer = true;\n        }\n      }\n      if (EndMapTypesDiffer) {\n        MapTypesArrayInit =\n            llvm::ConstantDataArray::get(CGF.Builder.getContext(), Mapping);\n        MaptypesName = CGM.getOpenMPRuntime().getName({\"offload_maptypes\"});\n        MapTypesArrayGbl = new llvm::GlobalVariable(\n            CGM.getModule(), MapTypesArrayInit->getType(),\n            /*isConstant=*/true, llvm::GlobalValue::PrivateLinkage,\n            MapTypesArrayInit, MaptypesName);\n        MapTypesArrayGbl->setUnnamedAddr(\n            llvm::GlobalValue::UnnamedAddr::Global);\n        Info.MapTypesArrayEnd = MapTypesArrayGbl;\n      }\n    }\n\n    for (unsigned I = 0; I < Info.NumberOfPtrs; ++I) {\n      llvm::Value *BPVal = *CombinedInfo.BasePointers[I];\n      llvm::Value *BP = CGF.Builder.CreateConstInBoundsGEP2_32(\n          llvm::ArrayType::get(CGM.VoidPtrTy, Info.NumberOfPtrs),\n          Info.BasePointersArray, 0, I);\n      BP = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          BP, BPVal->getType()->getPointerTo(/*AddrSpace=*/0));\n      Address BPAddr(BP, Ctx.getTypeAlignInChars(Ctx.VoidPtrTy));\n      CGF.Builder.CreateStore(BPVal, BPAddr);\n\n      if (Info.requiresDevicePointerInfo())\n        if (const ValueDecl *DevVD =\n                CombinedInfo.BasePointers[I].getDevicePtrDecl())\n          Info.CaptureDeviceAddrMap.try_emplace(DevVD, BPAddr);\n\n      llvm::Value *PVal = CombinedInfo.Pointers[I];\n      llvm::Value *P = CGF.Builder.CreateConstInBoundsGEP2_32(\n          llvm::ArrayType::get(CGM.VoidPtrTy, Info.NumberOfPtrs),\n          Info.PointersArray, 0, I);\n      P = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          P, PVal->getType()->getPointerTo(/*AddrSpace=*/0));\n      Address PAddr(P, Ctx.getTypeAlignInChars(Ctx.VoidPtrTy));\n      CGF.Builder.CreateStore(PVal, PAddr);\n\n      if (hasRuntimeEvaluationCaptureSize) {\n        llvm::Value *S = CGF.Builder.CreateConstInBoundsGEP2_32(\n            llvm::ArrayType::get(CGM.Int64Ty, Info.NumberOfPtrs),\n            Info.SizesArray,\n            /*Idx0=*/0,\n            /*Idx1=*/I);\n        Address SAddr(S, Ctx.getTypeAlignInChars(Int64Ty));\n        CGF.Builder.CreateStore(CGF.Builder.CreateIntCast(CombinedInfo.Sizes[I],\n                                                          CGM.Int64Ty,\n                                                          /*isSigned=*/true),\n                                SAddr);\n      }\n\n      // Fill up the mapper array.\n      llvm::Value *MFunc = llvm::ConstantPointerNull::get(CGM.VoidPtrTy);\n      if (CombinedInfo.Mappers[I]) {\n        MFunc = CGM.getOpenMPRuntime().getOrCreateUserDefinedMapperFunc(\n            cast<OMPDeclareMapperDecl>(CombinedInfo.Mappers[I]));\n        MFunc = CGF.Builder.CreatePointerCast(MFunc, CGM.VoidPtrTy);\n        Info.HasMapper = true;\n      }\n      Address MAddr = CGF.Builder.CreateConstArrayGEP(MappersArray, I);\n      CGF.Builder.CreateStore(MFunc, MAddr);\n    }\n  }\n\n  if (!IsNonContiguous || CombinedInfo.NonContigInfo.Offsets.empty() ||\n      Info.NumberOfPtrs == 0)\n    return;\n\n  emitNonContiguousDescriptor(CGF, CombinedInfo, Info);\n}\n\nnamespace {\n/// Additional arguments for emitOffloadingArraysArgument function.\nstruct ArgumentsOptions {\n  bool ForEndCall = false;\n  ArgumentsOptions() = default;\n  ArgumentsOptions(bool ForEndCall) : ForEndCall(ForEndCall) {}\n};\n} // namespace\n\n/// Emit the arguments to be passed to the runtime library based on the\n/// arrays of base pointers, pointers, sizes, map types, and mappers.  If\n/// ForEndCall, emit map types to be passed for the end of the region instead of\n/// the beginning.\nstatic void emitOffloadingArraysArgument(\n    CodeGenFunction &CGF, llvm::Value *&BasePointersArrayArg,\n    llvm::Value *&PointersArrayArg, llvm::Value *&SizesArrayArg,\n    llvm::Value *&MapTypesArrayArg, llvm::Value *&MapNamesArrayArg,\n    llvm::Value *&MappersArrayArg, CGOpenMPRuntime::TargetDataInfo &Info,\n    const ArgumentsOptions &Options = ArgumentsOptions()) {\n  assert((!Options.ForEndCall || Info.separateBeginEndCalls()) &&\n         \"expected region end call to runtime only when end call is separate\");\n  CodeGenModule &CGM = CGF.CGM;\n  if (Info.NumberOfPtrs) {\n    BasePointersArrayArg = CGF.Builder.CreateConstInBoundsGEP2_32(\n        llvm::ArrayType::get(CGM.VoidPtrTy, Info.NumberOfPtrs),\n        Info.BasePointersArray,\n        /*Idx0=*/0, /*Idx1=*/0);\n    PointersArrayArg = CGF.Builder.CreateConstInBoundsGEP2_32(\n        llvm::ArrayType::get(CGM.VoidPtrTy, Info.NumberOfPtrs),\n        Info.PointersArray,\n        /*Idx0=*/0,\n        /*Idx1=*/0);\n    SizesArrayArg = CGF.Builder.CreateConstInBoundsGEP2_32(\n        llvm::ArrayType::get(CGM.Int64Ty, Info.NumberOfPtrs), Info.SizesArray,\n        /*Idx0=*/0, /*Idx1=*/0);\n    MapTypesArrayArg = CGF.Builder.CreateConstInBoundsGEP2_32(\n        llvm::ArrayType::get(CGM.Int64Ty, Info.NumberOfPtrs),\n        Options.ForEndCall && Info.MapTypesArrayEnd ? Info.MapTypesArrayEnd\n                                                    : Info.MapTypesArray,\n        /*Idx0=*/0,\n        /*Idx1=*/0);\n\n    // Only emit the mapper information arrays if debug information is\n    // requested.\n    if (CGF.CGM.getCodeGenOpts().getDebugInfo() == codegenoptions::NoDebugInfo)\n      MapNamesArrayArg = llvm::ConstantPointerNull::get(CGM.VoidPtrPtrTy);\n    else\n      MapNamesArrayArg = CGF.Builder.CreateConstInBoundsGEP2_32(\n          llvm::ArrayType::get(CGM.VoidPtrTy, Info.NumberOfPtrs),\n          Info.MapNamesArray,\n          /*Idx0=*/0,\n          /*Idx1=*/0);\n    // If there is no user-defined mapper, set the mapper array to nullptr to\n    // avoid an unnecessary data privatization\n    if (!Info.HasMapper)\n      MappersArrayArg = llvm::ConstantPointerNull::get(CGM.VoidPtrPtrTy);\n    else\n      MappersArrayArg =\n          CGF.Builder.CreatePointerCast(Info.MappersArray, CGM.VoidPtrPtrTy);\n  } else {\n    BasePointersArrayArg = llvm::ConstantPointerNull::get(CGM.VoidPtrPtrTy);\n    PointersArrayArg = llvm::ConstantPointerNull::get(CGM.VoidPtrPtrTy);\n    SizesArrayArg = llvm::ConstantPointerNull::get(CGM.Int64Ty->getPointerTo());\n    MapTypesArrayArg =\n        llvm::ConstantPointerNull::get(CGM.Int64Ty->getPointerTo());\n    MapNamesArrayArg = llvm::ConstantPointerNull::get(CGM.VoidPtrPtrTy);\n    MappersArrayArg = llvm::ConstantPointerNull::get(CGM.VoidPtrPtrTy);\n  }\n}\n\n/// Check for inner distribute directive.\nstatic const OMPExecutableDirective *\ngetNestedDistributeDirective(ASTContext &Ctx, const OMPExecutableDirective &D) {\n  const auto *CS = D.getInnermostCapturedStmt();\n  const auto *Body =\n      CS->getCapturedStmt()->IgnoreContainers(/*IgnoreCaptured=*/true);\n  const Stmt *ChildStmt =\n      CGOpenMPSIMDRuntime::getSingleCompoundChild(Ctx, Body);\n\n  if (const auto *NestedDir =\n          dyn_cast_or_null<OMPExecutableDirective>(ChildStmt)) {\n    OpenMPDirectiveKind DKind = NestedDir->getDirectiveKind();\n    switch (D.getDirectiveKind()) {\n    case OMPD_target:\n      if (isOpenMPDistributeDirective(DKind))\n        return NestedDir;\n      if (DKind == OMPD_teams) {\n        Body = NestedDir->getInnermostCapturedStmt()->IgnoreContainers(\n            /*IgnoreCaptured=*/true);\n        if (!Body)\n          return nullptr;\n        ChildStmt = CGOpenMPSIMDRuntime::getSingleCompoundChild(Ctx, Body);\n        if (const auto *NND =\n                dyn_cast_or_null<OMPExecutableDirective>(ChildStmt)) {\n          DKind = NND->getDirectiveKind();\n          if (isOpenMPDistributeDirective(DKind))\n            return NND;\n        }\n      }\n      return nullptr;\n    case OMPD_target_teams:\n      if (isOpenMPDistributeDirective(DKind))\n        return NestedDir;\n      return nullptr;\n    case OMPD_target_parallel:\n    case OMPD_target_simd:\n    case OMPD_target_parallel_for:\n    case OMPD_target_parallel_for_simd:\n      return nullptr;\n    case OMPD_target_teams_distribute:\n    case OMPD_target_teams_distribute_simd:\n    case OMPD_target_teams_distribute_parallel_for:\n    case OMPD_target_teams_distribute_parallel_for_simd:\n    case OMPD_parallel:\n    case OMPD_for:\n    case OMPD_parallel_for:\n    case OMPD_parallel_master:\n    case OMPD_parallel_sections:\n    case OMPD_for_simd:\n    case OMPD_parallel_for_simd:\n    case OMPD_cancel:\n    case OMPD_cancellation_point:\n    case OMPD_ordered:\n    case OMPD_threadprivate:\n    case OMPD_allocate:\n    case OMPD_task:\n    case OMPD_simd:\n    case OMPD_tile:\n    case OMPD_sections:\n    case OMPD_section:\n    case OMPD_single:\n    case OMPD_master:\n    case OMPD_critical:\n    case OMPD_taskyield:\n    case OMPD_barrier:\n    case OMPD_taskwait:\n    case OMPD_taskgroup:\n    case OMPD_atomic:\n    case OMPD_flush:\n    case OMPD_depobj:\n    case OMPD_scan:\n    case OMPD_teams:\n    case OMPD_target_data:\n    case OMPD_target_exit_data:\n    case OMPD_target_enter_data:\n    case OMPD_distribute:\n    case OMPD_distribute_simd:\n    case OMPD_distribute_parallel_for:\n    case OMPD_distribute_parallel_for_simd:\n    case OMPD_teams_distribute:\n    case OMPD_teams_distribute_simd:\n    case OMPD_teams_distribute_parallel_for:\n    case OMPD_teams_distribute_parallel_for_simd:\n    case OMPD_target_update:\n    case OMPD_declare_simd:\n    case OMPD_declare_variant:\n    case OMPD_begin_declare_variant:\n    case OMPD_end_declare_variant:\n    case OMPD_declare_target:\n    case OMPD_end_declare_target:\n    case OMPD_declare_reduction:\n    case OMPD_declare_mapper:\n    case OMPD_taskloop:\n    case OMPD_taskloop_simd:\n    case OMPD_master_taskloop:\n    case OMPD_master_taskloop_simd:\n    case OMPD_parallel_master_taskloop:\n    case OMPD_parallel_master_taskloop_simd:\n    case OMPD_requires:\n    case OMPD_unknown:\n    default:\n      llvm_unreachable(\"Unexpected directive.\");\n    }\n  }\n\n  return nullptr;\n}\n\n/// Emit the user-defined mapper function. The code generation follows the\n/// pattern in the example below.\n/// \\code\n/// void .omp_mapper.<type_name>.<mapper_id>.(void *rt_mapper_handle,\n///                                           void *base, void *begin,\n///                                           int64_t size, int64_t type,\n///                                           void *name = nullptr) {\n///   // Allocate space for an array section first or add a base/begin for\n///   // pointer dereference.\n///   if ((size > 1 || (base != begin && maptype.IsPtrAndObj)) &&\n///       !maptype.IsDelete)\n///     __tgt_push_mapper_component(rt_mapper_handle, base, begin,\n///                                 size*sizeof(Ty), clearToFromMember(type));\n///   // Map members.\n///   for (unsigned i = 0; i < size; i++) {\n///     // For each component specified by this mapper:\n///     for (auto c : begin[i]->all_components) {\n///       if (c.hasMapper())\n///         (*c.Mapper())(rt_mapper_handle, c.arg_base, c.arg_begin, c.arg_size,\n///                       c.arg_type, c.arg_name);\n///       else\n///         __tgt_push_mapper_component(rt_mapper_handle, c.arg_base,\n///                                     c.arg_begin, c.arg_size, c.arg_type,\n///                                     c.arg_name);\n///     }\n///   }\n///   // Delete the array section.\n///   if (size > 1 && maptype.IsDelete)\n///     __tgt_push_mapper_component(rt_mapper_handle, base, begin,\n///                                 size*sizeof(Ty), clearToFromMember(type));\n/// }\n/// \\endcode\nvoid CGOpenMPRuntime::emitUserDefinedMapper(const OMPDeclareMapperDecl *D,\n                                            CodeGenFunction *CGF) {\n  if (UDMMap.count(D) > 0)\n    return;\n  ASTContext &C = CGM.getContext();\n  QualType Ty = D->getType();\n  QualType PtrTy = C.getPointerType(Ty).withRestrict();\n  QualType Int64Ty = C.getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/true);\n  auto *MapperVarDecl =\n      cast<VarDecl>(cast<DeclRefExpr>(D->getMapperVarRef())->getDecl());\n  SourceLocation Loc = D->getLocation();\n  CharUnits ElementSize = C.getTypeSizeInChars(Ty);\n\n  // Prepare mapper function arguments and attributes.\n  ImplicitParamDecl HandleArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                              C.VoidPtrTy, ImplicitParamDecl::Other);\n  ImplicitParamDecl BaseArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                            ImplicitParamDecl::Other);\n  ImplicitParamDecl BeginArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr,\n                             C.VoidPtrTy, ImplicitParamDecl::Other);\n  ImplicitParamDecl SizeArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, Int64Ty,\n                            ImplicitParamDecl::Other);\n  ImplicitParamDecl TypeArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, Int64Ty,\n                            ImplicitParamDecl::Other);\n  ImplicitParamDecl NameArg(C, /*DC=*/nullptr, Loc, /*Id=*/nullptr, C.VoidPtrTy,\n                            ImplicitParamDecl::Other);\n  FunctionArgList Args;\n  Args.push_back(&HandleArg);\n  Args.push_back(&BaseArg);\n  Args.push_back(&BeginArg);\n  Args.push_back(&SizeArg);\n  Args.push_back(&TypeArg);\n  Args.push_back(&NameArg);\n  const CGFunctionInfo &FnInfo =\n      CGM.getTypes().arrangeBuiltinFunctionDeclaration(C.VoidTy, Args);\n  llvm::FunctionType *FnTy = CGM.getTypes().GetFunctionType(FnInfo);\n  SmallString<64> TyStr;\n  llvm::raw_svector_ostream Out(TyStr);\n  CGM.getCXXABI().getMangleContext().mangleTypeName(Ty, Out);\n  std::string Name = getName({\"omp_mapper\", TyStr, D->getName()});\n  auto *Fn = llvm::Function::Create(FnTy, llvm::GlobalValue::InternalLinkage,\n                                    Name, &CGM.getModule());\n  CGM.SetInternalFunctionAttributes(GlobalDecl(), Fn, FnInfo);\n  Fn->removeFnAttr(llvm::Attribute::OptimizeNone);\n  // Start the mapper function code generation.\n  CodeGenFunction MapperCGF(CGM);\n  MapperCGF.StartFunction(GlobalDecl(), C.VoidTy, Fn, FnInfo, Args, Loc, Loc);\n  // Compute the starting and end addresses of array elements.\n  llvm::Value *Size = MapperCGF.EmitLoadOfScalar(\n      MapperCGF.GetAddrOfLocalVar(&SizeArg), /*Volatile=*/false,\n      C.getPointerType(Int64Ty), Loc);\n  // Prepare common arguments for array initiation and deletion.\n  llvm::Value *Handle = MapperCGF.EmitLoadOfScalar(\n      MapperCGF.GetAddrOfLocalVar(&HandleArg),\n      /*Volatile=*/false, C.getPointerType(C.VoidPtrTy), Loc);\n  llvm::Value *BaseIn = MapperCGF.EmitLoadOfScalar(\n      MapperCGF.GetAddrOfLocalVar(&BaseArg),\n      /*Volatile=*/false, C.getPointerType(C.VoidPtrTy), Loc);\n  llvm::Value *BeginIn = MapperCGF.EmitLoadOfScalar(\n      MapperCGF.GetAddrOfLocalVar(&BeginArg),\n      /*Volatile=*/false, C.getPointerType(C.VoidPtrTy), Loc);\n  // Convert the size in bytes into the number of array elements.\n  Size = MapperCGF.Builder.CreateExactUDiv(\n      Size, MapperCGF.Builder.getInt64(ElementSize.getQuantity()));\n  llvm::Value *PtrBegin = MapperCGF.Builder.CreateBitCast(\n      BeginIn, CGM.getTypes().ConvertTypeForMem(PtrTy));\n  llvm::Value *PtrEnd = MapperCGF.Builder.CreateGEP(PtrBegin, Size);\n  llvm::Value *MapType = MapperCGF.EmitLoadOfScalar(\n      MapperCGF.GetAddrOfLocalVar(&TypeArg), /*Volatile=*/false,\n      C.getPointerType(Int64Ty), Loc);\n\n  // Emit array initiation if this is an array section and \\p MapType indicates\n  // that memory allocation is required.\n  llvm::BasicBlock *HeadBB = MapperCGF.createBasicBlock(\"omp.arraymap.head\");\n  emitUDMapperArrayInitOrDel(MapperCGF, Handle, BaseIn, BeginIn, Size, MapType,\n                             ElementSize, HeadBB, /*IsInit=*/true);\n\n  // Emit a for loop to iterate through SizeArg of elements and map all of them.\n\n  // Emit the loop header block.\n  MapperCGF.EmitBlock(HeadBB);\n  llvm::BasicBlock *BodyBB = MapperCGF.createBasicBlock(\"omp.arraymap.body\");\n  llvm::BasicBlock *DoneBB = MapperCGF.createBasicBlock(\"omp.done\");\n  // Evaluate whether the initial condition is satisfied.\n  llvm::Value *IsEmpty =\n      MapperCGF.Builder.CreateICmpEQ(PtrBegin, PtrEnd, \"omp.arraymap.isempty\");\n  MapperCGF.Builder.CreateCondBr(IsEmpty, DoneBB, BodyBB);\n  llvm::BasicBlock *EntryBB = MapperCGF.Builder.GetInsertBlock();\n\n  // Emit the loop body block.\n  MapperCGF.EmitBlock(BodyBB);\n  llvm::BasicBlock *LastBB = BodyBB;\n  llvm::PHINode *PtrPHI = MapperCGF.Builder.CreatePHI(\n      PtrBegin->getType(), 2, \"omp.arraymap.ptrcurrent\");\n  PtrPHI->addIncoming(PtrBegin, EntryBB);\n  Address PtrCurrent =\n      Address(PtrPHI, MapperCGF.GetAddrOfLocalVar(&BeginArg)\n                          .getAlignment()\n                          .alignmentOfArrayElement(ElementSize));\n  // Privatize the declared variable of mapper to be the current array element.\n  CodeGenFunction::OMPPrivateScope Scope(MapperCGF);\n  Scope.addPrivate(MapperVarDecl, [PtrCurrent]() { return PtrCurrent; });\n  (void)Scope.Privatize();\n\n  // Get map clause information. Fill up the arrays with all mapped variables.\n  MappableExprsHandler::MapCombinedInfoTy Info;\n  MappableExprsHandler MEHandler(*D, MapperCGF);\n  MEHandler.generateAllInfoForMapper(Info);\n\n  // Call the runtime API __tgt_mapper_num_components to get the number of\n  // pre-existing components.\n  llvm::Value *OffloadingArgs[] = {Handle};\n  llvm::Value *PreviousSize = MapperCGF.EmitRuntimeCall(\n      OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                            OMPRTL___tgt_mapper_num_components),\n      OffloadingArgs);\n  llvm::Value *ShiftedPreviousSize = MapperCGF.Builder.CreateShl(\n      PreviousSize,\n      MapperCGF.Builder.getInt64(MappableExprsHandler::getFlagMemberOffset()));\n\n  // Fill up the runtime mapper handle for all components.\n  for (unsigned I = 0; I < Info.BasePointers.size(); ++I) {\n    llvm::Value *CurBaseArg = MapperCGF.Builder.CreateBitCast(\n        *Info.BasePointers[I], CGM.getTypes().ConvertTypeForMem(C.VoidPtrTy));\n    llvm::Value *CurBeginArg = MapperCGF.Builder.CreateBitCast(\n        Info.Pointers[I], CGM.getTypes().ConvertTypeForMem(C.VoidPtrTy));\n    llvm::Value *CurSizeArg = Info.Sizes[I];\n    llvm::Value *CurNameArg =\n        (CGM.getCodeGenOpts().getDebugInfo() == codegenoptions::NoDebugInfo)\n            ? llvm::ConstantPointerNull::get(CGM.VoidPtrTy)\n            : emitMappingInformation(MapperCGF, OMPBuilder, Info.Exprs[I]);\n\n    // Extract the MEMBER_OF field from the map type.\n    llvm::Value *OriMapType = MapperCGF.Builder.getInt64(Info.Types[I]);\n    llvm::Value *MemberMapType =\n        MapperCGF.Builder.CreateNUWAdd(OriMapType, ShiftedPreviousSize);\n\n    // Combine the map type inherited from user-defined mapper with that\n    // specified in the program. According to the OMP_MAP_TO and OMP_MAP_FROM\n    // bits of the \\a MapType, which is the input argument of the mapper\n    // function, the following code will set the OMP_MAP_TO and OMP_MAP_FROM\n    // bits of MemberMapType.\n    // [OpenMP 5.0], 1.2.6. map-type decay.\n    //        | alloc |  to   | from  | tofrom | release | delete\n    // ----------------------------------------------------------\n    // alloc  | alloc | alloc | alloc | alloc  | release | delete\n    // to     | alloc |  to   | alloc |   to   | release | delete\n    // from   | alloc | alloc | from  |  from  | release | delete\n    // tofrom | alloc |  to   | from  | tofrom | release | delete\n    llvm::Value *LeftToFrom = MapperCGF.Builder.CreateAnd(\n        MapType,\n        MapperCGF.Builder.getInt64(MappableExprsHandler::OMP_MAP_TO |\n                                   MappableExprsHandler::OMP_MAP_FROM));\n    llvm::BasicBlock *AllocBB = MapperCGF.createBasicBlock(\"omp.type.alloc\");\n    llvm::BasicBlock *AllocElseBB =\n        MapperCGF.createBasicBlock(\"omp.type.alloc.else\");\n    llvm::BasicBlock *ToBB = MapperCGF.createBasicBlock(\"omp.type.to\");\n    llvm::BasicBlock *ToElseBB = MapperCGF.createBasicBlock(\"omp.type.to.else\");\n    llvm::BasicBlock *FromBB = MapperCGF.createBasicBlock(\"omp.type.from\");\n    llvm::BasicBlock *EndBB = MapperCGF.createBasicBlock(\"omp.type.end\");\n    llvm::Value *IsAlloc = MapperCGF.Builder.CreateIsNull(LeftToFrom);\n    MapperCGF.Builder.CreateCondBr(IsAlloc, AllocBB, AllocElseBB);\n    // In case of alloc, clear OMP_MAP_TO and OMP_MAP_FROM.\n    MapperCGF.EmitBlock(AllocBB);\n    llvm::Value *AllocMapType = MapperCGF.Builder.CreateAnd(\n        MemberMapType,\n        MapperCGF.Builder.getInt64(~(MappableExprsHandler::OMP_MAP_TO |\n                                     MappableExprsHandler::OMP_MAP_FROM)));\n    MapperCGF.Builder.CreateBr(EndBB);\n    MapperCGF.EmitBlock(AllocElseBB);\n    llvm::Value *IsTo = MapperCGF.Builder.CreateICmpEQ(\n        LeftToFrom,\n        MapperCGF.Builder.getInt64(MappableExprsHandler::OMP_MAP_TO));\n    MapperCGF.Builder.CreateCondBr(IsTo, ToBB, ToElseBB);\n    // In case of to, clear OMP_MAP_FROM.\n    MapperCGF.EmitBlock(ToBB);\n    llvm::Value *ToMapType = MapperCGF.Builder.CreateAnd(\n        MemberMapType,\n        MapperCGF.Builder.getInt64(~MappableExprsHandler::OMP_MAP_FROM));\n    MapperCGF.Builder.CreateBr(EndBB);\n    MapperCGF.EmitBlock(ToElseBB);\n    llvm::Value *IsFrom = MapperCGF.Builder.CreateICmpEQ(\n        LeftToFrom,\n        MapperCGF.Builder.getInt64(MappableExprsHandler::OMP_MAP_FROM));\n    MapperCGF.Builder.CreateCondBr(IsFrom, FromBB, EndBB);\n    // In case of from, clear OMP_MAP_TO.\n    MapperCGF.EmitBlock(FromBB);\n    llvm::Value *FromMapType = MapperCGF.Builder.CreateAnd(\n        MemberMapType,\n        MapperCGF.Builder.getInt64(~MappableExprsHandler::OMP_MAP_TO));\n    // In case of tofrom, do nothing.\n    MapperCGF.EmitBlock(EndBB);\n    LastBB = EndBB;\n    llvm::PHINode *CurMapType =\n        MapperCGF.Builder.CreatePHI(CGM.Int64Ty, 4, \"omp.maptype\");\n    CurMapType->addIncoming(AllocMapType, AllocBB);\n    CurMapType->addIncoming(ToMapType, ToBB);\n    CurMapType->addIncoming(FromMapType, FromBB);\n    CurMapType->addIncoming(MemberMapType, ToElseBB);\n\n    llvm::Value *OffloadingArgs[] = {Handle,     CurBaseArg, CurBeginArg,\n                                     CurSizeArg, CurMapType, CurNameArg};\n    if (Info.Mappers[I]) {\n      // Call the corresponding mapper function.\n      llvm::Function *MapperFunc = getOrCreateUserDefinedMapperFunc(\n          cast<OMPDeclareMapperDecl>(Info.Mappers[I]));\n      assert(MapperFunc && \"Expect a valid mapper function is available.\");\n      MapperCGF.EmitNounwindRuntimeCall(MapperFunc, OffloadingArgs);\n    } else {\n      // Call the runtime API __tgt_push_mapper_component to fill up the runtime\n      // data structure.\n      MapperCGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), OMPRTL___tgt_push_mapper_component),\n          OffloadingArgs);\n    }\n  }\n\n  // Update the pointer to point to the next element that needs to be mapped,\n  // and check whether we have mapped all elements.\n  llvm::Value *PtrNext = MapperCGF.Builder.CreateConstGEP1_32(\n      PtrPHI, /*Idx0=*/1, \"omp.arraymap.next\");\n  PtrPHI->addIncoming(PtrNext, LastBB);\n  llvm::Value *IsDone =\n      MapperCGF.Builder.CreateICmpEQ(PtrNext, PtrEnd, \"omp.arraymap.isdone\");\n  llvm::BasicBlock *ExitBB = MapperCGF.createBasicBlock(\"omp.arraymap.exit\");\n  MapperCGF.Builder.CreateCondBr(IsDone, ExitBB, BodyBB);\n\n  MapperCGF.EmitBlock(ExitBB);\n  // Emit array deletion if this is an array section and \\p MapType indicates\n  // that deletion is required.\n  emitUDMapperArrayInitOrDel(MapperCGF, Handle, BaseIn, BeginIn, Size, MapType,\n                             ElementSize, DoneBB, /*IsInit=*/false);\n\n  // Emit the function exit block.\n  MapperCGF.EmitBlock(DoneBB, /*IsFinished=*/true);\n  MapperCGF.FinishFunction();\n  UDMMap.try_emplace(D, Fn);\n  if (CGF) {\n    auto &Decls = FunctionUDMMap.FindAndConstruct(CGF->CurFn);\n    Decls.second.push_back(D);\n  }\n}\n\n/// Emit the array initialization or deletion portion for user-defined mapper\n/// code generation. First, it evaluates whether an array section is mapped and\n/// whether the \\a MapType instructs to delete this section. If \\a IsInit is\n/// true, and \\a MapType indicates to not delete this array, array\n/// initialization code is generated. If \\a IsInit is false, and \\a MapType\n/// indicates to not this array, array deletion code is generated.\nvoid CGOpenMPRuntime::emitUDMapperArrayInitOrDel(\n    CodeGenFunction &MapperCGF, llvm::Value *Handle, llvm::Value *Base,\n    llvm::Value *Begin, llvm::Value *Size, llvm::Value *MapType,\n    CharUnits ElementSize, llvm::BasicBlock *ExitBB, bool IsInit) {\n  StringRef Prefix = IsInit ? \".init\" : \".del\";\n\n  // Evaluate if this is an array section.\n  llvm::BasicBlock *BodyBB =\n      MapperCGF.createBasicBlock(getName({\"omp.array\", Prefix}));\n  llvm::Value *IsArray = MapperCGF.Builder.CreateICmpSGT(\n      Size, MapperCGF.Builder.getInt64(1), \"omp.arrayinit.isarray\");\n  llvm::Value *DeleteBit = MapperCGF.Builder.CreateAnd(\n      MapType,\n      MapperCGF.Builder.getInt64(MappableExprsHandler::OMP_MAP_DELETE));\n  llvm::Value *DeleteCond;\n  llvm::Value *Cond;\n  if (IsInit) {\n    // base != begin?\n    llvm::Value *BaseIsBegin = MapperCGF.Builder.CreateIsNotNull(\n        MapperCGF.Builder.CreatePtrDiff(Base, Begin));\n    // IsPtrAndObj?\n    llvm::Value *PtrAndObjBit = MapperCGF.Builder.CreateAnd(\n        MapType,\n        MapperCGF.Builder.getInt64(MappableExprsHandler::OMP_MAP_PTR_AND_OBJ));\n    PtrAndObjBit = MapperCGF.Builder.CreateIsNotNull(PtrAndObjBit);\n    BaseIsBegin = MapperCGF.Builder.CreateAnd(BaseIsBegin, PtrAndObjBit);\n    Cond = MapperCGF.Builder.CreateOr(IsArray, BaseIsBegin);\n    DeleteCond = MapperCGF.Builder.CreateIsNull(\n        DeleteBit, getName({\"omp.array\", Prefix, \".delete\"}));\n  } else {\n    Cond = IsArray;\n    DeleteCond = MapperCGF.Builder.CreateIsNotNull(\n        DeleteBit, getName({\"omp.array\", Prefix, \".delete\"}));\n  }\n  Cond = MapperCGF.Builder.CreateAnd(Cond, DeleteCond);\n  MapperCGF.Builder.CreateCondBr(Cond, BodyBB, ExitBB);\n\n  MapperCGF.EmitBlock(BodyBB);\n  // Get the array size by multiplying element size and element number (i.e., \\p\n  // Size).\n  llvm::Value *ArraySize = MapperCGF.Builder.CreateNUWMul(\n      Size, MapperCGF.Builder.getInt64(ElementSize.getQuantity()));\n  // Remove OMP_MAP_TO and OMP_MAP_FROM from the map type, so that it achieves\n  // memory allocation/deletion purpose only.\n  llvm::Value *MapTypeArg = MapperCGF.Builder.CreateAnd(\n      MapType,\n      MapperCGF.Builder.getInt64(~(MappableExprsHandler::OMP_MAP_TO |\n                                   MappableExprsHandler::OMP_MAP_FROM |\n                                   MappableExprsHandler::OMP_MAP_MEMBER_OF)));\n  llvm::Value *MapNameArg = llvm::ConstantPointerNull::get(CGM.VoidPtrTy);\n\n  // Call the runtime API __tgt_push_mapper_component to fill up the runtime\n  // data structure.\n  llvm::Value *OffloadingArgs[] = {Handle,    Base,       Begin,\n                                   ArraySize, MapTypeArg, MapNameArg};\n  MapperCGF.EmitRuntimeCall(\n      OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                            OMPRTL___tgt_push_mapper_component),\n      OffloadingArgs);\n}\n\nllvm::Function *CGOpenMPRuntime::getOrCreateUserDefinedMapperFunc(\n    const OMPDeclareMapperDecl *D) {\n  auto I = UDMMap.find(D);\n  if (I != UDMMap.end())\n    return I->second;\n  emitUserDefinedMapper(D);\n  return UDMMap.lookup(D);\n}\n\nvoid CGOpenMPRuntime::emitTargetNumIterationsCall(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D,\n    llvm::Value *DeviceID,\n    llvm::function_ref<llvm::Value *(CodeGenFunction &CGF,\n                                     const OMPLoopDirective &D)>\n        SizeEmitter) {\n  OpenMPDirectiveKind Kind = D.getDirectiveKind();\n  const OMPExecutableDirective *TD = &D;\n  // Get nested teams distribute kind directive, if any.\n  if (!isOpenMPDistributeDirective(Kind) || !isOpenMPTeamsDirective(Kind))\n    TD = getNestedDistributeDirective(CGM.getContext(), D);\n  if (!TD)\n    return;\n  const auto *LD = cast<OMPLoopDirective>(TD);\n  auto &&CodeGen = [LD, DeviceID, SizeEmitter, &D, this](CodeGenFunction &CGF,\n                                                         PrePostActionTy &) {\n    if (llvm::Value *NumIterations = SizeEmitter(CGF, *LD)) {\n      llvm::Value *RTLoc = emitUpdateLocation(CGF, D.getBeginLoc());\n      llvm::Value *Args[] = {RTLoc, DeviceID, NumIterations};\n      CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), OMPRTL___kmpc_push_target_tripcount),\n          Args);\n    }\n  };\n  emitInlinedDirective(CGF, OMPD_unknown, CodeGen);\n}\n\nvoid CGOpenMPRuntime::emitTargetCall(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D,\n    llvm::Function *OutlinedFn, llvm::Value *OutlinedFnID, const Expr *IfCond,\n    llvm::PointerIntPair<const Expr *, 2, OpenMPDeviceClauseModifier> Device,\n    llvm::function_ref<llvm::Value *(CodeGenFunction &CGF,\n                                     const OMPLoopDirective &D)>\n        SizeEmitter) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  assert(OutlinedFn && \"Invalid outlined function!\");\n\n  const bool RequiresOuterTask = D.hasClausesOfKind<OMPDependClause>() ||\n                                 D.hasClausesOfKind<OMPNowaitClause>();\n  llvm::SmallVector<llvm::Value *, 16> CapturedVars;\n  const CapturedStmt &CS = *D.getCapturedStmt(OMPD_target);\n  auto &&ArgsCodegen = [&CS, &CapturedVars](CodeGenFunction &CGF,\n                                            PrePostActionTy &) {\n    CGF.GenerateOpenMPCapturedVars(CS, CapturedVars);\n  };\n  emitInlinedDirective(CGF, OMPD_unknown, ArgsCodegen);\n\n  CodeGenFunction::OMPTargetDataInfo InputInfo;\n  llvm::Value *MapTypesArray = nullptr;\n  llvm::Value *MapNamesArray = nullptr;\n  // Fill up the pointer arrays and transfer execution to the device.\n  auto &&ThenGen = [this, Device, OutlinedFn, OutlinedFnID, &D, &InputInfo,\n                    &MapTypesArray, &MapNamesArray, &CS, RequiresOuterTask,\n                    &CapturedVars,\n                    SizeEmitter](CodeGenFunction &CGF, PrePostActionTy &) {\n    if (Device.getInt() == OMPC_DEVICE_ancestor) {\n      // Reverse offloading is not supported, so just execute on the host.\n      if (RequiresOuterTask) {\n        CapturedVars.clear();\n        CGF.GenerateOpenMPCapturedVars(CS, CapturedVars);\n      }\n      emitOutlinedFunctionCall(CGF, D.getBeginLoc(), OutlinedFn, CapturedVars);\n      return;\n    }\n\n    // On top of the arrays that were filled up, the target offloading call\n    // takes as arguments the device id as well as the host pointer. The host\n    // pointer is used by the runtime library to identify the current target\n    // region, so it only has to be unique and not necessarily point to\n    // anything. It could be the pointer to the outlined function that\n    // implements the target region, but we aren't using that so that the\n    // compiler doesn't need to keep that, and could therefore inline the host\n    // function if proven worthwhile during optimization.\n\n    // From this point on, we need to have an ID of the target region defined.\n    assert(OutlinedFnID && \"Invalid outlined function ID!\");\n\n    // Emit device ID if any.\n    llvm::Value *DeviceID;\n    if (Device.getPointer()) {\n      assert((Device.getInt() == OMPC_DEVICE_unknown ||\n              Device.getInt() == OMPC_DEVICE_device_num) &&\n             \"Expected device_num modifier.\");\n      llvm::Value *DevVal = CGF.EmitScalarExpr(Device.getPointer());\n      DeviceID =\n          CGF.Builder.CreateIntCast(DevVal, CGF.Int64Ty, /*isSigned=*/true);\n    } else {\n      DeviceID = CGF.Builder.getInt64(OMP_DEVICEID_UNDEF);\n    }\n\n    // Emit the number of elements in the offloading arrays.\n    llvm::Value *PointerNum =\n        CGF.Builder.getInt32(InputInfo.NumberOfTargetItems);\n\n    // Return value of the runtime offloading call.\n    llvm::Value *Return;\n\n    llvm::Value *NumTeams = emitNumTeamsForTargetDirective(CGF, D);\n    llvm::Value *NumThreads = emitNumThreadsForTargetDirective(CGF, D);\n\n    // Source location for the ident struct\n    llvm::Value *RTLoc = emitUpdateLocation(CGF, D.getBeginLoc());\n\n    // Emit tripcount for the target loop-based directive.\n    emitTargetNumIterationsCall(CGF, D, DeviceID, SizeEmitter);\n\n    bool HasNowait = D.hasClausesOfKind<OMPNowaitClause>();\n    // The target region is an outlined function launched by the runtime\n    // via calls __tgt_target() or __tgt_target_teams().\n    //\n    // __tgt_target() launches a target region with one team and one thread,\n    // executing a serial region.  This master thread may in turn launch\n    // more threads within its team upon encountering a parallel region,\n    // however, no additional teams can be launched on the device.\n    //\n    // __tgt_target_teams() launches a target region with one or more teams,\n    // each with one or more threads.  This call is required for target\n    // constructs such as:\n    //  'target teams'\n    //  'target' / 'teams'\n    //  'target teams distribute parallel for'\n    //  'target parallel'\n    // and so on.\n    //\n    // Note that on the host and CPU targets, the runtime implementation of\n    // these calls simply call the outlined function without forking threads.\n    // The outlined functions themselves have runtime calls to\n    // __kmpc_fork_teams() and __kmpc_fork() for this purpose, codegen'd by\n    // the compiler in emitTeamsCall() and emitParallelCall().\n    //\n    // In contrast, on the NVPTX target, the implementation of\n    // __tgt_target_teams() launches a GPU kernel with the requested number\n    // of teams and threads so no additional calls to the runtime are required.\n    if (NumTeams) {\n      // If we have NumTeams defined this means that we have an enclosed teams\n      // region. Therefore we also expect to have NumThreads defined. These two\n      // values should be defined in the presence of a teams directive,\n      // regardless of having any clauses associated. If the user is using teams\n      // but no clauses, these two values will be the default that should be\n      // passed to the runtime library - a 32-bit integer with the value zero.\n      assert(NumThreads && \"Thread limit expression should be available along \"\n                           \"with number of teams.\");\n      llvm::Value *OffloadingArgs[] = {RTLoc,\n                                       DeviceID,\n                                       OutlinedFnID,\n                                       PointerNum,\n                                       InputInfo.BasePointersArray.getPointer(),\n                                       InputInfo.PointersArray.getPointer(),\n                                       InputInfo.SizesArray.getPointer(),\n                                       MapTypesArray,\n                                       MapNamesArray,\n                                       InputInfo.MappersArray.getPointer(),\n                                       NumTeams,\n                                       NumThreads};\n      Return = CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), HasNowait\n                                   ? OMPRTL___tgt_target_teams_nowait_mapper\n                                   : OMPRTL___tgt_target_teams_mapper),\n          OffloadingArgs);\n    } else {\n      llvm::Value *OffloadingArgs[] = {RTLoc,\n                                       DeviceID,\n                                       OutlinedFnID,\n                                       PointerNum,\n                                       InputInfo.BasePointersArray.getPointer(),\n                                       InputInfo.PointersArray.getPointer(),\n                                       InputInfo.SizesArray.getPointer(),\n                                       MapTypesArray,\n                                       MapNamesArray,\n                                       InputInfo.MappersArray.getPointer()};\n      Return = CGF.EmitRuntimeCall(\n          OMPBuilder.getOrCreateRuntimeFunction(\n              CGM.getModule(), HasNowait ? OMPRTL___tgt_target_nowait_mapper\n                                         : OMPRTL___tgt_target_mapper),\n          OffloadingArgs);\n    }\n\n    // Check the error code and execute the host version if required.\n    llvm::BasicBlock *OffloadFailedBlock =\n        CGF.createBasicBlock(\"omp_offload.failed\");\n    llvm::BasicBlock *OffloadContBlock =\n        CGF.createBasicBlock(\"omp_offload.cont\");\n    llvm::Value *Failed = CGF.Builder.CreateIsNotNull(Return);\n    CGF.Builder.CreateCondBr(Failed, OffloadFailedBlock, OffloadContBlock);\n\n    CGF.EmitBlock(OffloadFailedBlock);\n    if (RequiresOuterTask) {\n      CapturedVars.clear();\n      CGF.GenerateOpenMPCapturedVars(CS, CapturedVars);\n    }\n    emitOutlinedFunctionCall(CGF, D.getBeginLoc(), OutlinedFn, CapturedVars);\n    CGF.EmitBranch(OffloadContBlock);\n\n    CGF.EmitBlock(OffloadContBlock, /*IsFinished=*/true);\n  };\n\n  // Notify that the host version must be executed.\n  auto &&ElseGen = [this, &D, OutlinedFn, &CS, &CapturedVars,\n                    RequiresOuterTask](CodeGenFunction &CGF,\n                                       PrePostActionTy &) {\n    if (RequiresOuterTask) {\n      CapturedVars.clear();\n      CGF.GenerateOpenMPCapturedVars(CS, CapturedVars);\n    }\n    emitOutlinedFunctionCall(CGF, D.getBeginLoc(), OutlinedFn, CapturedVars);\n  };\n\n  auto &&TargetThenGen = [this, &ThenGen, &D, &InputInfo, &MapTypesArray,\n                          &MapNamesArray, &CapturedVars, RequiresOuterTask,\n                          &CS](CodeGenFunction &CGF, PrePostActionTy &) {\n    // Fill up the arrays with all the captured variables.\n    MappableExprsHandler::MapCombinedInfoTy CombinedInfo;\n\n    // Get mappable expression information.\n    MappableExprsHandler MEHandler(D, CGF);\n    llvm::DenseMap<llvm::Value *, llvm::Value *> LambdaPointers;\n    llvm::DenseSet<CanonicalDeclPtr<const Decl>> MappedVarSet;\n\n    auto RI = CS.getCapturedRecordDecl()->field_begin();\n    auto *CV = CapturedVars.begin();\n    for (CapturedStmt::const_capture_iterator CI = CS.capture_begin(),\n                                              CE = CS.capture_end();\n         CI != CE; ++CI, ++RI, ++CV) {\n      MappableExprsHandler::MapCombinedInfoTy CurInfo;\n      MappableExprsHandler::StructRangeInfoTy PartialStruct;\n\n      // VLA sizes are passed to the outlined region by copy and do not have map\n      // information associated.\n      if (CI->capturesVariableArrayType()) {\n        CurInfo.Exprs.push_back(nullptr);\n        CurInfo.BasePointers.push_back(*CV);\n        CurInfo.Pointers.push_back(*CV);\n        CurInfo.Sizes.push_back(CGF.Builder.CreateIntCast(\n            CGF.getTypeSize(RI->getType()), CGF.Int64Ty, /*isSigned=*/true));\n        // Copy to the device as an argument. No need to retrieve it.\n        CurInfo.Types.push_back(MappableExprsHandler::OMP_MAP_LITERAL |\n                                MappableExprsHandler::OMP_MAP_TARGET_PARAM |\n                                MappableExprsHandler::OMP_MAP_IMPLICIT);\n        CurInfo.Mappers.push_back(nullptr);\n      } else {\n        // If we have any information in the map clause, we use it, otherwise we\n        // just do a default mapping.\n        MEHandler.generateInfoForCapture(CI, *CV, CurInfo, PartialStruct);\n        if (!CI->capturesThis())\n          MappedVarSet.insert(CI->getCapturedVar());\n        else\n          MappedVarSet.insert(nullptr);\n        if (CurInfo.BasePointers.empty() && !PartialStruct.Base.isValid())\n          MEHandler.generateDefaultMapInfo(*CI, **RI, *CV, CurInfo);\n        // Generate correct mapping for variables captured by reference in\n        // lambdas.\n        if (CI->capturesVariable())\n          MEHandler.generateInfoForLambdaCaptures(CI->getCapturedVar(), *CV,\n                                                  CurInfo, LambdaPointers);\n      }\n      // We expect to have at least an element of information for this capture.\n      assert((!CurInfo.BasePointers.empty() || PartialStruct.Base.isValid()) &&\n             \"Non-existing map pointer for capture!\");\n      assert(CurInfo.BasePointers.size() == CurInfo.Pointers.size() &&\n             CurInfo.BasePointers.size() == CurInfo.Sizes.size() &&\n             CurInfo.BasePointers.size() == CurInfo.Types.size() &&\n             CurInfo.BasePointers.size() == CurInfo.Mappers.size() &&\n             \"Inconsistent map information sizes!\");\n\n      // If there is an entry in PartialStruct it means we have a struct with\n      // individual members mapped. Emit an extra combined entry.\n      if (PartialStruct.Base.isValid()) {\n        CombinedInfo.append(PartialStruct.PreliminaryMapData);\n        MEHandler.emitCombinedEntry(\n            CombinedInfo, CurInfo.Types, PartialStruct, nullptr,\n            !PartialStruct.PreliminaryMapData.BasePointers.empty());\n      }\n\n      // We need to append the results of this capture to what we already have.\n      CombinedInfo.append(CurInfo);\n    }\n    // Adjust MEMBER_OF flags for the lambdas captures.\n    MEHandler.adjustMemberOfForLambdaCaptures(\n        LambdaPointers, CombinedInfo.BasePointers, CombinedInfo.Pointers,\n        CombinedInfo.Types);\n    // Map any list items in a map clause that were not captures because they\n    // weren't referenced within the construct.\n    MEHandler.generateAllInfo(CombinedInfo, MappedVarSet);\n\n    TargetDataInfo Info;\n    // Fill up the arrays and create the arguments.\n    emitOffloadingArrays(CGF, CombinedInfo, Info, OMPBuilder);\n    emitOffloadingArraysArgument(\n        CGF, Info.BasePointersArray, Info.PointersArray, Info.SizesArray,\n        Info.MapTypesArray, Info.MapNamesArray, Info.MappersArray, Info,\n        {/*ForEndTask=*/false});\n\n    InputInfo.NumberOfTargetItems = Info.NumberOfPtrs;\n    InputInfo.BasePointersArray =\n        Address(Info.BasePointersArray, CGM.getPointerAlign());\n    InputInfo.PointersArray =\n        Address(Info.PointersArray, CGM.getPointerAlign());\n    InputInfo.SizesArray = Address(Info.SizesArray, CGM.getPointerAlign());\n    InputInfo.MappersArray = Address(Info.MappersArray, CGM.getPointerAlign());\n    MapTypesArray = Info.MapTypesArray;\n    MapNamesArray = Info.MapNamesArray;\n    if (RequiresOuterTask)\n      CGF.EmitOMPTargetTaskBasedDirective(D, ThenGen, InputInfo);\n    else\n      emitInlinedDirective(CGF, D.getDirectiveKind(), ThenGen);\n  };\n\n  auto &&TargetElseGen = [this, &ElseGen, &D, RequiresOuterTask](\n                             CodeGenFunction &CGF, PrePostActionTy &) {\n    if (RequiresOuterTask) {\n      CodeGenFunction::OMPTargetDataInfo InputInfo;\n      CGF.EmitOMPTargetTaskBasedDirective(D, ElseGen, InputInfo);\n    } else {\n      emitInlinedDirective(CGF, D.getDirectiveKind(), ElseGen);\n    }\n  };\n\n  // If we have a target function ID it means that we need to support\n  // offloading, otherwise, just execute on the host. We need to execute on host\n  // regardless of the conditional in the if clause if, e.g., the user do not\n  // specify target triples.\n  if (OutlinedFnID) {\n    if (IfCond) {\n      emitIfClause(CGF, IfCond, TargetThenGen, TargetElseGen);\n    } else {\n      RegionCodeGenTy ThenRCG(TargetThenGen);\n      ThenRCG(CGF);\n    }\n  } else {\n    RegionCodeGenTy ElseRCG(TargetElseGen);\n    ElseRCG(CGF);\n  }\n}\n\nvoid CGOpenMPRuntime::scanForTargetRegionsFunctions(const Stmt *S,\n                                                    StringRef ParentName) {\n  if (!S)\n    return;\n\n  // Codegen OMP target directives that offload compute to the device.\n  bool RequiresDeviceCodegen =\n      isa<OMPExecutableDirective>(S) &&\n      isOpenMPTargetExecutionDirective(\n          cast<OMPExecutableDirective>(S)->getDirectiveKind());\n\n  if (RequiresDeviceCodegen) {\n    const auto &E = *cast<OMPExecutableDirective>(S);\n    unsigned DeviceID;\n    unsigned FileID;\n    unsigned Line;\n    getTargetEntryUniqueInfo(CGM.getContext(), E.getBeginLoc(), DeviceID,\n                             FileID, Line);\n\n    // Is this a target region that should not be emitted as an entry point? If\n    // so just signal we are done with this target region.\n    if (!OffloadEntriesInfoManager.hasTargetRegionEntryInfo(DeviceID, FileID,\n                                                            ParentName, Line))\n      return;\n\n    switch (E.getDirectiveKind()) {\n    case OMPD_target:\n      CodeGenFunction::EmitOMPTargetDeviceFunction(CGM, ParentName,\n                                                   cast<OMPTargetDirective>(E));\n      break;\n    case OMPD_target_parallel:\n      CodeGenFunction::EmitOMPTargetParallelDeviceFunction(\n          CGM, ParentName, cast<OMPTargetParallelDirective>(E));\n      break;\n    case OMPD_target_teams:\n      CodeGenFunction::EmitOMPTargetTeamsDeviceFunction(\n          CGM, ParentName, cast<OMPTargetTeamsDirective>(E));\n      break;\n    case OMPD_target_teams_distribute:\n      CodeGenFunction::EmitOMPTargetTeamsDistributeDeviceFunction(\n          CGM, ParentName, cast<OMPTargetTeamsDistributeDirective>(E));\n      break;\n    case OMPD_target_teams_distribute_simd:\n      CodeGenFunction::EmitOMPTargetTeamsDistributeSimdDeviceFunction(\n          CGM, ParentName, cast<OMPTargetTeamsDistributeSimdDirective>(E));\n      break;\n    case OMPD_target_parallel_for:\n      CodeGenFunction::EmitOMPTargetParallelForDeviceFunction(\n          CGM, ParentName, cast<OMPTargetParallelForDirective>(E));\n      break;\n    case OMPD_target_parallel_for_simd:\n      CodeGenFunction::EmitOMPTargetParallelForSimdDeviceFunction(\n          CGM, ParentName, cast<OMPTargetParallelForSimdDirective>(E));\n      break;\n    case OMPD_target_simd:\n      CodeGenFunction::EmitOMPTargetSimdDeviceFunction(\n          CGM, ParentName, cast<OMPTargetSimdDirective>(E));\n      break;\n    case OMPD_target_teams_distribute_parallel_for:\n      CodeGenFunction::EmitOMPTargetTeamsDistributeParallelForDeviceFunction(\n          CGM, ParentName,\n          cast<OMPTargetTeamsDistributeParallelForDirective>(E));\n      break;\n    case OMPD_target_teams_distribute_parallel_for_simd:\n      CodeGenFunction::\n          EmitOMPTargetTeamsDistributeParallelForSimdDeviceFunction(\n              CGM, ParentName,\n              cast<OMPTargetTeamsDistributeParallelForSimdDirective>(E));\n      break;\n    case OMPD_parallel:\n    case OMPD_for:\n    case OMPD_parallel_for:\n    case OMPD_parallel_master:\n    case OMPD_parallel_sections:\n    case OMPD_for_simd:\n    case OMPD_parallel_for_simd:\n    case OMPD_cancel:\n    case OMPD_cancellation_point:\n    case OMPD_ordered:\n    case OMPD_threadprivate:\n    case OMPD_allocate:\n    case OMPD_task:\n    case OMPD_simd:\n    case OMPD_tile:\n    case OMPD_sections:\n    case OMPD_section:\n    case OMPD_single:\n    case OMPD_master:\n    case OMPD_critical:\n    case OMPD_taskyield:\n    case OMPD_barrier:\n    case OMPD_taskwait:\n    case OMPD_taskgroup:\n    case OMPD_atomic:\n    case OMPD_flush:\n    case OMPD_depobj:\n    case OMPD_scan:\n    case OMPD_teams:\n    case OMPD_target_data:\n    case OMPD_target_exit_data:\n    case OMPD_target_enter_data:\n    case OMPD_distribute:\n    case OMPD_distribute_simd:\n    case OMPD_distribute_parallel_for:\n    case OMPD_distribute_parallel_for_simd:\n    case OMPD_teams_distribute:\n    case OMPD_teams_distribute_simd:\n    case OMPD_teams_distribute_parallel_for:\n    case OMPD_teams_distribute_parallel_for_simd:\n    case OMPD_target_update:\n    case OMPD_declare_simd:\n    case OMPD_declare_variant:\n    case OMPD_begin_declare_variant:\n    case OMPD_end_declare_variant:\n    case OMPD_declare_target:\n    case OMPD_end_declare_target:\n    case OMPD_declare_reduction:\n    case OMPD_declare_mapper:\n    case OMPD_taskloop:\n    case OMPD_taskloop_simd:\n    case OMPD_master_taskloop:\n    case OMPD_master_taskloop_simd:\n    case OMPD_parallel_master_taskloop:\n    case OMPD_parallel_master_taskloop_simd:\n    case OMPD_requires:\n    case OMPD_unknown:\n    default:\n      llvm_unreachable(\"Unknown target directive for OpenMP device codegen.\");\n    }\n    return;\n  }\n\n  if (const auto *E = dyn_cast<OMPExecutableDirective>(S)) {\n    if (!E->hasAssociatedStmt() || !E->getAssociatedStmt())\n      return;\n\n    scanForTargetRegionsFunctions(E->getRawStmt(), ParentName);\n    return;\n  }\n\n  // If this is a lambda function, look into its body.\n  if (const auto *L = dyn_cast<LambdaExpr>(S))\n    S = L->getBody();\n\n  // Keep looking for target regions recursively.\n  for (const Stmt *II : S->children())\n    scanForTargetRegionsFunctions(II, ParentName);\n}\n\nbool CGOpenMPRuntime::emitTargetFunctions(GlobalDecl GD) {\n  // If emitting code for the host, we do not process FD here. Instead we do\n  // the normal code generation.\n  if (!CGM.getLangOpts().OpenMPIsDevice) {\n    if (const auto *FD = dyn_cast<FunctionDecl>(GD.getDecl())) {\n      Optional<OMPDeclareTargetDeclAttr::DevTypeTy> DevTy =\n          OMPDeclareTargetDeclAttr::getDeviceType(FD);\n      // Do not emit device_type(nohost) functions for the host.\n      if (DevTy && *DevTy == OMPDeclareTargetDeclAttr::DT_NoHost)\n        return true;\n    }\n    return false;\n  }\n\n  const ValueDecl *VD = cast<ValueDecl>(GD.getDecl());\n  // Try to detect target regions in the function.\n  if (const auto *FD = dyn_cast<FunctionDecl>(VD)) {\n    StringRef Name = CGM.getMangledName(GD);\n    scanForTargetRegionsFunctions(FD->getBody(), Name);\n    Optional<OMPDeclareTargetDeclAttr::DevTypeTy> DevTy =\n        OMPDeclareTargetDeclAttr::getDeviceType(FD);\n    // Do not emit device_type(nohost) functions for the host.\n    if (DevTy && *DevTy == OMPDeclareTargetDeclAttr::DT_Host)\n      return true;\n  }\n\n  // Do not to emit function if it is not marked as declare target.\n  return !OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD) &&\n         AlreadyEmittedTargetDecls.count(VD) == 0;\n}\n\nbool CGOpenMPRuntime::emitTargetGlobalVariable(GlobalDecl GD) {\n  if (!CGM.getLangOpts().OpenMPIsDevice)\n    return false;\n\n  // Check if there are Ctors/Dtors in this declaration and look for target\n  // regions in it. We use the complete variant to produce the kernel name\n  // mangling.\n  QualType RDTy = cast<VarDecl>(GD.getDecl())->getType();\n  if (const auto *RD = RDTy->getBaseElementTypeUnsafe()->getAsCXXRecordDecl()) {\n    for (const CXXConstructorDecl *Ctor : RD->ctors()) {\n      StringRef ParentName =\n          CGM.getMangledName(GlobalDecl(Ctor, Ctor_Complete));\n      scanForTargetRegionsFunctions(Ctor->getBody(), ParentName);\n    }\n    if (const CXXDestructorDecl *Dtor = RD->getDestructor()) {\n      StringRef ParentName =\n          CGM.getMangledName(GlobalDecl(Dtor, Dtor_Complete));\n      scanForTargetRegionsFunctions(Dtor->getBody(), ParentName);\n    }\n  }\n\n  // Do not to emit variable if it is not marked as declare target.\n  llvm::Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n      OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(\n          cast<VarDecl>(GD.getDecl()));\n  if (!Res || *Res == OMPDeclareTargetDeclAttr::MT_Link ||\n      (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n       HasRequiresUnifiedSharedMemory)) {\n    DeferredGlobalVariables.insert(cast<VarDecl>(GD.getDecl()));\n    return true;\n  }\n  return false;\n}\n\nllvm::Constant *\nCGOpenMPRuntime::registerTargetFirstprivateCopy(CodeGenFunction &CGF,\n                                                const VarDecl *VD) {\n  assert(VD->getType().isConstant(CGM.getContext()) &&\n         \"Expected constant variable.\");\n  StringRef VarName;\n  llvm::Constant *Addr;\n  llvm::GlobalValue::LinkageTypes Linkage;\n  QualType Ty = VD->getType();\n  SmallString<128> Buffer;\n  {\n    unsigned DeviceID;\n    unsigned FileID;\n    unsigned Line;\n    getTargetEntryUniqueInfo(CGM.getContext(), VD->getLocation(), DeviceID,\n                             FileID, Line);\n    llvm::raw_svector_ostream OS(Buffer);\n    OS << \"__omp_offloading_firstprivate_\" << llvm::format(\"_%x\", DeviceID)\n       << llvm::format(\"_%x_\", FileID) << VD->getName() << \"_l\" << Line;\n    VarName = OS.str();\n  }\n  Linkage = llvm::GlobalValue::InternalLinkage;\n  Addr =\n      getOrCreateInternalVariable(CGM.getTypes().ConvertTypeForMem(Ty), VarName,\n                                  getDefaultFirstprivateAddressSpace());\n  cast<llvm::GlobalValue>(Addr)->setLinkage(Linkage);\n  CharUnits VarSize = CGM.getContext().getTypeSizeInChars(Ty);\n  CGM.addCompilerUsedGlobal(cast<llvm::GlobalValue>(Addr));\n  OffloadEntriesInfoManager.registerDeviceGlobalVarEntryInfo(\n      VarName, Addr, VarSize,\n      OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryTo, Linkage);\n  return Addr;\n}\n\nvoid CGOpenMPRuntime::registerTargetGlobalVariable(const VarDecl *VD,\n                                                   llvm::Constant *Addr) {\n  if (CGM.getLangOpts().OMPTargetTriples.empty() &&\n      !CGM.getLangOpts().OpenMPIsDevice)\n    return;\n  llvm::Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n      OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD);\n  if (!Res) {\n    if (CGM.getLangOpts().OpenMPIsDevice) {\n      // Register non-target variables being emitted in device code (debug info\n      // may cause this).\n      StringRef VarName = CGM.getMangledName(VD);\n      EmittedNonTargetVariables.try_emplace(VarName, Addr);\n    }\n    return;\n  }\n  // Register declare target variables.\n  OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryKind Flags;\n  StringRef VarName;\n  CharUnits VarSize;\n  llvm::GlobalValue::LinkageTypes Linkage;\n\n  if (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n      !HasRequiresUnifiedSharedMemory) {\n    Flags = OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryTo;\n    VarName = CGM.getMangledName(VD);\n    if (VD->hasDefinition(CGM.getContext()) != VarDecl::DeclarationOnly) {\n      VarSize = CGM.getContext().getTypeSizeInChars(VD->getType());\n      assert(!VarSize.isZero() && \"Expected non-zero size of the variable\");\n    } else {\n      VarSize = CharUnits::Zero();\n    }\n    Linkage = CGM.getLLVMLinkageVarDefinition(VD, /*IsConstant=*/false);\n    // Temp solution to prevent optimizations of the internal variables.\n    if (CGM.getLangOpts().OpenMPIsDevice && !VD->isExternallyVisible()) {\n      std::string RefName = getName({VarName, \"ref\"});\n      if (!CGM.GetGlobalValue(RefName)) {\n        llvm::Constant *AddrRef =\n            getOrCreateInternalVariable(Addr->getType(), RefName);\n        auto *GVAddrRef = cast<llvm::GlobalVariable>(AddrRef);\n        GVAddrRef->setConstant(/*Val=*/true);\n        GVAddrRef->setLinkage(llvm::GlobalValue::InternalLinkage);\n        GVAddrRef->setInitializer(Addr);\n        CGM.addCompilerUsedGlobal(GVAddrRef);\n      }\n    }\n  } else {\n    assert(((*Res == OMPDeclareTargetDeclAttr::MT_Link) ||\n            (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n             HasRequiresUnifiedSharedMemory)) &&\n           \"Declare target attribute must link or to with unified memory.\");\n    if (*Res == OMPDeclareTargetDeclAttr::MT_Link)\n      Flags = OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryLink;\n    else\n      Flags = OffloadEntriesInfoManagerTy::OMPTargetGlobalVarEntryTo;\n\n    if (CGM.getLangOpts().OpenMPIsDevice) {\n      VarName = Addr->getName();\n      Addr = nullptr;\n    } else {\n      VarName = getAddrOfDeclareTargetVar(VD).getName();\n      Addr = cast<llvm::Constant>(getAddrOfDeclareTargetVar(VD).getPointer());\n    }\n    VarSize = CGM.getPointerSize();\n    Linkage = llvm::GlobalValue::WeakAnyLinkage;\n  }\n\n  OffloadEntriesInfoManager.registerDeviceGlobalVarEntryInfo(\n      VarName, Addr, VarSize, Flags, Linkage);\n}\n\nbool CGOpenMPRuntime::emitTargetGlobal(GlobalDecl GD) {\n  if (isa<FunctionDecl>(GD.getDecl()) ||\n      isa<OMPDeclareReductionDecl>(GD.getDecl()))\n    return emitTargetFunctions(GD);\n\n  return emitTargetGlobalVariable(GD);\n}\n\nvoid CGOpenMPRuntime::emitDeferredTargetDecls() const {\n  for (const VarDecl *VD : DeferredGlobalVariables) {\n    llvm::Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n        OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD);\n    if (!Res)\n      continue;\n    if (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n        !HasRequiresUnifiedSharedMemory) {\n      CGM.EmitGlobal(VD);\n    } else {\n      assert((*Res == OMPDeclareTargetDeclAttr::MT_Link ||\n              (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n               HasRequiresUnifiedSharedMemory)) &&\n             \"Expected link clause or to clause with unified memory.\");\n      (void)CGM.getOpenMPRuntime().getAddrOfDeclareTargetVar(VD);\n    }\n  }\n}\n\nvoid CGOpenMPRuntime::adjustTargetSpecificDataForLambdas(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D) const {\n  assert(isOpenMPTargetExecutionDirective(D.getDirectiveKind()) &&\n         \" Expected target-based directive.\");\n}\n\nvoid CGOpenMPRuntime::processRequiresDirective(const OMPRequiresDecl *D) {\n  for (const OMPClause *Clause : D->clauselists()) {\n    if (Clause->getClauseKind() == OMPC_unified_shared_memory) {\n      HasRequiresUnifiedSharedMemory = true;\n    } else if (const auto *AC =\n                   dyn_cast<OMPAtomicDefaultMemOrderClause>(Clause)) {\n      switch (AC->getAtomicDefaultMemOrderKind()) {\n      case OMPC_ATOMIC_DEFAULT_MEM_ORDER_acq_rel:\n        RequiresAtomicOrdering = llvm::AtomicOrdering::AcquireRelease;\n        break;\n      case OMPC_ATOMIC_DEFAULT_MEM_ORDER_seq_cst:\n        RequiresAtomicOrdering = llvm::AtomicOrdering::SequentiallyConsistent;\n        break;\n      case OMPC_ATOMIC_DEFAULT_MEM_ORDER_relaxed:\n        RequiresAtomicOrdering = llvm::AtomicOrdering::Monotonic;\n        break;\n      case OMPC_ATOMIC_DEFAULT_MEM_ORDER_unknown:\n        break;\n      }\n    }\n  }\n}\n\nllvm::AtomicOrdering CGOpenMPRuntime::getDefaultMemoryOrdering() const {\n  return RequiresAtomicOrdering;\n}\n\nbool CGOpenMPRuntime::hasAllocateAttributeForGlobalVar(const VarDecl *VD,\n                                                       LangAS &AS) {\n  if (!VD || !VD->hasAttr<OMPAllocateDeclAttr>())\n    return false;\n  const auto *A = VD->getAttr<OMPAllocateDeclAttr>();\n  switch(A->getAllocatorType()) {\n  case OMPAllocateDeclAttr::OMPNullMemAlloc:\n  case OMPAllocateDeclAttr::OMPDefaultMemAlloc:\n  // Not supported, fallback to the default mem space.\n  case OMPAllocateDeclAttr::OMPLargeCapMemAlloc:\n  case OMPAllocateDeclAttr::OMPCGroupMemAlloc:\n  case OMPAllocateDeclAttr::OMPHighBWMemAlloc:\n  case OMPAllocateDeclAttr::OMPLowLatMemAlloc:\n  case OMPAllocateDeclAttr::OMPThreadMemAlloc:\n  case OMPAllocateDeclAttr::OMPConstMemAlloc:\n  case OMPAllocateDeclAttr::OMPPTeamMemAlloc:\n    AS = LangAS::Default;\n    return true;\n  case OMPAllocateDeclAttr::OMPUserDefinedMemAlloc:\n    llvm_unreachable(\"Expected predefined allocator for the variables with the \"\n                     \"static storage.\");\n  }\n  return false;\n}\n\nbool CGOpenMPRuntime::hasRequiresUnifiedSharedMemory() const {\n  return HasRequiresUnifiedSharedMemory;\n}\n\nCGOpenMPRuntime::DisableAutoDeclareTargetRAII::DisableAutoDeclareTargetRAII(\n    CodeGenModule &CGM)\n    : CGM(CGM) {\n  if (CGM.getLangOpts().OpenMPIsDevice) {\n    SavedShouldMarkAsGlobal = CGM.getOpenMPRuntime().ShouldMarkAsGlobal;\n    CGM.getOpenMPRuntime().ShouldMarkAsGlobal = false;\n  }\n}\n\nCGOpenMPRuntime::DisableAutoDeclareTargetRAII::~DisableAutoDeclareTargetRAII() {\n  if (CGM.getLangOpts().OpenMPIsDevice)\n    CGM.getOpenMPRuntime().ShouldMarkAsGlobal = SavedShouldMarkAsGlobal;\n}\n\nbool CGOpenMPRuntime::markAsGlobalTarget(GlobalDecl GD) {\n  if (!CGM.getLangOpts().OpenMPIsDevice || !ShouldMarkAsGlobal)\n    return true;\n\n  const auto *D = cast<FunctionDecl>(GD.getDecl());\n  // Do not to emit function if it is marked as declare target as it was already\n  // emitted.\n  if (OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(D)) {\n    if (D->hasBody() && AlreadyEmittedTargetDecls.count(D) == 0) {\n      if (auto *F = dyn_cast_or_null<llvm::Function>(\n              CGM.GetGlobalValue(CGM.getMangledName(GD))))\n        return !F->isDeclaration();\n      return false;\n    }\n    return true;\n  }\n\n  return !AlreadyEmittedTargetDecls.insert(D).second;\n}\n\nllvm::Function *CGOpenMPRuntime::emitRequiresDirectiveRegFun() {\n  // If we don't have entries or if we are emitting code for the device, we\n  // don't need to do anything.\n  if (CGM.getLangOpts().OMPTargetTriples.empty() ||\n      CGM.getLangOpts().OpenMPSimd || CGM.getLangOpts().OpenMPIsDevice ||\n      (OffloadEntriesInfoManager.empty() &&\n       !HasEmittedDeclareTargetRegion &&\n       !HasEmittedTargetRegion))\n    return nullptr;\n\n  // Create and register the function that handles the requires directives.\n  ASTContext &C = CGM.getContext();\n\n  llvm::Function *RequiresRegFn;\n  {\n    CodeGenFunction CGF(CGM);\n    const auto &FI = CGM.getTypes().arrangeNullaryFunction();\n    llvm::FunctionType *FTy = CGM.getTypes().GetFunctionType(FI);\n    std::string ReqName = getName({\"omp_offloading\", \"requires_reg\"});\n    RequiresRegFn = CGM.CreateGlobalInitOrCleanUpFunction(FTy, ReqName, FI);\n    CGF.StartFunction(GlobalDecl(), C.VoidTy, RequiresRegFn, FI, {});\n    OpenMPOffloadingRequiresDirFlags Flags = OMP_REQ_NONE;\n    // TODO: check for other requires clauses.\n    // The requires directive takes effect only when a target region is\n    // present in the compilation unit. Otherwise it is ignored and not\n    // passed to the runtime. This avoids the runtime from throwing an error\n    // for mismatching requires clauses across compilation units that don't\n    // contain at least 1 target region.\n    assert((HasEmittedTargetRegion ||\n            HasEmittedDeclareTargetRegion ||\n            !OffloadEntriesInfoManager.empty()) &&\n           \"Target or declare target region expected.\");\n    if (HasRequiresUnifiedSharedMemory)\n      Flags = OMP_REQ_UNIFIED_SHARED_MEMORY;\n    CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                            CGM.getModule(), OMPRTL___tgt_register_requires),\n                        llvm::ConstantInt::get(CGM.Int64Ty, Flags));\n    CGF.FinishFunction();\n  }\n  return RequiresRegFn;\n}\n\nvoid CGOpenMPRuntime::emitTeamsCall(CodeGenFunction &CGF,\n                                    const OMPExecutableDirective &D,\n                                    SourceLocation Loc,\n                                    llvm::Function *OutlinedFn,\n                                    ArrayRef<llvm::Value *> CapturedVars) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  llvm::Value *RTLoc = emitUpdateLocation(CGF, Loc);\n  CodeGenFunction::RunCleanupsScope Scope(CGF);\n\n  // Build call __kmpc_fork_teams(loc, n, microtask, var1, .., varn);\n  llvm::Value *Args[] = {\n      RTLoc,\n      CGF.Builder.getInt32(CapturedVars.size()), // Number of captured vars\n      CGF.Builder.CreateBitCast(OutlinedFn, getKmpc_MicroPointerTy())};\n  llvm::SmallVector<llvm::Value *, 16> RealArgs;\n  RealArgs.append(std::begin(Args), std::end(Args));\n  RealArgs.append(CapturedVars.begin(), CapturedVars.end());\n\n  llvm::FunctionCallee RTLFn = OMPBuilder.getOrCreateRuntimeFunction(\n      CGM.getModule(), OMPRTL___kmpc_fork_teams);\n  CGF.EmitRuntimeCall(RTLFn, RealArgs);\n}\n\nvoid CGOpenMPRuntime::emitNumTeamsClause(CodeGenFunction &CGF,\n                                         const Expr *NumTeams,\n                                         const Expr *ThreadLimit,\n                                         SourceLocation Loc) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  llvm::Value *RTLoc = emitUpdateLocation(CGF, Loc);\n\n  llvm::Value *NumTeamsVal =\n      NumTeams\n          ? CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(NumTeams),\n                                      CGF.CGM.Int32Ty, /* isSigned = */ true)\n          : CGF.Builder.getInt32(0);\n\n  llvm::Value *ThreadLimitVal =\n      ThreadLimit\n          ? CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(ThreadLimit),\n                                      CGF.CGM.Int32Ty, /* isSigned = */ true)\n          : CGF.Builder.getInt32(0);\n\n  // Build call __kmpc_push_num_teamss(&loc, global_tid, num_teams, thread_limit)\n  llvm::Value *PushNumTeamsArgs[] = {RTLoc, getThreadID(CGF, Loc), NumTeamsVal,\n                                     ThreadLimitVal};\n  CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                          CGM.getModule(), OMPRTL___kmpc_push_num_teams),\n                      PushNumTeamsArgs);\n}\n\nvoid CGOpenMPRuntime::emitTargetDataCalls(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D, const Expr *IfCond,\n    const Expr *Device, const RegionCodeGenTy &CodeGen, TargetDataInfo &Info) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  // Action used to replace the default codegen action and turn privatization\n  // off.\n  PrePostActionTy NoPrivAction;\n\n  // Generate the code for the opening of the data environment. Capture all the\n  // arguments of the runtime call by reference because they are used in the\n  // closing of the region.\n  auto &&BeginThenGen = [this, &D, Device, &Info,\n                         &CodeGen](CodeGenFunction &CGF, PrePostActionTy &) {\n    // Fill up the arrays with all the mapped variables.\n    MappableExprsHandler::MapCombinedInfoTy CombinedInfo;\n\n    // Get map clause information.\n    MappableExprsHandler MEHandler(D, CGF);\n    MEHandler.generateAllInfo(CombinedInfo);\n\n    // Fill up the arrays and create the arguments.\n    emitOffloadingArrays(CGF, CombinedInfo, Info, OMPBuilder,\n                         /*IsNonContiguous=*/true);\n\n    llvm::Value *BasePointersArrayArg = nullptr;\n    llvm::Value *PointersArrayArg = nullptr;\n    llvm::Value *SizesArrayArg = nullptr;\n    llvm::Value *MapTypesArrayArg = nullptr;\n    llvm::Value *MapNamesArrayArg = nullptr;\n    llvm::Value *MappersArrayArg = nullptr;\n    emitOffloadingArraysArgument(CGF, BasePointersArrayArg, PointersArrayArg,\n                                 SizesArrayArg, MapTypesArrayArg,\n                                 MapNamesArrayArg, MappersArrayArg, Info);\n\n    // Emit device ID if any.\n    llvm::Value *DeviceID = nullptr;\n    if (Device) {\n      DeviceID = CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(Device),\n                                           CGF.Int64Ty, /*isSigned=*/true);\n    } else {\n      DeviceID = CGF.Builder.getInt64(OMP_DEVICEID_UNDEF);\n    }\n\n    // Emit the number of elements in the offloading arrays.\n    llvm::Value *PointerNum = CGF.Builder.getInt32(Info.NumberOfPtrs);\n    //\n    // Source location for the ident struct\n    llvm::Value *RTLoc = emitUpdateLocation(CGF, D.getBeginLoc());\n\n    llvm::Value *OffloadingArgs[] = {RTLoc,\n                                     DeviceID,\n                                     PointerNum,\n                                     BasePointersArrayArg,\n                                     PointersArrayArg,\n                                     SizesArrayArg,\n                                     MapTypesArrayArg,\n                                     MapNamesArrayArg,\n                                     MappersArrayArg};\n    CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(\n            CGM.getModule(), OMPRTL___tgt_target_data_begin_mapper),\n        OffloadingArgs);\n\n    // If device pointer privatization is required, emit the body of the region\n    // here. It will have to be duplicated: with and without privatization.\n    if (!Info.CaptureDeviceAddrMap.empty())\n      CodeGen(CGF);\n  };\n\n  // Generate code for the closing of the data region.\n  auto &&EndThenGen = [this, Device, &Info, &D](CodeGenFunction &CGF,\n                                                PrePostActionTy &) {\n    assert(Info.isValid() && \"Invalid data environment closing arguments.\");\n\n    llvm::Value *BasePointersArrayArg = nullptr;\n    llvm::Value *PointersArrayArg = nullptr;\n    llvm::Value *SizesArrayArg = nullptr;\n    llvm::Value *MapTypesArrayArg = nullptr;\n    llvm::Value *MapNamesArrayArg = nullptr;\n    llvm::Value *MappersArrayArg = nullptr;\n    emitOffloadingArraysArgument(CGF, BasePointersArrayArg, PointersArrayArg,\n                                 SizesArrayArg, MapTypesArrayArg,\n                                 MapNamesArrayArg, MappersArrayArg, Info,\n                                 {/*ForEndCall=*/true});\n\n    // Emit device ID if any.\n    llvm::Value *DeviceID = nullptr;\n    if (Device) {\n      DeviceID = CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(Device),\n                                           CGF.Int64Ty, /*isSigned=*/true);\n    } else {\n      DeviceID = CGF.Builder.getInt64(OMP_DEVICEID_UNDEF);\n    }\n\n    // Emit the number of elements in the offloading arrays.\n    llvm::Value *PointerNum = CGF.Builder.getInt32(Info.NumberOfPtrs);\n\n    // Source location for the ident struct\n    llvm::Value *RTLoc = emitUpdateLocation(CGF, D.getBeginLoc());\n\n    llvm::Value *OffloadingArgs[] = {RTLoc,\n                                     DeviceID,\n                                     PointerNum,\n                                     BasePointersArrayArg,\n                                     PointersArrayArg,\n                                     SizesArrayArg,\n                                     MapTypesArrayArg,\n                                     MapNamesArrayArg,\n                                     MappersArrayArg};\n    CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(\n            CGM.getModule(), OMPRTL___tgt_target_data_end_mapper),\n        OffloadingArgs);\n  };\n\n  // If we need device pointer privatization, we need to emit the body of the\n  // region with no privatization in the 'else' branch of the conditional.\n  // Otherwise, we don't have to do anything.\n  auto &&BeginElseGen = [&Info, &CodeGen, &NoPrivAction](CodeGenFunction &CGF,\n                                                         PrePostActionTy &) {\n    if (!Info.CaptureDeviceAddrMap.empty()) {\n      CodeGen.setAction(NoPrivAction);\n      CodeGen(CGF);\n    }\n  };\n\n  // We don't have to do anything to close the region if the if clause evaluates\n  // to false.\n  auto &&EndElseGen = [](CodeGenFunction &CGF, PrePostActionTy &) {};\n\n  if (IfCond) {\n    emitIfClause(CGF, IfCond, BeginThenGen, BeginElseGen);\n  } else {\n    RegionCodeGenTy RCG(BeginThenGen);\n    RCG(CGF);\n  }\n\n  // If we don't require privatization of device pointers, we emit the body in\n  // between the runtime calls. This avoids duplicating the body code.\n  if (Info.CaptureDeviceAddrMap.empty()) {\n    CodeGen.setAction(NoPrivAction);\n    CodeGen(CGF);\n  }\n\n  if (IfCond) {\n    emitIfClause(CGF, IfCond, EndThenGen, EndElseGen);\n  } else {\n    RegionCodeGenTy RCG(EndThenGen);\n    RCG(CGF);\n  }\n}\n\nvoid CGOpenMPRuntime::emitTargetDataStandAloneCall(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D, const Expr *IfCond,\n    const Expr *Device) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  assert((isa<OMPTargetEnterDataDirective>(D) ||\n          isa<OMPTargetExitDataDirective>(D) ||\n          isa<OMPTargetUpdateDirective>(D)) &&\n         \"Expecting either target enter, exit data, or update directives.\");\n\n  CodeGenFunction::OMPTargetDataInfo InputInfo;\n  llvm::Value *MapTypesArray = nullptr;\n  llvm::Value *MapNamesArray = nullptr;\n  // Generate the code for the opening of the data environment.\n  auto &&ThenGen = [this, &D, Device, &InputInfo, &MapTypesArray,\n                    &MapNamesArray](CodeGenFunction &CGF, PrePostActionTy &) {\n    // Emit device ID if any.\n    llvm::Value *DeviceID = nullptr;\n    if (Device) {\n      DeviceID = CGF.Builder.CreateIntCast(CGF.EmitScalarExpr(Device),\n                                           CGF.Int64Ty, /*isSigned=*/true);\n    } else {\n      DeviceID = CGF.Builder.getInt64(OMP_DEVICEID_UNDEF);\n    }\n\n    // Emit the number of elements in the offloading arrays.\n    llvm::Constant *PointerNum =\n        CGF.Builder.getInt32(InputInfo.NumberOfTargetItems);\n\n    // Source location for the ident struct\n    llvm::Value *RTLoc = emitUpdateLocation(CGF, D.getBeginLoc());\n\n    llvm::Value *OffloadingArgs[] = {RTLoc,\n                                     DeviceID,\n                                     PointerNum,\n                                     InputInfo.BasePointersArray.getPointer(),\n                                     InputInfo.PointersArray.getPointer(),\n                                     InputInfo.SizesArray.getPointer(),\n                                     MapTypesArray,\n                                     MapNamesArray,\n                                     InputInfo.MappersArray.getPointer()};\n\n    // Select the right runtime function call for each standalone\n    // directive.\n    const bool HasNowait = D.hasClausesOfKind<OMPNowaitClause>();\n    RuntimeFunction RTLFn;\n    switch (D.getDirectiveKind()) {\n    case OMPD_target_enter_data:\n      RTLFn = HasNowait ? OMPRTL___tgt_target_data_begin_nowait_mapper\n                        : OMPRTL___tgt_target_data_begin_mapper;\n      break;\n    case OMPD_target_exit_data:\n      RTLFn = HasNowait ? OMPRTL___tgt_target_data_end_nowait_mapper\n                        : OMPRTL___tgt_target_data_end_mapper;\n      break;\n    case OMPD_target_update:\n      RTLFn = HasNowait ? OMPRTL___tgt_target_data_update_nowait_mapper\n                        : OMPRTL___tgt_target_data_update_mapper;\n      break;\n    case OMPD_parallel:\n    case OMPD_for:\n    case OMPD_parallel_for:\n    case OMPD_parallel_master:\n    case OMPD_parallel_sections:\n    case OMPD_for_simd:\n    case OMPD_parallel_for_simd:\n    case OMPD_cancel:\n    case OMPD_cancellation_point:\n    case OMPD_ordered:\n    case OMPD_threadprivate:\n    case OMPD_allocate:\n    case OMPD_task:\n    case OMPD_simd:\n    case OMPD_tile:\n    case OMPD_sections:\n    case OMPD_section:\n    case OMPD_single:\n    case OMPD_master:\n    case OMPD_critical:\n    case OMPD_taskyield:\n    case OMPD_barrier:\n    case OMPD_taskwait:\n    case OMPD_taskgroup:\n    case OMPD_atomic:\n    case OMPD_flush:\n    case OMPD_depobj:\n    case OMPD_scan:\n    case OMPD_teams:\n    case OMPD_target_data:\n    case OMPD_distribute:\n    case OMPD_distribute_simd:\n    case OMPD_distribute_parallel_for:\n    case OMPD_distribute_parallel_for_simd:\n    case OMPD_teams_distribute:\n    case OMPD_teams_distribute_simd:\n    case OMPD_teams_distribute_parallel_for:\n    case OMPD_teams_distribute_parallel_for_simd:\n    case OMPD_declare_simd:\n    case OMPD_declare_variant:\n    case OMPD_begin_declare_variant:\n    case OMPD_end_declare_variant:\n    case OMPD_declare_target:\n    case OMPD_end_declare_target:\n    case OMPD_declare_reduction:\n    case OMPD_declare_mapper:\n    case OMPD_taskloop:\n    case OMPD_taskloop_simd:\n    case OMPD_master_taskloop:\n    case OMPD_master_taskloop_simd:\n    case OMPD_parallel_master_taskloop:\n    case OMPD_parallel_master_taskloop_simd:\n    case OMPD_target:\n    case OMPD_target_simd:\n    case OMPD_target_teams_distribute:\n    case OMPD_target_teams_distribute_simd:\n    case OMPD_target_teams_distribute_parallel_for:\n    case OMPD_target_teams_distribute_parallel_for_simd:\n    case OMPD_target_teams:\n    case OMPD_target_parallel:\n    case OMPD_target_parallel_for:\n    case OMPD_target_parallel_for_simd:\n    case OMPD_requires:\n    case OMPD_unknown:\n    default:\n      llvm_unreachable(\"Unexpected standalone target data directive.\");\n      break;\n    }\n    CGF.EmitRuntimeCall(\n        OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(), RTLFn),\n        OffloadingArgs);\n  };\n\n  auto &&TargetThenGen = [this, &ThenGen, &D, &InputInfo, &MapTypesArray,\n                          &MapNamesArray](CodeGenFunction &CGF,\n                                          PrePostActionTy &) {\n    // Fill up the arrays with all the mapped variables.\n    MappableExprsHandler::MapCombinedInfoTy CombinedInfo;\n\n    // Get map clause information.\n    MappableExprsHandler MEHandler(D, CGF);\n    MEHandler.generateAllInfo(CombinedInfo);\n\n    TargetDataInfo Info;\n    // Fill up the arrays and create the arguments.\n    emitOffloadingArrays(CGF, CombinedInfo, Info, OMPBuilder,\n                         /*IsNonContiguous=*/true);\n    bool RequiresOuterTask = D.hasClausesOfKind<OMPDependClause>() ||\n                             D.hasClausesOfKind<OMPNowaitClause>();\n    emitOffloadingArraysArgument(\n        CGF, Info.BasePointersArray, Info.PointersArray, Info.SizesArray,\n        Info.MapTypesArray, Info.MapNamesArray, Info.MappersArray, Info,\n        {/*ForEndTask=*/false});\n    InputInfo.NumberOfTargetItems = Info.NumberOfPtrs;\n    InputInfo.BasePointersArray =\n        Address(Info.BasePointersArray, CGM.getPointerAlign());\n    InputInfo.PointersArray =\n        Address(Info.PointersArray, CGM.getPointerAlign());\n    InputInfo.SizesArray =\n        Address(Info.SizesArray, CGM.getPointerAlign());\n    InputInfo.MappersArray = Address(Info.MappersArray, CGM.getPointerAlign());\n    MapTypesArray = Info.MapTypesArray;\n    MapNamesArray = Info.MapNamesArray;\n    if (RequiresOuterTask)\n      CGF.EmitOMPTargetTaskBasedDirective(D, ThenGen, InputInfo);\n    else\n      emitInlinedDirective(CGF, D.getDirectiveKind(), ThenGen);\n  };\n\n  if (IfCond) {\n    emitIfClause(CGF, IfCond, TargetThenGen,\n                 [](CodeGenFunction &CGF, PrePostActionTy &) {});\n  } else {\n    RegionCodeGenTy ThenRCG(TargetThenGen);\n    ThenRCG(CGF);\n  }\n}\n\nnamespace {\n  /// Kind of parameter in a function with 'declare simd' directive.\n  enum ParamKindTy { LinearWithVarStride, Linear, Uniform, Vector };\n  /// Attribute set of the parameter.\n  struct ParamAttrTy {\n    ParamKindTy Kind = Vector;\n    llvm::APSInt StrideOrArg;\n    llvm::APSInt Alignment;\n  };\n} // namespace\n\nstatic unsigned evaluateCDTSize(const FunctionDecl *FD,\n                                ArrayRef<ParamAttrTy> ParamAttrs) {\n  // Every vector variant of a SIMD-enabled function has a vector length (VLEN).\n  // If OpenMP clause \"simdlen\" is used, the VLEN is the value of the argument\n  // of that clause. The VLEN value must be power of 2.\n  // In other case the notion of the function`s \"characteristic data type\" (CDT)\n  // is used to compute the vector length.\n  // CDT is defined in the following order:\n  //   a) For non-void function, the CDT is the return type.\n  //   b) If the function has any non-uniform, non-linear parameters, then the\n  //   CDT is the type of the first such parameter.\n  //   c) If the CDT determined by a) or b) above is struct, union, or class\n  //   type which is pass-by-value (except for the type that maps to the\n  //   built-in complex data type), the characteristic data type is int.\n  //   d) If none of the above three cases is applicable, the CDT is int.\n  // The VLEN is then determined based on the CDT and the size of vector\n  // register of that ISA for which current vector version is generated. The\n  // VLEN is computed using the formula below:\n  //   VLEN  = sizeof(vector_register) / sizeof(CDT),\n  // where vector register size specified in section 3.2.1 Registers and the\n  // Stack Frame of original AMD64 ABI document.\n  QualType RetType = FD->getReturnType();\n  if (RetType.isNull())\n    return 0;\n  ASTContext &C = FD->getASTContext();\n  QualType CDT;\n  if (!RetType.isNull() && !RetType->isVoidType()) {\n    CDT = RetType;\n  } else {\n    unsigned Offset = 0;\n    if (const auto *MD = dyn_cast<CXXMethodDecl>(FD)) {\n      if (ParamAttrs[Offset].Kind == Vector)\n        CDT = C.getPointerType(C.getRecordType(MD->getParent()));\n      ++Offset;\n    }\n    if (CDT.isNull()) {\n      for (unsigned I = 0, E = FD->getNumParams(); I < E; ++I) {\n        if (ParamAttrs[I + Offset].Kind == Vector) {\n          CDT = FD->getParamDecl(I)->getType();\n          break;\n        }\n      }\n    }\n  }\n  if (CDT.isNull())\n    CDT = C.IntTy;\n  CDT = CDT->getCanonicalTypeUnqualified();\n  if (CDT->isRecordType() || CDT->isUnionType())\n    CDT = C.IntTy;\n  return C.getTypeSize(CDT);\n}\n\nstatic void\nemitX86DeclareSimdFunction(const FunctionDecl *FD, llvm::Function *Fn,\n                           const llvm::APSInt &VLENVal,\n                           ArrayRef<ParamAttrTy> ParamAttrs,\n                           OMPDeclareSimdDeclAttr::BranchStateTy State) {\n  struct ISADataTy {\n    char ISA;\n    unsigned VecRegSize;\n  };\n  ISADataTy ISAData[] = {\n      {\n          'b', 128\n      }, // SSE\n      {\n          'c', 256\n      }, // AVX\n      {\n          'd', 256\n      }, // AVX2\n      {\n          'e', 512\n      }, // AVX512\n  };\n  llvm::SmallVector<char, 2> Masked;\n  switch (State) {\n  case OMPDeclareSimdDeclAttr::BS_Undefined:\n    Masked.push_back('N');\n    Masked.push_back('M');\n    break;\n  case OMPDeclareSimdDeclAttr::BS_Notinbranch:\n    Masked.push_back('N');\n    break;\n  case OMPDeclareSimdDeclAttr::BS_Inbranch:\n    Masked.push_back('M');\n    break;\n  }\n  for (char Mask : Masked) {\n    for (const ISADataTy &Data : ISAData) {\n      SmallString<256> Buffer;\n      llvm::raw_svector_ostream Out(Buffer);\n      Out << \"_ZGV\" << Data.ISA << Mask;\n      if (!VLENVal) {\n        unsigned NumElts = evaluateCDTSize(FD, ParamAttrs);\n        assert(NumElts && \"Non-zero simdlen/cdtsize expected\");\n        Out << llvm::APSInt::getUnsigned(Data.VecRegSize / NumElts);\n      } else {\n        Out << VLENVal;\n      }\n      for (const ParamAttrTy &ParamAttr : ParamAttrs) {\n        switch (ParamAttr.Kind){\n        case LinearWithVarStride:\n          Out << 's' << ParamAttr.StrideOrArg;\n          break;\n        case Linear:\n          Out << 'l';\n          if (ParamAttr.StrideOrArg != 1)\n            Out << ParamAttr.StrideOrArg;\n          break;\n        case Uniform:\n          Out << 'u';\n          break;\n        case Vector:\n          Out << 'v';\n          break;\n        }\n        if (!!ParamAttr.Alignment)\n          Out << 'a' << ParamAttr.Alignment;\n      }\n      Out << '_' << Fn->getName();\n      Fn->addFnAttr(Out.str());\n    }\n  }\n}\n\n// This are the Functions that are needed to mangle the name of the\n// vector functions generated by the compiler, according to the rules\n// defined in the \"Vector Function ABI specifications for AArch64\",\n// available at\n// https://developer.arm.com/products/software-development-tools/hpc/arm-compiler-for-hpc/vector-function-abi.\n\n/// Maps To Vector (MTV), as defined in 3.1.1 of the AAVFABI.\n///\n/// TODO: Need to implement the behavior for reference marked with a\n/// var or no linear modifiers (1.b in the section). For this, we\n/// need to extend ParamKindTy to support the linear modifiers.\nstatic bool getAArch64MTV(QualType QT, ParamKindTy Kind) {\n  QT = QT.getCanonicalType();\n\n  if (QT->isVoidType())\n    return false;\n\n  if (Kind == ParamKindTy::Uniform)\n    return false;\n\n  if (Kind == ParamKindTy::Linear)\n    return false;\n\n  // TODO: Handle linear references with modifiers\n\n  if (Kind == ParamKindTy::LinearWithVarStride)\n    return false;\n\n  return true;\n}\n\n/// Pass By Value (PBV), as defined in 3.1.2 of the AAVFABI.\nstatic bool getAArch64PBV(QualType QT, ASTContext &C) {\n  QT = QT.getCanonicalType();\n  unsigned Size = C.getTypeSize(QT);\n\n  // Only scalars and complex within 16 bytes wide set PVB to true.\n  if (Size != 8 && Size != 16 && Size != 32 && Size != 64 && Size != 128)\n    return false;\n\n  if (QT->isFloatingType())\n    return true;\n\n  if (QT->isIntegerType())\n    return true;\n\n  if (QT->isPointerType())\n    return true;\n\n  // TODO: Add support for complex types (section 3.1.2, item 2).\n\n  return false;\n}\n\n/// Computes the lane size (LS) of a return type or of an input parameter,\n/// as defined by `LS(P)` in 3.2.1 of the AAVFABI.\n/// TODO: Add support for references, section 3.2.1, item 1.\nstatic unsigned getAArch64LS(QualType QT, ParamKindTy Kind, ASTContext &C) {\n  if (!getAArch64MTV(QT, Kind) && QT.getCanonicalType()->isPointerType()) {\n    QualType PTy = QT.getCanonicalType()->getPointeeType();\n    if (getAArch64PBV(PTy, C))\n      return C.getTypeSize(PTy);\n  }\n  if (getAArch64PBV(QT, C))\n    return C.getTypeSize(QT);\n\n  return C.getTypeSize(C.getUIntPtrType());\n}\n\n// Get Narrowest Data Size (NDS) and Widest Data Size (WDS) from the\n// signature of the scalar function, as defined in 3.2.2 of the\n// AAVFABI.\nstatic std::tuple<unsigned, unsigned, bool>\ngetNDSWDS(const FunctionDecl *FD, ArrayRef<ParamAttrTy> ParamAttrs) {\n  QualType RetType = FD->getReturnType().getCanonicalType();\n\n  ASTContext &C = FD->getASTContext();\n\n  bool OutputBecomesInput = false;\n\n  llvm::SmallVector<unsigned, 8> Sizes;\n  if (!RetType->isVoidType()) {\n    Sizes.push_back(getAArch64LS(RetType, ParamKindTy::Vector, C));\n    if (!getAArch64PBV(RetType, C) && getAArch64MTV(RetType, {}))\n      OutputBecomesInput = true;\n  }\n  for (unsigned I = 0, E = FD->getNumParams(); I < E; ++I) {\n    QualType QT = FD->getParamDecl(I)->getType().getCanonicalType();\n    Sizes.push_back(getAArch64LS(QT, ParamAttrs[I].Kind, C));\n  }\n\n  assert(!Sizes.empty() && \"Unable to determine NDS and WDS.\");\n  // The LS of a function parameter / return value can only be a power\n  // of 2, starting from 8 bits, up to 128.\n  assert(std::all_of(Sizes.begin(), Sizes.end(),\n                     [](unsigned Size) {\n                       return Size == 8 || Size == 16 || Size == 32 ||\n                              Size == 64 || Size == 128;\n                     }) &&\n         \"Invalid size\");\n\n  return std::make_tuple(*std::min_element(std::begin(Sizes), std::end(Sizes)),\n                         *std::max_element(std::begin(Sizes), std::end(Sizes)),\n                         OutputBecomesInput);\n}\n\n/// Mangle the parameter part of the vector function name according to\n/// their OpenMP classification. The mangling function is defined in\n/// section 3.5 of the AAVFABI.\nstatic std::string mangleVectorParameters(ArrayRef<ParamAttrTy> ParamAttrs) {\n  SmallString<256> Buffer;\n  llvm::raw_svector_ostream Out(Buffer);\n  for (const auto &ParamAttr : ParamAttrs) {\n    switch (ParamAttr.Kind) {\n    case LinearWithVarStride:\n      Out << \"ls\" << ParamAttr.StrideOrArg;\n      break;\n    case Linear:\n      Out << 'l';\n      // Don't print the step value if it is not present or if it is\n      // equal to 1.\n      if (ParamAttr.StrideOrArg != 1)\n        Out << ParamAttr.StrideOrArg;\n      break;\n    case Uniform:\n      Out << 'u';\n      break;\n    case Vector:\n      Out << 'v';\n      break;\n    }\n\n    if (!!ParamAttr.Alignment)\n      Out << 'a' << ParamAttr.Alignment;\n  }\n\n  return std::string(Out.str());\n}\n\n// Function used to add the attribute. The parameter `VLEN` is\n// templated to allow the use of \"x\" when targeting scalable functions\n// for SVE.\ntemplate <typename T>\nstatic void addAArch64VectorName(T VLEN, StringRef LMask, StringRef Prefix,\n                                 char ISA, StringRef ParSeq,\n                                 StringRef MangledName, bool OutputBecomesInput,\n                                 llvm::Function *Fn) {\n  SmallString<256> Buffer;\n  llvm::raw_svector_ostream Out(Buffer);\n  Out << Prefix << ISA << LMask << VLEN;\n  if (OutputBecomesInput)\n    Out << \"v\";\n  Out << ParSeq << \"_\" << MangledName;\n  Fn->addFnAttr(Out.str());\n}\n\n// Helper function to generate the Advanced SIMD names depending on\n// the value of the NDS when simdlen is not present.\nstatic void addAArch64AdvSIMDNDSNames(unsigned NDS, StringRef Mask,\n                                      StringRef Prefix, char ISA,\n                                      StringRef ParSeq, StringRef MangledName,\n                                      bool OutputBecomesInput,\n                                      llvm::Function *Fn) {\n  switch (NDS) {\n  case 8:\n    addAArch64VectorName(8, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    addAArch64VectorName(16, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    break;\n  case 16:\n    addAArch64VectorName(4, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    addAArch64VectorName(8, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    break;\n  case 32:\n    addAArch64VectorName(2, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    addAArch64VectorName(4, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    break;\n  case 64:\n  case 128:\n    addAArch64VectorName(2, Mask, Prefix, ISA, ParSeq, MangledName,\n                         OutputBecomesInput, Fn);\n    break;\n  default:\n    llvm_unreachable(\"Scalar type is too wide.\");\n  }\n}\n\n/// Emit vector function attributes for AArch64, as defined in the AAVFABI.\nstatic void emitAArch64DeclareSimdFunction(\n    CodeGenModule &CGM, const FunctionDecl *FD, unsigned UserVLEN,\n    ArrayRef<ParamAttrTy> ParamAttrs,\n    OMPDeclareSimdDeclAttr::BranchStateTy State, StringRef MangledName,\n    char ISA, unsigned VecRegSize, llvm::Function *Fn, SourceLocation SLoc) {\n\n  // Get basic data for building the vector signature.\n  const auto Data = getNDSWDS(FD, ParamAttrs);\n  const unsigned NDS = std::get<0>(Data);\n  const unsigned WDS = std::get<1>(Data);\n  const bool OutputBecomesInput = std::get<2>(Data);\n\n  // Check the values provided via `simdlen` by the user.\n  // 1. A `simdlen(1)` doesn't produce vector signatures,\n  if (UserVLEN == 1) {\n    unsigned DiagID = CGM.getDiags().getCustomDiagID(\n        DiagnosticsEngine::Warning,\n        \"The clause simdlen(1) has no effect when targeting aarch64.\");\n    CGM.getDiags().Report(SLoc, DiagID);\n    return;\n  }\n\n  // 2. Section 3.3.1, item 1: user input must be a power of 2 for\n  // Advanced SIMD output.\n  if (ISA == 'n' && UserVLEN && !llvm::isPowerOf2_32(UserVLEN)) {\n    unsigned DiagID = CGM.getDiags().getCustomDiagID(\n        DiagnosticsEngine::Warning, \"The value specified in simdlen must be a \"\n                                    \"power of 2 when targeting Advanced SIMD.\");\n    CGM.getDiags().Report(SLoc, DiagID);\n    return;\n  }\n\n  // 3. Section 3.4.1. SVE fixed lengh must obey the architectural\n  // limits.\n  if (ISA == 's' && UserVLEN != 0) {\n    if ((UserVLEN * WDS > 2048) || (UserVLEN * WDS % 128 != 0)) {\n      unsigned DiagID = CGM.getDiags().getCustomDiagID(\n          DiagnosticsEngine::Warning, \"The clause simdlen must fit the %0-bit \"\n                                      \"lanes in the architectural constraints \"\n                                      \"for SVE (min is 128-bit, max is \"\n                                      \"2048-bit, by steps of 128-bit)\");\n      CGM.getDiags().Report(SLoc, DiagID) << WDS;\n      return;\n    }\n  }\n\n  // Sort out parameter sequence.\n  const std::string ParSeq = mangleVectorParameters(ParamAttrs);\n  StringRef Prefix = \"_ZGV\";\n  // Generate simdlen from user input (if any).\n  if (UserVLEN) {\n    if (ISA == 's') {\n      // SVE generates only a masked function.\n      addAArch64VectorName(UserVLEN, \"M\", Prefix, ISA, ParSeq, MangledName,\n                           OutputBecomesInput, Fn);\n    } else {\n      assert(ISA == 'n' && \"Expected ISA either 's' or 'n'.\");\n      // Advanced SIMD generates one or two functions, depending on\n      // the `[not]inbranch` clause.\n      switch (State) {\n      case OMPDeclareSimdDeclAttr::BS_Undefined:\n        addAArch64VectorName(UserVLEN, \"N\", Prefix, ISA, ParSeq, MangledName,\n                             OutputBecomesInput, Fn);\n        addAArch64VectorName(UserVLEN, \"M\", Prefix, ISA, ParSeq, MangledName,\n                             OutputBecomesInput, Fn);\n        break;\n      case OMPDeclareSimdDeclAttr::BS_Notinbranch:\n        addAArch64VectorName(UserVLEN, \"N\", Prefix, ISA, ParSeq, MangledName,\n                             OutputBecomesInput, Fn);\n        break;\n      case OMPDeclareSimdDeclAttr::BS_Inbranch:\n        addAArch64VectorName(UserVLEN, \"M\", Prefix, ISA, ParSeq, MangledName,\n                             OutputBecomesInput, Fn);\n        break;\n      }\n    }\n  } else {\n    // If no user simdlen is provided, follow the AAVFABI rules for\n    // generating the vector length.\n    if (ISA == 's') {\n      // SVE, section 3.4.1, item 1.\n      addAArch64VectorName(\"x\", \"M\", Prefix, ISA, ParSeq, MangledName,\n                           OutputBecomesInput, Fn);\n    } else {\n      assert(ISA == 'n' && \"Expected ISA either 's' or 'n'.\");\n      // Advanced SIMD, Section 3.3.1 of the AAVFABI, generates one or\n      // two vector names depending on the use of the clause\n      // `[not]inbranch`.\n      switch (State) {\n      case OMPDeclareSimdDeclAttr::BS_Undefined:\n        addAArch64AdvSIMDNDSNames(NDS, \"N\", Prefix, ISA, ParSeq, MangledName,\n                                  OutputBecomesInput, Fn);\n        addAArch64AdvSIMDNDSNames(NDS, \"M\", Prefix, ISA, ParSeq, MangledName,\n                                  OutputBecomesInput, Fn);\n        break;\n      case OMPDeclareSimdDeclAttr::BS_Notinbranch:\n        addAArch64AdvSIMDNDSNames(NDS, \"N\", Prefix, ISA, ParSeq, MangledName,\n                                  OutputBecomesInput, Fn);\n        break;\n      case OMPDeclareSimdDeclAttr::BS_Inbranch:\n        addAArch64AdvSIMDNDSNames(NDS, \"M\", Prefix, ISA, ParSeq, MangledName,\n                                  OutputBecomesInput, Fn);\n        break;\n      }\n    }\n  }\n}\n\nvoid CGOpenMPRuntime::emitDeclareSimdFunction(const FunctionDecl *FD,\n                                              llvm::Function *Fn) {\n  ASTContext &C = CGM.getContext();\n  FD = FD->getMostRecentDecl();\n  // Map params to their positions in function decl.\n  llvm::DenseMap<const Decl *, unsigned> ParamPositions;\n  if (isa<CXXMethodDecl>(FD))\n    ParamPositions.try_emplace(FD, 0);\n  unsigned ParamPos = ParamPositions.size();\n  for (const ParmVarDecl *P : FD->parameters()) {\n    ParamPositions.try_emplace(P->getCanonicalDecl(), ParamPos);\n    ++ParamPos;\n  }\n  while (FD) {\n    for (const auto *Attr : FD->specific_attrs<OMPDeclareSimdDeclAttr>()) {\n      llvm::SmallVector<ParamAttrTy, 8> ParamAttrs(ParamPositions.size());\n      // Mark uniform parameters.\n      for (const Expr *E : Attr->uniforms()) {\n        E = E->IgnoreParenImpCasts();\n        unsigned Pos;\n        if (isa<CXXThisExpr>(E)) {\n          Pos = ParamPositions[FD];\n        } else {\n          const auto *PVD = cast<ParmVarDecl>(cast<DeclRefExpr>(E)->getDecl())\n                                ->getCanonicalDecl();\n          Pos = ParamPositions[PVD];\n        }\n        ParamAttrs[Pos].Kind = Uniform;\n      }\n      // Get alignment info.\n      auto NI = Attr->alignments_begin();\n      for (const Expr *E : Attr->aligneds()) {\n        E = E->IgnoreParenImpCasts();\n        unsigned Pos;\n        QualType ParmTy;\n        if (isa<CXXThisExpr>(E)) {\n          Pos = ParamPositions[FD];\n          ParmTy = E->getType();\n        } else {\n          const auto *PVD = cast<ParmVarDecl>(cast<DeclRefExpr>(E)->getDecl())\n                                ->getCanonicalDecl();\n          Pos = ParamPositions[PVD];\n          ParmTy = PVD->getType();\n        }\n        ParamAttrs[Pos].Alignment =\n            (*NI)\n                ? (*NI)->EvaluateKnownConstInt(C)\n                : llvm::APSInt::getUnsigned(\n                      C.toCharUnitsFromBits(C.getOpenMPDefaultSimdAlign(ParmTy))\n                          .getQuantity());\n        ++NI;\n      }\n      // Mark linear parameters.\n      auto SI = Attr->steps_begin();\n      auto MI = Attr->modifiers_begin();\n      for (const Expr *E : Attr->linears()) {\n        E = E->IgnoreParenImpCasts();\n        unsigned Pos;\n        // Rescaling factor needed to compute the linear parameter\n        // value in the mangled name.\n        unsigned PtrRescalingFactor = 1;\n        if (isa<CXXThisExpr>(E)) {\n          Pos = ParamPositions[FD];\n        } else {\n          const auto *PVD = cast<ParmVarDecl>(cast<DeclRefExpr>(E)->getDecl())\n                                ->getCanonicalDecl();\n          Pos = ParamPositions[PVD];\n          if (auto *P = dyn_cast<PointerType>(PVD->getType()))\n            PtrRescalingFactor = CGM.getContext()\n                                     .getTypeSizeInChars(P->getPointeeType())\n                                     .getQuantity();\n        }\n        ParamAttrTy &ParamAttr = ParamAttrs[Pos];\n        ParamAttr.Kind = Linear;\n        // Assuming a stride of 1, for `linear` without modifiers.\n        ParamAttr.StrideOrArg = llvm::APSInt::getUnsigned(1);\n        if (*SI) {\n          Expr::EvalResult Result;\n          if (!(*SI)->EvaluateAsInt(Result, C, Expr::SE_AllowSideEffects)) {\n            if (const auto *DRE =\n                    cast<DeclRefExpr>((*SI)->IgnoreParenImpCasts())) {\n              if (const auto *StridePVD = cast<ParmVarDecl>(DRE->getDecl())) {\n                ParamAttr.Kind = LinearWithVarStride;\n                ParamAttr.StrideOrArg = llvm::APSInt::getUnsigned(\n                    ParamPositions[StridePVD->getCanonicalDecl()]);\n              }\n            }\n          } else {\n            ParamAttr.StrideOrArg = Result.Val.getInt();\n          }\n        }\n        // If we are using a linear clause on a pointer, we need to\n        // rescale the value of linear_step with the byte size of the\n        // pointee type.\n        if (Linear == ParamAttr.Kind)\n          ParamAttr.StrideOrArg = ParamAttr.StrideOrArg * PtrRescalingFactor;\n        ++SI;\n        ++MI;\n      }\n      llvm::APSInt VLENVal;\n      SourceLocation ExprLoc;\n      const Expr *VLENExpr = Attr->getSimdlen();\n      if (VLENExpr) {\n        VLENVal = VLENExpr->EvaluateKnownConstInt(C);\n        ExprLoc = VLENExpr->getExprLoc();\n      }\n      OMPDeclareSimdDeclAttr::BranchStateTy State = Attr->getBranchState();\n      if (CGM.getTriple().isX86()) {\n        emitX86DeclareSimdFunction(FD, Fn, VLENVal, ParamAttrs, State);\n      } else if (CGM.getTriple().getArch() == llvm::Triple::aarch64) {\n        unsigned VLEN = VLENVal.getExtValue();\n        StringRef MangledName = Fn->getName();\n        if (CGM.getTarget().hasFeature(\"sve\"))\n          emitAArch64DeclareSimdFunction(CGM, FD, VLEN, ParamAttrs, State,\n                                         MangledName, 's', 128, Fn, ExprLoc);\n        if (CGM.getTarget().hasFeature(\"neon\"))\n          emitAArch64DeclareSimdFunction(CGM, FD, VLEN, ParamAttrs, State,\n                                         MangledName, 'n', 128, Fn, ExprLoc);\n      }\n    }\n    FD = FD->getPreviousDecl();\n  }\n}\n\nnamespace {\n/// Cleanup action for doacross support.\nclass DoacrossCleanupTy final : public EHScopeStack::Cleanup {\npublic:\n  static const int DoacrossFinArgs = 2;\n\nprivate:\n  llvm::FunctionCallee RTLFn;\n  llvm::Value *Args[DoacrossFinArgs];\n\npublic:\n  DoacrossCleanupTy(llvm::FunctionCallee RTLFn,\n                    ArrayRef<llvm::Value *> CallArgs)\n      : RTLFn(RTLFn) {\n    assert(CallArgs.size() == DoacrossFinArgs);\n    std::copy(CallArgs.begin(), CallArgs.end(), std::begin(Args));\n  }\n  void Emit(CodeGenFunction &CGF, Flags /*flags*/) override {\n    if (!CGF.HaveInsertPoint())\n      return;\n    CGF.EmitRuntimeCall(RTLFn, Args);\n  }\n};\n} // namespace\n\nvoid CGOpenMPRuntime::emitDoacrossInit(CodeGenFunction &CGF,\n                                       const OMPLoopDirective &D,\n                                       ArrayRef<Expr *> NumIterations) {\n  if (!CGF.HaveInsertPoint())\n    return;\n\n  ASTContext &C = CGM.getContext();\n  QualType Int64Ty = C.getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/true);\n  RecordDecl *RD;\n  if (KmpDimTy.isNull()) {\n    // Build struct kmp_dim {  // loop bounds info casted to kmp_int64\n    //  kmp_int64 lo; // lower\n    //  kmp_int64 up; // upper\n    //  kmp_int64 st; // stride\n    // };\n    RD = C.buildImplicitRecord(\"kmp_dim\");\n    RD->startDefinition();\n    addFieldToRecordDecl(C, RD, Int64Ty);\n    addFieldToRecordDecl(C, RD, Int64Ty);\n    addFieldToRecordDecl(C, RD, Int64Ty);\n    RD->completeDefinition();\n    KmpDimTy = C.getRecordType(RD);\n  } else {\n    RD = cast<RecordDecl>(KmpDimTy->getAsTagDecl());\n  }\n  llvm::APInt Size(/*numBits=*/32, NumIterations.size());\n  QualType ArrayTy =\n      C.getConstantArrayType(KmpDimTy, Size, nullptr, ArrayType::Normal, 0);\n\n  Address DimsAddr = CGF.CreateMemTemp(ArrayTy, \"dims\");\n  CGF.EmitNullInitialization(DimsAddr, ArrayTy);\n  enum { LowerFD = 0, UpperFD, StrideFD };\n  // Fill dims with data.\n  for (unsigned I = 0, E = NumIterations.size(); I < E; ++I) {\n    LValue DimsLVal = CGF.MakeAddrLValue(\n        CGF.Builder.CreateConstArrayGEP(DimsAddr, I), KmpDimTy);\n    // dims.upper = num_iterations;\n    LValue UpperLVal = CGF.EmitLValueForField(\n        DimsLVal, *std::next(RD->field_begin(), UpperFD));\n    llvm::Value *NumIterVal = CGF.EmitScalarConversion(\n        CGF.EmitScalarExpr(NumIterations[I]), NumIterations[I]->getType(),\n        Int64Ty, NumIterations[I]->getExprLoc());\n    CGF.EmitStoreOfScalar(NumIterVal, UpperLVal);\n    // dims.stride = 1;\n    LValue StrideLVal = CGF.EmitLValueForField(\n        DimsLVal, *std::next(RD->field_begin(), StrideFD));\n    CGF.EmitStoreOfScalar(llvm::ConstantInt::getSigned(CGM.Int64Ty, /*V=*/1),\n                          StrideLVal);\n  }\n\n  // Build call void __kmpc_doacross_init(ident_t *loc, kmp_int32 gtid,\n  // kmp_int32 num_dims, struct kmp_dim * dims);\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, D.getBeginLoc()),\n      getThreadID(CGF, D.getBeginLoc()),\n      llvm::ConstantInt::getSigned(CGM.Int32Ty, NumIterations.size()),\n      CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n          CGF.Builder.CreateConstArrayGEP(DimsAddr, 0).getPointer(),\n          CGM.VoidPtrTy)};\n\n  llvm::FunctionCallee RTLFn = OMPBuilder.getOrCreateRuntimeFunction(\n      CGM.getModule(), OMPRTL___kmpc_doacross_init);\n  CGF.EmitRuntimeCall(RTLFn, Args);\n  llvm::Value *FiniArgs[DoacrossCleanupTy::DoacrossFinArgs] = {\n      emitUpdateLocation(CGF, D.getEndLoc()), getThreadID(CGF, D.getEndLoc())};\n  llvm::FunctionCallee FiniRTLFn = OMPBuilder.getOrCreateRuntimeFunction(\n      CGM.getModule(), OMPRTL___kmpc_doacross_fini);\n  CGF.EHStack.pushCleanup<DoacrossCleanupTy>(NormalAndEHCleanup, FiniRTLFn,\n                                             llvm::makeArrayRef(FiniArgs));\n}\n\nvoid CGOpenMPRuntime::emitDoacrossOrdered(CodeGenFunction &CGF,\n                                          const OMPDependClause *C) {\n  QualType Int64Ty =\n      CGM.getContext().getIntTypeForBitwidth(/*DestWidth=*/64, /*Signed=*/1);\n  llvm::APInt Size(/*numBits=*/32, C->getNumLoops());\n  QualType ArrayTy = CGM.getContext().getConstantArrayType(\n      Int64Ty, Size, nullptr, ArrayType::Normal, 0);\n  Address CntAddr = CGF.CreateMemTemp(ArrayTy, \".cnt.addr\");\n  for (unsigned I = 0, E = C->getNumLoops(); I < E; ++I) {\n    const Expr *CounterVal = C->getLoopData(I);\n    assert(CounterVal);\n    llvm::Value *CntVal = CGF.EmitScalarConversion(\n        CGF.EmitScalarExpr(CounterVal), CounterVal->getType(), Int64Ty,\n        CounterVal->getExprLoc());\n    CGF.EmitStoreOfScalar(CntVal, CGF.Builder.CreateConstArrayGEP(CntAddr, I),\n                          /*Volatile=*/false, Int64Ty);\n  }\n  llvm::Value *Args[] = {\n      emitUpdateLocation(CGF, C->getBeginLoc()),\n      getThreadID(CGF, C->getBeginLoc()),\n      CGF.Builder.CreateConstArrayGEP(CntAddr, 0).getPointer()};\n  llvm::FunctionCallee RTLFn;\n  if (C->getDependencyKind() == OMPC_DEPEND_source) {\n    RTLFn = OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                                  OMPRTL___kmpc_doacross_post);\n  } else {\n    assert(C->getDependencyKind() == OMPC_DEPEND_sink);\n    RTLFn = OMPBuilder.getOrCreateRuntimeFunction(CGM.getModule(),\n                                                  OMPRTL___kmpc_doacross_wait);\n  }\n  CGF.EmitRuntimeCall(RTLFn, Args);\n}\n\nvoid CGOpenMPRuntime::emitCall(CodeGenFunction &CGF, SourceLocation Loc,\n                               llvm::FunctionCallee Callee,\n                               ArrayRef<llvm::Value *> Args) const {\n  assert(Loc.isValid() && \"Outlined function call location must be valid.\");\n  auto DL = ApplyDebugLocation::CreateDefaultArtificial(CGF, Loc);\n\n  if (auto *Fn = dyn_cast<llvm::Function>(Callee.getCallee())) {\n    if (Fn->doesNotThrow()) {\n      CGF.EmitNounwindRuntimeCall(Fn, Args);\n      return;\n    }\n  }\n  CGF.EmitRuntimeCall(Callee, Args);\n}\n\nvoid CGOpenMPRuntime::emitOutlinedFunctionCall(\n    CodeGenFunction &CGF, SourceLocation Loc, llvm::FunctionCallee OutlinedFn,\n    ArrayRef<llvm::Value *> Args) const {\n  emitCall(CGF, Loc, OutlinedFn, Args);\n}\n\nvoid CGOpenMPRuntime::emitFunctionProlog(CodeGenFunction &CGF, const Decl *D) {\n  if (const auto *FD = dyn_cast<FunctionDecl>(D))\n    if (OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(FD))\n      HasEmittedDeclareTargetRegion = true;\n}\n\nAddress CGOpenMPRuntime::getParameterAddress(CodeGenFunction &CGF,\n                                             const VarDecl *NativeParam,\n                                             const VarDecl *TargetParam) const {\n  return CGF.GetAddrOfLocalVar(NativeParam);\n}\n\nAddress CGOpenMPRuntime::getAddressOfLocalVariable(CodeGenFunction &CGF,\n                                                   const VarDecl *VD) {\n  if (!VD)\n    return Address::invalid();\n  Address UntiedAddr = Address::invalid();\n  Address UntiedRealAddr = Address::invalid();\n  auto It = FunctionToUntiedTaskStackMap.find(CGF.CurFn);\n  if (It != FunctionToUntiedTaskStackMap.end()) {\n    const UntiedLocalVarsAddressesMap &UntiedData =\n        UntiedLocalVarsStack[It->second];\n    auto I = UntiedData.find(VD);\n    if (I != UntiedData.end()) {\n      UntiedAddr = I->second.first;\n      UntiedRealAddr = I->second.second;\n    }\n  }\n  const VarDecl *CVD = VD->getCanonicalDecl();\n  if (CVD->hasAttr<OMPAllocateDeclAttr>()) {\n    // Use the default allocation.\n    if (!isAllocatableDecl(VD))\n      return UntiedAddr;\n    llvm::Value *Size;\n    CharUnits Align = CGM.getContext().getDeclAlign(CVD);\n    if (CVD->getType()->isVariablyModifiedType()) {\n      Size = CGF.getTypeSize(CVD->getType());\n      // Align the size: ((size + align - 1) / align) * align\n      Size = CGF.Builder.CreateNUWAdd(\n          Size, CGM.getSize(Align - CharUnits::fromQuantity(1)));\n      Size = CGF.Builder.CreateUDiv(Size, CGM.getSize(Align));\n      Size = CGF.Builder.CreateNUWMul(Size, CGM.getSize(Align));\n    } else {\n      CharUnits Sz = CGM.getContext().getTypeSizeInChars(CVD->getType());\n      Size = CGM.getSize(Sz.alignTo(Align));\n    }\n    llvm::Value *ThreadID = getThreadID(CGF, CVD->getBeginLoc());\n    const auto *AA = CVD->getAttr<OMPAllocateDeclAttr>();\n    assert(AA->getAllocator() &&\n           \"Expected allocator expression for non-default allocator.\");\n    llvm::Value *Allocator = CGF.EmitScalarExpr(AA->getAllocator());\n    // According to the standard, the original allocator type is a enum\n    // (integer). Convert to pointer type, if required.\n    Allocator = CGF.EmitScalarConversion(\n        Allocator, AA->getAllocator()->getType(), CGF.getContext().VoidPtrTy,\n        AA->getAllocator()->getExprLoc());\n    llvm::Value *Args[] = {ThreadID, Size, Allocator};\n\n    llvm::Value *Addr =\n        CGF.EmitRuntimeCall(OMPBuilder.getOrCreateRuntimeFunction(\n                                CGM.getModule(), OMPRTL___kmpc_alloc),\n                            Args, getName({CVD->getName(), \".void.addr\"}));\n    llvm::FunctionCallee FiniRTLFn = OMPBuilder.getOrCreateRuntimeFunction(\n        CGM.getModule(), OMPRTL___kmpc_free);\n    QualType Ty = CGM.getContext().getPointerType(CVD->getType());\n    Addr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n        Addr, CGF.ConvertTypeForMem(Ty), getName({CVD->getName(), \".addr\"}));\n    if (UntiedAddr.isValid())\n      CGF.EmitStoreOfScalar(Addr, UntiedAddr, /*Volatile=*/false, Ty);\n\n    // Cleanup action for allocate support.\n    class OMPAllocateCleanupTy final : public EHScopeStack::Cleanup {\n      llvm::FunctionCallee RTLFn;\n      unsigned LocEncoding;\n      Address Addr;\n      const Expr *Allocator;\n\n    public:\n      OMPAllocateCleanupTy(llvm::FunctionCallee RTLFn, unsigned LocEncoding,\n                           Address Addr, const Expr *Allocator)\n          : RTLFn(RTLFn), LocEncoding(LocEncoding), Addr(Addr),\n            Allocator(Allocator) {}\n      void Emit(CodeGenFunction &CGF, Flags /*flags*/) override {\n        if (!CGF.HaveInsertPoint())\n          return;\n        llvm::Value *Args[3];\n        Args[0] = CGF.CGM.getOpenMPRuntime().getThreadID(\n            CGF, SourceLocation::getFromRawEncoding(LocEncoding));\n        Args[1] = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n            Addr.getPointer(), CGF.VoidPtrTy);\n        llvm::Value *AllocVal = CGF.EmitScalarExpr(Allocator);\n        // According to the standard, the original allocator type is a enum\n        // (integer). Convert to pointer type, if required.\n        AllocVal = CGF.EmitScalarConversion(AllocVal, Allocator->getType(),\n                                            CGF.getContext().VoidPtrTy,\n                                            Allocator->getExprLoc());\n        Args[2] = AllocVal;\n\n        CGF.EmitRuntimeCall(RTLFn, Args);\n      }\n    };\n    Address VDAddr =\n        UntiedRealAddr.isValid() ? UntiedRealAddr : Address(Addr, Align);\n    CGF.EHStack.pushCleanup<OMPAllocateCleanupTy>(\n        NormalAndEHCleanup, FiniRTLFn, CVD->getLocation().getRawEncoding(),\n        VDAddr, AA->getAllocator());\n    if (UntiedRealAddr.isValid())\n      if (auto *Region =\n              dyn_cast_or_null<CGOpenMPRegionInfo>(CGF.CapturedStmtInfo))\n        Region->emitUntiedSwitch(CGF);\n    return VDAddr;\n  }\n  return UntiedAddr;\n}\n\nbool CGOpenMPRuntime::isLocalVarInUntiedTask(CodeGenFunction &CGF,\n                                             const VarDecl *VD) const {\n  auto It = FunctionToUntiedTaskStackMap.find(CGF.CurFn);\n  if (It == FunctionToUntiedTaskStackMap.end())\n    return false;\n  return UntiedLocalVarsStack[It->second].count(VD) > 0;\n}\n\nCGOpenMPRuntime::NontemporalDeclsRAII::NontemporalDeclsRAII(\n    CodeGenModule &CGM, const OMPLoopDirective &S)\n    : CGM(CGM), NeedToPush(S.hasClausesOfKind<OMPNontemporalClause>()) {\n  assert(CGM.getLangOpts().OpenMP && \"Not in OpenMP mode.\");\n  if (!NeedToPush)\n    return;\n  NontemporalDeclsSet &DS =\n      CGM.getOpenMPRuntime().NontemporalDeclsStack.emplace_back();\n  for (const auto *C : S.getClausesOfKind<OMPNontemporalClause>()) {\n    for (const Stmt *Ref : C->private_refs()) {\n      const auto *SimpleRefExpr = cast<Expr>(Ref)->IgnoreParenImpCasts();\n      const ValueDecl *VD;\n      if (const auto *DRE = dyn_cast<DeclRefExpr>(SimpleRefExpr)) {\n        VD = DRE->getDecl();\n      } else {\n        const auto *ME = cast<MemberExpr>(SimpleRefExpr);\n        assert((ME->isImplicitCXXThis() ||\n                isa<CXXThisExpr>(ME->getBase()->IgnoreParenImpCasts())) &&\n               \"Expected member of current class.\");\n        VD = ME->getMemberDecl();\n      }\n      DS.insert(VD);\n    }\n  }\n}\n\nCGOpenMPRuntime::NontemporalDeclsRAII::~NontemporalDeclsRAII() {\n  if (!NeedToPush)\n    return;\n  CGM.getOpenMPRuntime().NontemporalDeclsStack.pop_back();\n}\n\nCGOpenMPRuntime::UntiedTaskLocalDeclsRAII::UntiedTaskLocalDeclsRAII(\n    CodeGenFunction &CGF,\n    const llvm::DenseMap<CanonicalDeclPtr<const VarDecl>,\n                         std::pair<Address, Address>> &LocalVars)\n    : CGM(CGF.CGM), NeedToPush(!LocalVars.empty()) {\n  if (!NeedToPush)\n    return;\n  CGM.getOpenMPRuntime().FunctionToUntiedTaskStackMap.try_emplace(\n      CGF.CurFn, CGM.getOpenMPRuntime().UntiedLocalVarsStack.size());\n  CGM.getOpenMPRuntime().UntiedLocalVarsStack.push_back(LocalVars);\n}\n\nCGOpenMPRuntime::UntiedTaskLocalDeclsRAII::~UntiedTaskLocalDeclsRAII() {\n  if (!NeedToPush)\n    return;\n  CGM.getOpenMPRuntime().UntiedLocalVarsStack.pop_back();\n}\n\nbool CGOpenMPRuntime::isNontemporalDecl(const ValueDecl *VD) const {\n  assert(CGM.getLangOpts().OpenMP && \"Not in OpenMP mode.\");\n\n  return llvm::any_of(\n      CGM.getOpenMPRuntime().NontemporalDeclsStack,\n      [VD](const NontemporalDeclsSet &Set) { return Set.count(VD) > 0; });\n}\n\nvoid CGOpenMPRuntime::LastprivateConditionalRAII::tryToDisableInnerAnalysis(\n    const OMPExecutableDirective &S,\n    llvm::DenseSet<CanonicalDeclPtr<const Decl>> &NeedToAddForLPCsAsDisabled)\n    const {\n  llvm::DenseSet<CanonicalDeclPtr<const Decl>> NeedToCheckForLPCs;\n  // Vars in target/task regions must be excluded completely.\n  if (isOpenMPTargetExecutionDirective(S.getDirectiveKind()) ||\n      isOpenMPTaskingDirective(S.getDirectiveKind())) {\n    SmallVector<OpenMPDirectiveKind, 4> CaptureRegions;\n    getOpenMPCaptureRegions(CaptureRegions, S.getDirectiveKind());\n    const CapturedStmt *CS = S.getCapturedStmt(CaptureRegions.front());\n    for (const CapturedStmt::Capture &Cap : CS->captures()) {\n      if (Cap.capturesVariable() || Cap.capturesVariableByCopy())\n        NeedToCheckForLPCs.insert(Cap.getCapturedVar());\n    }\n  }\n  // Exclude vars in private clauses.\n  for (const auto *C : S.getClausesOfKind<OMPPrivateClause>()) {\n    for (const Expr *Ref : C->varlists()) {\n      if (!Ref->getType()->isScalarType())\n        continue;\n      const auto *DRE = dyn_cast<DeclRefExpr>(Ref->IgnoreParenImpCasts());\n      if (!DRE)\n        continue;\n      NeedToCheckForLPCs.insert(DRE->getDecl());\n    }\n  }\n  for (const auto *C : S.getClausesOfKind<OMPFirstprivateClause>()) {\n    for (const Expr *Ref : C->varlists()) {\n      if (!Ref->getType()->isScalarType())\n        continue;\n      const auto *DRE = dyn_cast<DeclRefExpr>(Ref->IgnoreParenImpCasts());\n      if (!DRE)\n        continue;\n      NeedToCheckForLPCs.insert(DRE->getDecl());\n    }\n  }\n  for (const auto *C : S.getClausesOfKind<OMPLastprivateClause>()) {\n    for (const Expr *Ref : C->varlists()) {\n      if (!Ref->getType()->isScalarType())\n        continue;\n      const auto *DRE = dyn_cast<DeclRefExpr>(Ref->IgnoreParenImpCasts());\n      if (!DRE)\n        continue;\n      NeedToCheckForLPCs.insert(DRE->getDecl());\n    }\n  }\n  for (const auto *C : S.getClausesOfKind<OMPReductionClause>()) {\n    for (const Expr *Ref : C->varlists()) {\n      if (!Ref->getType()->isScalarType())\n        continue;\n      const auto *DRE = dyn_cast<DeclRefExpr>(Ref->IgnoreParenImpCasts());\n      if (!DRE)\n        continue;\n      NeedToCheckForLPCs.insert(DRE->getDecl());\n    }\n  }\n  for (const auto *C : S.getClausesOfKind<OMPLinearClause>()) {\n    for (const Expr *Ref : C->varlists()) {\n      if (!Ref->getType()->isScalarType())\n        continue;\n      const auto *DRE = dyn_cast<DeclRefExpr>(Ref->IgnoreParenImpCasts());\n      if (!DRE)\n        continue;\n      NeedToCheckForLPCs.insert(DRE->getDecl());\n    }\n  }\n  for (const Decl *VD : NeedToCheckForLPCs) {\n    for (const LastprivateConditionalData &Data :\n         llvm::reverse(CGM.getOpenMPRuntime().LastprivateConditionalStack)) {\n      if (Data.DeclToUniqueName.count(VD) > 0) {\n        if (!Data.Disabled)\n          NeedToAddForLPCsAsDisabled.insert(VD);\n        break;\n      }\n    }\n  }\n}\n\nCGOpenMPRuntime::LastprivateConditionalRAII::LastprivateConditionalRAII(\n    CodeGenFunction &CGF, const OMPExecutableDirective &S, LValue IVLVal)\n    : CGM(CGF.CGM),\n      Action((CGM.getLangOpts().OpenMP >= 50 &&\n              llvm::any_of(S.getClausesOfKind<OMPLastprivateClause>(),\n                           [](const OMPLastprivateClause *C) {\n                             return C->getKind() ==\n                                    OMPC_LASTPRIVATE_conditional;\n                           }))\n                 ? ActionToDo::PushAsLastprivateConditional\n                 : ActionToDo::DoNotPush) {\n  assert(CGM.getLangOpts().OpenMP && \"Not in OpenMP mode.\");\n  if (CGM.getLangOpts().OpenMP < 50 || Action == ActionToDo::DoNotPush)\n    return;\n  assert(Action == ActionToDo::PushAsLastprivateConditional &&\n         \"Expected a push action.\");\n  LastprivateConditionalData &Data =\n      CGM.getOpenMPRuntime().LastprivateConditionalStack.emplace_back();\n  for (const auto *C : S.getClausesOfKind<OMPLastprivateClause>()) {\n    if (C->getKind() != OMPC_LASTPRIVATE_conditional)\n      continue;\n\n    for (const Expr *Ref : C->varlists()) {\n      Data.DeclToUniqueName.insert(std::make_pair(\n          cast<DeclRefExpr>(Ref->IgnoreParenImpCasts())->getDecl(),\n          SmallString<16>(generateUniqueName(CGM, \"pl_cond\", Ref))));\n    }\n  }\n  Data.IVLVal = IVLVal;\n  Data.Fn = CGF.CurFn;\n}\n\nCGOpenMPRuntime::LastprivateConditionalRAII::LastprivateConditionalRAII(\n    CodeGenFunction &CGF, const OMPExecutableDirective &S)\n    : CGM(CGF.CGM), Action(ActionToDo::DoNotPush) {\n  assert(CGM.getLangOpts().OpenMP && \"Not in OpenMP mode.\");\n  if (CGM.getLangOpts().OpenMP < 50)\n    return;\n  llvm::DenseSet<CanonicalDeclPtr<const Decl>> NeedToAddForLPCsAsDisabled;\n  tryToDisableInnerAnalysis(S, NeedToAddForLPCsAsDisabled);\n  if (!NeedToAddForLPCsAsDisabled.empty()) {\n    Action = ActionToDo::DisableLastprivateConditional;\n    LastprivateConditionalData &Data =\n        CGM.getOpenMPRuntime().LastprivateConditionalStack.emplace_back();\n    for (const Decl *VD : NeedToAddForLPCsAsDisabled)\n      Data.DeclToUniqueName.insert(std::make_pair(VD, SmallString<16>()));\n    Data.Fn = CGF.CurFn;\n    Data.Disabled = true;\n  }\n}\n\nCGOpenMPRuntime::LastprivateConditionalRAII\nCGOpenMPRuntime::LastprivateConditionalRAII::disable(\n    CodeGenFunction &CGF, const OMPExecutableDirective &S) {\n  return LastprivateConditionalRAII(CGF, S);\n}\n\nCGOpenMPRuntime::LastprivateConditionalRAII::~LastprivateConditionalRAII() {\n  if (CGM.getLangOpts().OpenMP < 50)\n    return;\n  if (Action == ActionToDo::DisableLastprivateConditional) {\n    assert(CGM.getOpenMPRuntime().LastprivateConditionalStack.back().Disabled &&\n           \"Expected list of disabled private vars.\");\n    CGM.getOpenMPRuntime().LastprivateConditionalStack.pop_back();\n  }\n  if (Action == ActionToDo::PushAsLastprivateConditional) {\n    assert(\n        !CGM.getOpenMPRuntime().LastprivateConditionalStack.back().Disabled &&\n        \"Expected list of lastprivate conditional vars.\");\n    CGM.getOpenMPRuntime().LastprivateConditionalStack.pop_back();\n  }\n}\n\nAddress CGOpenMPRuntime::emitLastprivateConditionalInit(CodeGenFunction &CGF,\n                                                        const VarDecl *VD) {\n  ASTContext &C = CGM.getContext();\n  auto I = LastprivateConditionalToTypes.find(CGF.CurFn);\n  if (I == LastprivateConditionalToTypes.end())\n    I = LastprivateConditionalToTypes.try_emplace(CGF.CurFn).first;\n  QualType NewType;\n  const FieldDecl *VDField;\n  const FieldDecl *FiredField;\n  LValue BaseLVal;\n  auto VI = I->getSecond().find(VD);\n  if (VI == I->getSecond().end()) {\n    RecordDecl *RD = C.buildImplicitRecord(\"lasprivate.conditional\");\n    RD->startDefinition();\n    VDField = addFieldToRecordDecl(C, RD, VD->getType().getNonReferenceType());\n    FiredField = addFieldToRecordDecl(C, RD, C.CharTy);\n    RD->completeDefinition();\n    NewType = C.getRecordType(RD);\n    Address Addr = CGF.CreateMemTemp(NewType, C.getDeclAlign(VD), VD->getName());\n    BaseLVal = CGF.MakeAddrLValue(Addr, NewType, AlignmentSource::Decl);\n    I->getSecond().try_emplace(VD, NewType, VDField, FiredField, BaseLVal);\n  } else {\n    NewType = std::get<0>(VI->getSecond());\n    VDField = std::get<1>(VI->getSecond());\n    FiredField = std::get<2>(VI->getSecond());\n    BaseLVal = std::get<3>(VI->getSecond());\n  }\n  LValue FiredLVal =\n      CGF.EmitLValueForField(BaseLVal, FiredField);\n  CGF.EmitStoreOfScalar(\n      llvm::ConstantInt::getNullValue(CGF.ConvertTypeForMem(C.CharTy)),\n      FiredLVal);\n  return CGF.EmitLValueForField(BaseLVal, VDField).getAddress(CGF);\n}\n\nnamespace {\n/// Checks if the lastprivate conditional variable is referenced in LHS.\nclass LastprivateConditionalRefChecker final\n    : public ConstStmtVisitor<LastprivateConditionalRefChecker, bool> {\n  ArrayRef<CGOpenMPRuntime::LastprivateConditionalData> LPM;\n  const Expr *FoundE = nullptr;\n  const Decl *FoundD = nullptr;\n  StringRef UniqueDeclName;\n  LValue IVLVal;\n  llvm::Function *FoundFn = nullptr;\n  SourceLocation Loc;\n\npublic:\n  bool VisitDeclRefExpr(const DeclRefExpr *E) {\n    for (const CGOpenMPRuntime::LastprivateConditionalData &D :\n         llvm::reverse(LPM)) {\n      auto It = D.DeclToUniqueName.find(E->getDecl());\n      if (It == D.DeclToUniqueName.end())\n        continue;\n      if (D.Disabled)\n        return false;\n      FoundE = E;\n      FoundD = E->getDecl()->getCanonicalDecl();\n      UniqueDeclName = It->second;\n      IVLVal = D.IVLVal;\n      FoundFn = D.Fn;\n      break;\n    }\n    return FoundE == E;\n  }\n  bool VisitMemberExpr(const MemberExpr *E) {\n    if (!CodeGenFunction::IsWrappedCXXThis(E->getBase()))\n      return false;\n    for (const CGOpenMPRuntime::LastprivateConditionalData &D :\n         llvm::reverse(LPM)) {\n      auto It = D.DeclToUniqueName.find(E->getMemberDecl());\n      if (It == D.DeclToUniqueName.end())\n        continue;\n      if (D.Disabled)\n        return false;\n      FoundE = E;\n      FoundD = E->getMemberDecl()->getCanonicalDecl();\n      UniqueDeclName = It->second;\n      IVLVal = D.IVLVal;\n      FoundFn = D.Fn;\n      break;\n    }\n    return FoundE == E;\n  }\n  bool VisitStmt(const Stmt *S) {\n    for (const Stmt *Child : S->children()) {\n      if (!Child)\n        continue;\n      if (const auto *E = dyn_cast<Expr>(Child))\n        if (!E->isGLValue())\n          continue;\n      if (Visit(Child))\n        return true;\n    }\n    return false;\n  }\n  explicit LastprivateConditionalRefChecker(\n      ArrayRef<CGOpenMPRuntime::LastprivateConditionalData> LPM)\n      : LPM(LPM) {}\n  std::tuple<const Expr *, const Decl *, StringRef, LValue, llvm::Function *>\n  getFoundData() const {\n    return std::make_tuple(FoundE, FoundD, UniqueDeclName, IVLVal, FoundFn);\n  }\n};\n} // namespace\n\nvoid CGOpenMPRuntime::emitLastprivateConditionalUpdate(CodeGenFunction &CGF,\n                                                       LValue IVLVal,\n                                                       StringRef UniqueDeclName,\n                                                       LValue LVal,\n                                                       SourceLocation Loc) {\n  // Last updated loop counter for the lastprivate conditional var.\n  // int<xx> last_iv = 0;\n  llvm::Type *LLIVTy = CGF.ConvertTypeForMem(IVLVal.getType());\n  llvm::Constant *LastIV =\n      getOrCreateInternalVariable(LLIVTy, getName({UniqueDeclName, \"iv\"}));\n  cast<llvm::GlobalVariable>(LastIV)->setAlignment(\n      IVLVal.getAlignment().getAsAlign());\n  LValue LastIVLVal = CGF.MakeNaturalAlignAddrLValue(LastIV, IVLVal.getType());\n\n  // Last value of the lastprivate conditional.\n  // decltype(priv_a) last_a;\n  llvm::Constant *Last = getOrCreateInternalVariable(\n      CGF.ConvertTypeForMem(LVal.getType()), UniqueDeclName);\n  cast<llvm::GlobalVariable>(Last)->setAlignment(\n      LVal.getAlignment().getAsAlign());\n  LValue LastLVal =\n      CGF.MakeAddrLValue(Last, LVal.getType(), LVal.getAlignment());\n\n  // Global loop counter. Required to handle inner parallel-for regions.\n  // iv\n  llvm::Value *IVVal = CGF.EmitLoadOfScalar(IVLVal, Loc);\n\n  // #pragma omp critical(a)\n  // if (last_iv <= iv) {\n  //   last_iv = iv;\n  //   last_a = priv_a;\n  // }\n  auto &&CodeGen = [&LastIVLVal, &IVLVal, IVVal, &LVal, &LastLVal,\n                    Loc](CodeGenFunction &CGF, PrePostActionTy &Action) {\n    Action.Enter(CGF);\n    llvm::Value *LastIVVal = CGF.EmitLoadOfScalar(LastIVLVal, Loc);\n    // (last_iv <= iv) ? Check if the variable is updated and store new\n    // value in global var.\n    llvm::Value *CmpRes;\n    if (IVLVal.getType()->isSignedIntegerType()) {\n      CmpRes = CGF.Builder.CreateICmpSLE(LastIVVal, IVVal);\n    } else {\n      assert(IVLVal.getType()->isUnsignedIntegerType() &&\n             \"Loop iteration variable must be integer.\");\n      CmpRes = CGF.Builder.CreateICmpULE(LastIVVal, IVVal);\n    }\n    llvm::BasicBlock *ThenBB = CGF.createBasicBlock(\"lp_cond_then\");\n    llvm::BasicBlock *ExitBB = CGF.createBasicBlock(\"lp_cond_exit\");\n    CGF.Builder.CreateCondBr(CmpRes, ThenBB, ExitBB);\n    // {\n    CGF.EmitBlock(ThenBB);\n\n    //   last_iv = iv;\n    CGF.EmitStoreOfScalar(IVVal, LastIVLVal);\n\n    //   last_a = priv_a;\n    switch (CGF.getEvaluationKind(LVal.getType())) {\n    case TEK_Scalar: {\n      llvm::Value *PrivVal = CGF.EmitLoadOfScalar(LVal, Loc);\n      CGF.EmitStoreOfScalar(PrivVal, LastLVal);\n      break;\n    }\n    case TEK_Complex: {\n      CodeGenFunction::ComplexPairTy PrivVal = CGF.EmitLoadOfComplex(LVal, Loc);\n      CGF.EmitStoreOfComplex(PrivVal, LastLVal, /*isInit=*/false);\n      break;\n    }\n    case TEK_Aggregate:\n      llvm_unreachable(\n          \"Aggregates are not supported in lastprivate conditional.\");\n    }\n    // }\n    CGF.EmitBranch(ExitBB);\n    // There is no need to emit line number for unconditional branch.\n    (void)ApplyDebugLocation::CreateEmpty(CGF);\n    CGF.EmitBlock(ExitBB, /*IsFinished=*/true);\n  };\n\n  if (CGM.getLangOpts().OpenMPSimd) {\n    // Do not emit as a critical region as no parallel region could be emitted.\n    RegionCodeGenTy ThenRCG(CodeGen);\n    ThenRCG(CGF);\n  } else {\n    emitCriticalRegion(CGF, UniqueDeclName, CodeGen, Loc);\n  }\n}\n\nvoid CGOpenMPRuntime::checkAndEmitLastprivateConditional(CodeGenFunction &CGF,\n                                                         const Expr *LHS) {\n  if (CGF.getLangOpts().OpenMP < 50 || LastprivateConditionalStack.empty())\n    return;\n  LastprivateConditionalRefChecker Checker(LastprivateConditionalStack);\n  if (!Checker.Visit(LHS))\n    return;\n  const Expr *FoundE;\n  const Decl *FoundD;\n  StringRef UniqueDeclName;\n  LValue IVLVal;\n  llvm::Function *FoundFn;\n  std::tie(FoundE, FoundD, UniqueDeclName, IVLVal, FoundFn) =\n      Checker.getFoundData();\n  if (FoundFn != CGF.CurFn) {\n    // Special codegen for inner parallel regions.\n    // ((struct.lastprivate.conditional*)&priv_a)->Fired = 1;\n    auto It = LastprivateConditionalToTypes[FoundFn].find(FoundD);\n    assert(It != LastprivateConditionalToTypes[FoundFn].end() &&\n           \"Lastprivate conditional is not found in outer region.\");\n    QualType StructTy = std::get<0>(It->getSecond());\n    const FieldDecl* FiredDecl = std::get<2>(It->getSecond());\n    LValue PrivLVal = CGF.EmitLValue(FoundE);\n    Address StructAddr = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(\n        PrivLVal.getAddress(CGF),\n        CGF.ConvertTypeForMem(CGF.getContext().getPointerType(StructTy)));\n    LValue BaseLVal =\n        CGF.MakeAddrLValue(StructAddr, StructTy, AlignmentSource::Decl);\n    LValue FiredLVal = CGF.EmitLValueForField(BaseLVal, FiredDecl);\n    CGF.EmitAtomicStore(RValue::get(llvm::ConstantInt::get(\n                            CGF.ConvertTypeForMem(FiredDecl->getType()), 1)),\n                        FiredLVal, llvm::AtomicOrdering::Unordered,\n                        /*IsVolatile=*/true, /*isInit=*/false);\n    return;\n  }\n\n  // Private address of the lastprivate conditional in the current context.\n  // priv_a\n  LValue LVal = CGF.EmitLValue(FoundE);\n  emitLastprivateConditionalUpdate(CGF, IVLVal, UniqueDeclName, LVal,\n                                   FoundE->getExprLoc());\n}\n\nvoid CGOpenMPRuntime::checkAndEmitSharedLastprivateConditional(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D,\n    const llvm::DenseSet<CanonicalDeclPtr<const VarDecl>> &IgnoredDecls) {\n  if (CGF.getLangOpts().OpenMP < 50 || LastprivateConditionalStack.empty())\n    return;\n  auto Range = llvm::reverse(LastprivateConditionalStack);\n  auto It = llvm::find_if(\n      Range, [](const LastprivateConditionalData &D) { return !D.Disabled; });\n  if (It == Range.end() || It->Fn != CGF.CurFn)\n    return;\n  auto LPCI = LastprivateConditionalToTypes.find(It->Fn);\n  assert(LPCI != LastprivateConditionalToTypes.end() &&\n         \"Lastprivates must be registered already.\");\n  SmallVector<OpenMPDirectiveKind, 4> CaptureRegions;\n  getOpenMPCaptureRegions(CaptureRegions, D.getDirectiveKind());\n  const CapturedStmt *CS = D.getCapturedStmt(CaptureRegions.back());\n  for (const auto &Pair : It->DeclToUniqueName) {\n    const auto *VD = cast<VarDecl>(Pair.first->getCanonicalDecl());\n    if (!CS->capturesVariable(VD) || IgnoredDecls.count(VD) > 0)\n      continue;\n    auto I = LPCI->getSecond().find(Pair.first);\n    assert(I != LPCI->getSecond().end() &&\n           \"Lastprivate must be rehistered already.\");\n    // bool Cmp = priv_a.Fired != 0;\n    LValue BaseLVal = std::get<3>(I->getSecond());\n    LValue FiredLVal =\n        CGF.EmitLValueForField(BaseLVal, std::get<2>(I->getSecond()));\n    llvm::Value *Res = CGF.EmitLoadOfScalar(FiredLVal, D.getBeginLoc());\n    llvm::Value *Cmp = CGF.Builder.CreateIsNotNull(Res);\n    llvm::BasicBlock *ThenBB = CGF.createBasicBlock(\"lpc.then\");\n    llvm::BasicBlock *DoneBB = CGF.createBasicBlock(\"lpc.done\");\n    // if (Cmp) {\n    CGF.Builder.CreateCondBr(Cmp, ThenBB, DoneBB);\n    CGF.EmitBlock(ThenBB);\n    Address Addr = CGF.GetAddrOfLocalVar(VD);\n    LValue LVal;\n    if (VD->getType()->isReferenceType())\n      LVal = CGF.EmitLoadOfReferenceLValue(Addr, VD->getType(),\n                                           AlignmentSource::Decl);\n    else\n      LVal = CGF.MakeAddrLValue(Addr, VD->getType().getNonReferenceType(),\n                                AlignmentSource::Decl);\n    emitLastprivateConditionalUpdate(CGF, It->IVLVal, Pair.second, LVal,\n                                     D.getBeginLoc());\n    auto AL = ApplyDebugLocation::CreateArtificial(CGF);\n    CGF.EmitBlock(DoneBB, /*IsFinal=*/true);\n    // }\n  }\n}\n\nvoid CGOpenMPRuntime::emitLastprivateConditionalFinalUpdate(\n    CodeGenFunction &CGF, LValue PrivLVal, const VarDecl *VD,\n    SourceLocation Loc) {\n  if (CGF.getLangOpts().OpenMP < 50)\n    return;\n  auto It = LastprivateConditionalStack.back().DeclToUniqueName.find(VD);\n  assert(It != LastprivateConditionalStack.back().DeclToUniqueName.end() &&\n         \"Unknown lastprivate conditional variable.\");\n  StringRef UniqueName = It->second;\n  llvm::GlobalVariable *GV = CGM.getModule().getNamedGlobal(UniqueName);\n  // The variable was not updated in the region - exit.\n  if (!GV)\n    return;\n  LValue LPLVal = CGF.MakeAddrLValue(\n      GV, PrivLVal.getType().getNonReferenceType(), PrivLVal.getAlignment());\n  llvm::Value *Res = CGF.EmitLoadOfScalar(LPLVal, Loc);\n  CGF.EmitStoreOfScalar(Res, PrivLVal);\n}\n\nllvm::Function *CGOpenMPSIMDRuntime::emitParallelOutlinedFunction(\n    const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n    OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nllvm::Function *CGOpenMPSIMDRuntime::emitTeamsOutlinedFunction(\n    const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n    OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nllvm::Function *CGOpenMPSIMDRuntime::emitTaskOutlinedFunction(\n    const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n    const VarDecl *PartIDVar, const VarDecl *TaskTVar,\n    OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen,\n    bool Tied, unsigned &NumberOfParts) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitParallelCall(CodeGenFunction &CGF,\n                                           SourceLocation Loc,\n                                           llvm::Function *OutlinedFn,\n                                           ArrayRef<llvm::Value *> CapturedVars,\n                                           const Expr *IfCond) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitCriticalRegion(\n    CodeGenFunction &CGF, StringRef CriticalName,\n    const RegionCodeGenTy &CriticalOpGen, SourceLocation Loc,\n    const Expr *Hint) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitMasterRegion(CodeGenFunction &CGF,\n                                           const RegionCodeGenTy &MasterOpGen,\n                                           SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskyieldCall(CodeGenFunction &CGF,\n                                            SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskgroupRegion(\n    CodeGenFunction &CGF, const RegionCodeGenTy &TaskgroupOpGen,\n    SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitSingleRegion(\n    CodeGenFunction &CGF, const RegionCodeGenTy &SingleOpGen,\n    SourceLocation Loc, ArrayRef<const Expr *> CopyprivateVars,\n    ArrayRef<const Expr *> DestExprs, ArrayRef<const Expr *> SrcExprs,\n    ArrayRef<const Expr *> AssignmentOps) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitOrderedRegion(CodeGenFunction &CGF,\n                                            const RegionCodeGenTy &OrderedOpGen,\n                                            SourceLocation Loc,\n                                            bool IsThreads) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitBarrierCall(CodeGenFunction &CGF,\n                                          SourceLocation Loc,\n                                          OpenMPDirectiveKind Kind,\n                                          bool EmitChecks,\n                                          bool ForceSimpleCall) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitForDispatchInit(\n    CodeGenFunction &CGF, SourceLocation Loc,\n    const OpenMPScheduleTy &ScheduleKind, unsigned IVSize, bool IVSigned,\n    bool Ordered, const DispatchRTInput &DispatchValues) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitForStaticInit(\n    CodeGenFunction &CGF, SourceLocation Loc, OpenMPDirectiveKind DKind,\n    const OpenMPScheduleTy &ScheduleKind, const StaticRTInput &Values) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitDistributeStaticInit(\n    CodeGenFunction &CGF, SourceLocation Loc,\n    OpenMPDistScheduleClauseKind SchedKind, const StaticRTInput &Values) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitForOrderedIterationEnd(CodeGenFunction &CGF,\n                                                     SourceLocation Loc,\n                                                     unsigned IVSize,\n                                                     bool IVSigned) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitForStaticFinish(CodeGenFunction &CGF,\n                                              SourceLocation Loc,\n                                              OpenMPDirectiveKind DKind) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nllvm::Value *CGOpenMPSIMDRuntime::emitForNext(CodeGenFunction &CGF,\n                                              SourceLocation Loc,\n                                              unsigned IVSize, bool IVSigned,\n                                              Address IL, Address LB,\n                                              Address UB, Address ST) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitNumThreadsClause(CodeGenFunction &CGF,\n                                               llvm::Value *NumThreads,\n                                               SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitProcBindClause(CodeGenFunction &CGF,\n                                             ProcBindKind ProcBind,\n                                             SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nAddress CGOpenMPSIMDRuntime::getAddrOfThreadPrivate(CodeGenFunction &CGF,\n                                                    const VarDecl *VD,\n                                                    Address VDAddr,\n                                                    SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nllvm::Function *CGOpenMPSIMDRuntime::emitThreadPrivateVarDefinition(\n    const VarDecl *VD, Address VDAddr, SourceLocation Loc, bool PerformInit,\n    CodeGenFunction *CGF) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nAddress CGOpenMPSIMDRuntime::getAddrOfArtificialThreadPrivate(\n    CodeGenFunction &CGF, QualType VarType, StringRef Name) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitFlush(CodeGenFunction &CGF,\n                                    ArrayRef<const Expr *> Vars,\n                                    SourceLocation Loc,\n                                    llvm::AtomicOrdering AO) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                       const OMPExecutableDirective &D,\n                                       llvm::Function *TaskFunction,\n                                       QualType SharedsTy, Address Shareds,\n                                       const Expr *IfCond,\n                                       const OMPTaskDataTy &Data) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskLoopCall(\n    CodeGenFunction &CGF, SourceLocation Loc, const OMPLoopDirective &D,\n    llvm::Function *TaskFunction, QualType SharedsTy, Address Shareds,\n    const Expr *IfCond, const OMPTaskDataTy &Data) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitReduction(\n    CodeGenFunction &CGF, SourceLocation Loc, ArrayRef<const Expr *> Privates,\n    ArrayRef<const Expr *> LHSExprs, ArrayRef<const Expr *> RHSExprs,\n    ArrayRef<const Expr *> ReductionOps, ReductionOptionsTy Options) {\n  assert(Options.SimpleReduction && \"Only simple reduction is expected.\");\n  CGOpenMPRuntime::emitReduction(CGF, Loc, Privates, LHSExprs, RHSExprs,\n                                 ReductionOps, Options);\n}\n\nllvm::Value *CGOpenMPSIMDRuntime::emitTaskReductionInit(\n    CodeGenFunction &CGF, SourceLocation Loc, ArrayRef<const Expr *> LHSExprs,\n    ArrayRef<const Expr *> RHSExprs, const OMPTaskDataTy &Data) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskReductionFini(CodeGenFunction &CGF,\n                                                SourceLocation Loc,\n                                                bool IsWorksharingReduction) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskReductionFixups(CodeGenFunction &CGF,\n                                                  SourceLocation Loc,\n                                                  ReductionCodeGen &RCG,\n                                                  unsigned N) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nAddress CGOpenMPSIMDRuntime::getTaskReductionItem(CodeGenFunction &CGF,\n                                                  SourceLocation Loc,\n                                                  llvm::Value *ReductionsPtr,\n                                                  LValue SharedLVal) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTaskwaitCall(CodeGenFunction &CGF,\n                                           SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitCancellationPointCall(\n    CodeGenFunction &CGF, SourceLocation Loc,\n    OpenMPDirectiveKind CancelRegion) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitCancelCall(CodeGenFunction &CGF,\n                                         SourceLocation Loc, const Expr *IfCond,\n                                         OpenMPDirectiveKind CancelRegion) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTargetOutlinedFunction(\n    const OMPExecutableDirective &D, StringRef ParentName,\n    llvm::Function *&OutlinedFn, llvm::Constant *&OutlinedFnID,\n    bool IsOffloadEntry, const RegionCodeGenTy &CodeGen) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTargetCall(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D,\n    llvm::Function *OutlinedFn, llvm::Value *OutlinedFnID, const Expr *IfCond,\n    llvm::PointerIntPair<const Expr *, 2, OpenMPDeviceClauseModifier> Device,\n    llvm::function_ref<llvm::Value *(CodeGenFunction &CGF,\n                                     const OMPLoopDirective &D)>\n        SizeEmitter) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nbool CGOpenMPSIMDRuntime::emitTargetFunctions(GlobalDecl GD) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nbool CGOpenMPSIMDRuntime::emitTargetGlobalVariable(GlobalDecl GD) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nbool CGOpenMPSIMDRuntime::emitTargetGlobal(GlobalDecl GD) {\n  return false;\n}\n\nvoid CGOpenMPSIMDRuntime::emitTeamsCall(CodeGenFunction &CGF,\n                                        const OMPExecutableDirective &D,\n                                        SourceLocation Loc,\n                                        llvm::Function *OutlinedFn,\n                                        ArrayRef<llvm::Value *> CapturedVars) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitNumTeamsClause(CodeGenFunction &CGF,\n                                             const Expr *NumTeams,\n                                             const Expr *ThreadLimit,\n                                             SourceLocation Loc) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTargetDataCalls(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D, const Expr *IfCond,\n    const Expr *Device, const RegionCodeGenTy &CodeGen, TargetDataInfo &Info) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitTargetDataStandAloneCall(\n    CodeGenFunction &CGF, const OMPExecutableDirective &D, const Expr *IfCond,\n    const Expr *Device) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitDoacrossInit(CodeGenFunction &CGF,\n                                           const OMPLoopDirective &D,\n                                           ArrayRef<Expr *> NumIterations) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nvoid CGOpenMPSIMDRuntime::emitDoacrossOrdered(CodeGenFunction &CGF,\n                                              const OMPDependClause *C) {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nconst VarDecl *\nCGOpenMPSIMDRuntime::translateParameter(const FieldDecl *FD,\n                                        const VarDecl *NativeParam) const {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n\nAddress\nCGOpenMPSIMDRuntime::getParameterAddress(CodeGenFunction &CGF,\n                                         const VarDecl *NativeParam,\n                                         const VarDecl *TargetParam) const {\n  llvm_unreachable(\"Not supported in SIMD-only mode\");\n}\n"}, "36": {"id": 36, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.h", "content": "//===----- CGOpenMPRuntime.h - Interface to OpenMP Runtimes -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This provides a class for OpenMP runtime code generation.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGOPENMPRUNTIME_H\n#define LLVM_CLANG_LIB_CODEGEN_CGOPENMPRUNTIME_H\n\n#include \"CGValue.h\"\n#include \"clang/AST/DeclOpenMP.h\"\n#include \"clang/AST/GlobalDecl.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/OpenMPKinds.h\"\n#include \"clang/Basic/SourceLocation.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/StringMap.h\"\n#include \"llvm/ADT/StringSet.h\"\n#include \"llvm/Frontend/OpenMP/OMPConstants.h\"\n#include \"llvm/Frontend/OpenMP/OMPIRBuilder.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/AtomicOrdering.h\"\n\nnamespace llvm {\nclass ArrayType;\nclass Constant;\nclass FunctionType;\nclass GlobalVariable;\nclass StructType;\nclass Type;\nclass Value;\nclass OpenMPIRBuilder;\n} // namespace llvm\n\nnamespace clang {\nclass Expr;\nclass OMPDependClause;\nclass OMPExecutableDirective;\nclass OMPLoopDirective;\nclass VarDecl;\nclass OMPDeclareReductionDecl;\nclass IdentifierInfo;\n\nnamespace CodeGen {\nclass Address;\nclass CodeGenFunction;\nclass CodeGenModule;\n\n/// A basic class for pre|post-action for advanced codegen sequence for OpenMP\n/// region.\nclass PrePostActionTy {\npublic:\n  explicit PrePostActionTy() {}\n  virtual void Enter(CodeGenFunction &CGF) {}\n  virtual void Exit(CodeGenFunction &CGF) {}\n  virtual ~PrePostActionTy() {}\n};\n\n/// Class provides a way to call simple version of codegen for OpenMP region, or\n/// an advanced with possible pre|post-actions in codegen.\nclass RegionCodeGenTy final {\n  intptr_t CodeGen;\n  typedef void (*CodeGenTy)(intptr_t, CodeGenFunction &, PrePostActionTy &);\n  CodeGenTy Callback;\n  mutable PrePostActionTy *PrePostAction;\n  RegionCodeGenTy() = delete;\n  RegionCodeGenTy &operator=(const RegionCodeGenTy &) = delete;\n  template <typename Callable>\n  static void CallbackFn(intptr_t CodeGen, CodeGenFunction &CGF,\n                         PrePostActionTy &Action) {\n    return (*reinterpret_cast<Callable *>(CodeGen))(CGF, Action);\n  }\n\npublic:\n  template <typename Callable>\n  RegionCodeGenTy(\n      Callable &&CodeGen,\n      std::enable_if_t<!std::is_same<std::remove_reference_t<Callable>,\n                                     RegionCodeGenTy>::value> * = nullptr)\n      : CodeGen(reinterpret_cast<intptr_t>(&CodeGen)),\n        Callback(CallbackFn<std::remove_reference_t<Callable>>),\n        PrePostAction(nullptr) {}\n  void setAction(PrePostActionTy &Action) const { PrePostAction = &Action; }\n  void operator()(CodeGenFunction &CGF) const;\n};\n\nstruct OMPTaskDataTy final {\n  SmallVector<const Expr *, 4> PrivateVars;\n  SmallVector<const Expr *, 4> PrivateCopies;\n  SmallVector<const Expr *, 4> FirstprivateVars;\n  SmallVector<const Expr *, 4> FirstprivateCopies;\n  SmallVector<const Expr *, 4> FirstprivateInits;\n  SmallVector<const Expr *, 4> LastprivateVars;\n  SmallVector<const Expr *, 4> LastprivateCopies;\n  SmallVector<const Expr *, 4> ReductionVars;\n  SmallVector<const Expr *, 4> ReductionOrigs;\n  SmallVector<const Expr *, 4> ReductionCopies;\n  SmallVector<const Expr *, 4> ReductionOps;\n  SmallVector<CanonicalDeclPtr<const VarDecl>, 4> PrivateLocals;\n  struct DependData {\n    OpenMPDependClauseKind DepKind = OMPC_DEPEND_unknown;\n    const Expr *IteratorExpr = nullptr;\n    SmallVector<const Expr *, 4> DepExprs;\n    explicit DependData() = default;\n    DependData(OpenMPDependClauseKind DepKind, const Expr *IteratorExpr)\n        : DepKind(DepKind), IteratorExpr(IteratorExpr) {}\n  };\n  SmallVector<DependData, 4> Dependences;\n  llvm::PointerIntPair<llvm::Value *, 1, bool> Final;\n  llvm::PointerIntPair<llvm::Value *, 1, bool> Schedule;\n  llvm::PointerIntPair<llvm::Value *, 1, bool> Priority;\n  llvm::Value *Reductions = nullptr;\n  unsigned NumberOfParts = 0;\n  bool Tied = true;\n  bool Nogroup = false;\n  bool IsReductionWithTaskMod = false;\n  bool IsWorksharingReduction = false;\n};\n\n/// Class intended to support codegen of all kind of the reduction clauses.\nclass ReductionCodeGen {\nprivate:\n  /// Data required for codegen of reduction clauses.\n  struct ReductionData {\n    /// Reference to the item shared between tasks to reduce into.\n    const Expr *Shared = nullptr;\n    /// Reference to the original item.\n    const Expr *Ref = nullptr;\n    /// Helper expression for generation of private copy.\n    const Expr *Private = nullptr;\n    /// Helper expression for generation reduction operation.\n    const Expr *ReductionOp = nullptr;\n    ReductionData(const Expr *Shared, const Expr *Ref, const Expr *Private,\n                  const Expr *ReductionOp)\n        : Shared(Shared), Ref(Ref), Private(Private), ReductionOp(ReductionOp) {\n    }\n  };\n  /// List of reduction-based clauses.\n  SmallVector<ReductionData, 4> ClausesData;\n\n  /// List of addresses of shared variables/expressions.\n  SmallVector<std::pair<LValue, LValue>, 4> SharedAddresses;\n  /// List of addresses of original variables/expressions.\n  SmallVector<std::pair<LValue, LValue>, 4> OrigAddresses;\n  /// Sizes of the reduction items in chars.\n  SmallVector<std::pair<llvm::Value *, llvm::Value *>, 4> Sizes;\n  /// Base declarations for the reduction items.\n  SmallVector<const VarDecl *, 4> BaseDecls;\n\n  /// Emits lvalue for shared expression.\n  LValue emitSharedLValue(CodeGenFunction &CGF, const Expr *E);\n  /// Emits upper bound for shared expression (if array section).\n  LValue emitSharedLValueUB(CodeGenFunction &CGF, const Expr *E);\n  /// Performs aggregate initialization.\n  /// \\param N Number of reduction item in the common list.\n  /// \\param PrivateAddr Address of the corresponding private item.\n  /// \\param SharedLVal Address of the original shared variable.\n  /// \\param DRD Declare reduction construct used for reduction item.\n  void emitAggregateInitialization(CodeGenFunction &CGF, unsigned N,\n                                   Address PrivateAddr, LValue SharedLVal,\n                                   const OMPDeclareReductionDecl *DRD);\n\npublic:\n  ReductionCodeGen(ArrayRef<const Expr *> Shareds, ArrayRef<const Expr *> Origs,\n                   ArrayRef<const Expr *> Privates,\n                   ArrayRef<const Expr *> ReductionOps);\n  /// Emits lvalue for the shared and original reduction item.\n  /// \\param N Number of the reduction item.\n  void emitSharedOrigLValue(CodeGenFunction &CGF, unsigned N);\n  /// Emits the code for the variable-modified type, if required.\n  /// \\param N Number of the reduction item.\n  void emitAggregateType(CodeGenFunction &CGF, unsigned N);\n  /// Emits the code for the variable-modified type, if required.\n  /// \\param N Number of the reduction item.\n  /// \\param Size Size of the type in chars.\n  void emitAggregateType(CodeGenFunction &CGF, unsigned N, llvm::Value *Size);\n  /// Performs initialization of the private copy for the reduction item.\n  /// \\param N Number of the reduction item.\n  /// \\param PrivateAddr Address of the corresponding private item.\n  /// \\param DefaultInit Default initialization sequence that should be\n  /// performed if no reduction specific initialization is found.\n  /// \\param SharedLVal Address of the original shared variable.\n  void\n  emitInitialization(CodeGenFunction &CGF, unsigned N, Address PrivateAddr,\n                     LValue SharedLVal,\n                     llvm::function_ref<bool(CodeGenFunction &)> DefaultInit);\n  /// Returns true if the private copy requires cleanups.\n  bool needCleanups(unsigned N);\n  /// Emits cleanup code for the reduction item.\n  /// \\param N Number of the reduction item.\n  /// \\param PrivateAddr Address of the corresponding private item.\n  void emitCleanups(CodeGenFunction &CGF, unsigned N, Address PrivateAddr);\n  /// Adjusts \\p PrivatedAddr for using instead of the original variable\n  /// address in normal operations.\n  /// \\param N Number of the reduction item.\n  /// \\param PrivateAddr Address of the corresponding private item.\n  Address adjustPrivateAddress(CodeGenFunction &CGF, unsigned N,\n                               Address PrivateAddr);\n  /// Returns LValue for the reduction item.\n  LValue getSharedLValue(unsigned N) const { return SharedAddresses[N].first; }\n  /// Returns LValue for the original reduction item.\n  LValue getOrigLValue(unsigned N) const { return OrigAddresses[N].first; }\n  /// Returns the size of the reduction item (in chars and total number of\n  /// elements in the item), or nullptr, if the size is a constant.\n  std::pair<llvm::Value *, llvm::Value *> getSizes(unsigned N) const {\n    return Sizes[N];\n  }\n  /// Returns the base declaration of the reduction item.\n  const VarDecl *getBaseDecl(unsigned N) const { return BaseDecls[N]; }\n  /// Returns the base declaration of the reduction item.\n  const Expr *getRefExpr(unsigned N) const { return ClausesData[N].Ref; }\n  /// Returns true if the initialization of the reduction item uses initializer\n  /// from declare reduction construct.\n  bool usesReductionInitializer(unsigned N) const;\n};\n\nclass CGOpenMPRuntime {\npublic:\n  /// Allows to disable automatic handling of functions used in target regions\n  /// as those marked as `omp declare target`.\n  class DisableAutoDeclareTargetRAII {\n    CodeGenModule &CGM;\n    bool SavedShouldMarkAsGlobal;\n\n  public:\n    DisableAutoDeclareTargetRAII(CodeGenModule &CGM);\n    ~DisableAutoDeclareTargetRAII();\n  };\n\n  /// Manages list of nontemporal decls for the specified directive.\n  class NontemporalDeclsRAII {\n    CodeGenModule &CGM;\n    const bool NeedToPush;\n\n  public:\n    NontemporalDeclsRAII(CodeGenModule &CGM, const OMPLoopDirective &S);\n    ~NontemporalDeclsRAII();\n  };\n\n  /// Manages list of nontemporal decls for the specified directive.\n  class UntiedTaskLocalDeclsRAII {\n    CodeGenModule &CGM;\n    const bool NeedToPush;\n\n  public:\n    UntiedTaskLocalDeclsRAII(\n        CodeGenFunction &CGF,\n        const llvm::DenseMap<CanonicalDeclPtr<const VarDecl>,\n                             std::pair<Address, Address>> &LocalVars);\n    ~UntiedTaskLocalDeclsRAII();\n  };\n\n  /// Maps the expression for the lastprivate variable to the global copy used\n  /// to store new value because original variables are not mapped in inner\n  /// parallel regions. Only private copies are captured but we need also to\n  /// store private copy in shared address.\n  /// Also, stores the expression for the private loop counter and it\n  /// threaprivate name.\n  struct LastprivateConditionalData {\n    llvm::MapVector<CanonicalDeclPtr<const Decl>, SmallString<16>>\n        DeclToUniqueName;\n    LValue IVLVal;\n    llvm::Function *Fn = nullptr;\n    bool Disabled = false;\n  };\n  /// Manages list of lastprivate conditional decls for the specified directive.\n  class LastprivateConditionalRAII {\n    enum class ActionToDo {\n      DoNotPush,\n      PushAsLastprivateConditional,\n      DisableLastprivateConditional,\n    };\n    CodeGenModule &CGM;\n    ActionToDo Action = ActionToDo::DoNotPush;\n\n    /// Check and try to disable analysis of inner regions for changes in\n    /// lastprivate conditional.\n    void tryToDisableInnerAnalysis(const OMPExecutableDirective &S,\n                                   llvm::DenseSet<CanonicalDeclPtr<const Decl>>\n                                       &NeedToAddForLPCsAsDisabled) const;\n\n    LastprivateConditionalRAII(CodeGenFunction &CGF,\n                               const OMPExecutableDirective &S);\n\n  public:\n    explicit LastprivateConditionalRAII(CodeGenFunction &CGF,\n                                        const OMPExecutableDirective &S,\n                                        LValue IVLVal);\n    static LastprivateConditionalRAII disable(CodeGenFunction &CGF,\n                                              const OMPExecutableDirective &S);\n    ~LastprivateConditionalRAII();\n  };\n\n  llvm::OpenMPIRBuilder &getOMPBuilder() { return OMPBuilder; }\n\nprotected:\n  CodeGenModule &CGM;\n  StringRef FirstSeparator, Separator;\n\n  /// An OpenMP-IR-Builder instance.\n  llvm::OpenMPIRBuilder OMPBuilder;\n\n  /// Constructor allowing to redefine the name separator for the variables.\n  explicit CGOpenMPRuntime(CodeGenModule &CGM, StringRef FirstSeparator,\n                           StringRef Separator);\n\n  /// Creates offloading entry for the provided entry ID \\a ID,\n  /// address \\a Addr, size \\a Size, and flags \\a Flags.\n  virtual void createOffloadEntry(llvm::Constant *ID, llvm::Constant *Addr,\n                                  uint64_t Size, int32_t Flags,\n                                  llvm::GlobalValue::LinkageTypes Linkage);\n\n  /// Helper to emit outlined function for 'target' directive.\n  /// \\param D Directive to emit.\n  /// \\param ParentName Name of the function that encloses the target region.\n  /// \\param OutlinedFn Outlined function value to be defined by this call.\n  /// \\param OutlinedFnID Outlined function ID value to be defined by this call.\n  /// \\param IsOffloadEntry True if the outlined function is an offload entry.\n  /// \\param CodeGen Lambda codegen specific to an accelerator device.\n  /// An outlined function may not be an entry if, e.g. the if clause always\n  /// evaluates to false.\n  virtual void emitTargetOutlinedFunctionHelper(const OMPExecutableDirective &D,\n                                                StringRef ParentName,\n                                                llvm::Function *&OutlinedFn,\n                                                llvm::Constant *&OutlinedFnID,\n                                                bool IsOffloadEntry,\n                                                const RegionCodeGenTy &CodeGen);\n\n  /// Emits object of ident_t type with info for source location.\n  /// \\param Flags Flags for OpenMP location.\n  ///\n  llvm::Value *emitUpdateLocation(CodeGenFunction &CGF, SourceLocation Loc,\n                                  unsigned Flags = 0);\n\n  /// Returns pointer to ident_t type.\n  llvm::Type *getIdentTyPointerTy();\n\n  /// Gets thread id value for the current thread.\n  ///\n  llvm::Value *getThreadID(CodeGenFunction &CGF, SourceLocation Loc);\n\n  /// Get the function name of an outlined region.\n  //  The name can be customized depending on the target.\n  //\n  virtual StringRef getOutlinedHelperName() const { return \".omp_outlined.\"; }\n\n  /// Emits \\p Callee function call with arguments \\p Args with location \\p Loc.\n  void emitCall(CodeGenFunction &CGF, SourceLocation Loc,\n                llvm::FunctionCallee Callee,\n                ArrayRef<llvm::Value *> Args = llvm::None) const;\n\n  /// Emits address of the word in a memory where current thread id is\n  /// stored.\n  virtual Address emitThreadIDAddress(CodeGenFunction &CGF, SourceLocation Loc);\n\n  void setLocThreadIdInsertPt(CodeGenFunction &CGF,\n                              bool AtCurrentPoint = false);\n  void clearLocThreadIdInsertPt(CodeGenFunction &CGF);\n\n  /// Check if the default location must be constant.\n  /// Default is false to support OMPT/OMPD.\n  virtual bool isDefaultLocationConstant() const { return false; }\n\n  /// Returns additional flags that can be stored in reserved_2 field of the\n  /// default location.\n  virtual unsigned getDefaultLocationReserved2Flags() const { return 0; }\n\n  /// Returns default flags for the barriers depending on the directive, for\n  /// which this barier is going to be emitted.\n  static unsigned getDefaultFlagsForBarriers(OpenMPDirectiveKind Kind);\n\n  /// Get the LLVM type for the critical name.\n  llvm::ArrayType *getKmpCriticalNameTy() const {return KmpCriticalNameTy;}\n\n  /// Returns corresponding lock object for the specified critical region\n  /// name. If the lock object does not exist it is created, otherwise the\n  /// reference to the existing copy is returned.\n  /// \\param CriticalName Name of the critical region.\n  ///\n  llvm::Value *getCriticalRegionLock(StringRef CriticalName);\n\nprivate:\n\n  /// Map for SourceLocation and OpenMP runtime library debug locations.\n  typedef llvm::DenseMap<SourceLocation, llvm::Value *> OpenMPDebugLocMapTy;\n  OpenMPDebugLocMapTy OpenMPDebugLocMap;\n  /// The type for a microtask which gets passed to __kmpc_fork_call().\n  /// Original representation is:\n  /// typedef void (kmpc_micro)(kmp_int32 global_tid, kmp_int32 bound_tid,...);\n  llvm::FunctionType *Kmpc_MicroTy = nullptr;\n  /// Stores debug location and ThreadID for the function.\n  struct DebugLocThreadIdTy {\n    llvm::Value *DebugLoc;\n    llvm::Value *ThreadID;\n    /// Insert point for the service instructions.\n    llvm::AssertingVH<llvm::Instruction> ServiceInsertPt = nullptr;\n  };\n  /// Map of local debug location, ThreadId and functions.\n  typedef llvm::DenseMap<llvm::Function *, DebugLocThreadIdTy>\n      OpenMPLocThreadIDMapTy;\n  OpenMPLocThreadIDMapTy OpenMPLocThreadIDMap;\n  /// Map of UDRs and corresponding combiner/initializer.\n  typedef llvm::DenseMap<const OMPDeclareReductionDecl *,\n                         std::pair<llvm::Function *, llvm::Function *>>\n      UDRMapTy;\n  UDRMapTy UDRMap;\n  /// Map of functions and locally defined UDRs.\n  typedef llvm::DenseMap<llvm::Function *,\n                         SmallVector<const OMPDeclareReductionDecl *, 4>>\n      FunctionUDRMapTy;\n  FunctionUDRMapTy FunctionUDRMap;\n  /// Map from the user-defined mapper declaration to its corresponding\n  /// functions.\n  llvm::DenseMap<const OMPDeclareMapperDecl *, llvm::Function *> UDMMap;\n  /// Map of functions and their local user-defined mappers.\n  using FunctionUDMMapTy =\n      llvm::DenseMap<llvm::Function *,\n                     SmallVector<const OMPDeclareMapperDecl *, 4>>;\n  FunctionUDMMapTy FunctionUDMMap;\n  /// Maps local variables marked as lastprivate conditional to their internal\n  /// types.\n  llvm::DenseMap<llvm::Function *,\n                 llvm::DenseMap<CanonicalDeclPtr<const Decl>,\n                                std::tuple<QualType, const FieldDecl *,\n                                           const FieldDecl *, LValue>>>\n      LastprivateConditionalToTypes;\n  /// Maps function to the position of the untied task locals stack.\n  llvm::DenseMap<llvm::Function *, unsigned> FunctionToUntiedTaskStackMap;\n  /// Type kmp_critical_name, originally defined as typedef kmp_int32\n  /// kmp_critical_name[8];\n  llvm::ArrayType *KmpCriticalNameTy;\n  /// An ordered map of auto-generated variables to their unique names.\n  /// It stores variables with the following names: 1) \".gomp_critical_user_\" +\n  /// <critical_section_name> + \".var\" for \"omp critical\" directives; 2)\n  /// <mangled_name_for_global_var> + \".cache.\" for cache for threadprivate\n  /// variables.\n  llvm::StringMap<llvm::AssertingVH<llvm::Constant>, llvm::BumpPtrAllocator>\n      InternalVars;\n  /// Type typedef kmp_int32 (* kmp_routine_entry_t)(kmp_int32, void *);\n  llvm::Type *KmpRoutineEntryPtrTy = nullptr;\n  QualType KmpRoutineEntryPtrQTy;\n  /// Type typedef struct kmp_task {\n  ///    void *              shareds; /**< pointer to block of pointers to\n  ///    shared vars   */\n  ///    kmp_routine_entry_t routine; /**< pointer to routine to call for\n  ///    executing task */\n  ///    kmp_int32           part_id; /**< part id for the task */\n  ///    kmp_routine_entry_t destructors; /* pointer to function to invoke\n  ///    deconstructors of firstprivate C++ objects */\n  /// } kmp_task_t;\n  QualType KmpTaskTQTy;\n  /// Saved kmp_task_t for task directive.\n  QualType SavedKmpTaskTQTy;\n  /// Saved kmp_task_t for taskloop-based directive.\n  QualType SavedKmpTaskloopTQTy;\n  /// Type typedef struct kmp_depend_info {\n  ///    kmp_intptr_t               base_addr;\n  ///    size_t                     len;\n  ///    struct {\n  ///             bool                   in:1;\n  ///             bool                   out:1;\n  ///    } flags;\n  /// } kmp_depend_info_t;\n  QualType KmpDependInfoTy;\n  /// Type typedef struct kmp_task_affinity_info {\n  ///    kmp_intptr_t base_addr;\n  ///    size_t len;\n  ///    struct {\n  ///      bool flag1 : 1;\n  ///      bool flag2 : 1;\n  ///      kmp_int32 reserved : 30;\n  ///   } flags;\n  /// } kmp_task_affinity_info_t;\n  QualType KmpTaskAffinityInfoTy;\n  /// struct kmp_dim {  // loop bounds info casted to kmp_int64\n  ///  kmp_int64 lo; // lower\n  ///  kmp_int64 up; // upper\n  ///  kmp_int64 st; // stride\n  /// };\n  QualType KmpDimTy;\n  /// Type struct __tgt_offload_entry{\n  ///   void      *addr;       // Pointer to the offload entry info.\n  ///                          // (function or global)\n  ///   char      *name;       // Name of the function or global.\n  ///   size_t     size;       // Size of the entry info (0 if it a function).\n  ///   int32_t flags;\n  ///   int32_t reserved;\n  /// };\n  QualType TgtOffloadEntryQTy;\n  /// Entity that registers the offloading constants that were emitted so\n  /// far.\n  class OffloadEntriesInfoManagerTy {\n    CodeGenModule &CGM;\n\n    /// Number of entries registered so far.\n    unsigned OffloadingEntriesNum = 0;\n\n  public:\n    /// Base class of the entries info.\n    class OffloadEntryInfo {\n    public:\n      /// Kind of a given entry.\n      enum OffloadingEntryInfoKinds : unsigned {\n        /// Entry is a target region.\n        OffloadingEntryInfoTargetRegion = 0,\n        /// Entry is a declare target variable.\n        OffloadingEntryInfoDeviceGlobalVar = 1,\n        /// Invalid entry info.\n        OffloadingEntryInfoInvalid = ~0u\n      };\n\n    protected:\n      OffloadEntryInfo() = delete;\n      explicit OffloadEntryInfo(OffloadingEntryInfoKinds Kind) : Kind(Kind) {}\n      explicit OffloadEntryInfo(OffloadingEntryInfoKinds Kind, unsigned Order,\n                                uint32_t Flags)\n          : Flags(Flags), Order(Order), Kind(Kind) {}\n      ~OffloadEntryInfo() = default;\n\n    public:\n      bool isValid() const { return Order != ~0u; }\n      unsigned getOrder() const { return Order; }\n      OffloadingEntryInfoKinds getKind() const { return Kind; }\n      uint32_t getFlags() const { return Flags; }\n      void setFlags(uint32_t NewFlags) { Flags = NewFlags; }\n      llvm::Constant *getAddress() const {\n        return cast_or_null<llvm::Constant>(Addr);\n      }\n      void setAddress(llvm::Constant *V) {\n        assert(!Addr.pointsToAliveValue() && \"Address has been set before!\");\n        Addr = V;\n      }\n      static bool classof(const OffloadEntryInfo *Info) { return true; }\n\n    private:\n      /// Address of the entity that has to be mapped for offloading.\n      llvm::WeakTrackingVH Addr;\n\n      /// Flags associated with the device global.\n      uint32_t Flags = 0u;\n\n      /// Order this entry was emitted.\n      unsigned Order = ~0u;\n\n      OffloadingEntryInfoKinds Kind = OffloadingEntryInfoInvalid;\n    };\n\n    /// Return true if a there are no entries defined.\n    bool empty() const;\n    /// Return number of entries defined so far.\n    unsigned size() const { return OffloadingEntriesNum; }\n    OffloadEntriesInfoManagerTy(CodeGenModule &CGM) : CGM(CGM) {}\n\n    //\n    // Target region entries related.\n    //\n\n    /// Kind of the target registry entry.\n    enum OMPTargetRegionEntryKind : uint32_t {\n      /// Mark the entry as target region.\n      OMPTargetRegionEntryTargetRegion = 0x0,\n      /// Mark the entry as a global constructor.\n      OMPTargetRegionEntryCtor = 0x02,\n      /// Mark the entry as a global destructor.\n      OMPTargetRegionEntryDtor = 0x04,\n    };\n\n    /// Target region entries info.\n    class OffloadEntryInfoTargetRegion final : public OffloadEntryInfo {\n      /// Address that can be used as the ID of the entry.\n      llvm::Constant *ID = nullptr;\n\n    public:\n      OffloadEntryInfoTargetRegion()\n          : OffloadEntryInfo(OffloadingEntryInfoTargetRegion) {}\n      explicit OffloadEntryInfoTargetRegion(unsigned Order,\n                                            llvm::Constant *Addr,\n                                            llvm::Constant *ID,\n                                            OMPTargetRegionEntryKind Flags)\n          : OffloadEntryInfo(OffloadingEntryInfoTargetRegion, Order, Flags),\n            ID(ID) {\n        setAddress(Addr);\n      }\n\n      llvm::Constant *getID() const { return ID; }\n      void setID(llvm::Constant *V) {\n        assert(!ID && \"ID has been set before!\");\n        ID = V;\n      }\n      static bool classof(const OffloadEntryInfo *Info) {\n        return Info->getKind() == OffloadingEntryInfoTargetRegion;\n      }\n    };\n\n    /// Initialize target region entry.\n    void initializeTargetRegionEntryInfo(unsigned DeviceID, unsigned FileID,\n                                         StringRef ParentName, unsigned LineNum,\n                                         unsigned Order);\n    /// Register target region entry.\n    void registerTargetRegionEntryInfo(unsigned DeviceID, unsigned FileID,\n                                       StringRef ParentName, unsigned LineNum,\n                                       llvm::Constant *Addr, llvm::Constant *ID,\n                                       OMPTargetRegionEntryKind Flags);\n    /// Return true if a target region entry with the provided information\n    /// exists.\n    bool hasTargetRegionEntryInfo(unsigned DeviceID, unsigned FileID,\n                                  StringRef ParentName, unsigned LineNum,\n                                  bool IgnoreAddressId = false) const;\n    /// brief Applies action \\a Action on all registered entries.\n    typedef llvm::function_ref<void(unsigned, unsigned, StringRef, unsigned,\n                                    const OffloadEntryInfoTargetRegion &)>\n        OffloadTargetRegionEntryInfoActTy;\n    void actOnTargetRegionEntriesInfo(\n        const OffloadTargetRegionEntryInfoActTy &Action);\n\n    //\n    // Device global variable entries related.\n    //\n\n    /// Kind of the global variable entry..\n    enum OMPTargetGlobalVarEntryKind : uint32_t {\n      /// Mark the entry as a to declare target.\n      OMPTargetGlobalVarEntryTo = 0x0,\n      /// Mark the entry as a to declare target link.\n      OMPTargetGlobalVarEntryLink = 0x1,\n    };\n\n    /// Device global variable entries info.\n    class OffloadEntryInfoDeviceGlobalVar final : public OffloadEntryInfo {\n      /// Type of the global variable.\n     CharUnits VarSize;\n     llvm::GlobalValue::LinkageTypes Linkage;\n\n   public:\n     OffloadEntryInfoDeviceGlobalVar()\n         : OffloadEntryInfo(OffloadingEntryInfoDeviceGlobalVar) {}\n     explicit OffloadEntryInfoDeviceGlobalVar(unsigned Order,\n                                              OMPTargetGlobalVarEntryKind Flags)\n         : OffloadEntryInfo(OffloadingEntryInfoDeviceGlobalVar, Order, Flags) {}\n     explicit OffloadEntryInfoDeviceGlobalVar(\n         unsigned Order, llvm::Constant *Addr, CharUnits VarSize,\n         OMPTargetGlobalVarEntryKind Flags,\n         llvm::GlobalValue::LinkageTypes Linkage)\n         : OffloadEntryInfo(OffloadingEntryInfoDeviceGlobalVar, Order, Flags),\n           VarSize(VarSize), Linkage(Linkage) {\n       setAddress(Addr);\n      }\n\n      CharUnits getVarSize() const { return VarSize; }\n      void setVarSize(CharUnits Size) { VarSize = Size; }\n      llvm::GlobalValue::LinkageTypes getLinkage() const { return Linkage; }\n      void setLinkage(llvm::GlobalValue::LinkageTypes LT) { Linkage = LT; }\n      static bool classof(const OffloadEntryInfo *Info) {\n        return Info->getKind() == OffloadingEntryInfoDeviceGlobalVar;\n      }\n    };\n\n    /// Initialize device global variable entry.\n    void initializeDeviceGlobalVarEntryInfo(StringRef Name,\n                                            OMPTargetGlobalVarEntryKind Flags,\n                                            unsigned Order);\n\n    /// Register device global variable entry.\n    void\n    registerDeviceGlobalVarEntryInfo(StringRef VarName, llvm::Constant *Addr,\n                                     CharUnits VarSize,\n                                     OMPTargetGlobalVarEntryKind Flags,\n                                     llvm::GlobalValue::LinkageTypes Linkage);\n    /// Checks if the variable with the given name has been registered already.\n    bool hasDeviceGlobalVarEntryInfo(StringRef VarName) const {\n      return OffloadEntriesDeviceGlobalVar.count(VarName) > 0;\n    }\n    /// Applies action \\a Action on all registered entries.\n    typedef llvm::function_ref<void(StringRef,\n                                    const OffloadEntryInfoDeviceGlobalVar &)>\n        OffloadDeviceGlobalVarEntryInfoActTy;\n    void actOnDeviceGlobalVarEntriesInfo(\n        const OffloadDeviceGlobalVarEntryInfoActTy &Action);\n\n  private:\n    // Storage for target region entries kind. The storage is to be indexed by\n    // file ID, device ID, parent function name and line number.\n    typedef llvm::DenseMap<unsigned, OffloadEntryInfoTargetRegion>\n        OffloadEntriesTargetRegionPerLine;\n    typedef llvm::StringMap<OffloadEntriesTargetRegionPerLine>\n        OffloadEntriesTargetRegionPerParentName;\n    typedef llvm::DenseMap<unsigned, OffloadEntriesTargetRegionPerParentName>\n        OffloadEntriesTargetRegionPerFile;\n    typedef llvm::DenseMap<unsigned, OffloadEntriesTargetRegionPerFile>\n        OffloadEntriesTargetRegionPerDevice;\n    typedef OffloadEntriesTargetRegionPerDevice OffloadEntriesTargetRegionTy;\n    OffloadEntriesTargetRegionTy OffloadEntriesTargetRegion;\n    /// Storage for device global variable entries kind. The storage is to be\n    /// indexed by mangled name.\n    typedef llvm::StringMap<OffloadEntryInfoDeviceGlobalVar>\n        OffloadEntriesDeviceGlobalVarTy;\n    OffloadEntriesDeviceGlobalVarTy OffloadEntriesDeviceGlobalVar;\n  };\n  OffloadEntriesInfoManagerTy OffloadEntriesInfoManager;\n\n  bool ShouldMarkAsGlobal = true;\n  /// List of the emitted declarations.\n  llvm::DenseSet<CanonicalDeclPtr<const Decl>> AlreadyEmittedTargetDecls;\n  /// List of the global variables with their addresses that should not be\n  /// emitted for the target.\n  llvm::StringMap<llvm::WeakTrackingVH> EmittedNonTargetVariables;\n\n  /// List of variables that can become declare target implicitly and, thus,\n  /// must be emitted.\n  llvm::SmallDenseSet<const VarDecl *> DeferredGlobalVariables;\n\n  using NontemporalDeclsSet = llvm::SmallDenseSet<CanonicalDeclPtr<const Decl>>;\n  /// Stack for list of declarations in current context marked as nontemporal.\n  /// The set is the union of all current stack elements.\n  llvm::SmallVector<NontemporalDeclsSet, 4> NontemporalDeclsStack;\n\n  using UntiedLocalVarsAddressesMap =\n      llvm::DenseMap<CanonicalDeclPtr<const VarDecl>,\n                     std::pair<Address, Address>>;\n  llvm::SmallVector<UntiedLocalVarsAddressesMap, 4> UntiedLocalVarsStack;\n\n  /// Stack for list of addresses of declarations in current context marked as\n  /// lastprivate conditional. The set is the union of all current stack\n  /// elements.\n  llvm::SmallVector<LastprivateConditionalData, 4> LastprivateConditionalStack;\n\n  /// Flag for keeping track of weather a requires unified_shared_memory\n  /// directive is present.\n  bool HasRequiresUnifiedSharedMemory = false;\n\n  /// Atomic ordering from the omp requires directive.\n  llvm::AtomicOrdering RequiresAtomicOrdering = llvm::AtomicOrdering::Monotonic;\n\n  /// Flag for keeping track of weather a target region has been emitted.\n  bool HasEmittedTargetRegion = false;\n\n  /// Flag for keeping track of weather a device routine has been emitted.\n  /// Device routines are specific to the\n  bool HasEmittedDeclareTargetRegion = false;\n\n  /// Loads all the offload entries information from the host IR\n  /// metadata.\n  void loadOffloadInfoMetadata();\n\n  /// Returns __tgt_offload_entry type.\n  QualType getTgtOffloadEntryQTy();\n\n  /// Start scanning from statement \\a S and and emit all target regions\n  /// found along the way.\n  /// \\param S Starting statement.\n  /// \\param ParentName Name of the function declaration that is being scanned.\n  void scanForTargetRegionsFunctions(const Stmt *S, StringRef ParentName);\n\n  /// Build type kmp_routine_entry_t (if not built yet).\n  void emitKmpRoutineEntryT(QualType KmpInt32Ty);\n\n  /// Returns pointer to kmpc_micro type.\n  llvm::Type *getKmpc_MicroPointerTy();\n\n  /// Returns __kmpc_for_static_init_* runtime function for the specified\n  /// size \\a IVSize and sign \\a IVSigned.\n  llvm::FunctionCallee createForStaticInitFunction(unsigned IVSize,\n                                                   bool IVSigned);\n\n  /// Returns __kmpc_dispatch_init_* runtime function for the specified\n  /// size \\a IVSize and sign \\a IVSigned.\n  llvm::FunctionCallee createDispatchInitFunction(unsigned IVSize,\n                                                  bool IVSigned);\n\n  /// Returns __kmpc_dispatch_next_* runtime function for the specified\n  /// size \\a IVSize and sign \\a IVSigned.\n  llvm::FunctionCallee createDispatchNextFunction(unsigned IVSize,\n                                                  bool IVSigned);\n\n  /// Returns __kmpc_dispatch_fini_* runtime function for the specified\n  /// size \\a IVSize and sign \\a IVSigned.\n  llvm::FunctionCallee createDispatchFiniFunction(unsigned IVSize,\n                                                  bool IVSigned);\n\n  /// If the specified mangled name is not in the module, create and\n  /// return threadprivate cache object. This object is a pointer's worth of\n  /// storage that's reserved for use by the OpenMP runtime.\n  /// \\param VD Threadprivate variable.\n  /// \\return Cache variable for the specified threadprivate.\n  llvm::Constant *getOrCreateThreadPrivateCache(const VarDecl *VD);\n\n  /// Gets (if variable with the given name already exist) or creates\n  /// internal global variable with the specified Name. The created variable has\n  /// linkage CommonLinkage by default and is initialized by null value.\n  /// \\param Ty Type of the global variable. If it is exist already the type\n  /// must be the same.\n  /// \\param Name Name of the variable.\n  llvm::Constant *getOrCreateInternalVariable(llvm::Type *Ty,\n                                              const llvm::Twine &Name,\n                                              unsigned AddressSpace = 0);\n\n  /// Set of threadprivate variables with the generated initializer.\n  llvm::StringSet<> ThreadPrivateWithDefinition;\n\n  /// Set of declare target variables with the generated initializer.\n  llvm::StringSet<> DeclareTargetWithDefinition;\n\n  /// Emits initialization code for the threadprivate variables.\n  /// \\param VDAddr Address of the global variable \\a VD.\n  /// \\param Ctor Pointer to a global init function for \\a VD.\n  /// \\param CopyCtor Pointer to a global copy function for \\a VD.\n  /// \\param Dtor Pointer to a global destructor function for \\a VD.\n  /// \\param Loc Location of threadprivate declaration.\n  void emitThreadPrivateVarInit(CodeGenFunction &CGF, Address VDAddr,\n                                llvm::Value *Ctor, llvm::Value *CopyCtor,\n                                llvm::Value *Dtor, SourceLocation Loc);\n\n  /// Emit the array initialization or deletion portion for user-defined mapper\n  /// code generation.\n  void emitUDMapperArrayInitOrDel(CodeGenFunction &MapperCGF,\n                                  llvm::Value *Handle, llvm::Value *BasePtr,\n                                  llvm::Value *Ptr, llvm::Value *Size,\n                                  llvm::Value *MapType, CharUnits ElementSize,\n                                  llvm::BasicBlock *ExitBB, bool IsInit);\n\n  struct TaskResultTy {\n    llvm::Value *NewTask = nullptr;\n    llvm::Function *TaskEntry = nullptr;\n    llvm::Value *NewTaskNewTaskTTy = nullptr;\n    LValue TDBase;\n    const RecordDecl *KmpTaskTQTyRD = nullptr;\n    llvm::Value *TaskDupFn = nullptr;\n  };\n  /// Emit task region for the task directive. The task region is emitted in\n  /// several steps:\n  /// 1. Emit a call to kmp_task_t *__kmpc_omp_task_alloc(ident_t *, kmp_int32\n  /// gtid, kmp_int32 flags, size_t sizeof_kmp_task_t, size_t sizeof_shareds,\n  /// kmp_routine_entry_t *task_entry). Here task_entry is a pointer to the\n  /// function:\n  /// kmp_int32 .omp_task_entry.(kmp_int32 gtid, kmp_task_t *tt) {\n  ///   TaskFunction(gtid, tt->part_id, tt->shareds);\n  ///   return 0;\n  /// }\n  /// 2. Copy a list of shared variables to field shareds of the resulting\n  /// structure kmp_task_t returned by the previous call (if any).\n  /// 3. Copy a pointer to destructions function to field destructions of the\n  /// resulting structure kmp_task_t.\n  /// \\param D Current task directive.\n  /// \\param TaskFunction An LLVM function with type void (*)(i32 /*gtid*/, i32\n  /// /*part_id*/, captured_struct */*__context*/);\n  /// \\param SharedsTy A type which contains references the shared variables.\n  /// \\param Shareds Context with the list of shared variables from the \\p\n  /// TaskFunction.\n  /// \\param Data Additional data for task generation like tiednsee, final\n  /// state, list of privates etc.\n  TaskResultTy emitTaskInit(CodeGenFunction &CGF, SourceLocation Loc,\n                            const OMPExecutableDirective &D,\n                            llvm::Function *TaskFunction, QualType SharedsTy,\n                            Address Shareds, const OMPTaskDataTy &Data);\n\n  /// Returns default address space for the constant firstprivates, 0 by\n  /// default.\n  virtual unsigned getDefaultFirstprivateAddressSpace() const { return 0; }\n\n  /// Emit code that pushes the trip count of loops associated with constructs\n  /// 'target teams distribute' and 'teams distribute parallel for'.\n  /// \\param SizeEmitter Emits the int64 value for the number of iterations of\n  /// the associated loop.\n  void emitTargetNumIterationsCall(\n      CodeGenFunction &CGF, const OMPExecutableDirective &D,\n      llvm::Value *DeviceID,\n      llvm::function_ref<llvm::Value *(CodeGenFunction &CGF,\n                                       const OMPLoopDirective &D)>\n          SizeEmitter);\n\n  /// Emit update for lastprivate conditional data.\n  void emitLastprivateConditionalUpdate(CodeGenFunction &CGF, LValue IVLVal,\n                                        StringRef UniqueDeclName, LValue LVal,\n                                        SourceLocation Loc);\n\n  /// Returns the number of the elements and the address of the depobj\n  /// dependency array.\n  /// \\return Number of elements in depobj array and the pointer to the array of\n  /// dependencies.\n  std::pair<llvm::Value *, LValue> getDepobjElements(CodeGenFunction &CGF,\n                                                     LValue DepobjLVal,\n                                                     SourceLocation Loc);\n\npublic:\n  explicit CGOpenMPRuntime(CodeGenModule &CGM)\n      : CGOpenMPRuntime(CGM, \".\", \".\") {}\n  virtual ~CGOpenMPRuntime() {}\n  virtual void clear();\n\n  /// Emits code for OpenMP 'if' clause using specified \\a CodeGen\n  /// function. Here is the logic:\n  /// if (Cond) {\n  ///   ThenGen();\n  /// } else {\n  ///   ElseGen();\n  /// }\n  void emitIfClause(CodeGenFunction &CGF, const Expr *Cond,\n                    const RegionCodeGenTy &ThenGen,\n                    const RegionCodeGenTy &ElseGen);\n\n  /// Checks if the \\p Body is the \\a CompoundStmt and returns its child\n  /// statement iff there is only one that is not evaluatable at the compile\n  /// time.\n  static const Stmt *getSingleCompoundChild(ASTContext &Ctx, const Stmt *Body);\n\n  /// Get the platform-specific name separator.\n  std::string getName(ArrayRef<StringRef> Parts) const;\n\n  /// Emit code for the specified user defined reduction construct.\n  virtual void emitUserDefinedReduction(CodeGenFunction *CGF,\n                                        const OMPDeclareReductionDecl *D);\n  /// Get combiner/initializer for the specified user-defined reduction, if any.\n  virtual std::pair<llvm::Function *, llvm::Function *>\n  getUserDefinedReduction(const OMPDeclareReductionDecl *D);\n\n  /// Emit the function for the user defined mapper construct.\n  void emitUserDefinedMapper(const OMPDeclareMapperDecl *D,\n                             CodeGenFunction *CGF = nullptr);\n  /// Get the function for the specified user-defined mapper. If it does not\n  /// exist, create one.\n  llvm::Function *\n  getOrCreateUserDefinedMapperFunc(const OMPDeclareMapperDecl *D);\n\n  /// Emits outlined function for the specified OpenMP parallel directive\n  /// \\a D. This outlined function has type void(*)(kmp_int32 *ThreadID,\n  /// kmp_int32 BoundID, struct context_vars*).\n  /// \\param D OpenMP directive.\n  /// \\param ThreadIDVar Variable for thread id in the current OpenMP region.\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  virtual llvm::Function *emitParallelOutlinedFunction(\n      const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n      OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen);\n\n  /// Emits outlined function for the specified OpenMP teams directive\n  /// \\a D. This outlined function has type void(*)(kmp_int32 *ThreadID,\n  /// kmp_int32 BoundID, struct context_vars*).\n  /// \\param D OpenMP directive.\n  /// \\param ThreadIDVar Variable for thread id in the current OpenMP region.\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  virtual llvm::Function *emitTeamsOutlinedFunction(\n      const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n      OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen);\n\n  /// Emits outlined function for the OpenMP task directive \\a D. This\n  /// outlined function has type void(*)(kmp_int32 ThreadID, struct task_t*\n  /// TaskT).\n  /// \\param D OpenMP directive.\n  /// \\param ThreadIDVar Variable for thread id in the current OpenMP region.\n  /// \\param PartIDVar Variable for partition id in the current OpenMP untied\n  /// task region.\n  /// \\param TaskTVar Variable for task_t argument.\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  /// \\param Tied true if task is generated for tied task, false otherwise.\n  /// \\param NumberOfParts Number of parts in untied task. Ignored for tied\n  /// tasks.\n  ///\n  virtual llvm::Function *emitTaskOutlinedFunction(\n      const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n      const VarDecl *PartIDVar, const VarDecl *TaskTVar,\n      OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen,\n      bool Tied, unsigned &NumberOfParts);\n\n  /// Cleans up references to the objects in finished function.\n  ///\n  virtual void functionFinished(CodeGenFunction &CGF);\n\n  /// Emits code for parallel or serial call of the \\a OutlinedFn with\n  /// variables captured in a record which address is stored in \\a\n  /// CapturedStruct.\n  /// \\param OutlinedFn Outlined function to be run in parallel threads. Type of\n  /// this function is void(*)(kmp_int32 *, kmp_int32, struct context_vars*).\n  /// \\param CapturedVars A pointer to the record with the references to\n  /// variables used in \\a OutlinedFn function.\n  /// \\param IfCond Condition in the associated 'if' clause, if it was\n  /// specified, nullptr otherwise.\n  ///\n  virtual void emitParallelCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                llvm::Function *OutlinedFn,\n                                ArrayRef<llvm::Value *> CapturedVars,\n                                const Expr *IfCond);\n\n  /// Emits a critical region.\n  /// \\param CriticalName Name of the critical region.\n  /// \\param CriticalOpGen Generator for the statement associated with the given\n  /// critical region.\n  /// \\param Hint Value of the 'hint' clause (optional).\n  virtual void emitCriticalRegion(CodeGenFunction &CGF, StringRef CriticalName,\n                                  const RegionCodeGenTy &CriticalOpGen,\n                                  SourceLocation Loc,\n                                  const Expr *Hint = nullptr);\n\n  /// Emits a master region.\n  /// \\param MasterOpGen Generator for the statement associated with the given\n  /// master region.\n  virtual void emitMasterRegion(CodeGenFunction &CGF,\n                                const RegionCodeGenTy &MasterOpGen,\n                                SourceLocation Loc);\n\n  /// Emits code for a taskyield directive.\n  virtual void emitTaskyieldCall(CodeGenFunction &CGF, SourceLocation Loc);\n\n  /// Emit a taskgroup region.\n  /// \\param TaskgroupOpGen Generator for the statement associated with the\n  /// given taskgroup region.\n  virtual void emitTaskgroupRegion(CodeGenFunction &CGF,\n                                   const RegionCodeGenTy &TaskgroupOpGen,\n                                   SourceLocation Loc);\n\n  /// Emits a single region.\n  /// \\param SingleOpGen Generator for the statement associated with the given\n  /// single region.\n  virtual void emitSingleRegion(CodeGenFunction &CGF,\n                                const RegionCodeGenTy &SingleOpGen,\n                                SourceLocation Loc,\n                                ArrayRef<const Expr *> CopyprivateVars,\n                                ArrayRef<const Expr *> DestExprs,\n                                ArrayRef<const Expr *> SrcExprs,\n                                ArrayRef<const Expr *> AssignmentOps);\n\n  /// Emit an ordered region.\n  /// \\param OrderedOpGen Generator for the statement associated with the given\n  /// ordered region.\n  virtual void emitOrderedRegion(CodeGenFunction &CGF,\n                                 const RegionCodeGenTy &OrderedOpGen,\n                                 SourceLocation Loc, bool IsThreads);\n\n  /// Emit an implicit/explicit barrier for OpenMP threads.\n  /// \\param Kind Directive for which this implicit barrier call must be\n  /// generated. Must be OMPD_barrier for explicit barrier generation.\n  /// \\param EmitChecks true if need to emit checks for cancellation barriers.\n  /// \\param ForceSimpleCall true simple barrier call must be emitted, false if\n  /// runtime class decides which one to emit (simple or with cancellation\n  /// checks).\n  ///\n  virtual void emitBarrierCall(CodeGenFunction &CGF, SourceLocation Loc,\n                               OpenMPDirectiveKind Kind,\n                               bool EmitChecks = true,\n                               bool ForceSimpleCall = false);\n\n  /// Check if the specified \\a ScheduleKind is static non-chunked.\n  /// This kind of worksharing directive is emitted without outer loop.\n  /// \\param ScheduleKind Schedule kind specified in the 'schedule' clause.\n  /// \\param Chunked True if chunk is specified in the clause.\n  ///\n  virtual bool isStaticNonchunked(OpenMPScheduleClauseKind ScheduleKind,\n                                  bool Chunked) const;\n\n  /// Check if the specified \\a ScheduleKind is static non-chunked.\n  /// This kind of distribute directive is emitted without outer loop.\n  /// \\param ScheduleKind Schedule kind specified in the 'dist_schedule' clause.\n  /// \\param Chunked True if chunk is specified in the clause.\n  ///\n  virtual bool isStaticNonchunked(OpenMPDistScheduleClauseKind ScheduleKind,\n                                  bool Chunked) const;\n\n  /// Check if the specified \\a ScheduleKind is static chunked.\n  /// \\param ScheduleKind Schedule kind specified in the 'schedule' clause.\n  /// \\param Chunked True if chunk is specified in the clause.\n  ///\n  virtual bool isStaticChunked(OpenMPScheduleClauseKind ScheduleKind,\n                               bool Chunked) const;\n\n  /// Check if the specified \\a ScheduleKind is static non-chunked.\n  /// \\param ScheduleKind Schedule kind specified in the 'dist_schedule' clause.\n  /// \\param Chunked True if chunk is specified in the clause.\n  ///\n  virtual bool isStaticChunked(OpenMPDistScheduleClauseKind ScheduleKind,\n                               bool Chunked) const;\n\n  /// Check if the specified \\a ScheduleKind is dynamic.\n  /// This kind of worksharing directive is emitted without outer loop.\n  /// \\param ScheduleKind Schedule Kind specified in the 'schedule' clause.\n  ///\n  virtual bool isDynamic(OpenMPScheduleClauseKind ScheduleKind) const;\n\n  /// struct with the values to be passed to the dispatch runtime function\n  struct DispatchRTInput {\n    /// Loop lower bound\n    llvm::Value *LB = nullptr;\n    /// Loop upper bound\n    llvm::Value *UB = nullptr;\n    /// Chunk size specified using 'schedule' clause (nullptr if chunk\n    /// was not specified)\n    llvm::Value *Chunk = nullptr;\n    DispatchRTInput() = default;\n    DispatchRTInput(llvm::Value *LB, llvm::Value *UB, llvm::Value *Chunk)\n        : LB(LB), UB(UB), Chunk(Chunk) {}\n  };\n\n  /// Call the appropriate runtime routine to initialize it before start\n  /// of loop.\n\n  /// This is used for non static scheduled types and when the ordered\n  /// clause is present on the loop construct.\n  /// Depending on the loop schedule, it is necessary to call some runtime\n  /// routine before start of the OpenMP loop to get the loop upper / lower\n  /// bounds \\a LB and \\a UB and stride \\a ST.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param ScheduleKind Schedule kind, specified by the 'schedule' clause.\n  /// \\param IVSize Size of the iteration variable in bits.\n  /// \\param IVSigned Sign of the iteration variable.\n  /// \\param Ordered true if loop is ordered, false otherwise.\n  /// \\param DispatchValues struct containing llvm values for lower bound, upper\n  /// bound, and chunk expression.\n  /// For the default (nullptr) value, the chunk 1 will be used.\n  ///\n  virtual void emitForDispatchInit(CodeGenFunction &CGF, SourceLocation Loc,\n                                   const OpenMPScheduleTy &ScheduleKind,\n                                   unsigned IVSize, bool IVSigned, bool Ordered,\n                                   const DispatchRTInput &DispatchValues);\n\n  /// Struct with the values to be passed to the static runtime function\n  struct StaticRTInput {\n    /// Size of the iteration variable in bits.\n    unsigned IVSize = 0;\n    /// Sign of the iteration variable.\n    bool IVSigned = false;\n    /// true if loop is ordered, false otherwise.\n    bool Ordered = false;\n    /// Address of the output variable in which the flag of the last iteration\n    /// is returned.\n    Address IL = Address::invalid();\n    /// Address of the output variable in which the lower iteration number is\n    /// returned.\n    Address LB = Address::invalid();\n    /// Address of the output variable in which the upper iteration number is\n    /// returned.\n    Address UB = Address::invalid();\n    /// Address of the output variable in which the stride value is returned\n    /// necessary to generated the static_chunked scheduled loop.\n    Address ST = Address::invalid();\n    /// Value of the chunk for the static_chunked scheduled loop. For the\n    /// default (nullptr) value, the chunk 1 will be used.\n    llvm::Value *Chunk = nullptr;\n    StaticRTInput(unsigned IVSize, bool IVSigned, bool Ordered, Address IL,\n                  Address LB, Address UB, Address ST,\n                  llvm::Value *Chunk = nullptr)\n        : IVSize(IVSize), IVSigned(IVSigned), Ordered(Ordered), IL(IL), LB(LB),\n          UB(UB), ST(ST), Chunk(Chunk) {}\n  };\n  /// Call the appropriate runtime routine to initialize it before start\n  /// of loop.\n  ///\n  /// This is used only in case of static schedule, when the user did not\n  /// specify a ordered clause on the loop construct.\n  /// Depending on the loop schedule, it is necessary to call some runtime\n  /// routine before start of the OpenMP loop to get the loop upper / lower\n  /// bounds LB and UB and stride ST.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param DKind Kind of the directive.\n  /// \\param ScheduleKind Schedule kind, specified by the 'schedule' clause.\n  /// \\param Values Input arguments for the construct.\n  ///\n  virtual void emitForStaticInit(CodeGenFunction &CGF, SourceLocation Loc,\n                                 OpenMPDirectiveKind DKind,\n                                 const OpenMPScheduleTy &ScheduleKind,\n                                 const StaticRTInput &Values);\n\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param SchedKind Schedule kind, specified by the 'dist_schedule' clause.\n  /// \\param Values Input arguments for the construct.\n  ///\n  virtual void emitDistributeStaticInit(CodeGenFunction &CGF,\n                                        SourceLocation Loc,\n                                        OpenMPDistScheduleClauseKind SchedKind,\n                                        const StaticRTInput &Values);\n\n  /// Call the appropriate runtime routine to notify that we finished\n  /// iteration of the ordered loop with the dynamic scheduling.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param IVSize Size of the iteration variable in bits.\n  /// \\param IVSigned Sign of the iteration variable.\n  ///\n  virtual void emitForOrderedIterationEnd(CodeGenFunction &CGF,\n                                          SourceLocation Loc, unsigned IVSize,\n                                          bool IVSigned);\n\n  /// Call the appropriate runtime routine to notify that we finished\n  /// all the work with current loop.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param DKind Kind of the directive for which the static finish is emitted.\n  ///\n  virtual void emitForStaticFinish(CodeGenFunction &CGF, SourceLocation Loc,\n                                   OpenMPDirectiveKind DKind);\n\n  /// Call __kmpc_dispatch_next(\n  ///          ident_t *loc, kmp_int32 tid, kmp_int32 *p_lastiter,\n  ///          kmp_int[32|64] *p_lower, kmp_int[32|64] *p_upper,\n  ///          kmp_int[32|64] *p_stride);\n  /// \\param IVSize Size of the iteration variable in bits.\n  /// \\param IVSigned Sign of the iteration variable.\n  /// \\param IL Address of the output variable in which the flag of the\n  /// last iteration is returned.\n  /// \\param LB Address of the output variable in which the lower iteration\n  /// number is returned.\n  /// \\param UB Address of the output variable in which the upper iteration\n  /// number is returned.\n  /// \\param ST Address of the output variable in which the stride value is\n  /// returned.\n  virtual llvm::Value *emitForNext(CodeGenFunction &CGF, SourceLocation Loc,\n                                   unsigned IVSize, bool IVSigned,\n                                   Address IL, Address LB,\n                                   Address UB, Address ST);\n\n  /// Emits call to void __kmpc_push_num_threads(ident_t *loc, kmp_int32\n  /// global_tid, kmp_int32 num_threads) to generate code for 'num_threads'\n  /// clause.\n  /// \\param NumThreads An integer value of threads.\n  virtual void emitNumThreadsClause(CodeGenFunction &CGF,\n                                    llvm::Value *NumThreads,\n                                    SourceLocation Loc);\n\n  /// Emit call to void __kmpc_push_proc_bind(ident_t *loc, kmp_int32\n  /// global_tid, int proc_bind) to generate code for 'proc_bind' clause.\n  virtual void emitProcBindClause(CodeGenFunction &CGF,\n                                  llvm::omp::ProcBindKind ProcBind,\n                                  SourceLocation Loc);\n\n  /// Returns address of the threadprivate variable for the current\n  /// thread.\n  /// \\param VD Threadprivate variable.\n  /// \\param VDAddr Address of the global variable \\a VD.\n  /// \\param Loc Location of the reference to threadprivate var.\n  /// \\return Address of the threadprivate variable for the current thread.\n  virtual Address getAddrOfThreadPrivate(CodeGenFunction &CGF,\n                                         const VarDecl *VD,\n                                         Address VDAddr,\n                                         SourceLocation Loc);\n\n  /// Returns the address of the variable marked as declare target with link\n  /// clause OR as declare target with to clause and unified memory.\n  virtual Address getAddrOfDeclareTargetVar(const VarDecl *VD);\n\n  /// Emit a code for initialization of threadprivate variable. It emits\n  /// a call to runtime library which adds initial value to the newly created\n  /// threadprivate variable (if it is not constant) and registers destructor\n  /// for the variable (if any).\n  /// \\param VD Threadprivate variable.\n  /// \\param VDAddr Address of the global variable \\a VD.\n  /// \\param Loc Location of threadprivate declaration.\n  /// \\param PerformInit true if initialization expression is not constant.\n  virtual llvm::Function *\n  emitThreadPrivateVarDefinition(const VarDecl *VD, Address VDAddr,\n                                 SourceLocation Loc, bool PerformInit,\n                                 CodeGenFunction *CGF = nullptr);\n\n  /// Emit a code for initialization of declare target variable.\n  /// \\param VD Declare target variable.\n  /// \\param Addr Address of the global variable \\a VD.\n  /// \\param PerformInit true if initialization expression is not constant.\n  virtual bool emitDeclareTargetVarDefinition(const VarDecl *VD,\n                                              llvm::GlobalVariable *Addr,\n                                              bool PerformInit);\n\n  /// Creates artificial threadprivate variable with name \\p Name and type \\p\n  /// VarType.\n  /// \\param VarType Type of the artificial threadprivate variable.\n  /// \\param Name Name of the artificial threadprivate variable.\n  virtual Address getAddrOfArtificialThreadPrivate(CodeGenFunction &CGF,\n                                                   QualType VarType,\n                                                   StringRef Name);\n\n  /// Emit flush of the variables specified in 'omp flush' directive.\n  /// \\param Vars List of variables to flush.\n  virtual void emitFlush(CodeGenFunction &CGF, ArrayRef<const Expr *> Vars,\n                         SourceLocation Loc, llvm::AtomicOrdering AO);\n\n  /// Emit task region for the task directive. The task region is\n  /// emitted in several steps:\n  /// 1. Emit a call to kmp_task_t *__kmpc_omp_task_alloc(ident_t *, kmp_int32\n  /// gtid, kmp_int32 flags, size_t sizeof_kmp_task_t, size_t sizeof_shareds,\n  /// kmp_routine_entry_t *task_entry). Here task_entry is a pointer to the\n  /// function:\n  /// kmp_int32 .omp_task_entry.(kmp_int32 gtid, kmp_task_t *tt) {\n  ///   TaskFunction(gtid, tt->part_id, tt->shareds);\n  ///   return 0;\n  /// }\n  /// 2. Copy a list of shared variables to field shareds of the resulting\n  /// structure kmp_task_t returned by the previous call (if any).\n  /// 3. Copy a pointer to destructions function to field destructions of the\n  /// resulting structure kmp_task_t.\n  /// 4. Emit a call to kmp_int32 __kmpc_omp_task(ident_t *, kmp_int32 gtid,\n  /// kmp_task_t *new_task), where new_task is a resulting structure from\n  /// previous items.\n  /// \\param D Current task directive.\n  /// \\param TaskFunction An LLVM function with type void (*)(i32 /*gtid*/, i32\n  /// /*part_id*/, captured_struct */*__context*/);\n  /// \\param SharedsTy A type which contains references the shared variables.\n  /// \\param Shareds Context with the list of shared variables from the \\p\n  /// TaskFunction.\n  /// \\param IfCond Not a nullptr if 'if' clause was specified, nullptr\n  /// otherwise.\n  /// \\param Data Additional data for task generation like tiednsee, final\n  /// state, list of privates etc.\n  virtual void emitTaskCall(CodeGenFunction &CGF, SourceLocation Loc,\n                            const OMPExecutableDirective &D,\n                            llvm::Function *TaskFunction, QualType SharedsTy,\n                            Address Shareds, const Expr *IfCond,\n                            const OMPTaskDataTy &Data);\n\n  /// Emit task region for the taskloop directive. The taskloop region is\n  /// emitted in several steps:\n  /// 1. Emit a call to kmp_task_t *__kmpc_omp_task_alloc(ident_t *, kmp_int32\n  /// gtid, kmp_int32 flags, size_t sizeof_kmp_task_t, size_t sizeof_shareds,\n  /// kmp_routine_entry_t *task_entry). Here task_entry is a pointer to the\n  /// function:\n  /// kmp_int32 .omp_task_entry.(kmp_int32 gtid, kmp_task_t *tt) {\n  ///   TaskFunction(gtid, tt->part_id, tt->shareds);\n  ///   return 0;\n  /// }\n  /// 2. Copy a list of shared variables to field shareds of the resulting\n  /// structure kmp_task_t returned by the previous call (if any).\n  /// 3. Copy a pointer to destructions function to field destructions of the\n  /// resulting structure kmp_task_t.\n  /// 4. Emit a call to void __kmpc_taskloop(ident_t *loc, int gtid, kmp_task_t\n  /// *task, int if_val, kmp_uint64 *lb, kmp_uint64 *ub, kmp_int64 st, int\n  /// nogroup, int sched, kmp_uint64 grainsize, void *task_dup ), where new_task\n  /// is a resulting structure from\n  /// previous items.\n  /// \\param D Current task directive.\n  /// \\param TaskFunction An LLVM function with type void (*)(i32 /*gtid*/, i32\n  /// /*part_id*/, captured_struct */*__context*/);\n  /// \\param SharedsTy A type which contains references the shared variables.\n  /// \\param Shareds Context with the list of shared variables from the \\p\n  /// TaskFunction.\n  /// \\param IfCond Not a nullptr if 'if' clause was specified, nullptr\n  /// otherwise.\n  /// \\param Data Additional data for task generation like tiednsee, final\n  /// state, list of privates etc.\n  virtual void emitTaskLoopCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                const OMPLoopDirective &D,\n                                llvm::Function *TaskFunction,\n                                QualType SharedsTy, Address Shareds,\n                                const Expr *IfCond, const OMPTaskDataTy &Data);\n\n  /// Emit code for the directive that does not require outlining.\n  ///\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  /// \\param HasCancel true if region has inner cancel directive, false\n  /// otherwise.\n  virtual void emitInlinedDirective(CodeGenFunction &CGF,\n                                    OpenMPDirectiveKind InnermostKind,\n                                    const RegionCodeGenTy &CodeGen,\n                                    bool HasCancel = false);\n\n  /// Emits reduction function.\n  /// \\param ArgsType Array type containing pointers to reduction variables.\n  /// \\param Privates List of private copies for original reduction arguments.\n  /// \\param LHSExprs List of LHS in \\a ReductionOps reduction operations.\n  /// \\param RHSExprs List of RHS in \\a ReductionOps reduction operations.\n  /// \\param ReductionOps List of reduction operations in form 'LHS binop RHS'\n  /// or 'operator binop(LHS, RHS)'.\n  llvm::Function *emitReductionFunction(SourceLocation Loc,\n                                        llvm::Type *ArgsType,\n                                        ArrayRef<const Expr *> Privates,\n                                        ArrayRef<const Expr *> LHSExprs,\n                                        ArrayRef<const Expr *> RHSExprs,\n                                        ArrayRef<const Expr *> ReductionOps);\n\n  /// Emits single reduction combiner\n  void emitSingleReductionCombiner(CodeGenFunction &CGF,\n                                   const Expr *ReductionOp,\n                                   const Expr *PrivateRef,\n                                   const DeclRefExpr *LHS,\n                                   const DeclRefExpr *RHS);\n\n  struct ReductionOptionsTy {\n    bool WithNowait;\n    bool SimpleReduction;\n    OpenMPDirectiveKind ReductionKind;\n  };\n  /// Emit a code for reduction clause. Next code should be emitted for\n  /// reduction:\n  /// \\code\n  ///\n  /// static kmp_critical_name lock = { 0 };\n  ///\n  /// void reduce_func(void *lhs[<n>], void *rhs[<n>]) {\n  ///  ...\n  ///  *(Type<i>*)lhs[i] = RedOp<i>(*(Type<i>*)lhs[i], *(Type<i>*)rhs[i]);\n  ///  ...\n  /// }\n  ///\n  /// ...\n  /// void *RedList[<n>] = {&<RHSExprs>[0], ..., &<RHSExprs>[<n>-1]};\n  /// switch (__kmpc_reduce{_nowait}(<loc>, <gtid>, <n>, sizeof(RedList),\n  /// RedList, reduce_func, &<lock>)) {\n  /// case 1:\n  ///  ...\n  ///  <LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]);\n  ///  ...\n  /// __kmpc_end_reduce{_nowait}(<loc>, <gtid>, &<lock>);\n  /// break;\n  /// case 2:\n  ///  ...\n  ///  Atomic(<LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]));\n  ///  ...\n  /// break;\n  /// default:;\n  /// }\n  /// \\endcode\n  ///\n  /// \\param Privates List of private copies for original reduction arguments.\n  /// \\param LHSExprs List of LHS in \\a ReductionOps reduction operations.\n  /// \\param RHSExprs List of RHS in \\a ReductionOps reduction operations.\n  /// \\param ReductionOps List of reduction operations in form 'LHS binop RHS'\n  /// or 'operator binop(LHS, RHS)'.\n  /// \\param Options List of options for reduction codegen:\n  ///     WithNowait true if parent directive has also nowait clause, false\n  ///     otherwise.\n  ///     SimpleReduction Emit reduction operation only. Used for omp simd\n  ///     directive on the host.\n  ///     ReductionKind The kind of reduction to perform.\n  virtual void emitReduction(CodeGenFunction &CGF, SourceLocation Loc,\n                             ArrayRef<const Expr *> Privates,\n                             ArrayRef<const Expr *> LHSExprs,\n                             ArrayRef<const Expr *> RHSExprs,\n                             ArrayRef<const Expr *> ReductionOps,\n                             ReductionOptionsTy Options);\n\n  /// Emit a code for initialization of task reduction clause. Next code\n  /// should be emitted for reduction:\n  /// \\code\n  ///\n  /// _taskred_item_t red_data[n];\n  /// ...\n  /// red_data[i].shar = &shareds[i];\n  /// red_data[i].orig = &origs[i];\n  /// red_data[i].size = sizeof(origs[i]);\n  /// red_data[i].f_init = (void*)RedInit<i>;\n  /// red_data[i].f_fini = (void*)RedDest<i>;\n  /// red_data[i].f_comb = (void*)RedOp<i>;\n  /// red_data[i].flags = <Flag_i>;\n  /// ...\n  /// void* tg1 = __kmpc_taskred_init(gtid, n, red_data);\n  /// \\endcode\n  /// For reduction clause with task modifier it emits the next call:\n  /// \\code\n  ///\n  /// _taskred_item_t red_data[n];\n  /// ...\n  /// red_data[i].shar = &shareds[i];\n  /// red_data[i].orig = &origs[i];\n  /// red_data[i].size = sizeof(origs[i]);\n  /// red_data[i].f_init = (void*)RedInit<i>;\n  /// red_data[i].f_fini = (void*)RedDest<i>;\n  /// red_data[i].f_comb = (void*)RedOp<i>;\n  /// red_data[i].flags = <Flag_i>;\n  /// ...\n  /// void* tg1 = __kmpc_taskred_modifier_init(loc, gtid, is_worksharing, n,\n  /// red_data);\n  /// \\endcode\n  /// \\param LHSExprs List of LHS in \\a Data.ReductionOps reduction operations.\n  /// \\param RHSExprs List of RHS in \\a Data.ReductionOps reduction operations.\n  /// \\param Data Additional data for task generation like tiedness, final\n  /// state, list of privates, reductions etc.\n  virtual llvm::Value *emitTaskReductionInit(CodeGenFunction &CGF,\n                                             SourceLocation Loc,\n                                             ArrayRef<const Expr *> LHSExprs,\n                                             ArrayRef<const Expr *> RHSExprs,\n                                             const OMPTaskDataTy &Data);\n\n  /// Emits the following code for reduction clause with task modifier:\n  /// \\code\n  /// __kmpc_task_reduction_modifier_fini(loc, gtid, is_worksharing);\n  /// \\endcode\n  virtual void emitTaskReductionFini(CodeGenFunction &CGF, SourceLocation Loc,\n                                     bool IsWorksharingReduction);\n\n  /// Required to resolve existing problems in the runtime. Emits threadprivate\n  /// variables to store the size of the VLAs/array sections for\n  /// initializer/combiner/finalizer functions.\n  /// \\param RCG Allows to reuse an existing data for the reductions.\n  /// \\param N Reduction item for which fixups must be emitted.\n  virtual void emitTaskReductionFixups(CodeGenFunction &CGF, SourceLocation Loc,\n                                       ReductionCodeGen &RCG, unsigned N);\n\n  /// Get the address of `void *` type of the privatue copy of the reduction\n  /// item specified by the \\p SharedLVal.\n  /// \\param ReductionsPtr Pointer to the reduction data returned by the\n  /// emitTaskReductionInit function.\n  /// \\param SharedLVal Address of the original reduction item.\n  virtual Address getTaskReductionItem(CodeGenFunction &CGF, SourceLocation Loc,\n                                       llvm::Value *ReductionsPtr,\n                                       LValue SharedLVal);\n\n  /// Emit code for 'taskwait' directive.\n  virtual void emitTaskwaitCall(CodeGenFunction &CGF, SourceLocation Loc);\n\n  /// Emit code for 'cancellation point' construct.\n  /// \\param CancelRegion Region kind for which the cancellation point must be\n  /// emitted.\n  ///\n  virtual void emitCancellationPointCall(CodeGenFunction &CGF,\n                                         SourceLocation Loc,\n                                         OpenMPDirectiveKind CancelRegion);\n\n  /// Emit code for 'cancel' construct.\n  /// \\param IfCond Condition in the associated 'if' clause, if it was\n  /// specified, nullptr otherwise.\n  /// \\param CancelRegion Region kind for which the cancel must be emitted.\n  ///\n  virtual void emitCancelCall(CodeGenFunction &CGF, SourceLocation Loc,\n                              const Expr *IfCond,\n                              OpenMPDirectiveKind CancelRegion);\n\n  /// Emit outilined function for 'target' directive.\n  /// \\param D Directive to emit.\n  /// \\param ParentName Name of the function that encloses the target region.\n  /// \\param OutlinedFn Outlined function value to be defined by this call.\n  /// \\param OutlinedFnID Outlined function ID value to be defined by this call.\n  /// \\param IsOffloadEntry True if the outlined function is an offload entry.\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  /// An outlined function may not be an entry if, e.g. the if clause always\n  /// evaluates to false.\n  virtual void emitTargetOutlinedFunction(const OMPExecutableDirective &D,\n                                          StringRef ParentName,\n                                          llvm::Function *&OutlinedFn,\n                                          llvm::Constant *&OutlinedFnID,\n                                          bool IsOffloadEntry,\n                                          const RegionCodeGenTy &CodeGen);\n\n  /// Emit the target offloading code associated with \\a D. The emitted\n  /// code attempts offloading the execution to the device, an the event of\n  /// a failure it executes the host version outlined in \\a OutlinedFn.\n  /// \\param D Directive to emit.\n  /// \\param OutlinedFn Host version of the code to be offloaded.\n  /// \\param OutlinedFnID ID of host version of the code to be offloaded.\n  /// \\param IfCond Expression evaluated in if clause associated with the target\n  /// directive, or null if no if clause is used.\n  /// \\param Device Expression evaluated in device clause associated with the\n  /// target directive, or null if no device clause is used and device modifier.\n  /// \\param SizeEmitter Callback to emit number of iterations for loop-based\n  /// directives.\n  virtual void emitTargetCall(\n      CodeGenFunction &CGF, const OMPExecutableDirective &D,\n      llvm::Function *OutlinedFn, llvm::Value *OutlinedFnID, const Expr *IfCond,\n      llvm::PointerIntPair<const Expr *, 2, OpenMPDeviceClauseModifier> Device,\n      llvm::function_ref<llvm::Value *(CodeGenFunction &CGF,\n                                       const OMPLoopDirective &D)>\n          SizeEmitter);\n\n  /// Emit the target regions enclosed in \\a GD function definition or\n  /// the function itself in case it is a valid device function. Returns true if\n  /// \\a GD was dealt with successfully.\n  /// \\param GD Function to scan.\n  virtual bool emitTargetFunctions(GlobalDecl GD);\n\n  /// Emit the global variable if it is a valid device global variable.\n  /// Returns true if \\a GD was dealt with successfully.\n  /// \\param GD Variable declaration to emit.\n  virtual bool emitTargetGlobalVariable(GlobalDecl GD);\n\n  /// Checks if the provided global decl \\a GD is a declare target variable and\n  /// registers it when emitting code for the host.\n  virtual void registerTargetGlobalVariable(const VarDecl *VD,\n                                            llvm::Constant *Addr);\n\n  /// Registers provided target firstprivate variable as global on the\n  /// target.\n  llvm::Constant *registerTargetFirstprivateCopy(CodeGenFunction &CGF,\n                                                 const VarDecl *VD);\n\n  /// Emit the global \\a GD if it is meaningful for the target. Returns\n  /// if it was emitted successfully.\n  /// \\param GD Global to scan.\n  virtual bool emitTargetGlobal(GlobalDecl GD);\n\n  /// Creates and returns a registration function for when at least one\n  /// requires directives was used in the current module.\n  llvm::Function *emitRequiresDirectiveRegFun();\n\n  /// Creates all the offload entries in the current compilation unit\n  /// along with the associated metadata.\n  void createOffloadEntriesAndInfoMetadata();\n\n  /// Emits code for teams call of the \\a OutlinedFn with\n  /// variables captured in a record which address is stored in \\a\n  /// CapturedStruct.\n  /// \\param OutlinedFn Outlined function to be run by team masters. Type of\n  /// this function is void(*)(kmp_int32 *, kmp_int32, struct context_vars*).\n  /// \\param CapturedVars A pointer to the record with the references to\n  /// variables used in \\a OutlinedFn function.\n  ///\n  virtual void emitTeamsCall(CodeGenFunction &CGF,\n                             const OMPExecutableDirective &D,\n                             SourceLocation Loc, llvm::Function *OutlinedFn,\n                             ArrayRef<llvm::Value *> CapturedVars);\n\n  /// Emits call to void __kmpc_push_num_teams(ident_t *loc, kmp_int32\n  /// global_tid, kmp_int32 num_teams, kmp_int32 thread_limit) to generate code\n  /// for num_teams clause.\n  /// \\param NumTeams An integer expression of teams.\n  /// \\param ThreadLimit An integer expression of threads.\n  virtual void emitNumTeamsClause(CodeGenFunction &CGF, const Expr *NumTeams,\n                                  const Expr *ThreadLimit, SourceLocation Loc);\n\n  /// Struct that keeps all the relevant information that should be kept\n  /// throughout a 'target data' region.\n  class TargetDataInfo {\n    /// Set to true if device pointer information have to be obtained.\n    bool RequiresDevicePointerInfo = false;\n    /// Set to true if Clang emits separate runtime calls for the beginning and\n    /// end of the region.  These calls might have separate map type arrays.\n    bool SeparateBeginEndCalls = false;\n\n  public:\n    /// The array of base pointer passed to the runtime library.\n    llvm::Value *BasePointersArray = nullptr;\n    /// The array of section pointers passed to the runtime library.\n    llvm::Value *PointersArray = nullptr;\n    /// The array of sizes passed to the runtime library.\n    llvm::Value *SizesArray = nullptr;\n    /// The array of map types passed to the runtime library for the beginning\n    /// of the region or for the entire region if there are no separate map\n    /// types for the region end.\n    llvm::Value *MapTypesArray = nullptr;\n    /// The array of map types passed to the runtime library for the end of the\n    /// region, or nullptr if there are no separate map types for the region\n    /// end.\n    llvm::Value *MapTypesArrayEnd = nullptr;\n    /// The array of user-defined mappers passed to the runtime library.\n    llvm::Value *MappersArray = nullptr;\n    /// The array of original declaration names of mapped pointers sent to the\n    /// runtime library for debugging\n    llvm::Value *MapNamesArray = nullptr;\n    /// Indicate whether any user-defined mapper exists.\n    bool HasMapper = false;\n    /// The total number of pointers passed to the runtime library.\n    unsigned NumberOfPtrs = 0u;\n    /// Map between the a declaration of a capture and the corresponding base\n    /// pointer address where the runtime returns the device pointers.\n    llvm::DenseMap<const ValueDecl *, Address> CaptureDeviceAddrMap;\n\n    explicit TargetDataInfo() {}\n    explicit TargetDataInfo(bool RequiresDevicePointerInfo,\n                            bool SeparateBeginEndCalls)\n        : RequiresDevicePointerInfo(RequiresDevicePointerInfo),\n          SeparateBeginEndCalls(SeparateBeginEndCalls) {}\n    /// Clear information about the data arrays.\n    void clearArrayInfo() {\n      BasePointersArray = nullptr;\n      PointersArray = nullptr;\n      SizesArray = nullptr;\n      MapTypesArray = nullptr;\n      MapTypesArrayEnd = nullptr;\n      MapNamesArray = nullptr;\n      MappersArray = nullptr;\n      HasMapper = false;\n      NumberOfPtrs = 0u;\n    }\n    /// Return true if the current target data information has valid arrays.\n    bool isValid() {\n      return BasePointersArray && PointersArray && SizesArray &&\n             MapTypesArray && (!HasMapper || MappersArray) && NumberOfPtrs;\n    }\n    bool requiresDevicePointerInfo() { return RequiresDevicePointerInfo; }\n    bool separateBeginEndCalls() { return SeparateBeginEndCalls; }\n  };\n\n  /// Emit the target data mapping code associated with \\a D.\n  /// \\param D Directive to emit.\n  /// \\param IfCond Expression evaluated in if clause associated with the\n  /// target directive, or null if no device clause is used.\n  /// \\param Device Expression evaluated in device clause associated with the\n  /// target directive, or null if no device clause is used.\n  /// \\param Info A record used to store information that needs to be preserved\n  /// until the region is closed.\n  virtual void emitTargetDataCalls(CodeGenFunction &CGF,\n                                   const OMPExecutableDirective &D,\n                                   const Expr *IfCond, const Expr *Device,\n                                   const RegionCodeGenTy &CodeGen,\n                                   TargetDataInfo &Info);\n\n  /// Emit the data mapping/movement code associated with the directive\n  /// \\a D that should be of the form 'target [{enter|exit} data | update]'.\n  /// \\param D Directive to emit.\n  /// \\param IfCond Expression evaluated in if clause associated with the target\n  /// directive, or null if no if clause is used.\n  /// \\param Device Expression evaluated in device clause associated with the\n  /// target directive, or null if no device clause is used.\n  virtual void emitTargetDataStandAloneCall(CodeGenFunction &CGF,\n                                            const OMPExecutableDirective &D,\n                                            const Expr *IfCond,\n                                            const Expr *Device);\n\n  /// Marks function \\a Fn with properly mangled versions of vector functions.\n  /// \\param FD Function marked as 'declare simd'.\n  /// \\param Fn LLVM function that must be marked with 'declare simd'\n  /// attributes.\n  virtual void emitDeclareSimdFunction(const FunctionDecl *FD,\n                                       llvm::Function *Fn);\n\n  /// Emit initialization for doacross loop nesting support.\n  /// \\param D Loop-based construct used in doacross nesting construct.\n  virtual void emitDoacrossInit(CodeGenFunction &CGF, const OMPLoopDirective &D,\n                                ArrayRef<Expr *> NumIterations);\n\n  /// Emit code for doacross ordered directive with 'depend' clause.\n  /// \\param C 'depend' clause with 'sink|source' dependency kind.\n  virtual void emitDoacrossOrdered(CodeGenFunction &CGF,\n                                   const OMPDependClause *C);\n\n  /// Translates the native parameter of outlined function if this is required\n  /// for target.\n  /// \\param FD Field decl from captured record for the parameter.\n  /// \\param NativeParam Parameter itself.\n  virtual const VarDecl *translateParameter(const FieldDecl *FD,\n                                            const VarDecl *NativeParam) const {\n    return NativeParam;\n  }\n\n  /// Gets the address of the native argument basing on the address of the\n  /// target-specific parameter.\n  /// \\param NativeParam Parameter itself.\n  /// \\param TargetParam Corresponding target-specific parameter.\n  virtual Address getParameterAddress(CodeGenFunction &CGF,\n                                      const VarDecl *NativeParam,\n                                      const VarDecl *TargetParam) const;\n\n  /// Choose default schedule type and chunk value for the\n  /// dist_schedule clause.\n  virtual void getDefaultDistScheduleAndChunk(CodeGenFunction &CGF,\n      const OMPLoopDirective &S, OpenMPDistScheduleClauseKind &ScheduleKind,\n      llvm::Value *&Chunk) const {}\n\n  /// Choose default schedule type and chunk value for the\n  /// schedule clause.\n  virtual void getDefaultScheduleAndChunk(CodeGenFunction &CGF,\n      const OMPLoopDirective &S, OpenMPScheduleClauseKind &ScheduleKind,\n      const Expr *&ChunkExpr) const;\n\n  /// Emits call of the outlined function with the provided arguments,\n  /// translating these arguments to correct target-specific arguments.\n  virtual void\n  emitOutlinedFunctionCall(CodeGenFunction &CGF, SourceLocation Loc,\n                           llvm::FunctionCallee OutlinedFn,\n                           ArrayRef<llvm::Value *> Args = llvm::None) const;\n\n  /// Emits OpenMP-specific function prolog.\n  /// Required for device constructs.\n  virtual void emitFunctionProlog(CodeGenFunction &CGF, const Decl *D);\n\n  /// Gets the OpenMP-specific address of the local variable.\n  virtual Address getAddressOfLocalVariable(CodeGenFunction &CGF,\n                                            const VarDecl *VD);\n\n  /// Marks the declaration as already emitted for the device code and returns\n  /// true, if it was marked already, and false, otherwise.\n  bool markAsGlobalTarget(GlobalDecl GD);\n\n  /// Emit deferred declare target variables marked for deferred emission.\n  void emitDeferredTargetDecls() const;\n\n  /// Adjust some parameters for the target-based directives, like addresses of\n  /// the variables captured by reference in lambdas.\n  virtual void\n  adjustTargetSpecificDataForLambdas(CodeGenFunction &CGF,\n                                     const OMPExecutableDirective &D) const;\n\n  /// Perform check on requires decl to ensure that target architecture\n  /// supports unified addressing\n  virtual void processRequiresDirective(const OMPRequiresDecl *D);\n\n  /// Gets default memory ordering as specified in requires directive.\n  llvm::AtomicOrdering getDefaultMemoryOrdering() const;\n\n  /// Checks if the variable has associated OMPAllocateDeclAttr attribute with\n  /// the predefined allocator and translates it into the corresponding address\n  /// space.\n  virtual bool hasAllocateAttributeForGlobalVar(const VarDecl *VD, LangAS &AS);\n\n  /// Return whether the unified_shared_memory has been specified.\n  bool hasRequiresUnifiedSharedMemory() const;\n\n  /// Checks if the \\p VD variable is marked as nontemporal declaration in\n  /// current context.\n  bool isNontemporalDecl(const ValueDecl *VD) const;\n\n  /// Create specialized alloca to handle lastprivate conditionals.\n  Address emitLastprivateConditionalInit(CodeGenFunction &CGF,\n                                         const VarDecl *VD);\n\n  /// Checks if the provided \\p LVal is lastprivate conditional and emits the\n  /// code to update the value of the original variable.\n  /// \\code\n  /// lastprivate(conditional: a)\n  /// ...\n  /// <type> a;\n  /// lp_a = ...;\n  /// #pragma omp critical(a)\n  /// if (last_iv_a <= iv) {\n  ///   last_iv_a = iv;\n  ///   global_a = lp_a;\n  /// }\n  /// \\endcode\n  virtual void checkAndEmitLastprivateConditional(CodeGenFunction &CGF,\n                                                  const Expr *LHS);\n\n  /// Checks if the lastprivate conditional was updated in inner region and\n  /// writes the value.\n  /// \\code\n  /// lastprivate(conditional: a)\n  /// ...\n  /// <type> a;bool Fired = false;\n  /// #pragma omp ... shared(a)\n  /// {\n  ///   lp_a = ...;\n  ///   Fired = true;\n  /// }\n  /// if (Fired) {\n  ///   #pragma omp critical(a)\n  ///   if (last_iv_a <= iv) {\n  ///     last_iv_a = iv;\n  ///     global_a = lp_a;\n  ///   }\n  ///   Fired = false;\n  /// }\n  /// \\endcode\n  virtual void checkAndEmitSharedLastprivateConditional(\n      CodeGenFunction &CGF, const OMPExecutableDirective &D,\n      const llvm::DenseSet<CanonicalDeclPtr<const VarDecl>> &IgnoredDecls);\n\n  /// Gets the address of the global copy used for lastprivate conditional\n  /// update, if any.\n  /// \\param PrivLVal LValue for the private copy.\n  /// \\param VD Original lastprivate declaration.\n  virtual void emitLastprivateConditionalFinalUpdate(CodeGenFunction &CGF,\n                                                     LValue PrivLVal,\n                                                     const VarDecl *VD,\n                                                     SourceLocation Loc);\n\n  /// Emits list of dependecies based on the provided data (array of\n  /// dependence/expression pairs).\n  /// \\returns Pointer to the first element of the array casted to VoidPtr type.\n  std::pair<llvm::Value *, Address>\n  emitDependClause(CodeGenFunction &CGF,\n                   ArrayRef<OMPTaskDataTy::DependData> Dependencies,\n                   SourceLocation Loc);\n\n  /// Emits list of dependecies based on the provided data (array of\n  /// dependence/expression pairs) for depobj construct. In this case, the\n  /// variable is allocated in dynamically. \\returns Pointer to the first\n  /// element of the array casted to VoidPtr type.\n  Address emitDepobjDependClause(CodeGenFunction &CGF,\n                                 const OMPTaskDataTy::DependData &Dependencies,\n                                 SourceLocation Loc);\n\n  /// Emits the code to destroy the dependency object provided in depobj\n  /// directive.\n  void emitDestroyClause(CodeGenFunction &CGF, LValue DepobjLVal,\n                         SourceLocation Loc);\n\n  /// Updates the dependency kind in the specified depobj object.\n  /// \\param DepobjLVal LValue for the main depobj object.\n  /// \\param NewDepKind New dependency kind.\n  void emitUpdateClause(CodeGenFunction &CGF, LValue DepobjLVal,\n                        OpenMPDependClauseKind NewDepKind, SourceLocation Loc);\n\n  /// Initializes user defined allocators specified in the uses_allocators\n  /// clauses.\n  void emitUsesAllocatorsInit(CodeGenFunction &CGF, const Expr *Allocator,\n                              const Expr *AllocatorTraits);\n\n  /// Destroys user defined allocators specified in the uses_allocators clause.\n  void emitUsesAllocatorsFini(CodeGenFunction &CGF, const Expr *Allocator);\n\n  /// Returns true if the variable is a local variable in untied task.\n  bool isLocalVarInUntiedTask(CodeGenFunction &CGF, const VarDecl *VD) const;\n};\n\n/// Class supports emissionof SIMD-only code.\nclass CGOpenMPSIMDRuntime final : public CGOpenMPRuntime {\npublic:\n  explicit CGOpenMPSIMDRuntime(CodeGenModule &CGM) : CGOpenMPRuntime(CGM) {}\n  ~CGOpenMPSIMDRuntime() override {}\n\n  /// Emits outlined function for the specified OpenMP parallel directive\n  /// \\a D. This outlined function has type void(*)(kmp_int32 *ThreadID,\n  /// kmp_int32 BoundID, struct context_vars*).\n  /// \\param D OpenMP directive.\n  /// \\param ThreadIDVar Variable for thread id in the current OpenMP region.\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  llvm::Function *\n  emitParallelOutlinedFunction(const OMPExecutableDirective &D,\n                               const VarDecl *ThreadIDVar,\n                               OpenMPDirectiveKind InnermostKind,\n                               const RegionCodeGenTy &CodeGen) override;\n\n  /// Emits outlined function for the specified OpenMP teams directive\n  /// \\a D. This outlined function has type void(*)(kmp_int32 *ThreadID,\n  /// kmp_int32 BoundID, struct context_vars*).\n  /// \\param D OpenMP directive.\n  /// \\param ThreadIDVar Variable for thread id in the current OpenMP region.\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  llvm::Function *\n  emitTeamsOutlinedFunction(const OMPExecutableDirective &D,\n                            const VarDecl *ThreadIDVar,\n                            OpenMPDirectiveKind InnermostKind,\n                            const RegionCodeGenTy &CodeGen) override;\n\n  /// Emits outlined function for the OpenMP task directive \\a D. This\n  /// outlined function has type void(*)(kmp_int32 ThreadID, struct task_t*\n  /// TaskT).\n  /// \\param D OpenMP directive.\n  /// \\param ThreadIDVar Variable for thread id in the current OpenMP region.\n  /// \\param PartIDVar Variable for partition id in the current OpenMP untied\n  /// task region.\n  /// \\param TaskTVar Variable for task_t argument.\n  /// \\param InnermostKind Kind of innermost directive (for simple directives it\n  /// is a directive itself, for combined - its innermost directive).\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  /// \\param Tied true if task is generated for tied task, false otherwise.\n  /// \\param NumberOfParts Number of parts in untied task. Ignored for tied\n  /// tasks.\n  ///\n  llvm::Function *emitTaskOutlinedFunction(\n      const OMPExecutableDirective &D, const VarDecl *ThreadIDVar,\n      const VarDecl *PartIDVar, const VarDecl *TaskTVar,\n      OpenMPDirectiveKind InnermostKind, const RegionCodeGenTy &CodeGen,\n      bool Tied, unsigned &NumberOfParts) override;\n\n  /// Emits code for parallel or serial call of the \\a OutlinedFn with\n  /// variables captured in a record which address is stored in \\a\n  /// CapturedStruct.\n  /// \\param OutlinedFn Outlined function to be run in parallel threads. Type of\n  /// this function is void(*)(kmp_int32 *, kmp_int32, struct context_vars*).\n  /// \\param CapturedVars A pointer to the record with the references to\n  /// variables used in \\a OutlinedFn function.\n  /// \\param IfCond Condition in the associated 'if' clause, if it was\n  /// specified, nullptr otherwise.\n  ///\n  void emitParallelCall(CodeGenFunction &CGF, SourceLocation Loc,\n                        llvm::Function *OutlinedFn,\n                        ArrayRef<llvm::Value *> CapturedVars,\n                        const Expr *IfCond) override;\n\n  /// Emits a critical region.\n  /// \\param CriticalName Name of the critical region.\n  /// \\param CriticalOpGen Generator for the statement associated with the given\n  /// critical region.\n  /// \\param Hint Value of the 'hint' clause (optional).\n  void emitCriticalRegion(CodeGenFunction &CGF, StringRef CriticalName,\n                          const RegionCodeGenTy &CriticalOpGen,\n                          SourceLocation Loc,\n                          const Expr *Hint = nullptr) override;\n\n  /// Emits a master region.\n  /// \\param MasterOpGen Generator for the statement associated with the given\n  /// master region.\n  void emitMasterRegion(CodeGenFunction &CGF,\n                        const RegionCodeGenTy &MasterOpGen,\n                        SourceLocation Loc) override;\n\n  /// Emits code for a taskyield directive.\n  void emitTaskyieldCall(CodeGenFunction &CGF, SourceLocation Loc) override;\n\n  /// Emit a taskgroup region.\n  /// \\param TaskgroupOpGen Generator for the statement associated with the\n  /// given taskgroup region.\n  void emitTaskgroupRegion(CodeGenFunction &CGF,\n                           const RegionCodeGenTy &TaskgroupOpGen,\n                           SourceLocation Loc) override;\n\n  /// Emits a single region.\n  /// \\param SingleOpGen Generator for the statement associated with the given\n  /// single region.\n  void emitSingleRegion(CodeGenFunction &CGF,\n                        const RegionCodeGenTy &SingleOpGen, SourceLocation Loc,\n                        ArrayRef<const Expr *> CopyprivateVars,\n                        ArrayRef<const Expr *> DestExprs,\n                        ArrayRef<const Expr *> SrcExprs,\n                        ArrayRef<const Expr *> AssignmentOps) override;\n\n  /// Emit an ordered region.\n  /// \\param OrderedOpGen Generator for the statement associated with the given\n  /// ordered region.\n  void emitOrderedRegion(CodeGenFunction &CGF,\n                         const RegionCodeGenTy &OrderedOpGen,\n                         SourceLocation Loc, bool IsThreads) override;\n\n  /// Emit an implicit/explicit barrier for OpenMP threads.\n  /// \\param Kind Directive for which this implicit barrier call must be\n  /// generated. Must be OMPD_barrier for explicit barrier generation.\n  /// \\param EmitChecks true if need to emit checks for cancellation barriers.\n  /// \\param ForceSimpleCall true simple barrier call must be emitted, false if\n  /// runtime class decides which one to emit (simple or with cancellation\n  /// checks).\n  ///\n  void emitBarrierCall(CodeGenFunction &CGF, SourceLocation Loc,\n                       OpenMPDirectiveKind Kind, bool EmitChecks = true,\n                       bool ForceSimpleCall = false) override;\n\n  /// This is used for non static scheduled types and when the ordered\n  /// clause is present on the loop construct.\n  /// Depending on the loop schedule, it is necessary to call some runtime\n  /// routine before start of the OpenMP loop to get the loop upper / lower\n  /// bounds \\a LB and \\a UB and stride \\a ST.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param ScheduleKind Schedule kind, specified by the 'schedule' clause.\n  /// \\param IVSize Size of the iteration variable in bits.\n  /// \\param IVSigned Sign of the iteration variable.\n  /// \\param Ordered true if loop is ordered, false otherwise.\n  /// \\param DispatchValues struct containing llvm values for lower bound, upper\n  /// bound, and chunk expression.\n  /// For the default (nullptr) value, the chunk 1 will be used.\n  ///\n  void emitForDispatchInit(CodeGenFunction &CGF, SourceLocation Loc,\n                           const OpenMPScheduleTy &ScheduleKind,\n                           unsigned IVSize, bool IVSigned, bool Ordered,\n                           const DispatchRTInput &DispatchValues) override;\n\n  /// Call the appropriate runtime routine to initialize it before start\n  /// of loop.\n  ///\n  /// This is used only in case of static schedule, when the user did not\n  /// specify a ordered clause on the loop construct.\n  /// Depending on the loop schedule, it is necessary to call some runtime\n  /// routine before start of the OpenMP loop to get the loop upper / lower\n  /// bounds LB and UB and stride ST.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param DKind Kind of the directive.\n  /// \\param ScheduleKind Schedule kind, specified by the 'schedule' clause.\n  /// \\param Values Input arguments for the construct.\n  ///\n  void emitForStaticInit(CodeGenFunction &CGF, SourceLocation Loc,\n                         OpenMPDirectiveKind DKind,\n                         const OpenMPScheduleTy &ScheduleKind,\n                         const StaticRTInput &Values) override;\n\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param SchedKind Schedule kind, specified by the 'dist_schedule' clause.\n  /// \\param Values Input arguments for the construct.\n  ///\n  void emitDistributeStaticInit(CodeGenFunction &CGF, SourceLocation Loc,\n                                OpenMPDistScheduleClauseKind SchedKind,\n                                const StaticRTInput &Values) override;\n\n  /// Call the appropriate runtime routine to notify that we finished\n  /// iteration of the ordered loop with the dynamic scheduling.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param IVSize Size of the iteration variable in bits.\n  /// \\param IVSigned Sign of the iteration variable.\n  ///\n  void emitForOrderedIterationEnd(CodeGenFunction &CGF, SourceLocation Loc,\n                                  unsigned IVSize, bool IVSigned) override;\n\n  /// Call the appropriate runtime routine to notify that we finished\n  /// all the work with current loop.\n  ///\n  /// \\param CGF Reference to current CodeGenFunction.\n  /// \\param Loc Clang source location.\n  /// \\param DKind Kind of the directive for which the static finish is emitted.\n  ///\n  void emitForStaticFinish(CodeGenFunction &CGF, SourceLocation Loc,\n                           OpenMPDirectiveKind DKind) override;\n\n  /// Call __kmpc_dispatch_next(\n  ///          ident_t *loc, kmp_int32 tid, kmp_int32 *p_lastiter,\n  ///          kmp_int[32|64] *p_lower, kmp_int[32|64] *p_upper,\n  ///          kmp_int[32|64] *p_stride);\n  /// \\param IVSize Size of the iteration variable in bits.\n  /// \\param IVSigned Sign of the iteration variable.\n  /// \\param IL Address of the output variable in which the flag of the\n  /// last iteration is returned.\n  /// \\param LB Address of the output variable in which the lower iteration\n  /// number is returned.\n  /// \\param UB Address of the output variable in which the upper iteration\n  /// number is returned.\n  /// \\param ST Address of the output variable in which the stride value is\n  /// returned.\n  llvm::Value *emitForNext(CodeGenFunction &CGF, SourceLocation Loc,\n                           unsigned IVSize, bool IVSigned, Address IL,\n                           Address LB, Address UB, Address ST) override;\n\n  /// Emits call to void __kmpc_push_num_threads(ident_t *loc, kmp_int32\n  /// global_tid, kmp_int32 num_threads) to generate code for 'num_threads'\n  /// clause.\n  /// \\param NumThreads An integer value of threads.\n  void emitNumThreadsClause(CodeGenFunction &CGF, llvm::Value *NumThreads,\n                            SourceLocation Loc) override;\n\n  /// Emit call to void __kmpc_push_proc_bind(ident_t *loc, kmp_int32\n  /// global_tid, int proc_bind) to generate code for 'proc_bind' clause.\n  void emitProcBindClause(CodeGenFunction &CGF,\n                          llvm::omp::ProcBindKind ProcBind,\n                          SourceLocation Loc) override;\n\n  /// Returns address of the threadprivate variable for the current\n  /// thread.\n  /// \\param VD Threadprivate variable.\n  /// \\param VDAddr Address of the global variable \\a VD.\n  /// \\param Loc Location of the reference to threadprivate var.\n  /// \\return Address of the threadprivate variable for the current thread.\n  Address getAddrOfThreadPrivate(CodeGenFunction &CGF, const VarDecl *VD,\n                                 Address VDAddr, SourceLocation Loc) override;\n\n  /// Emit a code for initialization of threadprivate variable. It emits\n  /// a call to runtime library which adds initial value to the newly created\n  /// threadprivate variable (if it is not constant) and registers destructor\n  /// for the variable (if any).\n  /// \\param VD Threadprivate variable.\n  /// \\param VDAddr Address of the global variable \\a VD.\n  /// \\param Loc Location of threadprivate declaration.\n  /// \\param PerformInit true if initialization expression is not constant.\n  llvm::Function *\n  emitThreadPrivateVarDefinition(const VarDecl *VD, Address VDAddr,\n                                 SourceLocation Loc, bool PerformInit,\n                                 CodeGenFunction *CGF = nullptr) override;\n\n  /// Creates artificial threadprivate variable with name \\p Name and type \\p\n  /// VarType.\n  /// \\param VarType Type of the artificial threadprivate variable.\n  /// \\param Name Name of the artificial threadprivate variable.\n  Address getAddrOfArtificialThreadPrivate(CodeGenFunction &CGF,\n                                           QualType VarType,\n                                           StringRef Name) override;\n\n  /// Emit flush of the variables specified in 'omp flush' directive.\n  /// \\param Vars List of variables to flush.\n  void emitFlush(CodeGenFunction &CGF, ArrayRef<const Expr *> Vars,\n                 SourceLocation Loc, llvm::AtomicOrdering AO) override;\n\n  /// Emit task region for the task directive. The task region is\n  /// emitted in several steps:\n  /// 1. Emit a call to kmp_task_t *__kmpc_omp_task_alloc(ident_t *, kmp_int32\n  /// gtid, kmp_int32 flags, size_t sizeof_kmp_task_t, size_t sizeof_shareds,\n  /// kmp_routine_entry_t *task_entry). Here task_entry is a pointer to the\n  /// function:\n  /// kmp_int32 .omp_task_entry.(kmp_int32 gtid, kmp_task_t *tt) {\n  ///   TaskFunction(gtid, tt->part_id, tt->shareds);\n  ///   return 0;\n  /// }\n  /// 2. Copy a list of shared variables to field shareds of the resulting\n  /// structure kmp_task_t returned by the previous call (if any).\n  /// 3. Copy a pointer to destructions function to field destructions of the\n  /// resulting structure kmp_task_t.\n  /// 4. Emit a call to kmp_int32 __kmpc_omp_task(ident_t *, kmp_int32 gtid,\n  /// kmp_task_t *new_task), where new_task is a resulting structure from\n  /// previous items.\n  /// \\param D Current task directive.\n  /// \\param TaskFunction An LLVM function with type void (*)(i32 /*gtid*/, i32\n  /// /*part_id*/, captured_struct */*__context*/);\n  /// \\param SharedsTy A type which contains references the shared variables.\n  /// \\param Shareds Context with the list of shared variables from the \\p\n  /// TaskFunction.\n  /// \\param IfCond Not a nullptr if 'if' clause was specified, nullptr\n  /// otherwise.\n  /// \\param Data Additional data for task generation like tiednsee, final\n  /// state, list of privates etc.\n  void emitTaskCall(CodeGenFunction &CGF, SourceLocation Loc,\n                    const OMPExecutableDirective &D,\n                    llvm::Function *TaskFunction, QualType SharedsTy,\n                    Address Shareds, const Expr *IfCond,\n                    const OMPTaskDataTy &Data) override;\n\n  /// Emit task region for the taskloop directive. The taskloop region is\n  /// emitted in several steps:\n  /// 1. Emit a call to kmp_task_t *__kmpc_omp_task_alloc(ident_t *, kmp_int32\n  /// gtid, kmp_int32 flags, size_t sizeof_kmp_task_t, size_t sizeof_shareds,\n  /// kmp_routine_entry_t *task_entry). Here task_entry is a pointer to the\n  /// function:\n  /// kmp_int32 .omp_task_entry.(kmp_int32 gtid, kmp_task_t *tt) {\n  ///   TaskFunction(gtid, tt->part_id, tt->shareds);\n  ///   return 0;\n  /// }\n  /// 2. Copy a list of shared variables to field shareds of the resulting\n  /// structure kmp_task_t returned by the previous call (if any).\n  /// 3. Copy a pointer to destructions function to field destructions of the\n  /// resulting structure kmp_task_t.\n  /// 4. Emit a call to void __kmpc_taskloop(ident_t *loc, int gtid, kmp_task_t\n  /// *task, int if_val, kmp_uint64 *lb, kmp_uint64 *ub, kmp_int64 st, int\n  /// nogroup, int sched, kmp_uint64 grainsize, void *task_dup ), where new_task\n  /// is a resulting structure from\n  /// previous items.\n  /// \\param D Current task directive.\n  /// \\param TaskFunction An LLVM function with type void (*)(i32 /*gtid*/, i32\n  /// /*part_id*/, captured_struct */*__context*/);\n  /// \\param SharedsTy A type which contains references the shared variables.\n  /// \\param Shareds Context with the list of shared variables from the \\p\n  /// TaskFunction.\n  /// \\param IfCond Not a nullptr if 'if' clause was specified, nullptr\n  /// otherwise.\n  /// \\param Data Additional data for task generation like tiednsee, final\n  /// state, list of privates etc.\n  void emitTaskLoopCall(CodeGenFunction &CGF, SourceLocation Loc,\n                        const OMPLoopDirective &D, llvm::Function *TaskFunction,\n                        QualType SharedsTy, Address Shareds, const Expr *IfCond,\n                        const OMPTaskDataTy &Data) override;\n\n  /// Emit a code for reduction clause. Next code should be emitted for\n  /// reduction:\n  /// \\code\n  ///\n  /// static kmp_critical_name lock = { 0 };\n  ///\n  /// void reduce_func(void *lhs[<n>], void *rhs[<n>]) {\n  ///  ...\n  ///  *(Type<i>*)lhs[i] = RedOp<i>(*(Type<i>*)lhs[i], *(Type<i>*)rhs[i]);\n  ///  ...\n  /// }\n  ///\n  /// ...\n  /// void *RedList[<n>] = {&<RHSExprs>[0], ..., &<RHSExprs>[<n>-1]};\n  /// switch (__kmpc_reduce{_nowait}(<loc>, <gtid>, <n>, sizeof(RedList),\n  /// RedList, reduce_func, &<lock>)) {\n  /// case 1:\n  ///  ...\n  ///  <LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]);\n  ///  ...\n  /// __kmpc_end_reduce{_nowait}(<loc>, <gtid>, &<lock>);\n  /// break;\n  /// case 2:\n  ///  ...\n  ///  Atomic(<LHSExprs>[i] = RedOp<i>(*<LHSExprs>[i], *<RHSExprs>[i]));\n  ///  ...\n  /// break;\n  /// default:;\n  /// }\n  /// \\endcode\n  ///\n  /// \\param Privates List of private copies for original reduction arguments.\n  /// \\param LHSExprs List of LHS in \\a ReductionOps reduction operations.\n  /// \\param RHSExprs List of RHS in \\a ReductionOps reduction operations.\n  /// \\param ReductionOps List of reduction operations in form 'LHS binop RHS'\n  /// or 'operator binop(LHS, RHS)'.\n  /// \\param Options List of options for reduction codegen:\n  ///     WithNowait true if parent directive has also nowait clause, false\n  ///     otherwise.\n  ///     SimpleReduction Emit reduction operation only. Used for omp simd\n  ///     directive on the host.\n  ///     ReductionKind The kind of reduction to perform.\n  void emitReduction(CodeGenFunction &CGF, SourceLocation Loc,\n                     ArrayRef<const Expr *> Privates,\n                     ArrayRef<const Expr *> LHSExprs,\n                     ArrayRef<const Expr *> RHSExprs,\n                     ArrayRef<const Expr *> ReductionOps,\n                     ReductionOptionsTy Options) override;\n\n  /// Emit a code for initialization of task reduction clause. Next code\n  /// should be emitted for reduction:\n  /// \\code\n  ///\n  /// _taskred_item_t red_data[n];\n  /// ...\n  /// red_data[i].shar = &shareds[i];\n  /// red_data[i].orig = &origs[i];\n  /// red_data[i].size = sizeof(origs[i]);\n  /// red_data[i].f_init = (void*)RedInit<i>;\n  /// red_data[i].f_fini = (void*)RedDest<i>;\n  /// red_data[i].f_comb = (void*)RedOp<i>;\n  /// red_data[i].flags = <Flag_i>;\n  /// ...\n  /// void* tg1 = __kmpc_taskred_init(gtid, n, red_data);\n  /// \\endcode\n  /// For reduction clause with task modifier it emits the next call:\n  /// \\code\n  ///\n  /// _taskred_item_t red_data[n];\n  /// ...\n  /// red_data[i].shar = &shareds[i];\n  /// red_data[i].orig = &origs[i];\n  /// red_data[i].size = sizeof(origs[i]);\n  /// red_data[i].f_init = (void*)RedInit<i>;\n  /// red_data[i].f_fini = (void*)RedDest<i>;\n  /// red_data[i].f_comb = (void*)RedOp<i>;\n  /// red_data[i].flags = <Flag_i>;\n  /// ...\n  /// void* tg1 = __kmpc_taskred_modifier_init(loc, gtid, is_worksharing, n,\n  /// red_data);\n  /// \\endcode\n  /// \\param LHSExprs List of LHS in \\a Data.ReductionOps reduction operations.\n  /// \\param RHSExprs List of RHS in \\a Data.ReductionOps reduction operations.\n  /// \\param Data Additional data for task generation like tiedness, final\n  /// state, list of privates, reductions etc.\n  llvm::Value *emitTaskReductionInit(CodeGenFunction &CGF, SourceLocation Loc,\n                                     ArrayRef<const Expr *> LHSExprs,\n                                     ArrayRef<const Expr *> RHSExprs,\n                                     const OMPTaskDataTy &Data) override;\n\n  /// Emits the following code for reduction clause with task modifier:\n  /// \\code\n  /// __kmpc_task_reduction_modifier_fini(loc, gtid, is_worksharing);\n  /// \\endcode\n  void emitTaskReductionFini(CodeGenFunction &CGF, SourceLocation Loc,\n                             bool IsWorksharingReduction) override;\n\n  /// Required to resolve existing problems in the runtime. Emits threadprivate\n  /// variables to store the size of the VLAs/array sections for\n  /// initializer/combiner/finalizer functions + emits threadprivate variable to\n  /// store the pointer to the original reduction item for the custom\n  /// initializer defined by declare reduction construct.\n  /// \\param RCG Allows to reuse an existing data for the reductions.\n  /// \\param N Reduction item for which fixups must be emitted.\n  void emitTaskReductionFixups(CodeGenFunction &CGF, SourceLocation Loc,\n                               ReductionCodeGen &RCG, unsigned N) override;\n\n  /// Get the address of `void *` type of the privatue copy of the reduction\n  /// item specified by the \\p SharedLVal.\n  /// \\param ReductionsPtr Pointer to the reduction data returned by the\n  /// emitTaskReductionInit function.\n  /// \\param SharedLVal Address of the original reduction item.\n  Address getTaskReductionItem(CodeGenFunction &CGF, SourceLocation Loc,\n                               llvm::Value *ReductionsPtr,\n                               LValue SharedLVal) override;\n\n  /// Emit code for 'taskwait' directive.\n  void emitTaskwaitCall(CodeGenFunction &CGF, SourceLocation Loc) override;\n\n  /// Emit code for 'cancellation point' construct.\n  /// \\param CancelRegion Region kind for which the cancellation point must be\n  /// emitted.\n  ///\n  void emitCancellationPointCall(CodeGenFunction &CGF, SourceLocation Loc,\n                                 OpenMPDirectiveKind CancelRegion) override;\n\n  /// Emit code for 'cancel' construct.\n  /// \\param IfCond Condition in the associated 'if' clause, if it was\n  /// specified, nullptr otherwise.\n  /// \\param CancelRegion Region kind for which the cancel must be emitted.\n  ///\n  void emitCancelCall(CodeGenFunction &CGF, SourceLocation Loc,\n                      const Expr *IfCond,\n                      OpenMPDirectiveKind CancelRegion) override;\n\n  /// Emit outilined function for 'target' directive.\n  /// \\param D Directive to emit.\n  /// \\param ParentName Name of the function that encloses the target region.\n  /// \\param OutlinedFn Outlined function value to be defined by this call.\n  /// \\param OutlinedFnID Outlined function ID value to be defined by this call.\n  /// \\param IsOffloadEntry True if the outlined function is an offload entry.\n  /// \\param CodeGen Code generation sequence for the \\a D directive.\n  /// An outlined function may not be an entry if, e.g. the if clause always\n  /// evaluates to false.\n  void emitTargetOutlinedFunction(const OMPExecutableDirective &D,\n                                  StringRef ParentName,\n                                  llvm::Function *&OutlinedFn,\n                                  llvm::Constant *&OutlinedFnID,\n                                  bool IsOffloadEntry,\n                                  const RegionCodeGenTy &CodeGen) override;\n\n  /// Emit the target offloading code associated with \\a D. The emitted\n  /// code attempts offloading the execution to the device, an the event of\n  /// a failure it executes the host version outlined in \\a OutlinedFn.\n  /// \\param D Directive to emit.\n  /// \\param OutlinedFn Host version of the code to be offloaded.\n  /// \\param OutlinedFnID ID of host version of the code to be offloaded.\n  /// \\param IfCond Expression evaluated in if clause associated with the target\n  /// directive, or null if no if clause is used.\n  /// \\param Device Expression evaluated in device clause associated with the\n  /// target directive, or null if no device clause is used and device modifier.\n  void emitTargetCall(\n      CodeGenFunction &CGF, const OMPExecutableDirective &D,\n      llvm::Function *OutlinedFn, llvm::Value *OutlinedFnID, const Expr *IfCond,\n      llvm::PointerIntPair<const Expr *, 2, OpenMPDeviceClauseModifier> Device,\n      llvm::function_ref<llvm::Value *(CodeGenFunction &CGF,\n                                       const OMPLoopDirective &D)>\n          SizeEmitter) override;\n\n  /// Emit the target regions enclosed in \\a GD function definition or\n  /// the function itself in case it is a valid device function. Returns true if\n  /// \\a GD was dealt with successfully.\n  /// \\param GD Function to scan.\n  bool emitTargetFunctions(GlobalDecl GD) override;\n\n  /// Emit the global variable if it is a valid device global variable.\n  /// Returns true if \\a GD was dealt with successfully.\n  /// \\param GD Variable declaration to emit.\n  bool emitTargetGlobalVariable(GlobalDecl GD) override;\n\n  /// Emit the global \\a GD if it is meaningful for the target. Returns\n  /// if it was emitted successfully.\n  /// \\param GD Global to scan.\n  bool emitTargetGlobal(GlobalDecl GD) override;\n\n  /// Emits code for teams call of the \\a OutlinedFn with\n  /// variables captured in a record which address is stored in \\a\n  /// CapturedStruct.\n  /// \\param OutlinedFn Outlined function to be run by team masters. Type of\n  /// this function is void(*)(kmp_int32 *, kmp_int32, struct context_vars*).\n  /// \\param CapturedVars A pointer to the record with the references to\n  /// variables used in \\a OutlinedFn function.\n  ///\n  void emitTeamsCall(CodeGenFunction &CGF, const OMPExecutableDirective &D,\n                     SourceLocation Loc, llvm::Function *OutlinedFn,\n                     ArrayRef<llvm::Value *> CapturedVars) override;\n\n  /// Emits call to void __kmpc_push_num_teams(ident_t *loc, kmp_int32\n  /// global_tid, kmp_int32 num_teams, kmp_int32 thread_limit) to generate code\n  /// for num_teams clause.\n  /// \\param NumTeams An integer expression of teams.\n  /// \\param ThreadLimit An integer expression of threads.\n  void emitNumTeamsClause(CodeGenFunction &CGF, const Expr *NumTeams,\n                          const Expr *ThreadLimit, SourceLocation Loc) override;\n\n  /// Emit the target data mapping code associated with \\a D.\n  /// \\param D Directive to emit.\n  /// \\param IfCond Expression evaluated in if clause associated with the\n  /// target directive, or null if no device clause is used.\n  /// \\param Device Expression evaluated in device clause associated with the\n  /// target directive, or null if no device clause is used.\n  /// \\param Info A record used to store information that needs to be preserved\n  /// until the region is closed.\n  void emitTargetDataCalls(CodeGenFunction &CGF,\n                           const OMPExecutableDirective &D, const Expr *IfCond,\n                           const Expr *Device, const RegionCodeGenTy &CodeGen,\n                           TargetDataInfo &Info) override;\n\n  /// Emit the data mapping/movement code associated with the directive\n  /// \\a D that should be of the form 'target [{enter|exit} data | update]'.\n  /// \\param D Directive to emit.\n  /// \\param IfCond Expression evaluated in if clause associated with the target\n  /// directive, or null if no if clause is used.\n  /// \\param Device Expression evaluated in device clause associated with the\n  /// target directive, or null if no device clause is used.\n  void emitTargetDataStandAloneCall(CodeGenFunction &CGF,\n                                    const OMPExecutableDirective &D,\n                                    const Expr *IfCond,\n                                    const Expr *Device) override;\n\n  /// Emit initialization for doacross loop nesting support.\n  /// \\param D Loop-based construct used in doacross nesting construct.\n  void emitDoacrossInit(CodeGenFunction &CGF, const OMPLoopDirective &D,\n                        ArrayRef<Expr *> NumIterations) override;\n\n  /// Emit code for doacross ordered directive with 'depend' clause.\n  /// \\param C 'depend' clause with 'sink|source' dependency kind.\n  void emitDoacrossOrdered(CodeGenFunction &CGF,\n                           const OMPDependClause *C) override;\n\n  /// Translates the native parameter of outlined function if this is required\n  /// for target.\n  /// \\param FD Field decl from captured record for the parameter.\n  /// \\param NativeParam Parameter itself.\n  const VarDecl *translateParameter(const FieldDecl *FD,\n                                    const VarDecl *NativeParam) const override;\n\n  /// Gets the address of the native argument basing on the address of the\n  /// target-specific parameter.\n  /// \\param NativeParam Parameter itself.\n  /// \\param TargetParam Corresponding target-specific parameter.\n  Address getParameterAddress(CodeGenFunction &CGF, const VarDecl *NativeParam,\n                              const VarDecl *TargetParam) const override;\n\n  /// Gets the OpenMP-specific address of the local variable.\n  Address getAddressOfLocalVariable(CodeGenFunction &CGF,\n                                    const VarDecl *VD) override {\n    return Address::invalid();\n  }\n};\n\n} // namespace CodeGen\n} // namespace clang\n\n#endif\n"}, "38": {"id": 38, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "content": "//===-- CodeGenFunction.h - Per-Function state for LLVM CodeGen -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This is the internal per-function state used for llvm translation.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CODEGENFUNCTION_H\n#define LLVM_CLANG_LIB_CODEGEN_CODEGENFUNCTION_H\n\n#include \"CGBuilder.h\"\n#include \"CGDebugInfo.h\"\n#include \"CGLoopInfo.h\"\n#include \"CGValue.h\"\n#include \"CodeGenModule.h\"\n#include \"CodeGenPGO.h\"\n#include \"EHScopeStack.h\"\n#include \"VarBypassDetector.h\"\n#include \"clang/AST/CharUnits.h\"\n#include \"clang/AST/CurrentSourceLocExprScope.h\"\n#include \"clang/AST/ExprCXX.h\"\n#include \"clang/AST/ExprObjC.h\"\n#include \"clang/AST/ExprOpenMP.h\"\n#include \"clang/AST/StmtOpenMP.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/ABI.h\"\n#include \"clang/Basic/CapturedStmt.h\"\n#include \"clang/Basic/CodeGenOptions.h\"\n#include \"clang/Basic/OpenMPKinds.h\"\n#include \"clang/Basic/TargetInfo.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Frontend/OpenMP/OMPIRBuilder.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Transforms/Utils/SanitizerStats.h\"\n\nnamespace llvm {\nclass BasicBlock;\nclass LLVMContext;\nclass MDNode;\nclass Module;\nclass SwitchInst;\nclass Twine;\nclass Value;\nclass CanonicalLoopInfo;\n}\n\nnamespace clang {\nclass ASTContext;\nclass BlockDecl;\nclass CXXDestructorDecl;\nclass CXXForRangeStmt;\nclass CXXTryStmt;\nclass Decl;\nclass LabelDecl;\nclass EnumConstantDecl;\nclass FunctionDecl;\nclass FunctionProtoType;\nclass LabelStmt;\nclass ObjCContainerDecl;\nclass ObjCInterfaceDecl;\nclass ObjCIvarDecl;\nclass ObjCMethodDecl;\nclass ObjCImplementationDecl;\nclass ObjCPropertyImplDecl;\nclass TargetInfo;\nclass VarDecl;\nclass ObjCForCollectionStmt;\nclass ObjCAtTryStmt;\nclass ObjCAtThrowStmt;\nclass ObjCAtSynchronizedStmt;\nclass ObjCAutoreleasePoolStmt;\nclass OMPUseDevicePtrClause;\nclass OMPUseDeviceAddrClause;\nclass ReturnsNonNullAttr;\nclass SVETypeFlags;\nclass OMPExecutableDirective;\n\nnamespace analyze_os_log {\nclass OSLogBufferLayout;\n}\n\nnamespace CodeGen {\nclass CodeGenTypes;\nclass CGCallee;\nclass CGFunctionInfo;\nclass CGRecordLayout;\nclass CGBlockInfo;\nclass CGCXXABI;\nclass BlockByrefHelpers;\nclass BlockByrefInfo;\nclass BlockFlags;\nclass BlockFieldFlags;\nclass RegionCodeGenTy;\nclass TargetCodeGenInfo;\nstruct OMPTaskDataTy;\nstruct CGCoroData;\n\n/// The kind of evaluation to perform on values of a particular\n/// type.  Basically, is the code in CGExprScalar, CGExprComplex, or\n/// CGExprAgg?\n///\n/// TODO: should vectors maybe be split out into their own thing?\nenum TypeEvaluationKind {\n  TEK_Scalar,\n  TEK_Complex,\n  TEK_Aggregate\n};\n\n#define LIST_SANITIZER_CHECKS                                                  \\\n  SANITIZER_CHECK(AddOverflow, add_overflow, 0)                                \\\n  SANITIZER_CHECK(BuiltinUnreachable, builtin_unreachable, 0)                  \\\n  SANITIZER_CHECK(CFICheckFail, cfi_check_fail, 0)                             \\\n  SANITIZER_CHECK(DivremOverflow, divrem_overflow, 0)                          \\\n  SANITIZER_CHECK(DynamicTypeCacheMiss, dynamic_type_cache_miss, 0)            \\\n  SANITIZER_CHECK(FloatCastOverflow, float_cast_overflow, 0)                   \\\n  SANITIZER_CHECK(FunctionTypeMismatch, function_type_mismatch, 1)             \\\n  SANITIZER_CHECK(ImplicitConversion, implicit_conversion, 0)                  \\\n  SANITIZER_CHECK(InvalidBuiltin, invalid_builtin, 0)                          \\\n  SANITIZER_CHECK(InvalidObjCCast, invalid_objc_cast, 0)                       \\\n  SANITIZER_CHECK(LoadInvalidValue, load_invalid_value, 0)                     \\\n  SANITIZER_CHECK(MissingReturn, missing_return, 0)                            \\\n  SANITIZER_CHECK(MulOverflow, mul_overflow, 0)                                \\\n  SANITIZER_CHECK(NegateOverflow, negate_overflow, 0)                          \\\n  SANITIZER_CHECK(NullabilityArg, nullability_arg, 0)                          \\\n  SANITIZER_CHECK(NullabilityReturn, nullability_return, 1)                    \\\n  SANITIZER_CHECK(NonnullArg, nonnull_arg, 0)                                  \\\n  SANITIZER_CHECK(NonnullReturn, nonnull_return, 1)                            \\\n  SANITIZER_CHECK(OutOfBounds, out_of_bounds, 0)                               \\\n  SANITIZER_CHECK(PointerOverflow, pointer_overflow, 0)                        \\\n  SANITIZER_CHECK(ShiftOutOfBounds, shift_out_of_bounds, 0)                    \\\n  SANITIZER_CHECK(SubOverflow, sub_overflow, 0)                                \\\n  SANITIZER_CHECK(TypeMismatch, type_mismatch, 1)                              \\\n  SANITIZER_CHECK(AlignmentAssumption, alignment_assumption, 0)                \\\n  SANITIZER_CHECK(VLABoundNotPositive, vla_bound_not_positive, 0)\n\nenum SanitizerHandler {\n#define SANITIZER_CHECK(Enum, Name, Version) Enum,\n  LIST_SANITIZER_CHECKS\n#undef SANITIZER_CHECK\n};\n\n/// Helper class with most of the code for saving a value for a\n/// conditional expression cleanup.\nstruct DominatingLLVMValue {\n  typedef llvm::PointerIntPair<llvm::Value*, 1, bool> saved_type;\n\n  /// Answer whether the given value needs extra work to be saved.\n  static bool needsSaving(llvm::Value *value) {\n    // If it's not an instruction, we don't need to save.\n    if (!isa<llvm::Instruction>(value)) return false;\n\n    // If it's an instruction in the entry block, we don't need to save.\n    llvm::BasicBlock *block = cast<llvm::Instruction>(value)->getParent();\n    return (block != &block->getParent()->getEntryBlock());\n  }\n\n  static saved_type save(CodeGenFunction &CGF, llvm::Value *value);\n  static llvm::Value *restore(CodeGenFunction &CGF, saved_type value);\n};\n\n/// A partial specialization of DominatingValue for llvm::Values that\n/// might be llvm::Instructions.\ntemplate <class T> struct DominatingPointer<T,true> : DominatingLLVMValue {\n  typedef T *type;\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return static_cast<T*>(DominatingLLVMValue::restore(CGF, value));\n  }\n};\n\n/// A specialization of DominatingValue for Address.\ntemplate <> struct DominatingValue<Address> {\n  typedef Address type;\n\n  struct saved_type {\n    DominatingLLVMValue::saved_type SavedValue;\n    CharUnits Alignment;\n  };\n\n  static bool needsSaving(type value) {\n    return DominatingLLVMValue::needsSaving(value.getPointer());\n  }\n  static saved_type save(CodeGenFunction &CGF, type value) {\n    return { DominatingLLVMValue::save(CGF, value.getPointer()),\n             value.getAlignment() };\n  }\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return Address(DominatingLLVMValue::restore(CGF, value.SavedValue),\n                   value.Alignment);\n  }\n};\n\n/// A specialization of DominatingValue for RValue.\ntemplate <> struct DominatingValue<RValue> {\n  typedef RValue type;\n  class saved_type {\n    enum Kind { ScalarLiteral, ScalarAddress, AggregateLiteral,\n                AggregateAddress, ComplexAddress };\n\n    llvm::Value *Value;\n    unsigned K : 3;\n    unsigned Align : 29;\n    saved_type(llvm::Value *v, Kind k, unsigned a = 0)\n      : Value(v), K(k), Align(a) {}\n\n  public:\n    static bool needsSaving(RValue value);\n    static saved_type save(CodeGenFunction &CGF, RValue value);\n    RValue restore(CodeGenFunction &CGF);\n\n    // implementations in CGCleanup.cpp\n  };\n\n  static bool needsSaving(type value) {\n    return saved_type::needsSaving(value);\n  }\n  static saved_type save(CodeGenFunction &CGF, type value) {\n    return saved_type::save(CGF, value);\n  }\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return value.restore(CGF);\n  }\n};\n\n/// CodeGenFunction - This class organizes the per-function state that is used\n/// while generating LLVM code.\nclass CodeGenFunction : public CodeGenTypeCache {\n  CodeGenFunction(const CodeGenFunction &) = delete;\n  void operator=(const CodeGenFunction &) = delete;\n\n  friend class CGCXXABI;\npublic:\n  /// A jump destination is an abstract label, branching to which may\n  /// require a jump out through normal cleanups.\n  struct JumpDest {\n    JumpDest() : Block(nullptr), ScopeDepth(), Index(0) {}\n    JumpDest(llvm::BasicBlock *Block,\n             EHScopeStack::stable_iterator Depth,\n             unsigned Index)\n      : Block(Block), ScopeDepth(Depth), Index(Index) {}\n\n    bool isValid() const { return Block != nullptr; }\n    llvm::BasicBlock *getBlock() const { return Block; }\n    EHScopeStack::stable_iterator getScopeDepth() const { return ScopeDepth; }\n    unsigned getDestIndex() const { return Index; }\n\n    // This should be used cautiously.\n    void setScopeDepth(EHScopeStack::stable_iterator depth) {\n      ScopeDepth = depth;\n    }\n\n  private:\n    llvm::BasicBlock *Block;\n    EHScopeStack::stable_iterator ScopeDepth;\n    unsigned Index;\n  };\n\n  CodeGenModule &CGM;  // Per-module state.\n  const TargetInfo &Target;\n\n  // For EH/SEH outlined funclets, this field points to parent's CGF\n  CodeGenFunction *ParentCGF = nullptr;\n\n  typedef std::pair<llvm::Value *, llvm::Value *> ComplexPairTy;\n  LoopInfoStack LoopStack;\n  CGBuilderTy Builder;\n\n  // Stores variables for which we can't generate correct lifetime markers\n  // because of jumps.\n  VarBypassDetector Bypasses;\n\n  /// List of recently emitted OMPCanonicalLoops.\n  ///\n  /// Since OMPCanonicalLoops are nested inside other statements (in particular\n  /// CapturedStmt generated by OMPExecutableDirective and non-perfectly nested\n  /// loops), we cannot directly call OMPEmitOMPCanonicalLoop and receive its\n  /// llvm::CanonicalLoopInfo. Instead, we call EmitStmt and any\n  /// OMPEmitOMPCanonicalLoop called by it will add its CanonicalLoopInfo to\n  /// this stack when done. Entering a new loop requires clearing this list; it\n  /// either means we start parsing a new loop nest (in which case the previous\n  /// loop nest goes out of scope) or a second loop in the same level in which\n  /// case it would be ambiguous into which of the two (or more) loops the loop\n  /// nest would extend.\n  SmallVector<llvm::CanonicalLoopInfo *, 4> OMPLoopNestStack;\n\n  // CodeGen lambda for loops and support for ordered clause\n  typedef llvm::function_ref<void(CodeGenFunction &, const OMPLoopDirective &,\n                                  JumpDest)>\n      CodeGenLoopTy;\n  typedef llvm::function_ref<void(CodeGenFunction &, SourceLocation,\n                                  const unsigned, const bool)>\n      CodeGenOrderedTy;\n\n  // Codegen lambda for loop bounds in worksharing loop constructs\n  typedef llvm::function_ref<std::pair<LValue, LValue>(\n      CodeGenFunction &, const OMPExecutableDirective &S)>\n      CodeGenLoopBoundsTy;\n\n  // Codegen lambda for loop bounds in dispatch-based loop implementation\n  typedef llvm::function_ref<std::pair<llvm::Value *, llvm::Value *>(\n      CodeGenFunction &, const OMPExecutableDirective &S, Address LB,\n      Address UB)>\n      CodeGenDispatchBoundsTy;\n\n  /// CGBuilder insert helper. This function is called after an\n  /// instruction is created using Builder.\n  void InsertHelper(llvm::Instruction *I, const llvm::Twine &Name,\n                    llvm::BasicBlock *BB,\n                    llvm::BasicBlock::iterator InsertPt) const;\n\n  /// CurFuncDecl - Holds the Decl for the current outermost\n  /// non-closure context.\n  const Decl *CurFuncDecl;\n  /// CurCodeDecl - This is the inner-most code context, which includes blocks.\n  const Decl *CurCodeDecl;\n  const CGFunctionInfo *CurFnInfo;\n  QualType FnRetTy;\n  llvm::Function *CurFn = nullptr;\n\n  // Holds coroutine data if the current function is a coroutine. We use a\n  // wrapper to manage its lifetime, so that we don't have to define CGCoroData\n  // in this header.\n  struct CGCoroInfo {\n    std::unique_ptr<CGCoroData> Data;\n    CGCoroInfo();\n    ~CGCoroInfo();\n  };\n  CGCoroInfo CurCoro;\n\n  bool isCoroutine() const {\n    return CurCoro.Data != nullptr;\n  }\n\n  /// CurGD - The GlobalDecl for the current function being compiled.\n  GlobalDecl CurGD;\n\n  /// PrologueCleanupDepth - The cleanup depth enclosing all the\n  /// cleanups associated with the parameters.\n  EHScopeStack::stable_iterator PrologueCleanupDepth;\n\n  /// ReturnBlock - Unified return block.\n  JumpDest ReturnBlock;\n\n  /// ReturnValue - The temporary alloca to hold the return\n  /// value. This is invalid iff the function has no return value.\n  Address ReturnValue = Address::invalid();\n\n  /// ReturnValuePointer - The temporary alloca to hold a pointer to sret.\n  /// This is invalid if sret is not in use.\n  Address ReturnValuePointer = Address::invalid();\n\n  /// If a return statement is being visited, this holds the return statment's\n  /// result expression.\n  const Expr *RetExpr = nullptr;\n\n  /// Return true if a label was seen in the current scope.\n  bool hasLabelBeenSeenInCurrentScope() const {\n    if (CurLexicalScope)\n      return CurLexicalScope->hasLabels();\n    return !LabelMap.empty();\n  }\n\n  /// AllocaInsertPoint - This is an instruction in the entry block before which\n  /// we prefer to insert allocas.\n  llvm::AssertingVH<llvm::Instruction> AllocaInsertPt;\n\n  /// API for captured statement code generation.\n  class CGCapturedStmtInfo {\n  public:\n    explicit CGCapturedStmtInfo(CapturedRegionKind K = CR_Default)\n        : Kind(K), ThisValue(nullptr), CXXThisFieldDecl(nullptr) {}\n    explicit CGCapturedStmtInfo(const CapturedStmt &S,\n                                CapturedRegionKind K = CR_Default)\n      : Kind(K), ThisValue(nullptr), CXXThisFieldDecl(nullptr) {\n\n      RecordDecl::field_iterator Field =\n        S.getCapturedRecordDecl()->field_begin();\n      for (CapturedStmt::const_capture_iterator I = S.capture_begin(),\n                                                E = S.capture_end();\n           I != E; ++I, ++Field) {\n        if (I->capturesThis())\n          CXXThisFieldDecl = *Field;\n        else if (I->capturesVariable())\n          CaptureFields[I->getCapturedVar()->getCanonicalDecl()] = *Field;\n        else if (I->capturesVariableByCopy())\n          CaptureFields[I->getCapturedVar()->getCanonicalDecl()] = *Field;\n      }\n    }\n\n    virtual ~CGCapturedStmtInfo();\n\n    CapturedRegionKind getKind() const { return Kind; }\n\n    virtual void setContextValue(llvm::Value *V) { ThisValue = V; }\n    // Retrieve the value of the context parameter.\n    virtual llvm::Value *getContextValue() const { return ThisValue; }\n\n    /// Lookup the captured field decl for a variable.\n    virtual const FieldDecl *lookup(const VarDecl *VD) const {\n      return CaptureFields.lookup(VD->getCanonicalDecl());\n    }\n\n    bool isCXXThisExprCaptured() const { return getThisFieldDecl() != nullptr; }\n    virtual FieldDecl *getThisFieldDecl() const { return CXXThisFieldDecl; }\n\n    static bool classof(const CGCapturedStmtInfo *) {\n      return true;\n    }\n\n    /// Emit the captured statement body.\n    virtual void EmitBody(CodeGenFunction &CGF, const Stmt *S) {\n      CGF.incrementProfileCounter(S);\n      CGF.EmitStmt(S);\n    }\n\n    /// Get the name of the capture helper.\n    virtual StringRef getHelperName() const { return \"__captured_stmt\"; }\n\n  private:\n    /// The kind of captured statement being generated.\n    CapturedRegionKind Kind;\n\n    /// Keep the map between VarDecl and FieldDecl.\n    llvm::SmallDenseMap<const VarDecl *, FieldDecl *> CaptureFields;\n\n    /// The base address of the captured record, passed in as the first\n    /// argument of the parallel region function.\n    llvm::Value *ThisValue;\n\n    /// Captured 'this' type.\n    FieldDecl *CXXThisFieldDecl;\n  };\n  CGCapturedStmtInfo *CapturedStmtInfo = nullptr;\n\n  /// RAII for correct setting/restoring of CapturedStmtInfo.\n  class CGCapturedStmtRAII {\n  private:\n    CodeGenFunction &CGF;\n    CGCapturedStmtInfo *PrevCapturedStmtInfo;\n  public:\n    CGCapturedStmtRAII(CodeGenFunction &CGF,\n                       CGCapturedStmtInfo *NewCapturedStmtInfo)\n        : CGF(CGF), PrevCapturedStmtInfo(CGF.CapturedStmtInfo) {\n      CGF.CapturedStmtInfo = NewCapturedStmtInfo;\n    }\n    ~CGCapturedStmtRAII() { CGF.CapturedStmtInfo = PrevCapturedStmtInfo; }\n  };\n\n  /// An abstract representation of regular/ObjC call/message targets.\n  class AbstractCallee {\n    /// The function declaration of the callee.\n    const Decl *CalleeDecl;\n\n  public:\n    AbstractCallee() : CalleeDecl(nullptr) {}\n    AbstractCallee(const FunctionDecl *FD) : CalleeDecl(FD) {}\n    AbstractCallee(const ObjCMethodDecl *OMD) : CalleeDecl(OMD) {}\n    bool hasFunctionDecl() const {\n      return dyn_cast_or_null<FunctionDecl>(CalleeDecl);\n    }\n    const Decl *getDecl() const { return CalleeDecl; }\n    unsigned getNumParams() const {\n      if (const auto *FD = dyn_cast<FunctionDecl>(CalleeDecl))\n        return FD->getNumParams();\n      return cast<ObjCMethodDecl>(CalleeDecl)->param_size();\n    }\n    const ParmVarDecl *getParamDecl(unsigned I) const {\n      if (const auto *FD = dyn_cast<FunctionDecl>(CalleeDecl))\n        return FD->getParamDecl(I);\n      return *(cast<ObjCMethodDecl>(CalleeDecl)->param_begin() + I);\n    }\n  };\n\n  /// Sanitizers enabled for this function.\n  SanitizerSet SanOpts;\n\n  /// True if CodeGen currently emits code implementing sanitizer checks.\n  bool IsSanitizerScope = false;\n\n  /// RAII object to set/unset CodeGenFunction::IsSanitizerScope.\n  class SanitizerScope {\n    CodeGenFunction *CGF;\n  public:\n    SanitizerScope(CodeGenFunction *CGF);\n    ~SanitizerScope();\n  };\n\n  /// In C++, whether we are code generating a thunk.  This controls whether we\n  /// should emit cleanups.\n  bool CurFuncIsThunk = false;\n\n  /// In ARC, whether we should autorelease the return value.\n  bool AutoreleaseResult = false;\n\n  /// Whether we processed a Microsoft-style asm block during CodeGen. These can\n  /// potentially set the return value.\n  bool SawAsmBlock = false;\n\n  const NamedDecl *CurSEHParent = nullptr;\n\n  /// True if the current function is an outlined SEH helper. This can be a\n  /// finally block or filter expression.\n  bool IsOutlinedSEHHelper = false;\n\n  /// True if CodeGen currently emits code inside presereved access index\n  /// region.\n  bool IsInPreservedAIRegion = false;\n\n  /// True if the current statement has nomerge attribute.\n  bool InNoMergeAttributedStmt = false;\n\n  /// True if the current function should be marked mustprogress.\n  bool FnIsMustProgress = false;\n\n  /// True if the C++ Standard Requires Progress.\n  bool CPlusPlusWithProgress() {\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Never)\n      return false;\n\n    return getLangOpts().CPlusPlus11 || getLangOpts().CPlusPlus14 ||\n           getLangOpts().CPlusPlus17 || getLangOpts().CPlusPlus20;\n  }\n\n  /// True if the C Standard Requires Progress.\n  bool CWithProgress() {\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Always)\n      return true;\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Never)\n      return false;\n\n    return getLangOpts().C11 || getLangOpts().C17 || getLangOpts().C2x;\n  }\n\n  /// True if the language standard requires progress in functions or\n  /// in infinite loops with non-constant conditionals.\n  bool LanguageRequiresProgress() {\n    return CWithProgress() || CPlusPlusWithProgress();\n  }\n\n  const CodeGen::CGBlockInfo *BlockInfo = nullptr;\n  llvm::Value *BlockPointer = nullptr;\n\n  llvm::DenseMap<const VarDecl *, FieldDecl *> LambdaCaptureFields;\n  FieldDecl *LambdaThisCaptureField = nullptr;\n\n  /// A mapping from NRVO variables to the flags used to indicate\n  /// when the NRVO has been applied to this variable.\n  llvm::DenseMap<const VarDecl *, llvm::Value *> NRVOFlags;\n\n  EHScopeStack EHStack;\n  llvm::SmallVector<char, 256> LifetimeExtendedCleanupStack;\n  llvm::SmallVector<const JumpDest *, 2> SEHTryEpilogueStack;\n\n  llvm::Instruction *CurrentFuncletPad = nullptr;\n\n  class CallLifetimeEnd final : public EHScopeStack::Cleanup {\n    llvm::Value *Addr;\n    llvm::Value *Size;\n\n  public:\n    CallLifetimeEnd(Address addr, llvm::Value *size)\n        : Addr(addr.getPointer()), Size(size) {}\n\n    void Emit(CodeGenFunction &CGF, Flags flags) override {\n      CGF.EmitLifetimeEnd(Size, Addr);\n    }\n  };\n\n  /// Header for data within LifetimeExtendedCleanupStack.\n  struct LifetimeExtendedCleanupHeader {\n    /// The size of the following cleanup object.\n    unsigned Size;\n    /// The kind of cleanup to push: a value from the CleanupKind enumeration.\n    unsigned Kind : 31;\n    /// Whether this is a conditional cleanup.\n    unsigned IsConditional : 1;\n\n    size_t getSize() const { return Size; }\n    CleanupKind getKind() const { return (CleanupKind)Kind; }\n    bool isConditional() const { return IsConditional; }\n  };\n\n  /// i32s containing the indexes of the cleanup destinations.\n  Address NormalCleanupDest = Address::invalid();\n\n  unsigned NextCleanupDestIndex = 1;\n\n  /// EHResumeBlock - Unified block containing a call to llvm.eh.resume.\n  llvm::BasicBlock *EHResumeBlock = nullptr;\n\n  /// The exception slot.  All landing pads write the current exception pointer\n  /// into this alloca.\n  llvm::Value *ExceptionSlot = nullptr;\n\n  /// The selector slot.  Under the MandatoryCleanup model, all landing pads\n  /// write the current selector value into this alloca.\n  llvm::AllocaInst *EHSelectorSlot = nullptr;\n\n  /// A stack of exception code slots. Entering an __except block pushes a slot\n  /// on the stack and leaving pops one. The __exception_code() intrinsic loads\n  /// a value from the top of the stack.\n  SmallVector<Address, 1> SEHCodeSlotStack;\n\n  /// Value returned by __exception_info intrinsic.\n  llvm::Value *SEHInfo = nullptr;\n\n  /// Emits a landing pad for the current EH stack.\n  llvm::BasicBlock *EmitLandingPad();\n\n  llvm::BasicBlock *getInvokeDestImpl();\n\n  /// Parent loop-based directive for scan directive.\n  const OMPExecutableDirective *OMPParentLoopDirectiveForScan = nullptr;\n  llvm::BasicBlock *OMPBeforeScanBlock = nullptr;\n  llvm::BasicBlock *OMPAfterScanBlock = nullptr;\n  llvm::BasicBlock *OMPScanExitBlock = nullptr;\n  llvm::BasicBlock *OMPScanDispatch = nullptr;\n  bool OMPFirstScanLoop = false;\n\n  /// Manages parent directive for scan directives.\n  class ParentLoopDirectiveForScanRegion {\n    CodeGenFunction &CGF;\n    const OMPExecutableDirective *ParentLoopDirectiveForScan;\n\n  public:\n    ParentLoopDirectiveForScanRegion(\n        CodeGenFunction &CGF,\n        const OMPExecutableDirective &ParentLoopDirectiveForScan)\n        : CGF(CGF),\n          ParentLoopDirectiveForScan(CGF.OMPParentLoopDirectiveForScan) {\n      CGF.OMPParentLoopDirectiveForScan = &ParentLoopDirectiveForScan;\n    }\n    ~ParentLoopDirectiveForScanRegion() {\n      CGF.OMPParentLoopDirectiveForScan = ParentLoopDirectiveForScan;\n    }\n  };\n\n  template <class T>\n  typename DominatingValue<T>::saved_type saveValueInCond(T value) {\n    return DominatingValue<T>::save(*this, value);\n  }\n\n  class CGFPOptionsRAII {\n  public:\n    CGFPOptionsRAII(CodeGenFunction &CGF, FPOptions FPFeatures);\n    CGFPOptionsRAII(CodeGenFunction &CGF, const Expr *E);\n    ~CGFPOptionsRAII();\n\n  private:\n    void ConstructorHelper(FPOptions FPFeatures);\n    CodeGenFunction &CGF;\n    FPOptions OldFPFeatures;\n    llvm::fp::ExceptionBehavior OldExcept;\n    llvm::RoundingMode OldRounding;\n    Optional<CGBuilderTy::FastMathFlagGuard> FMFGuard;\n  };\n  FPOptions CurFPFeatures;\n\npublic:\n  /// ObjCEHValueStack - Stack of Objective-C exception values, used for\n  /// rethrows.\n  SmallVector<llvm::Value*, 8> ObjCEHValueStack;\n\n  /// A class controlling the emission of a finally block.\n  class FinallyInfo {\n    /// Where the catchall's edge through the cleanup should go.\n    JumpDest RethrowDest;\n\n    /// A function to call to enter the catch.\n    llvm::FunctionCallee BeginCatchFn;\n\n    /// An i1 variable indicating whether or not the @finally is\n    /// running for an exception.\n    llvm::AllocaInst *ForEHVar;\n\n    /// An i8* variable into which the exception pointer to rethrow\n    /// has been saved.\n    llvm::AllocaInst *SavedExnVar;\n\n  public:\n    void enter(CodeGenFunction &CGF, const Stmt *Finally,\n               llvm::FunctionCallee beginCatchFn,\n               llvm::FunctionCallee endCatchFn, llvm::FunctionCallee rethrowFn);\n    void exit(CodeGenFunction &CGF);\n  };\n\n  /// Returns true inside SEH __try blocks.\n  bool isSEHTryScope() const { return !SEHTryEpilogueStack.empty(); }\n\n  /// Returns true while emitting a cleanuppad.\n  bool isCleanupPadScope() const {\n    return CurrentFuncletPad && isa<llvm::CleanupPadInst>(CurrentFuncletPad);\n  }\n\n  /// pushFullExprCleanup - Push a cleanup to be run at the end of the\n  /// current full-expression.  Safe against the possibility that\n  /// we're currently inside a conditionally-evaluated expression.\n  template <class T, class... As>\n  void pushFullExprCleanup(CleanupKind kind, As... A) {\n    // If we're not in a conditional branch, or if none of the\n    // arguments requires saving, then use the unconditional cleanup.\n    if (!isInConditionalBranch())\n      return EHStack.pushCleanup<T>(kind, A...);\n\n    // Stash values in a tuple so we can guarantee the order of saves.\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved{saveValueInCond(A)...};\n\n    typedef EHScopeStack::ConditionalCleanup<T, As...> CleanupType;\n    EHStack.pushCleanupTuple<CleanupType>(kind, Saved);\n    initFullExprCleanup();\n  }\n\n  /// Queue a cleanup to be pushed after finishing the current full-expression,\n  /// potentially with an active flag.\n  template <class T, class... As>\n  void pushCleanupAfterFullExpr(CleanupKind Kind, As... A) {\n    if (!isInConditionalBranch())\n      return pushCleanupAfterFullExprWithActiveFlag<T>(Kind, Address::invalid(),\n                                                       A...);\n\n    Address ActiveFlag = createCleanupActiveFlag();\n    assert(!DominatingValue<Address>::needsSaving(ActiveFlag) &&\n           \"cleanup active flag should never need saving\");\n\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved{saveValueInCond(A)...};\n\n    typedef EHScopeStack::ConditionalCleanup<T, As...> CleanupType;\n    pushCleanupAfterFullExprWithActiveFlag<CleanupType>(Kind, ActiveFlag, Saved);\n  }\n\n  template <class T, class... As>\n  void pushCleanupAfterFullExprWithActiveFlag(CleanupKind Kind,\n                                              Address ActiveFlag, As... A) {\n    LifetimeExtendedCleanupHeader Header = {sizeof(T), Kind,\n                                            ActiveFlag.isValid()};\n\n    size_t OldSize = LifetimeExtendedCleanupStack.size();\n    LifetimeExtendedCleanupStack.resize(\n        LifetimeExtendedCleanupStack.size() + sizeof(Header) + Header.Size +\n        (Header.IsConditional ? sizeof(ActiveFlag) : 0));\n\n    static_assert(sizeof(Header) % alignof(T) == 0,\n                  \"Cleanup will be allocated on misaligned address\");\n    char *Buffer = &LifetimeExtendedCleanupStack[OldSize];\n    new (Buffer) LifetimeExtendedCleanupHeader(Header);\n    new (Buffer + sizeof(Header)) T(A...);\n    if (Header.IsConditional)\n      new (Buffer + sizeof(Header) + sizeof(T)) Address(ActiveFlag);\n  }\n\n  /// Set up the last cleanup that was pushed as a conditional\n  /// full-expression cleanup.\n  void initFullExprCleanup() {\n    initFullExprCleanupWithFlag(createCleanupActiveFlag());\n  }\n\n  void initFullExprCleanupWithFlag(Address ActiveFlag);\n  Address createCleanupActiveFlag();\n\n  /// PushDestructorCleanup - Push a cleanup to call the\n  /// complete-object destructor of an object of the given type at the\n  /// given address.  Does nothing if T is not a C++ class type with a\n  /// non-trivial destructor.\n  void PushDestructorCleanup(QualType T, Address Addr);\n\n  /// PushDestructorCleanup - Push a cleanup to call the\n  /// complete-object variant of the given destructor on the object at\n  /// the given address.\n  void PushDestructorCleanup(const CXXDestructorDecl *Dtor, QualType T,\n                             Address Addr);\n\n  /// PopCleanupBlock - Will pop the cleanup entry on the stack and\n  /// process all branch fixups.\n  void PopCleanupBlock(bool FallThroughIsBranchThrough = false);\n\n  /// DeactivateCleanupBlock - Deactivates the given cleanup block.\n  /// The block cannot be reactivated.  Pops it if it's the top of the\n  /// stack.\n  ///\n  /// \\param DominatingIP - An instruction which is known to\n  ///   dominate the current IP (if set) and which lies along\n  ///   all paths of execution between the current IP and the\n  ///   the point at which the cleanup comes into scope.\n  void DeactivateCleanupBlock(EHScopeStack::stable_iterator Cleanup,\n                              llvm::Instruction *DominatingIP);\n\n  /// ActivateCleanupBlock - Activates an initially-inactive cleanup.\n  /// Cannot be used to resurrect a deactivated cleanup.\n  ///\n  /// \\param DominatingIP - An instruction which is known to\n  ///   dominate the current IP (if set) and which lies along\n  ///   all paths of execution between the current IP and the\n  ///   the point at which the cleanup comes into scope.\n  void ActivateCleanupBlock(EHScopeStack::stable_iterator Cleanup,\n                            llvm::Instruction *DominatingIP);\n\n  /// Enters a new scope for capturing cleanups, all of which\n  /// will be executed once the scope is exited.\n  class RunCleanupsScope {\n    EHScopeStack::stable_iterator CleanupStackDepth, OldCleanupScopeDepth;\n    size_t LifetimeExtendedCleanupStackSize;\n    bool OldDidCallStackSave;\n  protected:\n    bool PerformCleanup;\n  private:\n\n    RunCleanupsScope(const RunCleanupsScope &) = delete;\n    void operator=(const RunCleanupsScope &) = delete;\n\n  protected:\n    CodeGenFunction& CGF;\n\n  public:\n    /// Enter a new cleanup scope.\n    explicit RunCleanupsScope(CodeGenFunction &CGF)\n      : PerformCleanup(true), CGF(CGF)\n    {\n      CleanupStackDepth = CGF.EHStack.stable_begin();\n      LifetimeExtendedCleanupStackSize =\n          CGF.LifetimeExtendedCleanupStack.size();\n      OldDidCallStackSave = CGF.DidCallStackSave;\n      CGF.DidCallStackSave = false;\n      OldCleanupScopeDepth = CGF.CurrentCleanupScopeDepth;\n      CGF.CurrentCleanupScopeDepth = CleanupStackDepth;\n    }\n\n    /// Exit this cleanup scope, emitting any accumulated cleanups.\n    ~RunCleanupsScope() {\n      if (PerformCleanup)\n        ForceCleanup();\n    }\n\n    /// Determine whether this scope requires any cleanups.\n    bool requiresCleanups() const {\n      return CGF.EHStack.stable_begin() != CleanupStackDepth;\n    }\n\n    /// Force the emission of cleanups now, instead of waiting\n    /// until this object is destroyed.\n    /// \\param ValuesToReload - A list of values that need to be available at\n    /// the insertion point after cleanup emission. If cleanup emission created\n    /// a shared cleanup block, these value pointers will be rewritten.\n    /// Otherwise, they not will be modified.\n    void ForceCleanup(std::initializer_list<llvm::Value**> ValuesToReload = {}) {\n      assert(PerformCleanup && \"Already forced cleanup\");\n      CGF.DidCallStackSave = OldDidCallStackSave;\n      CGF.PopCleanupBlocks(CleanupStackDepth, LifetimeExtendedCleanupStackSize,\n                           ValuesToReload);\n      PerformCleanup = false;\n      CGF.CurrentCleanupScopeDepth = OldCleanupScopeDepth;\n    }\n  };\n\n  // Cleanup stack depth of the RunCleanupsScope that was pushed most recently.\n  EHScopeStack::stable_iterator CurrentCleanupScopeDepth =\n      EHScopeStack::stable_end();\n\n  class LexicalScope : public RunCleanupsScope {\n    SourceRange Range;\n    SmallVector<const LabelDecl*, 4> Labels;\n    LexicalScope *ParentScope;\n\n    LexicalScope(const LexicalScope &) = delete;\n    void operator=(const LexicalScope &) = delete;\n\n  public:\n    /// Enter a new cleanup scope.\n    explicit LexicalScope(CodeGenFunction &CGF, SourceRange Range)\n      : RunCleanupsScope(CGF), Range(Range), ParentScope(CGF.CurLexicalScope) {\n      CGF.CurLexicalScope = this;\n      if (CGDebugInfo *DI = CGF.getDebugInfo())\n        DI->EmitLexicalBlockStart(CGF.Builder, Range.getBegin());\n    }\n\n    void addLabel(const LabelDecl *label) {\n      assert(PerformCleanup && \"adding label to dead scope?\");\n      Labels.push_back(label);\n    }\n\n    /// Exit this cleanup scope, emitting any accumulated\n    /// cleanups.\n    ~LexicalScope() {\n      if (CGDebugInfo *DI = CGF.getDebugInfo())\n        DI->EmitLexicalBlockEnd(CGF.Builder, Range.getEnd());\n\n      // If we should perform a cleanup, force them now.  Note that\n      // this ends the cleanup scope before rescoping any labels.\n      if (PerformCleanup) {\n        ApplyDebugLocation DL(CGF, Range.getEnd());\n        ForceCleanup();\n      }\n    }\n\n    /// Force the emission of cleanups now, instead of waiting\n    /// until this object is destroyed.\n    void ForceCleanup() {\n      CGF.CurLexicalScope = ParentScope;\n      RunCleanupsScope::ForceCleanup();\n\n      if (!Labels.empty())\n        rescopeLabels();\n    }\n\n    bool hasLabels() const {\n      return !Labels.empty();\n    }\n\n    void rescopeLabels();\n  };\n\n  typedef llvm::DenseMap<const Decl *, Address> DeclMapTy;\n\n  /// The class used to assign some variables some temporarily addresses.\n  class OMPMapVars {\n    DeclMapTy SavedLocals;\n    DeclMapTy SavedTempAddresses;\n    OMPMapVars(const OMPMapVars &) = delete;\n    void operator=(const OMPMapVars &) = delete;\n\n  public:\n    explicit OMPMapVars() = default;\n    ~OMPMapVars() {\n      assert(SavedLocals.empty() && \"Did not restored original addresses.\");\n    };\n\n    /// Sets the address of the variable \\p LocalVD to be \\p TempAddr in\n    /// function \\p CGF.\n    /// \\return true if at least one variable was set already, false otherwise.\n    bool setVarAddr(CodeGenFunction &CGF, const VarDecl *LocalVD,\n                    Address TempAddr) {\n      LocalVD = LocalVD->getCanonicalDecl();\n      // Only save it once.\n      if (SavedLocals.count(LocalVD)) return false;\n\n      // Copy the existing local entry to SavedLocals.\n      auto it = CGF.LocalDeclMap.find(LocalVD);\n      if (it != CGF.LocalDeclMap.end())\n        SavedLocals.try_emplace(LocalVD, it->second);\n      else\n        SavedLocals.try_emplace(LocalVD, Address::invalid());\n\n      // Generate the private entry.\n      QualType VarTy = LocalVD->getType();\n      if (VarTy->isReferenceType()) {\n        Address Temp = CGF.CreateMemTemp(VarTy);\n        CGF.Builder.CreateStore(TempAddr.getPointer(), Temp);\n        TempAddr = Temp;\n      }\n      SavedTempAddresses.try_emplace(LocalVD, TempAddr);\n\n      return true;\n    }\n\n    /// Applies new addresses to the list of the variables.\n    /// \\return true if at least one variable is using new address, false\n    /// otherwise.\n    bool apply(CodeGenFunction &CGF) {\n      copyInto(SavedTempAddresses, CGF.LocalDeclMap);\n      SavedTempAddresses.clear();\n      return !SavedLocals.empty();\n    }\n\n    /// Restores original addresses of the variables.\n    void restore(CodeGenFunction &CGF) {\n      if (!SavedLocals.empty()) {\n        copyInto(SavedLocals, CGF.LocalDeclMap);\n        SavedLocals.clear();\n      }\n    }\n\n  private:\n    /// Copy all the entries in the source map over the corresponding\n    /// entries in the destination, which must exist.\n    static void copyInto(const DeclMapTy &Src, DeclMapTy &Dest) {\n      for (auto &Pair : Src) {\n        if (!Pair.second.isValid()) {\n          Dest.erase(Pair.first);\n          continue;\n        }\n\n        auto I = Dest.find(Pair.first);\n        if (I != Dest.end())\n          I->second = Pair.second;\n        else\n          Dest.insert(Pair);\n      }\n    }\n  };\n\n  /// The scope used to remap some variables as private in the OpenMP loop body\n  /// (or other captured region emitted without outlining), and to restore old\n  /// vars back on exit.\n  class OMPPrivateScope : public RunCleanupsScope {\n    OMPMapVars MappedVars;\n    OMPPrivateScope(const OMPPrivateScope &) = delete;\n    void operator=(const OMPPrivateScope &) = delete;\n\n  public:\n    /// Enter a new OpenMP private scope.\n    explicit OMPPrivateScope(CodeGenFunction &CGF) : RunCleanupsScope(CGF) {}\n\n    /// Registers \\p LocalVD variable as a private and apply \\p PrivateGen\n    /// function for it to generate corresponding private variable. \\p\n    /// PrivateGen returns an address of the generated private variable.\n    /// \\return true if the variable is registered as private, false if it has\n    /// been privatized already.\n    bool addPrivate(const VarDecl *LocalVD,\n                    const llvm::function_ref<Address()> PrivateGen) {\n      assert(PerformCleanup && \"adding private to dead scope\");\n      return MappedVars.setVarAddr(CGF, LocalVD, PrivateGen());\n    }\n\n    /// Privatizes local variables previously registered as private.\n    /// Registration is separate from the actual privatization to allow\n    /// initializers use values of the original variables, not the private one.\n    /// This is important, for example, if the private variable is a class\n    /// variable initialized by a constructor that references other private\n    /// variables. But at initialization original variables must be used, not\n    /// private copies.\n    /// \\return true if at least one variable was privatized, false otherwise.\n    bool Privatize() { return MappedVars.apply(CGF); }\n\n    void ForceCleanup() {\n      RunCleanupsScope::ForceCleanup();\n      MappedVars.restore(CGF);\n    }\n\n    /// Exit scope - all the mapped variables are restored.\n    ~OMPPrivateScope() {\n      if (PerformCleanup)\n        ForceCleanup();\n    }\n\n    /// Checks if the global variable is captured in current function.\n    bool isGlobalVarCaptured(const VarDecl *VD) const {\n      VD = VD->getCanonicalDecl();\n      return !VD->isLocalVarDeclOrParm() && CGF.LocalDeclMap.count(VD) > 0;\n    }\n  };\n\n  /// Save/restore original map of previously emitted local vars in case when we\n  /// need to duplicate emission of the same code several times in the same\n  /// function for OpenMP code.\n  class OMPLocalDeclMapRAII {\n    CodeGenFunction &CGF;\n    DeclMapTy SavedMap;\n\n  public:\n    OMPLocalDeclMapRAII(CodeGenFunction &CGF)\n        : CGF(CGF), SavedMap(CGF.LocalDeclMap) {}\n    ~OMPLocalDeclMapRAII() { SavedMap.swap(CGF.LocalDeclMap); }\n  };\n\n  /// Takes the old cleanup stack size and emits the cleanup blocks\n  /// that have been added.\n  void\n  PopCleanupBlocks(EHScopeStack::stable_iterator OldCleanupStackSize,\n                   std::initializer_list<llvm::Value **> ValuesToReload = {});\n\n  /// Takes the old cleanup stack size and emits the cleanup blocks\n  /// that have been added, then adds all lifetime-extended cleanups from\n  /// the given position to the stack.\n  void\n  PopCleanupBlocks(EHScopeStack::stable_iterator OldCleanupStackSize,\n                   size_t OldLifetimeExtendedStackSize,\n                   std::initializer_list<llvm::Value **> ValuesToReload = {});\n\n  void ResolveBranchFixups(llvm::BasicBlock *Target);\n\n  /// The given basic block lies in the current EH scope, but may be a\n  /// target of a potentially scope-crossing jump; get a stable handle\n  /// to which we can perform this jump later.\n  JumpDest getJumpDestInCurrentScope(llvm::BasicBlock *Target) {\n    return JumpDest(Target,\n                    EHStack.getInnermostNormalCleanup(),\n                    NextCleanupDestIndex++);\n  }\n\n  /// The given basic block lies in the current EH scope, but may be a\n  /// target of a potentially scope-crossing jump; get a stable handle\n  /// to which we can perform this jump later.\n  JumpDest getJumpDestInCurrentScope(StringRef Name = StringRef()) {\n    return getJumpDestInCurrentScope(createBasicBlock(Name));\n  }\n\n  /// EmitBranchThroughCleanup - Emit a branch from the current insert\n  /// block through the normal cleanup handling code (if any) and then\n  /// on to \\arg Dest.\n  void EmitBranchThroughCleanup(JumpDest Dest);\n\n  /// isObviouslyBranchWithoutCleanups - Return true if a branch to the\n  /// specified destination obviously has no cleanups to run.  'false' is always\n  /// a conservatively correct answer for this method.\n  bool isObviouslyBranchWithoutCleanups(JumpDest Dest) const;\n\n  /// popCatchScope - Pops the catch scope at the top of the EHScope\n  /// stack, emitting any required code (other than the catch handlers\n  /// themselves).\n  void popCatchScope();\n\n  llvm::BasicBlock *getEHResumeBlock(bool isCleanup);\n  llvm::BasicBlock *getEHDispatchBlock(EHScopeStack::stable_iterator scope);\n  llvm::BasicBlock *\n  getFuncletEHDispatchBlock(EHScopeStack::stable_iterator scope);\n\n  /// An object to manage conditionally-evaluated expressions.\n  class ConditionalEvaluation {\n    llvm::BasicBlock *StartBB;\n\n  public:\n    ConditionalEvaluation(CodeGenFunction &CGF)\n      : StartBB(CGF.Builder.GetInsertBlock()) {}\n\n    void begin(CodeGenFunction &CGF) {\n      assert(CGF.OutermostConditional != this);\n      if (!CGF.OutermostConditional)\n        CGF.OutermostConditional = this;\n    }\n\n    void end(CodeGenFunction &CGF) {\n      assert(CGF.OutermostConditional != nullptr);\n      if (CGF.OutermostConditional == this)\n        CGF.OutermostConditional = nullptr;\n    }\n\n    /// Returns a block which will be executed prior to each\n    /// evaluation of the conditional code.\n    llvm::BasicBlock *getStartingBlock() const {\n      return StartBB;\n    }\n  };\n\n  /// isInConditionalBranch - Return true if we're currently emitting\n  /// one branch or the other of a conditional expression.\n  bool isInConditionalBranch() const { return OutermostConditional != nullptr; }\n\n  void setBeforeOutermostConditional(llvm::Value *value, Address addr) {\n    assert(isInConditionalBranch());\n    llvm::BasicBlock *block = OutermostConditional->getStartingBlock();\n    auto store = new llvm::StoreInst(value, addr.getPointer(), &block->back());\n    store->setAlignment(addr.getAlignment().getAsAlign());\n  }\n\n  /// An RAII object to record that we're evaluating a statement\n  /// expression.\n  class StmtExprEvaluation {\n    CodeGenFunction &CGF;\n\n    /// We have to save the outermost conditional: cleanups in a\n    /// statement expression aren't conditional just because the\n    /// StmtExpr is.\n    ConditionalEvaluation *SavedOutermostConditional;\n\n  public:\n    StmtExprEvaluation(CodeGenFunction &CGF)\n      : CGF(CGF), SavedOutermostConditional(CGF.OutermostConditional) {\n      CGF.OutermostConditional = nullptr;\n    }\n\n    ~StmtExprEvaluation() {\n      CGF.OutermostConditional = SavedOutermostConditional;\n      CGF.EnsureInsertPoint();\n    }\n  };\n\n  /// An object which temporarily prevents a value from being\n  /// destroyed by aggressive peephole optimizations that assume that\n  /// all uses of a value have been realized in the IR.\n  class PeepholeProtection {\n    llvm::Instruction *Inst;\n    friend class CodeGenFunction;\n\n  public:\n    PeepholeProtection() : Inst(nullptr) {}\n  };\n\n  /// A non-RAII class containing all the information about a bound\n  /// opaque value.  OpaqueValueMapping, below, is a RAII wrapper for\n  /// this which makes individual mappings very simple; using this\n  /// class directly is useful when you have a variable number of\n  /// opaque values or don't want the RAII functionality for some\n  /// reason.\n  class OpaqueValueMappingData {\n    const OpaqueValueExpr *OpaqueValue;\n    bool BoundLValue;\n    CodeGenFunction::PeepholeProtection Protection;\n\n    OpaqueValueMappingData(const OpaqueValueExpr *ov,\n                           bool boundLValue)\n      : OpaqueValue(ov), BoundLValue(boundLValue) {}\n  public:\n    OpaqueValueMappingData() : OpaqueValue(nullptr) {}\n\n    static bool shouldBindAsLValue(const Expr *expr) {\n      // gl-values should be bound as l-values for obvious reasons.\n      // Records should be bound as l-values because IR generation\n      // always keeps them in memory.  Expressions of function type\n      // act exactly like l-values but are formally required to be\n      // r-values in C.\n      return expr->isGLValue() ||\n             expr->getType()->isFunctionType() ||\n             hasAggregateEvaluationKind(expr->getType());\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const Expr *e) {\n      if (shouldBindAsLValue(ov))\n        return bind(CGF, ov, CGF.EmitLValue(e));\n      return bind(CGF, ov, CGF.EmitAnyExpr(e));\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const LValue &lv) {\n      assert(shouldBindAsLValue(ov));\n      CGF.OpaqueLValues.insert(std::make_pair(ov, lv));\n      return OpaqueValueMappingData(ov, true);\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const RValue &rv) {\n      assert(!shouldBindAsLValue(ov));\n      CGF.OpaqueRValues.insert(std::make_pair(ov, rv));\n\n      OpaqueValueMappingData data(ov, false);\n\n      // Work around an extremely aggressive peephole optimization in\n      // EmitScalarConversion which assumes that all other uses of a\n      // value are extant.\n      data.Protection = CGF.protectFromPeepholes(rv);\n\n      return data;\n    }\n\n    bool isValid() const { return OpaqueValue != nullptr; }\n    void clear() { OpaqueValue = nullptr; }\n\n    void unbind(CodeGenFunction &CGF) {\n      assert(OpaqueValue && \"no data to unbind!\");\n\n      if (BoundLValue) {\n        CGF.OpaqueLValues.erase(OpaqueValue);\n      } else {\n        CGF.OpaqueRValues.erase(OpaqueValue);\n        CGF.unprotectFromPeepholes(Protection);\n      }\n    }\n  };\n\n  /// An RAII object to set (and then clear) a mapping for an OpaqueValueExpr.\n  class OpaqueValueMapping {\n    CodeGenFunction &CGF;\n    OpaqueValueMappingData Data;\n\n  public:\n    static bool shouldBindAsLValue(const Expr *expr) {\n      return OpaqueValueMappingData::shouldBindAsLValue(expr);\n    }\n\n    /// Build the opaque value mapping for the given conditional\n    /// operator if it's the GNU ?: extension.  This is a common\n    /// enough pattern that the convenience operator is really\n    /// helpful.\n    ///\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const AbstractConditionalOperator *op) : CGF(CGF) {\n      if (isa<ConditionalOperator>(op))\n        // Leave Data empty.\n        return;\n\n      const BinaryConditionalOperator *e = cast<BinaryConditionalOperator>(op);\n      Data = OpaqueValueMappingData::bind(CGF, e->getOpaqueValue(),\n                                          e->getCommon());\n    }\n\n    /// Build the opaque value mapping for an OpaqueValueExpr whose source\n    /// expression is set to the expression the OVE represents.\n    OpaqueValueMapping(CodeGenFunction &CGF, const OpaqueValueExpr *OV)\n        : CGF(CGF) {\n      if (OV) {\n        assert(OV->getSourceExpr() && \"wrong form of OpaqueValueMapping used \"\n                                      \"for OVE with no source expression\");\n        Data = OpaqueValueMappingData::bind(CGF, OV, OV->getSourceExpr());\n      }\n    }\n\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const OpaqueValueExpr *opaqueValue,\n                       LValue lvalue)\n      : CGF(CGF), Data(OpaqueValueMappingData::bind(CGF, opaqueValue, lvalue)) {\n    }\n\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const OpaqueValueExpr *opaqueValue,\n                       RValue rvalue)\n      : CGF(CGF), Data(OpaqueValueMappingData::bind(CGF, opaqueValue, rvalue)) {\n    }\n\n    void pop() {\n      Data.unbind(CGF);\n      Data.clear();\n    }\n\n    ~OpaqueValueMapping() {\n      if (Data.isValid()) Data.unbind(CGF);\n    }\n  };\n\nprivate:\n  CGDebugInfo *DebugInfo;\n  /// Used to create unique names for artificial VLA size debug info variables.\n  unsigned VLAExprCounter = 0;\n  bool DisableDebugInfo = false;\n\n  /// DidCallStackSave - Whether llvm.stacksave has been called. Used to avoid\n  /// calling llvm.stacksave for multiple VLAs in the same scope.\n  bool DidCallStackSave = false;\n\n  /// IndirectBranch - The first time an indirect goto is seen we create a block\n  /// with an indirect branch.  Every time we see the address of a label taken,\n  /// we add the label to the indirect goto.  Every subsequent indirect goto is\n  /// codegen'd as a jump to the IndirectBranch's basic block.\n  llvm::IndirectBrInst *IndirectBranch = nullptr;\n\n  /// LocalDeclMap - This keeps track of the LLVM allocas or globals for local C\n  /// decls.\n  DeclMapTy LocalDeclMap;\n\n  // Keep track of the cleanups for callee-destructed parameters pushed to the\n  // cleanup stack so that they can be deactivated later.\n  llvm::DenseMap<const ParmVarDecl *, EHScopeStack::stable_iterator>\n      CalleeDestructedParamCleanups;\n\n  /// SizeArguments - If a ParmVarDecl had the pass_object_size attribute, this\n  /// will contain a mapping from said ParmVarDecl to its implicit \"object_size\"\n  /// parameter.\n  llvm::SmallDenseMap<const ParmVarDecl *, const ImplicitParamDecl *, 2>\n      SizeArguments;\n\n  /// Track escaped local variables with auto storage. Used during SEH\n  /// outlining to produce a call to llvm.localescape.\n  llvm::DenseMap<llvm::AllocaInst *, int> EscapedLocals;\n\n  /// LabelMap - This keeps track of the LLVM basic block for each C label.\n  llvm::DenseMap<const LabelDecl*, JumpDest> LabelMap;\n\n  // BreakContinueStack - This keeps track of where break and continue\n  // statements should jump to.\n  struct BreakContinue {\n    BreakContinue(JumpDest Break, JumpDest Continue)\n      : BreakBlock(Break), ContinueBlock(Continue) {}\n\n    JumpDest BreakBlock;\n    JumpDest ContinueBlock;\n  };\n  SmallVector<BreakContinue, 8> BreakContinueStack;\n\n  /// Handles cancellation exit points in OpenMP-related constructs.\n  class OpenMPCancelExitStack {\n    /// Tracks cancellation exit point and join point for cancel-related exit\n    /// and normal exit.\n    struct CancelExit {\n      CancelExit() = default;\n      CancelExit(OpenMPDirectiveKind Kind, JumpDest ExitBlock,\n                 JumpDest ContBlock)\n          : Kind(Kind), ExitBlock(ExitBlock), ContBlock(ContBlock) {}\n      OpenMPDirectiveKind Kind = llvm::omp::OMPD_unknown;\n      /// true if the exit block has been emitted already by the special\n      /// emitExit() call, false if the default codegen is used.\n      bool HasBeenEmitted = false;\n      JumpDest ExitBlock;\n      JumpDest ContBlock;\n    };\n\n    SmallVector<CancelExit, 8> Stack;\n\n  public:\n    OpenMPCancelExitStack() : Stack(1) {}\n    ~OpenMPCancelExitStack() = default;\n    /// Fetches the exit block for the current OpenMP construct.\n    JumpDest getExitBlock() const { return Stack.back().ExitBlock; }\n    /// Emits exit block with special codegen procedure specific for the related\n    /// OpenMP construct + emits code for normal construct cleanup.\n    void emitExit(CodeGenFunction &CGF, OpenMPDirectiveKind Kind,\n                  const llvm::function_ref<void(CodeGenFunction &)> CodeGen) {\n      if (Stack.back().Kind == Kind && getExitBlock().isValid()) {\n        assert(CGF.getOMPCancelDestination(Kind).isValid());\n        assert(CGF.HaveInsertPoint());\n        assert(!Stack.back().HasBeenEmitted);\n        auto IP = CGF.Builder.saveAndClearIP();\n        CGF.EmitBlock(Stack.back().ExitBlock.getBlock());\n        CodeGen(CGF);\n        CGF.EmitBranch(Stack.back().ContBlock.getBlock());\n        CGF.Builder.restoreIP(IP);\n        Stack.back().HasBeenEmitted = true;\n      }\n      CodeGen(CGF);\n    }\n    /// Enter the cancel supporting \\a Kind construct.\n    /// \\param Kind OpenMP directive that supports cancel constructs.\n    /// \\param HasCancel true, if the construct has inner cancel directive,\n    /// false otherwise.\n    void enter(CodeGenFunction &CGF, OpenMPDirectiveKind Kind, bool HasCancel) {\n      Stack.push_back({Kind,\n                       HasCancel ? CGF.getJumpDestInCurrentScope(\"cancel.exit\")\n                                 : JumpDest(),\n                       HasCancel ? CGF.getJumpDestInCurrentScope(\"cancel.cont\")\n                                 : JumpDest()});\n    }\n    /// Emits default exit point for the cancel construct (if the special one\n    /// has not be used) + join point for cancel/normal exits.\n    void exit(CodeGenFunction &CGF) {\n      if (getExitBlock().isValid()) {\n        assert(CGF.getOMPCancelDestination(Stack.back().Kind).isValid());\n        bool HaveIP = CGF.HaveInsertPoint();\n        if (!Stack.back().HasBeenEmitted) {\n          if (HaveIP)\n            CGF.EmitBranchThroughCleanup(Stack.back().ContBlock);\n          CGF.EmitBlock(Stack.back().ExitBlock.getBlock());\n          CGF.EmitBranchThroughCleanup(Stack.back().ContBlock);\n        }\n        CGF.EmitBlock(Stack.back().ContBlock.getBlock());\n        if (!HaveIP) {\n          CGF.Builder.CreateUnreachable();\n          CGF.Builder.ClearInsertionPoint();\n        }\n      }\n      Stack.pop_back();\n    }\n  };\n  OpenMPCancelExitStack OMPCancelStack;\n\n  /// Calculate branch weights for the likelihood attribute\n  llvm::MDNode *createBranchWeights(Stmt::Likelihood LH) const;\n\n  CodeGenPGO PGO;\n\n  /// Calculate branch weights appropriate for PGO data\n  llvm::MDNode *createProfileWeights(uint64_t TrueCount,\n                                     uint64_t FalseCount) const;\n  llvm::MDNode *createProfileWeights(ArrayRef<uint64_t> Weights) const;\n  llvm::MDNode *createProfileWeightsForLoop(const Stmt *Cond,\n                                            uint64_t LoopCount) const;\n\n  /// Calculate the branch weight for PGO data or the likelihood attribute.\n  /// The function tries to get the weight of \\ref createProfileWeightsForLoop.\n  /// If that fails it gets the weight of \\ref createBranchWeights.\n  llvm::MDNode *createProfileOrBranchWeightsForLoop(const Stmt *Cond,\n                                                    uint64_t LoopCount,\n                                                    const Stmt *Body) const;\n\npublic:\n  /// Increment the profiler's counter for the given statement by \\p StepV.\n  /// If \\p StepV is null, the default increment is 1.\n  void incrementProfileCounter(const Stmt *S, llvm::Value *StepV = nullptr) {\n    if (CGM.getCodeGenOpts().hasProfileClangInstr() &&\n        !CurFn->hasFnAttribute(llvm::Attribute::NoProfile))\n      PGO.emitCounterIncrement(Builder, S, StepV);\n    PGO.setCurrentStmt(S);\n  }\n\n  /// Get the profiler's count for the given statement.\n  uint64_t getProfileCount(const Stmt *S) {\n    Optional<uint64_t> Count = PGO.getStmtCount(S);\n    if (!Count.hasValue())\n      return 0;\n    return *Count;\n  }\n\n  /// Set the profiler's current count.\n  void setCurrentProfileCount(uint64_t Count) {\n    PGO.setCurrentRegionCount(Count);\n  }\n\n  /// Get the profiler's current count. This is generally the count for the most\n  /// recently incremented counter.\n  uint64_t getCurrentProfileCount() {\n    return PGO.getCurrentRegionCount();\n  }\n\nprivate:\n\n  /// SwitchInsn - This is nearest current switch instruction. It is null if\n  /// current context is not in a switch.\n  llvm::SwitchInst *SwitchInsn = nullptr;\n  /// The branch weights of SwitchInsn when doing instrumentation based PGO.\n  SmallVector<uint64_t, 16> *SwitchWeights = nullptr;\n\n  /// The likelihood attributes of the SwitchCase.\n  SmallVector<Stmt::Likelihood, 16> *SwitchLikelihood = nullptr;\n\n  /// CaseRangeBlock - This block holds if condition check for last case\n  /// statement range in current switch instruction.\n  llvm::BasicBlock *CaseRangeBlock = nullptr;\n\n  /// OpaqueLValues - Keeps track of the current set of opaque value\n  /// expressions.\n  llvm::DenseMap<const OpaqueValueExpr *, LValue> OpaqueLValues;\n  llvm::DenseMap<const OpaqueValueExpr *, RValue> OpaqueRValues;\n\n  // VLASizeMap - This keeps track of the associated size for each VLA type.\n  // We track this by the size expression rather than the type itself because\n  // in certain situations, like a const qualifier applied to an VLA typedef,\n  // multiple VLA types can share the same size expression.\n  // FIXME: Maybe this could be a stack of maps that is pushed/popped as we\n  // enter/leave scopes.\n  llvm::DenseMap<const Expr*, llvm::Value*> VLASizeMap;\n\n  /// A block containing a single 'unreachable' instruction.  Created\n  /// lazily by getUnreachableBlock().\n  llvm::BasicBlock *UnreachableBlock = nullptr;\n\n  /// Counts of the number return expressions in the function.\n  unsigned NumReturnExprs = 0;\n\n  /// Count the number of simple (constant) return expressions in the function.\n  unsigned NumSimpleReturnExprs = 0;\n\n  /// The last regular (non-return) debug location (breakpoint) in the function.\n  SourceLocation LastStopPoint;\n\npublic:\n  /// Source location information about the default argument or member\n  /// initializer expression we're evaluating, if any.\n  CurrentSourceLocExprScope CurSourceLocExprScope;\n  using SourceLocExprScopeGuard =\n      CurrentSourceLocExprScope::SourceLocExprScopeGuard;\n\n  /// A scope within which we are constructing the fields of an object which\n  /// might use a CXXDefaultInitExpr. This stashes away a 'this' value to use\n  /// if we need to evaluate a CXXDefaultInitExpr within the evaluation.\n  class FieldConstructionScope {\n  public:\n    FieldConstructionScope(CodeGenFunction &CGF, Address This)\n        : CGF(CGF), OldCXXDefaultInitExprThis(CGF.CXXDefaultInitExprThis) {\n      CGF.CXXDefaultInitExprThis = This;\n    }\n    ~FieldConstructionScope() {\n      CGF.CXXDefaultInitExprThis = OldCXXDefaultInitExprThis;\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    Address OldCXXDefaultInitExprThis;\n  };\n\n  /// The scope of a CXXDefaultInitExpr. Within this scope, the value of 'this'\n  /// is overridden to be the object under construction.\n  class CXXDefaultInitExprScope  {\n  public:\n    CXXDefaultInitExprScope(CodeGenFunction &CGF, const CXXDefaultInitExpr *E)\n        : CGF(CGF), OldCXXThisValue(CGF.CXXThisValue),\n          OldCXXThisAlignment(CGF.CXXThisAlignment),\n          SourceLocScope(E, CGF.CurSourceLocExprScope) {\n      CGF.CXXThisValue = CGF.CXXDefaultInitExprThis.getPointer();\n      CGF.CXXThisAlignment = CGF.CXXDefaultInitExprThis.getAlignment();\n    }\n    ~CXXDefaultInitExprScope() {\n      CGF.CXXThisValue = OldCXXThisValue;\n      CGF.CXXThisAlignment = OldCXXThisAlignment;\n    }\n\n  public:\n    CodeGenFunction &CGF;\n    llvm::Value *OldCXXThisValue;\n    CharUnits OldCXXThisAlignment;\n    SourceLocExprScopeGuard SourceLocScope;\n  };\n\n  struct CXXDefaultArgExprScope : SourceLocExprScopeGuard {\n    CXXDefaultArgExprScope(CodeGenFunction &CGF, const CXXDefaultArgExpr *E)\n        : SourceLocExprScopeGuard(E, CGF.CurSourceLocExprScope) {}\n  };\n\n  /// The scope of an ArrayInitLoopExpr. Within this scope, the value of the\n  /// current loop index is overridden.\n  class ArrayInitLoopExprScope {\n  public:\n    ArrayInitLoopExprScope(CodeGenFunction &CGF, llvm::Value *Index)\n      : CGF(CGF), OldArrayInitIndex(CGF.ArrayInitIndex) {\n      CGF.ArrayInitIndex = Index;\n    }\n    ~ArrayInitLoopExprScope() {\n      CGF.ArrayInitIndex = OldArrayInitIndex;\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    llvm::Value *OldArrayInitIndex;\n  };\n\n  class InlinedInheritingConstructorScope {\n  public:\n    InlinedInheritingConstructorScope(CodeGenFunction &CGF, GlobalDecl GD)\n        : CGF(CGF), OldCurGD(CGF.CurGD), OldCurFuncDecl(CGF.CurFuncDecl),\n          OldCurCodeDecl(CGF.CurCodeDecl),\n          OldCXXABIThisDecl(CGF.CXXABIThisDecl),\n          OldCXXABIThisValue(CGF.CXXABIThisValue),\n          OldCXXThisValue(CGF.CXXThisValue),\n          OldCXXABIThisAlignment(CGF.CXXABIThisAlignment),\n          OldCXXThisAlignment(CGF.CXXThisAlignment),\n          OldReturnValue(CGF.ReturnValue), OldFnRetTy(CGF.FnRetTy),\n          OldCXXInheritedCtorInitExprArgs(\n              std::move(CGF.CXXInheritedCtorInitExprArgs)) {\n      CGF.CurGD = GD;\n      CGF.CurFuncDecl = CGF.CurCodeDecl =\n          cast<CXXConstructorDecl>(GD.getDecl());\n      CGF.CXXABIThisDecl = nullptr;\n      CGF.CXXABIThisValue = nullptr;\n      CGF.CXXThisValue = nullptr;\n      CGF.CXXABIThisAlignment = CharUnits();\n      CGF.CXXThisAlignment = CharUnits();\n      CGF.ReturnValue = Address::invalid();\n      CGF.FnRetTy = QualType();\n      CGF.CXXInheritedCtorInitExprArgs.clear();\n    }\n    ~InlinedInheritingConstructorScope() {\n      CGF.CurGD = OldCurGD;\n      CGF.CurFuncDecl = OldCurFuncDecl;\n      CGF.CurCodeDecl = OldCurCodeDecl;\n      CGF.CXXABIThisDecl = OldCXXABIThisDecl;\n      CGF.CXXABIThisValue = OldCXXABIThisValue;\n      CGF.CXXThisValue = OldCXXThisValue;\n      CGF.CXXABIThisAlignment = OldCXXABIThisAlignment;\n      CGF.CXXThisAlignment = OldCXXThisAlignment;\n      CGF.ReturnValue = OldReturnValue;\n      CGF.FnRetTy = OldFnRetTy;\n      CGF.CXXInheritedCtorInitExprArgs =\n          std::move(OldCXXInheritedCtorInitExprArgs);\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    GlobalDecl OldCurGD;\n    const Decl *OldCurFuncDecl;\n    const Decl *OldCurCodeDecl;\n    ImplicitParamDecl *OldCXXABIThisDecl;\n    llvm::Value *OldCXXABIThisValue;\n    llvm::Value *OldCXXThisValue;\n    CharUnits OldCXXABIThisAlignment;\n    CharUnits OldCXXThisAlignment;\n    Address OldReturnValue;\n    QualType OldFnRetTy;\n    CallArgList OldCXXInheritedCtorInitExprArgs;\n  };\n\n  // Helper class for the OpenMP IR Builder. Allows reusability of code used for\n  // region body, and finalization codegen callbacks. This will class will also\n  // contain privatization functions used by the privatization call backs\n  //\n  // TODO: this is temporary class for things that are being moved out of\n  // CGOpenMPRuntime, new versions of current CodeGenFunction methods, or\n  // utility function for use with the OMPBuilder. Once that move to use the\n  // OMPBuilder is done, everything here will either become part of CodeGenFunc.\n  // directly, or a new helper class that will contain functions used by both\n  // this and the OMPBuilder\n\n  struct OMPBuilderCBHelpers {\n\n    OMPBuilderCBHelpers() = delete;\n    OMPBuilderCBHelpers(const OMPBuilderCBHelpers &) = delete;\n    OMPBuilderCBHelpers &operator=(const OMPBuilderCBHelpers &) = delete;\n\n    using InsertPointTy = llvm::OpenMPIRBuilder::InsertPointTy;\n\n    /// Cleanup action for allocate support.\n    class OMPAllocateCleanupTy final : public EHScopeStack::Cleanup {\n\n    private:\n      llvm::CallInst *RTLFnCI;\n\n    public:\n      OMPAllocateCleanupTy(llvm::CallInst *RLFnCI) : RTLFnCI(RLFnCI) {\n        RLFnCI->removeFromParent();\n      }\n\n      void Emit(CodeGenFunction &CGF, Flags /*flags*/) override {\n        if (!CGF.HaveInsertPoint())\n          return;\n        CGF.Builder.Insert(RTLFnCI);\n      }\n    };\n\n    /// Returns address of the threadprivate variable for the current\n    /// thread. This Also create any necessary OMP runtime calls.\n    ///\n    /// \\param VD VarDecl for Threadprivate variable.\n    /// \\param VDAddr Address of the Vardecl\n    /// \\param Loc  The location where the barrier directive was encountered\n    static Address getAddrOfThreadPrivate(CodeGenFunction &CGF,\n                                          const VarDecl *VD, Address VDAddr,\n                                          SourceLocation Loc);\n\n    /// Gets the OpenMP-specific address of the local variable /p VD.\n    static Address getAddressOfLocalVariable(CodeGenFunction &CGF,\n                                             const VarDecl *VD);\n    /// Get the platform-specific name separator.\n    /// \\param Parts different parts of the final name that needs separation\n    /// \\param FirstSeparator First separator used between the initial two\n    ///        parts of the name.\n    /// \\param Separator separator used between all of the rest consecutinve\n    ///        parts of the name\n    static std::string getNameWithSeparators(ArrayRef<StringRef> Parts,\n                                             StringRef FirstSeparator = \".\",\n                                             StringRef Separator = \".\");\n    /// Emit the Finalization for an OMP region\n    /// \\param CGF\tThe Codegen function this belongs to\n    /// \\param IP\tInsertion point for generating the finalization code.\n    static void FinalizeOMPRegion(CodeGenFunction &CGF, InsertPointTy IP) {\n      CGBuilderTy::InsertPointGuard IPG(CGF.Builder);\n      assert(IP.getBlock()->end() != IP.getPoint() &&\n             \"OpenMP IR Builder should cause terminated block!\");\n\n      llvm::BasicBlock *IPBB = IP.getBlock();\n      llvm::BasicBlock *DestBB = IPBB->getUniqueSuccessor();\n      assert(DestBB && \"Finalization block should have one successor!\");\n\n      // erase and replace with cleanup branch.\n      IPBB->getTerminator()->eraseFromParent();\n      CGF.Builder.SetInsertPoint(IPBB);\n      CodeGenFunction::JumpDest Dest = CGF.getJumpDestInCurrentScope(DestBB);\n      CGF.EmitBranchThroughCleanup(Dest);\n    }\n\n    /// Emit the body of an OMP region\n    /// \\param CGF\tThe Codegen function this belongs to\n    /// \\param RegionBodyStmt\tThe body statement for the OpenMP region being\n    /// \t\t\t generated\n    /// \\param CodeGenIP\tInsertion point for generating the body code.\n    /// \\param FiniBB\tThe finalization basic block\n    static void EmitOMPRegionBody(CodeGenFunction &CGF,\n                                  const Stmt *RegionBodyStmt,\n                                  InsertPointTy CodeGenIP,\n                                  llvm::BasicBlock &FiniBB) {\n      llvm::BasicBlock *CodeGenIPBB = CodeGenIP.getBlock();\n      if (llvm::Instruction *CodeGenIPBBTI = CodeGenIPBB->getTerminator())\n        CodeGenIPBBTI->eraseFromParent();\n\n      CGF.Builder.SetInsertPoint(CodeGenIPBB);\n\n      CGF.EmitStmt(RegionBodyStmt);\n\n      if (CGF.Builder.saveIP().isSet())\n        CGF.Builder.CreateBr(&FiniBB);\n    }\n\n    /// RAII for preserving necessary info during Outlined region body codegen.\n    class OutlinedRegionBodyRAII {\n\n      llvm::AssertingVH<llvm::Instruction> OldAllocaIP;\n      CodeGenFunction::JumpDest OldReturnBlock;\n      CGBuilderTy::InsertPoint IP;\n      CodeGenFunction &CGF;\n\n    public:\n      OutlinedRegionBodyRAII(CodeGenFunction &cgf, InsertPointTy &AllocaIP,\n                             llvm::BasicBlock &RetBB)\n          : CGF(cgf) {\n        assert(AllocaIP.isSet() &&\n               \"Must specify Insertion point for allocas of outlined function\");\n        OldAllocaIP = CGF.AllocaInsertPt;\n        CGF.AllocaInsertPt = &*AllocaIP.getPoint();\n        IP = CGF.Builder.saveIP();\n\n        OldReturnBlock = CGF.ReturnBlock;\n        CGF.ReturnBlock = CGF.getJumpDestInCurrentScope(&RetBB);\n      }\n\n      ~OutlinedRegionBodyRAII() {\n        CGF.AllocaInsertPt = OldAllocaIP;\n        CGF.ReturnBlock = OldReturnBlock;\n        CGF.Builder.restoreIP(IP);\n      }\n    };\n\n    /// RAII for preserving necessary info during inlined region body codegen.\n    class InlinedRegionBodyRAII {\n\n      llvm::AssertingVH<llvm::Instruction> OldAllocaIP;\n      CodeGenFunction &CGF;\n\n    public:\n      InlinedRegionBodyRAII(CodeGenFunction &cgf, InsertPointTy &AllocaIP,\n                            llvm::BasicBlock &FiniBB)\n          : CGF(cgf) {\n        // Alloca insertion block should be in the entry block of the containing\n        // function so it expects an empty AllocaIP in which case will reuse the\n        // old alloca insertion point, or a new AllocaIP in the same block as\n        // the old one\n        assert((!AllocaIP.isSet() ||\n                CGF.AllocaInsertPt->getParent() == AllocaIP.getBlock()) &&\n               \"Insertion point should be in the entry block of containing \"\n               \"function!\");\n        OldAllocaIP = CGF.AllocaInsertPt;\n        if (AllocaIP.isSet())\n          CGF.AllocaInsertPt = &*AllocaIP.getPoint();\n\n        // TODO: Remove the call, after making sure the counter is not used by\n        //       the EHStack.\n        // Since this is an inlined region, it should not modify the\n        // ReturnBlock, and should reuse the one for the enclosing outlined\n        // region. So, the JumpDest being return by the function is discarded\n        (void)CGF.getJumpDestInCurrentScope(&FiniBB);\n      }\n\n      ~InlinedRegionBodyRAII() { CGF.AllocaInsertPt = OldAllocaIP; }\n    };\n  };\n\nprivate:\n  /// CXXThisDecl - When generating code for a C++ member function,\n  /// this will hold the implicit 'this' declaration.\n  ImplicitParamDecl *CXXABIThisDecl = nullptr;\n  llvm::Value *CXXABIThisValue = nullptr;\n  llvm::Value *CXXThisValue = nullptr;\n  CharUnits CXXABIThisAlignment;\n  CharUnits CXXThisAlignment;\n\n  /// The value of 'this' to use when evaluating CXXDefaultInitExprs within\n  /// this expression.\n  Address CXXDefaultInitExprThis = Address::invalid();\n\n  /// The current array initialization index when evaluating an\n  /// ArrayInitIndexExpr within an ArrayInitLoopExpr.\n  llvm::Value *ArrayInitIndex = nullptr;\n\n  /// The values of function arguments to use when evaluating\n  /// CXXInheritedCtorInitExprs within this context.\n  CallArgList CXXInheritedCtorInitExprArgs;\n\n  /// CXXStructorImplicitParamDecl - When generating code for a constructor or\n  /// destructor, this will hold the implicit argument (e.g. VTT).\n  ImplicitParamDecl *CXXStructorImplicitParamDecl = nullptr;\n  llvm::Value *CXXStructorImplicitParamValue = nullptr;\n\n  /// OutermostConditional - Points to the outermost active\n  /// conditional control.  This is used so that we know if a\n  /// temporary should be destroyed conditionally.\n  ConditionalEvaluation *OutermostConditional = nullptr;\n\n  /// The current lexical scope.\n  LexicalScope *CurLexicalScope = nullptr;\n\n  /// The current source location that should be used for exception\n  /// handling code.\n  SourceLocation CurEHLocation;\n\n  /// BlockByrefInfos - For each __block variable, contains\n  /// information about the layout of the variable.\n  llvm::DenseMap<const ValueDecl *, BlockByrefInfo> BlockByrefInfos;\n\n  /// Used by -fsanitize=nullability-return to determine whether the return\n  /// value can be checked.\n  llvm::Value *RetValNullabilityPrecondition = nullptr;\n\n  /// Check if -fsanitize=nullability-return instrumentation is required for\n  /// this function.\n  bool requiresReturnValueNullabilityCheck() const {\n    return RetValNullabilityPrecondition;\n  }\n\n  /// Used to store precise source locations for return statements by the\n  /// runtime return value checks.\n  Address ReturnLocation = Address::invalid();\n\n  /// Check if the return value of this function requires sanitization.\n  bool requiresReturnValueCheck() const;\n\n  llvm::BasicBlock *TerminateLandingPad = nullptr;\n  llvm::BasicBlock *TerminateHandler = nullptr;\n  llvm::SmallVector<llvm::BasicBlock *, 2> TrapBBs;\n\n  /// Terminate funclets keyed by parent funclet pad.\n  llvm::MapVector<llvm::Value *, llvm::BasicBlock *> TerminateFunclets;\n\n  /// Largest vector width used in ths function. Will be used to create a\n  /// function attribute.\n  unsigned LargestVectorWidth = 0;\n\n  /// True if we need emit the life-time markers.\n  const bool ShouldEmitLifetimeMarkers;\n\n  /// Add OpenCL kernel arg metadata and the kernel attribute metadata to\n  /// the function metadata.\n  void EmitOpenCLKernelMetadata(const FunctionDecl *FD,\n                                llvm::Function *Fn);\n\npublic:\n  CodeGenFunction(CodeGenModule &cgm, bool suppressNewContext=false);\n  ~CodeGenFunction();\n\n  CodeGenTypes &getTypes() const { return CGM.getTypes(); }\n  ASTContext &getContext() const { return CGM.getContext(); }\n  CGDebugInfo *getDebugInfo() {\n    if (DisableDebugInfo)\n      return nullptr;\n    return DebugInfo;\n  }\n  void disableDebugInfo() { DisableDebugInfo = true; }\n  void enableDebugInfo() { DisableDebugInfo = false; }\n\n  bool shouldUseFusedARCCalls() {\n    return CGM.getCodeGenOpts().OptimizationLevel == 0;\n  }\n\n  const LangOptions &getLangOpts() const { return CGM.getLangOpts(); }\n\n  /// Returns a pointer to the function's exception object and selector slot,\n  /// which is assigned in every landing pad.\n  Address getExceptionSlot();\n  Address getEHSelectorSlot();\n\n  /// Returns the contents of the function's exception object and selector\n  /// slots.\n  llvm::Value *getExceptionFromSlot();\n  llvm::Value *getSelectorFromSlot();\n\n  Address getNormalCleanupDestSlot();\n\n  llvm::BasicBlock *getUnreachableBlock() {\n    if (!UnreachableBlock) {\n      UnreachableBlock = createBasicBlock(\"unreachable\");\n      new llvm::UnreachableInst(getLLVMContext(), UnreachableBlock);\n    }\n    return UnreachableBlock;\n  }\n\n  llvm::BasicBlock *getInvokeDest() {\n    if (!EHStack.requiresLandingPad()) return nullptr;\n    return getInvokeDestImpl();\n  }\n\n  bool currentFunctionUsesSEHTry() const { return CurSEHParent != nullptr; }\n\n  const TargetInfo &getTarget() const { return Target; }\n  llvm::LLVMContext &getLLVMContext() { return CGM.getLLVMContext(); }\n  const TargetCodeGenInfo &getTargetHooks() const {\n    return CGM.getTargetCodeGenInfo();\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                                  Cleanups\n  //===--------------------------------------------------------------------===//\n\n  typedef void Destroyer(CodeGenFunction &CGF, Address addr, QualType ty);\n\n  void pushIrregularPartialArrayCleanup(llvm::Value *arrayBegin,\n                                        Address arrayEndPointer,\n                                        QualType elementType,\n                                        CharUnits elementAlignment,\n                                        Destroyer *destroyer);\n  void pushRegularPartialArrayCleanup(llvm::Value *arrayBegin,\n                                      llvm::Value *arrayEnd,\n                                      QualType elementType,\n                                      CharUnits elementAlignment,\n                                      Destroyer *destroyer);\n\n  void pushDestroy(QualType::DestructionKind dtorKind,\n                   Address addr, QualType type);\n  void pushEHDestroy(QualType::DestructionKind dtorKind,\n                     Address addr, QualType type);\n  void pushDestroy(CleanupKind kind, Address addr, QualType type,\n                   Destroyer *destroyer, bool useEHCleanupForArray);\n  void pushLifetimeExtendedDestroy(CleanupKind kind, Address addr,\n                                   QualType type, Destroyer *destroyer,\n                                   bool useEHCleanupForArray);\n  void pushCallObjectDeleteCleanup(const FunctionDecl *OperatorDelete,\n                                   llvm::Value *CompletePtr,\n                                   QualType ElementType);\n  void pushStackRestore(CleanupKind kind, Address SPMem);\n  void emitDestroy(Address addr, QualType type, Destroyer *destroyer,\n                   bool useEHCleanupForArray);\n  llvm::Function *generateDestroyHelper(Address addr, QualType type,\n                                        Destroyer *destroyer,\n                                        bool useEHCleanupForArray,\n                                        const VarDecl *VD);\n  void emitArrayDestroy(llvm::Value *begin, llvm::Value *end,\n                        QualType elementType, CharUnits elementAlign,\n                        Destroyer *destroyer,\n                        bool checkZeroLength, bool useEHCleanup);\n\n  Destroyer *getDestroyer(QualType::DestructionKind destructionKind);\n\n  /// Determines whether an EH cleanup is required to destroy a type\n  /// with the given destruction kind.\n  bool needsEHCleanup(QualType::DestructionKind kind) {\n    switch (kind) {\n    case QualType::DK_none:\n      return false;\n    case QualType::DK_cxx_destructor:\n    case QualType::DK_objc_weak_lifetime:\n    case QualType::DK_nontrivial_c_struct:\n      return getLangOpts().Exceptions;\n    case QualType::DK_objc_strong_lifetime:\n      return getLangOpts().Exceptions &&\n             CGM.getCodeGenOpts().ObjCAutoRefCountExceptions;\n    }\n    llvm_unreachable(\"bad destruction kind\");\n  }\n\n  CleanupKind getCleanupKind(QualType::DestructionKind kind) {\n    return (needsEHCleanup(kind) ? NormalAndEHCleanup : NormalCleanup);\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                                  Objective-C\n  //===--------------------------------------------------------------------===//\n\n  void GenerateObjCMethod(const ObjCMethodDecl *OMD);\n\n  void StartObjCMethod(const ObjCMethodDecl *MD, const ObjCContainerDecl *CD);\n\n  /// GenerateObjCGetter - Synthesize an Objective-C property getter function.\n  void GenerateObjCGetter(ObjCImplementationDecl *IMP,\n                          const ObjCPropertyImplDecl *PID);\n  void generateObjCGetterBody(const ObjCImplementationDecl *classImpl,\n                              const ObjCPropertyImplDecl *propImpl,\n                              const ObjCMethodDecl *GetterMothodDecl,\n                              llvm::Constant *AtomicHelperFn);\n\n  void GenerateObjCCtorDtorMethod(ObjCImplementationDecl *IMP,\n                                  ObjCMethodDecl *MD, bool ctor);\n\n  /// GenerateObjCSetter - Synthesize an Objective-C property setter function\n  /// for the given property.\n  void GenerateObjCSetter(ObjCImplementationDecl *IMP,\n                          const ObjCPropertyImplDecl *PID);\n  void generateObjCSetterBody(const ObjCImplementationDecl *classImpl,\n                              const ObjCPropertyImplDecl *propImpl,\n                              llvm::Constant *AtomicHelperFn);\n\n  //===--------------------------------------------------------------------===//\n  //                                  Block Bits\n  //===--------------------------------------------------------------------===//\n\n  /// Emit block literal.\n  /// \\return an LLVM value which is a pointer to a struct which contains\n  /// information about the block, including the block invoke function, the\n  /// captured variables, etc.\n  llvm::Value *EmitBlockLiteral(const BlockExpr *);\n\n  llvm::Function *GenerateBlockFunction(GlobalDecl GD,\n                                        const CGBlockInfo &Info,\n                                        const DeclMapTy &ldm,\n                                        bool IsLambdaConversionToBlock,\n                                        bool BuildGlobalBlock);\n\n  /// Check if \\p T is a C++ class that has a destructor that can throw.\n  static bool cxxDestructorCanThrow(QualType T);\n\n  llvm::Constant *GenerateCopyHelperFunction(const CGBlockInfo &blockInfo);\n  llvm::Constant *GenerateDestroyHelperFunction(const CGBlockInfo &blockInfo);\n  llvm::Constant *GenerateObjCAtomicSetterCopyHelperFunction(\n                                             const ObjCPropertyImplDecl *PID);\n  llvm::Constant *GenerateObjCAtomicGetterCopyHelperFunction(\n                                             const ObjCPropertyImplDecl *PID);\n  llvm::Value *EmitBlockCopyAndAutorelease(llvm::Value *Block, QualType Ty);\n\n  void BuildBlockRelease(llvm::Value *DeclPtr, BlockFieldFlags flags,\n                         bool CanThrow);\n\n  class AutoVarEmission;\n\n  void emitByrefStructureInit(const AutoVarEmission &emission);\n\n  /// Enter a cleanup to destroy a __block variable.  Note that this\n  /// cleanup should be a no-op if the variable hasn't left the stack\n  /// yet; if a cleanup is required for the variable itself, that needs\n  /// to be done externally.\n  ///\n  /// \\param Kind Cleanup kind.\n  ///\n  /// \\param Addr When \\p LoadBlockVarAddr is false, the address of the __block\n  /// structure that will be passed to _Block_object_dispose. When\n  /// \\p LoadBlockVarAddr is true, the address of the field of the block\n  /// structure that holds the address of the __block structure.\n  ///\n  /// \\param Flags The flag that will be passed to _Block_object_dispose.\n  ///\n  /// \\param LoadBlockVarAddr Indicates whether we need to emit a load from\n  /// \\p Addr to get the address of the __block structure.\n  void enterByrefCleanup(CleanupKind Kind, Address Addr, BlockFieldFlags Flags,\n                         bool LoadBlockVarAddr, bool CanThrow);\n\n  void setBlockContextParameter(const ImplicitParamDecl *D, unsigned argNum,\n                                llvm::Value *ptr);\n\n  Address LoadBlockStruct();\n  Address GetAddrOfBlockDecl(const VarDecl *var);\n\n  /// BuildBlockByrefAddress - Computes the location of the\n  /// data in a variable which is declared as __block.\n  Address emitBlockByrefAddress(Address baseAddr, const VarDecl *V,\n                                bool followForward = true);\n  Address emitBlockByrefAddress(Address baseAddr,\n                                const BlockByrefInfo &info,\n                                bool followForward,\n                                const llvm::Twine &name);\n\n  const BlockByrefInfo &getBlockByrefInfo(const VarDecl *var);\n\n  QualType BuildFunctionArgList(GlobalDecl GD, FunctionArgList &Args);\n\n  void GenerateCode(GlobalDecl GD, llvm::Function *Fn,\n                    const CGFunctionInfo &FnInfo);\n\n  /// Annotate the function with an attribute that disables TSan checking at\n  /// runtime.\n  void markAsIgnoreThreadCheckingAtRuntime(llvm::Function *Fn);\n\n  /// Emit code for the start of a function.\n  /// \\param Loc       The location to be associated with the function.\n  /// \\param StartLoc  The location of the function body.\n  void StartFunction(GlobalDecl GD,\n                     QualType RetTy,\n                     llvm::Function *Fn,\n                     const CGFunctionInfo &FnInfo,\n                     const FunctionArgList &Args,\n                     SourceLocation Loc = SourceLocation(),\n                     SourceLocation StartLoc = SourceLocation());\n\n  static bool IsConstructorDelegationValid(const CXXConstructorDecl *Ctor);\n\n  void EmitConstructorBody(FunctionArgList &Args);\n  void EmitDestructorBody(FunctionArgList &Args);\n  void emitImplicitAssignmentOperatorBody(FunctionArgList &Args);\n  void EmitFunctionBody(const Stmt *Body);\n  void EmitBlockWithFallThrough(llvm::BasicBlock *BB, const Stmt *S);\n\n  void EmitForwardingCallToLambda(const CXXMethodDecl *LambdaCallOperator,\n                                  CallArgList &CallArgs);\n  void EmitLambdaBlockInvokeBody();\n  void EmitLambdaDelegatingInvokeBody(const CXXMethodDecl *MD);\n  void EmitLambdaStaticInvokeBody(const CXXMethodDecl *MD);\n  void EmitLambdaVLACapture(const VariableArrayType *VAT, LValue LV) {\n    EmitStoreThroughLValue(RValue::get(VLASizeMap[VAT->getSizeExpr()]), LV);\n  }\n  void EmitAsanPrologueOrEpilogue(bool Prologue);\n\n  /// Emit the unified return block, trying to avoid its emission when\n  /// possible.\n  /// \\return The debug location of the user written return statement if the\n  /// return block is is avoided.\n  llvm::DebugLoc EmitReturnBlock();\n\n  /// FinishFunction - Complete IR generation of the current function. It is\n  /// legal to call this function even if there is no current insertion point.\n  void FinishFunction(SourceLocation EndLoc=SourceLocation());\n\n  void StartThunk(llvm::Function *Fn, GlobalDecl GD,\n                  const CGFunctionInfo &FnInfo, bool IsUnprototyped);\n\n  void EmitCallAndReturnForThunk(llvm::FunctionCallee Callee,\n                                 const ThunkInfo *Thunk, bool IsUnprototyped);\n\n  void FinishThunk();\n\n  /// Emit a musttail call for a thunk with a potentially adjusted this pointer.\n  void EmitMustTailThunk(GlobalDecl GD, llvm::Value *AdjustedThisPtr,\n                         llvm::FunctionCallee Callee);\n\n  /// Generate a thunk for the given method.\n  void generateThunk(llvm::Function *Fn, const CGFunctionInfo &FnInfo,\n                     GlobalDecl GD, const ThunkInfo &Thunk,\n                     bool IsUnprototyped);\n\n  llvm::Function *GenerateVarArgsThunk(llvm::Function *Fn,\n                                       const CGFunctionInfo &FnInfo,\n                                       GlobalDecl GD, const ThunkInfo &Thunk);\n\n  void EmitCtorPrologue(const CXXConstructorDecl *CD, CXXCtorType Type,\n                        FunctionArgList &Args);\n\n  void EmitInitializerForField(FieldDecl *Field, LValue LHS, Expr *Init);\n\n  /// Struct with all information about dynamic [sub]class needed to set vptr.\n  struct VPtr {\n    BaseSubobject Base;\n    const CXXRecordDecl *NearestVBase;\n    CharUnits OffsetFromNearestVBase;\n    const CXXRecordDecl *VTableClass;\n  };\n\n  /// Initialize the vtable pointer of the given subobject.\n  void InitializeVTablePointer(const VPtr &vptr);\n\n  typedef llvm::SmallVector<VPtr, 4> VPtrsVector;\n\n  typedef llvm::SmallPtrSet<const CXXRecordDecl *, 4> VisitedVirtualBasesSetTy;\n  VPtrsVector getVTablePointers(const CXXRecordDecl *VTableClass);\n\n  void getVTablePointers(BaseSubobject Base, const CXXRecordDecl *NearestVBase,\n                         CharUnits OffsetFromNearestVBase,\n                         bool BaseIsNonVirtualPrimaryBase,\n                         const CXXRecordDecl *VTableClass,\n                         VisitedVirtualBasesSetTy &VBases, VPtrsVector &vptrs);\n\n  void InitializeVTablePointers(const CXXRecordDecl *ClassDecl);\n\n  /// GetVTablePtr - Return the Value of the vtable pointer member pointed\n  /// to by This.\n  llvm::Value *GetVTablePtr(Address This, llvm::Type *VTableTy,\n                            const CXXRecordDecl *VTableClass);\n\n  enum CFITypeCheckKind {\n    CFITCK_VCall,\n    CFITCK_NVCall,\n    CFITCK_DerivedCast,\n    CFITCK_UnrelatedCast,\n    CFITCK_ICall,\n    CFITCK_NVMFCall,\n    CFITCK_VMFCall,\n  };\n\n  /// Derived is the presumed address of an object of type T after a\n  /// cast. If T is a polymorphic class type, emit a check that the virtual\n  /// table for Derived belongs to a class derived from T.\n  void EmitVTablePtrCheckForCast(QualType T, llvm::Value *Derived,\n                                 bool MayBeNull, CFITypeCheckKind TCK,\n                                 SourceLocation Loc);\n\n  /// EmitVTablePtrCheckForCall - Virtual method MD is being called via VTable.\n  /// If vptr CFI is enabled, emit a check that VTable is valid.\n  void EmitVTablePtrCheckForCall(const CXXRecordDecl *RD, llvm::Value *VTable,\n                                 CFITypeCheckKind TCK, SourceLocation Loc);\n\n  /// EmitVTablePtrCheck - Emit a check that VTable is a valid virtual table for\n  /// RD using llvm.type.test.\n  void EmitVTablePtrCheck(const CXXRecordDecl *RD, llvm::Value *VTable,\n                          CFITypeCheckKind TCK, SourceLocation Loc);\n\n  /// If whole-program virtual table optimization is enabled, emit an assumption\n  /// that VTable is a member of RD's type identifier. Or, if vptr CFI is\n  /// enabled, emit a check that VTable is a member of RD's type identifier.\n  void EmitTypeMetadataCodeForVCall(const CXXRecordDecl *RD,\n                                    llvm::Value *VTable, SourceLocation Loc);\n\n  /// Returns whether we should perform a type checked load when loading a\n  /// virtual function for virtual calls to members of RD. This is generally\n  /// true when both vcall CFI and whole-program-vtables are enabled.\n  bool ShouldEmitVTableTypeCheckedLoad(const CXXRecordDecl *RD);\n\n  /// Emit a type checked load from the given vtable.\n  llvm::Value *EmitVTableTypeCheckedLoad(const CXXRecordDecl *RD, llvm::Value *VTable,\n                                         uint64_t VTableByteOffset);\n\n  /// EnterDtorCleanups - Enter the cleanups necessary to complete the\n  /// given phase of destruction for a destructor.  The end result\n  /// should call destructors on members and base classes in reverse\n  /// order of their construction.\n  void EnterDtorCleanups(const CXXDestructorDecl *Dtor, CXXDtorType Type);\n\n  /// ShouldInstrumentFunction - Return true if the current function should be\n  /// instrumented with __cyg_profile_func_* calls\n  bool ShouldInstrumentFunction();\n\n  /// ShouldXRayInstrument - Return true if the current function should be\n  /// instrumented with XRay nop sleds.\n  bool ShouldXRayInstrumentFunction() const;\n\n  /// AlwaysEmitXRayCustomEvents - Return true if we must unconditionally emit\n  /// XRay custom event handling calls.\n  bool AlwaysEmitXRayCustomEvents() const;\n\n  /// AlwaysEmitXRayTypedEvents - Return true if clang must unconditionally emit\n  /// XRay typed event handling calls.\n  bool AlwaysEmitXRayTypedEvents() const;\n\n  /// Encode an address into a form suitable for use in a function prologue.\n  llvm::Constant *EncodeAddrForUseInPrologue(llvm::Function *F,\n                                             llvm::Constant *Addr);\n\n  /// Decode an address used in a function prologue, encoded by \\c\n  /// EncodeAddrForUseInPrologue.\n  llvm::Value *DecodeAddrUsedInPrologue(llvm::Value *F,\n                                        llvm::Value *EncodedAddr);\n\n  /// EmitFunctionProlog - Emit the target specific LLVM code to load the\n  /// arguments for the given function. This is also responsible for naming the\n  /// LLVM function arguments.\n  void EmitFunctionProlog(const CGFunctionInfo &FI,\n                          llvm::Function *Fn,\n                          const FunctionArgList &Args);\n\n  /// EmitFunctionEpilog - Emit the target specific LLVM code to return the\n  /// given temporary.\n  void EmitFunctionEpilog(const CGFunctionInfo &FI, bool EmitRetDbgLoc,\n                          SourceLocation EndLoc);\n\n  /// Emit a test that checks if the return value \\p RV is nonnull.\n  void EmitReturnValueCheck(llvm::Value *RV);\n\n  /// EmitStartEHSpec - Emit the start of the exception spec.\n  void EmitStartEHSpec(const Decl *D);\n\n  /// EmitEndEHSpec - Emit the end of the exception spec.\n  void EmitEndEHSpec(const Decl *D);\n\n  /// getTerminateLandingPad - Return a landing pad that just calls terminate.\n  llvm::BasicBlock *getTerminateLandingPad();\n\n  /// getTerminateLandingPad - Return a cleanup funclet that just calls\n  /// terminate.\n  llvm::BasicBlock *getTerminateFunclet();\n\n  /// getTerminateHandler - Return a handler (not a landing pad, just\n  /// a catch handler) that just calls terminate.  This is used when\n  /// a terminate scope encloses a try.\n  llvm::BasicBlock *getTerminateHandler();\n\n  llvm::Type *ConvertTypeForMem(QualType T);\n  llvm::Type *ConvertType(QualType T);\n  llvm::Type *ConvertType(const TypeDecl *T) {\n    return ConvertType(getContext().getTypeDeclType(T));\n  }\n\n  /// LoadObjCSelf - Load the value of self. This function is only valid while\n  /// generating code for an Objective-C method.\n  llvm::Value *LoadObjCSelf();\n\n  /// TypeOfSelfObject - Return type of object that this self represents.\n  QualType TypeOfSelfObject();\n\n  /// getEvaluationKind - Return the TypeEvaluationKind of QualType \\c T.\n  static TypeEvaluationKind getEvaluationKind(QualType T);\n\n  static bool hasScalarEvaluationKind(QualType T) {\n    return getEvaluationKind(T) == TEK_Scalar;\n  }\n\n  static bool hasAggregateEvaluationKind(QualType T) {\n    return getEvaluationKind(T) == TEK_Aggregate;\n  }\n\n  /// createBasicBlock - Create an LLVM basic block.\n  llvm::BasicBlock *createBasicBlock(const Twine &name = \"\",\n                                     llvm::Function *parent = nullptr,\n                                     llvm::BasicBlock *before = nullptr) {\n    return llvm::BasicBlock::Create(getLLVMContext(), name, parent, before);\n  }\n\n  /// getBasicBlockForLabel - Return the LLVM basicblock that the specified\n  /// label maps to.\n  JumpDest getJumpDestForLabel(const LabelDecl *S);\n\n  /// SimplifyForwardingBlocks - If the given basic block is only a branch to\n  /// another basic block, simplify it. This assumes that no other code could\n  /// potentially reference the basic block.\n  void SimplifyForwardingBlocks(llvm::BasicBlock *BB);\n\n  /// EmitBlock - Emit the given block \\arg BB and set it as the insert point,\n  /// adding a fall-through branch from the current insert block if\n  /// necessary. It is legal to call this function even if there is no current\n  /// insertion point.\n  ///\n  /// IsFinished - If true, indicates that the caller has finished emitting\n  /// branches to the given block and does not expect to emit code into it. This\n  /// means the block can be ignored if it is unreachable.\n  void EmitBlock(llvm::BasicBlock *BB, bool IsFinished=false);\n\n  /// EmitBlockAfterUses - Emit the given block somewhere hopefully\n  /// near its uses, and leave the insertion point in it.\n  void EmitBlockAfterUses(llvm::BasicBlock *BB);\n\n  /// EmitBranch - Emit a branch to the specified basic block from the current\n  /// insert block, taking care to avoid creation of branches from dummy\n  /// blocks. It is legal to call this function even if there is no current\n  /// insertion point.\n  ///\n  /// This function clears the current insertion point. The caller should follow\n  /// calls to this function with calls to Emit*Block prior to generation new\n  /// code.\n  void EmitBranch(llvm::BasicBlock *Block);\n\n  /// HaveInsertPoint - True if an insertion point is defined. If not, this\n  /// indicates that the current code being emitted is unreachable.\n  bool HaveInsertPoint() const {\n    return Builder.GetInsertBlock() != nullptr;\n  }\n\n  /// EnsureInsertPoint - Ensure that an insertion point is defined so that\n  /// emitted IR has a place to go. Note that by definition, if this function\n  /// creates a block then that block is unreachable; callers may do better to\n  /// detect when no insertion point is defined and simply skip IR generation.\n  void EnsureInsertPoint() {\n    if (!HaveInsertPoint())\n      EmitBlock(createBasicBlock());\n  }\n\n  /// ErrorUnsupported - Print out an error that codegen doesn't support the\n  /// specified stmt yet.\n  void ErrorUnsupported(const Stmt *S, const char *Type);\n\n  //===--------------------------------------------------------------------===//\n  //                                  Helpers\n  //===--------------------------------------------------------------------===//\n\n  LValue MakeAddrLValue(Address Addr, QualType T,\n                        AlignmentSource Source = AlignmentSource::Type) {\n    return LValue::MakeAddr(Addr, T, getContext(), LValueBaseInfo(Source),\n                            CGM.getTBAAAccessInfo(T));\n  }\n\n  LValue MakeAddrLValue(Address Addr, QualType T, LValueBaseInfo BaseInfo,\n                        TBAAAccessInfo TBAAInfo) {\n    return LValue::MakeAddr(Addr, T, getContext(), BaseInfo, TBAAInfo);\n  }\n\n  LValue MakeAddrLValue(llvm::Value *V, QualType T, CharUnits Alignment,\n                        AlignmentSource Source = AlignmentSource::Type) {\n    return LValue::MakeAddr(Address(V, Alignment), T, getContext(),\n                            LValueBaseInfo(Source), CGM.getTBAAAccessInfo(T));\n  }\n\n  LValue MakeAddrLValue(llvm::Value *V, QualType T, CharUnits Alignment,\n                        LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo) {\n    return LValue::MakeAddr(Address(V, Alignment), T, getContext(),\n                            BaseInfo, TBAAInfo);\n  }\n\n  LValue MakeNaturalAlignPointeeAddrLValue(llvm::Value *V, QualType T);\n  LValue MakeNaturalAlignAddrLValue(llvm::Value *V, QualType T);\n\n  Address EmitLoadOfReference(LValue RefLVal,\n                              LValueBaseInfo *PointeeBaseInfo = nullptr,\n                              TBAAAccessInfo *PointeeTBAAInfo = nullptr);\n  LValue EmitLoadOfReferenceLValue(LValue RefLVal);\n  LValue EmitLoadOfReferenceLValue(Address RefAddr, QualType RefTy,\n                                   AlignmentSource Source =\n                                       AlignmentSource::Type) {\n    LValue RefLVal = MakeAddrLValue(RefAddr, RefTy, LValueBaseInfo(Source),\n                                    CGM.getTBAAAccessInfo(RefTy));\n    return EmitLoadOfReferenceLValue(RefLVal);\n  }\n\n  Address EmitLoadOfPointer(Address Ptr, const PointerType *PtrTy,\n                            LValueBaseInfo *BaseInfo = nullptr,\n                            TBAAAccessInfo *TBAAInfo = nullptr);\n  LValue EmitLoadOfPointerLValue(Address Ptr, const PointerType *PtrTy);\n\n  /// CreateTempAlloca - This creates an alloca and inserts it into the entry\n  /// block if \\p ArraySize is nullptr, otherwise inserts it at the current\n  /// insertion point of the builder. The caller is responsible for setting an\n  /// appropriate alignment on\n  /// the alloca.\n  ///\n  /// \\p ArraySize is the number of array elements to be allocated if it\n  ///    is not nullptr.\n  ///\n  /// LangAS::Default is the address space of pointers to local variables and\n  /// temporaries, as exposed in the source language. In certain\n  /// configurations, this is not the same as the alloca address space, and a\n  /// cast is needed to lift the pointer from the alloca AS into\n  /// LangAS::Default. This can happen when the target uses a restricted\n  /// address space for the stack but the source language requires\n  /// LangAS::Default to be a generic address space. The latter condition is\n  /// common for most programming languages; OpenCL is an exception in that\n  /// LangAS::Default is the private address space, which naturally maps\n  /// to the stack.\n  ///\n  /// Because the address of a temporary is often exposed to the program in\n  /// various ways, this function will perform the cast. The original alloca\n  /// instruction is returned through \\p Alloca if it is not nullptr.\n  ///\n  /// The cast is not performaed in CreateTempAllocaWithoutCast. This is\n  /// more efficient if the caller knows that the address will not be exposed.\n  llvm::AllocaInst *CreateTempAlloca(llvm::Type *Ty, const Twine &Name = \"tmp\",\n                                     llvm::Value *ArraySize = nullptr);\n  Address CreateTempAlloca(llvm::Type *Ty, CharUnits align,\n                           const Twine &Name = \"tmp\",\n                           llvm::Value *ArraySize = nullptr,\n                           Address *Alloca = nullptr);\n  Address CreateTempAllocaWithoutCast(llvm::Type *Ty, CharUnits align,\n                                      const Twine &Name = \"tmp\",\n                                      llvm::Value *ArraySize = nullptr);\n\n  /// CreateDefaultAlignedTempAlloca - This creates an alloca with the\n  /// default ABI alignment of the given LLVM type.\n  ///\n  /// IMPORTANT NOTE: This is *not* generally the right alignment for\n  /// any given AST type that happens to have been lowered to the\n  /// given IR type.  This should only ever be used for function-local,\n  /// IR-driven manipulations like saving and restoring a value.  Do\n  /// not hand this address off to arbitrary IRGen routines, and especially\n  /// do not pass it as an argument to a function that might expect a\n  /// properly ABI-aligned value.\n  Address CreateDefaultAlignTempAlloca(llvm::Type *Ty,\n                                       const Twine &Name = \"tmp\");\n\n  /// InitTempAlloca - Provide an initial value for the given alloca which\n  /// will be observable at all locations in the function.\n  ///\n  /// The address should be something that was returned from one of\n  /// the CreateTempAlloca or CreateMemTemp routines, and the\n  /// initializer must be valid in the entry block (i.e. it must\n  /// either be a constant or an argument value).\n  void InitTempAlloca(Address Alloca, llvm::Value *Value);\n\n  /// CreateIRTemp - Create a temporary IR object of the given type, with\n  /// appropriate alignment. This routine should only be used when an temporary\n  /// value needs to be stored into an alloca (for example, to avoid explicit\n  /// PHI construction), but the type is the IR type, not the type appropriate\n  /// for storing in memory.\n  ///\n  /// That is, this is exactly equivalent to CreateMemTemp, but calling\n  /// ConvertType instead of ConvertTypeForMem.\n  Address CreateIRTemp(QualType T, const Twine &Name = \"tmp\");\n\n  /// CreateMemTemp - Create a temporary memory object of the given type, with\n  /// appropriate alignmen and cast it to the default address space. Returns\n  /// the original alloca instruction by \\p Alloca if it is not nullptr.\n  Address CreateMemTemp(QualType T, const Twine &Name = \"tmp\",\n                        Address *Alloca = nullptr);\n  Address CreateMemTemp(QualType T, CharUnits Align, const Twine &Name = \"tmp\",\n                        Address *Alloca = nullptr);\n\n  /// CreateMemTemp - Create a temporary memory object of the given type, with\n  /// appropriate alignmen without casting it to the default address space.\n  Address CreateMemTempWithoutCast(QualType T, const Twine &Name = \"tmp\");\n  Address CreateMemTempWithoutCast(QualType T, CharUnits Align,\n                                   const Twine &Name = \"tmp\");\n\n  /// CreateAggTemp - Create a temporary memory object for the given\n  /// aggregate type.\n  AggValueSlot CreateAggTemp(QualType T, const Twine &Name = \"tmp\",\n                             Address *Alloca = nullptr) {\n    return AggValueSlot::forAddr(CreateMemTemp(T, Name, Alloca),\n                                 T.getQualifiers(),\n                                 AggValueSlot::IsNotDestructed,\n                                 AggValueSlot::DoesNotNeedGCBarriers,\n                                 AggValueSlot::IsNotAliased,\n                                 AggValueSlot::DoesNotOverlap);\n  }\n\n  /// Emit a cast to void* in the appropriate address space.\n  llvm::Value *EmitCastToVoidPtr(llvm::Value *value);\n\n  /// EvaluateExprAsBool - Perform the usual unary conversions on the specified\n  /// expression and compare the result against zero, returning an Int1Ty value.\n  llvm::Value *EvaluateExprAsBool(const Expr *E);\n\n  /// EmitIgnoredExpr - Emit an expression in a context which ignores the result.\n  void EmitIgnoredExpr(const Expr *E);\n\n  /// EmitAnyExpr - Emit code to compute the specified expression which can have\n  /// any type.  The result is returned as an RValue struct.  If this is an\n  /// aggregate expression, the aggloc/agglocvolatile arguments indicate where\n  /// the result should be returned.\n  ///\n  /// \\param ignoreResult True if the resulting value isn't used.\n  RValue EmitAnyExpr(const Expr *E,\n                     AggValueSlot aggSlot = AggValueSlot::ignored(),\n                     bool ignoreResult = false);\n\n  // EmitVAListRef - Emit a \"reference\" to a va_list; this is either the address\n  // or the value of the expression, depending on how va_list is defined.\n  Address EmitVAListRef(const Expr *E);\n\n  /// Emit a \"reference\" to a __builtin_ms_va_list; this is\n  /// always the value of the expression, because a __builtin_ms_va_list is a\n  /// pointer to a char.\n  Address EmitMSVAListRef(const Expr *E);\n\n  /// EmitAnyExprToTemp - Similarly to EmitAnyExpr(), however, the result will\n  /// always be accessible even if no aggregate location is provided.\n  RValue EmitAnyExprToTemp(const Expr *E);\n\n  /// EmitAnyExprToMem - Emits the code necessary to evaluate an\n  /// arbitrary expression into the given memory location.\n  void EmitAnyExprToMem(const Expr *E, Address Location,\n                        Qualifiers Quals, bool IsInitializer);\n\n  void EmitAnyExprToExn(const Expr *E, Address Addr);\n\n  /// EmitExprAsInit - Emits the code necessary to initialize a\n  /// location in memory with the given initializer.\n  void EmitExprAsInit(const Expr *init, const ValueDecl *D, LValue lvalue,\n                      bool capturedByInit);\n\n  /// hasVolatileMember - returns true if aggregate type has a volatile\n  /// member.\n  bool hasVolatileMember(QualType T) {\n    if (const RecordType *RT = T->getAs<RecordType>()) {\n      const RecordDecl *RD = cast<RecordDecl>(RT->getDecl());\n      return RD->hasVolatileMember();\n    }\n    return false;\n  }\n\n  /// Determine whether a return value slot may overlap some other object.\n  AggValueSlot::Overlap_t getOverlapForReturnValue() {\n    // FIXME: Assuming no overlap here breaks guaranteed copy elision for base\n    // class subobjects. These cases may need to be revisited depending on the\n    // resolution of the relevant core issue.\n    return AggValueSlot::DoesNotOverlap;\n  }\n\n  /// Determine whether a field initialization may overlap some other object.\n  AggValueSlot::Overlap_t getOverlapForFieldInit(const FieldDecl *FD);\n\n  /// Determine whether a base class initialization may overlap some other\n  /// object.\n  AggValueSlot::Overlap_t getOverlapForBaseInit(const CXXRecordDecl *RD,\n                                                const CXXRecordDecl *BaseRD,\n                                                bool IsVirtual);\n\n  /// Emit an aggregate assignment.\n  void EmitAggregateAssign(LValue Dest, LValue Src, QualType EltTy) {\n    bool IsVolatile = hasVolatileMember(EltTy);\n    EmitAggregateCopy(Dest, Src, EltTy, AggValueSlot::MayOverlap, IsVolatile);\n  }\n\n  void EmitAggregateCopyCtor(LValue Dest, LValue Src,\n                             AggValueSlot::Overlap_t MayOverlap) {\n    EmitAggregateCopy(Dest, Src, Src.getType(), MayOverlap);\n  }\n\n  /// EmitAggregateCopy - Emit an aggregate copy.\n  ///\n  /// \\param isVolatile \\c true iff either the source or the destination is\n  ///        volatile.\n  /// \\param MayOverlap Whether the tail padding of the destination might be\n  ///        occupied by some other object. More efficient code can often be\n  ///        generated if not.\n  void EmitAggregateCopy(LValue Dest, LValue Src, QualType EltTy,\n                         AggValueSlot::Overlap_t MayOverlap,\n                         bool isVolatile = false);\n\n  /// GetAddrOfLocalVar - Return the address of a local variable.\n  Address GetAddrOfLocalVar(const VarDecl *VD) {\n    auto it = LocalDeclMap.find(VD);\n    assert(it != LocalDeclMap.end() &&\n           \"Invalid argument to GetAddrOfLocalVar(), no decl!\");\n    return it->second;\n  }\n\n  /// Given an opaque value expression, return its LValue mapping if it exists,\n  /// otherwise create one.\n  LValue getOrCreateOpaqueLValueMapping(const OpaqueValueExpr *e);\n\n  /// Given an opaque value expression, return its RValue mapping if it exists,\n  /// otherwise create one.\n  RValue getOrCreateOpaqueRValueMapping(const OpaqueValueExpr *e);\n\n  /// Get the index of the current ArrayInitLoopExpr, if any.\n  llvm::Value *getArrayInitIndex() { return ArrayInitIndex; }\n\n  /// getAccessedFieldNo - Given an encoded value and a result number, return\n  /// the input field number being accessed.\n  static unsigned getAccessedFieldNo(unsigned Idx, const llvm::Constant *Elts);\n\n  llvm::BlockAddress *GetAddrOfLabel(const LabelDecl *L);\n  llvm::BasicBlock *GetIndirectGotoBlock();\n\n  /// Check if \\p E is a C++ \"this\" pointer wrapped in value-preserving casts.\n  static bool IsWrappedCXXThis(const Expr *E);\n\n  /// EmitNullInitialization - Generate code to set a value of the given type to\n  /// null, If the type contains data member pointers, they will be initialized\n  /// to -1 in accordance with the Itanium C++ ABI.\n  void EmitNullInitialization(Address DestPtr, QualType Ty);\n\n  /// Emits a call to an LLVM variable-argument intrinsic, either\n  /// \\c llvm.va_start or \\c llvm.va_end.\n  /// \\param ArgValue A reference to the \\c va_list as emitted by either\n  /// \\c EmitVAListRef or \\c EmitMSVAListRef.\n  /// \\param IsStart If \\c true, emits a call to \\c llvm.va_start; otherwise,\n  /// calls \\c llvm.va_end.\n  llvm::Value *EmitVAStartEnd(llvm::Value *ArgValue, bool IsStart);\n\n  /// Generate code to get an argument from the passed in pointer\n  /// and update it accordingly.\n  /// \\param VE The \\c VAArgExpr for which to generate code.\n  /// \\param VAListAddr Receives a reference to the \\c va_list as emitted by\n  /// either \\c EmitVAListRef or \\c EmitMSVAListRef.\n  /// \\returns A pointer to the argument.\n  // FIXME: We should be able to get rid of this method and use the va_arg\n  // instruction in LLVM instead once it works well enough.\n  Address EmitVAArg(VAArgExpr *VE, Address &VAListAddr);\n\n  /// emitArrayLength - Compute the length of an array, even if it's a\n  /// VLA, and drill down to the base element type.\n  llvm::Value *emitArrayLength(const ArrayType *arrayType,\n                               QualType &baseType,\n                               Address &addr);\n\n  /// EmitVLASize - Capture all the sizes for the VLA expressions in\n  /// the given variably-modified type and store them in the VLASizeMap.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitVariablyModifiedType(QualType Ty);\n\n  struct VlaSizePair {\n    llvm::Value *NumElts;\n    QualType Type;\n\n    VlaSizePair(llvm::Value *NE, QualType T) : NumElts(NE), Type(T) {}\n  };\n\n  /// Return the number of elements for a single dimension\n  /// for the given array type.\n  VlaSizePair getVLAElements1D(const VariableArrayType *vla);\n  VlaSizePair getVLAElements1D(QualType vla);\n\n  /// Returns an LLVM value that corresponds to the size,\n  /// in non-variably-sized elements, of a variable length array type,\n  /// plus that largest non-variably-sized element type.  Assumes that\n  /// the type has already been emitted with EmitVariablyModifiedType.\n  VlaSizePair getVLASize(const VariableArrayType *vla);\n  VlaSizePair getVLASize(QualType vla);\n\n  /// LoadCXXThis - Load the value of 'this'. This function is only valid while\n  /// generating code for an C++ member function.\n  llvm::Value *LoadCXXThis() {\n    assert(CXXThisValue && \"no 'this' value for this function\");\n    return CXXThisValue;\n  }\n  Address LoadCXXThisAddress();\n\n  /// LoadCXXVTT - Load the VTT parameter to base constructors/destructors have\n  /// virtual bases.\n  // FIXME: Every place that calls LoadCXXVTT is something\n  // that needs to be abstracted properly.\n  llvm::Value *LoadCXXVTT() {\n    assert(CXXStructorImplicitParamValue && \"no VTT value for this function\");\n    return CXXStructorImplicitParamValue;\n  }\n\n  /// GetAddressOfBaseOfCompleteClass - Convert the given pointer to a\n  /// complete class to the given direct base.\n  Address\n  GetAddressOfDirectBaseInCompleteClass(Address Value,\n                                        const CXXRecordDecl *Derived,\n                                        const CXXRecordDecl *Base,\n                                        bool BaseIsVirtual);\n\n  static bool ShouldNullCheckClassCastValue(const CastExpr *Cast);\n\n  /// GetAddressOfBaseClass - This function will add the necessary delta to the\n  /// load of 'this' and returns address of the base class.\n  Address GetAddressOfBaseClass(Address Value,\n                                const CXXRecordDecl *Derived,\n                                CastExpr::path_const_iterator PathBegin,\n                                CastExpr::path_const_iterator PathEnd,\n                                bool NullCheckValue, SourceLocation Loc);\n\n  Address GetAddressOfDerivedClass(Address Value,\n                                   const CXXRecordDecl *Derived,\n                                   CastExpr::path_const_iterator PathBegin,\n                                   CastExpr::path_const_iterator PathEnd,\n                                   bool NullCheckValue);\n\n  /// GetVTTParameter - Return the VTT parameter that should be passed to a\n  /// base constructor/destructor with virtual bases.\n  /// FIXME: VTTs are Itanium ABI-specific, so the definition should move\n  /// to ItaniumCXXABI.cpp together with all the references to VTT.\n  llvm::Value *GetVTTParameter(GlobalDecl GD, bool ForVirtualBase,\n                               bool Delegating);\n\n  void EmitDelegateCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                      CXXCtorType CtorType,\n                                      const FunctionArgList &Args,\n                                      SourceLocation Loc);\n  // It's important not to confuse this and the previous function. Delegating\n  // constructors are the C++0x feature. The constructor delegate optimization\n  // is used to reduce duplication in the base and complete consturctors where\n  // they are substantially the same.\n  void EmitDelegatingCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                        const FunctionArgList &Args);\n\n  /// Emit a call to an inheriting constructor (that is, one that invokes a\n  /// constructor inherited from a base class) by inlining its definition. This\n  /// is necessary if the ABI does not support forwarding the arguments to the\n  /// base class constructor (because they're variadic or similar).\n  void EmitInlinedInheritingCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                               CXXCtorType CtorType,\n                                               bool ForVirtualBase,\n                                               bool Delegating,\n                                               CallArgList &Args);\n\n  /// Emit a call to a constructor inherited from a base class, passing the\n  /// current constructor's arguments along unmodified (without even making\n  /// a copy).\n  void EmitInheritedCXXConstructorCall(const CXXConstructorDecl *D,\n                                       bool ForVirtualBase, Address This,\n                                       bool InheritedFromVBase,\n                                       const CXXInheritedCtorInitExpr *E);\n\n  void EmitCXXConstructorCall(const CXXConstructorDecl *D, CXXCtorType Type,\n                              bool ForVirtualBase, bool Delegating,\n                              AggValueSlot ThisAVS, const CXXConstructExpr *E);\n\n  void EmitCXXConstructorCall(const CXXConstructorDecl *D, CXXCtorType Type,\n                              bool ForVirtualBase, bool Delegating,\n                              Address This, CallArgList &Args,\n                              AggValueSlot::Overlap_t Overlap,\n                              SourceLocation Loc, bool NewPointerIsChecked);\n\n  /// Emit assumption load for all bases. Requires to be be called only on\n  /// most-derived class and not under construction of the object.\n  void EmitVTableAssumptionLoads(const CXXRecordDecl *ClassDecl, Address This);\n\n  /// Emit assumption that vptr load == global vtable.\n  void EmitVTableAssumptionLoad(const VPtr &vptr, Address This);\n\n  void EmitSynthesizedCXXCopyCtorCall(const CXXConstructorDecl *D,\n                                      Address This, Address Src,\n                                      const CXXConstructExpr *E);\n\n  void EmitCXXAggrConstructorCall(const CXXConstructorDecl *D,\n                                  const ArrayType *ArrayTy,\n                                  Address ArrayPtr,\n                                  const CXXConstructExpr *E,\n                                  bool NewPointerIsChecked,\n                                  bool ZeroInitialization = false);\n\n  void EmitCXXAggrConstructorCall(const CXXConstructorDecl *D,\n                                  llvm::Value *NumElements,\n                                  Address ArrayPtr,\n                                  const CXXConstructExpr *E,\n                                  bool NewPointerIsChecked,\n                                  bool ZeroInitialization = false);\n\n  static Destroyer destroyCXXObject;\n\n  void EmitCXXDestructorCall(const CXXDestructorDecl *D, CXXDtorType Type,\n                             bool ForVirtualBase, bool Delegating, Address This,\n                             QualType ThisTy);\n\n  void EmitNewArrayInitializer(const CXXNewExpr *E, QualType elementType,\n                               llvm::Type *ElementTy, Address NewPtr,\n                               llvm::Value *NumElements,\n                               llvm::Value *AllocSizeWithoutCookie);\n\n  void EmitCXXTemporary(const CXXTemporary *Temporary, QualType TempType,\n                        Address Ptr);\n\n  llvm::Value *EmitLifetimeStart(uint64_t Size, llvm::Value *Addr);\n  void EmitLifetimeEnd(llvm::Value *Size, llvm::Value *Addr);\n\n  llvm::Value *EmitCXXNewExpr(const CXXNewExpr *E);\n  void EmitCXXDeleteExpr(const CXXDeleteExpr *E);\n\n  void EmitDeleteCall(const FunctionDecl *DeleteFD, llvm::Value *Ptr,\n                      QualType DeleteTy, llvm::Value *NumElements = nullptr,\n                      CharUnits CookieSize = CharUnits());\n\n  RValue EmitBuiltinNewDeleteCall(const FunctionProtoType *Type,\n                                  const CallExpr *TheCallExpr, bool IsDelete);\n\n  llvm::Value *EmitCXXTypeidExpr(const CXXTypeidExpr *E);\n  llvm::Value *EmitDynamicCast(Address V, const CXXDynamicCastExpr *DCE);\n  Address EmitCXXUuidofExpr(const CXXUuidofExpr *E);\n\n  /// Situations in which we might emit a check for the suitability of a\n  /// pointer or glvalue. Needs to be kept in sync with ubsan_handlers.cpp in\n  /// compiler-rt.\n  enum TypeCheckKind {\n    /// Checking the operand of a load. Must be suitably sized and aligned.\n    TCK_Load,\n    /// Checking the destination of a store. Must be suitably sized and aligned.\n    TCK_Store,\n    /// Checking the bound value in a reference binding. Must be suitably sized\n    /// and aligned, but is not required to refer to an object (until the\n    /// reference is used), per core issue 453.\n    TCK_ReferenceBinding,\n    /// Checking the object expression in a non-static data member access. Must\n    /// be an object within its lifetime.\n    TCK_MemberAccess,\n    /// Checking the 'this' pointer for a call to a non-static member function.\n    /// Must be an object within its lifetime.\n    TCK_MemberCall,\n    /// Checking the 'this' pointer for a constructor call.\n    TCK_ConstructorCall,\n    /// Checking the operand of a static_cast to a derived pointer type. Must be\n    /// null or an object within its lifetime.\n    TCK_DowncastPointer,\n    /// Checking the operand of a static_cast to a derived reference type. Must\n    /// be an object within its lifetime.\n    TCK_DowncastReference,\n    /// Checking the operand of a cast to a base object. Must be suitably sized\n    /// and aligned.\n    TCK_Upcast,\n    /// Checking the operand of a cast to a virtual base object. Must be an\n    /// object within its lifetime.\n    TCK_UpcastToVirtualBase,\n    /// Checking the value assigned to a _Nonnull pointer. Must not be null.\n    TCK_NonnullAssign,\n    /// Checking the operand of a dynamic_cast or a typeid expression.  Must be\n    /// null or an object within its lifetime.\n    TCK_DynamicOperation\n  };\n\n  /// Determine whether the pointer type check \\p TCK permits null pointers.\n  static bool isNullPointerAllowed(TypeCheckKind TCK);\n\n  /// Determine whether the pointer type check \\p TCK requires a vptr check.\n  static bool isVptrCheckRequired(TypeCheckKind TCK, QualType Ty);\n\n  /// Whether any type-checking sanitizers are enabled. If \\c false,\n  /// calls to EmitTypeCheck can be skipped.\n  bool sanitizePerformTypeCheck() const;\n\n  /// Emit a check that \\p V is the address of storage of the\n  /// appropriate size and alignment for an object of type \\p Type\n  /// (or if ArraySize is provided, for an array of that bound).\n  void EmitTypeCheck(TypeCheckKind TCK, SourceLocation Loc, llvm::Value *V,\n                     QualType Type, CharUnits Alignment = CharUnits::Zero(),\n                     SanitizerSet SkippedChecks = SanitizerSet(),\n                     llvm::Value *ArraySize = nullptr);\n\n  /// Emit a check that \\p Base points into an array object, which\n  /// we can access at index \\p Index. \\p Accessed should be \\c false if we\n  /// this expression is used as an lvalue, for instance in \"&Arr[Idx]\".\n  void EmitBoundsCheck(const Expr *E, const Expr *Base, llvm::Value *Index,\n                       QualType IndexType, bool Accessed);\n\n  llvm::Value *EmitScalarPrePostIncDec(const UnaryOperator *E, LValue LV,\n                                       bool isInc, bool isPre);\n  ComplexPairTy EmitComplexPrePostIncDec(const UnaryOperator *E, LValue LV,\n                                         bool isInc, bool isPre);\n\n  /// Converts Location to a DebugLoc, if debug information is enabled.\n  llvm::DebugLoc SourceLocToDebugLoc(SourceLocation Location);\n\n  /// Get the record field index as represented in debug info.\n  unsigned getDebugInfoFIndex(const RecordDecl *Rec, unsigned FieldIndex);\n\n\n  //===--------------------------------------------------------------------===//\n  //                            Declaration Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitDecl - Emit a declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitDecl(const Decl &D);\n\n  /// EmitVarDecl - Emit a local variable declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitVarDecl(const VarDecl &D);\n\n  void EmitScalarInit(const Expr *init, const ValueDecl *D, LValue lvalue,\n                      bool capturedByInit);\n\n  typedef void SpecialInitFn(CodeGenFunction &Init, const VarDecl &D,\n                             llvm::Value *Address);\n\n  /// Determine whether the given initializer is trivial in the sense\n  /// that it requires no code to be generated.\n  bool isTrivialInitializer(const Expr *Init);\n\n  /// EmitAutoVarDecl - Emit an auto variable declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitAutoVarDecl(const VarDecl &D);\n\n  class AutoVarEmission {\n    friend class CodeGenFunction;\n\n    const VarDecl *Variable;\n\n    /// The address of the alloca for languages with explicit address space\n    /// (e.g. OpenCL) or alloca casted to generic pointer for address space\n    /// agnostic languages (e.g. C++). Invalid if the variable was emitted\n    /// as a global constant.\n    Address Addr;\n\n    llvm::Value *NRVOFlag;\n\n    /// True if the variable is a __block variable that is captured by an\n    /// escaping block.\n    bool IsEscapingByRef;\n\n    /// True if the variable is of aggregate type and has a constant\n    /// initializer.\n    bool IsConstantAggregate;\n\n    /// Non-null if we should use lifetime annotations.\n    llvm::Value *SizeForLifetimeMarkers;\n\n    /// Address with original alloca instruction. Invalid if the variable was\n    /// emitted as a global constant.\n    Address AllocaAddr;\n\n    struct Invalid {};\n    AutoVarEmission(Invalid)\n        : Variable(nullptr), Addr(Address::invalid()),\n          AllocaAddr(Address::invalid()) {}\n\n    AutoVarEmission(const VarDecl &variable)\n        : Variable(&variable), Addr(Address::invalid()), NRVOFlag(nullptr),\n          IsEscapingByRef(false), IsConstantAggregate(false),\n          SizeForLifetimeMarkers(nullptr), AllocaAddr(Address::invalid()) {}\n\n    bool wasEmittedAsGlobal() const { return !Addr.isValid(); }\n\n  public:\n    static AutoVarEmission invalid() { return AutoVarEmission(Invalid()); }\n\n    bool useLifetimeMarkers() const {\n      return SizeForLifetimeMarkers != nullptr;\n    }\n    llvm::Value *getSizeForLifetimeMarkers() const {\n      assert(useLifetimeMarkers());\n      return SizeForLifetimeMarkers;\n    }\n\n    /// Returns the raw, allocated address, which is not necessarily\n    /// the address of the object itself. It is casted to default\n    /// address space for address space agnostic languages.\n    Address getAllocatedAddress() const {\n      return Addr;\n    }\n\n    /// Returns the address for the original alloca instruction.\n    Address getOriginalAllocatedAddress() const { return AllocaAddr; }\n\n    /// Returns the address of the object within this declaration.\n    /// Note that this does not chase the forwarding pointer for\n    /// __block decls.\n    Address getObjectAddress(CodeGenFunction &CGF) const {\n      if (!IsEscapingByRef) return Addr;\n\n      return CGF.emitBlockByrefAddress(Addr, Variable, /*forward*/ false);\n    }\n  };\n  AutoVarEmission EmitAutoVarAlloca(const VarDecl &var);\n  void EmitAutoVarInit(const AutoVarEmission &emission);\n  void EmitAutoVarCleanups(const AutoVarEmission &emission);\n  void emitAutoVarTypeCleanup(const AutoVarEmission &emission,\n                              QualType::DestructionKind dtorKind);\n\n  /// Emits the alloca and debug information for the size expressions for each\n  /// dimension of an array. It registers the association of its (1-dimensional)\n  /// QualTypes and size expression's debug node, so that CGDebugInfo can\n  /// reference this node when creating the DISubrange object to describe the\n  /// array types.\n  void EmitAndRegisterVariableArrayDimensions(CGDebugInfo *DI,\n                                              const VarDecl &D,\n                                              bool EmitDebugInfo);\n\n  void EmitStaticVarDecl(const VarDecl &D,\n                         llvm::GlobalValue::LinkageTypes Linkage);\n\n  class ParamValue {\n    llvm::Value *Value;\n    unsigned Alignment;\n    ParamValue(llvm::Value *V, unsigned A) : Value(V), Alignment(A) {}\n  public:\n    static ParamValue forDirect(llvm::Value *value) {\n      return ParamValue(value, 0);\n    }\n    static ParamValue forIndirect(Address addr) {\n      assert(!addr.getAlignment().isZero());\n      return ParamValue(addr.getPointer(), addr.getAlignment().getQuantity());\n    }\n\n    bool isIndirect() const { return Alignment != 0; }\n    llvm::Value *getAnyValue() const { return Value; }\n\n    llvm::Value *getDirectValue() const {\n      assert(!isIndirect());\n      return Value;\n    }\n\n    Address getIndirectAddress() const {\n      assert(isIndirect());\n      return Address(Value, CharUnits::fromQuantity(Alignment));\n    }\n  };\n\n  /// EmitParmDecl - Emit a ParmVarDecl or an ImplicitParamDecl.\n  void EmitParmDecl(const VarDecl &D, ParamValue Arg, unsigned ArgNo);\n\n  /// protectFromPeepholes - Protect a value that we're intending to\n  /// store to the side, but which will probably be used later, from\n  /// aggressive peepholing optimizations that might delete it.\n  ///\n  /// Pass the result to unprotectFromPeepholes to declare that\n  /// protection is no longer required.\n  ///\n  /// There's no particular reason why this shouldn't apply to\n  /// l-values, it's just that no existing peepholes work on pointers.\n  PeepholeProtection protectFromPeepholes(RValue rvalue);\n  void unprotectFromPeepholes(PeepholeProtection protection);\n\n  void emitAlignmentAssumptionCheck(llvm::Value *Ptr, QualType Ty,\n                                    SourceLocation Loc,\n                                    SourceLocation AssumptionLoc,\n                                    llvm::Value *Alignment,\n                                    llvm::Value *OffsetValue,\n                                    llvm::Value *TheCheck,\n                                    llvm::Instruction *Assumption);\n\n  void emitAlignmentAssumption(llvm::Value *PtrValue, QualType Ty,\n                               SourceLocation Loc, SourceLocation AssumptionLoc,\n                               llvm::Value *Alignment,\n                               llvm::Value *OffsetValue = nullptr);\n\n  void emitAlignmentAssumption(llvm::Value *PtrValue, const Expr *E,\n                               SourceLocation AssumptionLoc,\n                               llvm::Value *Alignment,\n                               llvm::Value *OffsetValue = nullptr);\n\n  //===--------------------------------------------------------------------===//\n  //                             Statement Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitStopPoint - Emit a debug stoppoint if we are emitting debug info.\n  void EmitStopPoint(const Stmt *S);\n\n  /// EmitStmt - Emit the code for the statement \\arg S. It is legal to call\n  /// this function even if there is no current insertion point.\n  ///\n  /// This function may clear the current insertion point; callers should use\n  /// EnsureInsertPoint if they wish to subsequently generate code without first\n  /// calling EmitBlock, EmitBranch, or EmitStmt.\n  void EmitStmt(const Stmt *S, ArrayRef<const Attr *> Attrs = None);\n\n  /// EmitSimpleStmt - Try to emit a \"simple\" statement which does not\n  /// necessarily require an insertion point or debug information; typically\n  /// because the statement amounts to a jump or a container of other\n  /// statements.\n  ///\n  /// \\return True if the statement was handled.\n  bool EmitSimpleStmt(const Stmt *S, ArrayRef<const Attr *> Attrs);\n\n  Address EmitCompoundStmt(const CompoundStmt &S, bool GetLast = false,\n                           AggValueSlot AVS = AggValueSlot::ignored());\n  Address EmitCompoundStmtWithoutScope(const CompoundStmt &S,\n                                       bool GetLast = false,\n                                       AggValueSlot AVS =\n                                                AggValueSlot::ignored());\n\n  /// EmitLabel - Emit the block for the given label. It is legal to call this\n  /// function even if there is no current insertion point.\n  void EmitLabel(const LabelDecl *D); // helper for EmitLabelStmt.\n\n  void EmitLabelStmt(const LabelStmt &S);\n  void EmitAttributedStmt(const AttributedStmt &S);\n  void EmitGotoStmt(const GotoStmt &S);\n  void EmitIndirectGotoStmt(const IndirectGotoStmt &S);\n  void EmitIfStmt(const IfStmt &S);\n\n  void EmitWhileStmt(const WhileStmt &S,\n                     ArrayRef<const Attr *> Attrs = None);\n  void EmitDoStmt(const DoStmt &S, ArrayRef<const Attr *> Attrs = None);\n  void EmitForStmt(const ForStmt &S,\n                   ArrayRef<const Attr *> Attrs = None);\n  void EmitReturnStmt(const ReturnStmt &S);\n  void EmitDeclStmt(const DeclStmt &S);\n  void EmitBreakStmt(const BreakStmt &S);\n  void EmitContinueStmt(const ContinueStmt &S);\n  void EmitSwitchStmt(const SwitchStmt &S);\n  void EmitDefaultStmt(const DefaultStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitCaseStmt(const CaseStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitCaseStmtRange(const CaseStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitAsmStmt(const AsmStmt &S);\n\n  void EmitObjCForCollectionStmt(const ObjCForCollectionStmt &S);\n  void EmitObjCAtTryStmt(const ObjCAtTryStmt &S);\n  void EmitObjCAtThrowStmt(const ObjCAtThrowStmt &S);\n  void EmitObjCAtSynchronizedStmt(const ObjCAtSynchronizedStmt &S);\n  void EmitObjCAutoreleasePoolStmt(const ObjCAutoreleasePoolStmt &S);\n\n  void EmitCoroutineBody(const CoroutineBodyStmt &S);\n  void EmitCoreturnStmt(const CoreturnStmt &S);\n  RValue EmitCoawaitExpr(const CoawaitExpr &E,\n                         AggValueSlot aggSlot = AggValueSlot::ignored(),\n                         bool ignoreResult = false);\n  LValue EmitCoawaitLValue(const CoawaitExpr *E);\n  RValue EmitCoyieldExpr(const CoyieldExpr &E,\n                         AggValueSlot aggSlot = AggValueSlot::ignored(),\n                         bool ignoreResult = false);\n  LValue EmitCoyieldLValue(const CoyieldExpr *E);\n  RValue EmitCoroutineIntrinsic(const CallExpr *E, unsigned int IID);\n\n  void EnterCXXTryStmt(const CXXTryStmt &S, bool IsFnTryBlock = false);\n  void ExitCXXTryStmt(const CXXTryStmt &S, bool IsFnTryBlock = false);\n\n  void EmitCXXTryStmt(const CXXTryStmt &S);\n  void EmitSEHTryStmt(const SEHTryStmt &S);\n  void EmitSEHLeaveStmt(const SEHLeaveStmt &S);\n  void EnterSEHTryStmt(const SEHTryStmt &S);\n  void ExitSEHTryStmt(const SEHTryStmt &S);\n\n  void pushSEHCleanup(CleanupKind kind,\n                      llvm::Function *FinallyFunc);\n  void startOutlinedSEHHelper(CodeGenFunction &ParentCGF, bool IsFilter,\n                              const Stmt *OutlinedStmt);\n\n  llvm::Function *GenerateSEHFilterFunction(CodeGenFunction &ParentCGF,\n                                            const SEHExceptStmt &Except);\n\n  llvm::Function *GenerateSEHFinallyFunction(CodeGenFunction &ParentCGF,\n                                             const SEHFinallyStmt &Finally);\n\n  void EmitSEHExceptionCodeSave(CodeGenFunction &ParentCGF,\n                                llvm::Value *ParentFP,\n                                llvm::Value *EntryEBP);\n  llvm::Value *EmitSEHExceptionCode();\n  llvm::Value *EmitSEHExceptionInfo();\n  llvm::Value *EmitSEHAbnormalTermination();\n\n  /// Emit simple code for OpenMP directives in Simd-only mode.\n  void EmitSimpleOMPExecutableDirective(const OMPExecutableDirective &D);\n\n  /// Scan the outlined statement for captures from the parent function. For\n  /// each capture, mark the capture as escaped and emit a call to\n  /// llvm.localrecover. Insert the localrecover result into the LocalDeclMap.\n  void EmitCapturedLocals(CodeGenFunction &ParentCGF, const Stmt *OutlinedStmt,\n                          bool IsFilter);\n\n  /// Recovers the address of a local in a parent function. ParentVar is the\n  /// address of the variable used in the immediate parent function. It can\n  /// either be an alloca or a call to llvm.localrecover if there are nested\n  /// outlined functions. ParentFP is the frame pointer of the outermost parent\n  /// frame.\n  Address recoverAddrOfEscapedLocal(CodeGenFunction &ParentCGF,\n                                    Address ParentVar,\n                                    llvm::Value *ParentFP);\n\n  void EmitCXXForRangeStmt(const CXXForRangeStmt &S,\n                           ArrayRef<const Attr *> Attrs = None);\n\n  /// Controls insertion of cancellation exit blocks in worksharing constructs.\n  class OMPCancelStackRAII {\n    CodeGenFunction &CGF;\n\n  public:\n    OMPCancelStackRAII(CodeGenFunction &CGF, OpenMPDirectiveKind Kind,\n                       bool HasCancel)\n        : CGF(CGF) {\n      CGF.OMPCancelStack.enter(CGF, Kind, HasCancel);\n    }\n    ~OMPCancelStackRAII() { CGF.OMPCancelStack.exit(CGF); }\n  };\n\n  /// Returns calculated size of the specified type.\n  llvm::Value *getTypeSize(QualType Ty);\n  LValue InitCapturedStruct(const CapturedStmt &S);\n  llvm::Function *EmitCapturedStmt(const CapturedStmt &S, CapturedRegionKind K);\n  llvm::Function *GenerateCapturedStmtFunction(const CapturedStmt &S);\n  Address GenerateCapturedStmtArgument(const CapturedStmt &S);\n  llvm::Function *GenerateOpenMPCapturedStmtFunction(const CapturedStmt &S,\n                                                     SourceLocation Loc);\n  void GenerateOpenMPCapturedVars(const CapturedStmt &S,\n                                  SmallVectorImpl<llvm::Value *> &CapturedVars);\n  void emitOMPSimpleStore(LValue LVal, RValue RVal, QualType RValTy,\n                          SourceLocation Loc);\n  /// Perform element by element copying of arrays with type \\a\n  /// OriginalType from \\a SrcAddr to \\a DestAddr using copying procedure\n  /// generated by \\a CopyGen.\n  ///\n  /// \\param DestAddr Address of the destination array.\n  /// \\param SrcAddr Address of the source array.\n  /// \\param OriginalType Type of destination and source arrays.\n  /// \\param CopyGen Copying procedure that copies value of single array element\n  /// to another single array element.\n  void EmitOMPAggregateAssign(\n      Address DestAddr, Address SrcAddr, QualType OriginalType,\n      const llvm::function_ref<void(Address, Address)> CopyGen);\n  /// Emit proper copying of data from one variable to another.\n  ///\n  /// \\param OriginalType Original type of the copied variables.\n  /// \\param DestAddr Destination address.\n  /// \\param SrcAddr Source address.\n  /// \\param DestVD Destination variable used in \\a CopyExpr (for arrays, has\n  /// type of the base array element).\n  /// \\param SrcVD Source variable used in \\a CopyExpr (for arrays, has type of\n  /// the base array element).\n  /// \\param Copy Actual copygin expression for copying data from \\a SrcVD to \\a\n  /// DestVD.\n  void EmitOMPCopy(QualType OriginalType,\n                   Address DestAddr, Address SrcAddr,\n                   const VarDecl *DestVD, const VarDecl *SrcVD,\n                   const Expr *Copy);\n  /// Emit atomic update code for constructs: \\a X = \\a X \\a BO \\a E or\n  /// \\a X = \\a E \\a BO \\a E.\n  ///\n  /// \\param X Value to be updated.\n  /// \\param E Update value.\n  /// \\param BO Binary operation for update operation.\n  /// \\param IsXLHSInRHSPart true if \\a X is LHS in RHS part of the update\n  /// expression, false otherwise.\n  /// \\param AO Atomic ordering of the generated atomic instructions.\n  /// \\param CommonGen Code generator for complex expressions that cannot be\n  /// expressed through atomicrmw instruction.\n  /// \\returns <true, OldAtomicValue> if simple 'atomicrmw' instruction was\n  /// generated, <false, RValue::get(nullptr)> otherwise.\n  std::pair<bool, RValue> EmitOMPAtomicSimpleUpdateExpr(\n      LValue X, RValue E, BinaryOperatorKind BO, bool IsXLHSInRHSPart,\n      llvm::AtomicOrdering AO, SourceLocation Loc,\n      const llvm::function_ref<RValue(RValue)> CommonGen);\n  bool EmitOMPFirstprivateClause(const OMPExecutableDirective &D,\n                                 OMPPrivateScope &PrivateScope);\n  void EmitOMPPrivateClause(const OMPExecutableDirective &D,\n                            OMPPrivateScope &PrivateScope);\n  void EmitOMPUseDevicePtrClause(\n      const OMPUseDevicePtrClause &C, OMPPrivateScope &PrivateScope,\n      const llvm::DenseMap<const ValueDecl *, Address> &CaptureDeviceAddrMap);\n  void EmitOMPUseDeviceAddrClause(\n      const OMPUseDeviceAddrClause &C, OMPPrivateScope &PrivateScope,\n      const llvm::DenseMap<const ValueDecl *, Address> &CaptureDeviceAddrMap);\n  /// Emit code for copyin clause in \\a D directive. The next code is\n  /// generated at the start of outlined functions for directives:\n  /// \\code\n  /// threadprivate_var1 = master_threadprivate_var1;\n  /// operator=(threadprivate_var2, master_threadprivate_var2);\n  /// ...\n  /// __kmpc_barrier(&loc, global_tid);\n  /// \\endcode\n  ///\n  /// \\param D OpenMP directive possibly with 'copyin' clause(s).\n  /// \\returns true if at least one copyin variable is found, false otherwise.\n  bool EmitOMPCopyinClause(const OMPExecutableDirective &D);\n  /// Emit initial code for lastprivate variables. If some variable is\n  /// not also firstprivate, then the default initialization is used. Otherwise\n  /// initialization of this variable is performed by EmitOMPFirstprivateClause\n  /// method.\n  ///\n  /// \\param D Directive that may have 'lastprivate' directives.\n  /// \\param PrivateScope Private scope for capturing lastprivate variables for\n  /// proper codegen in internal captured statement.\n  ///\n  /// \\returns true if there is at least one lastprivate variable, false\n  /// otherwise.\n  bool EmitOMPLastprivateClauseInit(const OMPExecutableDirective &D,\n                                    OMPPrivateScope &PrivateScope);\n  /// Emit final copying of lastprivate values to original variables at\n  /// the end of the worksharing or simd directive.\n  ///\n  /// \\param D Directive that has at least one 'lastprivate' directives.\n  /// \\param IsLastIterCond Boolean condition that must be set to 'i1 true' if\n  /// it is the last iteration of the loop code in associated directive, or to\n  /// 'i1 false' otherwise. If this item is nullptr, no final check is required.\n  void EmitOMPLastprivateClauseFinal(const OMPExecutableDirective &D,\n                                     bool NoFinals,\n                                     llvm::Value *IsLastIterCond = nullptr);\n  /// Emit initial code for linear clauses.\n  void EmitOMPLinearClause(const OMPLoopDirective &D,\n                           CodeGenFunction::OMPPrivateScope &PrivateScope);\n  /// Emit final code for linear clauses.\n  /// \\param CondGen Optional conditional code for final part of codegen for\n  /// linear clause.\n  void EmitOMPLinearClauseFinal(\n      const OMPLoopDirective &D,\n      const llvm::function_ref<llvm::Value *(CodeGenFunction &)> CondGen);\n  /// Emit initial code for reduction variables. Creates reduction copies\n  /// and initializes them with the values according to OpenMP standard.\n  ///\n  /// \\param D Directive (possibly) with the 'reduction' clause.\n  /// \\param PrivateScope Private scope for capturing reduction variables for\n  /// proper codegen in internal captured statement.\n  ///\n  void EmitOMPReductionClauseInit(const OMPExecutableDirective &D,\n                                  OMPPrivateScope &PrivateScope,\n                                  bool ForInscan = false);\n  /// Emit final update of reduction values to original variables at\n  /// the end of the directive.\n  ///\n  /// \\param D Directive that has at least one 'reduction' directives.\n  /// \\param ReductionKind The kind of reduction to perform.\n  void EmitOMPReductionClauseFinal(const OMPExecutableDirective &D,\n                                   const OpenMPDirectiveKind ReductionKind);\n  /// Emit initial code for linear variables. Creates private copies\n  /// and initializes them with the values according to OpenMP standard.\n  ///\n  /// \\param D Directive (possibly) with the 'linear' clause.\n  /// \\return true if at least one linear variable is found that should be\n  /// initialized with the value of the original variable, false otherwise.\n  bool EmitOMPLinearClauseInit(const OMPLoopDirective &D);\n\n  typedef const llvm::function_ref<void(CodeGenFunction & /*CGF*/,\n                                        llvm::Function * /*OutlinedFn*/,\n                                        const OMPTaskDataTy & /*Data*/)>\n      TaskGenTy;\n  void EmitOMPTaskBasedDirective(const OMPExecutableDirective &S,\n                                 const OpenMPDirectiveKind CapturedRegion,\n                                 const RegionCodeGenTy &BodyGen,\n                                 const TaskGenTy &TaskGen, OMPTaskDataTy &Data);\n  struct OMPTargetDataInfo {\n    Address BasePointersArray = Address::invalid();\n    Address PointersArray = Address::invalid();\n    Address SizesArray = Address::invalid();\n    Address MappersArray = Address::invalid();\n    unsigned NumberOfTargetItems = 0;\n    explicit OMPTargetDataInfo() = default;\n    OMPTargetDataInfo(Address BasePointersArray, Address PointersArray,\n                      Address SizesArray, Address MappersArray,\n                      unsigned NumberOfTargetItems)\n        : BasePointersArray(BasePointersArray), PointersArray(PointersArray),\n          SizesArray(SizesArray), MappersArray(MappersArray),\n          NumberOfTargetItems(NumberOfTargetItems) {}\n  };\n  void EmitOMPTargetTaskBasedDirective(const OMPExecutableDirective &S,\n                                       const RegionCodeGenTy &BodyGen,\n                                       OMPTargetDataInfo &InputInfo);\n\n  void EmitOMPParallelDirective(const OMPParallelDirective &S);\n  void EmitOMPSimdDirective(const OMPSimdDirective &S);\n  void EmitOMPTileDirective(const OMPTileDirective &S);\n  void EmitOMPForDirective(const OMPForDirective &S);\n  void EmitOMPForSimdDirective(const OMPForSimdDirective &S);\n  void EmitOMPSectionsDirective(const OMPSectionsDirective &S);\n  void EmitOMPSectionDirective(const OMPSectionDirective &S);\n  void EmitOMPSingleDirective(const OMPSingleDirective &S);\n  void EmitOMPMasterDirective(const OMPMasterDirective &S);\n  void EmitOMPCriticalDirective(const OMPCriticalDirective &S);\n  void EmitOMPParallelForDirective(const OMPParallelForDirective &S);\n  void EmitOMPParallelForSimdDirective(const OMPParallelForSimdDirective &S);\n  void EmitOMPParallelSectionsDirective(const OMPParallelSectionsDirective &S);\n  void EmitOMPParallelMasterDirective(const OMPParallelMasterDirective &S);\n  void EmitOMPTaskDirective(const OMPTaskDirective &S);\n  void EmitOMPTaskyieldDirective(const OMPTaskyieldDirective &S);\n  void EmitOMPBarrierDirective(const OMPBarrierDirective &S);\n  void EmitOMPTaskwaitDirective(const OMPTaskwaitDirective &S);\n  void EmitOMPTaskgroupDirective(const OMPTaskgroupDirective &S);\n  void EmitOMPFlushDirective(const OMPFlushDirective &S);\n  void EmitOMPDepobjDirective(const OMPDepobjDirective &S);\n  void EmitOMPScanDirective(const OMPScanDirective &S);\n  void EmitOMPOrderedDirective(const OMPOrderedDirective &S);\n  void EmitOMPAtomicDirective(const OMPAtomicDirective &S);\n  void EmitOMPTargetDirective(const OMPTargetDirective &S);\n  void EmitOMPTargetDataDirective(const OMPTargetDataDirective &S);\n  void EmitOMPTargetEnterDataDirective(const OMPTargetEnterDataDirective &S);\n  void EmitOMPTargetExitDataDirective(const OMPTargetExitDataDirective &S);\n  void EmitOMPTargetUpdateDirective(const OMPTargetUpdateDirective &S);\n  void EmitOMPTargetParallelDirective(const OMPTargetParallelDirective &S);\n  void\n  EmitOMPTargetParallelForDirective(const OMPTargetParallelForDirective &S);\n  void EmitOMPTeamsDirective(const OMPTeamsDirective &S);\n  void\n  EmitOMPCancellationPointDirective(const OMPCancellationPointDirective &S);\n  void EmitOMPCancelDirective(const OMPCancelDirective &S);\n  void EmitOMPTaskLoopBasedDirective(const OMPLoopDirective &S);\n  void EmitOMPTaskLoopDirective(const OMPTaskLoopDirective &S);\n  void EmitOMPTaskLoopSimdDirective(const OMPTaskLoopSimdDirective &S);\n  void EmitOMPMasterTaskLoopDirective(const OMPMasterTaskLoopDirective &S);\n  void\n  EmitOMPMasterTaskLoopSimdDirective(const OMPMasterTaskLoopSimdDirective &S);\n  void EmitOMPParallelMasterTaskLoopDirective(\n      const OMPParallelMasterTaskLoopDirective &S);\n  void EmitOMPParallelMasterTaskLoopSimdDirective(\n      const OMPParallelMasterTaskLoopSimdDirective &S);\n  void EmitOMPDistributeDirective(const OMPDistributeDirective &S);\n  void EmitOMPDistributeParallelForDirective(\n      const OMPDistributeParallelForDirective &S);\n  void EmitOMPDistributeParallelForSimdDirective(\n      const OMPDistributeParallelForSimdDirective &S);\n  void EmitOMPDistributeSimdDirective(const OMPDistributeSimdDirective &S);\n  void EmitOMPTargetParallelForSimdDirective(\n      const OMPTargetParallelForSimdDirective &S);\n  void EmitOMPTargetSimdDirective(const OMPTargetSimdDirective &S);\n  void EmitOMPTeamsDistributeDirective(const OMPTeamsDistributeDirective &S);\n  void\n  EmitOMPTeamsDistributeSimdDirective(const OMPTeamsDistributeSimdDirective &S);\n  void EmitOMPTeamsDistributeParallelForSimdDirective(\n      const OMPTeamsDistributeParallelForSimdDirective &S);\n  void EmitOMPTeamsDistributeParallelForDirective(\n      const OMPTeamsDistributeParallelForDirective &S);\n  void EmitOMPTargetTeamsDirective(const OMPTargetTeamsDirective &S);\n  void EmitOMPTargetTeamsDistributeDirective(\n      const OMPTargetTeamsDistributeDirective &S);\n  void EmitOMPTargetTeamsDistributeParallelForDirective(\n      const OMPTargetTeamsDistributeParallelForDirective &S);\n  void EmitOMPTargetTeamsDistributeParallelForSimdDirective(\n      const OMPTargetTeamsDistributeParallelForSimdDirective &S);\n  void EmitOMPTargetTeamsDistributeSimdDirective(\n      const OMPTargetTeamsDistributeSimdDirective &S);\n\n  /// Emit device code for the target directive.\n  static void EmitOMPTargetDeviceFunction(CodeGenModule &CGM,\n                                          StringRef ParentName,\n                                          const OMPTargetDirective &S);\n  static void\n  EmitOMPTargetParallelDeviceFunction(CodeGenModule &CGM, StringRef ParentName,\n                                      const OMPTargetParallelDirective &S);\n  /// Emit device code for the target parallel for directive.\n  static void EmitOMPTargetParallelForDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetParallelForDirective &S);\n  /// Emit device code for the target parallel for simd directive.\n  static void EmitOMPTargetParallelForSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetParallelForSimdDirective &S);\n  /// Emit device code for the target teams directive.\n  static void\n  EmitOMPTargetTeamsDeviceFunction(CodeGenModule &CGM, StringRef ParentName,\n                                   const OMPTargetTeamsDirective &S);\n  /// Emit device code for the target teams distribute directive.\n  static void EmitOMPTargetTeamsDistributeDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeDirective &S);\n  /// Emit device code for the target teams distribute simd directive.\n  static void EmitOMPTargetTeamsDistributeSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeSimdDirective &S);\n  /// Emit device code for the target simd directive.\n  static void EmitOMPTargetSimdDeviceFunction(CodeGenModule &CGM,\n                                              StringRef ParentName,\n                                              const OMPTargetSimdDirective &S);\n  /// Emit device code for the target teams distribute parallel for simd\n  /// directive.\n  static void EmitOMPTargetTeamsDistributeParallelForSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeParallelForSimdDirective &S);\n\n  static void EmitOMPTargetTeamsDistributeParallelForDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeParallelForDirective &S);\n\n  /// Emit the Stmt \\p S and return its topmost canonical loop, if any.\n  /// TODO: The \\p Depth paramter is not yet implemented and must be 1. In the\n  /// future it is meant to be the number of loops expected in the loop nests\n  /// (usually specified by the \"collapse\" clause) that are collapsed to a\n  /// single loop by this function.\n  llvm::CanonicalLoopInfo *EmitOMPCollapsedCanonicalLoopNest(const Stmt *S,\n                                                             int Depth);\n\n  /// Emit an OMPCanonicalLoop using the OpenMPIRBuilder.\n  void EmitOMPCanonicalLoop(const OMPCanonicalLoop *S);\n\n  /// Emit inner loop of the worksharing/simd construct.\n  ///\n  /// \\param S Directive, for which the inner loop must be emitted.\n  /// \\param RequiresCleanup true, if directive has some associated private\n  /// variables.\n  /// \\param LoopCond Bollean condition for loop continuation.\n  /// \\param IncExpr Increment expression for loop control variable.\n  /// \\param BodyGen Generator for the inner body of the inner loop.\n  /// \\param PostIncGen Genrator for post-increment code (required for ordered\n  /// loop directvies).\n  void EmitOMPInnerLoop(\n      const OMPExecutableDirective &S, bool RequiresCleanup,\n      const Expr *LoopCond, const Expr *IncExpr,\n      const llvm::function_ref<void(CodeGenFunction &)> BodyGen,\n      const llvm::function_ref<void(CodeGenFunction &)> PostIncGen);\n\n  JumpDest getOMPCancelDestination(OpenMPDirectiveKind Kind);\n  /// Emit initial code for loop counters of loop-based directives.\n  void EmitOMPPrivateLoopCounters(const OMPLoopDirective &S,\n                                  OMPPrivateScope &LoopScope);\n\n  /// Helper for the OpenMP loop directives.\n  void EmitOMPLoopBody(const OMPLoopDirective &D, JumpDest LoopExit);\n\n  /// Emit code for the worksharing loop-based directive.\n  /// \\return true, if this construct has any lastprivate clause, false -\n  /// otherwise.\n  bool EmitOMPWorksharingLoop(const OMPLoopDirective &S, Expr *EUB,\n                              const CodeGenLoopBoundsTy &CodeGenLoopBounds,\n                              const CodeGenDispatchBoundsTy &CGDispatchBounds);\n\n  /// Emit code for the distribute loop-based directive.\n  void EmitOMPDistributeLoop(const OMPLoopDirective &S,\n                             const CodeGenLoopTy &CodeGenLoop, Expr *IncExpr);\n\n  /// Helpers for the OpenMP loop directives.\n  void EmitOMPSimdInit(const OMPLoopDirective &D, bool IsMonotonic = false);\n  void EmitOMPSimdFinal(\n      const OMPLoopDirective &D,\n      const llvm::function_ref<llvm::Value *(CodeGenFunction &)> CondGen);\n\n  /// Emits the lvalue for the expression with possibly captured variable.\n  LValue EmitOMPSharedLValue(const Expr *E);\n\nprivate:\n  /// Helpers for blocks.\n  llvm::Value *EmitBlockLiteral(const CGBlockInfo &Info);\n\n  /// struct with the values to be passed to the OpenMP loop-related functions\n  struct OMPLoopArguments {\n    /// loop lower bound\n    Address LB = Address::invalid();\n    /// loop upper bound\n    Address UB = Address::invalid();\n    /// loop stride\n    Address ST = Address::invalid();\n    /// isLastIteration argument for runtime functions\n    Address IL = Address::invalid();\n    /// Chunk value generated by sema\n    llvm::Value *Chunk = nullptr;\n    /// EnsureUpperBound\n    Expr *EUB = nullptr;\n    /// IncrementExpression\n    Expr *IncExpr = nullptr;\n    /// Loop initialization\n    Expr *Init = nullptr;\n    /// Loop exit condition\n    Expr *Cond = nullptr;\n    /// Update of LB after a whole chunk has been executed\n    Expr *NextLB = nullptr;\n    /// Update of UB after a whole chunk has been executed\n    Expr *NextUB = nullptr;\n    OMPLoopArguments() = default;\n    OMPLoopArguments(Address LB, Address UB, Address ST, Address IL,\n                     llvm::Value *Chunk = nullptr, Expr *EUB = nullptr,\n                     Expr *IncExpr = nullptr, Expr *Init = nullptr,\n                     Expr *Cond = nullptr, Expr *NextLB = nullptr,\n                     Expr *NextUB = nullptr)\n        : LB(LB), UB(UB), ST(ST), IL(IL), Chunk(Chunk), EUB(EUB),\n          IncExpr(IncExpr), Init(Init), Cond(Cond), NextLB(NextLB),\n          NextUB(NextUB) {}\n  };\n  void EmitOMPOuterLoop(bool DynamicOrOrdered, bool IsMonotonic,\n                        const OMPLoopDirective &S, OMPPrivateScope &LoopScope,\n                        const OMPLoopArguments &LoopArgs,\n                        const CodeGenLoopTy &CodeGenLoop,\n                        const CodeGenOrderedTy &CodeGenOrdered);\n  void EmitOMPForOuterLoop(const OpenMPScheduleTy &ScheduleKind,\n                           bool IsMonotonic, const OMPLoopDirective &S,\n                           OMPPrivateScope &LoopScope, bool Ordered,\n                           const OMPLoopArguments &LoopArgs,\n                           const CodeGenDispatchBoundsTy &CGDispatchBounds);\n  void EmitOMPDistributeOuterLoop(OpenMPDistScheduleClauseKind ScheduleKind,\n                                  const OMPLoopDirective &S,\n                                  OMPPrivateScope &LoopScope,\n                                  const OMPLoopArguments &LoopArgs,\n                                  const CodeGenLoopTy &CodeGenLoopContent);\n  /// Emit code for sections directive.\n  void EmitSections(const OMPExecutableDirective &S);\n\npublic:\n\n  //===--------------------------------------------------------------------===//\n  //                         LValue Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  /// Create a check that a scalar RValue is non-null.\n  llvm::Value *EmitNonNullRValueCheck(RValue RV, QualType T);\n\n  /// GetUndefRValue - Get an appropriate 'undef' rvalue for the given type.\n  RValue GetUndefRValue(QualType Ty);\n\n  /// EmitUnsupportedRValue - Emit a dummy r-value using the type of E\n  /// and issue an ErrorUnsupported style diagnostic (using the\n  /// provided Name).\n  RValue EmitUnsupportedRValue(const Expr *E,\n                               const char *Name);\n\n  /// EmitUnsupportedLValue - Emit a dummy l-value using the type of E and issue\n  /// an ErrorUnsupported style diagnostic (using the provided Name).\n  LValue EmitUnsupportedLValue(const Expr *E,\n                               const char *Name);\n\n  /// EmitLValue - Emit code to compute a designator that specifies the location\n  /// of the expression.\n  ///\n  /// This can return one of two things: a simple address or a bitfield\n  /// reference.  In either case, the LLVM Value* in the LValue structure is\n  /// guaranteed to be an LLVM pointer type.\n  ///\n  /// If this returns a bitfield reference, nothing about the pointee type of\n  /// the LLVM value is known: For example, it may not be a pointer to an\n  /// integer.\n  ///\n  /// If this returns a normal address, and if the lvalue's C type is fixed\n  /// size, this method guarantees that the returned pointer type will point to\n  /// an LLVM type of the same size of the lvalue's type.  If the lvalue has a\n  /// variable length type, this is not possible.\n  ///\n  LValue EmitLValue(const Expr *E);\n\n  /// Same as EmitLValue but additionally we generate checking code to\n  /// guard against undefined behavior.  This is only suitable when we know\n  /// that the address will be used to access the object.\n  LValue EmitCheckedLValue(const Expr *E, TypeCheckKind TCK);\n\n  RValue convertTempToRValue(Address addr, QualType type,\n                             SourceLocation Loc);\n\n  void EmitAtomicInit(Expr *E, LValue lvalue);\n\n  bool LValueIsSuitableForInlineAtomic(LValue Src);\n\n  RValue EmitAtomicLoad(LValue LV, SourceLocation SL,\n                        AggValueSlot Slot = AggValueSlot::ignored());\n\n  RValue EmitAtomicLoad(LValue lvalue, SourceLocation loc,\n                        llvm::AtomicOrdering AO, bool IsVolatile = false,\n                        AggValueSlot slot = AggValueSlot::ignored());\n\n  void EmitAtomicStore(RValue rvalue, LValue lvalue, bool isInit);\n\n  void EmitAtomicStore(RValue rvalue, LValue lvalue, llvm::AtomicOrdering AO,\n                       bool IsVolatile, bool isInit);\n\n  std::pair<RValue, llvm::Value *> EmitAtomicCompareExchange(\n      LValue Obj, RValue Expected, RValue Desired, SourceLocation Loc,\n      llvm::AtomicOrdering Success =\n          llvm::AtomicOrdering::SequentiallyConsistent,\n      llvm::AtomicOrdering Failure =\n          llvm::AtomicOrdering::SequentiallyConsistent,\n      bool IsWeak = false, AggValueSlot Slot = AggValueSlot::ignored());\n\n  void EmitAtomicUpdate(LValue LVal, llvm::AtomicOrdering AO,\n                        const llvm::function_ref<RValue(RValue)> &UpdateOp,\n                        bool IsVolatile);\n\n  /// EmitToMemory - Change a scalar value from its value\n  /// representation to its in-memory representation.\n  llvm::Value *EmitToMemory(llvm::Value *Value, QualType Ty);\n\n  /// EmitFromMemory - Change a scalar value from its memory\n  /// representation to its value representation.\n  llvm::Value *EmitFromMemory(llvm::Value *Value, QualType Ty);\n\n  /// Check if the scalar \\p Value is within the valid range for the given\n  /// type \\p Ty.\n  ///\n  /// Returns true if a check is needed (even if the range is unknown).\n  bool EmitScalarRangeCheck(llvm::Value *Value, QualType Ty,\n                            SourceLocation Loc);\n\n  /// EmitLoadOfScalar - Load a scalar value from an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.\n  llvm::Value *EmitLoadOfScalar(Address Addr, bool Volatile, QualType Ty,\n                                SourceLocation Loc,\n                                AlignmentSource Source = AlignmentSource::Type,\n                                bool isNontemporal = false) {\n    return EmitLoadOfScalar(Addr, Volatile, Ty, Loc, LValueBaseInfo(Source),\n                            CGM.getTBAAAccessInfo(Ty), isNontemporal);\n  }\n\n  llvm::Value *EmitLoadOfScalar(Address Addr, bool Volatile, QualType Ty,\n                                SourceLocation Loc, LValueBaseInfo BaseInfo,\n                                TBAAAccessInfo TBAAInfo,\n                                bool isNontemporal = false);\n\n  /// EmitLoadOfScalar - Load a scalar value from an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.  The l-value must be a simple\n  /// l-value.\n  llvm::Value *EmitLoadOfScalar(LValue lvalue, SourceLocation Loc);\n\n  /// EmitStoreOfScalar - Store a scalar value to an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.\n  void EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                         bool Volatile, QualType Ty,\n                         AlignmentSource Source = AlignmentSource::Type,\n                         bool isInit = false, bool isNontemporal = false) {\n    EmitStoreOfScalar(Value, Addr, Volatile, Ty, LValueBaseInfo(Source),\n                      CGM.getTBAAAccessInfo(Ty), isInit, isNontemporal);\n  }\n\n  void EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                         bool Volatile, QualType Ty,\n                         LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo,\n                         bool isInit = false, bool isNontemporal = false);\n\n  /// EmitStoreOfScalar - Store a scalar value to an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.  The l-value must be a simple\n  /// l-value.  The isInit flag indicates whether this is an initialization.\n  /// If so, atomic qualifiers are ignored and the store is always non-atomic.\n  void EmitStoreOfScalar(llvm::Value *value, LValue lvalue, bool isInit=false);\n\n  /// EmitLoadOfLValue - Given an expression that represents a value lvalue,\n  /// this method emits the address of the lvalue, then loads the result as an\n  /// rvalue, returning the rvalue.\n  RValue EmitLoadOfLValue(LValue V, SourceLocation Loc);\n  RValue EmitLoadOfExtVectorElementLValue(LValue V);\n  RValue EmitLoadOfBitfieldLValue(LValue LV, SourceLocation Loc);\n  RValue EmitLoadOfGlobalRegLValue(LValue LV);\n\n  /// EmitStoreThroughLValue - Store the specified rvalue into the specified\n  /// lvalue, where both are guaranteed to the have the same type, and that type\n  /// is 'Ty'.\n  void EmitStoreThroughLValue(RValue Src, LValue Dst, bool isInit = false);\n  void EmitStoreThroughExtVectorComponentLValue(RValue Src, LValue Dst);\n  void EmitStoreThroughGlobalRegLValue(RValue Src, LValue Dst);\n\n  /// EmitStoreThroughBitfieldLValue - Store Src into Dst with same constraints\n  /// as EmitStoreThroughLValue.\n  ///\n  /// \\param Result [out] - If non-null, this will be set to a Value* for the\n  /// bit-field contents after the store, appropriate for use as the result of\n  /// an assignment to the bit-field.\n  void EmitStoreThroughBitfieldLValue(RValue Src, LValue Dst,\n                                      llvm::Value **Result=nullptr);\n\n  /// Emit an l-value for an assignment (simple or compound) of complex type.\n  LValue EmitComplexAssignmentLValue(const BinaryOperator *E);\n  LValue EmitComplexCompoundAssignmentLValue(const CompoundAssignOperator *E);\n  LValue EmitScalarCompoundAssignWithComplex(const CompoundAssignOperator *E,\n                                             llvm::Value *&Result);\n\n  // Note: only available for agg return types\n  LValue EmitBinaryOperatorLValue(const BinaryOperator *E);\n  LValue EmitCompoundAssignmentLValue(const CompoundAssignOperator *E);\n  // Note: only available for agg return types\n  LValue EmitCallExprLValue(const CallExpr *E);\n  // Note: only available for agg return types\n  LValue EmitVAArgExprLValue(const VAArgExpr *E);\n  LValue EmitDeclRefLValue(const DeclRefExpr *E);\n  LValue EmitStringLiteralLValue(const StringLiteral *E);\n  LValue EmitObjCEncodeExprLValue(const ObjCEncodeExpr *E);\n  LValue EmitPredefinedLValue(const PredefinedExpr *E);\n  LValue EmitUnaryOpLValue(const UnaryOperator *E);\n  LValue EmitArraySubscriptExpr(const ArraySubscriptExpr *E,\n                                bool Accessed = false);\n  LValue EmitMatrixSubscriptExpr(const MatrixSubscriptExpr *E);\n  LValue EmitOMPArraySectionExpr(const OMPArraySectionExpr *E,\n                                 bool IsLowerBound = true);\n  LValue EmitExtVectorElementExpr(const ExtVectorElementExpr *E);\n  LValue EmitMemberExpr(const MemberExpr *E);\n  LValue EmitObjCIsaExpr(const ObjCIsaExpr *E);\n  LValue EmitCompoundLiteralLValue(const CompoundLiteralExpr *E);\n  LValue EmitInitListLValue(const InitListExpr *E);\n  LValue EmitConditionalOperatorLValue(const AbstractConditionalOperator *E);\n  LValue EmitCastLValue(const CastExpr *E);\n  LValue EmitMaterializeTemporaryExpr(const MaterializeTemporaryExpr *E);\n  LValue EmitOpaqueValueLValue(const OpaqueValueExpr *e);\n\n  Address EmitExtVectorElementLValue(LValue V);\n\n  RValue EmitRValueForField(LValue LV, const FieldDecl *FD, SourceLocation Loc);\n\n  Address EmitArrayToPointerDecay(const Expr *Array,\n                                  LValueBaseInfo *BaseInfo = nullptr,\n                                  TBAAAccessInfo *TBAAInfo = nullptr);\n\n  class ConstantEmission {\n    llvm::PointerIntPair<llvm::Constant*, 1, bool> ValueAndIsReference;\n    ConstantEmission(llvm::Constant *C, bool isReference)\n      : ValueAndIsReference(C, isReference) {}\n  public:\n    ConstantEmission() {}\n    static ConstantEmission forReference(llvm::Constant *C) {\n      return ConstantEmission(C, true);\n    }\n    static ConstantEmission forValue(llvm::Constant *C) {\n      return ConstantEmission(C, false);\n    }\n\n    explicit operator bool() const {\n      return ValueAndIsReference.getOpaqueValue() != nullptr;\n    }\n\n    bool isReference() const { return ValueAndIsReference.getInt(); }\n    LValue getReferenceLValue(CodeGenFunction &CGF, Expr *refExpr) const {\n      assert(isReference());\n      return CGF.MakeNaturalAlignAddrLValue(ValueAndIsReference.getPointer(),\n                                            refExpr->getType());\n    }\n\n    llvm::Constant *getValue() const {\n      assert(!isReference());\n      return ValueAndIsReference.getPointer();\n    }\n  };\n\n  ConstantEmission tryEmitAsConstant(DeclRefExpr *refExpr);\n  ConstantEmission tryEmitAsConstant(const MemberExpr *ME);\n  llvm::Value *emitScalarConstant(const ConstantEmission &Constant, Expr *E);\n\n  RValue EmitPseudoObjectRValue(const PseudoObjectExpr *e,\n                                AggValueSlot slot = AggValueSlot::ignored());\n  LValue EmitPseudoObjectLValue(const PseudoObjectExpr *e);\n\n  llvm::Value *EmitIvarOffset(const ObjCInterfaceDecl *Interface,\n                              const ObjCIvarDecl *Ivar);\n  LValue EmitLValueForField(LValue Base, const FieldDecl* Field);\n  LValue EmitLValueForLambdaField(const FieldDecl *Field);\n\n  /// EmitLValueForFieldInitialization - Like EmitLValueForField, except that\n  /// if the Field is a reference, this will return the address of the reference\n  /// and not the address of the value stored in the reference.\n  LValue EmitLValueForFieldInitialization(LValue Base,\n                                          const FieldDecl* Field);\n\n  LValue EmitLValueForIvar(QualType ObjectTy,\n                           llvm::Value* Base, const ObjCIvarDecl *Ivar,\n                           unsigned CVRQualifiers);\n\n  LValue EmitCXXConstructLValue(const CXXConstructExpr *E);\n  LValue EmitCXXBindTemporaryLValue(const CXXBindTemporaryExpr *E);\n  LValue EmitCXXTypeidLValue(const CXXTypeidExpr *E);\n  LValue EmitCXXUuidofLValue(const CXXUuidofExpr *E);\n\n  LValue EmitObjCMessageExprLValue(const ObjCMessageExpr *E);\n  LValue EmitObjCIvarRefLValue(const ObjCIvarRefExpr *E);\n  LValue EmitStmtExprLValue(const StmtExpr *E);\n  LValue EmitPointerToDataMemberBinaryExpr(const BinaryOperator *E);\n  LValue EmitObjCSelectorLValue(const ObjCSelectorExpr *E);\n  void   EmitDeclRefExprDbgValue(const DeclRefExpr *E, const APValue &Init);\n\n  //===--------------------------------------------------------------------===//\n  //                         Scalar Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitCall - Generate a call of the given function, expecting the given\n  /// result type, and using the given argument list which specifies both the\n  /// LLVM arguments and the types they were derived from.\n  RValue EmitCall(const CGFunctionInfo &CallInfo, const CGCallee &Callee,\n                  ReturnValueSlot ReturnValue, const CallArgList &Args,\n                  llvm::CallBase **callOrInvoke, SourceLocation Loc);\n  RValue EmitCall(const CGFunctionInfo &CallInfo, const CGCallee &Callee,\n                  ReturnValueSlot ReturnValue, const CallArgList &Args,\n                  llvm::CallBase **callOrInvoke = nullptr) {\n    return EmitCall(CallInfo, Callee, ReturnValue, Args, callOrInvoke,\n                    SourceLocation());\n  }\n  RValue EmitCall(QualType FnType, const CGCallee &Callee, const CallExpr *E,\n                  ReturnValueSlot ReturnValue, llvm::Value *Chain = nullptr);\n  RValue EmitCallExpr(const CallExpr *E,\n                      ReturnValueSlot ReturnValue = ReturnValueSlot());\n  RValue EmitSimpleCallExpr(const CallExpr *E, ReturnValueSlot ReturnValue);\n  CGCallee EmitCallee(const Expr *E);\n\n  void checkTargetFeatures(const CallExpr *E, const FunctionDecl *TargetDecl);\n  void checkTargetFeatures(SourceLocation Loc, const FunctionDecl *TargetDecl);\n\n  llvm::CallInst *EmitRuntimeCall(llvm::FunctionCallee callee,\n                                  const Twine &name = \"\");\n  llvm::CallInst *EmitRuntimeCall(llvm::FunctionCallee callee,\n                                  ArrayRef<llvm::Value *> args,\n                                  const Twine &name = \"\");\n  llvm::CallInst *EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                          const Twine &name = \"\");\n  llvm::CallInst *EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                          ArrayRef<llvm::Value *> args,\n                                          const Twine &name = \"\");\n\n  SmallVector<llvm::OperandBundleDef, 1>\n  getBundlesForFunclet(llvm::Value *Callee);\n\n  llvm::CallBase *EmitCallOrInvoke(llvm::FunctionCallee Callee,\n                                   ArrayRef<llvm::Value *> Args,\n                                   const Twine &Name = \"\");\n  llvm::CallBase *EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                          ArrayRef<llvm::Value *> args,\n                                          const Twine &name = \"\");\n  llvm::CallBase *EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                          const Twine &name = \"\");\n  void EmitNoreturnRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                       ArrayRef<llvm::Value *> args);\n\n  CGCallee BuildAppleKextVirtualCall(const CXXMethodDecl *MD,\n                                     NestedNameSpecifier *Qual,\n                                     llvm::Type *Ty);\n\n  CGCallee BuildAppleKextVirtualDestructorCall(const CXXDestructorDecl *DD,\n                                               CXXDtorType Type,\n                                               const CXXRecordDecl *RD);\n\n  // Return the copy constructor name with the prefix \"__copy_constructor_\"\n  // removed.\n  static std::string getNonTrivialCopyConstructorStr(QualType QT,\n                                                     CharUnits Alignment,\n                                                     bool IsVolatile,\n                                                     ASTContext &Ctx);\n\n  // Return the destructor name with the prefix \"__destructor_\" removed.\n  static std::string getNonTrivialDestructorStr(QualType QT,\n                                                CharUnits Alignment,\n                                                bool IsVolatile,\n                                                ASTContext &Ctx);\n\n  // These functions emit calls to the special functions of non-trivial C\n  // structs.\n  void defaultInitNonTrivialCStructVar(LValue Dst);\n  void callCStructDefaultConstructor(LValue Dst);\n  void callCStructDestructor(LValue Dst);\n  void callCStructCopyConstructor(LValue Dst, LValue Src);\n  void callCStructMoveConstructor(LValue Dst, LValue Src);\n  void callCStructCopyAssignmentOperator(LValue Dst, LValue Src);\n  void callCStructMoveAssignmentOperator(LValue Dst, LValue Src);\n\n  RValue\n  EmitCXXMemberOrOperatorCall(const CXXMethodDecl *Method,\n                              const CGCallee &Callee,\n                              ReturnValueSlot ReturnValue, llvm::Value *This,\n                              llvm::Value *ImplicitParam,\n                              QualType ImplicitParamTy, const CallExpr *E,\n                              CallArgList *RtlArgs);\n  RValue EmitCXXDestructorCall(GlobalDecl Dtor, const CGCallee &Callee,\n                               llvm::Value *This, QualType ThisTy,\n                               llvm::Value *ImplicitParam,\n                               QualType ImplicitParamTy, const CallExpr *E);\n  RValue EmitCXXMemberCallExpr(const CXXMemberCallExpr *E,\n                               ReturnValueSlot ReturnValue);\n  RValue EmitCXXMemberOrOperatorMemberCallExpr(const CallExpr *CE,\n                                               const CXXMethodDecl *MD,\n                                               ReturnValueSlot ReturnValue,\n                                               bool HasQualifier,\n                                               NestedNameSpecifier *Qualifier,\n                                               bool IsArrow, const Expr *Base);\n  // Compute the object pointer.\n  Address EmitCXXMemberDataPointerAddress(const Expr *E, Address base,\n                                          llvm::Value *memberPtr,\n                                          const MemberPointerType *memberPtrType,\n                                          LValueBaseInfo *BaseInfo = nullptr,\n                                          TBAAAccessInfo *TBAAInfo = nullptr);\n  RValue EmitCXXMemberPointerCallExpr(const CXXMemberCallExpr *E,\n                                      ReturnValueSlot ReturnValue);\n\n  RValue EmitCXXOperatorMemberCallExpr(const CXXOperatorCallExpr *E,\n                                       const CXXMethodDecl *MD,\n                                       ReturnValueSlot ReturnValue);\n  RValue EmitCXXPseudoDestructorExpr(const CXXPseudoDestructorExpr *E);\n\n  RValue EmitCUDAKernelCallExpr(const CUDAKernelCallExpr *E,\n                                ReturnValueSlot ReturnValue);\n\n  RValue EmitNVPTXDevicePrintfCallExpr(const CallExpr *E,\n                                       ReturnValueSlot ReturnValue);\n  RValue EmitAMDGPUDevicePrintfCallExpr(const CallExpr *E,\n                                        ReturnValueSlot ReturnValue);\n\n  RValue EmitBuiltinExpr(const GlobalDecl GD, unsigned BuiltinID,\n                         const CallExpr *E, ReturnValueSlot ReturnValue);\n\n  RValue emitRotate(const CallExpr *E, bool IsRotateRight);\n\n  /// Emit IR for __builtin_os_log_format.\n  RValue emitBuiltinOSLogFormat(const CallExpr &E);\n\n  /// Emit IR for __builtin_is_aligned.\n  RValue EmitBuiltinIsAligned(const CallExpr *E);\n  /// Emit IR for __builtin_align_up/__builtin_align_down.\n  RValue EmitBuiltinAlignTo(const CallExpr *E, bool AlignUp);\n\n  llvm::Function *generateBuiltinOSLogHelperFunction(\n      const analyze_os_log::OSLogBufferLayout &Layout,\n      CharUnits BufferAlignment);\n\n  RValue EmitBlockCallExpr(const CallExpr *E, ReturnValueSlot ReturnValue);\n\n  /// EmitTargetBuiltinExpr - Emit the given builtin call. Returns 0 if the call\n  /// is unhandled by the current target.\n  llvm::Value *EmitTargetBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue);\n\n  llvm::Value *EmitAArch64CompareBuiltinExpr(llvm::Value *Op, llvm::Type *Ty,\n                                             const llvm::CmpInst::Predicate Fp,\n                                             const llvm::CmpInst::Predicate Ip,\n                                             const llvm::Twine &Name = \"\");\n  llvm::Value *EmitARMBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                  ReturnValueSlot ReturnValue,\n                                  llvm::Triple::ArchType Arch);\n  llvm::Value *EmitARMMVEBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue,\n                                     llvm::Triple::ArchType Arch);\n  llvm::Value *EmitARMCDEBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue,\n                                     llvm::Triple::ArchType Arch);\n  llvm::Value *EmitCMSEClearRecord(llvm::Value *V, llvm::IntegerType *ITy,\n                                   QualType RTy);\n  llvm::Value *EmitCMSEClearRecord(llvm::Value *V, llvm::ArrayType *ATy,\n                                   QualType RTy);\n\n  llvm::Value *EmitCommonNeonBuiltinExpr(unsigned BuiltinID,\n                                         unsigned LLVMIntrinsic,\n                                         unsigned AltLLVMIntrinsic,\n                                         const char *NameHint,\n                                         unsigned Modifier,\n                                         const CallExpr *E,\n                                         SmallVectorImpl<llvm::Value *> &Ops,\n                                         Address PtrOp0, Address PtrOp1,\n                                         llvm::Triple::ArchType Arch);\n\n  llvm::Function *LookupNeonLLVMIntrinsic(unsigned IntrinsicID,\n                                          unsigned Modifier, llvm::Type *ArgTy,\n                                          const CallExpr *E);\n  llvm::Value *EmitNeonCall(llvm::Function *F,\n                            SmallVectorImpl<llvm::Value*> &O,\n                            const char *name,\n                            unsigned shift = 0, bool rightshift = false);\n  llvm::Value *EmitNeonSplat(llvm::Value *V, llvm::Constant *Idx,\n                             const llvm::ElementCount &Count);\n  llvm::Value *EmitNeonSplat(llvm::Value *V, llvm::Constant *Idx);\n  llvm::Value *EmitNeonShiftVector(llvm::Value *V, llvm::Type *Ty,\n                                   bool negateForRightShift);\n  llvm::Value *EmitNeonRShiftImm(llvm::Value *Vec, llvm::Value *Amt,\n                                 llvm::Type *Ty, bool usgn, const char *name);\n  llvm::Value *vectorWrapScalar16(llvm::Value *Op);\n  /// SVEBuiltinMemEltTy - Returns the memory element type for this memory\n  /// access builtin.  Only required if it can't be inferred from the base\n  /// pointer operand.\n  llvm::Type *SVEBuiltinMemEltTy(SVETypeFlags TypeFlags);\n\n  SmallVector<llvm::Type *, 2> getSVEOverloadTypes(SVETypeFlags TypeFlags,\n                                                   llvm::Type *ReturnType,\n                                                   ArrayRef<llvm::Value *> Ops);\n  llvm::Type *getEltType(SVETypeFlags TypeFlags);\n  llvm::ScalableVectorType *getSVEType(const SVETypeFlags &TypeFlags);\n  llvm::ScalableVectorType *getSVEPredType(SVETypeFlags TypeFlags);\n  llvm::Value *EmitSVEAllTruePred(SVETypeFlags TypeFlags);\n  llvm::Value *EmitSVEDupX(llvm::Value *Scalar);\n  llvm::Value *EmitSVEDupX(llvm::Value *Scalar, llvm::Type *Ty);\n  llvm::Value *EmitSVEReinterpret(llvm::Value *Val, llvm::Type *Ty);\n  llvm::Value *EmitSVEPMull(SVETypeFlags TypeFlags,\n                            llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                            unsigned BuiltinID);\n  llvm::Value *EmitSVEMovl(SVETypeFlags TypeFlags,\n                           llvm::ArrayRef<llvm::Value *> Ops,\n                           unsigned BuiltinID);\n  llvm::Value *EmitSVEPredicateCast(llvm::Value *Pred,\n                                    llvm::ScalableVectorType *VTy);\n  llvm::Value *EmitSVEGatherLoad(SVETypeFlags TypeFlags,\n                                 llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                                 unsigned IntID);\n  llvm::Value *EmitSVEScatterStore(SVETypeFlags TypeFlags,\n                                   llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                                   unsigned IntID);\n  llvm::Value *EmitSVEMaskedLoad(const CallExpr *, llvm::Type *ReturnTy,\n                                 SmallVectorImpl<llvm::Value *> &Ops,\n                                 unsigned BuiltinID, bool IsZExtReturn);\n  llvm::Value *EmitSVEMaskedStore(const CallExpr *,\n                                  SmallVectorImpl<llvm::Value *> &Ops,\n                                  unsigned BuiltinID);\n  llvm::Value *EmitSVEPrefetchLoad(SVETypeFlags TypeFlags,\n                                   SmallVectorImpl<llvm::Value *> &Ops,\n                                   unsigned BuiltinID);\n  llvm::Value *EmitSVEGatherPrefetch(SVETypeFlags TypeFlags,\n                                     SmallVectorImpl<llvm::Value *> &Ops,\n                                     unsigned IntID);\n  llvm::Value *EmitSVEStructLoad(SVETypeFlags TypeFlags,\n                                 SmallVectorImpl<llvm::Value *> &Ops, unsigned IntID);\n  llvm::Value *EmitSVEStructStore(SVETypeFlags TypeFlags,\n                                  SmallVectorImpl<llvm::Value *> &Ops,\n                                  unsigned IntID);\n  llvm::Value *EmitAArch64SVEBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n\n  llvm::Value *EmitAArch64BuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                      llvm::Triple::ArchType Arch);\n  llvm::Value *EmitBPFBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n\n  llvm::Value *BuildVector(ArrayRef<llvm::Value*> Ops);\n  llvm::Value *EmitX86BuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitPPCBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitAMDGPUBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitSystemZBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitNVPTXBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitWebAssemblyBuiltinExpr(unsigned BuiltinID,\n                                          const CallExpr *E);\n  llvm::Value *EmitHexagonBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitRISCVBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                    ReturnValueSlot ReturnValue);\n  bool ProcessOrderScopeAMDGCN(llvm::Value *Order, llvm::Value *Scope,\n                               llvm::AtomicOrdering &AO,\n                               llvm::SyncScope::ID &SSID);\n\n  enum class MSVCIntrin;\n  llvm::Value *EmitMSVCBuiltinExpr(MSVCIntrin BuiltinID, const CallExpr *E);\n\n  llvm::Value *EmitBuiltinAvailable(const VersionTuple &Version);\n\n  llvm::Value *EmitObjCProtocolExpr(const ObjCProtocolExpr *E);\n  llvm::Value *EmitObjCStringLiteral(const ObjCStringLiteral *E);\n  llvm::Value *EmitObjCBoxedExpr(const ObjCBoxedExpr *E);\n  llvm::Value *EmitObjCArrayLiteral(const ObjCArrayLiteral *E);\n  llvm::Value *EmitObjCDictionaryLiteral(const ObjCDictionaryLiteral *E);\n  llvm::Value *EmitObjCCollectionLiteral(const Expr *E,\n                                const ObjCMethodDecl *MethodWithObjects);\n  llvm::Value *EmitObjCSelectorExpr(const ObjCSelectorExpr *E);\n  RValue EmitObjCMessageExpr(const ObjCMessageExpr *E,\n                             ReturnValueSlot Return = ReturnValueSlot());\n\n  /// Retrieves the default cleanup kind for an ARC cleanup.\n  /// Except under -fobjc-arc-eh, ARC cleanups are normal-only.\n  CleanupKind getARCCleanupKind() {\n    return CGM.getCodeGenOpts().ObjCAutoRefCountExceptions\n             ? NormalAndEHCleanup : NormalCleanup;\n  }\n\n  // ARC primitives.\n  void EmitARCInitWeak(Address addr, llvm::Value *value);\n  void EmitARCDestroyWeak(Address addr);\n  llvm::Value *EmitARCLoadWeak(Address addr);\n  llvm::Value *EmitARCLoadWeakRetained(Address addr);\n  llvm::Value *EmitARCStoreWeak(Address addr, llvm::Value *value, bool ignored);\n  void emitARCCopyAssignWeak(QualType Ty, Address DstAddr, Address SrcAddr);\n  void emitARCMoveAssignWeak(QualType Ty, Address DstAddr, Address SrcAddr);\n  void EmitARCCopyWeak(Address dst, Address src);\n  void EmitARCMoveWeak(Address dst, Address src);\n  llvm::Value *EmitARCRetainAutorelease(QualType type, llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleaseNonBlock(llvm::Value *value);\n  llvm::Value *EmitARCStoreStrong(LValue lvalue, llvm::Value *value,\n                                  bool resultIgnored);\n  llvm::Value *EmitARCStoreStrongCall(Address addr, llvm::Value *value,\n                                      bool resultIgnored);\n  llvm::Value *EmitARCRetain(QualType type, llvm::Value *value);\n  llvm::Value *EmitARCRetainNonBlock(llvm::Value *value);\n  llvm::Value *EmitARCRetainBlock(llvm::Value *value, bool mandatory);\n  void EmitARCDestroyStrong(Address addr, ARCPreciseLifetime_t precise);\n  void EmitARCRelease(llvm::Value *value, ARCPreciseLifetime_t precise);\n  llvm::Value *EmitARCAutorelease(llvm::Value *value);\n  llvm::Value *EmitARCAutoreleaseReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleaseReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleasedReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCUnsafeClaimAutoreleasedReturnValue(llvm::Value *value);\n\n  llvm::Value *EmitObjCAutorelease(llvm::Value *value, llvm::Type *returnType);\n  llvm::Value *EmitObjCRetainNonBlock(llvm::Value *value,\n                                      llvm::Type *returnType);\n  void EmitObjCRelease(llvm::Value *value, ARCPreciseLifetime_t precise);\n\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreAutoreleasing(const BinaryOperator *e);\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreStrong(const BinaryOperator *e, bool ignored);\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreUnsafeUnretained(const BinaryOperator *e, bool ignored);\n\n  llvm::Value *EmitObjCAlloc(llvm::Value *value,\n                             llvm::Type *returnType);\n  llvm::Value *EmitObjCAllocWithZone(llvm::Value *value,\n                                     llvm::Type *returnType);\n  llvm::Value *EmitObjCAllocInit(llvm::Value *value, llvm::Type *resultType);\n\n  llvm::Value *EmitObjCThrowOperand(const Expr *expr);\n  llvm::Value *EmitObjCConsumeObject(QualType T, llvm::Value *Ptr);\n  llvm::Value *EmitObjCExtendObjectLifetime(QualType T, llvm::Value *Ptr);\n\n  llvm::Value *EmitARCExtendBlockObject(const Expr *expr);\n  llvm::Value *EmitARCReclaimReturnedObject(const Expr *e,\n                                            bool allowUnsafeClaim);\n  llvm::Value *EmitARCRetainScalarExpr(const Expr *expr);\n  llvm::Value *EmitARCRetainAutoreleaseScalarExpr(const Expr *expr);\n  llvm::Value *EmitARCUnsafeUnretainedScalarExpr(const Expr *expr);\n\n  void EmitARCIntrinsicUse(ArrayRef<llvm::Value*> values);\n\n  void EmitARCNoopIntrinsicUse(ArrayRef<llvm::Value *> values);\n\n  static Destroyer destroyARCStrongImprecise;\n  static Destroyer destroyARCStrongPrecise;\n  static Destroyer destroyARCWeak;\n  static Destroyer emitARCIntrinsicUse;\n  static Destroyer destroyNonTrivialCStruct;\n\n  void EmitObjCAutoreleasePoolPop(llvm::Value *Ptr);\n  llvm::Value *EmitObjCAutoreleasePoolPush();\n  llvm::Value *EmitObjCMRRAutoreleasePoolPush();\n  void EmitObjCAutoreleasePoolCleanup(llvm::Value *Ptr);\n  void EmitObjCMRRAutoreleasePoolPop(llvm::Value *Ptr);\n\n  /// Emits a reference binding to the passed in expression.\n  RValue EmitReferenceBindingToExpr(const Expr *E);\n\n  //===--------------------------------------------------------------------===//\n  //                           Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  // Expressions are broken into three classes: scalar, complex, aggregate.\n\n  /// EmitScalarExpr - Emit the computation of the specified expression of LLVM\n  /// scalar type, returning the result.\n  llvm::Value *EmitScalarExpr(const Expr *E , bool IgnoreResultAssign = false);\n\n  /// Emit a conversion from the specified type to the specified destination\n  /// type, both of which are LLVM scalar types.\n  llvm::Value *EmitScalarConversion(llvm::Value *Src, QualType SrcTy,\n                                    QualType DstTy, SourceLocation Loc);\n\n  /// Emit a conversion from the specified complex type to the specified\n  /// destination type, where the destination type is an LLVM scalar type.\n  llvm::Value *EmitComplexToScalarConversion(ComplexPairTy Src, QualType SrcTy,\n                                             QualType DstTy,\n                                             SourceLocation Loc);\n\n  /// EmitAggExpr - Emit the computation of the specified expression\n  /// of aggregate type.  The result is computed into the given slot,\n  /// which may be null to indicate that the value is not needed.\n  void EmitAggExpr(const Expr *E, AggValueSlot AS);\n\n  /// EmitAggExprToLValue - Emit the computation of the specified expression of\n  /// aggregate type into a temporary LValue.\n  LValue EmitAggExprToLValue(const Expr *E);\n\n  /// Build all the stores needed to initialize an aggregate at Dest with the\n  /// value Val.\n  void EmitAggregateStore(llvm::Value *Val, Address Dest, bool DestIsVolatile);\n\n  /// EmitExtendGCLifetime - Given a pointer to an Objective-C object,\n  /// make sure it survives garbage collection until this point.\n  void EmitExtendGCLifetime(llvm::Value *object);\n\n  /// EmitComplexExpr - Emit the computation of the specified expression of\n  /// complex type, returning the result.\n  ComplexPairTy EmitComplexExpr(const Expr *E,\n                                bool IgnoreReal = false,\n                                bool IgnoreImag = false);\n\n  /// EmitComplexExprIntoLValue - Emit the given expression of complex\n  /// type and place its result into the specified l-value.\n  void EmitComplexExprIntoLValue(const Expr *E, LValue dest, bool isInit);\n\n  /// EmitStoreOfComplex - Store a complex number into the specified l-value.\n  void EmitStoreOfComplex(ComplexPairTy V, LValue dest, bool isInit);\n\n  /// EmitLoadOfComplex - Load a complex number from the specified l-value.\n  ComplexPairTy EmitLoadOfComplex(LValue src, SourceLocation loc);\n\n  Address emitAddrOfRealComponent(Address complex, QualType complexType);\n  Address emitAddrOfImagComponent(Address complex, QualType complexType);\n\n  /// AddInitializerToStaticVarDecl - Add the initializer for 'D' to the\n  /// global variable that has already been created for it.  If the initializer\n  /// has a different type than GV does, this may free GV and return a different\n  /// one.  Otherwise it just returns GV.\n  llvm::GlobalVariable *\n  AddInitializerToStaticVarDecl(const VarDecl &D,\n                                llvm::GlobalVariable *GV);\n\n  // Emit an @llvm.invariant.start call for the given memory region.\n  void EmitInvariantStart(llvm::Constant *Addr, CharUnits Size);\n\n  /// EmitCXXGlobalVarDeclInit - Create the initializer for a C++\n  /// variable with global storage.\n  void EmitCXXGlobalVarDeclInit(const VarDecl &D, llvm::Constant *DeclPtr,\n                                bool PerformInit);\n\n  llvm::Function *createAtExitStub(const VarDecl &VD, llvm::FunctionCallee Dtor,\n                                   llvm::Constant *Addr);\n\n  /// Call atexit() with a function that passes the given argument to\n  /// the given function.\n  void registerGlobalDtorWithAtExit(const VarDecl &D, llvm::FunctionCallee fn,\n                                    llvm::Constant *addr);\n\n  /// Call atexit() with function dtorStub.\n  void registerGlobalDtorWithAtExit(llvm::Constant *dtorStub);\n\n  /// Call unatexit() with function dtorStub.\n  llvm::Value *unregisterGlobalDtorWithUnAtExit(llvm::Constant *dtorStub);\n\n  /// Emit code in this function to perform a guarded variable\n  /// initialization.  Guarded initializations are used when it's not\n  /// possible to prove that an initialization will be done exactly\n  /// once, e.g. with a static local variable or a static data member\n  /// of a class template.\n  void EmitCXXGuardedInit(const VarDecl &D, llvm::GlobalVariable *DeclPtr,\n                          bool PerformInit);\n\n  enum class GuardKind { VariableGuard, TlsGuard };\n\n  /// Emit a branch to select whether or not to perform guarded initialization.\n  void EmitCXXGuardedInitBranch(llvm::Value *NeedsInit,\n                                llvm::BasicBlock *InitBlock,\n                                llvm::BasicBlock *NoInitBlock,\n                                GuardKind Kind, const VarDecl *D);\n\n  /// GenerateCXXGlobalInitFunc - Generates code for initializing global\n  /// variables.\n  void\n  GenerateCXXGlobalInitFunc(llvm::Function *Fn,\n                            ArrayRef<llvm::Function *> CXXThreadLocals,\n                            ConstantAddress Guard = ConstantAddress::invalid());\n\n  /// GenerateCXXGlobalCleanUpFunc - Generates code for cleaning up global\n  /// variables.\n  void GenerateCXXGlobalCleanUpFunc(\n      llvm::Function *Fn,\n      const std::vector<std::tuple<llvm::FunctionType *, llvm::WeakTrackingVH,\n                                   llvm::Constant *>> &DtorsOrStermFinalizers);\n\n  void GenerateCXXGlobalVarDeclInitFunc(llvm::Function *Fn,\n                                        const VarDecl *D,\n                                        llvm::GlobalVariable *Addr,\n                                        bool PerformInit);\n\n  void EmitCXXConstructExpr(const CXXConstructExpr *E, AggValueSlot Dest);\n\n  void EmitSynthesizedCXXCopyCtor(Address Dest, Address Src, const Expr *Exp);\n\n  void EmitCXXThrowExpr(const CXXThrowExpr *E, bool KeepInsertionPoint = true);\n\n  RValue EmitAtomicExpr(AtomicExpr *E);\n\n  //===--------------------------------------------------------------------===//\n  //                         Annotations Emission\n  //===--------------------------------------------------------------------===//\n\n  /// Emit an annotation call (intrinsic).\n  llvm::Value *EmitAnnotationCall(llvm::Function *AnnotationFn,\n                                  llvm::Value *AnnotatedVal,\n                                  StringRef AnnotationStr,\n                                  SourceLocation Location,\n                                  const AnnotateAttr *Attr);\n\n  /// Emit local annotations for the local variable V, declared by D.\n  void EmitVarAnnotations(const VarDecl *D, llvm::Value *V);\n\n  /// Emit field annotations for the given field & value. Returns the\n  /// annotation result.\n  Address EmitFieldAnnotations(const FieldDecl *D, Address V);\n\n  //===--------------------------------------------------------------------===//\n  //                             Internal Helpers\n  //===--------------------------------------------------------------------===//\n\n  /// ContainsLabel - Return true if the statement contains a label in it.  If\n  /// this statement is not executed normally, it not containing a label means\n  /// that we can just remove the code.\n  static bool ContainsLabel(const Stmt *S, bool IgnoreCaseStmts = false);\n\n  /// containsBreak - Return true if the statement contains a break out of it.\n  /// If the statement (recursively) contains a switch or loop with a break\n  /// inside of it, this is fine.\n  static bool containsBreak(const Stmt *S);\n\n  /// Determine if the given statement might introduce a declaration into the\n  /// current scope, by being a (possibly-labelled) DeclStmt.\n  static bool mightAddDeclToScope(const Stmt *S);\n\n  /// ConstantFoldsToSimpleInteger - If the specified expression does not fold\n  /// to a constant, or if it does but contains a label, return false.  If it\n  /// constant folds return true and set the boolean result in Result.\n  bool ConstantFoldsToSimpleInteger(const Expr *Cond, bool &Result,\n                                    bool AllowLabels = false);\n\n  /// ConstantFoldsToSimpleInteger - If the specified expression does not fold\n  /// to a constant, or if it does but contains a label, return false.  If it\n  /// constant folds return true and set the folded value.\n  bool ConstantFoldsToSimpleInteger(const Expr *Cond, llvm::APSInt &Result,\n                                    bool AllowLabels = false);\n\n  /// isInstrumentedCondition - Determine whether the given condition is an\n  /// instrumentable condition (i.e. no \"&&\" or \"||\").\n  static bool isInstrumentedCondition(const Expr *C);\n\n  /// EmitBranchToCounterBlock - Emit a conditional branch to a new block that\n  /// increments a profile counter based on the semantics of the given logical\n  /// operator opcode.  This is used to instrument branch condition coverage\n  /// for logical operators.\n  void EmitBranchToCounterBlock(const Expr *Cond, BinaryOperator::Opcode LOp,\n                                llvm::BasicBlock *TrueBlock,\n                                llvm::BasicBlock *FalseBlock,\n                                uint64_t TrueCount = 0,\n                                Stmt::Likelihood LH = Stmt::LH_None,\n                                const Expr *CntrIdx = nullptr);\n\n  /// EmitBranchOnBoolExpr - Emit a branch on a boolean condition (e.g. for an\n  /// if statement) to the specified blocks.  Based on the condition, this might\n  /// try to simplify the codegen of the conditional based on the branch.\n  /// TrueCount should be the number of times we expect the condition to\n  /// evaluate to true based on PGO data.\n  void EmitBranchOnBoolExpr(const Expr *Cond, llvm::BasicBlock *TrueBlock,\n                            llvm::BasicBlock *FalseBlock, uint64_t TrueCount,\n                            Stmt::Likelihood LH = Stmt::LH_None);\n\n  /// Given an assignment `*LHS = RHS`, emit a test that checks if \\p RHS is\n  /// nonnull, if \\p LHS is marked _Nonnull.\n  void EmitNullabilityCheck(LValue LHS, llvm::Value *RHS, SourceLocation Loc);\n\n  /// An enumeration which makes it easier to specify whether or not an\n  /// operation is a subtraction.\n  enum { NotSubtraction = false, IsSubtraction = true };\n\n  /// Same as IRBuilder::CreateInBoundsGEP, but additionally emits a check to\n  /// detect undefined behavior when the pointer overflow sanitizer is enabled.\n  /// \\p SignedIndices indicates whether any of the GEP indices are signed.\n  /// \\p IsSubtraction indicates whether the expression used to form the GEP\n  /// is a subtraction.\n  llvm::Value *EmitCheckedInBoundsGEP(llvm::Value *Ptr,\n                                      ArrayRef<llvm::Value *> IdxList,\n                                      bool SignedIndices,\n                                      bool IsSubtraction,\n                                      SourceLocation Loc,\n                                      const Twine &Name = \"\");\n\n  /// Specifies which type of sanitizer check to apply when handling a\n  /// particular builtin.\n  enum BuiltinCheckKind {\n    BCK_CTZPassedZero,\n    BCK_CLZPassedZero,\n  };\n\n  /// Emits an argument for a call to a builtin. If the builtin sanitizer is\n  /// enabled, a runtime check specified by \\p Kind is also emitted.\n  llvm::Value *EmitCheckedArgForBuiltin(const Expr *E, BuiltinCheckKind Kind);\n\n  /// Emit a description of a type in a format suitable for passing to\n  /// a runtime sanitizer handler.\n  llvm::Constant *EmitCheckTypeDescriptor(QualType T);\n\n  /// Convert a value into a format suitable for passing to a runtime\n  /// sanitizer handler.\n  llvm::Value *EmitCheckValue(llvm::Value *V);\n\n  /// Emit a description of a source location in a format suitable for\n  /// passing to a runtime sanitizer handler.\n  llvm::Constant *EmitCheckSourceLocation(SourceLocation Loc);\n\n  /// Create a basic block that will either trap or call a handler function in\n  /// the UBSan runtime with the provided arguments, and create a conditional\n  /// branch to it.\n  void EmitCheck(ArrayRef<std::pair<llvm::Value *, SanitizerMask>> Checked,\n                 SanitizerHandler Check, ArrayRef<llvm::Constant *> StaticArgs,\n                 ArrayRef<llvm::Value *> DynamicArgs);\n\n  /// Emit a slow path cross-DSO CFI check which calls __cfi_slowpath\n  /// if Cond if false.\n  void EmitCfiSlowPathCheck(SanitizerMask Kind, llvm::Value *Cond,\n                            llvm::ConstantInt *TypeId, llvm::Value *Ptr,\n                            ArrayRef<llvm::Constant *> StaticArgs);\n\n  /// Emit a reached-unreachable diagnostic if \\p Loc is valid and runtime\n  /// checking is enabled. Otherwise, just emit an unreachable instruction.\n  void EmitUnreachable(SourceLocation Loc);\n\n  /// Create a basic block that will call the trap intrinsic, and emit a\n  /// conditional branch to it, for the -ftrapv checks.\n  void EmitTrapCheck(llvm::Value *Checked, SanitizerHandler CheckHandlerID);\n\n  /// Emit a call to trap or debugtrap and attach function attribute\n  /// \"trap-func-name\" if specified.\n  llvm::CallInst *EmitTrapCall(llvm::Intrinsic::ID IntrID);\n\n  /// Emit a stub for the cross-DSO CFI check function.\n  void EmitCfiCheckStub();\n\n  /// Emit a cross-DSO CFI failure handling function.\n  void EmitCfiCheckFail();\n\n  /// Create a check for a function parameter that may potentially be\n  /// declared as non-null.\n  void EmitNonNullArgCheck(RValue RV, QualType ArgType, SourceLocation ArgLoc,\n                           AbstractCallee AC, unsigned ParmNum);\n\n  /// EmitCallArg - Emit a single call argument.\n  void EmitCallArg(CallArgList &args, const Expr *E, QualType ArgType);\n\n  /// EmitDelegateCallArg - We are performing a delegate call; that\n  /// is, the current function is delegating to another one.  Produce\n  /// a r-value suitable for passing the given parameter.\n  void EmitDelegateCallArg(CallArgList &args, const VarDecl *param,\n                           SourceLocation loc);\n\n  /// SetFPAccuracy - Set the minimum required accuracy of the given floating\n  /// point operation, expressed as the maximum relative error in ulp.\n  void SetFPAccuracy(llvm::Value *Val, float Accuracy);\n\n  /// SetFPModel - Control floating point behavior via fp-model settings.\n  void SetFPModel();\n\n  /// Set the codegen fast-math flags.\n  void SetFastMathFlags(FPOptions FPFeatures);\n\nprivate:\n  llvm::MDNode *getRangeForLoadFromType(QualType Ty);\n  void EmitReturnOfRValue(RValue RV, QualType Ty);\n\n  void deferPlaceholderReplacement(llvm::Instruction *Old, llvm::Value *New);\n\n  llvm::SmallVector<std::pair<llvm::WeakTrackingVH, llvm::Value *>, 4>\n      DeferredReplacements;\n\n  /// Set the address of a local variable.\n  void setAddrOfLocalVar(const VarDecl *VD, Address Addr) {\n    assert(!LocalDeclMap.count(VD) && \"Decl already exists in LocalDeclMap!\");\n    LocalDeclMap.insert({VD, Addr});\n  }\n\n  /// ExpandTypeFromArgs - Reconstruct a structure of type \\arg Ty\n  /// from function arguments into \\arg Dst. See ABIArgInfo::Expand.\n  ///\n  /// \\param AI - The first function argument of the expansion.\n  void ExpandTypeFromArgs(QualType Ty, LValue Dst,\n                          llvm::Function::arg_iterator &AI);\n\n  /// ExpandTypeToArgs - Expand an CallArg \\arg Arg, with the LLVM type for \\arg\n  /// Ty, into individual arguments on the provided vector \\arg IRCallArgs,\n  /// starting at index \\arg IRCallArgPos. See ABIArgInfo::Expand.\n  void ExpandTypeToArgs(QualType Ty, CallArg Arg, llvm::FunctionType *IRFuncTy,\n                        SmallVectorImpl<llvm::Value *> &IRCallArgs,\n                        unsigned &IRCallArgPos);\n\n  llvm::Value* EmitAsmInput(const TargetInfo::ConstraintInfo &Info,\n                            const Expr *InputExpr, std::string &ConstraintStr);\n\n  llvm::Value* EmitAsmInputLValue(const TargetInfo::ConstraintInfo &Info,\n                                  LValue InputValue, QualType InputType,\n                                  std::string &ConstraintStr,\n                                  SourceLocation Loc);\n\n  /// Attempts to statically evaluate the object size of E. If that\n  /// fails, emits code to figure the size of E out for us. This is\n  /// pass_object_size aware.\n  ///\n  /// If EmittedExpr is non-null, this will use that instead of re-emitting E.\n  llvm::Value *evaluateOrEmitBuiltinObjectSize(const Expr *E, unsigned Type,\n                                               llvm::IntegerType *ResType,\n                                               llvm::Value *EmittedE,\n                                               bool IsDynamic);\n\n  /// Emits the size of E, as required by __builtin_object_size. This\n  /// function is aware of pass_object_size parameters, and will act accordingly\n  /// if E is a parameter with the pass_object_size attribute.\n  llvm::Value *emitBuiltinObjectSize(const Expr *E, unsigned Type,\n                                     llvm::IntegerType *ResType,\n                                     llvm::Value *EmittedE,\n                                     bool IsDynamic);\n\n  void emitZeroOrPatternForAutoVarInit(QualType type, const VarDecl &D,\n                                       Address Loc);\n\npublic:\n  enum class EvaluationOrder {\n    ///! No language constraints on evaluation order.\n    Default,\n    ///! Language semantics require left-to-right evaluation.\n    ForceLeftToRight,\n    ///! Language semantics require right-to-left evaluation.\n    ForceRightToLeft\n  };\n\n  // Wrapper for function prototype sources. Wraps either a FunctionProtoType or\n  // an ObjCMethodDecl.\n  struct PrototypeWrapper {\n    llvm::PointerUnion<const FunctionProtoType *, const ObjCMethodDecl *> P;\n\n    PrototypeWrapper(const FunctionProtoType *FT) : P(FT) {}\n    PrototypeWrapper(const ObjCMethodDecl *MD) : P(MD) {}\n  };\n\n  void EmitCallArgs(CallArgList &Args, PrototypeWrapper Prototype,\n                    llvm::iterator_range<CallExpr::const_arg_iterator> ArgRange,\n                    AbstractCallee AC = AbstractCallee(),\n                    unsigned ParamsToSkip = 0,\n                    EvaluationOrder Order = EvaluationOrder::Default);\n\n  /// EmitPointerWithAlignment - Given an expression with a pointer type,\n  /// emit the value and compute our best estimate of the alignment of the\n  /// pointee.\n  ///\n  /// \\param BaseInfo - If non-null, this will be initialized with\n  /// information about the source of the alignment and the may-alias\n  /// attribute.  Note that this function will conservatively fall back on\n  /// the type when it doesn't recognize the expression and may-alias will\n  /// be set to false.\n  ///\n  /// One reasonable way to use this information is when there's a language\n  /// guarantee that the pointer must be aligned to some stricter value, and\n  /// we're simply trying to ensure that sufficiently obvious uses of under-\n  /// aligned objects don't get miscompiled; for example, a placement new\n  /// into the address of a local variable.  In such a case, it's quite\n  /// reasonable to just ignore the returned alignment when it isn't from an\n  /// explicit source.\n  Address EmitPointerWithAlignment(const Expr *Addr,\n                                   LValueBaseInfo *BaseInfo = nullptr,\n                                   TBAAAccessInfo *TBAAInfo = nullptr);\n\n  /// If \\p E references a parameter with pass_object_size info or a constant\n  /// array size modifier, emit the object size divided by the size of \\p EltTy.\n  /// Otherwise return null.\n  llvm::Value *LoadPassedObjectSize(const Expr *E, QualType EltTy);\n\n  void EmitSanitizerStatReport(llvm::SanitizerStatKind SSK);\n\n  struct MultiVersionResolverOption {\n    llvm::Function *Function;\n    FunctionDecl *FD;\n    struct Conds {\n      StringRef Architecture;\n      llvm::SmallVector<StringRef, 8> Features;\n\n      Conds(StringRef Arch, ArrayRef<StringRef> Feats)\n          : Architecture(Arch), Features(Feats.begin(), Feats.end()) {}\n    } Conditions;\n\n    MultiVersionResolverOption(llvm::Function *F, StringRef Arch,\n                               ArrayRef<StringRef> Feats)\n        : Function(F), Conditions(Arch, Feats) {}\n  };\n\n  // Emits the body of a multiversion function's resolver. Assumes that the\n  // options are already sorted in the proper order, with the 'default' option\n  // last (if it exists).\n  void EmitMultiVersionResolver(llvm::Function *Resolver,\n                                ArrayRef<MultiVersionResolverOption> Options);\n\n  static uint64_t GetX86CpuSupportsMask(ArrayRef<StringRef> FeatureStrs);\n\nprivate:\n  QualType getVarArgType(const Expr *Arg);\n\n  void EmitDeclMetadata();\n\n  BlockByrefHelpers *buildByrefHelpers(llvm::StructType &byrefType,\n                                  const AutoVarEmission &emission);\n\n  void AddObjCARCExceptionMetadata(llvm::Instruction *Inst);\n\n  llvm::Value *GetValueForARMHint(unsigned BuiltinID);\n  llvm::Value *EmitX86CpuIs(const CallExpr *E);\n  llvm::Value *EmitX86CpuIs(StringRef CPUStr);\n  llvm::Value *EmitX86CpuSupports(const CallExpr *E);\n  llvm::Value *EmitX86CpuSupports(ArrayRef<StringRef> FeatureStrs);\n  llvm::Value *EmitX86CpuSupports(uint64_t Mask);\n  llvm::Value *EmitX86CpuInit();\n  llvm::Value *FormResolverCondition(const MultiVersionResolverOption &RO);\n};\n\n/// TargetFeatures - This class is used to check whether the builtin function\n/// has the required tagert specific features. It is able to support the\n/// combination of ','(and), '|'(or), and '()'. By default, the priority of\n/// ',' is higher than that of '|' .\n/// E.g:\n/// A,B|C means the builtin function requires both A and B, or C.\n/// If we want the builtin function requires both A and B, or both A and C,\n/// there are two ways: A,B|A,C or A,(B|C).\n/// The FeaturesList should not contain spaces, and brackets must appear in\n/// pairs.\nclass TargetFeatures {\n  struct FeatureListStatus {\n    bool HasFeatures;\n    StringRef CurFeaturesList;\n  };\n\n  const llvm::StringMap<bool> &CallerFeatureMap;\n\n  FeatureListStatus getAndFeatures(StringRef FeatureList) {\n    int InParentheses = 0;\n    bool HasFeatures = true;\n    size_t SubexpressionStart = 0;\n    for (size_t i = 0, e = FeatureList.size(); i < e; ++i) {\n      char CurrentToken = FeatureList[i];\n      switch (CurrentToken) {\n      default:\n        break;\n      case '(':\n        if (InParentheses == 0)\n          SubexpressionStart = i + 1;\n        ++InParentheses;\n        break;\n      case ')':\n        --InParentheses;\n        assert(InParentheses >= 0 && \"Parentheses are not in pair\");\n        LLVM_FALLTHROUGH;\n      case '|':\n      case ',':\n        if (InParentheses == 0) {\n          if (HasFeatures && i != SubexpressionStart) {\n            StringRef F = FeatureList.slice(SubexpressionStart, i);\n            HasFeatures = CurrentToken == ')' ? hasRequiredFeatures(F)\n                                              : CallerFeatureMap.lookup(F);\n          }\n          SubexpressionStart = i + 1;\n          if (CurrentToken == '|') {\n            return {HasFeatures, FeatureList.substr(SubexpressionStart)};\n          }\n        }\n        break;\n      }\n    }\n    assert(InParentheses == 0 && \"Parentheses are not in pair\");\n    if (HasFeatures && SubexpressionStart != FeatureList.size())\n      HasFeatures =\n          CallerFeatureMap.lookup(FeatureList.substr(SubexpressionStart));\n    return {HasFeatures, StringRef()};\n  }\n\npublic:\n  bool hasRequiredFeatures(StringRef FeatureList) {\n    FeatureListStatus FS = {false, FeatureList};\n    while (!FS.HasFeatures && !FS.CurFeaturesList.empty())\n      FS = getAndFeatures(FS.CurFeaturesList);\n    return FS.HasFeatures;\n  }\n\n  TargetFeatures(const llvm::StringMap<bool> &CallerFeatureMap)\n      : CallerFeatureMap(CallerFeatureMap) {}\n};\n\ninline DominatingLLVMValue::saved_type\nDominatingLLVMValue::save(CodeGenFunction &CGF, llvm::Value *value) {\n  if (!needsSaving(value)) return saved_type(value, false);\n\n  // Otherwise, we need an alloca.\n  auto align = CharUnits::fromQuantity(\n            CGF.CGM.getDataLayout().getPrefTypeAlignment(value->getType()));\n  Address alloca =\n    CGF.CreateTempAlloca(value->getType(), align, \"cond-cleanup.save\");\n  CGF.Builder.CreateStore(value, alloca);\n\n  return saved_type(alloca.getPointer(), true);\n}\n\ninline llvm::Value *DominatingLLVMValue::restore(CodeGenFunction &CGF,\n                                                 saved_type value) {\n  // If the value says it wasn't saved, trust that it's still dominating.\n  if (!value.getInt()) return value.getPointer();\n\n  // Otherwise, it should be an alloca instruction, as set up in save().\n  auto alloca = cast<llvm::AllocaInst>(value.getPointer());\n  return CGF.Builder.CreateAlignedLoad(alloca, alloca->getAlign());\n}\n\n}  // end namespace CodeGen\n\n// Map the LangOption for floating point exception behavior into\n// the corresponding enum in the IR.\nllvm::fp::ExceptionBehavior\nToConstrainedExceptMD(LangOptions::FPExceptionModeKind Kind);\n}  // end namespace clang\n\n#endif\n"}}, "reports": [{"events": [{"location": {"col": 7, "file": 4, "line": 1556}, "message": "'ImplicitParamDecl' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Decl.h", "reportHash": "ef7a06bb31ea4781701516b2f1d4ebe0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 110}, "message": "'CGOpenMPOutlinedRegionInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "eb448c79d791a6b507e4472ee3005f81", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 143}, "message": "'CGOpenMPTaskOutlinedRegionInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "f379964654d473436ee849fd722e4be4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 35, "line": 145}, "message": "'UntiedTaskActionTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "1c44ec8276bb9e539f7fb322f310ad00", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 319}, "message": "'CGOpenMPTargetRegionInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "f7ed6c24af5181bd44b713a692a1b3aa", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 348}, "message": "'CGOpenMPInnerExprInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "d00c36834353cc9c1fedd368b86fdbfc", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 573}, "message": "'CleanupTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "6098af6f35d7dddbe3cdbb1d1482b0d9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 2180}, "message": "'CommonActionTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "2674fae05e9dc82b2b0cbd2df39c0a3f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 35, "line": 3387}, "message": "'PrivateHelpersTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "c3f3e36caf255f0e075bad4d29af3511", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 6332}, "message": "'OMPUsesAllocatorsActionTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "eb79acdb030bd1e0d0867e24b0e18578", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 7013}, "message": "'MappableExprsHandler' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "578ed2cfaf4d8f9b80dd6115048cab25", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 35, "line": 7117}, "message": "'MapCombinedInfoTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "9bc63574f998cf5e560adfd023fe27ae", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 35, "line": 7157}, "message": "'StructRangeInfoTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "2c70615ce8a49d911b03bd28b7401c50", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 35, "line": 9402}, "message": "'ArgumentsOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "144584548ea73207dec147cf167dda96", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 11702}, "message": "'DoacrossCleanupTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "e3ea33cc55ae869fac806e1570b80e56", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 11, "file": 35, "line": 11921}, "message": "'OMPAllocateCleanupTy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.cpp", "reportHash": "74b00c9887c4db6a8e8701929a4fda54", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 36, "line": 130}, "message": "'ReductionCodeGen' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.h", "reportHash": "bb060d7a9a776b3c908b8ac78c49ae45", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 36, "line": 1627}, "message": "'TargetDataInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntime.h", "reportHash": "0dddb83e6bd2bc8eb951495934bb9c13", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 38, "line": 3399}, "message": "'OMPTargetDataInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "15edfad95c517c3dba19dcf901b750bc", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
