<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"18": {"id": 18, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AliasAnalysis.h", "content": "//===- llvm/Analysis/AliasAnalysis.h - Alias Analysis Interface -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the generic AliasAnalysis interface, which is used as the\n// common interface used by all clients of alias analysis information, and\n// implemented by all alias analysis implementations.  Mod/Ref information is\n// also captured by this interface.\n//\n// Implementations of this interface must implement the various virtual methods,\n// which automatically provides functionality for the entire suite of client\n// APIs.\n//\n// This API identifies memory regions with the MemoryLocation class. The pointer\n// component specifies the base memory address of the region. The Size specifies\n// the maximum size (in address units) of the memory region, or\n// MemoryLocation::UnknownSize if the size is not known. The TBAA tag\n// identifies the \"type\" of the memory reference; see the\n// TypeBasedAliasAnalysis class for details.\n//\n// Some non-obvious details include:\n//  - Pointers that point to two completely different objects in memory never\n//    alias, regardless of the value of the Size component.\n//  - NoAlias doesn't imply inequal pointers. The most obvious example of this\n//    is two pointers to constant memory. Even if they are equal, constant\n//    memory is never stored to, so there will never be any dependencies.\n//    In this and other situations, the pointers may be both NoAlias and\n//    MustAlias at the same time. The current API can only return one result,\n//    though this is rarely a problem in practice.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_ALIASANALYSIS_H\n#define LLVM_ANALYSIS_ALIASANALYSIS_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Analysis/MemoryLocation.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include <cstdint>\n#include <functional>\n#include <memory>\n#include <vector>\n\nnamespace llvm {\n\nclass AnalysisUsage;\nclass AtomicCmpXchgInst;\nclass BasicAAResult;\nclass BasicBlock;\nclass CatchPadInst;\nclass CatchReturnInst;\nclass DominatorTree;\nclass FenceInst;\nclass Function;\nclass InvokeInst;\nclass PreservedAnalyses;\nclass TargetLibraryInfo;\nclass Value;\n\n/// The possible results of an alias query.\n///\n/// These results are always computed between two MemoryLocation objects as\n/// a query to some alias analysis.\n///\n/// Note that these are unscoped enumerations because we would like to support\n/// implicitly testing a result for the existence of any possible aliasing with\n/// a conversion to bool, but an \"enum class\" doesn't support this. The\n/// canonical names from the literature are suffixed and unique anyways, and so\n/// they serve as global constants in LLVM for these results.\n///\n/// See docs/AliasAnalysis.html for more information on the specific meanings\n/// of these values.\nenum AliasResult : uint8_t {\n  /// The two locations do not alias at all.\n  ///\n  /// This value is arranged to convert to false, while all other values\n  /// convert to true. This allows a boolean context to convert the result to\n  /// a binary flag indicating whether there is the possibility of aliasing.\n  NoAlias = 0,\n  /// The two locations may or may not alias. This is the least precise result.\n  MayAlias,\n  /// The two locations alias, but only due to a partial overlap.\n  PartialAlias,\n  /// The two locations precisely alias each other.\n  MustAlias,\n};\n\n/// << operator for AliasResult.\nraw_ostream &operator<<(raw_ostream &OS, AliasResult AR);\n\n/// Flags indicating whether a memory access modifies or references memory.\n///\n/// This is no access at all, a modification, a reference, or both\n/// a modification and a reference. These are specifically structured such that\n/// they form a three bit matrix and bit-tests for 'mod' or 'ref' or 'must'\n/// work with any of the possible values.\nenum class ModRefInfo : uint8_t {\n  /// Must is provided for completeness, but no routines will return only\n  /// Must today. See definition of Must below.\n  Must = 0,\n  /// The access may reference the value stored in memory,\n  /// a mustAlias relation was found, and no mayAlias or partialAlias found.\n  MustRef = 1,\n  /// The access may modify the value stored in memory,\n  /// a mustAlias relation was found, and no mayAlias or partialAlias found.\n  MustMod = 2,\n  /// The access may reference, modify or both the value stored in memory,\n  /// a mustAlias relation was found, and no mayAlias or partialAlias found.\n  MustModRef = MustRef | MustMod,\n  /// The access neither references nor modifies the value stored in memory.\n  NoModRef = 4,\n  /// The access may reference the value stored in memory.\n  Ref = NoModRef | MustRef,\n  /// The access may modify the value stored in memory.\n  Mod = NoModRef | MustMod,\n  /// The access may reference and may modify the value stored in memory.\n  ModRef = Ref | Mod,\n\n  /// About Must:\n  /// Must is set in a best effort manner.\n  /// We usually do not try our best to infer Must, instead it is merely\n  /// another piece of \"free\" information that is presented when available.\n  /// Must set means there was certainly a MustAlias found. For calls,\n  /// where multiple arguments are checked (argmemonly), this translates to\n  /// only MustAlias or NoAlias was found.\n  /// Must is not set for RAR accesses, even if the two locations must\n  /// alias. The reason is that two read accesses translate to an early return\n  /// of NoModRef. An additional alias check to set Must may be\n  /// expensive. Other cases may also not set Must(e.g. callCapturesBefore).\n  /// We refer to Must being *set* when the most significant bit is *cleared*.\n  /// Conversely we *clear* Must information by *setting* the Must bit to 1.\n};\n\nLLVM_NODISCARD inline bool isNoModRef(const ModRefInfo MRI) {\n  return (static_cast<int>(MRI) & static_cast<int>(ModRefInfo::MustModRef)) ==\n         static_cast<int>(ModRefInfo::Must);\n}\nLLVM_NODISCARD inline bool isModOrRefSet(const ModRefInfo MRI) {\n  return static_cast<int>(MRI) & static_cast<int>(ModRefInfo::MustModRef);\n}\nLLVM_NODISCARD inline bool isModAndRefSet(const ModRefInfo MRI) {\n  return (static_cast<int>(MRI) & static_cast<int>(ModRefInfo::MustModRef)) ==\n         static_cast<int>(ModRefInfo::MustModRef);\n}\nLLVM_NODISCARD inline bool isModSet(const ModRefInfo MRI) {\n  return static_cast<int>(MRI) & static_cast<int>(ModRefInfo::MustMod);\n}\nLLVM_NODISCARD inline bool isRefSet(const ModRefInfo MRI) {\n  return static_cast<int>(MRI) & static_cast<int>(ModRefInfo::MustRef);\n}\nLLVM_NODISCARD inline bool isMustSet(const ModRefInfo MRI) {\n  return !(static_cast<int>(MRI) & static_cast<int>(ModRefInfo::NoModRef));\n}\n\nLLVM_NODISCARD inline ModRefInfo setMod(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) |\n                    static_cast<int>(ModRefInfo::MustMod));\n}\nLLVM_NODISCARD inline ModRefInfo setRef(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) |\n                    static_cast<int>(ModRefInfo::MustRef));\n}\nLLVM_NODISCARD inline ModRefInfo setMust(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) &\n                    static_cast<int>(ModRefInfo::MustModRef));\n}\nLLVM_NODISCARD inline ModRefInfo setModAndRef(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) |\n                    static_cast<int>(ModRefInfo::MustModRef));\n}\nLLVM_NODISCARD inline ModRefInfo clearMod(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) & static_cast<int>(ModRefInfo::Ref));\n}\nLLVM_NODISCARD inline ModRefInfo clearRef(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) & static_cast<int>(ModRefInfo::Mod));\n}\nLLVM_NODISCARD inline ModRefInfo clearMust(const ModRefInfo MRI) {\n  return ModRefInfo(static_cast<int>(MRI) |\n                    static_cast<int>(ModRefInfo::NoModRef));\n}\nLLVM_NODISCARD inline ModRefInfo unionModRef(const ModRefInfo MRI1,\n                                             const ModRefInfo MRI2) {\n  return ModRefInfo(static_cast<int>(MRI1) | static_cast<int>(MRI2));\n}\nLLVM_NODISCARD inline ModRefInfo intersectModRef(const ModRefInfo MRI1,\n                                                 const ModRefInfo MRI2) {\n  return ModRefInfo(static_cast<int>(MRI1) & static_cast<int>(MRI2));\n}\n\n/// The locations at which a function might access memory.\n///\n/// These are primarily used in conjunction with the \\c AccessKind bits to\n/// describe both the nature of access and the locations of access for a\n/// function call.\nenum FunctionModRefLocation {\n  /// Base case is no access to memory.\n  FMRL_Nowhere = 0,\n  /// Access to memory via argument pointers.\n  FMRL_ArgumentPointees = 8,\n  /// Memory that is inaccessible via LLVM IR.\n  FMRL_InaccessibleMem = 16,\n  /// Access to any memory.\n  FMRL_Anywhere = 32 | FMRL_InaccessibleMem | FMRL_ArgumentPointees\n};\n\n/// Summary of how a function affects memory in the program.\n///\n/// Loads from constant globals are not considered memory accesses for this\n/// interface. Also, functions may freely modify stack space local to their\n/// invocation without having to report it through these interfaces.\nenum FunctionModRefBehavior {\n  /// This function does not perform any non-local loads or stores to memory.\n  ///\n  /// This property corresponds to the GCC 'const' attribute.\n  /// This property corresponds to the LLVM IR 'readnone' attribute.\n  /// This property corresponds to the IntrNoMem LLVM intrinsic flag.\n  FMRB_DoesNotAccessMemory =\n      FMRL_Nowhere | static_cast<int>(ModRefInfo::NoModRef),\n\n  /// The only memory references in this function (if it has any) are\n  /// non-volatile loads from objects pointed to by its pointer-typed\n  /// arguments, with arbitrary offsets.\n  ///\n  /// This property corresponds to the combination of the IntrReadMem\n  /// and IntrArgMemOnly LLVM intrinsic flags.\n  FMRB_OnlyReadsArgumentPointees =\n      FMRL_ArgumentPointees | static_cast<int>(ModRefInfo::Ref),\n\n  /// The only memory references in this function (if it has any) are\n  /// non-volatile stores from objects pointed to by its pointer-typed\n  /// arguments, with arbitrary offsets.\n  ///\n  /// This property corresponds to the combination of the IntrWriteMem\n  /// and IntrArgMemOnly LLVM intrinsic flags.\n  FMRB_OnlyWritesArgumentPointees =\n      FMRL_ArgumentPointees | static_cast<int>(ModRefInfo::Mod),\n\n  /// The only memory references in this function (if it has any) are\n  /// non-volatile loads and stores from objects pointed to by its\n  /// pointer-typed arguments, with arbitrary offsets.\n  ///\n  /// This property corresponds to the IntrArgMemOnly LLVM intrinsic flag.\n  FMRB_OnlyAccessesArgumentPointees =\n      FMRL_ArgumentPointees | static_cast<int>(ModRefInfo::ModRef),\n\n  /// The only memory references in this function (if it has any) are\n  /// reads of memory that is otherwise inaccessible via LLVM IR.\n  ///\n  /// This property corresponds to the LLVM IR inaccessiblememonly attribute.\n  FMRB_OnlyReadsInaccessibleMem =\n      FMRL_InaccessibleMem | static_cast<int>(ModRefInfo::Ref),\n\n  /// The only memory references in this function (if it has any) are\n  /// writes to memory that is otherwise inaccessible via LLVM IR.\n  ///\n  /// This property corresponds to the LLVM IR inaccessiblememonly attribute.\n  FMRB_OnlyWritesInaccessibleMem =\n      FMRL_InaccessibleMem | static_cast<int>(ModRefInfo::Mod),\n\n  /// The only memory references in this function (if it has any) are\n  /// references of memory that is otherwise inaccessible via LLVM IR.\n  ///\n  /// This property corresponds to the LLVM IR inaccessiblememonly attribute.\n  FMRB_OnlyAccessesInaccessibleMem =\n      FMRL_InaccessibleMem | static_cast<int>(ModRefInfo::ModRef),\n\n  /// The function may perform non-volatile loads from objects pointed\n  /// to by its pointer-typed arguments, with arbitrary offsets, and\n  /// it may also perform loads of memory that is otherwise\n  /// inaccessible via LLVM IR.\n  ///\n  /// This property corresponds to the LLVM IR\n  /// inaccessiblemem_or_argmemonly attribute.\n  FMRB_OnlyReadsInaccessibleOrArgMem = FMRL_InaccessibleMem |\n                                       FMRL_ArgumentPointees |\n                                       static_cast<int>(ModRefInfo::Ref),\n\n  /// The function may perform non-volatile stores to objects pointed\n  /// to by its pointer-typed arguments, with arbitrary offsets, and\n  /// it may also perform stores of memory that is otherwise\n  /// inaccessible via LLVM IR.\n  ///\n  /// This property corresponds to the LLVM IR\n  /// inaccessiblemem_or_argmemonly attribute.\n  FMRB_OnlyWritesInaccessibleOrArgMem = FMRL_InaccessibleMem |\n                                        FMRL_ArgumentPointees |\n                                        static_cast<int>(ModRefInfo::Mod),\n\n  /// The function may perform non-volatile loads and stores of objects\n  /// pointed to by its pointer-typed arguments, with arbitrary offsets, and\n  /// it may also perform loads and stores of memory that is otherwise\n  /// inaccessible via LLVM IR.\n  ///\n  /// This property corresponds to the LLVM IR\n  /// inaccessiblemem_or_argmemonly attribute.\n  FMRB_OnlyAccessesInaccessibleOrArgMem = FMRL_InaccessibleMem |\n                                          FMRL_ArgumentPointees |\n                                          static_cast<int>(ModRefInfo::ModRef),\n\n  /// This function does not perform any non-local stores or volatile loads,\n  /// but may read from any memory location.\n  ///\n  /// This property corresponds to the GCC 'pure' attribute.\n  /// This property corresponds to the LLVM IR 'readonly' attribute.\n  /// This property corresponds to the IntrReadMem LLVM intrinsic flag.\n  FMRB_OnlyReadsMemory = FMRL_Anywhere | static_cast<int>(ModRefInfo::Ref),\n\n  // This function does not read from memory anywhere, but may write to any\n  // memory location.\n  //\n  // This property corresponds to the LLVM IR 'writeonly' attribute.\n  // This property corresponds to the IntrWriteMem LLVM intrinsic flag.\n  FMRB_OnlyWritesMemory = FMRL_Anywhere | static_cast<int>(ModRefInfo::Mod),\n\n  /// This indicates that the function could not be classified into one of the\n  /// behaviors above.\n  FMRB_UnknownModRefBehavior =\n      FMRL_Anywhere | static_cast<int>(ModRefInfo::ModRef)\n};\n\n// Wrapper method strips bits significant only in FunctionModRefBehavior,\n// to obtain a valid ModRefInfo. The benefit of using the wrapper is that if\n// ModRefInfo enum changes, the wrapper can be updated to & with the new enum\n// entry with all bits set to 1.\nLLVM_NODISCARD inline ModRefInfo\ncreateModRefInfo(const FunctionModRefBehavior FMRB) {\n  return ModRefInfo(FMRB & static_cast<int>(ModRefInfo::ModRef));\n}\n\n/// This class stores info we want to provide to or retain within an alias\n/// query. By default, the root query is stateless and starts with a freshly\n/// constructed info object. Specific alias analyses can use this query info to\n/// store per-query state that is important for recursive or nested queries to\n/// avoid recomputing. To enable preserving this state across multiple queries\n/// where safe (due to the IR not changing), use a `BatchAAResults` wrapper.\n/// The information stored in an `AAQueryInfo` is currently limitted to the\n/// caches used by BasicAA, but can further be extended to fit other AA needs.\nclass AAQueryInfo {\n  /// Storage for estimated relative offsets between two partially aliased\n  /// values. Used to optimize out redundant parts of loads/stores (in GVN/DSE).\n  /// These users cannot process quite complicated addresses (e.g. GEPs with\n  /// non-constant offsets). Used by BatchAAResults only.\n  bool CacheOffsets = false;\n  SmallDenseMap<std::pair<std::pair<const Value *, const Value *>,\n                          std::pair<uint64_t, uint64_t>>,\n                int64_t, 4>\n      ClobberOffsets;\n\npublic:\n  using LocPair = std::pair<MemoryLocation, MemoryLocation>;\n  struct CacheEntry {\n    AliasResult Result;\n    /// Number of times a NoAlias assumption has been used.\n    /// 0 for assumptions that have not been used, -1 for definitive results.\n    int NumAssumptionUses;\n    /// Whether this is a definitive (non-assumption) result.\n    bool isDefinitive() const { return NumAssumptionUses < 0; }\n  };\n  using AliasCacheT = SmallDenseMap<LocPair, CacheEntry, 8>;\n  AliasCacheT AliasCache;\n\n  using IsCapturedCacheT = SmallDenseMap<const Value *, bool, 8>;\n  IsCapturedCacheT IsCapturedCache;\n\n  /// Query depth used to distinguish recursive queries.\n  unsigned Depth = 0;\n\n  /// How many active NoAlias assumption uses there are.\n  int NumAssumptionUses = 0;\n\n  /// Location pairs for which an assumption based result is currently stored.\n  /// Used to remove all potentially incorrect results from the cache if an\n  /// assumption is disproven.\n  SmallVector<AAQueryInfo::LocPair, 4> AssumptionBasedResults;\n\n  AAQueryInfo(bool CacheOffsets = false)\n      : CacheOffsets(CacheOffsets), ClobberOffsets(), AliasCache(),\n        IsCapturedCache() {}\n\n  /// Create a new AAQueryInfo based on this one, but with the cache cleared.\n  /// This is used for recursive queries across phis, where cache results may\n  /// not be valid.\n  AAQueryInfo withEmptyCache() {\n    AAQueryInfo NewAAQI;\n    NewAAQI.Depth = Depth;\n    return NewAAQI;\n  }\n\n  Optional<int64_t> getClobberOffset(const Value *Ptr1, const Value *Ptr2,\n                                     uint64_t Size1, uint64_t Size2) const {\n    assert(CacheOffsets && \"Clobber offset cached in batch mode only!\");\n    const bool Swapped = Ptr1 > Ptr2;\n    if (Swapped) {\n      std::swap(Ptr1, Ptr2);\n      std::swap(Size1, Size2);\n    }\n    const auto IOff = ClobberOffsets.find({{Ptr1, Ptr2}, {Size1, Size2}});\n    if (IOff != ClobberOffsets.end())\n      return Swapped ? -IOff->second : IOff->second;\n    return None;\n  }\n\n  void setClobberOffset(const Value *Ptr1, const Value *Ptr2, uint64_t Size1,\n                        uint64_t Size2, int64_t Offset) {\n    // Cache offset for batch mode only.\n    if (!CacheOffsets)\n      return;\n    if (Ptr1 > Ptr2) {\n      std::swap(Ptr1, Ptr2);\n      std::swap(Size1, Size2);\n      Offset = -Offset;\n    }\n    ClobberOffsets[{{Ptr1, Ptr2}, {Size1, Size2}}] = Offset;\n  }\n};\n\nclass BatchAAResults;\n\nclass AAResults {\npublic:\n  // Make these results default constructable and movable. We have to spell\n  // these out because MSVC won't synthesize them.\n  AAResults(const TargetLibraryInfo &TLI) : TLI(TLI) {}\n  AAResults(AAResults &&Arg);\n  ~AAResults();\n\n  /// Register a specific AA result.\n  template <typename AAResultT> void addAAResult(AAResultT &AAResult) {\n    // FIXME: We should use a much lighter weight system than the usual\n    // polymorphic pattern because we don't own AAResult. It should\n    // ideally involve two pointers and no separate allocation.\n    AAs.emplace_back(new Model<AAResultT>(AAResult, *this));\n  }\n\n  /// Register a function analysis ID that the results aggregation depends on.\n  ///\n  /// This is used in the new pass manager to implement the invalidation logic\n  /// where we must invalidate the results aggregation if any of our component\n  /// analyses become invalid.\n  void addAADependencyID(AnalysisKey *ID) { AADeps.push_back(ID); }\n\n  /// Handle invalidation events in the new pass manager.\n  ///\n  /// The aggregation is invalidated if any of the underlying analyses is\n  /// invalidated.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\n  //===--------------------------------------------------------------------===//\n  /// \\name Alias Queries\n  /// @{\n\n  /// The main low level interface to the alias analysis implementation.\n  /// Returns an AliasResult indicating whether the two pointers are aliased to\n  /// each other. This is the interface that must be implemented by specific\n  /// alias analysis implementations.\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB);\n\n  /// A convenience wrapper around the primary \\c alias interface.\n  AliasResult alias(const Value *V1, LocationSize V1Size, const Value *V2,\n                    LocationSize V2Size) {\n    return alias(MemoryLocation(V1, V1Size), MemoryLocation(V2, V2Size));\n  }\n\n  /// A convenience wrapper around the primary \\c alias interface.\n  AliasResult alias(const Value *V1, const Value *V2) {\n    return alias(MemoryLocation::getBeforeOrAfter(V1),\n                 MemoryLocation::getBeforeOrAfter(V2));\n  }\n\n  /// A trivial helper function to check to see if the specified pointers are\n  /// no-alias.\n  bool isNoAlias(const MemoryLocation &LocA, const MemoryLocation &LocB) {\n    return alias(LocA, LocB) == NoAlias;\n  }\n\n  /// A convenience wrapper around the \\c isNoAlias helper interface.\n  bool isNoAlias(const Value *V1, LocationSize V1Size, const Value *V2,\n                 LocationSize V2Size) {\n    return isNoAlias(MemoryLocation(V1, V1Size), MemoryLocation(V2, V2Size));\n  }\n\n  /// A convenience wrapper around the \\c isNoAlias helper interface.\n  bool isNoAlias(const Value *V1, const Value *V2) {\n    return isNoAlias(MemoryLocation::getBeforeOrAfter(V1),\n                     MemoryLocation::getBeforeOrAfter(V2));\n  }\n\n  /// A trivial helper function to check to see if the specified pointers are\n  /// must-alias.\n  bool isMustAlias(const MemoryLocation &LocA, const MemoryLocation &LocB) {\n    return alias(LocA, LocB) == MustAlias;\n  }\n\n  /// A convenience wrapper around the \\c isMustAlias helper interface.\n  bool isMustAlias(const Value *V1, const Value *V2) {\n    return alias(V1, LocationSize::precise(1), V2, LocationSize::precise(1)) ==\n           MustAlias;\n  }\n\n  /// Checks whether the given location points to constant memory, or if\n  /// \\p OrLocal is true whether it points to a local alloca.\n  bool pointsToConstantMemory(const MemoryLocation &Loc, bool OrLocal = false);\n\n  /// A convenience wrapper around the primary \\c pointsToConstantMemory\n  /// interface.\n  bool pointsToConstantMemory(const Value *P, bool OrLocal = false) {\n    return pointsToConstantMemory(MemoryLocation::getBeforeOrAfter(P), OrLocal);\n  }\n\n  /// @}\n  //===--------------------------------------------------------------------===//\n  /// \\name Simple mod/ref information\n  /// @{\n\n  /// Get the ModRef info associated with a pointer argument of a call. The\n  /// result's bits are set to indicate the allowed aliasing ModRef kinds. Note\n  /// that these bits do not necessarily account for the overall behavior of\n  /// the function, but rather only provide additional per-argument\n  /// information. This never sets ModRefInfo::Must.\n  ModRefInfo getArgModRefInfo(const CallBase *Call, unsigned ArgIdx);\n\n  /// Return the behavior of the given call site.\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call);\n\n  /// Return the behavior when calling the given function.\n  FunctionModRefBehavior getModRefBehavior(const Function *F);\n\n  /// Checks if the specified call is known to never read or write memory.\n  ///\n  /// Note that if the call only reads from known-constant memory, it is also\n  /// legal to return true. Also, calls that unwind the stack are legal for\n  /// this predicate.\n  ///\n  /// Many optimizations (such as CSE and LICM) can be performed on such calls\n  /// without worrying about aliasing properties, and many calls have this\n  /// property (e.g. calls to 'sin' and 'cos').\n  ///\n  /// This property corresponds to the GCC 'const' attribute.\n  bool doesNotAccessMemory(const CallBase *Call) {\n    return getModRefBehavior(Call) == FMRB_DoesNotAccessMemory;\n  }\n\n  /// Checks if the specified function is known to never read or write memory.\n  ///\n  /// Note that if the function only reads from known-constant memory, it is\n  /// also legal to return true. Also, function that unwind the stack are legal\n  /// for this predicate.\n  ///\n  /// Many optimizations (such as CSE and LICM) can be performed on such calls\n  /// to such functions without worrying about aliasing properties, and many\n  /// functions have this property (e.g. 'sin' and 'cos').\n  ///\n  /// This property corresponds to the GCC 'const' attribute.\n  bool doesNotAccessMemory(const Function *F) {\n    return getModRefBehavior(F) == FMRB_DoesNotAccessMemory;\n  }\n\n  /// Checks if the specified call is known to only read from non-volatile\n  /// memory (or not access memory at all).\n  ///\n  /// Calls that unwind the stack are legal for this predicate.\n  ///\n  /// This property allows many common optimizations to be performed in the\n  /// absence of interfering store instructions, such as CSE of strlen calls.\n  ///\n  /// This property corresponds to the GCC 'pure' attribute.\n  bool onlyReadsMemory(const CallBase *Call) {\n    return onlyReadsMemory(getModRefBehavior(Call));\n  }\n\n  /// Checks if the specified function is known to only read from non-volatile\n  /// memory (or not access memory at all).\n  ///\n  /// Functions that unwind the stack are legal for this predicate.\n  ///\n  /// This property allows many common optimizations to be performed in the\n  /// absence of interfering store instructions, such as CSE of strlen calls.\n  ///\n  /// This property corresponds to the GCC 'pure' attribute.\n  bool onlyReadsMemory(const Function *F) {\n    return onlyReadsMemory(getModRefBehavior(F));\n  }\n\n  /// Checks if functions with the specified behavior are known to only read\n  /// from non-volatile memory (or not access memory at all).\n  static bool onlyReadsMemory(FunctionModRefBehavior MRB) {\n    return !isModSet(createModRefInfo(MRB));\n  }\n\n  /// Checks if functions with the specified behavior are known to only write\n  /// memory (or not access memory at all).\n  static bool doesNotReadMemory(FunctionModRefBehavior MRB) {\n    return !isRefSet(createModRefInfo(MRB));\n  }\n\n  /// Checks if functions with the specified behavior are known to read and\n  /// write at most from objects pointed to by their pointer-typed arguments\n  /// (with arbitrary offsets).\n  static bool onlyAccessesArgPointees(FunctionModRefBehavior MRB) {\n    return !((unsigned)MRB & FMRL_Anywhere & ~FMRL_ArgumentPointees);\n  }\n\n  /// Checks if functions with the specified behavior are known to potentially\n  /// read or write from objects pointed to be their pointer-typed arguments\n  /// (with arbitrary offsets).\n  static bool doesAccessArgPointees(FunctionModRefBehavior MRB) {\n    return isModOrRefSet(createModRefInfo(MRB)) &&\n           ((unsigned)MRB & FMRL_ArgumentPointees);\n  }\n\n  /// Checks if functions with the specified behavior are known to read and\n  /// write at most from memory that is inaccessible from LLVM IR.\n  static bool onlyAccessesInaccessibleMem(FunctionModRefBehavior MRB) {\n    return !((unsigned)MRB & FMRL_Anywhere & ~FMRL_InaccessibleMem);\n  }\n\n  /// Checks if functions with the specified behavior are known to potentially\n  /// read or write from memory that is inaccessible from LLVM IR.\n  static bool doesAccessInaccessibleMem(FunctionModRefBehavior MRB) {\n    return isModOrRefSet(createModRefInfo(MRB)) &&\n             ((unsigned)MRB & FMRL_InaccessibleMem);\n  }\n\n  /// Checks if functions with the specified behavior are known to read and\n  /// write at most from memory that is inaccessible from LLVM IR or objects\n  /// pointed to by their pointer-typed arguments (with arbitrary offsets).\n  static bool onlyAccessesInaccessibleOrArgMem(FunctionModRefBehavior MRB) {\n    return !((unsigned)MRB & FMRL_Anywhere &\n             ~(FMRL_InaccessibleMem | FMRL_ArgumentPointees));\n  }\n\n  /// getModRefInfo (for call sites) - Return information about whether\n  /// a particular call site modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for call sites) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const CallBase *Call, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(Call, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for loads) - Return information about whether\n  /// a particular load modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const LoadInst *L, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for loads) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const LoadInst *L, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(L, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for stores) - Return information about whether\n  /// a particular store modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const StoreInst *S, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for stores) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const StoreInst *S, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(S, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for fences) - Return information about whether\n  /// a particular store modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const FenceInst *S, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for fences) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const FenceInst *S, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(S, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for cmpxchges) - Return information about whether\n  /// a particular cmpxchg modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const AtomicCmpXchgInst *CX,\n                           const MemoryLocation &Loc);\n\n  /// getModRefInfo (for cmpxchges) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const AtomicCmpXchgInst *CX, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(CX, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for atomicrmws) - Return information about whether\n  /// a particular atomicrmw modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const AtomicRMWInst *RMW, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for atomicrmws) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const AtomicRMWInst *RMW, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(RMW, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for va_args) - Return information about whether\n  /// a particular va_arg modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const VAArgInst *I, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for va_args) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const VAArgInst *I, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(I, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for catchpads) - Return information about whether\n  /// a particular catchpad modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const CatchPadInst *I, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for catchpads) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const CatchPadInst *I, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(I, MemoryLocation(P, Size));\n  }\n\n  /// getModRefInfo (for catchrets) - Return information about whether\n  /// a particular catchret modifies or reads the specified memory location.\n  ModRefInfo getModRefInfo(const CatchReturnInst *I, const MemoryLocation &Loc);\n\n  /// getModRefInfo (for catchrets) - A convenience wrapper.\n  ModRefInfo getModRefInfo(const CatchReturnInst *I, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(I, MemoryLocation(P, Size));\n  }\n\n  /// Check whether or not an instruction may read or write the optionally\n  /// specified memory location.\n  ///\n  ///\n  /// An instruction that doesn't read or write memory may be trivially LICM'd\n  /// for example.\n  ///\n  /// For function calls, this delegates to the alias-analysis specific\n  /// call-site mod-ref behavior queries. Otherwise it delegates to the specific\n  /// helpers above.\n  ModRefInfo getModRefInfo(const Instruction *I,\n                           const Optional<MemoryLocation> &OptLoc) {\n    AAQueryInfo AAQIP;\n    return getModRefInfo(I, OptLoc, AAQIP);\n  }\n\n  /// A convenience wrapper for constructing the memory location.\n  ModRefInfo getModRefInfo(const Instruction *I, const Value *P,\n                           LocationSize Size) {\n    return getModRefInfo(I, MemoryLocation(P, Size));\n  }\n\n  /// Return information about whether a call and an instruction may refer to\n  /// the same memory locations.\n  ModRefInfo getModRefInfo(Instruction *I, const CallBase *Call);\n\n  /// Return information about whether two call sites may refer to the same set\n  /// of memory locations. See the AA documentation for details:\n  ///   http://llvm.org/docs/AliasAnalysis.html#ModRefInfo\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2);\n\n  /// Return information about whether a particular call site modifies\n  /// or reads the specified memory location \\p MemLoc before instruction \\p I\n  /// in a BasicBlock.\n  /// Early exits in callCapturesBefore may lead to ModRefInfo::Must not being\n  /// set.\n  ModRefInfo callCapturesBefore(const Instruction *I,\n                                const MemoryLocation &MemLoc, DominatorTree *DT);\n\n  /// A convenience wrapper to synthesize a memory location.\n  ModRefInfo callCapturesBefore(const Instruction *I, const Value *P,\n                                LocationSize Size, DominatorTree *DT) {\n    return callCapturesBefore(I, MemoryLocation(P, Size), DT);\n  }\n\n  /// @}\n  //===--------------------------------------------------------------------===//\n  /// \\name Higher level methods for querying mod/ref information.\n  /// @{\n\n  /// Check if it is possible for execution of the specified basic block to\n  /// modify the location Loc.\n  bool canBasicBlockModify(const BasicBlock &BB, const MemoryLocation &Loc);\n\n  /// A convenience wrapper synthesizing a memory location.\n  bool canBasicBlockModify(const BasicBlock &BB, const Value *P,\n                           LocationSize Size) {\n    return canBasicBlockModify(BB, MemoryLocation(P, Size));\n  }\n\n  /// Check if it is possible for the execution of the specified instructions\n  /// to mod\\ref (according to the mode) the location Loc.\n  ///\n  /// The instructions to consider are all of the instructions in the range of\n  /// [I1,I2] INCLUSIVE. I1 and I2 must be in the same basic block.\n  bool canInstructionRangeModRef(const Instruction &I1, const Instruction &I2,\n                                 const MemoryLocation &Loc,\n                                 const ModRefInfo Mode);\n\n  /// A convenience wrapper synthesizing a memory location.\n  bool canInstructionRangeModRef(const Instruction &I1, const Instruction &I2,\n                                 const Value *Ptr, LocationSize Size,\n                                 const ModRefInfo Mode) {\n    return canInstructionRangeModRef(I1, I2, MemoryLocation(Ptr, Size), Mode);\n  }\n\nprivate:\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n  bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                              bool OrLocal = false);\n  ModRefInfo getModRefInfo(Instruction *I, const CallBase *Call2,\n                           AAQueryInfo &AAQIP);\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const VAArgInst *V, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const LoadInst *L, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const StoreInst *S, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const FenceInst *S, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const AtomicCmpXchgInst *CX,\n                           const MemoryLocation &Loc, AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const AtomicRMWInst *RMW, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const CatchPadInst *I, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const CatchReturnInst *I, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const Instruction *I,\n                           const Optional<MemoryLocation> &OptLoc,\n                           AAQueryInfo &AAQIP);\n\n  class Concept;\n\n  template <typename T> class Model;\n\n  template <typename T> friend class AAResultBase;\n\n  const TargetLibraryInfo &TLI;\n\n  std::vector<std::unique_ptr<Concept>> AAs;\n\n  std::vector<AnalysisKey *> AADeps;\n\n  friend class BatchAAResults;\n};\n\n/// This class is a wrapper over an AAResults, and it is intended to be used\n/// only when there are no IR changes inbetween queries. BatchAAResults is\n/// reusing the same `AAQueryInfo` to preserve the state across queries,\n/// esentially making AA work in \"batch mode\". The internal state cannot be\n/// cleared, so to go \"out-of-batch-mode\", the user must either use AAResults,\n/// or create a new BatchAAResults.\nclass BatchAAResults {\n  AAResults &AA;\n  AAQueryInfo AAQI;\n\npublic:\n  BatchAAResults(AAResults &AAR, bool CacheOffsets = false)\n      : AA(AAR), AAQI(CacheOffsets) {}\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB) {\n    return AA.alias(LocA, LocB, AAQI);\n  }\n  bool pointsToConstantMemory(const MemoryLocation &Loc, bool OrLocal = false) {\n    return AA.pointsToConstantMemory(Loc, AAQI, OrLocal);\n  }\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc) {\n    return AA.getModRefInfo(Call, Loc, AAQI);\n  }\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2) {\n    return AA.getModRefInfo(Call1, Call2, AAQI);\n  }\n  ModRefInfo getModRefInfo(const Instruction *I,\n                           const Optional<MemoryLocation> &OptLoc) {\n    return AA.getModRefInfo(I, OptLoc, AAQI);\n  }\n  ModRefInfo getModRefInfo(Instruction *I, const CallBase *Call2) {\n    return AA.getModRefInfo(I, Call2, AAQI);\n  }\n  ModRefInfo getArgModRefInfo(const CallBase *Call, unsigned ArgIdx) {\n    return AA.getArgModRefInfo(Call, ArgIdx);\n  }\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call) {\n    return AA.getModRefBehavior(Call);\n  }\n  bool isMustAlias(const MemoryLocation &LocA, const MemoryLocation &LocB) {\n    return alias(LocA, LocB) == MustAlias;\n  }\n  bool isMustAlias(const Value *V1, const Value *V2) {\n    return alias(MemoryLocation(V1, LocationSize::precise(1)),\n                 MemoryLocation(V2, LocationSize::precise(1))) == MustAlias;\n  }\n  Optional<int64_t> getClobberOffset(const MemoryLocation &LocA,\n                                     const MemoryLocation &LocB) const;\n};\n\n/// Temporary typedef for legacy code that uses a generic \\c AliasAnalysis\n/// pointer or reference.\nusing AliasAnalysis = AAResults;\n\n/// A private abstract base class describing the concept of an individual alias\n/// analysis implementation.\n///\n/// This interface is implemented by any \\c Model instantiation. It is also the\n/// interface which a type used to instantiate the model must provide.\n///\n/// All of these methods model methods by the same name in the \\c\n/// AAResults class. Only differences and specifics to how the\n/// implementations are called are documented here.\nclass AAResults::Concept {\npublic:\n  virtual ~Concept() = 0;\n\n  /// An update API used internally by the AAResults to provide\n  /// a handle back to the top level aggregation.\n  virtual void setAAResults(AAResults *NewAAR) = 0;\n\n  //===--------------------------------------------------------------------===//\n  /// \\name Alias Queries\n  /// @{\n\n  /// The main low level interface to the alias analysis implementation.\n  /// Returns an AliasResult indicating whether the two pointers are aliased to\n  /// each other. This is the interface that must be implemented by specific\n  /// alias analysis implementations.\n  virtual AliasResult alias(const MemoryLocation &LocA,\n                            const MemoryLocation &LocB, AAQueryInfo &AAQI) = 0;\n\n  /// Checks whether the given location points to constant memory, or if\n  /// \\p OrLocal is true whether it points to a local alloca.\n  virtual bool pointsToConstantMemory(const MemoryLocation &Loc,\n                                      AAQueryInfo &AAQI, bool OrLocal) = 0;\n\n  /// @}\n  //===--------------------------------------------------------------------===//\n  /// \\name Simple mod/ref information\n  /// @{\n\n  /// Get the ModRef info associated with a pointer argument of a callsite. The\n  /// result's bits are set to indicate the allowed aliasing ModRef kinds. Note\n  /// that these bits do not necessarily account for the overall behavior of\n  /// the function, but rather only provide additional per-argument\n  /// information.\n  virtual ModRefInfo getArgModRefInfo(const CallBase *Call,\n                                      unsigned ArgIdx) = 0;\n\n  /// Return the behavior of the given call site.\n  virtual FunctionModRefBehavior getModRefBehavior(const CallBase *Call) = 0;\n\n  /// Return the behavior when calling the given function.\n  virtual FunctionModRefBehavior getModRefBehavior(const Function *F) = 0;\n\n  /// getModRefInfo (for call sites) - Return information about whether\n  /// a particular call site modifies or reads the specified memory location.\n  virtual ModRefInfo getModRefInfo(const CallBase *Call,\n                                   const MemoryLocation &Loc,\n                                   AAQueryInfo &AAQI) = 0;\n\n  /// Return information about whether two call sites may refer to the same set\n  /// of memory locations. See the AA documentation for details:\n  ///   http://llvm.org/docs/AliasAnalysis.html#ModRefInfo\n  virtual ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                                   AAQueryInfo &AAQI) = 0;\n\n  /// @}\n};\n\n/// A private class template which derives from \\c Concept and wraps some other\n/// type.\n///\n/// This models the concept by directly forwarding each interface point to the\n/// wrapped type which must implement a compatible interface. This provides\n/// a type erased binding.\ntemplate <typename AAResultT> class AAResults::Model final : public Concept {\n  AAResultT &Result;\n\npublic:\n  explicit Model(AAResultT &Result, AAResults &AAR) : Result(Result) {\n    Result.setAAResults(&AAR);\n  }\n  ~Model() override = default;\n\n  void setAAResults(AAResults *NewAAR) override { Result.setAAResults(NewAAR); }\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI) override {\n    return Result.alias(LocA, LocB, AAQI);\n  }\n\n  bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                              bool OrLocal) override {\n    return Result.pointsToConstantMemory(Loc, AAQI, OrLocal);\n  }\n\n  ModRefInfo getArgModRefInfo(const CallBase *Call, unsigned ArgIdx) override {\n    return Result.getArgModRefInfo(Call, ArgIdx);\n  }\n\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call) override {\n    return Result.getModRefBehavior(Call);\n  }\n\n  FunctionModRefBehavior getModRefBehavior(const Function *F) override {\n    return Result.getModRefBehavior(F);\n  }\n\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI) override {\n    return Result.getModRefInfo(Call, Loc, AAQI);\n  }\n\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                           AAQueryInfo &AAQI) override {\n    return Result.getModRefInfo(Call1, Call2, AAQI);\n  }\n};\n\n/// A CRTP-driven \"mixin\" base class to help implement the function alias\n/// analysis results concept.\n///\n/// Because of the nature of many alias analysis implementations, they often\n/// only implement a subset of the interface. This base class will attempt to\n/// implement the remaining portions of the interface in terms of simpler forms\n/// of the interface where possible, and otherwise provide conservatively\n/// correct fallback implementations.\n///\n/// Implementors of an alias analysis should derive from this CRTP, and then\n/// override specific methods that they wish to customize. There is no need to\n/// use virtual anywhere, the CRTP base class does static dispatch to the\n/// derived type passed into it.\ntemplate <typename DerivedT> class AAResultBase {\n  // Expose some parts of the interface only to the AAResults::Model\n  // for wrapping. Specifically, this allows the model to call our\n  // setAAResults method without exposing it as a fully public API.\n  friend class AAResults::Model<DerivedT>;\n\n  /// A pointer to the AAResults object that this AAResult is\n  /// aggregated within. May be null if not aggregated.\n  AAResults *AAR = nullptr;\n\n  /// Helper to dispatch calls back through the derived type.\n  DerivedT &derived() { return static_cast<DerivedT &>(*this); }\n\n  /// A setter for the AAResults pointer, which is used to satisfy the\n  /// AAResults::Model contract.\n  void setAAResults(AAResults *NewAAR) { AAR = NewAAR; }\n\nprotected:\n  /// This proxy class models a common pattern where we delegate to either the\n  /// top-level \\c AAResults aggregation if one is registered, or to the\n  /// current result if none are registered.\n  class AAResultsProxy {\n    AAResults *AAR;\n    DerivedT &CurrentResult;\n\n  public:\n    AAResultsProxy(AAResults *AAR, DerivedT &CurrentResult)\n        : AAR(AAR), CurrentResult(CurrentResult) {}\n\n    AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                      AAQueryInfo &AAQI) {\n      return AAR ? AAR->alias(LocA, LocB, AAQI)\n                 : CurrentResult.alias(LocA, LocB, AAQI);\n    }\n\n    bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                                bool OrLocal) {\n      return AAR ? AAR->pointsToConstantMemory(Loc, AAQI, OrLocal)\n                 : CurrentResult.pointsToConstantMemory(Loc, AAQI, OrLocal);\n    }\n\n    ModRefInfo getArgModRefInfo(const CallBase *Call, unsigned ArgIdx) {\n      return AAR ? AAR->getArgModRefInfo(Call, ArgIdx)\n                 : CurrentResult.getArgModRefInfo(Call, ArgIdx);\n    }\n\n    FunctionModRefBehavior getModRefBehavior(const CallBase *Call) {\n      return AAR ? AAR->getModRefBehavior(Call)\n                 : CurrentResult.getModRefBehavior(Call);\n    }\n\n    FunctionModRefBehavior getModRefBehavior(const Function *F) {\n      return AAR ? AAR->getModRefBehavior(F) : CurrentResult.getModRefBehavior(F);\n    }\n\n    ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                             AAQueryInfo &AAQI) {\n      return AAR ? AAR->getModRefInfo(Call, Loc, AAQI)\n                 : CurrentResult.getModRefInfo(Call, Loc, AAQI);\n    }\n\n    ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                             AAQueryInfo &AAQI) {\n      return AAR ? AAR->getModRefInfo(Call1, Call2, AAQI)\n                 : CurrentResult.getModRefInfo(Call1, Call2, AAQI);\n    }\n  };\n\n  explicit AAResultBase() = default;\n\n  // Provide all the copy and move constructors so that derived types aren't\n  // constrained.\n  AAResultBase(const AAResultBase &Arg) {}\n  AAResultBase(AAResultBase &&Arg) {}\n\n  /// Get a proxy for the best AA result set to query at this time.\n  ///\n  /// When this result is part of a larger aggregation, this will proxy to that\n  /// aggregation. When this result is used in isolation, it will just delegate\n  /// back to the derived class's implementation.\n  ///\n  /// Note that callers of this need to take considerable care to not cause\n  /// performance problems when they use this routine, in the case of a large\n  /// number of alias analyses being aggregated, it can be expensive to walk\n  /// back across the chain.\n  AAResultsProxy getBestAAResults() { return AAResultsProxy(AAR, derived()); }\n\npublic:\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI) {\n    return MayAlias;\n  }\n\n  bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                              bool OrLocal) {\n    return false;\n  }\n\n  ModRefInfo getArgModRefInfo(const CallBase *Call, unsigned ArgIdx) {\n    return ModRefInfo::ModRef;\n  }\n\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call) {\n    return FMRB_UnknownModRefBehavior;\n  }\n\n  FunctionModRefBehavior getModRefBehavior(const Function *F) {\n    return FMRB_UnknownModRefBehavior;\n  }\n\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI) {\n    return ModRefInfo::ModRef;\n  }\n\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                           AAQueryInfo &AAQI) {\n    return ModRefInfo::ModRef;\n  }\n};\n\n/// Return true if this pointer is returned by a noalias function.\nbool isNoAliasCall(const Value *V);\n\n/// Return true if this pointer refers to a distinct and identifiable object.\n/// This returns true for:\n///    Global Variables and Functions (but not Global Aliases)\n///    Allocas\n///    ByVal and NoAlias Arguments\n///    NoAlias returns (e.g. calls to malloc)\n///\nbool isIdentifiedObject(const Value *V);\n\n/// Return true if V is umabigously identified at the function-level.\n/// Different IdentifiedFunctionLocals can't alias.\n/// Further, an IdentifiedFunctionLocal can not alias with any function\n/// arguments other than itself, which is not necessarily true for\n/// IdentifiedObjects.\nbool isIdentifiedFunctionLocal(const Value *V);\n\n/// A manager for alias analyses.\n///\n/// This class can have analyses registered with it and when run, it will run\n/// all of them and aggregate their results into single AA results interface\n/// that dispatches across all of the alias analysis results available.\n///\n/// Note that the order in which analyses are registered is very significant.\n/// That is the order in which the results will be aggregated and queried.\n///\n/// This manager effectively wraps the AnalysisManager for registering alias\n/// analyses. When you register your alias analysis with this manager, it will\n/// ensure the analysis itself is registered with its AnalysisManager.\n///\n/// The result of this analysis is only invalidated if one of the particular\n/// aggregated AA results end up being invalidated. This removes the need to\n/// explicitly preserve the results of `AAManager`. Note that analyses should no\n/// longer be registered once the `AAManager` is run.\nclass AAManager : public AnalysisInfoMixin<AAManager> {\npublic:\n  using Result = AAResults;\n\n  /// Register a specific AA result.\n  template <typename AnalysisT> void registerFunctionAnalysis() {\n    ResultGetters.push_back(&getFunctionAAResultImpl<AnalysisT>);\n  }\n\n  /// Register a specific AA result.\n  template <typename AnalysisT> void registerModuleAnalysis() {\n    ResultGetters.push_back(&getModuleAAResultImpl<AnalysisT>);\n  }\n\n  Result run(Function &F, FunctionAnalysisManager &AM);\n\nprivate:\n  friend AnalysisInfoMixin<AAManager>;\n\n  static AnalysisKey Key;\n\n  SmallVector<void (*)(Function &F, FunctionAnalysisManager &AM,\n                       AAResults &AAResults),\n              4> ResultGetters;\n\n  template <typename AnalysisT>\n  static void getFunctionAAResultImpl(Function &F,\n                                      FunctionAnalysisManager &AM,\n                                      AAResults &AAResults) {\n    AAResults.addAAResult(AM.template getResult<AnalysisT>(F));\n    AAResults.addAADependencyID(AnalysisT::ID());\n  }\n\n  template <typename AnalysisT>\n  static void getModuleAAResultImpl(Function &F, FunctionAnalysisManager &AM,\n                                    AAResults &AAResults) {\n    auto &MAMProxy = AM.getResult<ModuleAnalysisManagerFunctionProxy>(F);\n    if (auto *R =\n            MAMProxy.template getCachedResult<AnalysisT>(*F.getParent())) {\n      AAResults.addAAResult(*R);\n      MAMProxy\n          .template registerOuterAnalysisInvalidation<AnalysisT, AAManager>();\n    }\n  }\n};\n\n/// A wrapper pass to provide the legacy pass manager access to a suitably\n/// prepared AAResults object.\nclass AAResultsWrapperPass : public FunctionPass {\n  std::unique_ptr<AAResults> AAR;\n\npublic:\n  static char ID;\n\n  AAResultsWrapperPass();\n\n  AAResults &getAAResults() { return *AAR; }\n  const AAResults &getAAResults() const { return *AAR; }\n\n  bool runOnFunction(Function &F) override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n/// A wrapper pass for external alias analyses. This just squirrels away the\n/// callback used to run any analyses and register their results.\nstruct ExternalAAWrapperPass : ImmutablePass {\n  using CallbackT = std::function<void(Pass &, Function &, AAResults &)>;\n\n  CallbackT CB;\n\n  static char ID;\n\n  ExternalAAWrapperPass();\n\n  explicit ExternalAAWrapperPass(CallbackT CB);\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override {\n    AU.setPreservesAll();\n  }\n};\n\nFunctionPass *createAAResultsWrapperPass();\n\n/// A wrapper pass around a callback which can be used to populate the\n/// AAResults in the AAResultsWrapperPass from an external AA.\n///\n/// The callback provided here will be used each time we prepare an AAResults\n/// object, and will receive a reference to the function wrapper pass, the\n/// function, and the AAResults object to populate. This should be used when\n/// setting up a custom pass pipeline to inject a hook into the AA results.\nImmutablePass *createExternalAAWrapperPass(\n    std::function<void(Pass &, Function &, AAResults &)> Callback);\n\n/// A helper for the legacy pass manager to create a \\c AAResults\n/// object populated to the best of our ability for a particular function when\n/// inside of a \\c ModulePass or a \\c CallGraphSCCPass.\n///\n/// If a \\c ModulePass or a \\c CallGraphSCCPass calls \\p\n/// createLegacyPMAAResults, it also needs to call \\p addUsedAAAnalyses in \\p\n/// getAnalysisUsage.\nAAResults createLegacyPMAAResults(Pass &P, Function &F, BasicAAResult &BAR);\n\n/// A helper for the legacy pass manager to populate \\p AU to add uses to make\n/// sure the analyses required by \\p createLegacyPMAAResults are available.\nvoid getAAResultsAnalysisUsage(AnalysisUsage &AU);\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_ALIASANALYSIS_H\n"}, "21": {"id": 21, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AssumptionCache.h", "content": "//===- llvm/Analysis/AssumptionCache.h - Track @llvm.assume -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file contains a pass that keeps track of @llvm.assume intrinsics in\n// the functions of a module (allowing assumptions within any function to be\n// found cheaply by other parts of the optimizer).\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_ASSUMPTIONCACHE_H\n#define LLVM_ANALYSIS_ASSUMPTIONCACHE_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n#include <memory>\n\nnamespace llvm {\n\nclass CallInst;\nclass Function;\nclass raw_ostream;\nclass Value;\n\n/// A cache of \\@llvm.assume calls within a function.\n///\n/// This cache provides fast lookup of assumptions within a function by caching\n/// them and amortizing the cost of scanning for them across all queries. Passes\n/// that create new assumptions are required to call registerAssumption() to\n/// register any new \\@llvm.assume calls that they create. Deletions of\n/// \\@llvm.assume calls do not require special handling.\nclass AssumptionCache {\npublic:\n  /// Value of ResultElem::Index indicating that the argument to the call of the\n  /// llvm.assume.\n  enum : unsigned { ExprResultIdx = std::numeric_limits<unsigned>::max() };\n\n  struct ResultElem {\n    WeakVH Assume;\n\n    /// contains either ExprResultIdx or the index of the operand bundle\n    /// containing the knowledge.\n    unsigned Index;\n    operator Value *() const { return Assume; }\n  };\n\nprivate:\n  /// The function for which this cache is handling assumptions.\n  ///\n  /// We track this to lazily populate our assumptions.\n  Function &F;\n\n  /// Vector of weak value handles to calls of the \\@llvm.assume\n  /// intrinsic.\n  SmallVector<ResultElem, 4> AssumeHandles;\n\n  class AffectedValueCallbackVH final : public CallbackVH {\n    AssumptionCache *AC;\n\n    void deleted() override;\n    void allUsesReplacedWith(Value *) override;\n\n  public:\n    using DMI = DenseMapInfo<Value *>;\n\n    AffectedValueCallbackVH(Value *V, AssumptionCache *AC = nullptr)\n        : CallbackVH(V), AC(AC) {}\n  };\n\n  friend AffectedValueCallbackVH;\n\n  /// A map of values about which an assumption might be providing\n  /// information to the relevant set of assumptions.\n  using AffectedValuesMap =\n      DenseMap<AffectedValueCallbackVH, SmallVector<ResultElem, 1>,\n               AffectedValueCallbackVH::DMI>;\n  AffectedValuesMap AffectedValues;\n\n  /// Get the vector of assumptions which affect a value from the cache.\n  SmallVector<ResultElem, 1> &getOrInsertAffectedValues(Value *V);\n\n  /// Move affected values in the cache for OV to be affected values for NV.\n  void transferAffectedValuesInCache(Value *OV, Value *NV);\n\n  /// Flag tracking whether we have scanned the function yet.\n  ///\n  /// We want to be as lazy about this as possible, and so we scan the function\n  /// at the last moment.\n  bool Scanned = false;\n\n  /// Scan the function for assumptions and add them to the cache.\n  void scanFunction();\n\npublic:\n  /// Construct an AssumptionCache from a function by scanning all of\n  /// its instructions.\n  AssumptionCache(Function &F) : F(F) {}\n\n  /// This cache is designed to be self-updating and so it should never be\n  /// invalidated.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  /// Add an \\@llvm.assume intrinsic to this function's cache.\n  ///\n  /// The call passed in must be an instruction within this function and must\n  /// not already be in the cache.\n  void registerAssumption(CallInst *CI);\n\n  /// Remove an \\@llvm.assume intrinsic from this function's cache if it has\n  /// been added to the cache earlier.\n  void unregisterAssumption(CallInst *CI);\n\n  /// Update the cache of values being affected by this assumption (i.e.\n  /// the values about which this assumption provides information).\n  void updateAffectedValues(CallInst *CI);\n\n  /// Clear the cache of \\@llvm.assume intrinsics for a function.\n  ///\n  /// It will be re-scanned the next time it is requested.\n  void clear() {\n    AssumeHandles.clear();\n    AffectedValues.clear();\n    Scanned = false;\n  }\n\n  /// Access the list of assumption handles currently tracked for this\n  /// function.\n  ///\n  /// Note that these produce weak handles that may be null. The caller must\n  /// handle that case.\n  /// FIXME: We should replace this with pointee_iterator<filter_iterator<...>>\n  /// when we can write that to filter out the null values. Then caller code\n  /// will become simpler.\n  MutableArrayRef<ResultElem> assumptions() {\n    if (!Scanned)\n      scanFunction();\n    return AssumeHandles;\n  }\n\n  /// Access the list of assumptions which affect this value.\n  MutableArrayRef<ResultElem> assumptionsFor(const Value *V) {\n    if (!Scanned)\n      scanFunction();\n\n    auto AVI = AffectedValues.find_as(const_cast<Value *>(V));\n    if (AVI == AffectedValues.end())\n      return MutableArrayRef<ResultElem>();\n\n    return AVI->second;\n  }\n};\n\n/// A function analysis which provides an \\c AssumptionCache.\n///\n/// This analysis is intended for use with the new pass manager and will vend\n/// assumption caches for a given function.\nclass AssumptionAnalysis : public AnalysisInfoMixin<AssumptionAnalysis> {\n  friend AnalysisInfoMixin<AssumptionAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = AssumptionCache;\n\n  AssumptionCache run(Function &F, FunctionAnalysisManager &) {\n    return AssumptionCache(F);\n  }\n};\n\n/// Printer pass for the \\c AssumptionAnalysis results.\nclass AssumptionPrinterPass : public PassInfoMixin<AssumptionPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit AssumptionPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// An immutable pass that tracks lazily created \\c AssumptionCache\n/// objects.\n///\n/// This is essentially a workaround for the legacy pass manager's weaknesses\n/// which associates each assumption cache with Function and clears it if the\n/// function is deleted. The nature of the AssumptionCache is that it is not\n/// invalidated by any changes to the function body and so this is sufficient\n/// to be conservatively correct.\nclass AssumptionCacheTracker : public ImmutablePass {\n  /// A callback value handle applied to function objects, which we use to\n  /// delete our cache of intrinsics for a function when it is deleted.\n  class FunctionCallbackVH final : public CallbackVH {\n    AssumptionCacheTracker *ACT;\n\n    void deleted() override;\n\n  public:\n    using DMI = DenseMapInfo<Value *>;\n\n    FunctionCallbackVH(Value *V, AssumptionCacheTracker *ACT = nullptr)\n        : CallbackVH(V), ACT(ACT) {}\n  };\n\n  friend FunctionCallbackVH;\n\n  using FunctionCallsMap =\n      DenseMap<FunctionCallbackVH, std::unique_ptr<AssumptionCache>,\n               FunctionCallbackVH::DMI>;\n\n  FunctionCallsMap AssumptionCaches;\n\npublic:\n  /// Get the cached assumptions for a function.\n  ///\n  /// If no assumptions are cached, this will scan the function. Otherwise, the\n  /// existing cache will be returned.\n  AssumptionCache &getAssumptionCache(Function &F);\n\n  /// Return the cached assumptions for a function if it has already been\n  /// scanned. Otherwise return nullptr.\n  AssumptionCache *lookupAssumptionCache(Function &F);\n\n  AssumptionCacheTracker();\n  ~AssumptionCacheTracker() override;\n\n  void releaseMemory() override {\n    verifyAnalysis();\n    AssumptionCaches.shrink_and_clear();\n  }\n\n  void verifyAnalysis() const override;\n\n  bool doFinalization(Module &) override {\n    verifyAnalysis();\n    return false;\n  }\n\n  static char ID; // Pass identification, replacement for typeid\n};\n\ntemplate<> struct simplify_type<AssumptionCache::ResultElem> {\n  using SimpleType = Value *;\n\n  static SimpleType getSimplifiedValue(AssumptionCache::ResultElem &Val) {\n    return Val;\n  }\n};\ntemplate<> struct simplify_type<const AssumptionCache::ResultElem> {\n  using SimpleType = /*const*/ Value *;\n\n  static SimpleType getSimplifiedValue(const AssumptionCache::ResultElem &Val) {\n    return Val;\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_ASSUMPTIONCACHE_H\n"}, "22": {"id": 22, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/BasicAliasAnalysis.h", "content": "//===- BasicAliasAnalysis.h - Stateless, local Alias Analysis ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This is the interface for LLVM's primary stateless and local alias analysis.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_BASICALIASANALYSIS_H\n#define LLVM_ANALYSIS_BASICALIASANALYSIS_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include <algorithm>\n#include <cstdint>\n#include <memory>\n#include <utility>\n\nnamespace llvm {\n\nstruct AAMDNodes;\nclass APInt;\nclass AssumptionCache;\nclass BasicBlock;\nclass DataLayout;\nclass DominatorTree;\nclass Function;\nclass GEPOperator;\nclass LoopInfo;\nclass PHINode;\nclass SelectInst;\nclass TargetLibraryInfo;\nclass PhiValues;\nclass Value;\n\n/// This is the AA result object for the basic, local, and stateless alias\n/// analysis. It implements the AA query interface in an entirely stateless\n/// manner. As one consequence, it is never invalidated due to IR changes.\n/// While it does retain some storage, that is used as an optimization and not\n/// to preserve information from query to query. However it does retain handles\n/// to various other analyses and must be recomputed when those analyses are.\nclass BasicAAResult : public AAResultBase<BasicAAResult> {\n  friend AAResultBase<BasicAAResult>;\n\n  const DataLayout &DL;\n  const Function &F;\n  const TargetLibraryInfo &TLI;\n  AssumptionCache &AC;\n  DominatorTree *DT;\n  LoopInfo *LI;\n  PhiValues *PV;\n\npublic:\n  BasicAAResult(const DataLayout &DL, const Function &F,\n                const TargetLibraryInfo &TLI, AssumptionCache &AC,\n                DominatorTree *DT = nullptr, LoopInfo *LI = nullptr,\n                PhiValues *PV = nullptr)\n      : AAResultBase(), DL(DL), F(F), TLI(TLI), AC(AC), DT(DT), LI(LI), PV(PV)\n        {}\n\n  BasicAAResult(const BasicAAResult &Arg)\n      : AAResultBase(Arg), DL(Arg.DL), F(Arg.F), TLI(Arg.TLI), AC(Arg.AC),\n        DT(Arg.DT),  LI(Arg.LI), PV(Arg.PV) {}\n  BasicAAResult(BasicAAResult &&Arg)\n      : AAResultBase(std::move(Arg)), DL(Arg.DL), F(Arg.F), TLI(Arg.TLI),\n        AC(Arg.AC), DT(Arg.DT), LI(Arg.LI), PV(Arg.PV) {}\n\n  /// Handle invalidation events in the new pass manager.\n  bool invalidate(Function &Fn, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                           AAQueryInfo &AAQI);\n\n  /// Chases pointers until we find a (constant global) or not.\n  bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                              bool OrLocal);\n\n  /// Get the location associated with a pointer argument of a callsite.\n  ModRefInfo getArgModRefInfo(const CallBase *Call, unsigned ArgIdx);\n\n  /// Returns the behavior when calling the given call site.\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call);\n\n  /// Returns the behavior when calling the given function. For use when the\n  /// call site is not known.\n  FunctionModRefBehavior getModRefBehavior(const Function *Fn);\n\nprivate:\n  // A linear transformation of a Value; this class represents ZExt(SExt(V,\n  // SExtBits), ZExtBits) * Scale + Offset.\n  struct VariableGEPIndex {\n    // An opaque Value - we can't decompose this further.\n    const Value *V;\n\n    // We need to track what extensions we've done as we consider the same Value\n    // with different extensions as different variables in a GEP's linear\n    // expression;\n    // e.g.: if V == -1, then sext(x) != zext(x).\n    unsigned ZExtBits;\n    unsigned SExtBits;\n\n    APInt Scale;\n\n    // Context instruction to use when querying information about this index.\n    const Instruction *CxtI;\n\n    void dump() const {\n      print(dbgs());\n      dbgs() << \"\\n\";\n    }\n    void print(raw_ostream &OS) const {\n      OS << \"(V=\" << V->getName()\n\t << \", zextbits=\" << ZExtBits\n\t << \", sextbits=\" << SExtBits\n\t << \", scale=\" << Scale << \")\";\n    }\n  };\n\n  // Represents the internal structure of a GEP, decomposed into a base pointer,\n  // constant offsets, and variable scaled indices.\n  struct DecomposedGEP {\n    // Base pointer of the GEP\n    const Value *Base;\n    // Total constant offset from base.\n    APInt Offset;\n    // Scaled variable (non-constant) indices.\n    SmallVector<VariableGEPIndex, 4> VarIndices;\n    // Is GEP index scale compile-time constant.\n    bool HasCompileTimeConstantScale;\n    // Are all operations inbounds GEPs or non-indexing operations?\n    // (None iff expression doesn't involve any geps)\n    Optional<bool> InBounds;\n\n    void dump() const {\n      print(dbgs());\n      dbgs() << \"\\n\";\n    }\n    void print(raw_ostream &OS) const {\n      OS << \"(DecomposedGEP Base=\" << Base->getName()\n         << \", Offset=\" << Offset\n         << \", VarIndices=[\";\n      for (size_t i = 0; i < VarIndices.size(); i++) {\n        if (i != 0)\n          OS << \", \";\n        VarIndices[i].print(OS);\n      }\n      OS << \"], HasCompileTimeConstantScale=\" << HasCompileTimeConstantScale\n         << \")\";\n    }\n  };\n\n  /// Tracks phi nodes we have visited.\n  ///\n  /// When interpret \"Value\" pointer equality as value equality we need to make\n  /// sure that the \"Value\" is not part of a cycle. Otherwise, two uses could\n  /// come from different \"iterations\" of a cycle and see different values for\n  /// the same \"Value\" pointer.\n  ///\n  /// The following example shows the problem:\n  ///   %p = phi(%alloca1, %addr2)\n  ///   %l = load %ptr\n  ///   %addr1 = gep, %alloca2, 0, %l\n  ///   %addr2 = gep  %alloca2, 0, (%l + 1)\n  ///      alias(%p, %addr1) -> MayAlias !\n  ///   store %l, ...\n  SmallPtrSet<const BasicBlock *, 8> VisitedPhiBBs;\n\n  /// Tracks instructions visited by pointsToConstantMemory.\n  SmallPtrSet<const Value *, 16> Visited;\n\n  static const Value *\n  GetLinearExpression(const Value *V, APInt &Scale, APInt &Offset,\n                      unsigned &ZExtBits, unsigned &SExtBits,\n                      const DataLayout &DL, unsigned Depth, AssumptionCache *AC,\n                      DominatorTree *DT, bool &NSW, bool &NUW);\n\n  static DecomposedGEP\n  DecomposeGEPExpression(const Value *V, const DataLayout &DL,\n                         AssumptionCache *AC, DominatorTree *DT);\n\n  static bool isGEPBaseAtNegativeOffset(const GEPOperator *GEPOp,\n      const DecomposedGEP &DecompGEP, const DecomposedGEP &DecompObject,\n      LocationSize ObjectAccessSize);\n\n  /// A Heuristic for aliasGEP that searches for a constant offset\n  /// between the variables.\n  ///\n  /// GetLinearExpression has some limitations, as generally zext(%x + 1)\n  /// != zext(%x) + zext(1) if the arithmetic overflows. GetLinearExpression\n  /// will therefore conservatively refuse to decompose these expressions.\n  /// However, we know that, for all %x, zext(%x) != zext(%x + 1), even if\n  /// the addition overflows.\n  bool\n  constantOffsetHeuristic(const SmallVectorImpl<VariableGEPIndex> &VarIndices,\n                          LocationSize V1Size, LocationSize V2Size,\n                          const APInt &BaseOffset, AssumptionCache *AC,\n                          DominatorTree *DT);\n\n  bool isValueEqualInPotentialCycles(const Value *V1, const Value *V2);\n\n  void GetIndexDifference(SmallVectorImpl<VariableGEPIndex> &Dest,\n                          const SmallVectorImpl<VariableGEPIndex> &Src);\n\n  AliasResult aliasGEP(const GEPOperator *V1, LocationSize V1Size,\n                       const AAMDNodes &V1AAInfo, const Value *V2,\n                       LocationSize V2Size, const AAMDNodes &V2AAInfo,\n                       const Value *UnderlyingV1, const Value *UnderlyingV2,\n                       AAQueryInfo &AAQI);\n\n  AliasResult aliasPHI(const PHINode *PN, LocationSize PNSize,\n                       const AAMDNodes &PNAAInfo, const Value *V2,\n                       LocationSize V2Size, const AAMDNodes &V2AAInfo,\n                       AAQueryInfo &AAQI);\n\n  AliasResult aliasSelect(const SelectInst *SI, LocationSize SISize,\n                          const AAMDNodes &SIAAInfo, const Value *V2,\n                          LocationSize V2Size, const AAMDNodes &V2AAInfo,\n                          AAQueryInfo &AAQI);\n\n  AliasResult aliasCheck(const Value *V1, LocationSize V1Size,\n                         const AAMDNodes &V1AATag, const Value *V2,\n                         LocationSize V2Size, const AAMDNodes &V2AATag,\n                         AAQueryInfo &AAQI);\n\n  AliasResult aliasCheckRecursive(const Value *V1, LocationSize V1Size,\n                                  const AAMDNodes &V1AATag, const Value *V2,\n                                  LocationSize V2Size, const AAMDNodes &V2AATag,\n                                  AAQueryInfo &AAQI, const Value *O1,\n                                  const Value *O2);\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\nclass BasicAA : public AnalysisInfoMixin<BasicAA> {\n  friend AnalysisInfoMixin<BasicAA>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = BasicAAResult;\n\n  BasicAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the BasicAAResult object.\nclass BasicAAWrapperPass : public FunctionPass {\n  std::unique_ptr<BasicAAResult> Result;\n\n  virtual void anchor();\n\npublic:\n  static char ID;\n\n  BasicAAWrapperPass();\n\n  BasicAAResult &getResult() { return *Result; }\n  const BasicAAResult &getResult() const { return *Result; }\n\n  bool runOnFunction(Function &F) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\nFunctionPass *createBasicAAWrapperPass();\n\n/// A helper for the legacy pass manager to create a \\c BasicAAResult object\n/// populated to the best of our ability for a particular function when inside\n/// of a \\c ModulePass or a \\c CallGraphSCCPass.\nBasicAAResult createLegacyPMBasicAAResult(Pass &P, Function &F);\n\n/// This class is a functor to be used in legacy module or SCC passes for\n/// computing AA results for a function. We store the results in fields so that\n/// they live long enough to be queried, but we re-use them each time.\nclass LegacyAARGetter {\n  Pass &P;\n  Optional<BasicAAResult> BAR;\n  Optional<AAResults> AAR;\n\npublic:\n  LegacyAARGetter(Pass &P) : P(P) {}\n  AAResults &operator()(Function &F) {\n    BAR.emplace(createLegacyPMBasicAAResult(P, F));\n    AAR.emplace(createLegacyPMAAResults(P, F, *BAR));\n    return *AAR;\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_BASICALIASANALYSIS_H\n"}, "23": {"id": 23, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/BlockFrequencyInfo.h", "content": "//===- BlockFrequencyInfo.h - Block Frequency Analysis ----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Loops should be simplified before this analysis.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_BLOCKFREQUENCYINFO_H\n#define LLVM_ANALYSIS_BLOCKFREQUENCYINFO_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/BlockFrequency.h\"\n#include <cstdint>\n#include <memory>\n\nnamespace llvm {\n\nclass BasicBlock;\nclass BranchProbabilityInfo;\nclass Function;\nclass LoopInfo;\nclass Module;\nclass raw_ostream;\ntemplate <class BlockT> class BlockFrequencyInfoImpl;\n\nenum PGOViewCountsType { PGOVCT_None, PGOVCT_Graph, PGOVCT_Text };\n\n/// BlockFrequencyInfo pass uses BlockFrequencyInfoImpl implementation to\n/// estimate IR basic block frequencies.\nclass BlockFrequencyInfo {\n  using ImplType = BlockFrequencyInfoImpl<BasicBlock>;\n\n  std::unique_ptr<ImplType> BFI;\n\npublic:\n  BlockFrequencyInfo();\n  BlockFrequencyInfo(const Function &F, const BranchProbabilityInfo &BPI,\n                     const LoopInfo &LI);\n  BlockFrequencyInfo(const BlockFrequencyInfo &) = delete;\n  BlockFrequencyInfo &operator=(const BlockFrequencyInfo &) = delete;\n  BlockFrequencyInfo(BlockFrequencyInfo &&Arg);\n  BlockFrequencyInfo &operator=(BlockFrequencyInfo &&RHS);\n  ~BlockFrequencyInfo();\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  const Function *getFunction() const;\n  const BranchProbabilityInfo *getBPI() const;\n  void view(StringRef = \"BlockFrequencyDAGs\") const;\n\n  /// getblockFreq - Return block frequency. Return 0 if we don't have the\n  /// information. Please note that initial frequency is equal to ENTRY_FREQ. It\n  /// means that we should not rely on the value itself, but only on the\n  /// comparison to the other block frequencies. We do this to avoid using of\n  /// floating points.\n  BlockFrequency getBlockFreq(const BasicBlock *BB) const;\n\n  /// Returns the estimated profile count of \\p BB.\n  /// This computes the relative block frequency of \\p BB and multiplies it by\n  /// the enclosing function's count (if available) and returns the value.\n  Optional<uint64_t> getBlockProfileCount(const BasicBlock *BB,\n                                          bool AllowSynthetic = false) const;\n\n  /// Returns the estimated profile count of \\p Freq.\n  /// This uses the frequency \\p Freq and multiplies it by\n  /// the enclosing function's count (if available) and returns the value.\n  Optional<uint64_t> getProfileCountFromFreq(uint64_t Freq) const;\n\n  /// Returns true if \\p BB is an irreducible loop header\n  /// block. Otherwise false.\n  bool isIrrLoopHeader(const BasicBlock *BB);\n\n  // Set the frequency of the given basic block.\n  void setBlockFreq(const BasicBlock *BB, uint64_t Freq);\n\n  /// Set the frequency of \\p ReferenceBB to \\p Freq and scale the frequencies\n  /// of the blocks in \\p BlocksToScale such that their frequencies relative\n  /// to \\p ReferenceBB remain unchanged.\n  void setBlockFreqAndScale(const BasicBlock *ReferenceBB, uint64_t Freq,\n                            SmallPtrSetImpl<BasicBlock *> &BlocksToScale);\n\n  /// calculate - compute block frequency info for the given function.\n  void calculate(const Function &F, const BranchProbabilityInfo &BPI,\n                 const LoopInfo &LI);\n\n  // Print the block frequency Freq to OS using the current functions entry\n  // frequency to convert freq into a relative decimal form.\n  raw_ostream &printBlockFreq(raw_ostream &OS, const BlockFrequency Freq) const;\n\n  // Convenience method that attempts to look up the frequency associated with\n  // BB and print it to OS.\n  raw_ostream &printBlockFreq(raw_ostream &OS, const BasicBlock *BB) const;\n\n  uint64_t getEntryFreq() const;\n  void releaseMemory();\n  void print(raw_ostream &OS) const;\n\n  // Compare to the other BFI and verify they match.\n  void verifyMatch(BlockFrequencyInfo &Other) const;\n};\n\n/// Analysis pass which computes \\c BlockFrequencyInfo.\nclass BlockFrequencyAnalysis\n    : public AnalysisInfoMixin<BlockFrequencyAnalysis> {\n  friend AnalysisInfoMixin<BlockFrequencyAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result type for this analysis pass.\n  using Result = BlockFrequencyInfo;\n\n  /// Run the analysis pass over a function and produce BFI.\n  Result run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c BlockFrequencyInfo results.\nclass BlockFrequencyPrinterPass\n    : public PassInfoMixin<BlockFrequencyPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit BlockFrequencyPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy analysis pass which computes \\c BlockFrequencyInfo.\nclass BlockFrequencyInfoWrapperPass : public FunctionPass {\n  BlockFrequencyInfo BFI;\n\npublic:\n  static char ID;\n\n  BlockFrequencyInfoWrapperPass();\n  ~BlockFrequencyInfoWrapperPass() override;\n\n  BlockFrequencyInfo &getBFI() { return BFI; }\n  const BlockFrequencyInfo &getBFI() const { return BFI; }\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void print(raw_ostream &OS, const Module *M) const override;\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_BLOCKFREQUENCYINFO_H\n"}, "24": {"id": 24, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/BranchProbabilityInfo.h", "content": "//===- BranchProbabilityInfo.h - Branch Probability Analysis ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass is used to evaluate branch probabilties.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_BRANCHPROBABILITYINFO_H\n#define LLVM_ANALYSIS_BRANCHPROBABILITYINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/BranchProbability.h\"\n#include \"llvm/Support/Casting.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstdint>\n#include <memory>\n#include <utility>\n\nnamespace llvm {\n\nclass Function;\nclass Loop;\nclass LoopInfo;\nclass raw_ostream;\nclass DominatorTree;\nclass PostDominatorTree;\nclass TargetLibraryInfo;\nclass Value;\n\n/// Analysis providing branch probability information.\n///\n/// This is a function analysis which provides information on the relative\n/// probabilities of each \"edge\" in the function's CFG where such an edge is\n/// defined by a pair (PredBlock and an index in the successors). The\n/// probability of an edge from one block is always relative to the\n/// probabilities of other edges from the block. The probabilites of all edges\n/// from a block sum to exactly one (100%).\n/// We use a pair (PredBlock and an index in the successors) to uniquely\n/// identify an edge, since we can have multiple edges from Src to Dst.\n/// As an example, we can have a switch which jumps to Dst with value 0 and\n/// value 10.\n///\n/// Process of computing branch probabilities can be logically viewed as three\n/// step process:\n///\n///   First, if there is a profile information associated with the branch then\n/// it is trivially translated to branch probabilities. There is one exception\n/// from this rule though. Probabilities for edges leading to \"unreachable\"\n/// blocks (blocks with the estimated weight not greater than\n/// UNREACHABLE_WEIGHT) are evaluated according to static estimation and\n/// override profile information. If no branch probabilities were calculated\n/// on this step then take the next one.\n///\n///   Second, estimate absolute execution weights for each block based on\n/// statically known information. Roots of such information are \"cold\",\n/// \"unreachable\", \"noreturn\" and \"unwind\" blocks. Those blocks get their\n/// weights set to BlockExecWeight::COLD, BlockExecWeight::UNREACHABLE,\n/// BlockExecWeight::NORETURN and BlockExecWeight::UNWIND respectively. Then the\n/// weights are propagated to the other blocks up the domination line. In\n/// addition, if all successors have estimated weights set then maximum of these\n/// weights assigned to the block itself (while this is not ideal heuristic in\n/// theory it's simple and works reasonably well in most cases) and the process\n/// repeats. Once the process of weights propagation converges branch\n/// probabilities are set for all such branches that have at least one successor\n/// with the weight set. Default execution weight (BlockExecWeight::DEFAULT) is\n/// used for any successors which doesn't have its weight set. For loop back\n/// branches we use their weights scaled by loop trip count equal to\n/// 'LBH_TAKEN_WEIGHT/LBH_NOTTAKEN_WEIGHT'.\n///\n/// Here is a simple example demonstrating how the described algorithm works.\n///\n///          BB1\n///         /   \\\n///        v     v\n///      BB2     BB3\n///     /   \\\n///    v     v\n///  ColdBB  UnreachBB\n///\n/// Initially, ColdBB is associated with COLD_WEIGHT and UnreachBB with\n/// UNREACHABLE_WEIGHT. COLD_WEIGHT is set to BB2 as maximum between its\n/// successors. BB1 and BB3 has no explicit estimated weights and assumed to\n/// have DEFAULT_WEIGHT. Based on assigned weights branches will have the\n/// following probabilities:\n/// P(BB1->BB2) = COLD_WEIGHT/(COLD_WEIGHT + DEFAULT_WEIGHT) =\n///   0xffff / (0xffff + 0xfffff) = 0.0588(5.9%)\n/// P(BB1->BB3) = DEFAULT_WEIGHT_WEIGHT/(COLD_WEIGHT + DEFAULT_WEIGHT) =\n///          0xfffff / (0xffff + 0xfffff) = 0.941(94.1%)\n/// P(BB2->ColdBB) = COLD_WEIGHT/(COLD_WEIGHT + UNREACHABLE_WEIGHT) = 1(100%)\n/// P(BB2->UnreachBB) =\n///   UNREACHABLE_WEIGHT/(COLD_WEIGHT+UNREACHABLE_WEIGHT) = 0(0%)\n///\n/// If no branch probabilities were calculated on this step then take the next\n/// one.\n///\n///   Third, apply different kinds of local heuristics for each individual\n/// branch until first match. For example probability of a pointer to be null is\n/// estimated as PH_TAKEN_WEIGHT/(PH_TAKEN_WEIGHT + PH_NONTAKEN_WEIGHT). If\n/// no local heuristic has been matched then branch is left with no explicit\n/// probability set and assumed to have default probability.\nclass BranchProbabilityInfo {\npublic:\n  BranchProbabilityInfo() = default;\n\n  BranchProbabilityInfo(const Function &F, const LoopInfo &LI,\n                        const TargetLibraryInfo *TLI = nullptr,\n                        DominatorTree *DT = nullptr,\n                        PostDominatorTree *PDT = nullptr) {\n    calculate(F, LI, TLI, DT, PDT);\n  }\n\n  BranchProbabilityInfo(BranchProbabilityInfo &&Arg)\n      : Probs(std::move(Arg.Probs)), LastF(Arg.LastF),\n        EstimatedBlockWeight(std::move(Arg.EstimatedBlockWeight)) {}\n\n  BranchProbabilityInfo(const BranchProbabilityInfo &) = delete;\n  BranchProbabilityInfo &operator=(const BranchProbabilityInfo &) = delete;\n\n  BranchProbabilityInfo &operator=(BranchProbabilityInfo &&RHS) {\n    releaseMemory();\n    Probs = std::move(RHS.Probs);\n    EstimatedBlockWeight = std::move(RHS.EstimatedBlockWeight);\n    return *this;\n  }\n\n  bool invalidate(Function &, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  void releaseMemory();\n\n  void print(raw_ostream &OS) const;\n\n  /// Get an edge's probability, relative to other out-edges of the Src.\n  ///\n  /// This routine provides access to the fractional probability between zero\n  /// (0%) and one (100%) of this edge executing, relative to other edges\n  /// leaving the 'Src' block. The returned probability is never zero, and can\n  /// only be one if the source block has only one successor.\n  BranchProbability getEdgeProbability(const BasicBlock *Src,\n                                       unsigned IndexInSuccessors) const;\n\n  /// Get the probability of going from Src to Dst.\n  ///\n  /// It returns the sum of all probabilities for edges from Src to Dst.\n  BranchProbability getEdgeProbability(const BasicBlock *Src,\n                                       const BasicBlock *Dst) const;\n\n  BranchProbability getEdgeProbability(const BasicBlock *Src,\n                                       const_succ_iterator Dst) const;\n\n  /// Test if an edge is hot relative to other out-edges of the Src.\n  ///\n  /// Check whether this edge out of the source block is 'hot'. We define hot\n  /// as having a relative probability >= 80%.\n  bool isEdgeHot(const BasicBlock *Src, const BasicBlock *Dst) const;\n\n  /// Retrieve the hot successor of a block if one exists.\n  ///\n  /// Given a basic block, look through its successors and if one exists for\n  /// which \\see isEdgeHot would return true, return that successor block.\n  const BasicBlock *getHotSucc(const BasicBlock *BB) const;\n\n  /// Print an edge's probability.\n  ///\n  /// Retrieves an edge's probability similarly to \\see getEdgeProbability, but\n  /// then prints that probability to the provided stream. That stream is then\n  /// returned.\n  raw_ostream &printEdgeProbability(raw_ostream &OS, const BasicBlock *Src,\n                                    const BasicBlock *Dst) const;\n\npublic:\n  /// Set the raw probabilities for all edges from the given block.\n  ///\n  /// This allows a pass to explicitly set edge probabilities for a block. It\n  /// can be used when updating the CFG to update the branch probability\n  /// information.\n  void setEdgeProbability(const BasicBlock *Src,\n                          const SmallVectorImpl<BranchProbability> &Probs);\n\n  /// Copy outgoing edge probabilities from \\p Src to \\p Dst.\n  ///\n  /// This allows to keep probabilities unset for the destination if they were\n  /// unset for source.\n  void copyEdgeProbabilities(BasicBlock *Src, BasicBlock *Dst);\n\n  static BranchProbability getBranchProbStackProtector(bool IsLikely) {\n    static const BranchProbability LikelyProb((1u << 20) - 1, 1u << 20);\n    return IsLikely ? LikelyProb : LikelyProb.getCompl();\n  }\n\n  void calculate(const Function &F, const LoopInfo &LI,\n                 const TargetLibraryInfo *TLI, DominatorTree *DT,\n                 PostDominatorTree *PDT);\n\n  /// Forget analysis results for the given basic block.\n  void eraseBlock(const BasicBlock *BB);\n\n  // Data structure to track SCCs for handling irreducible loops.\n  class SccInfo {\n    // Enum of types to classify basic blocks in SCC. Basic block belonging to\n    // SCC is 'Inner' until it is either 'Header' or 'Exiting'. Note that a\n    // basic block can be 'Header' and 'Exiting' at the same time.\n    enum SccBlockType {\n      Inner = 0x0,\n      Header = 0x1,\n      Exiting = 0x2,\n    };\n    // Map of basic blocks to SCC IDs they belong to. If basic block doesn't\n    // belong to any SCC it is not in the map.\n    using SccMap = DenseMap<const BasicBlock *, int>;\n    // Each basic block in SCC is attributed with one or several types from\n    // SccBlockType. Map value has uint32_t type (instead of SccBlockType)\n    // since basic block may be for example \"Header\" and \"Exiting\" at the same\n    // time and we need to be able to keep more than one value from\n    // SccBlockType.\n    using SccBlockTypeMap = DenseMap<const BasicBlock *, uint32_t>;\n    // Vector containing classification of basic blocks for all  SCCs where i'th\n    // vector element corresponds to SCC with ID equal to i.\n    using SccBlockTypeMaps = std::vector<SccBlockTypeMap>;\n\n    SccMap SccNums;\n    SccBlockTypeMaps SccBlocks;\n\n  public:\n    explicit SccInfo(const Function &F);\n\n    /// If \\p BB belongs to some SCC then ID of that SCC is returned, otherwise\n    /// -1 is returned. If \\p BB belongs to more than one SCC at the same time\n    /// result is undefined.\n    int getSCCNum(const BasicBlock *BB) const;\n    /// Returns true if \\p BB is a 'header' block in SCC with \\p SccNum ID,\n    /// false otherwise.\n    bool isSCCHeader(const BasicBlock *BB, int SccNum) const {\n      return getSccBlockType(BB, SccNum) & Header;\n    }\n    /// Returns true if \\p BB is an 'exiting' block in SCC with \\p SccNum ID,\n    /// false otherwise.\n    bool isSCCExitingBlock(const BasicBlock *BB, int SccNum) const {\n      return getSccBlockType(BB, SccNum) & Exiting;\n    }\n    /// Fills in \\p Enters vector with all such blocks that don't belong to\n    /// SCC with \\p SccNum ID but there is an edge to a block belonging to the\n    /// SCC.\n    void getSccEnterBlocks(int SccNum,\n                           SmallVectorImpl<BasicBlock *> &Enters) const;\n    /// Fills in \\p Exits vector with all such blocks that don't belong to\n    /// SCC with \\p SccNum ID but there is an edge from a block belonging to the\n    /// SCC.\n    void getSccExitBlocks(int SccNum,\n                          SmallVectorImpl<BasicBlock *> &Exits) const;\n\n  private:\n    /// Returns \\p BB's type according to classification given by SccBlockType\n    /// enum. Please note that \\p BB must belong to SSC with \\p SccNum ID.\n    uint32_t getSccBlockType(const BasicBlock *BB, int SccNum) const;\n    /// Calculates \\p BB's type and stores it in internal data structures for\n    /// future use. Please note that \\p BB must belong to SSC with \\p SccNum ID.\n    void calculateSccBlockType(const BasicBlock *BB, int SccNum);\n  };\n\nprivate:\n  // We need to store CallbackVH's in order to correctly handle basic block\n  // removal.\n  class BasicBlockCallbackVH final : public CallbackVH {\n    BranchProbabilityInfo *BPI;\n\n    void deleted() override {\n      assert(BPI != nullptr);\n      BPI->eraseBlock(cast<BasicBlock>(getValPtr()));\n    }\n\n  public:\n    BasicBlockCallbackVH(const Value *V, BranchProbabilityInfo *BPI = nullptr)\n        : CallbackVH(const_cast<Value *>(V)), BPI(BPI) {}\n  };\n\n  /// Pair of Loop and SCC ID number. Used to unify handling of normal and\n  /// SCC based loop representations.\n  using LoopData = std::pair<Loop *, int>;\n  /// Helper class to keep basic block along with its loop data information.\n  class LoopBlock {\n  public:\n    explicit LoopBlock(const BasicBlock *BB, const LoopInfo &LI,\n                       const SccInfo &SccI);\n\n    const BasicBlock *getBlock() const { return BB; }\n    BasicBlock *getBlock() { return const_cast<BasicBlock *>(BB); }\n    LoopData getLoopData() const { return LD; }\n    Loop *getLoop() const { return LD.first; }\n    int getSccNum() const { return LD.second; }\n\n    bool belongsToLoop() const { return getLoop() || getSccNum() != -1; }\n    bool belongsToSameLoop(const LoopBlock &LB) const {\n      return (LB.getLoop() && getLoop() == LB.getLoop()) ||\n             (LB.getSccNum() != -1 && getSccNum() == LB.getSccNum());\n    }\n\n  private:\n    const BasicBlock *const BB = nullptr;\n    LoopData LD = {nullptr, -1};\n  };\n\n  // Pair of LoopBlocks representing an edge from first to second block.\n  using LoopEdge = std::pair<const LoopBlock &, const LoopBlock &>;\n\n  DenseSet<BasicBlockCallbackVH, DenseMapInfo<Value*>> Handles;\n\n  // Since we allow duplicate edges from one basic block to another, we use\n  // a pair (PredBlock and an index in the successors) to specify an edge.\n  using Edge = std::pair<const BasicBlock *, unsigned>;\n\n  DenseMap<Edge, BranchProbability> Probs;\n\n  /// Track the last function we run over for printing.\n  const Function *LastF = nullptr;\n\n  const LoopInfo *LI = nullptr;\n\n  /// Keeps information about all SCCs in a function.\n  std::unique_ptr<const SccInfo> SccI;\n\n  /// Keeps mapping of a basic block to its estimated weight.\n  SmallDenseMap<const BasicBlock *, uint32_t> EstimatedBlockWeight;\n\n  /// Keeps mapping of a loop to estimated weight to enter the loop.\n  SmallDenseMap<LoopData, uint32_t> EstimatedLoopWeight;\n\n  /// Helper to construct LoopBlock for \\p BB.\n  LoopBlock getLoopBlock(const BasicBlock *BB) const {\n    return LoopBlock(BB, *LI, *SccI.get());\n  }\n\n  /// Returns true if destination block belongs to some loop and source block is\n  /// either doesn't belong to any loop or belongs to a loop which is not inner\n  /// relative to the destination block.\n  bool isLoopEnteringEdge(const LoopEdge &Edge) const;\n  /// Returns true if source block belongs to some loop and destination block is\n  /// either doesn't belong to any loop or belongs to a loop which is not inner\n  /// relative to the source block.\n  bool isLoopExitingEdge(const LoopEdge &Edge) const;\n  /// Returns true if \\p Edge is either enters to or exits from some loop, false\n  /// in all other cases.\n  bool isLoopEnteringExitingEdge(const LoopEdge &Edge) const;\n  /// Returns true if source and destination blocks belongs to the same loop and\n  /// destination block is loop header.\n  bool isLoopBackEdge(const LoopEdge &Edge) const;\n  // Fills in \\p Enters vector with all \"enter\" blocks to a loop \\LB belongs to.\n  void getLoopEnterBlocks(const LoopBlock &LB,\n                          SmallVectorImpl<BasicBlock *> &Enters) const;\n  // Fills in \\p Exits vector with all \"exit\" blocks from a loop \\LB belongs to.\n  void getLoopExitBlocks(const LoopBlock &LB,\n                         SmallVectorImpl<BasicBlock *> &Exits) const;\n\n  /// Returns estimated weight for \\p BB. None if \\p BB has no estimated weight.\n  Optional<uint32_t> getEstimatedBlockWeight(const BasicBlock *BB) const;\n\n  /// Returns estimated weight to enter \\p L. In other words it is weight of\n  /// loop's header block not scaled by trip count. Returns None if \\p L has no\n  /// no estimated weight.\n  Optional<uint32_t> getEstimatedLoopWeight(const LoopData &L) const;\n\n  /// Return estimated weight for \\p Edge. Returns None if estimated weight is\n  /// unknown.\n  Optional<uint32_t> getEstimatedEdgeWeight(const LoopEdge &Edge) const;\n\n  /// Iterates over all edges leading from \\p SrcBB to \\p Successors and\n  /// returns maximum of all estimated weights. If at least one edge has unknown\n  /// estimated weight None is returned.\n  template <class IterT>\n  Optional<uint32_t>\n  getMaxEstimatedEdgeWeight(const LoopBlock &SrcBB,\n                            iterator_range<IterT> Successors) const;\n\n  /// If \\p LoopBB has no estimated weight then set it to \\p BBWeight and\n  /// return true. Otherwise \\p BB's weight remains unchanged and false is\n  /// returned. In addition all blocks/loops that might need their weight to be\n  /// re-estimated are put into BlockWorkList/LoopWorkList.\n  bool updateEstimatedBlockWeight(LoopBlock &LoopBB, uint32_t BBWeight,\n                                  SmallVectorImpl<BasicBlock *> &BlockWorkList,\n                                  SmallVectorImpl<LoopBlock> &LoopWorkList);\n\n  /// Starting from \\p LoopBB (including \\p LoopBB itself) propagate \\p BBWeight\n  /// up the domination tree.\n  void propagateEstimatedBlockWeight(const LoopBlock &LoopBB, DominatorTree *DT,\n                                     PostDominatorTree *PDT, uint32_t BBWeight,\n                                     SmallVectorImpl<BasicBlock *> &WorkList,\n                                     SmallVectorImpl<LoopBlock> &LoopWorkList);\n\n  /// Returns block's weight encoded in the IR.\n  Optional<uint32_t> getInitialEstimatedBlockWeight(const BasicBlock *BB);\n\n  // Computes estimated weights for all blocks in \\p F.\n  void computeEestimateBlockWeight(const Function &F, DominatorTree *DT,\n                                   PostDominatorTree *PDT);\n\n  /// Based on computed weights by \\p computeEstimatedBlockWeight set\n  /// probabilities on branches.\n  bool calcEstimatedHeuristics(const BasicBlock *BB);\n  bool calcMetadataWeights(const BasicBlock *BB);\n  bool calcPointerHeuristics(const BasicBlock *BB);\n  bool calcZeroHeuristics(const BasicBlock *BB, const TargetLibraryInfo *TLI);\n  bool calcFloatingPointHeuristics(const BasicBlock *BB);\n};\n\n/// Analysis pass which computes \\c BranchProbabilityInfo.\nclass BranchProbabilityAnalysis\n    : public AnalysisInfoMixin<BranchProbabilityAnalysis> {\n  friend AnalysisInfoMixin<BranchProbabilityAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result type for this analysis pass.\n  using Result = BranchProbabilityInfo;\n\n  /// Run the analysis pass over a function and produce BPI.\n  BranchProbabilityInfo run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c BranchProbabilityAnalysis results.\nclass BranchProbabilityPrinterPass\n    : public PassInfoMixin<BranchProbabilityPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit BranchProbabilityPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy analysis pass which computes \\c BranchProbabilityInfo.\nclass BranchProbabilityInfoWrapperPass : public FunctionPass {\n  BranchProbabilityInfo BPI;\n\npublic:\n  static char ID;\n\n  BranchProbabilityInfoWrapperPass();\n\n  BranchProbabilityInfo &getBPI() { return BPI; }\n  const BranchProbabilityInfo &getBPI() const { return BPI; }\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void print(raw_ostream &OS, const Module *M = nullptr) const override;\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_BRANCHPROBABILITYINFO_H\n"}, "25": {"id": 25, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFGPrinter.h", "content": "//===-- CFGPrinter.h - CFG printer external interface -----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines a 'dot-cfg' analysis pass, which emits the\n// cfg.<fnname>.dot file for each function in the program, with a graph of the\n// CFG for that function.\n//\n// This file defines external functions that can be called to explicitly\n// instantiate the CFG printer.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_CFGPRINTER_H\n#define LLVM_ANALYSIS_CFGPRINTER_H\n\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/Analysis/BlockFrequencyInfo.h\"\n#include \"llvm/Analysis/BranchProbabilityInfo.h\"\n#include \"llvm/Analysis/HeatUtils.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/FormatVariadic.h\"\n#include \"llvm/Support/GraphWriter.h\"\n\nnamespace llvm {\nclass CFGViewerPass : public PassInfoMixin<CFGViewerPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass CFGOnlyViewerPass : public PassInfoMixin<CFGOnlyViewerPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass CFGPrinterPass : public PassInfoMixin<CFGPrinterPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass CFGOnlyPrinterPass : public PassInfoMixin<CFGOnlyPrinterPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass DOTFuncInfo {\nprivate:\n  const Function *F;\n  const BlockFrequencyInfo *BFI;\n  const BranchProbabilityInfo *BPI;\n  uint64_t MaxFreq;\n  bool ShowHeat;\n  bool EdgeWeights;\n  bool RawWeights;\n\npublic:\n  DOTFuncInfo(const Function *F) : DOTFuncInfo(F, nullptr, nullptr, 0) {}\n\n  DOTFuncInfo(const Function *F, const BlockFrequencyInfo *BFI,\n              const BranchProbabilityInfo *BPI, uint64_t MaxFreq)\n      : F(F), BFI(BFI), BPI(BPI), MaxFreq(MaxFreq) {\n    ShowHeat = false;\n    EdgeWeights = !!BPI; // Print EdgeWeights when BPI is available.\n    RawWeights = !!BFI;  // Print RawWeights when BFI is available.\n  }\n\n  const BlockFrequencyInfo *getBFI() { return BFI; }\n\n  const BranchProbabilityInfo *getBPI() { return BPI; }\n\n  const Function *getFunction() { return this->F; }\n\n  uint64_t getMaxFreq() { return MaxFreq; }\n\n  uint64_t getFreq(const BasicBlock *BB) {\n    return BFI->getBlockFreq(BB).getFrequency();\n  }\n\n  void setHeatColors(bool ShowHeat) { this->ShowHeat = ShowHeat; }\n\n  bool showHeatColors() { return ShowHeat; }\n\n  void setRawEdgeWeights(bool RawWeights) { this->RawWeights = RawWeights; }\n\n  bool useRawEdgeWeights() { return RawWeights; }\n\n  void setEdgeWeights(bool EdgeWeights) { this->EdgeWeights = EdgeWeights; }\n\n  bool showEdgeWeights() { return EdgeWeights; }\n};\n\ntemplate <>\nstruct GraphTraits<DOTFuncInfo *> : public GraphTraits<const BasicBlock *> {\n  static NodeRef getEntryNode(DOTFuncInfo *CFGInfo) {\n    return &(CFGInfo->getFunction()->getEntryBlock());\n  }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator = pointer_iterator<Function::const_iterator>;\n\n  static nodes_iterator nodes_begin(DOTFuncInfo *CFGInfo) {\n    return nodes_iterator(CFGInfo->getFunction()->begin());\n  }\n\n  static nodes_iterator nodes_end(DOTFuncInfo *CFGInfo) {\n    return nodes_iterator(CFGInfo->getFunction()->end());\n  }\n\n  static size_t size(DOTFuncInfo *CFGInfo) {\n    return CFGInfo->getFunction()->size();\n  }\n};\n\ntemplate <>\nstruct DOTGraphTraits<DOTFuncInfo *> : public DefaultDOTGraphTraits {\n\n  // Cache for is hidden property\n  llvm::DenseMap<const BasicBlock *, bool> isHiddenBasicBlock;\n\n  DOTGraphTraits(bool isSimple = false) : DefaultDOTGraphTraits(isSimple) {}\n\n  static std::string getGraphName(DOTFuncInfo *CFGInfo) {\n    return \"CFG for '\" + CFGInfo->getFunction()->getName().str() + \"' function\";\n  }\n\n  static std::string getSimpleNodeLabel(const BasicBlock *Node, DOTFuncInfo *) {\n    if (!Node->getName().empty())\n      return Node->getName().str();\n\n    std::string Str;\n    raw_string_ostream OS(Str);\n\n    Node->printAsOperand(OS, false);\n    return OS.str();\n  }\n\n  static void eraseComment(std::string &OutStr, unsigned &I, unsigned Idx) {\n    OutStr.erase(OutStr.begin() + I, OutStr.begin() + Idx);\n    --I;\n  }\n\n  static std::string getCompleteNodeLabel(\n      const BasicBlock *Node, DOTFuncInfo *,\n      llvm::function_ref<void(raw_string_ostream &, const BasicBlock &)>\n          HandleBasicBlock = [](raw_string_ostream &OS,\n                                const BasicBlock &Node) -> void { OS << Node; },\n      llvm::function_ref<void(std::string &, unsigned &, unsigned)>\n          HandleComment = eraseComment) {\n    enum { MaxColumns = 80 };\n    std::string Str;\n    raw_string_ostream OS(Str);\n\n    if (Node->getName().empty()) {\n      Node->printAsOperand(OS, false);\n      OS << \":\";\n    }\n\n    HandleBasicBlock(OS, *Node);\n    std::string OutStr = OS.str();\n    if (OutStr[0] == '\\n')\n      OutStr.erase(OutStr.begin());\n\n    // Process string output to make it nicer...\n    unsigned ColNum = 0;\n    unsigned LastSpace = 0;\n    for (unsigned i = 0; i != OutStr.length(); ++i) {\n      if (OutStr[i] == '\\n') { // Left justify\n        OutStr[i] = '\\\\';\n        OutStr.insert(OutStr.begin() + i + 1, 'l');\n        ColNum = 0;\n        LastSpace = 0;\n      } else if (OutStr[i] == ';') {             // Delete comments!\n        unsigned Idx = OutStr.find('\\n', i + 1); // Find end of line\n        HandleComment(OutStr, i, Idx);\n      } else if (ColNum == MaxColumns) { // Wrap lines.\n        // Wrap very long names even though we can't find a space.\n        if (!LastSpace)\n          LastSpace = i;\n        OutStr.insert(LastSpace, \"\\\\l...\");\n        ColNum = i - LastSpace;\n        LastSpace = 0;\n        i += 3; // The loop will advance 'i' again.\n      } else\n        ++ColNum;\n      if (OutStr[i] == ' ')\n        LastSpace = i;\n    }\n    return OutStr;\n  }\n\n  std::string getNodeLabel(const BasicBlock *Node, DOTFuncInfo *CFGInfo) {\n\n    if (isSimple())\n      return getSimpleNodeLabel(Node, CFGInfo);\n    else\n      return getCompleteNodeLabel(Node, CFGInfo);\n  }\n\n  static std::string getEdgeSourceLabel(const BasicBlock *Node,\n                                        const_succ_iterator I) {\n    // Label source of conditional branches with \"T\" or \"F\"\n    if (const BranchInst *BI = dyn_cast<BranchInst>(Node->getTerminator()))\n      if (BI->isConditional())\n        return (I == succ_begin(Node)) ? \"T\" : \"F\";\n\n    // Label source of switch edges with the associated value.\n    if (const SwitchInst *SI = dyn_cast<SwitchInst>(Node->getTerminator())) {\n      unsigned SuccNo = I.getSuccessorIndex();\n\n      if (SuccNo == 0)\n        return \"def\";\n\n      std::string Str;\n      raw_string_ostream OS(Str);\n      auto Case = *SwitchInst::ConstCaseIt::fromSuccessorIndex(SI, SuccNo);\n      OS << Case.getCaseValue()->getValue();\n      return OS.str();\n    }\n    return \"\";\n  }\n\n  /// Display the raw branch weights from PGO.\n  std::string getEdgeAttributes(const BasicBlock *Node, const_succ_iterator I,\n                                DOTFuncInfo *CFGInfo) {\n    if (!CFGInfo->showEdgeWeights())\n      return \"\";\n\n    const Instruction *TI = Node->getTerminator();\n    if (TI->getNumSuccessors() == 1)\n      return \"penwidth=2\";\n\n    unsigned OpNo = I.getSuccessorIndex();\n\n    if (OpNo >= TI->getNumSuccessors())\n      return \"\";\n\n    BasicBlock *SuccBB = TI->getSuccessor(OpNo);\n    auto BranchProb = CFGInfo->getBPI()->getEdgeProbability(Node, SuccBB);\n    double WeightPercent = ((double)BranchProb.getNumerator()) /\n                           ((double)BranchProb.getDenominator());\n    double Width = 1 + WeightPercent;\n\n    if (!CFGInfo->useRawEdgeWeights())\n      return formatv(\"label=\\\"{0:P}\\\" penwidth={1}\", WeightPercent, Width)\n          .str();\n\n    // Prepend a 'W' to indicate that this is a weight rather than the actual\n    // profile count (due to scaling).\n\n    uint64_t Freq = CFGInfo->getFreq(Node);\n    std::string Attrs = formatv(\"label=\\\"W:{0}\\\" penwidth={1}\",\n                                (uint64_t)(Freq * WeightPercent), Width);\n    if (Attrs.size())\n      return Attrs;\n\n    MDNode *WeightsNode = TI->getMetadata(LLVMContext::MD_prof);\n    if (!WeightsNode)\n      return \"\";\n\n    MDString *MDName = cast<MDString>(WeightsNode->getOperand(0));\n    if (MDName->getString() != \"branch_weights\")\n      return \"\";\n\n    OpNo = I.getSuccessorIndex() + 1;\n    if (OpNo >= WeightsNode->getNumOperands())\n      return \"\";\n    ConstantInt *Weight =\n        mdconst::dyn_extract<ConstantInt>(WeightsNode->getOperand(OpNo));\n    if (!Weight)\n      return \"\";\n    return (\"label=\\\"W:\" + std::to_string(Weight->getZExtValue()) +\n            \"\\\" penwidth=\" + std::to_string(Width));\n  }\n\n  std::string getNodeAttributes(const BasicBlock *Node, DOTFuncInfo *CFGInfo) {\n\n    if (!CFGInfo->showHeatColors())\n      return \"\";\n\n    uint64_t Freq = CFGInfo->getFreq(Node);\n    std::string Color = getHeatColor(Freq, CFGInfo->getMaxFreq());\n    std::string EdgeColor = (Freq <= (CFGInfo->getMaxFreq() / 2))\n                                ? (getHeatColor(0))\n                                : (getHeatColor(1));\n\n    std::string Attrs = \"color=\\\"\" + EdgeColor + \"ff\\\", style=filled,\" +\n                        \" fillcolor=\\\"\" + Color + \"70\\\"\";\n    return Attrs;\n  }\n  bool isNodeHidden(const BasicBlock *Node, const DOTFuncInfo *CFGInfo);\n  void computeHiddenNodes(const Function *F);\n};\n} // End llvm namespace\n\nnamespace llvm {\nclass FunctionPass;\nFunctionPass *createCFGPrinterLegacyPassPass();\nFunctionPass *createCFGOnlyPrinterLegacyPassPass();\n} // End llvm namespace\n\n#endif\n"}, "26": {"id": 26, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFLAndersAliasAnalysis.h", "content": "//==- CFLAndersAliasAnalysis.h - Unification-based Alias Analysis -*- C++-*-==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This is the interface for LLVM's inclusion-based alias analysis\n/// implemented with CFL graph reachability.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_CFLANDERSALIASANALYSIS_H\n#define LLVM_ANALYSIS_CFLANDERSALIASANALYSIS_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/Analysis/CFLAliasAnalysisUtils.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include <forward_list>\n#include <memory>\n\nnamespace llvm {\n\nclass Function;\nclass MemoryLocation;\nclass TargetLibraryInfo;\n\nnamespace cflaa {\n\nstruct AliasSummary;\n\n} // end namespace cflaa\n\nclass CFLAndersAAResult : public AAResultBase<CFLAndersAAResult> {\n  friend AAResultBase<CFLAndersAAResult>;\n\n  class FunctionInfo;\n\npublic:\n  explicit CFLAndersAAResult(\n      std::function<const TargetLibraryInfo &(Function &F)> GetTLI);\n  CFLAndersAAResult(CFLAndersAAResult &&RHS);\n  ~CFLAndersAAResult();\n\n  /// Handle invalidation events from the new pass manager.\n  /// By definition, this result is stateless and so remains valid.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  /// Evict the given function from cache\n  void evict(const Function *Fn);\n\n  /// Get the alias summary for the given function\n  /// Return nullptr if the summary is not found or not available\n  const cflaa::AliasSummary *getAliasSummary(const Function &);\n\n  AliasResult query(const MemoryLocation &, const MemoryLocation &);\n  AliasResult alias(const MemoryLocation &, const MemoryLocation &,\n                    AAQueryInfo &);\n\nprivate:\n  /// Ensures that the given function is available in the cache.\n  /// Returns the appropriate entry from the cache.\n  const Optional<FunctionInfo> &ensureCached(const Function &);\n\n  /// Inserts the given Function into the cache.\n  void scan(const Function &);\n\n  /// Build summary for a given function\n  FunctionInfo buildInfoFrom(const Function &);\n\n  std::function<const TargetLibraryInfo &(Function &F)> GetTLI;\n\n  /// Cached mapping of Functions to their StratifiedSets.\n  /// If a function's sets are currently being built, it is marked\n  /// in the cache as an Optional without a value. This way, if we\n  /// have any kind of recursion, it is discernable from a function\n  /// that simply has empty sets.\n  DenseMap<const Function *, Optional<FunctionInfo>> Cache;\n\n  std::forward_list<cflaa::FunctionHandle<CFLAndersAAResult>> Handles;\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\n///\n/// FIXME: We really should refactor CFL to use the analysis more heavily, and\n/// in particular to leverage invalidation to trigger re-computation.\nclass CFLAndersAA : public AnalysisInfoMixin<CFLAndersAA> {\n  friend AnalysisInfoMixin<CFLAndersAA>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = CFLAndersAAResult;\n\n  CFLAndersAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the CFLAndersAAResult object.\nclass CFLAndersAAWrapperPass : public ImmutablePass {\n  std::unique_ptr<CFLAndersAAResult> Result;\n\npublic:\n  static char ID;\n\n  CFLAndersAAWrapperPass();\n\n  CFLAndersAAResult &getResult() { return *Result; }\n  const CFLAndersAAResult &getResult() const { return *Result; }\n\n  void initializePass() override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n// createCFLAndersAAWrapperPass - This pass implements a set-based approach to\n// alias analysis.\nImmutablePass *createCFLAndersAAWrapperPass();\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_CFLANDERSALIASANALYSIS_H\n"}, "27": {"id": 27, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFLSteensAliasAnalysis.h", "content": "//==- CFLSteensAliasAnalysis.h - Unification-based Alias Analysis -*- C++-*-==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This is the interface for LLVM's unification-based alias analysis\n/// implemented with CFL graph reachability.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_CFLSTEENSALIASANALYSIS_H\n#define LLVM_ANALYSIS_CFLSTEENSALIASANALYSIS_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/Analysis/CFLAliasAnalysisUtils.h\"\n#include \"llvm/Analysis/MemoryLocation.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Casting.h\"\n#include <forward_list>\n#include <memory>\n\nnamespace llvm {\n\nclass Function;\nclass TargetLibraryInfo;\n\nnamespace cflaa {\n\nstruct AliasSummary;\n\n} // end namespace cflaa\n\nclass CFLSteensAAResult : public AAResultBase<CFLSteensAAResult> {\n  friend AAResultBase<CFLSteensAAResult>;\n\n  class FunctionInfo;\n\npublic:\n  explicit CFLSteensAAResult(\n      std::function<const TargetLibraryInfo &(Function &)> GetTLI);\n  CFLSteensAAResult(CFLSteensAAResult &&Arg);\n  ~CFLSteensAAResult();\n\n  /// Handle invalidation events from the new pass manager.\n  ///\n  /// By definition, this result is stateless and so remains valid.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  /// Inserts the given Function into the cache.\n  void scan(Function *Fn);\n\n  void evict(Function *Fn);\n\n  /// Ensures that the given function is available in the cache.\n  /// Returns the appropriate entry from the cache.\n  const Optional<FunctionInfo> &ensureCached(Function *Fn);\n\n  /// Get the alias summary for the given function\n  /// Return nullptr if the summary is not found or not available\n  const cflaa::AliasSummary *getAliasSummary(Function &Fn);\n\n  AliasResult query(const MemoryLocation &LocA, const MemoryLocation &LocB);\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI) {\n    if (LocA.Ptr == LocB.Ptr)\n      return MustAlias;\n\n    // Comparisons between global variables and other constants should be\n    // handled by BasicAA.\n    // CFLSteensAA may report NoAlias when comparing a GlobalValue and\n    // ConstantExpr, but every query needs to have at least one Value tied to a\n    // Function, and neither GlobalValues nor ConstantExprs are.\n    if (isa<Constant>(LocA.Ptr) && isa<Constant>(LocB.Ptr))\n      return AAResultBase::alias(LocA, LocB, AAQI);\n\n    AliasResult QueryResult = query(LocA, LocB);\n    if (QueryResult == MayAlias)\n      return AAResultBase::alias(LocA, LocB, AAQI);\n\n    return QueryResult;\n  }\n\nprivate:\n  std::function<const TargetLibraryInfo &(Function &)> GetTLI;\n\n  /// Cached mapping of Functions to their StratifiedSets.\n  /// If a function's sets are currently being built, it is marked\n  /// in the cache as an Optional without a value. This way, if we\n  /// have any kind of recursion, it is discernable from a function\n  /// that simply has empty sets.\n  DenseMap<Function *, Optional<FunctionInfo>> Cache;\n  std::forward_list<cflaa::FunctionHandle<CFLSteensAAResult>> Handles;\n\n  FunctionInfo buildSetsFrom(Function *F);\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\n///\n/// FIXME: We really should refactor CFL to use the analysis more heavily, and\n/// in particular to leverage invalidation to trigger re-computation of sets.\nclass CFLSteensAA : public AnalysisInfoMixin<CFLSteensAA> {\n  friend AnalysisInfoMixin<CFLSteensAA>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = CFLSteensAAResult;\n\n  CFLSteensAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the CFLSteensAAResult object.\nclass CFLSteensAAWrapperPass : public ImmutablePass {\n  std::unique_ptr<CFLSteensAAResult> Result;\n\npublic:\n  static char ID;\n\n  CFLSteensAAWrapperPass();\n\n  CFLSteensAAResult &getResult() { return *Result; }\n  const CFLSteensAAResult &getResult() const { return *Result; }\n\n  void initializePass() override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n// createCFLSteensAAWrapperPass - This pass implements a set-based approach to\n// alias analysis.\nImmutablePass *createCFLSteensAAWrapperPass();\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_CFLSTEENSALIASANALYSIS_H\n"}, "28": {"id": 28, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CGSCCPassManager.h", "content": "//===- CGSCCPassManager.h - Call graph pass management ----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// This header provides classes for managing passes over SCCs of the call\n/// graph. These passes form an important component of LLVM's interprocedural\n/// optimizations. Because they operate on the SCCs of the call graph, and they\n/// traverse the graph in post-order, they can effectively do pair-wise\n/// interprocedural optimizations for all call edges in the program while\n/// incrementally refining it and improving the context of these pair-wise\n/// optimizations. At each call site edge, the callee has already been\n/// optimized as much as is possible. This in turn allows very accurate\n/// analysis of it for IPO.\n///\n/// A secondary more general goal is to be able to isolate optimization on\n/// unrelated parts of the IR module. This is useful to ensure our\n/// optimizations are principled and don't miss oportunities where refinement\n/// of one part of the module influence transformations in another part of the\n/// module. But this is also useful if we want to parallelize the optimizations\n/// across common large module graph shapes which tend to be very wide and have\n/// large regions of unrelated cliques.\n///\n/// To satisfy these goals, we use the LazyCallGraph which provides two graphs\n/// nested inside each other (and built lazily from the bottom-up): the call\n/// graph proper, and a reference graph. The reference graph is super set of\n/// the call graph and is a conservative approximation of what could through\n/// scalar or CGSCC transforms *become* the call graph. Using this allows us to\n/// ensure we optimize functions prior to them being introduced into the call\n/// graph by devirtualization or other technique, and thus ensures that\n/// subsequent pair-wise interprocedural optimizations observe the optimized\n/// form of these functions. The (potentially transitive) reference\n/// reachability used by the reference graph is a conservative approximation\n/// that still allows us to have independent regions of the graph.\n///\n/// FIXME: There is one major drawback of the reference graph: in its naive\n/// form it is quadratic because it contains a distinct edge for each\n/// (potentially indirect) reference, even if are all through some common\n/// global table of function pointers. This can be fixed in a number of ways\n/// that essentially preserve enough of the normalization. While it isn't\n/// expected to completely preclude the usability of this, it will need to be\n/// addressed.\n///\n///\n/// All of these issues are made substantially more complex in the face of\n/// mutations to the call graph while optimization passes are being run. When\n/// mutations to the call graph occur we want to achieve two different things:\n///\n/// - We need to update the call graph in-flight and invalidate analyses\n///   cached on entities in the graph. Because of the cache-based analysis\n///   design of the pass manager, it is essential to have stable identities for\n///   the elements of the IR that passes traverse, and to invalidate any\n///   analyses cached on these elements as the mutations take place.\n///\n/// - We want to preserve the incremental and post-order traversal of the\n///   graph even as it is refined and mutated. This means we want optimization\n///   to observe the most refined form of the call graph and to do so in\n///   post-order.\n///\n/// To address this, the CGSCC manager uses both worklists that can be expanded\n/// by passes which transform the IR, and provides invalidation tests to skip\n/// entries that become dead. This extra data is provided to every SCC pass so\n/// that it can carefully update the manager's traversal as the call graph\n/// mutates.\n///\n/// We also provide support for running function passes within the CGSCC walk,\n/// and there we provide automatic update of the call graph including of the\n/// pass manager to reflect call graph changes that fall out naturally as part\n/// of scalar transformations.\n///\n/// The patterns used to ensure the goals of post-order visitation of the fully\n/// refined graph:\n///\n/// 1) Sink toward the \"bottom\" as the graph is refined. This means that any\n///    iteration continues in some valid post-order sequence after the mutation\n///    has altered the structure.\n///\n/// 2) Enqueue in post-order, including the current entity. If the current\n///    entity's shape changes, it and everything after it in post-order needs\n///    to be visited to observe that shape.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_CGSCCPASSMANAGER_H\n#define LLVM_ANALYSIS_CGSCCPASSMANAGER_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/PriorityWorklist.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Analysis/LazyCallGraph.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/InstIterator.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <algorithm>\n#include <cassert>\n#include <utility>\n\nnamespace llvm {\n\nstruct CGSCCUpdateResult;\nclass Module;\n\n// Allow debug logging in this inline function.\n#define DEBUG_TYPE \"cgscc\"\n\n/// Extern template declaration for the analysis set for this IR unit.\nextern template class AllAnalysesOn<LazyCallGraph::SCC>;\n\nextern template class AnalysisManager<LazyCallGraph::SCC, LazyCallGraph &>;\n\n/// The CGSCC analysis manager.\n///\n/// See the documentation for the AnalysisManager template for detail\n/// documentation. This type serves as a convenient way to refer to this\n/// construct in the adaptors and proxies used to integrate this into the larger\n/// pass manager infrastructure.\nusing CGSCCAnalysisManager =\n    AnalysisManager<LazyCallGraph::SCC, LazyCallGraph &>;\n\n// Explicit specialization and instantiation declarations for the pass manager.\n// See the comments on the definition of the specialization for details on how\n// it differs from the primary template.\ntemplate <>\nPreservedAnalyses\nPassManager<LazyCallGraph::SCC, CGSCCAnalysisManager, LazyCallGraph &,\n            CGSCCUpdateResult &>::run(LazyCallGraph::SCC &InitialC,\n                                      CGSCCAnalysisManager &AM,\n                                      LazyCallGraph &G, CGSCCUpdateResult &UR);\nextern template class PassManager<LazyCallGraph::SCC, CGSCCAnalysisManager,\n                                  LazyCallGraph &, CGSCCUpdateResult &>;\n\n/// The CGSCC pass manager.\n///\n/// See the documentation for the PassManager template for details. It runs\n/// a sequence of SCC passes over each SCC that the manager is run over. This\n/// type serves as a convenient way to refer to this construct.\nusing CGSCCPassManager =\n    PassManager<LazyCallGraph::SCC, CGSCCAnalysisManager, LazyCallGraph &,\n                CGSCCUpdateResult &>;\n\n/// An explicit specialization of the require analysis template pass.\ntemplate <typename AnalysisT>\nstruct RequireAnalysisPass<AnalysisT, LazyCallGraph::SCC, CGSCCAnalysisManager,\n                           LazyCallGraph &, CGSCCUpdateResult &>\n    : PassInfoMixin<RequireAnalysisPass<AnalysisT, LazyCallGraph::SCC,\n                                        CGSCCAnalysisManager, LazyCallGraph &,\n                                        CGSCCUpdateResult &>> {\n  PreservedAnalyses run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &AM,\n                        LazyCallGraph &CG, CGSCCUpdateResult &) {\n    (void)AM.template getResult<AnalysisT>(C, CG);\n    return PreservedAnalyses::all();\n  }\n};\n\n/// A proxy from a \\c CGSCCAnalysisManager to a \\c Module.\nusing CGSCCAnalysisManagerModuleProxy =\n    InnerAnalysisManagerProxy<CGSCCAnalysisManager, Module>;\n\n/// We need a specialized result for the \\c CGSCCAnalysisManagerModuleProxy so\n/// it can have access to the call graph in order to walk all the SCCs when\n/// invalidating things.\ntemplate <> class CGSCCAnalysisManagerModuleProxy::Result {\npublic:\n  explicit Result(CGSCCAnalysisManager &InnerAM, LazyCallGraph &G)\n      : InnerAM(&InnerAM), G(&G) {}\n\n  /// Accessor for the analysis manager.\n  CGSCCAnalysisManager &getManager() { return *InnerAM; }\n\n  /// Handler for invalidation of the Module.\n  ///\n  /// If the proxy analysis itself is preserved, then we assume that the set of\n  /// SCCs in the Module hasn't changed. Thus any pointers to SCCs in the\n  /// CGSCCAnalysisManager are still valid, and we don't need to call \\c clear\n  /// on the CGSCCAnalysisManager.\n  ///\n  /// Regardless of whether this analysis is marked as preserved, all of the\n  /// analyses in the \\c CGSCCAnalysisManager are potentially invalidated based\n  /// on the set of preserved analyses.\n  bool invalidate(Module &M, const PreservedAnalyses &PA,\n                  ModuleAnalysisManager::Invalidator &Inv);\n\nprivate:\n  CGSCCAnalysisManager *InnerAM;\n  LazyCallGraph *G;\n};\n\n/// Provide a specialized run method for the \\c CGSCCAnalysisManagerModuleProxy\n/// so it can pass the lazy call graph to the result.\ntemplate <>\nCGSCCAnalysisManagerModuleProxy::Result\nCGSCCAnalysisManagerModuleProxy::run(Module &M, ModuleAnalysisManager &AM);\n\n// Ensure the \\c CGSCCAnalysisManagerModuleProxy is provided as an extern\n// template.\nextern template class InnerAnalysisManagerProxy<CGSCCAnalysisManager, Module>;\n\nextern template class OuterAnalysisManagerProxy<\n    ModuleAnalysisManager, LazyCallGraph::SCC, LazyCallGraph &>;\n\n/// A proxy from a \\c ModuleAnalysisManager to an \\c SCC.\nusing ModuleAnalysisManagerCGSCCProxy =\n    OuterAnalysisManagerProxy<ModuleAnalysisManager, LazyCallGraph::SCC,\n                              LazyCallGraph &>;\n\n/// Support structure for SCC passes to communicate updates the call graph back\n/// to the CGSCC pass manager infrsatructure.\n///\n/// The CGSCC pass manager runs SCC passes which are allowed to update the call\n/// graph and SCC structures. This means the structure the pass manager works\n/// on is mutating underneath it. In order to support that, there needs to be\n/// careful communication about the precise nature and ramifications of these\n/// updates to the pass management infrastructure.\n///\n/// All SCC passes will have to accept a reference to the management layer's\n/// update result struct and use it to reflect the results of any CG updates\n/// performed.\n///\n/// Passes which do not change the call graph structure in any way can just\n/// ignore this argument to their run method.\nstruct CGSCCUpdateResult {\n  /// Worklist of the RefSCCs queued for processing.\n  ///\n  /// When a pass refines the graph and creates new RefSCCs or causes them to\n  /// have a different shape or set of component SCCs it should add the RefSCCs\n  /// to this worklist so that we visit them in the refined form.\n  ///\n  /// This worklist is in reverse post-order, as we pop off the back in order\n  /// to observe RefSCCs in post-order. When adding RefSCCs, clients should add\n  /// them in reverse post-order.\n  SmallPriorityWorklist<LazyCallGraph::RefSCC *, 1> &RCWorklist;\n\n  /// Worklist of the SCCs queued for processing.\n  ///\n  /// When a pass refines the graph and creates new SCCs or causes them to have\n  /// a different shape or set of component functions it should add the SCCs to\n  /// this worklist so that we visit them in the refined form.\n  ///\n  /// Note that if the SCCs are part of a RefSCC that is added to the \\c\n  /// RCWorklist, they don't need to be added here as visiting the RefSCC will\n  /// be sufficient to re-visit the SCCs within it.\n  ///\n  /// This worklist is in reverse post-order, as we pop off the back in order\n  /// to observe SCCs in post-order. When adding SCCs, clients should add them\n  /// in reverse post-order.\n  SmallPriorityWorklist<LazyCallGraph::SCC *, 1> &CWorklist;\n\n  /// The set of invalidated RefSCCs which should be skipped if they are found\n  /// in \\c RCWorklist.\n  ///\n  /// This is used to quickly prune out RefSCCs when they get deleted and\n  /// happen to already be on the worklist. We use this primarily to avoid\n  /// scanning the list and removing entries from it.\n  SmallPtrSetImpl<LazyCallGraph::RefSCC *> &InvalidatedRefSCCs;\n\n  /// The set of invalidated SCCs which should be skipped if they are found\n  /// in \\c CWorklist.\n  ///\n  /// This is used to quickly prune out SCCs when they get deleted and happen\n  /// to already be on the worklist. We use this primarily to avoid scanning\n  /// the list and removing entries from it.\n  SmallPtrSetImpl<LazyCallGraph::SCC *> &InvalidatedSCCs;\n\n  /// If non-null, the updated current \\c RefSCC being processed.\n  ///\n  /// This is set when a graph refinement takes place an the \"current\" point in\n  /// the graph moves \"down\" or earlier in the post-order walk. This will often\n  /// cause the \"current\" RefSCC to be a newly created RefSCC object and the\n  /// old one to be added to the above worklist. When that happens, this\n  /// pointer is non-null and can be used to continue processing the \"top\" of\n  /// the post-order walk.\n  LazyCallGraph::RefSCC *UpdatedRC;\n\n  /// If non-null, the updated current \\c SCC being processed.\n  ///\n  /// This is set when a graph refinement takes place an the \"current\" point in\n  /// the graph moves \"down\" or earlier in the post-order walk. This will often\n  /// cause the \"current\" SCC to be a newly created SCC object and the old one\n  /// to be added to the above worklist. When that happens, this pointer is\n  /// non-null and can be used to continue processing the \"top\" of the\n  /// post-order walk.\n  LazyCallGraph::SCC *UpdatedC;\n\n  /// Preserved analyses across SCCs.\n  ///\n  /// We specifically want to allow CGSCC passes to mutate ancestor IR\n  /// (changing both the CG structure and the function IR itself). However,\n  /// this means we need to take special care to correctly mark what analyses\n  /// are preserved *across* SCCs. We have to track this out-of-band here\n  /// because within the main `PassManeger` infrastructure we need to mark\n  /// everything within an SCC as preserved in order to avoid repeatedly\n  /// invalidating the same analyses as we unnest pass managers and adaptors.\n  /// So we track the cross-SCC version of the preserved analyses here from any\n  /// code that does direct invalidation of SCC analyses, and then use it\n  /// whenever we move forward in the post-order walk of SCCs before running\n  /// passes over the new SCC.\n  PreservedAnalyses CrossSCCPA;\n\n  /// A hacky area where the inliner can retain history about inlining\n  /// decisions that mutated the call graph's SCC structure in order to avoid\n  /// infinite inlining. See the comments in the inliner's CG update logic.\n  ///\n  /// FIXME: Keeping this here seems like a big layering issue, we should look\n  /// for a better technique.\n  SmallDenseSet<std::pair<LazyCallGraph::Node *, LazyCallGraph::SCC *>, 4>\n      &InlinedInternalEdges;\n\n  /// Weak VHs to keep track of indirect calls for the purposes of detecting\n  /// devirtualization.\n  ///\n  /// This is a map to avoid having duplicate entries. If a Value is\n  /// deallocated, its corresponding WeakTrackingVH will be nulled out. When\n  /// checking if a Value is in the map or not, also check if the corresponding\n  /// WeakTrackingVH is null to avoid issues with a new Value sharing the same\n  /// address as a deallocated one.\n  SmallMapVector<Value *, WeakTrackingVH, 16> IndirectVHs;\n};\n\n/// The core module pass which does a post-order walk of the SCCs and\n/// runs a CGSCC pass over each one.\n///\n/// Designed to allow composition of a CGSCCPass(Manager) and\n/// a ModulePassManager. Note that this pass must be run with a module analysis\n/// manager as it uses the LazyCallGraph analysis. It will also run the\n/// \\c CGSCCAnalysisManagerModuleProxy analysis prior to running the CGSCC\n/// pass over the module to enable a \\c FunctionAnalysisManager to be used\n/// within this run safely.\nclass ModuleToPostOrderCGSCCPassAdaptor\n    : public PassInfoMixin<ModuleToPostOrderCGSCCPassAdaptor> {\npublic:\n  using PassConceptT =\n      detail::PassConcept<LazyCallGraph::SCC, CGSCCAnalysisManager,\n                          LazyCallGraph &, CGSCCUpdateResult &>;\n\n  explicit ModuleToPostOrderCGSCCPassAdaptor(std::unique_ptr<PassConceptT> Pass)\n      : Pass(std::move(Pass)) {}\n\n  ModuleToPostOrderCGSCCPassAdaptor(ModuleToPostOrderCGSCCPassAdaptor &&Arg)\n      : Pass(std::move(Arg.Pass)) {}\n\n  friend void swap(ModuleToPostOrderCGSCCPassAdaptor &LHS,\n                   ModuleToPostOrderCGSCCPassAdaptor &RHS) {\n    std::swap(LHS.Pass, RHS.Pass);\n  }\n\n  ModuleToPostOrderCGSCCPassAdaptor &\n  operator=(ModuleToPostOrderCGSCCPassAdaptor RHS) {\n    swap(*this, RHS);\n    return *this;\n  }\n\n  /// Runs the CGSCC pass across every SCC in the module.\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n\n  static bool isRequired() { return true; }\n\nprivate:\n  std::unique_ptr<PassConceptT> Pass;\n};\n\n/// A function to deduce a function pass type and wrap it in the\n/// templated adaptor.\ntemplate <typename CGSCCPassT>\nModuleToPostOrderCGSCCPassAdaptor\ncreateModuleToPostOrderCGSCCPassAdaptor(CGSCCPassT Pass) {\n  using PassModelT = detail::PassModel<LazyCallGraph::SCC, CGSCCPassT,\n                                       PreservedAnalyses, CGSCCAnalysisManager,\n                                       LazyCallGraph &, CGSCCUpdateResult &>;\n  return ModuleToPostOrderCGSCCPassAdaptor(\n      std::make_unique<PassModelT>(std::move(Pass)));\n}\n\n/// A proxy from a \\c FunctionAnalysisManager to an \\c SCC.\n///\n/// When a module pass runs and triggers invalidation, both the CGSCC and\n/// Function analysis manager proxies on the module get an invalidation event.\n/// We don't want to fully duplicate responsibility for most of the\n/// invalidation logic. Instead, this layer is only responsible for SCC-local\n/// invalidation events. We work with the module's FunctionAnalysisManager to\n/// invalidate function analyses.\nclass FunctionAnalysisManagerCGSCCProxy\n    : public AnalysisInfoMixin<FunctionAnalysisManagerCGSCCProxy> {\npublic:\n  class Result {\n  public:\n    explicit Result() : FAM(nullptr) {}\n    explicit Result(FunctionAnalysisManager &FAM) : FAM(&FAM) {}\n\n    void updateFAM(FunctionAnalysisManager &FAM) { this->FAM = &FAM; }\n    /// Accessor for the analysis manager.\n    FunctionAnalysisManager &getManager() {\n      assert(FAM);\n      return *FAM;\n    }\n\n    bool invalidate(LazyCallGraph::SCC &C, const PreservedAnalyses &PA,\n                    CGSCCAnalysisManager::Invalidator &Inv);\n\n  private:\n    FunctionAnalysisManager *FAM;\n  };\n\n  /// Computes the \\c FunctionAnalysisManager and stores it in the result proxy.\n  Result run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &AM, LazyCallGraph &);\n\nprivate:\n  friend AnalysisInfoMixin<FunctionAnalysisManagerCGSCCProxy>;\n\n  static AnalysisKey Key;\n};\n\nextern template class OuterAnalysisManagerProxy<CGSCCAnalysisManager, Function>;\n\n/// A proxy from a \\c CGSCCAnalysisManager to a \\c Function.\nusing CGSCCAnalysisManagerFunctionProxy =\n    OuterAnalysisManagerProxy<CGSCCAnalysisManager, Function>;\n\n/// Helper to update the call graph after running a function pass.\n///\n/// Function passes can only mutate the call graph in specific ways. This\n/// routine provides a helper that updates the call graph in those ways\n/// including returning whether any changes were made and populating a CG\n/// update result struct for the overall CGSCC walk.\nLazyCallGraph::SCC &updateCGAndAnalysisManagerForFunctionPass(\n    LazyCallGraph &G, LazyCallGraph::SCC &C, LazyCallGraph::Node &N,\n    CGSCCAnalysisManager &AM, CGSCCUpdateResult &UR,\n    FunctionAnalysisManager &FAM);\n\n/// Helper to update the call graph after running a CGSCC pass.\n///\n/// CGSCC passes can only mutate the call graph in specific ways. This\n/// routine provides a helper that updates the call graph in those ways\n/// including returning whether any changes were made and populating a CG\n/// update result struct for the overall CGSCC walk.\nLazyCallGraph::SCC &updateCGAndAnalysisManagerForCGSCCPass(\n    LazyCallGraph &G, LazyCallGraph::SCC &C, LazyCallGraph::Node &N,\n    CGSCCAnalysisManager &AM, CGSCCUpdateResult &UR,\n    FunctionAnalysisManager &FAM);\n\n/// Adaptor that maps from a SCC to its functions.\n///\n/// Designed to allow composition of a FunctionPass(Manager) and\n/// a CGSCCPassManager. Note that if this pass is constructed with a pointer\n/// to a \\c CGSCCAnalysisManager it will run the\n/// \\c FunctionAnalysisManagerCGSCCProxy analysis prior to running the function\n/// pass over the SCC to enable a \\c FunctionAnalysisManager to be used\n/// within this run safely.\nclass CGSCCToFunctionPassAdaptor\n    : public PassInfoMixin<CGSCCToFunctionPassAdaptor> {\npublic:\n  using PassConceptT = detail::PassConcept<Function, FunctionAnalysisManager>;\n\n  explicit CGSCCToFunctionPassAdaptor(std::unique_ptr<PassConceptT> Pass)\n      : Pass(std::move(Pass)) {}\n\n  CGSCCToFunctionPassAdaptor(CGSCCToFunctionPassAdaptor &&Arg)\n      : Pass(std::move(Arg.Pass)) {}\n\n  friend void swap(CGSCCToFunctionPassAdaptor &LHS,\n                   CGSCCToFunctionPassAdaptor &RHS) {\n    std::swap(LHS.Pass, RHS.Pass);\n  }\n\n  CGSCCToFunctionPassAdaptor &operator=(CGSCCToFunctionPassAdaptor RHS) {\n    swap(*this, RHS);\n    return *this;\n  }\n\n  /// Runs the function pass across every function in the module.\n  PreservedAnalyses run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &AM,\n                        LazyCallGraph &CG, CGSCCUpdateResult &UR);\n\n  static bool isRequired() { return true; }\n\nprivate:\n  std::unique_ptr<PassConceptT> Pass;\n};\n\n/// A function to deduce a function pass type and wrap it in the\n/// templated adaptor.\ntemplate <typename FunctionPassT>\nCGSCCToFunctionPassAdaptor\ncreateCGSCCToFunctionPassAdaptor(FunctionPassT Pass) {\n  using PassModelT =\n      detail::PassModel<Function, FunctionPassT, PreservedAnalyses,\n                        FunctionAnalysisManager>;\n  return CGSCCToFunctionPassAdaptor(\n      std::make_unique<PassModelT>(std::move(Pass)));\n}\n\n/// A helper that repeats an SCC pass each time an indirect call is refined to\n/// a direct call by that pass.\n///\n/// While the CGSCC pass manager works to re-visit SCCs and RefSCCs as they\n/// change shape, we may also want to repeat an SCC pass if it simply refines\n/// an indirect call to a direct call, even if doing so does not alter the\n/// shape of the graph. Note that this only pertains to direct calls to\n/// functions where IPO across the SCC may be able to compute more precise\n/// results. For intrinsics, we assume scalar optimizations already can fully\n/// reason about them.\n///\n/// This repetition has the potential to be very large however, as each one\n/// might refine a single call site. As a consequence, in practice we use an\n/// upper bound on the number of repetitions to limit things.\nclass DevirtSCCRepeatedPass : public PassInfoMixin<DevirtSCCRepeatedPass> {\npublic:\n  using PassConceptT =\n      detail::PassConcept<LazyCallGraph::SCC, CGSCCAnalysisManager,\n                          LazyCallGraph &, CGSCCUpdateResult &>;\n\n  explicit DevirtSCCRepeatedPass(std::unique_ptr<PassConceptT> Pass,\n                                 int MaxIterations)\n      : Pass(std::move(Pass)), MaxIterations(MaxIterations) {}\n\n  /// Runs the wrapped pass up to \\c MaxIterations on the SCC, iterating\n  /// whenever an indirect call is refined.\n  PreservedAnalyses run(LazyCallGraph::SCC &InitialC, CGSCCAnalysisManager &AM,\n                        LazyCallGraph &CG, CGSCCUpdateResult &UR);\n\nprivate:\n  std::unique_ptr<PassConceptT> Pass;\n  int MaxIterations;\n};\n\n/// A function to deduce a function pass type and wrap it in the\n/// templated adaptor.\ntemplate <typename CGSCCPassT>\nDevirtSCCRepeatedPass createDevirtSCCRepeatedPass(CGSCCPassT Pass,\n                                                  int MaxIterations) {\n  using PassModelT = detail::PassModel<LazyCallGraph::SCC, CGSCCPassT,\n                                       PreservedAnalyses, CGSCCAnalysisManager,\n                                       LazyCallGraph &, CGSCCUpdateResult &>;\n  return DevirtSCCRepeatedPass(std::make_unique<PassModelT>(std::move(Pass)),\n                               MaxIterations);\n}\n\n// Clear out the debug logging macro.\n#undef DEBUG_TYPE\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_CGSCCPASSMANAGER_H\n"}, "29": {"id": 29, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CallGraph.h", "content": "//===- CallGraph.h - Build a Module's call graph ----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// This file provides interfaces used to build and manipulate a call graph,\n/// which is a very useful tool for interprocedural optimization.\n///\n/// Every function in a module is represented as a node in the call graph.  The\n/// callgraph node keeps track of which functions are called by the function\n/// corresponding to the node.\n///\n/// A call graph may contain nodes where the function that they correspond to\n/// is null.  These 'external' nodes are used to represent control flow that is\n/// not represented (or analyzable) in the module.  In particular, this\n/// analysis builds one external node such that:\n///   1. All functions in the module without internal linkage will have edges\n///      from this external node, indicating that they could be called by\n///      functions outside of the module.\n///   2. All functions whose address is used for something more than a direct\n///      call, for example being stored into a memory location will also have\n///      an edge from this external node.  Since they may be called by an\n///      unknown caller later, they must be tracked as such.\n///\n/// There is a second external node added for calls that leave this module.\n/// Functions have a call edge to the external node iff:\n///   1. The function is external, reflecting the fact that they could call\n///      anything without internal linkage or that has its address taken.\n///   2. The function contains an indirect function call.\n///\n/// As an extension in the future, there may be multiple nodes with a null\n/// function.  These will be used when we can prove (through pointer analysis)\n/// that an indirect call site can call only a specific set of functions.\n///\n/// Because of these properties, the CallGraph captures a conservative superset\n/// of all of the caller-callee relationships, which is useful for\n/// transformations.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_CALLGRAPH_H\n#define LLVM_ANALYSIS_CALLGRAPH_H\n\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Intrinsics.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n#include <cassert>\n#include <map>\n#include <memory>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\nclass CallGraphNode;\nclass Module;\nclass raw_ostream;\n\n/// The basic data container for the call graph of a \\c Module of IR.\n///\n/// This class exposes both the interface to the call graph for a module of IR.\n///\n/// The core call graph itself can also be updated to reflect changes to the IR.\nclass CallGraph {\n  Module &M;\n\n  using FunctionMapTy =\n      std::map<const Function *, std::unique_ptr<CallGraphNode>>;\n\n  /// A map from \\c Function* to \\c CallGraphNode*.\n  FunctionMapTy FunctionMap;\n\n  /// This node has edges to all external functions and those internal\n  /// functions that have their address taken.\n  CallGraphNode *ExternalCallingNode;\n\n  /// This node has edges to it from all functions making indirect calls\n  /// or calling an external function.\n  std::unique_ptr<CallGraphNode> CallsExternalNode;\n\npublic:\n  explicit CallGraph(Module &M);\n  CallGraph(CallGraph &&Arg);\n  ~CallGraph();\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\n  using iterator = FunctionMapTy::iterator;\n  using const_iterator = FunctionMapTy::const_iterator;\n\n  /// Returns the module the call graph corresponds to.\n  Module &getModule() const { return M; }\n\n  bool invalidate(Module &, const PreservedAnalyses &PA,\n                  ModuleAnalysisManager::Invalidator &);\n\n  inline iterator begin() { return FunctionMap.begin(); }\n  inline iterator end() { return FunctionMap.end(); }\n  inline const_iterator begin() const { return FunctionMap.begin(); }\n  inline const_iterator end() const { return FunctionMap.end(); }\n\n  /// Returns the call graph node for the provided function.\n  inline const CallGraphNode *operator[](const Function *F) const {\n    const_iterator I = FunctionMap.find(F);\n    assert(I != FunctionMap.end() && \"Function not in callgraph!\");\n    return I->second.get();\n  }\n\n  /// Returns the call graph node for the provided function.\n  inline CallGraphNode *operator[](const Function *F) {\n    const_iterator I = FunctionMap.find(F);\n    assert(I != FunctionMap.end() && \"Function not in callgraph!\");\n    return I->second.get();\n  }\n\n  /// Returns the \\c CallGraphNode which is used to represent\n  /// undetermined calls into the callgraph.\n  CallGraphNode *getExternalCallingNode() const { return ExternalCallingNode; }\n\n  CallGraphNode *getCallsExternalNode() const {\n    return CallsExternalNode.get();\n  }\n\n  /// Old node has been deleted, and New is to be used in its place, update the\n  /// ExternalCallingNode.\n  void ReplaceExternalCallEdge(CallGraphNode *Old, CallGraphNode *New);\n\n  //===---------------------------------------------------------------------\n  // Functions to keep a call graph up to date with a function that has been\n  // modified.\n  //\n\n  /// Unlink the function from this module, returning it.\n  ///\n  /// Because this removes the function from the module, the call graph node is\n  /// destroyed.  This is only valid if the function does not call any other\n  /// functions (ie, there are no edges in it's CGN).  The easiest way to do\n  /// this is to dropAllReferences before calling this.\n  Function *removeFunctionFromModule(CallGraphNode *CGN);\n\n  /// Similar to operator[], but this will insert a new CallGraphNode for\n  /// \\c F if one does not already exist.\n  CallGraphNode *getOrInsertFunction(const Function *F);\n\n  /// Populate \\p CGN based on the calls inside the associated function.\n  void populateCallGraphNode(CallGraphNode *CGN);\n\n  /// Add a function to the call graph, and link the node to all of the\n  /// functions that it calls.\n  void addToCallGraph(Function *F);\n};\n\n/// A node in the call graph for a module.\n///\n/// Typically represents a function in the call graph. There are also special\n/// \"null\" nodes used to represent theoretical entries in the call graph.\nclass CallGraphNode {\npublic:\n  /// A pair of the calling instruction (a call or invoke)\n  /// and the call graph node being called.\n  /// Call graph node may have two types of call records which represent an edge\n  /// in the call graph - reference or a call edge. Reference edges are not\n  /// associated with any call instruction and are created with the first field\n  /// set to `None`, while real call edges have instruction address in this\n  /// field. Therefore, all real call edges are expected to have a value in the\n  /// first field and it is not supposed to be `nullptr`.\n  /// Reference edges, for example, are used for connecting broker function\n  /// caller to the callback function for callback call sites.\n  using CallRecord = std::pair<Optional<WeakTrackingVH>, CallGraphNode *>;\n\npublic:\n  using CalledFunctionsVector = std::vector<CallRecord>;\n\n  /// Creates a node for the specified function.\n  inline CallGraphNode(CallGraph *CG, Function *F) : CG(CG), F(F) {}\n\n  CallGraphNode(const CallGraphNode &) = delete;\n  CallGraphNode &operator=(const CallGraphNode &) = delete;\n\n  ~CallGraphNode() {\n    assert(NumReferences == 0 && \"Node deleted while references remain\");\n  }\n\n  using iterator = std::vector<CallRecord>::iterator;\n  using const_iterator = std::vector<CallRecord>::const_iterator;\n\n  /// Returns the function that this call graph node represents.\n  Function *getFunction() const { return F; }\n\n  inline iterator begin() { return CalledFunctions.begin(); }\n  inline iterator end() { return CalledFunctions.end(); }\n  inline const_iterator begin() const { return CalledFunctions.begin(); }\n  inline const_iterator end() const { return CalledFunctions.end(); }\n  inline bool empty() const { return CalledFunctions.empty(); }\n  inline unsigned size() const { return (unsigned)CalledFunctions.size(); }\n\n  /// Returns the number of other CallGraphNodes in this CallGraph that\n  /// reference this node in their callee list.\n  unsigned getNumReferences() const { return NumReferences; }\n\n  /// Returns the i'th called function.\n  CallGraphNode *operator[](unsigned i) const {\n    assert(i < CalledFunctions.size() && \"Invalid index\");\n    return CalledFunctions[i].second;\n  }\n\n  /// Print out this call graph node.\n  void dump() const;\n  void print(raw_ostream &OS) const;\n\n  //===---------------------------------------------------------------------\n  // Methods to keep a call graph up to date with a function that has been\n  // modified\n  //\n\n  /// Removes all edges from this CallGraphNode to any functions it\n  /// calls.\n  void removeAllCalledFunctions() {\n    while (!CalledFunctions.empty()) {\n      CalledFunctions.back().second->DropRef();\n      CalledFunctions.pop_back();\n    }\n  }\n\n  /// Moves all the callee information from N to this node.\n  void stealCalledFunctionsFrom(CallGraphNode *N) {\n    assert(CalledFunctions.empty() &&\n           \"Cannot steal callsite information if I already have some\");\n    std::swap(CalledFunctions, N->CalledFunctions);\n  }\n\n  /// Adds a function to the list of functions called by this one.\n  void addCalledFunction(CallBase *Call, CallGraphNode *M) {\n    assert(!Call || !Call->getCalledFunction() ||\n           !Call->getCalledFunction()->isIntrinsic() ||\n           !Intrinsic::isLeaf(Call->getCalledFunction()->getIntrinsicID()));\n    CalledFunctions.emplace_back(\n        Call ? Optional<WeakTrackingVH>(Call) : Optional<WeakTrackingVH>(), M);\n    M->AddRef();\n  }\n\n  void removeCallEdge(iterator I) {\n    I->second->DropRef();\n    *I = CalledFunctions.back();\n    CalledFunctions.pop_back();\n  }\n\n  /// Removes the edge in the node for the specified call site.\n  ///\n  /// Note that this method takes linear time, so it should be used sparingly.\n  void removeCallEdgeFor(CallBase &Call);\n\n  /// Removes all call edges from this node to the specified callee\n  /// function.\n  ///\n  /// This takes more time to execute than removeCallEdgeTo, so it should not\n  /// be used unless necessary.\n  void removeAnyCallEdgeTo(CallGraphNode *Callee);\n\n  /// Removes one edge associated with a null callsite from this node to\n  /// the specified callee function.\n  void removeOneAbstractEdgeTo(CallGraphNode *Callee);\n\n  /// Replaces the edge in the node for the specified call site with a\n  /// new one.\n  ///\n  /// Note that this method takes linear time, so it should be used sparingly.\n  void replaceCallEdge(CallBase &Call, CallBase &NewCall,\n                       CallGraphNode *NewNode);\n\nprivate:\n  friend class CallGraph;\n\n  CallGraph *CG;\n  Function *F;\n\n  std::vector<CallRecord> CalledFunctions;\n\n  /// The number of times that this CallGraphNode occurs in the\n  /// CalledFunctions array of this or other CallGraphNodes.\n  unsigned NumReferences = 0;\n\n  void DropRef() { --NumReferences; }\n  void AddRef() { ++NumReferences; }\n\n  /// A special function that should only be used by the CallGraph class.\n  void allReferencesDropped() { NumReferences = 0; }\n};\n\n/// An analysis pass to compute the \\c CallGraph for a \\c Module.\n///\n/// This class implements the concept of an analysis pass used by the \\c\n/// ModuleAnalysisManager to run an analysis over a module and cache the\n/// resulting data.\nclass CallGraphAnalysis : public AnalysisInfoMixin<CallGraphAnalysis> {\n  friend AnalysisInfoMixin<CallGraphAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// A formulaic type to inform clients of the result type.\n  using Result = CallGraph;\n\n  /// Compute the \\c CallGraph for the module \\c M.\n  ///\n  /// The real work here is done in the \\c CallGraph constructor.\n  CallGraph run(Module &M, ModuleAnalysisManager &) { return CallGraph(M); }\n};\n\n/// Printer pass for the \\c CallGraphAnalysis results.\nclass CallGraphPrinterPass : public PassInfoMixin<CallGraphPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit CallGraphPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// The \\c ModulePass which wraps up a \\c CallGraph and the logic to\n/// build it.\n///\n/// This class exposes both the interface to the call graph container and the\n/// module pass which runs over a module of IR and produces the call graph. The\n/// call graph interface is entirelly a wrapper around a \\c CallGraph object\n/// which is stored internally for each module.\nclass CallGraphWrapperPass : public ModulePass {\n  std::unique_ptr<CallGraph> G;\n\npublic:\n  static char ID; // Class identification, replacement for typeinfo\n\n  CallGraphWrapperPass();\n  ~CallGraphWrapperPass() override;\n\n  /// The internal \\c CallGraph around which the rest of this interface\n  /// is wrapped.\n  const CallGraph &getCallGraph() const { return *G; }\n  CallGraph &getCallGraph() { return *G; }\n\n  using iterator = CallGraph::iterator;\n  using const_iterator = CallGraph::const_iterator;\n\n  /// Returns the module the call graph corresponds to.\n  Module &getModule() const { return G->getModule(); }\n\n  inline iterator begin() { return G->begin(); }\n  inline iterator end() { return G->end(); }\n  inline const_iterator begin() const { return G->begin(); }\n  inline const_iterator end() const { return G->end(); }\n\n  /// Returns the call graph node for the provided function.\n  inline const CallGraphNode *operator[](const Function *F) const {\n    return (*G)[F];\n  }\n\n  /// Returns the call graph node for the provided function.\n  inline CallGraphNode *operator[](const Function *F) { return (*G)[F]; }\n\n  /// Returns the \\c CallGraphNode which is used to represent\n  /// undetermined calls into the callgraph.\n  CallGraphNode *getExternalCallingNode() const {\n    return G->getExternalCallingNode();\n  }\n\n  CallGraphNode *getCallsExternalNode() const {\n    return G->getCallsExternalNode();\n  }\n\n  //===---------------------------------------------------------------------\n  // Functions to keep a call graph up to date with a function that has been\n  // modified.\n  //\n\n  /// Unlink the function from this module, returning it.\n  ///\n  /// Because this removes the function from the module, the call graph node is\n  /// destroyed.  This is only valid if the function does not call any other\n  /// functions (ie, there are no edges in it's CGN).  The easiest way to do\n  /// this is to dropAllReferences before calling this.\n  Function *removeFunctionFromModule(CallGraphNode *CGN) {\n    return G->removeFunctionFromModule(CGN);\n  }\n\n  /// Similar to operator[], but this will insert a new CallGraphNode for\n  /// \\c F if one does not already exist.\n  CallGraphNode *getOrInsertFunction(const Function *F) {\n    return G->getOrInsertFunction(F);\n  }\n\n  //===---------------------------------------------------------------------\n  // Implementation of the ModulePass interface needed here.\n  //\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  bool runOnModule(Module &M) override;\n  void releaseMemory() override;\n\n  void print(raw_ostream &o, const Module *) const override;\n  void dump() const;\n};\n\n//===----------------------------------------------------------------------===//\n// GraphTraits specializations for call graphs so that they can be treated as\n// graphs by the generic graph algorithms.\n//\n\n// Provide graph traits for traversing call graphs using standard graph\n// traversals.\ntemplate <> struct GraphTraits<CallGraphNode *> {\n  using NodeRef = CallGraphNode *;\n  using CGNPairTy = CallGraphNode::CallRecord;\n\n  static NodeRef getEntryNode(CallGraphNode *CGN) { return CGN; }\n  static CallGraphNode *CGNGetValue(CGNPairTy P) { return P.second; }\n\n  using ChildIteratorType =\n      mapped_iterator<CallGraphNode::iterator, decltype(&CGNGetValue)>;\n\n  static ChildIteratorType child_begin(NodeRef N) {\n    return ChildIteratorType(N->begin(), &CGNGetValue);\n  }\n\n  static ChildIteratorType child_end(NodeRef N) {\n    return ChildIteratorType(N->end(), &CGNGetValue);\n  }\n};\n\ntemplate <> struct GraphTraits<const CallGraphNode *> {\n  using NodeRef = const CallGraphNode *;\n  using CGNPairTy = CallGraphNode::CallRecord;\n  using EdgeRef = const CallGraphNode::CallRecord &;\n\n  static NodeRef getEntryNode(const CallGraphNode *CGN) { return CGN; }\n  static const CallGraphNode *CGNGetValue(CGNPairTy P) { return P.second; }\n\n  using ChildIteratorType =\n      mapped_iterator<CallGraphNode::const_iterator, decltype(&CGNGetValue)>;\n  using ChildEdgeIteratorType = CallGraphNode::const_iterator;\n\n  static ChildIteratorType child_begin(NodeRef N) {\n    return ChildIteratorType(N->begin(), &CGNGetValue);\n  }\n\n  static ChildIteratorType child_end(NodeRef N) {\n    return ChildIteratorType(N->end(), &CGNGetValue);\n  }\n\n  static ChildEdgeIteratorType child_edge_begin(NodeRef N) {\n    return N->begin();\n  }\n  static ChildEdgeIteratorType child_edge_end(NodeRef N) { return N->end(); }\n\n  static NodeRef edge_dest(EdgeRef E) { return E.second; }\n};\n\ntemplate <>\nstruct GraphTraits<CallGraph *> : public GraphTraits<CallGraphNode *> {\n  using PairTy =\n      std::pair<const Function *const, std::unique_ptr<CallGraphNode>>;\n\n  static NodeRef getEntryNode(CallGraph *CGN) {\n    return CGN->getExternalCallingNode(); // Start at the external node!\n  }\n\n  static CallGraphNode *CGGetValuePtr(const PairTy &P) {\n    return P.second.get();\n  }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator =\n      mapped_iterator<CallGraph::iterator, decltype(&CGGetValuePtr)>;\n\n  static nodes_iterator nodes_begin(CallGraph *CG) {\n    return nodes_iterator(CG->begin(), &CGGetValuePtr);\n  }\n\n  static nodes_iterator nodes_end(CallGraph *CG) {\n    return nodes_iterator(CG->end(), &CGGetValuePtr);\n  }\n};\n\ntemplate <>\nstruct GraphTraits<const CallGraph *> : public GraphTraits<\n                                            const CallGraphNode *> {\n  using PairTy =\n      std::pair<const Function *const, std::unique_ptr<CallGraphNode>>;\n\n  static NodeRef getEntryNode(const CallGraph *CGN) {\n    return CGN->getExternalCallingNode(); // Start at the external node!\n  }\n\n  static const CallGraphNode *CGGetValuePtr(const PairTy &P) {\n    return P.second.get();\n  }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator =\n      mapped_iterator<CallGraph::const_iterator, decltype(&CGGetValuePtr)>;\n\n  static nodes_iterator nodes_begin(const CallGraph *CG) {\n    return nodes_iterator(CG->begin(), &CGGetValuePtr);\n  }\n\n  static nodes_iterator nodes_end(const CallGraph *CG) {\n    return nodes_iterator(CG->end(), &CGGetValuePtr);\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_CALLGRAPH_H\n"}, "31": {"id": 31, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DDG.h", "content": "//===- llvm/Analysis/DDG.h --------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the Data-Dependence Graph (DDG).\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_DDG_H\n#define LLVM_ANALYSIS_DDG_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DirectedGraph.h\"\n#include \"llvm/Analysis/DependenceAnalysis.h\"\n#include \"llvm/Analysis/DependenceGraphBuilder.h\"\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/IR/Instructions.h\"\n\nnamespace llvm {\nclass DDGNode;\nclass DDGEdge;\nusing DDGNodeBase = DGNode<DDGNode, DDGEdge>;\nusing DDGEdgeBase = DGEdge<DDGNode, DDGEdge>;\nusing DDGBase = DirectedGraph<DDGNode, DDGEdge>;\nclass LPMUpdater;\n\n/// Data Dependence Graph Node\n/// The graph can represent the following types of nodes:\n/// 1. Single instruction node containing just one instruction.\n/// 2. Multiple instruction node where two or more instructions from\n///    the same basic block are merged into one node.\n/// 3. Pi-block node which is a group of other DDG nodes that are part of a\n///    strongly-connected component of the graph.\n///    A pi-block node contains more than one single or multiple instruction\n///    nodes. The root node cannot be part of a pi-block.\n/// 4. Root node is a special node that connects to all components such that\n///    there is always a path from it to any node in the graph.\nclass DDGNode : public DDGNodeBase {\npublic:\n  using InstructionListType = SmallVectorImpl<Instruction *>;\n\n  enum class NodeKind {\n    Unknown,\n    SingleInstruction,\n    MultiInstruction,\n    PiBlock,\n    Root,\n  };\n\n  DDGNode() = delete;\n  DDGNode(const NodeKind K) : DDGNodeBase(), Kind(K) {}\n  DDGNode(const DDGNode &N) : DDGNodeBase(N), Kind(N.Kind) {}\n  DDGNode(DDGNode &&N) : DDGNodeBase(std::move(N)), Kind(N.Kind) {}\n  virtual ~DDGNode() = 0;\n\n  DDGNode &operator=(const DDGNode &N) {\n    DGNode::operator=(N);\n    Kind = N.Kind;\n    return *this;\n  }\n\n  DDGNode &operator=(DDGNode &&N) {\n    DGNode::operator=(std::move(N));\n    Kind = N.Kind;\n    return *this;\n  }\n\n  /// Getter for the kind of this node.\n  NodeKind getKind() const { return Kind; }\n\n  /// Collect a list of instructions, in \\p IList, for which predicate \\p Pred\n  /// evaluates to true when iterating over instructions of this node. Return\n  /// true if at least one instruction was collected, and false otherwise.\n  bool collectInstructions(llvm::function_ref<bool(Instruction *)> const &Pred,\n                           InstructionListType &IList) const;\n\nprotected:\n  /// Setter for the kind of this node.\n  void setKind(NodeKind K) { Kind = K; }\n\nprivate:\n  NodeKind Kind;\n};\n\n/// Subclass of DDGNode representing the root node of the graph.\n/// There should only be one such node in a given graph.\nclass RootDDGNode : public DDGNode {\npublic:\n  RootDDGNode() : DDGNode(NodeKind::Root) {}\n  RootDDGNode(const RootDDGNode &N) = delete;\n  RootDDGNode(RootDDGNode &&N) : DDGNode(std::move(N)) {}\n  ~RootDDGNode() {}\n\n  /// Define classof to be able to use isa<>, cast<>, dyn_cast<>, etc.\n  static bool classof(const DDGNode *N) {\n    return N->getKind() == NodeKind::Root;\n  }\n  static bool classof(const RootDDGNode *N) { return true; }\n};\n\n/// Subclass of DDGNode representing single or multi-instruction nodes.\nclass SimpleDDGNode : public DDGNode {\n  friend class DDGBuilder;\n\npublic:\n  SimpleDDGNode() = delete;\n  SimpleDDGNode(Instruction &I);\n  SimpleDDGNode(const SimpleDDGNode &N);\n  SimpleDDGNode(SimpleDDGNode &&N);\n  ~SimpleDDGNode();\n\n  SimpleDDGNode &operator=(const SimpleDDGNode &N) {\n    DDGNode::operator=(N);\n    InstList = N.InstList;\n    return *this;\n  }\n\n  SimpleDDGNode &operator=(SimpleDDGNode &&N) {\n    DDGNode::operator=(std::move(N));\n    InstList = std::move(N.InstList);\n    return *this;\n  }\n\n  /// Get the list of instructions in this node.\n  const InstructionListType &getInstructions() const {\n    assert(!InstList.empty() && \"Instruction List is empty.\");\n    return InstList;\n  }\n  InstructionListType &getInstructions() {\n    return const_cast<InstructionListType &>(\n        static_cast<const SimpleDDGNode *>(this)->getInstructions());\n  }\n\n  /// Get the first/last instruction in the node.\n  Instruction *getFirstInstruction() const { return getInstructions().front(); }\n  Instruction *getLastInstruction() const { return getInstructions().back(); }\n\n  /// Define classof to be able to use isa<>, cast<>, dyn_cast<>, etc.\n  static bool classof(const DDGNode *N) {\n    return N->getKind() == NodeKind::SingleInstruction ||\n           N->getKind() == NodeKind::MultiInstruction;\n  }\n  static bool classof(const SimpleDDGNode *N) { return true; }\n\nprivate:\n  /// Append the list of instructions in \\p Input to this node.\n  void appendInstructions(const InstructionListType &Input) {\n    setKind((InstList.size() == 0 && Input.size() == 1)\n                ? NodeKind::SingleInstruction\n                : NodeKind::MultiInstruction);\n    llvm::append_range(InstList, Input);\n  }\n  void appendInstructions(const SimpleDDGNode &Input) {\n    appendInstructions(Input.getInstructions());\n  }\n\n  /// List of instructions associated with a single or multi-instruction node.\n  SmallVector<Instruction *, 2> InstList;\n};\n\n/// Subclass of DDGNode representing a pi-block. A pi-block represents a group\n/// of DDG nodes that are part of a strongly-connected component of the graph.\n/// Replacing all the SCCs with pi-blocks results in an acyclic representation\n/// of the DDG. For example if we have:\n/// {a -> b}, {b -> c, d}, {c -> a}\n/// the cycle a -> b -> c -> a is abstracted into a pi-block \"p\" as follows:\n/// {p -> d} with \"p\" containing: {a -> b}, {b -> c}, {c -> a}\nclass PiBlockDDGNode : public DDGNode {\npublic:\n  using PiNodeList = SmallVector<DDGNode *, 4>;\n\n  PiBlockDDGNode() = delete;\n  PiBlockDDGNode(const PiNodeList &List);\n  PiBlockDDGNode(const PiBlockDDGNode &N);\n  PiBlockDDGNode(PiBlockDDGNode &&N);\n  ~PiBlockDDGNode();\n\n  PiBlockDDGNode &operator=(const PiBlockDDGNode &N) {\n    DDGNode::operator=(N);\n    NodeList = N.NodeList;\n    return *this;\n  }\n\n  PiBlockDDGNode &operator=(PiBlockDDGNode &&N) {\n    DDGNode::operator=(std::move(N));\n    NodeList = std::move(N.NodeList);\n    return *this;\n  }\n\n  /// Get the list of nodes in this pi-block.\n  const PiNodeList &getNodes() const {\n    assert(!NodeList.empty() && \"Node list is empty.\");\n    return NodeList;\n  }\n  PiNodeList &getNodes() {\n    return const_cast<PiNodeList &>(\n        static_cast<const PiBlockDDGNode *>(this)->getNodes());\n  }\n\n  /// Define classof to be able to use isa<>, cast<>, dyn_cast<>, etc.\n  static bool classof(const DDGNode *N) {\n    return N->getKind() == NodeKind::PiBlock;\n  }\n\nprivate:\n  /// List of nodes in this pi-block.\n  PiNodeList NodeList;\n};\n\n/// Data Dependency Graph Edge.\n/// An edge in the DDG can represent a def-use relationship or\n/// a memory dependence based on the result of DependenceAnalysis.\n/// A rooted edge connects the root node to one of the components\n/// of the graph.\nclass DDGEdge : public DDGEdgeBase {\npublic:\n  /// The kind of edge in the DDG\n  enum class EdgeKind {\n    Unknown,\n    RegisterDefUse,\n    MemoryDependence,\n    Rooted,\n    Last = Rooted // Must be equal to the largest enum value.\n  };\n\n  explicit DDGEdge(DDGNode &N) = delete;\n  DDGEdge(DDGNode &N, EdgeKind K) : DDGEdgeBase(N), Kind(K) {}\n  DDGEdge(const DDGEdge &E) : DDGEdgeBase(E), Kind(E.getKind()) {}\n  DDGEdge(DDGEdge &&E) : DDGEdgeBase(std::move(E)), Kind(E.Kind) {}\n  DDGEdge &operator=(const DDGEdge &E) {\n    DDGEdgeBase::operator=(E);\n    Kind = E.Kind;\n    return *this;\n  }\n\n  DDGEdge &operator=(DDGEdge &&E) {\n    DDGEdgeBase::operator=(std::move(E));\n    Kind = E.Kind;\n    return *this;\n  }\n\n  /// Get the edge kind\n  EdgeKind getKind() const { return Kind; };\n\n  /// Return true if this is a def-use edge, and false otherwise.\n  bool isDefUse() const { return Kind == EdgeKind::RegisterDefUse; }\n\n  /// Return true if this is a memory dependence edge, and false otherwise.\n  bool isMemoryDependence() const { return Kind == EdgeKind::MemoryDependence; }\n\n  /// Return true if this is an edge stemming from the root node, and false\n  /// otherwise.\n  bool isRooted() const { return Kind == EdgeKind::Rooted; }\n\nprivate:\n  EdgeKind Kind;\n};\n\n/// Encapsulate some common data and functionality needed for different\n/// variations of data dependence graphs.\ntemplate <typename NodeType> class DependenceGraphInfo {\npublic:\n  using DependenceList = SmallVector<std::unique_ptr<Dependence>, 1>;\n\n  DependenceGraphInfo() = delete;\n  DependenceGraphInfo(const DependenceGraphInfo &G) = delete;\n  DependenceGraphInfo(const std::string &N, const DependenceInfo &DepInfo)\n      : Name(N), DI(DepInfo), Root(nullptr) {}\n  DependenceGraphInfo(DependenceGraphInfo &&G)\n      : Name(std::move(G.Name)), DI(std::move(G.DI)), Root(G.Root) {}\n  virtual ~DependenceGraphInfo() {}\n\n  /// Return the label that is used to name this graph.\n  StringRef getName() const { return Name; }\n\n  /// Return the root node of the graph.\n  NodeType &getRoot() const {\n    assert(Root && \"Root node is not available yet. Graph construction may \"\n                   \"still be in progress\\n\");\n    return *Root;\n  }\n\n  /// Collect all the data dependency infos coming from any pair of memory\n  /// accesses from \\p Src to \\p Dst, and store them into \\p Deps. Return true\n  /// if a dependence exists, and false otherwise.\n  bool getDependencies(const NodeType &Src, const NodeType &Dst,\n                       DependenceList &Deps) const;\n\n  /// Return a string representing the type of dependence that the dependence\n  /// analysis identified between the two given nodes. This function assumes\n  /// that there is a memory dependence between the given two nodes.\n  std::string getDependenceString(const NodeType &Src,\n                                  const NodeType &Dst) const;\n\nprotected:\n  // Name of the graph.\n  std::string Name;\n\n  // Store a copy of DependenceInfo in the graph, so that individual memory\n  // dependencies don't need to be stored. Instead when the dependence is\n  // queried it is recomputed using @DI.\n  const DependenceInfo DI;\n\n  // A special node in the graph that has an edge to every connected component of\n  // the graph, to ensure all nodes are reachable in a graph walk.\n  NodeType *Root = nullptr;\n};\n\nusing DDGInfo = DependenceGraphInfo<DDGNode>;\n\n/// Data Dependency Graph\nclass DataDependenceGraph : public DDGBase, public DDGInfo {\n  friend AbstractDependenceGraphBuilder<DataDependenceGraph>;\n  friend class DDGBuilder;\n\npublic:\n  using NodeType = DDGNode;\n  using EdgeType = DDGEdge;\n\n  DataDependenceGraph() = delete;\n  DataDependenceGraph(const DataDependenceGraph &G) = delete;\n  DataDependenceGraph(DataDependenceGraph &&G)\n      : DDGBase(std::move(G)), DDGInfo(std::move(G)) {}\n  DataDependenceGraph(Function &F, DependenceInfo &DI);\n  DataDependenceGraph(Loop &L, LoopInfo &LI, DependenceInfo &DI);\n  ~DataDependenceGraph();\n\n  /// If node \\p N belongs to a pi-block return a pointer to the pi-block,\n  /// otherwise return null.\n  const PiBlockDDGNode *getPiBlock(const NodeType &N) const;\n\nprotected:\n  /// Add node \\p N to the graph, if it's not added yet, and keep track of the\n  /// root node as well as pi-blocks and their members. Return true if node is\n  /// successfully added.\n  bool addNode(NodeType &N);\n\nprivate:\n  using PiBlockMapType = DenseMap<const NodeType *, const PiBlockDDGNode *>;\n\n  /// Mapping from graph nodes to their containing pi-blocks. If a node is not\n  /// part of a pi-block, it will not appear in this map.\n  PiBlockMapType PiBlockMap;\n};\n\n/// Concrete implementation of a pure data dependence graph builder. This class\n/// provides custom implementation for the pure-virtual functions used in the\n/// generic dependence graph build algorithm.\n///\n/// For information about time complexity of the build algorithm see the\n/// comments near the declaration of AbstractDependenceGraphBuilder.\nclass DDGBuilder : public AbstractDependenceGraphBuilder<DataDependenceGraph> {\npublic:\n  DDGBuilder(DataDependenceGraph &G, DependenceInfo &D,\n             const BasicBlockListType &BBs)\n      : AbstractDependenceGraphBuilder(G, D, BBs) {}\n  DDGNode &createRootNode() final override {\n    auto *RN = new RootDDGNode();\n    assert(RN && \"Failed to allocate memory for DDG root node.\");\n    Graph.addNode(*RN);\n    return *RN;\n  }\n  DDGNode &createFineGrainedNode(Instruction &I) final override {\n    auto *SN = new SimpleDDGNode(I);\n    assert(SN && \"Failed to allocate memory for simple DDG node.\");\n    Graph.addNode(*SN);\n    return *SN;\n  }\n  DDGNode &createPiBlock(const NodeListType &L) final override {\n    auto *Pi = new PiBlockDDGNode(L);\n    assert(Pi && \"Failed to allocate memory for pi-block node.\");\n    Graph.addNode(*Pi);\n    return *Pi;\n  }\n  DDGEdge &createDefUseEdge(DDGNode &Src, DDGNode &Tgt) final override {\n    auto *E = new DDGEdge(Tgt, DDGEdge::EdgeKind::RegisterDefUse);\n    assert(E && \"Failed to allocate memory for edge\");\n    Graph.connect(Src, Tgt, *E);\n    return *E;\n  }\n  DDGEdge &createMemoryEdge(DDGNode &Src, DDGNode &Tgt) final override {\n    auto *E = new DDGEdge(Tgt, DDGEdge::EdgeKind::MemoryDependence);\n    assert(E && \"Failed to allocate memory for edge\");\n    Graph.connect(Src, Tgt, *E);\n    return *E;\n  }\n  DDGEdge &createRootedEdge(DDGNode &Src, DDGNode &Tgt) final override {\n    auto *E = new DDGEdge(Tgt, DDGEdge::EdgeKind::Rooted);\n    assert(E && \"Failed to allocate memory for edge\");\n    assert(isa<RootDDGNode>(Src) && \"Expected root node\");\n    Graph.connect(Src, Tgt, *E);\n    return *E;\n  }\n\n  const NodeListType &getNodesInPiBlock(const DDGNode &N) final override {\n    auto *PiNode = dyn_cast<const PiBlockDDGNode>(&N);\n    assert(PiNode && \"Expected a pi-block node.\");\n    return PiNode->getNodes();\n  }\n\n  /// Return true if the two nodes \\pSrc and \\pTgt are both simple nodes and\n  /// the consecutive instructions after merging belong to the same basic block.\n  bool areNodesMergeable(const DDGNode &Src,\n                         const DDGNode &Tgt) const final override;\n  void mergeNodes(DDGNode &Src, DDGNode &Tgt) final override;\n  bool shouldSimplify() const final override;\n  bool shouldCreatePiBlocks() const final override;\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const DDGNode &N);\nraw_ostream &operator<<(raw_ostream &OS, const DDGNode::NodeKind K);\nraw_ostream &operator<<(raw_ostream &OS, const DDGEdge &E);\nraw_ostream &operator<<(raw_ostream &OS, const DDGEdge::EdgeKind K);\nraw_ostream &operator<<(raw_ostream &OS, const DataDependenceGraph &G);\n\n//===--------------------------------------------------------------------===//\n// DDG Analysis Passes\n//===--------------------------------------------------------------------===//\n\n/// Analysis pass that builds the DDG for a loop.\nclass DDGAnalysis : public AnalysisInfoMixin<DDGAnalysis> {\npublic:\n  using Result = std::unique_ptr<DataDependenceGraph>;\n  Result run(Loop &L, LoopAnalysisManager &AM, LoopStandardAnalysisResults &AR);\n\nprivate:\n  friend AnalysisInfoMixin<DDGAnalysis>;\n  static AnalysisKey Key;\n};\n\n/// Textual printer pass for the DDG of a loop.\nclass DDGAnalysisPrinterPass : public PassInfoMixin<DDGAnalysisPrinterPass> {\npublic:\n  explicit DDGAnalysisPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n\nprivate:\n  raw_ostream &OS;\n};\n\n//===--------------------------------------------------------------------===//\n// DependenceGraphInfo Implementation\n//===--------------------------------------------------------------------===//\n\ntemplate <typename NodeType>\nbool DependenceGraphInfo<NodeType>::getDependencies(\n    const NodeType &Src, const NodeType &Dst, DependenceList &Deps) const {\n  assert(Deps.empty() && \"Expected empty output list at the start.\");\n\n  // List of memory access instructions from src and dst nodes.\n  SmallVector<Instruction *, 8> SrcIList, DstIList;\n  auto isMemoryAccess = [](const Instruction *I) {\n    return I->mayReadOrWriteMemory();\n  };\n  Src.collectInstructions(isMemoryAccess, SrcIList);\n  Dst.collectInstructions(isMemoryAccess, DstIList);\n\n  for (auto *SrcI : SrcIList)\n    for (auto *DstI : DstIList)\n      if (auto Dep =\n              const_cast<DependenceInfo *>(&DI)->depends(SrcI, DstI, true))\n        Deps.push_back(std::move(Dep));\n\n  return !Deps.empty();\n}\n\ntemplate <typename NodeType>\nstd::string\nDependenceGraphInfo<NodeType>::getDependenceString(const NodeType &Src,\n                                                   const NodeType &Dst) const {\n  std::string Str;\n  raw_string_ostream OS(Str);\n  DependenceList Deps;\n  if (!getDependencies(Src, Dst, Deps))\n    return OS.str();\n  interleaveComma(Deps, OS, [&](const std::unique_ptr<Dependence> &D) {\n    D->dump(OS);\n    // Remove the extra new-line character printed by the dump\n    // method\n    if (OS.str().back() == '\\n')\n      OS.str().pop_back();\n  });\n\n  return OS.str();\n}\n\n//===--------------------------------------------------------------------===//\n// GraphTraits specializations for the DDG\n//===--------------------------------------------------------------------===//\n\n/// non-const versions of the grapth trait specializations for DDG\ntemplate <> struct GraphTraits<DDGNode *> {\n  using NodeRef = DDGNode *;\n\n  static DDGNode *DDGGetTargetNode(DGEdge<DDGNode, DDGEdge> *P) {\n    return &P->getTargetNode();\n  }\n\n  // Provide a mapped iterator so that the GraphTrait-based implementations can\n  // find the target nodes without having to explicitly go through the edges.\n  using ChildIteratorType =\n      mapped_iterator<DDGNode::iterator, decltype(&DDGGetTargetNode)>;\n  using ChildEdgeIteratorType = DDGNode::iterator;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) {\n    return ChildIteratorType(N->begin(), &DDGGetTargetNode);\n  }\n  static ChildIteratorType child_end(NodeRef N) {\n    return ChildIteratorType(N->end(), &DDGGetTargetNode);\n  }\n\n  static ChildEdgeIteratorType child_edge_begin(NodeRef N) {\n    return N->begin();\n  }\n  static ChildEdgeIteratorType child_edge_end(NodeRef N) { return N->end(); }\n};\n\ntemplate <>\nstruct GraphTraits<DataDependenceGraph *> : public GraphTraits<DDGNode *> {\n  using nodes_iterator = DataDependenceGraph::iterator;\n  static NodeRef getEntryNode(DataDependenceGraph *DG) {\n    return &DG->getRoot();\n  }\n  static nodes_iterator nodes_begin(DataDependenceGraph *DG) {\n    return DG->begin();\n  }\n  static nodes_iterator nodes_end(DataDependenceGraph *DG) { return DG->end(); }\n};\n\n/// const versions of the grapth trait specializations for DDG\ntemplate <> struct GraphTraits<const DDGNode *> {\n  using NodeRef = const DDGNode *;\n\n  static const DDGNode *DDGGetTargetNode(const DGEdge<DDGNode, DDGEdge> *P) {\n    return &P->getTargetNode();\n  }\n\n  // Provide a mapped iterator so that the GraphTrait-based implementations can\n  // find the target nodes without having to explicitly go through the edges.\n  using ChildIteratorType =\n      mapped_iterator<DDGNode::const_iterator, decltype(&DDGGetTargetNode)>;\n  using ChildEdgeIteratorType = DDGNode::const_iterator;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) {\n    return ChildIteratorType(N->begin(), &DDGGetTargetNode);\n  }\n  static ChildIteratorType child_end(NodeRef N) {\n    return ChildIteratorType(N->end(), &DDGGetTargetNode);\n  }\n\n  static ChildEdgeIteratorType child_edge_begin(NodeRef N) {\n    return N->begin();\n  }\n  static ChildEdgeIteratorType child_edge_end(NodeRef N) { return N->end(); }\n};\n\ntemplate <>\nstruct GraphTraits<const DataDependenceGraph *>\n    : public GraphTraits<const DDGNode *> {\n  using nodes_iterator = DataDependenceGraph::const_iterator;\n  static NodeRef getEntryNode(const DataDependenceGraph *DG) {\n    return &DG->getRoot();\n  }\n  static nodes_iterator nodes_begin(const DataDependenceGraph *DG) {\n    return DG->begin();\n  }\n  static nodes_iterator nodes_end(const DataDependenceGraph *DG) {\n    return DG->end();\n  }\n};\n\n} // namespace llvm\n\n#endif // LLVM_ANALYSIS_DDG_H\n"}, "32": {"id": 32, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DDGPrinter.h", "content": "//===- llvm/Analysis/DDGPrinter.h -------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n//===----------------------------------------------------------------------===//\n//\n// This file defines the DOT printer for the Data-Dependence Graph (DDG).\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_DDGPRINTER_H\n#define LLVM_ANALYSIS_DDGPRINTER_H\n\n#include \"llvm/Analysis/DDG.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/DOTGraphTraits.h\"\n\nnamespace llvm {\n\n//===--------------------------------------------------------------------===//\n// Implementation of DDG DOT Printer for a loop.\n//===--------------------------------------------------------------------===//\nclass DDGDotPrinterPass : public PassInfoMixin<DDGDotPrinterPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n//===--------------------------------------------------------------------===//\n// Specialization of DOTGraphTraits.\n//===--------------------------------------------------------------------===//\ntemplate <>\nstruct DOTGraphTraits<const DataDependenceGraph *>\n    : public DefaultDOTGraphTraits {\n\n  DOTGraphTraits(bool IsSimple = false) : DefaultDOTGraphTraits(IsSimple) {}\n\n  /// Generate a title for the graph in DOT format\n  std::string getGraphName(const DataDependenceGraph *G) {\n    assert(G && \"expected a valid pointer to the graph.\");\n    return \"DDG for '\" + std::string(G->getName()) + \"'\";\n  }\n\n  /// Print a DDG node either in concise form (-ddg-dot-only) or\n  /// verbose mode (-ddg-dot).\n  std::string getNodeLabel(const DDGNode *Node,\n                           const DataDependenceGraph *Graph);\n\n  /// Print attributes of an edge in the DDG graph. If the edge\n  /// is a MemoryDependence edge, then detailed dependence info\n  /// available from DependenceAnalysis is displayed.\n  std::string\n  getEdgeAttributes(const DDGNode *Node,\n                    GraphTraits<const DDGNode *>::ChildIteratorType I,\n                    const DataDependenceGraph *G);\n\n  /// Do not print nodes that are part of a pi-block separately. They\n  /// will be printed when their containing pi-block is being printed.\n  bool isNodeHidden(const DDGNode *Node, const DataDependenceGraph *G);\n\nprivate:\n  /// Print a DDG node in concise form.\n  static std::string getSimpleNodeLabel(const DDGNode *Node,\n                                        const DataDependenceGraph *G);\n\n  /// Print a DDG node with more information including containing instructions\n  /// and detailed information about the dependence edges.\n  static std::string getVerboseNodeLabel(const DDGNode *Node,\n                                         const DataDependenceGraph *G);\n\n  /// Print a DDG edge in concise form.\n  static std::string getSimpleEdgeAttributes(const DDGNode *Src,\n                                             const DDGEdge *Edge,\n                                             const DataDependenceGraph *G);\n\n  /// Print a DDG edge with more information including detailed information\n  /// about the dependence edges.\n  static std::string getVerboseEdgeAttributes(const DDGNode *Src,\n                                              const DDGEdge *Edge,\n                                              const DataDependenceGraph *G);\n};\n\nusing DDGDotGraphTraits = DOTGraphTraits<const DataDependenceGraph *>;\n\n} // namespace llvm\n\n#endif // LLVM_ANALYSIS_DDGPRINTER_H\n"}, "33": {"id": 33, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DemandedBits.h", "content": "//===- llvm/Analysis/DemandedBits.h - Determine demanded bits ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass implements a demanded bits analysis. A demanded bit is one that\n// contributes to a result; bits that are not demanded can be either zero or\n// one without affecting control or data flow. For example in this sequence:\n//\n//   %1 = add i32 %x, %y\n//   %2 = trunc i32 %1 to i16\n//\n// Only the lowest 16 bits of %1 are demanded; the rest are removed by the\n// trunc.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_DEMANDEDBITS_H\n#define LLVM_ANALYSIS_DEMANDEDBITS_H\n\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass DominatorTree;\nclass Function;\nclass Instruction;\nstruct KnownBits;\nclass raw_ostream;\n\nclass DemandedBits {\npublic:\n  DemandedBits(Function &F, AssumptionCache &AC, DominatorTree &DT) :\n    F(F), AC(AC), DT(DT) {}\n\n  /// Return the bits demanded from instruction I.\n  ///\n  /// For vector instructions individual vector elements are not distinguished:\n  /// A bit is demanded if it is demanded for any of the vector elements. The\n  /// size of the return value corresponds to the type size in bits of the\n  /// scalar type.\n  ///\n  /// Instructions that do not have integer or vector of integer type are\n  /// accepted, but will always produce a mask with all bits set.\n  APInt getDemandedBits(Instruction *I);\n\n  /// Return true if, during analysis, I could not be reached.\n  bool isInstructionDead(Instruction *I);\n\n  /// Return whether this use is dead by means of not having any demanded bits.\n  bool isUseDead(Use *U);\n\n  void print(raw_ostream &OS);\n\n  /// Compute alive bits of one addition operand from alive output and known\n  /// operand bits\n  static APInt determineLiveOperandBitsAdd(unsigned OperandNo,\n                                           const APInt &AOut,\n                                           const KnownBits &LHS,\n                                           const KnownBits &RHS);\n\n  /// Compute alive bits of one subtraction operand from alive output and known\n  /// operand bits\n  static APInt determineLiveOperandBitsSub(unsigned OperandNo,\n                                           const APInt &AOut,\n                                           const KnownBits &LHS,\n                                           const KnownBits &RHS);\n\nprivate:\n  void performAnalysis();\n  void determineLiveOperandBits(const Instruction *UserI,\n    const Value *Val, unsigned OperandNo,\n    const APInt &AOut, APInt &AB,\n    KnownBits &Known, KnownBits &Known2, bool &KnownBitsComputed);\n\n  Function &F;\n  AssumptionCache &AC;\n  DominatorTree &DT;\n\n  bool Analyzed = false;\n\n  // The set of visited instructions (non-integer-typed only).\n  SmallPtrSet<Instruction*, 32> Visited;\n  DenseMap<Instruction *, APInt> AliveBits;\n  // Uses with no demanded bits. If the user also has no demanded bits, the use\n  // might not be stored explicitly in this map, to save memory during analysis.\n  SmallPtrSet<Use *, 16> DeadUses;\n};\n\nclass DemandedBitsWrapperPass : public FunctionPass {\nprivate:\n  mutable Optional<DemandedBits> DB;\n\npublic:\n  static char ID; // Pass identification, replacement for typeid\n\n  DemandedBitsWrapperPass();\n\n  bool runOnFunction(Function &F) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  /// Clean up memory in between runs\n  void releaseMemory() override;\n\n  DemandedBits &getDemandedBits() { return *DB; }\n\n  void print(raw_ostream &OS, const Module *M) const override;\n};\n\n/// An analysis that produces \\c DemandedBits for a function.\nclass DemandedBitsAnalysis : public AnalysisInfoMixin<DemandedBitsAnalysis> {\n  friend AnalysisInfoMixin<DemandedBitsAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result type for this analysis pass.\n  using Result = DemandedBits;\n\n  /// Run the analysis pass over a function and produce demanded bits\n  /// information.\n  DemandedBits run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for DemandedBits\nclass DemandedBitsPrinterPass : public PassInfoMixin<DemandedBitsPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit DemandedBitsPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Create a demanded bits analysis pass.\nFunctionPass *createDemandedBitsWrapperPass();\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_DEMANDEDBITS_H\n"}, "34": {"id": 34, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DependenceAnalysis.h", "content": "//===-- llvm/Analysis/DependenceAnalysis.h -------------------- -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// DependenceAnalysis is an LLVM pass that analyses dependences between memory\n// accesses. Currently, it is an implementation of the approach described in\n//\n//            Practical Dependence Testing\n//            Goff, Kennedy, Tseng\n//            PLDI 1991\n//\n// There's a single entry point that analyzes the dependence between a pair\n// of memory references in a function, returning either NULL, for no dependence,\n// or a more-or-less detailed description of the dependence between them.\n//\n// This pass exists to support the DependenceGraph pass. There are two separate\n// passes because there's a useful separation of concerns. A dependence exists\n// if two conditions are met:\n//\n//    1) Two instructions reference the same memory location, and\n//    2) There is a flow of control leading from one instruction to the other.\n//\n// DependenceAnalysis attacks the first condition; DependenceGraph will attack\n// the second (it's not yet ready).\n//\n// Please note that this is work in progress and the interface is subject to\n// change.\n//\n// Plausible changes:\n//    Return a set of more precise dependences instead of just one dependence\n//    summarizing all.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_DEPENDENCEANALYSIS_H\n#define LLVM_ANALYSIS_DEPENDENCEANALYSIS_H\n\n#include \"llvm/ADT/SmallBitVector.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n  class AAResults;\n  template <typename T> class ArrayRef;\n  class Loop;\n  class LoopInfo;\n  class ScalarEvolution;\n  class SCEV;\n  class SCEVConstant;\n  class raw_ostream;\n\n  /// Dependence - This class represents a dependence between two memory\n  /// memory references in a function. It contains minimal information and\n  /// is used in the very common situation where the compiler is unable to\n  /// determine anything beyond the existence of a dependence; that is, it\n  /// represents a confused dependence (see also FullDependence). In most\n  /// cases (for output, flow, and anti dependences), the dependence implies\n  /// an ordering, where the source must precede the destination; in contrast,\n  /// input dependences are unordered.\n  ///\n  /// When a dependence graph is built, each Dependence will be a member of\n  /// the set of predecessor edges for its destination instruction and a set\n  /// if successor edges for its source instruction. These sets are represented\n  /// as singly-linked lists, with the \"next\" fields stored in the dependence\n  /// itelf.\n  class Dependence {\n  protected:\n    Dependence(Dependence &&) = default;\n    Dependence &operator=(Dependence &&) = default;\n\n  public:\n    Dependence(Instruction *Source,\n               Instruction *Destination) :\n      Src(Source),\n      Dst(Destination),\n      NextPredecessor(nullptr),\n      NextSuccessor(nullptr) {}\n    virtual ~Dependence() {}\n\n    /// Dependence::DVEntry - Each level in the distance/direction vector\n    /// has a direction (or perhaps a union of several directions), and\n    /// perhaps a distance.\n    struct DVEntry {\n      enum { NONE = 0,\n             LT = 1,\n             EQ = 2,\n             LE = 3,\n             GT = 4,\n             NE = 5,\n             GE = 6,\n             ALL = 7 };\n      unsigned char Direction : 3; // Init to ALL, then refine.\n      bool Scalar    : 1; // Init to true.\n      bool PeelFirst : 1; // Peeling the first iteration will break dependence.\n      bool PeelLast  : 1; // Peeling the last iteration will break the dependence.\n      bool Splitable : 1; // Splitting the loop will break dependence.\n      const SCEV *Distance; // NULL implies no distance available.\n      DVEntry() : Direction(ALL), Scalar(true), PeelFirst(false),\n                  PeelLast(false), Splitable(false), Distance(nullptr) { }\n    };\n\n    /// getSrc - Returns the source instruction for this dependence.\n    ///\n    Instruction *getSrc() const { return Src; }\n\n    /// getDst - Returns the destination instruction for this dependence.\n    ///\n    Instruction *getDst() const { return Dst; }\n\n    /// isInput - Returns true if this is an input dependence.\n    ///\n    bool isInput() const;\n\n    /// isOutput - Returns true if this is an output dependence.\n    ///\n    bool isOutput() const;\n\n    /// isFlow - Returns true if this is a flow (aka true) dependence.\n    ///\n    bool isFlow() const;\n\n    /// isAnti - Returns true if this is an anti dependence.\n    ///\n    bool isAnti() const;\n\n    /// isOrdered - Returns true if dependence is Output, Flow, or Anti\n    ///\n    bool isOrdered() const { return isOutput() || isFlow() || isAnti(); }\n\n    /// isUnordered - Returns true if dependence is Input\n    ///\n    bool isUnordered() const { return isInput(); }\n\n    /// isLoopIndependent - Returns true if this is a loop-independent\n    /// dependence.\n    virtual bool isLoopIndependent() const { return true; }\n\n    /// isConfused - Returns true if this dependence is confused\n    /// (the compiler understands nothing and makes worst-case\n    /// assumptions).\n    virtual bool isConfused() const { return true; }\n\n    /// isConsistent - Returns true if this dependence is consistent\n    /// (occurs every time the source and destination are executed).\n    virtual bool isConsistent() const { return false; }\n\n    /// getLevels - Returns the number of common loops surrounding the\n    /// source and destination of the dependence.\n    virtual unsigned getLevels() const { return 0; }\n\n    /// getDirection - Returns the direction associated with a particular\n    /// level.\n    virtual unsigned getDirection(unsigned Level) const { return DVEntry::ALL; }\n\n    /// getDistance - Returns the distance (or NULL) associated with a\n    /// particular level.\n    virtual const SCEV *getDistance(unsigned Level) const { return nullptr; }\n\n    /// isPeelFirst - Returns true if peeling the first iteration from\n    /// this loop will break this dependence.\n    virtual bool isPeelFirst(unsigned Level) const { return false; }\n\n    /// isPeelLast - Returns true if peeling the last iteration from\n    /// this loop will break this dependence.\n    virtual bool isPeelLast(unsigned Level) const { return false; }\n\n    /// isSplitable - Returns true if splitting this loop will break\n    /// the dependence.\n    virtual bool isSplitable(unsigned Level) const { return false; }\n\n    /// isScalar - Returns true if a particular level is scalar; that is,\n    /// if no subscript in the source or destination mention the induction\n    /// variable associated with the loop at this level.\n    virtual bool isScalar(unsigned Level) const;\n\n    /// getNextPredecessor - Returns the value of the NextPredecessor\n    /// field.\n    const Dependence *getNextPredecessor() const { return NextPredecessor; }\n\n    /// getNextSuccessor - Returns the value of the NextSuccessor\n    /// field.\n    const Dependence *getNextSuccessor() const { return NextSuccessor; }\n\n    /// setNextPredecessor - Sets the value of the NextPredecessor\n    /// field.\n    void setNextPredecessor(const Dependence *pred) { NextPredecessor = pred; }\n\n    /// setNextSuccessor - Sets the value of the NextSuccessor\n    /// field.\n    void setNextSuccessor(const Dependence *succ) { NextSuccessor = succ; }\n\n    /// dump - For debugging purposes, dumps a dependence to OS.\n    ///\n    void dump(raw_ostream &OS) const;\n\n  private:\n    Instruction *Src, *Dst;\n    const Dependence *NextPredecessor, *NextSuccessor;\n    friend class DependenceInfo;\n  };\n\n  /// FullDependence - This class represents a dependence between two memory\n  /// references in a function. It contains detailed information about the\n  /// dependence (direction vectors, etc.) and is used when the compiler is\n  /// able to accurately analyze the interaction of the references; that is,\n  /// it is not a confused dependence (see Dependence). In most cases\n  /// (for output, flow, and anti dependences), the dependence implies an\n  /// ordering, where the source must precede the destination; in contrast,\n  /// input dependences are unordered.\n  class FullDependence final : public Dependence {\n  public:\n    FullDependence(Instruction *Src, Instruction *Dst, bool LoopIndependent,\n                   unsigned Levels);\n\n    /// isLoopIndependent - Returns true if this is a loop-independent\n    /// dependence.\n    bool isLoopIndependent() const override { return LoopIndependent; }\n\n    /// isConfused - Returns true if this dependence is confused\n    /// (the compiler understands nothing and makes worst-case\n    /// assumptions).\n    bool isConfused() const override { return false; }\n\n    /// isConsistent - Returns true if this dependence is consistent\n    /// (occurs every time the source and destination are executed).\n    bool isConsistent() const override { return Consistent; }\n\n    /// getLevels - Returns the number of common loops surrounding the\n    /// source and destination of the dependence.\n    unsigned getLevels() const override { return Levels; }\n\n    /// getDirection - Returns the direction associated with a particular\n    /// level.\n    unsigned getDirection(unsigned Level) const override;\n\n    /// getDistance - Returns the distance (or NULL) associated with a\n    /// particular level.\n    const SCEV *getDistance(unsigned Level) const override;\n\n    /// isPeelFirst - Returns true if peeling the first iteration from\n    /// this loop will break this dependence.\n    bool isPeelFirst(unsigned Level) const override;\n\n    /// isPeelLast - Returns true if peeling the last iteration from\n    /// this loop will break this dependence.\n    bool isPeelLast(unsigned Level) const override;\n\n    /// isSplitable - Returns true if splitting the loop will break\n    /// the dependence.\n    bool isSplitable(unsigned Level) const override;\n\n    /// isScalar - Returns true if a particular level is scalar; that is,\n    /// if no subscript in the source or destination mention the induction\n    /// variable associated with the loop at this level.\n    bool isScalar(unsigned Level) const override;\n\n  private:\n    unsigned short Levels;\n    bool LoopIndependent;\n    bool Consistent; // Init to true, then refine.\n    std::unique_ptr<DVEntry[]> DV;\n    friend class DependenceInfo;\n  };\n\n  /// DependenceInfo - This class is the main dependence-analysis driver.\n  ///\n  class DependenceInfo {\n  public:\n    DependenceInfo(Function *F, AAResults *AA, ScalarEvolution *SE,\n                   LoopInfo *LI)\n        : AA(AA), SE(SE), LI(LI), F(F) {}\n\n    /// Handle transitive invalidation when the cached analysis results go away.\n    bool invalidate(Function &F, const PreservedAnalyses &PA,\n                    FunctionAnalysisManager::Invalidator &Inv);\n\n    /// depends - Tests for a dependence between the Src and Dst instructions.\n    /// Returns NULL if no dependence; otherwise, returns a Dependence (or a\n    /// FullDependence) with as much information as can be gleaned.\n    /// The flag PossiblyLoopIndependent should be set by the caller\n    /// if it appears that control flow can reach from Src to Dst\n    /// without traversing a loop back edge.\n    std::unique_ptr<Dependence> depends(Instruction *Src,\n                                        Instruction *Dst,\n                                        bool PossiblyLoopIndependent);\n\n    /// getSplitIteration - Give a dependence that's splittable at some\n    /// particular level, return the iteration that should be used to split\n    /// the loop.\n    ///\n    /// Generally, the dependence analyzer will be used to build\n    /// a dependence graph for a function (basically a map from instructions\n    /// to dependences). Looking for cycles in the graph shows us loops\n    /// that cannot be trivially vectorized/parallelized.\n    ///\n    /// We can try to improve the situation by examining all the dependences\n    /// that make up the cycle, looking for ones we can break.\n    /// Sometimes, peeling the first or last iteration of a loop will break\n    /// dependences, and there are flags for those possibilities.\n    /// Sometimes, splitting a loop at some other iteration will do the trick,\n    /// and we've got a flag for that case. Rather than waste the space to\n    /// record the exact iteration (since we rarely know), we provide\n    /// a method that calculates the iteration. It's a drag that it must work\n    /// from scratch, but wonderful in that it's possible.\n    ///\n    /// Here's an example:\n    ///\n    ///    for (i = 0; i < 10; i++)\n    ///        A[i] = ...\n    ///        ... = A[11 - i]\n    ///\n    /// There's a loop-carried flow dependence from the store to the load,\n    /// found by the weak-crossing SIV test. The dependence will have a flag,\n    /// indicating that the dependence can be broken by splitting the loop.\n    /// Calling getSplitIteration will return 5.\n    /// Splitting the loop breaks the dependence, like so:\n    ///\n    ///    for (i = 0; i <= 5; i++)\n    ///        A[i] = ...\n    ///        ... = A[11 - i]\n    ///    for (i = 6; i < 10; i++)\n    ///        A[i] = ...\n    ///        ... = A[11 - i]\n    ///\n    /// breaks the dependence and allows us to vectorize/parallelize\n    /// both loops.\n    const SCEV *getSplitIteration(const Dependence &Dep, unsigned Level);\n\n    Function *getFunction() const { return F; }\n\n  private:\n    AAResults *AA;\n    ScalarEvolution *SE;\n    LoopInfo *LI;\n    Function *F;\n\n    /// Subscript - This private struct represents a pair of subscripts from\n    /// a pair of potentially multi-dimensional array references. We use a\n    /// vector of them to guide subscript partitioning.\n    struct Subscript {\n      const SCEV *Src;\n      const SCEV *Dst;\n      enum ClassificationKind { ZIV, SIV, RDIV, MIV, NonLinear } Classification;\n      SmallBitVector Loops;\n      SmallBitVector GroupLoops;\n      SmallBitVector Group;\n    };\n\n    struct CoefficientInfo {\n      const SCEV *Coeff;\n      const SCEV *PosPart;\n      const SCEV *NegPart;\n      const SCEV *Iterations;\n    };\n\n    struct BoundInfo {\n      const SCEV *Iterations;\n      const SCEV *Upper[8];\n      const SCEV *Lower[8];\n      unsigned char Direction;\n      unsigned char DirSet;\n    };\n\n    /// Constraint - This private class represents a constraint, as defined\n    /// in the paper\n    ///\n    ///           Practical Dependence Testing\n    ///           Goff, Kennedy, Tseng\n    ///           PLDI 1991\n    ///\n    /// There are 5 kinds of constraint, in a hierarchy.\n    ///   1) Any - indicates no constraint, any dependence is possible.\n    ///   2) Line - A line ax + by = c, where a, b, and c are parameters,\n    ///             representing the dependence equation.\n    ///   3) Distance - The value d of the dependence distance;\n    ///   4) Point - A point <x, y> representing the dependence from\n    ///              iteration x to iteration y.\n    ///   5) Empty - No dependence is possible.\n    class Constraint {\n    private:\n      enum ConstraintKind { Empty, Point, Distance, Line, Any } Kind;\n      ScalarEvolution *SE;\n      const SCEV *A;\n      const SCEV *B;\n      const SCEV *C;\n      const Loop *AssociatedLoop;\n\n    public:\n      /// isEmpty - Return true if the constraint is of kind Empty.\n      bool isEmpty() const { return Kind == Empty; }\n\n      /// isPoint - Return true if the constraint is of kind Point.\n      bool isPoint() const { return Kind == Point; }\n\n      /// isDistance - Return true if the constraint is of kind Distance.\n      bool isDistance() const { return Kind == Distance; }\n\n      /// isLine - Return true if the constraint is of kind Line.\n      /// Since Distance's can also be represented as Lines, we also return\n      /// true if the constraint is of kind Distance.\n      bool isLine() const { return Kind == Line || Kind == Distance; }\n\n      /// isAny - Return true if the constraint is of kind Any;\n      bool isAny() const { return Kind == Any; }\n\n      /// getX - If constraint is a point <X, Y>, returns X.\n      /// Otherwise assert.\n      const SCEV *getX() const;\n\n      /// getY - If constraint is a point <X, Y>, returns Y.\n      /// Otherwise assert.\n      const SCEV *getY() const;\n\n      /// getA - If constraint is a line AX + BY = C, returns A.\n      /// Otherwise assert.\n      const SCEV *getA() const;\n\n      /// getB - If constraint is a line AX + BY = C, returns B.\n      /// Otherwise assert.\n      const SCEV *getB() const;\n\n      /// getC - If constraint is a line AX + BY = C, returns C.\n      /// Otherwise assert.\n      const SCEV *getC() const;\n\n      /// getD - If constraint is a distance, returns D.\n      /// Otherwise assert.\n      const SCEV *getD() const;\n\n      /// getAssociatedLoop - Returns the loop associated with this constraint.\n      const Loop *getAssociatedLoop() const;\n\n      /// setPoint - Change a constraint to Point.\n      void setPoint(const SCEV *X, const SCEV *Y, const Loop *CurrentLoop);\n\n      /// setLine - Change a constraint to Line.\n      void setLine(const SCEV *A, const SCEV *B,\n                   const SCEV *C, const Loop *CurrentLoop);\n\n      /// setDistance - Change a constraint to Distance.\n      void setDistance(const SCEV *D, const Loop *CurrentLoop);\n\n      /// setEmpty - Change a constraint to Empty.\n      void setEmpty();\n\n      /// setAny - Change a constraint to Any.\n      void setAny(ScalarEvolution *SE);\n\n      /// dump - For debugging purposes. Dumps the constraint\n      /// out to OS.\n      void dump(raw_ostream &OS) const;\n    };\n\n    /// establishNestingLevels - Examines the loop nesting of the Src and Dst\n    /// instructions and establishes their shared loops. Sets the variables\n    /// CommonLevels, SrcLevels, and MaxLevels.\n    /// The source and destination instructions needn't be contained in the same\n    /// loop. The routine establishNestingLevels finds the level of most deeply\n    /// nested loop that contains them both, CommonLevels. An instruction that's\n    /// not contained in a loop is at level = 0. MaxLevels is equal to the level\n    /// of the source plus the level of the destination, minus CommonLevels.\n    /// This lets us allocate vectors MaxLevels in length, with room for every\n    /// distinct loop referenced in both the source and destination subscripts.\n    /// The variable SrcLevels is the nesting depth of the source instruction.\n    /// It's used to help calculate distinct loops referenced by the destination.\n    /// Here's the map from loops to levels:\n    ///            0 - unused\n    ///            1 - outermost common loop\n    ///          ... - other common loops\n    /// CommonLevels - innermost common loop\n    ///          ... - loops containing Src but not Dst\n    ///    SrcLevels - innermost loop containing Src but not Dst\n    ///          ... - loops containing Dst but not Src\n    ///    MaxLevels - innermost loop containing Dst but not Src\n    /// Consider the follow code fragment:\n    ///    for (a = ...) {\n    ///      for (b = ...) {\n    ///        for (c = ...) {\n    ///          for (d = ...) {\n    ///            A[] = ...;\n    ///          }\n    ///        }\n    ///        for (e = ...) {\n    ///          for (f = ...) {\n    ///            for (g = ...) {\n    ///              ... = A[];\n    ///            }\n    ///          }\n    ///        }\n    ///      }\n    ///    }\n    /// If we're looking at the possibility of a dependence between the store\n    /// to A (the Src) and the load from A (the Dst), we'll note that they\n    /// have 2 loops in common, so CommonLevels will equal 2 and the direction\n    /// vector for Result will have 2 entries. SrcLevels = 4 and MaxLevels = 7.\n    /// A map from loop names to level indices would look like\n    ///     a - 1\n    ///     b - 2 = CommonLevels\n    ///     c - 3\n    ///     d - 4 = SrcLevels\n    ///     e - 5\n    ///     f - 6\n    ///     g - 7 = MaxLevels\n    void establishNestingLevels(const Instruction *Src,\n                                const Instruction *Dst);\n\n    unsigned CommonLevels, SrcLevels, MaxLevels;\n\n    /// mapSrcLoop - Given one of the loops containing the source, return\n    /// its level index in our numbering scheme.\n    unsigned mapSrcLoop(const Loop *SrcLoop) const;\n\n    /// mapDstLoop - Given one of the loops containing the destination,\n    /// return its level index in our numbering scheme.\n    unsigned mapDstLoop(const Loop *DstLoop) const;\n\n    /// isLoopInvariant - Returns true if Expression is loop invariant\n    /// in LoopNest.\n    bool isLoopInvariant(const SCEV *Expression, const Loop *LoopNest) const;\n\n    /// Makes sure all subscript pairs share the same integer type by\n    /// sign-extending as necessary.\n    /// Sign-extending a subscript is safe because getelementptr assumes the\n    /// array subscripts are signed.\n    void unifySubscriptType(ArrayRef<Subscript *> Pairs);\n\n    /// removeMatchingExtensions - Examines a subscript pair.\n    /// If the source and destination are identically sign (or zero)\n    /// extended, it strips off the extension in an effort to\n    /// simplify the actual analysis.\n    void removeMatchingExtensions(Subscript *Pair);\n\n    /// collectCommonLoops - Finds the set of loops from the LoopNest that\n    /// have a level <= CommonLevels and are referred to by the SCEV Expression.\n    void collectCommonLoops(const SCEV *Expression,\n                            const Loop *LoopNest,\n                            SmallBitVector &Loops) const;\n\n    /// checkSrcSubscript - Examines the SCEV Src, returning true iff it's\n    /// linear. Collect the set of loops mentioned by Src.\n    bool checkSrcSubscript(const SCEV *Src,\n                           const Loop *LoopNest,\n                           SmallBitVector &Loops);\n\n    /// checkDstSubscript - Examines the SCEV Dst, returning true iff it's\n    /// linear. Collect the set of loops mentioned by Dst.\n    bool checkDstSubscript(const SCEV *Dst,\n                           const Loop *LoopNest,\n                           SmallBitVector &Loops);\n\n    /// isKnownPredicate - Compare X and Y using the predicate Pred.\n    /// Basically a wrapper for SCEV::isKnownPredicate,\n    /// but tries harder, especially in the presence of sign and zero\n    /// extensions and symbolics.\n    bool isKnownPredicate(ICmpInst::Predicate Pred,\n                          const SCEV *X,\n                          const SCEV *Y) const;\n\n    /// isKnownLessThan - Compare to see if S is less than Size\n    /// Another wrapper for isKnownNegative(S - max(Size, 1)) with some extra\n    /// checking if S is an AddRec and we can prove lessthan using the loop\n    /// bounds.\n    bool isKnownLessThan(const SCEV *S, const SCEV *Size) const;\n\n    /// isKnownNonNegative - Compare to see if S is known not to be negative\n    /// Uses the fact that S comes from Ptr, which may be an inbound GEP,\n    /// Proving there is no wrapping going on.\n    bool isKnownNonNegative(const SCEV *S, const Value *Ptr) const;\n\n    /// collectUpperBound - All subscripts are the same type (on my machine,\n    /// an i64). The loop bound may be a smaller type. collectUpperBound\n    /// find the bound, if available, and zero extends it to the Type T.\n    /// (I zero extend since the bound should always be >= 0.)\n    /// If no upper bound is available, return NULL.\n    const SCEV *collectUpperBound(const Loop *l, Type *T) const;\n\n    /// collectConstantUpperBound - Calls collectUpperBound(), then\n    /// attempts to cast it to SCEVConstant. If the cast fails,\n    /// returns NULL.\n    const SCEVConstant *collectConstantUpperBound(const Loop *l, Type *T) const;\n\n    /// classifyPair - Examines the subscript pair (the Src and Dst SCEVs)\n    /// and classifies it as either ZIV, SIV, RDIV, MIV, or Nonlinear.\n    /// Collects the associated loops in a set.\n    Subscript::ClassificationKind classifyPair(const SCEV *Src,\n                                           const Loop *SrcLoopNest,\n                                           const SCEV *Dst,\n                                           const Loop *DstLoopNest,\n                                           SmallBitVector &Loops);\n\n    /// testZIV - Tests the ZIV subscript pair (Src and Dst) for dependence.\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// If the dependence isn't proven to exist,\n    /// marks the Result as inconsistent.\n    bool testZIV(const SCEV *Src,\n                 const SCEV *Dst,\n                 FullDependence &Result) const;\n\n    /// testSIV - Tests the SIV subscript pair (Src and Dst) for dependence.\n    /// Things of the form [c1 + a1*i] and [c2 + a2*j], where\n    /// i and j are induction variables, c1 and c2 are loop invariant,\n    /// and a1 and a2 are constant.\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Sets appropriate direction vector entry and, when possible,\n    /// the distance vector entry.\n    /// If the dependence isn't proven to exist,\n    /// marks the Result as inconsistent.\n    bool testSIV(const SCEV *Src,\n                 const SCEV *Dst,\n                 unsigned &Level,\n                 FullDependence &Result,\n                 Constraint &NewConstraint,\n                 const SCEV *&SplitIter) const;\n\n    /// testRDIV - Tests the RDIV subscript pair (Src and Dst) for dependence.\n    /// Things of the form [c1 + a1*i] and [c2 + a2*j]\n    /// where i and j are induction variables, c1 and c2 are loop invariant,\n    /// and a1 and a2 are constant.\n    /// With minor algebra, this test can also be used for things like\n    /// [c1 + a1*i + a2*j][c2].\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Marks the Result as inconsistent.\n    bool testRDIV(const SCEV *Src,\n                  const SCEV *Dst,\n                  FullDependence &Result) const;\n\n    /// testMIV - Tests the MIV subscript pair (Src and Dst) for dependence.\n    /// Returns true if dependence disproved.\n    /// Can sometimes refine direction vectors.\n    bool testMIV(const SCEV *Src,\n                 const SCEV *Dst,\n                 const SmallBitVector &Loops,\n                 FullDependence &Result) const;\n\n    /// strongSIVtest - Tests the strong SIV subscript pair (Src and Dst)\n    /// for dependence.\n    /// Things of the form [c1 + a*i] and [c2 + a*i],\n    /// where i is an induction variable, c1 and c2 are loop invariant,\n    /// and a is a constant\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Sets appropriate direction and distance.\n    bool strongSIVtest(const SCEV *Coeff,\n                       const SCEV *SrcConst,\n                       const SCEV *DstConst,\n                       const Loop *CurrentLoop,\n                       unsigned Level,\n                       FullDependence &Result,\n                       Constraint &NewConstraint) const;\n\n    /// weakCrossingSIVtest - Tests the weak-crossing SIV subscript pair\n    /// (Src and Dst) for dependence.\n    /// Things of the form [c1 + a*i] and [c2 - a*i],\n    /// where i is an induction variable, c1 and c2 are loop invariant,\n    /// and a is a constant.\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Sets appropriate direction entry.\n    /// Set consistent to false.\n    /// Marks the dependence as splitable.\n    bool weakCrossingSIVtest(const SCEV *SrcCoeff,\n                             const SCEV *SrcConst,\n                             const SCEV *DstConst,\n                             const Loop *CurrentLoop,\n                             unsigned Level,\n                             FullDependence &Result,\n                             Constraint &NewConstraint,\n                             const SCEV *&SplitIter) const;\n\n    /// ExactSIVtest - Tests the SIV subscript pair\n    /// (Src and Dst) for dependence.\n    /// Things of the form [c1 + a1*i] and [c2 + a2*i],\n    /// where i is an induction variable, c1 and c2 are loop invariant,\n    /// and a1 and a2 are constant.\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Sets appropriate direction entry.\n    /// Set consistent to false.\n    bool exactSIVtest(const SCEV *SrcCoeff,\n                      const SCEV *DstCoeff,\n                      const SCEV *SrcConst,\n                      const SCEV *DstConst,\n                      const Loop *CurrentLoop,\n                      unsigned Level,\n                      FullDependence &Result,\n                      Constraint &NewConstraint) const;\n\n    /// weakZeroSrcSIVtest - Tests the weak-zero SIV subscript pair\n    /// (Src and Dst) for dependence.\n    /// Things of the form [c1] and [c2 + a*i],\n    /// where i is an induction variable, c1 and c2 are loop invariant,\n    /// and a is a constant. See also weakZeroDstSIVtest.\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Sets appropriate direction entry.\n    /// Set consistent to false.\n    /// If loop peeling will break the dependence, mark appropriately.\n    bool weakZeroSrcSIVtest(const SCEV *DstCoeff,\n                            const SCEV *SrcConst,\n                            const SCEV *DstConst,\n                            const Loop *CurrentLoop,\n                            unsigned Level,\n                            FullDependence &Result,\n                            Constraint &NewConstraint) const;\n\n    /// weakZeroDstSIVtest - Tests the weak-zero SIV subscript pair\n    /// (Src and Dst) for dependence.\n    /// Things of the form [c1 + a*i] and [c2],\n    /// where i is an induction variable, c1 and c2 are loop invariant,\n    /// and a is a constant. See also weakZeroSrcSIVtest.\n    /// Returns true if any possible dependence is disproved.\n    /// If there might be a dependence, returns false.\n    /// Sets appropriate direction entry.\n    /// Set consistent to false.\n    /// If loop peeling will break the dependence, mark appropriately.\n    bool weakZeroDstSIVtest(const SCEV *SrcCoeff,\n                            const SCEV *SrcConst,\n                            const SCEV *DstConst,\n                            const Loop *CurrentLoop,\n                            unsigned Level,\n                            FullDependence &Result,\n                            Constraint &NewConstraint) const;\n\n    /// exactRDIVtest - Tests the RDIV subscript pair for dependence.\n    /// Things of the form [c1 + a*i] and [c2 + b*j],\n    /// where i and j are induction variable, c1 and c2 are loop invariant,\n    /// and a and b are constants.\n    /// Returns true if any possible dependence is disproved.\n    /// Marks the result as inconsistent.\n    /// Works in some cases that symbolicRDIVtest doesn't,\n    /// and vice versa.\n    bool exactRDIVtest(const SCEV *SrcCoeff,\n                       const SCEV *DstCoeff,\n                       const SCEV *SrcConst,\n                       const SCEV *DstConst,\n                       const Loop *SrcLoop,\n                       const Loop *DstLoop,\n                       FullDependence &Result) const;\n\n    /// symbolicRDIVtest - Tests the RDIV subscript pair for dependence.\n    /// Things of the form [c1 + a*i] and [c2 + b*j],\n    /// where i and j are induction variable, c1 and c2 are loop invariant,\n    /// and a and b are constants.\n    /// Returns true if any possible dependence is disproved.\n    /// Marks the result as inconsistent.\n    /// Works in some cases that exactRDIVtest doesn't,\n    /// and vice versa. Can also be used as a backup for\n    /// ordinary SIV tests.\n    bool symbolicRDIVtest(const SCEV *SrcCoeff,\n                          const SCEV *DstCoeff,\n                          const SCEV *SrcConst,\n                          const SCEV *DstConst,\n                          const Loop *SrcLoop,\n                          const Loop *DstLoop) const;\n\n    /// gcdMIVtest - Tests an MIV subscript pair for dependence.\n    /// Returns true if any possible dependence is disproved.\n    /// Marks the result as inconsistent.\n    /// Can sometimes disprove the equal direction for 1 or more loops.\n    //  Can handle some symbolics that even the SIV tests don't get,\n    /// so we use it as a backup for everything.\n    bool gcdMIVtest(const SCEV *Src,\n                    const SCEV *Dst,\n                    FullDependence &Result) const;\n\n    /// banerjeeMIVtest - Tests an MIV subscript pair for dependence.\n    /// Returns true if any possible dependence is disproved.\n    /// Marks the result as inconsistent.\n    /// Computes directions.\n    bool banerjeeMIVtest(const SCEV *Src,\n                         const SCEV *Dst,\n                         const SmallBitVector &Loops,\n                         FullDependence &Result) const;\n\n    /// collectCoefficientInfo - Walks through the subscript,\n    /// collecting each coefficient, the associated loop bounds,\n    /// and recording its positive and negative parts for later use.\n    CoefficientInfo *collectCoeffInfo(const SCEV *Subscript,\n                                      bool SrcFlag,\n                                      const SCEV *&Constant) const;\n\n    /// getPositivePart - X^+ = max(X, 0).\n    ///\n    const SCEV *getPositivePart(const SCEV *X) const;\n\n    /// getNegativePart - X^- = min(X, 0).\n    ///\n    const SCEV *getNegativePart(const SCEV *X) const;\n\n    /// getLowerBound - Looks through all the bounds info and\n    /// computes the lower bound given the current direction settings\n    /// at each level.\n    const SCEV *getLowerBound(BoundInfo *Bound) const;\n\n    /// getUpperBound - Looks through all the bounds info and\n    /// computes the upper bound given the current direction settings\n    /// at each level.\n    const SCEV *getUpperBound(BoundInfo *Bound) const;\n\n    /// exploreDirections - Hierarchically expands the direction vector\n    /// search space, combining the directions of discovered dependences\n    /// in the DirSet field of Bound. Returns the number of distinct\n    /// dependences discovered. If the dependence is disproved,\n    /// it will return 0.\n    unsigned exploreDirections(unsigned Level,\n                               CoefficientInfo *A,\n                               CoefficientInfo *B,\n                               BoundInfo *Bound,\n                               const SmallBitVector &Loops,\n                               unsigned &DepthExpanded,\n                               const SCEV *Delta) const;\n\n    /// testBounds - Returns true iff the current bounds are plausible.\n    bool testBounds(unsigned char DirKind,\n                    unsigned Level,\n                    BoundInfo *Bound,\n                    const SCEV *Delta) const;\n\n    /// findBoundsALL - Computes the upper and lower bounds for level K\n    /// using the * direction. Records them in Bound.\n    void findBoundsALL(CoefficientInfo *A,\n                       CoefficientInfo *B,\n                       BoundInfo *Bound,\n                       unsigned K) const;\n\n    /// findBoundsLT - Computes the upper and lower bounds for level K\n    /// using the < direction. Records them in Bound.\n    void findBoundsLT(CoefficientInfo *A,\n                      CoefficientInfo *B,\n                      BoundInfo *Bound,\n                      unsigned K) const;\n\n    /// findBoundsGT - Computes the upper and lower bounds for level K\n    /// using the > direction. Records them in Bound.\n    void findBoundsGT(CoefficientInfo *A,\n                      CoefficientInfo *B,\n                      BoundInfo *Bound,\n                      unsigned K) const;\n\n    /// findBoundsEQ - Computes the upper and lower bounds for level K\n    /// using the = direction. Records them in Bound.\n    void findBoundsEQ(CoefficientInfo *A,\n                      CoefficientInfo *B,\n                      BoundInfo *Bound,\n                      unsigned K) const;\n\n    /// intersectConstraints - Updates X with the intersection\n    /// of the Constraints X and Y. Returns true if X has changed.\n    bool intersectConstraints(Constraint *X,\n                              const Constraint *Y);\n\n    /// propagate - Review the constraints, looking for opportunities\n    /// to simplify a subscript pair (Src and Dst).\n    /// Return true if some simplification occurs.\n    /// If the simplification isn't exact (that is, if it is conservative\n    /// in terms of dependence), set consistent to false.\n    bool propagate(const SCEV *&Src,\n                   const SCEV *&Dst,\n                   SmallBitVector &Loops,\n                   SmallVectorImpl<Constraint> &Constraints,\n                   bool &Consistent);\n\n    /// propagateDistance - Attempt to propagate a distance\n    /// constraint into a subscript pair (Src and Dst).\n    /// Return true if some simplification occurs.\n    /// If the simplification isn't exact (that is, if it is conservative\n    /// in terms of dependence), set consistent to false.\n    bool propagateDistance(const SCEV *&Src,\n                           const SCEV *&Dst,\n                           Constraint &CurConstraint,\n                           bool &Consistent);\n\n    /// propagatePoint - Attempt to propagate a point\n    /// constraint into a subscript pair (Src and Dst).\n    /// Return true if some simplification occurs.\n    bool propagatePoint(const SCEV *&Src,\n                        const SCEV *&Dst,\n                        Constraint &CurConstraint);\n\n    /// propagateLine - Attempt to propagate a line\n    /// constraint into a subscript pair (Src and Dst).\n    /// Return true if some simplification occurs.\n    /// If the simplification isn't exact (that is, if it is conservative\n    /// in terms of dependence), set consistent to false.\n    bool propagateLine(const SCEV *&Src,\n                       const SCEV *&Dst,\n                       Constraint &CurConstraint,\n                       bool &Consistent);\n\n    /// findCoefficient - Given a linear SCEV,\n    /// return the coefficient corresponding to specified loop.\n    /// If there isn't one, return the SCEV constant 0.\n    /// For example, given a*i + b*j + c*k, returning the coefficient\n    /// corresponding to the j loop would yield b.\n    const SCEV *findCoefficient(const SCEV *Expr,\n                                const Loop *TargetLoop) const;\n\n    /// zeroCoefficient - Given a linear SCEV,\n    /// return the SCEV given by zeroing out the coefficient\n    /// corresponding to the specified loop.\n    /// For example, given a*i + b*j + c*k, zeroing the coefficient\n    /// corresponding to the j loop would yield a*i + c*k.\n    const SCEV *zeroCoefficient(const SCEV *Expr,\n                                const Loop *TargetLoop) const;\n\n    /// addToCoefficient - Given a linear SCEV Expr,\n    /// return the SCEV given by adding some Value to the\n    /// coefficient corresponding to the specified TargetLoop.\n    /// For example, given a*i + b*j + c*k, adding 1 to the coefficient\n    /// corresponding to the j loop would yield a*i + (b+1)*j + c*k.\n    const SCEV *addToCoefficient(const SCEV *Expr,\n                                 const Loop *TargetLoop,\n                                 const SCEV *Value)  const;\n\n    /// updateDirection - Update direction vector entry\n    /// based on the current constraint.\n    void updateDirection(Dependence::DVEntry &Level,\n                         const Constraint &CurConstraint) const;\n\n    /// Given a linear access function, tries to recover subscripts\n    /// for each dimension of the array element access.\n    bool tryDelinearize(Instruction *Src, Instruction *Dst,\n                        SmallVectorImpl<Subscript> &Pair);\n\n    /// Tries to delinearize access function for a fixed size multi-dimensional\n    /// array, by deriving subscripts from GEP instructions. Returns true upon\n    /// success and false otherwise.\n    bool tryDelinearizeFixedSize(Instruction *Src, Instruction *Dst,\n                                 const SCEV *SrcAccessFn,\n                                 const SCEV *DstAccessFn,\n                                 SmallVectorImpl<const SCEV *> &SrcSubscripts,\n                                 SmallVectorImpl<const SCEV *> &DstSubscripts);\n\n    /// Tries to delinearize access function for a multi-dimensional array with\n    /// symbolic runtime sizes.\n    /// Returns true upon success and false otherwise.\n    bool tryDelinearizeParametricSize(\n        Instruction *Src, Instruction *Dst, const SCEV *SrcAccessFn,\n        const SCEV *DstAccessFn, SmallVectorImpl<const SCEV *> &SrcSubscripts,\n        SmallVectorImpl<const SCEV *> &DstSubscripts);\n\n    /// checkSubscript - Helper function for checkSrcSubscript and\n    /// checkDstSubscript to avoid duplicate code\n    bool checkSubscript(const SCEV *Expr, const Loop *LoopNest,\n                        SmallBitVector &Loops, bool IsSrc);\n  }; // class DependenceInfo\n\n  /// AnalysisPass to compute dependence information in a function\n  class DependenceAnalysis : public AnalysisInfoMixin<DependenceAnalysis> {\n  public:\n    typedef DependenceInfo Result;\n    Result run(Function &F, FunctionAnalysisManager &FAM);\n\n  private:\n    static AnalysisKey Key;\n    friend struct AnalysisInfoMixin<DependenceAnalysis>;\n  }; // class DependenceAnalysis\n\n  /// Printer pass to dump DA results.\n  struct DependenceAnalysisPrinterPass\n      : public PassInfoMixin<DependenceAnalysisPrinterPass> {\n    DependenceAnalysisPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n    PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n\n  private:\n    raw_ostream &OS;\n  }; // class DependenceAnalysisPrinterPass\n\n  /// Legacy pass manager pass to access dependence information\n  class DependenceAnalysisWrapperPass : public FunctionPass {\n  public:\n    static char ID; // Class identification, replacement for typeinfo\n    DependenceAnalysisWrapperPass();\n\n    bool runOnFunction(Function &F) override;\n    void releaseMemory() override;\n    void getAnalysisUsage(AnalysisUsage &) const override;\n    void print(raw_ostream &, const Module * = nullptr) const override;\n    DependenceInfo &getDI() const;\n\n  private:\n    std::unique_ptr<DependenceInfo> info;\n  }; // class DependenceAnalysisWrapperPass\n\n  /// createDependenceAnalysisPass - This creates an instance of the\n  /// DependenceAnalysis wrapper pass.\n  FunctionPass *createDependenceAnalysisWrapperPass();\n\n} // namespace llvm\n\n#endif\n"}, "35": {"id": 35, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DivergenceAnalysis.h", "content": "//===- llvm/Analysis/DivergenceAnalysis.h - Divergence Analysis -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// The divergence analysis determines which instructions and branches are\n// divergent given a set of divergent source instructions.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_DIVERGENCEANALYSIS_H\n#define LLVM_ANALYSIS_DIVERGENCEANALYSIS_H\n\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/Analysis/SyncDependenceAnalysis.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/Pass.h\"\n#include <vector>\n\nnamespace llvm {\nclass Module;\nclass Value;\nclass Instruction;\nclass Loop;\nclass raw_ostream;\nclass TargetTransformInfo;\n\n/// \\brief Generic divergence analysis for reducible CFGs.\n///\n/// This analysis propagates divergence in a data-parallel context from sources\n/// of divergence to all users. It requires reducible CFGs. All assignments\n/// should be in SSA form.\nclass DivergenceAnalysisImpl {\npublic:\n  /// \\brief This instance will analyze the whole function \\p F or the loop \\p\n  /// RegionLoop.\n  ///\n  /// \\param RegionLoop if non-null the analysis is restricted to \\p RegionLoop.\n  /// Otherwise the whole function is analyzed.\n  /// \\param IsLCSSAForm whether the analysis may assume that the IR in the\n  /// region in in LCSSA form.\n  DivergenceAnalysisImpl(const Function &F, const Loop *RegionLoop,\n                         const DominatorTree &DT, const LoopInfo &LI,\n                         SyncDependenceAnalysis &SDA, bool IsLCSSAForm);\n\n  /// \\brief The loop that defines the analyzed region (if any).\n  const Loop *getRegionLoop() const { return RegionLoop; }\n  const Function &getFunction() const { return F; }\n\n  /// \\brief Whether \\p BB is part of the region.\n  bool inRegion(const BasicBlock &BB) const;\n  /// \\brief Whether \\p I is part of the region.\n  bool inRegion(const Instruction &I) const;\n\n  /// \\brief Mark \\p UniVal as a value that is always uniform.\n  void addUniformOverride(const Value &UniVal);\n\n  /// \\brief Mark \\p DivVal as a value that is always divergent. Will not do so\n  /// if `isAlwaysUniform(DivVal)`.\n  /// \\returns Whether the tracked divergence state of \\p DivVal changed.\n  bool markDivergent(const Value &DivVal);\n\n  /// \\brief Propagate divergence to all instructions in the region.\n  /// Divergence is seeded by calls to \\p markDivergent.\n  void compute();\n\n  /// \\brief Whether any value was marked or analyzed to be divergent.\n  bool hasDetectedDivergence() const { return !DivergentValues.empty(); }\n\n  /// \\brief Whether \\p Val will always return a uniform value regardless of its\n  /// operands\n  bool isAlwaysUniform(const Value &Val) const;\n\n  /// \\brief Whether \\p Val is divergent at its definition.\n  bool isDivergent(const Value &Val) const;\n\n  /// \\brief Whether \\p U is divergent. Uses of a uniform value can be\n  /// divergent.\n  bool isDivergentUse(const Use &U) const;\n\nprivate:\n  /// \\brief Mark \\p Term as divergent and push all Instructions that become\n  /// divergent as a result on the worklist.\n  void analyzeControlDivergence(const Instruction &Term);\n  /// \\brief Mark all phi nodes in \\p JoinBlock as divergent and push them on\n  /// the worklist.\n  void taintAndPushPhiNodes(const BasicBlock &JoinBlock);\n\n  /// \\brief Identify all Instructions that become divergent because \\p DivExit\n  /// is a divergent loop exit of \\p DivLoop. Mark those instructions as\n  /// divergent and push them on the worklist.\n  void propagateLoopExitDivergence(const BasicBlock &DivExit,\n                                   const Loop &DivLoop);\n\n  /// \\brief Internal implementation function for propagateLoopExitDivergence.\n  void analyzeLoopExitDivergence(const BasicBlock &DivExit,\n                                 const Loop &OuterDivLoop);\n\n  /// \\brief Mark all instruction as divergent that use a value defined in \\p\n  /// OuterDivLoop. Push their users on the worklist.\n  void analyzeTemporalDivergence(const Instruction &I,\n                                 const Loop &OuterDivLoop);\n\n  /// \\brief Push all users of \\p Val (in the region) to the worklist.\n  void pushUsers(const Value &I);\n\n  /// \\brief Whether \\p Val is divergent when read in \\p ObservingBlock.\n  bool isTemporalDivergent(const BasicBlock &ObservingBlock,\n                           const Value &Val) const;\n\n  /// \\brief Whether \\p Block is join divergent\n  ///\n  /// (see markBlockJoinDivergent).\n  bool isJoinDivergent(const BasicBlock &Block) const {\n    return DivergentJoinBlocks.contains(&Block);\n  }\n\nprivate:\n  const Function &F;\n  // If regionLoop != nullptr, analysis is only performed within \\p RegionLoop.\n  // Otherwise, analyze the whole function\n  const Loop *RegionLoop;\n\n  const DominatorTree &DT;\n  const LoopInfo &LI;\n\n  // Recognized divergent loops\n  DenseSet<const Loop *> DivergentLoops;\n\n  // The SDA links divergent branches to divergent control-flow joins.\n  SyncDependenceAnalysis &SDA;\n\n  // Use simplified code path for LCSSA form.\n  bool IsLCSSAForm;\n\n  // Set of known-uniform values.\n  DenseSet<const Value *> UniformOverrides;\n\n  // Blocks with joining divergent control from different predecessors.\n  DenseSet<const BasicBlock *> DivergentJoinBlocks; // FIXME Deprecated\n\n  // Detected/marked divergent values.\n  DenseSet<const Value *> DivergentValues;\n\n  // Internal worklist for divergence propagation.\n  std::vector<const Instruction *> Worklist;\n};\n\nclass DivergenceInfo {\n  Function &F;\n\n  // If the function contains an irreducible region the divergence\n  // analysis can run indefinitely. We set ContainsIrreducible and no\n  // analysis is actually performed on the function. All values in\n  // this function are conservatively reported as divergent instead.\n  bool ContainsIrreducible;\n  std::unique_ptr<SyncDependenceAnalysis> SDA;\n  std::unique_ptr<DivergenceAnalysisImpl> DA;\n\npublic:\n  DivergenceInfo(Function &F, const DominatorTree &DT,\n                 const PostDominatorTree &PDT, const LoopInfo &LI,\n                 const TargetTransformInfo &TTI, bool KnownReducible);\n\n  /// Whether any divergence was detected.\n  bool hasDivergence() const {\n    return ContainsIrreducible || DA->hasDetectedDivergence();\n  }\n\n  /// The GPU kernel this analysis result is for\n  const Function &getFunction() const { return F; }\n\n  /// Whether \\p V is divergent at its definition.\n  bool isDivergent(const Value &V) const {\n    return ContainsIrreducible || DA->isDivergent(V);\n  }\n\n  /// Whether \\p U is divergent. Uses of a uniform value can be divergent.\n  bool isDivergentUse(const Use &U) const {\n    return ContainsIrreducible || DA->isDivergentUse(U);\n  }\n\n  /// Whether \\p V is uniform/non-divergent.\n  bool isUniform(const Value &V) const { return !isDivergent(V); }\n\n  /// Whether \\p U is uniform/non-divergent. Uses of a uniform value can be\n  /// divergent.\n  bool isUniformUse(const Use &U) const { return !isDivergentUse(U); }\n};\n\n/// \\brief Divergence analysis frontend for GPU kernels.\nclass DivergenceAnalysis : public AnalysisInfoMixin<DivergenceAnalysis> {\n  friend AnalysisInfoMixin<DivergenceAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = DivergenceInfo;\n\n  /// Runs the divergence analysis on @F, a GPU kernel\n  Result run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass to dump divergence analysis results.\nstruct DivergenceAnalysisPrinterPass\n    : public PassInfoMixin<DivergenceAnalysisPrinterPass> {\n  DivergenceAnalysisPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n\nprivate:\n  raw_ostream &OS;\n}; // class DivergenceAnalysisPrinterPass\n\n} // namespace llvm\n\n#endif // LLVM_ANALYSIS_DIVERGENCEANALYSIS_H\n"}, "36": {"id": 36, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DominanceFrontier.h", "content": "//===- llvm/Analysis/DominanceFrontier.h - Dominator Frontiers --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the DominanceFrontier class, which calculate and holds the\n// dominance frontier for a function.\n//\n// This should be considered deprecated, don't add any more uses of this data\n// structure.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_DOMINANCEFRONTIER_H\n#define LLVM_ANALYSIS_DOMINANCEFRONTIER_H\n\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/Config/llvm-config.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/GenericDomTree.h\"\n#include <cassert>\n#include <map>\n#include <set>\n#include <utility>\n\nnamespace llvm {\n\nclass Function;\nclass raw_ostream;\n\n//===----------------------------------------------------------------------===//\n/// DominanceFrontierBase - Common base class for computing forward and inverse\n/// dominance frontiers for a function.\n///\ntemplate <class BlockT, bool IsPostDom>\nclass DominanceFrontierBase {\npublic:\n  using DomSetType = std::set<BlockT *>;                // Dom set for a bb\n  using DomSetMapType = std::map<BlockT *, DomSetType>; // Dom set map\n\nprotected:\n  using BlockTraits = GraphTraits<BlockT *>;\n\n  DomSetMapType Frontiers;\n  // Postdominators can have multiple roots.\n  SmallVector<BlockT *, IsPostDom ? 4 : 1> Roots;\n  static constexpr bool IsPostDominators = IsPostDom;\n\npublic:\n  DominanceFrontierBase() = default;\n\n  /// getRoots - Return the root blocks of the current CFG.  This may include\n  /// multiple blocks if we are computing post dominators.  For forward\n  /// dominators, this will always be a single block (the entry node).\n  const SmallVectorImpl<BlockT *> &getRoots() const { return Roots; }\n\n  BlockT *getRoot() const {\n    assert(Roots.size() == 1 && \"Should always have entry node!\");\n    return Roots[0];\n  }\n\n  /// isPostDominator - Returns true if analysis based of postdoms\n  bool isPostDominator() const {\n    return IsPostDominators;\n  }\n\n  void releaseMemory() {\n    Frontiers.clear();\n  }\n\n  // Accessor interface:\n  using iterator = typename DomSetMapType::iterator;\n  using const_iterator = typename DomSetMapType::const_iterator;\n\n  iterator begin() { return Frontiers.begin(); }\n  const_iterator begin() const { return Frontiers.begin(); }\n  iterator end() { return Frontiers.end(); }\n  const_iterator end() const { return Frontiers.end(); }\n  iterator find(BlockT *B) { return Frontiers.find(B); }\n  const_iterator find(BlockT *B) const { return Frontiers.find(B); }\n\n  iterator addBasicBlock(BlockT *BB, const DomSetType &frontier) {\n    assert(find(BB) == end() && \"Block already in DominanceFrontier!\");\n    return Frontiers.insert(std::make_pair(BB, frontier)).first;\n  }\n\n  /// removeBlock - Remove basic block BB's frontier.\n  void removeBlock(BlockT *BB);\n\n  void addToFrontier(iterator I, BlockT *Node);\n\n  void removeFromFrontier(iterator I, BlockT *Node);\n\n  /// compareDomSet - Return false if two domsets match. Otherwise\n  /// return true;\n  bool compareDomSet(DomSetType &DS1, const DomSetType &DS2) const;\n\n  /// compare - Return true if the other dominance frontier base matches\n  /// this dominance frontier base. Otherwise return false.\n  bool compare(DominanceFrontierBase &Other) const;\n\n  /// print - Convert to human readable form\n  ///\n  void print(raw_ostream &OS) const;\n\n  /// dump - Dump the dominance frontier to dbgs().\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  void dump() const;\n#endif\n};\n\n//===-------------------------------------\n/// DominanceFrontier Class - Concrete subclass of DominanceFrontierBase that is\n/// used to compute a forward dominator frontiers.\n///\ntemplate <class BlockT>\nclass ForwardDominanceFrontierBase\n    : public DominanceFrontierBase<BlockT, false> {\nprivate:\n  using BlockTraits = GraphTraits<BlockT *>;\n\npublic:\n  using DomTreeT = DomTreeBase<BlockT>;\n  using DomTreeNodeT = DomTreeNodeBase<BlockT>;\n  using DomSetType = typename DominanceFrontierBase<BlockT, false>::DomSetType;\n\n  void analyze(DomTreeT &DT) {\n    assert(DT.root_size() == 1 &&\n           \"Only one entry block for forward domfronts!\");\n    this->Roots = {DT.getRoot()};\n    calculate(DT, DT[this->Roots[0]]);\n  }\n\n  const DomSetType &calculate(const DomTreeT &DT, const DomTreeNodeT *Node);\n};\n\nclass DominanceFrontier : public ForwardDominanceFrontierBase<BasicBlock> {\npublic:\n  using DomTreeT = DomTreeBase<BasicBlock>;\n  using DomTreeNodeT = DomTreeNodeBase<BasicBlock>;\n  using DomSetType = DominanceFrontierBase<BasicBlock, false>::DomSetType;\n  using iterator = DominanceFrontierBase<BasicBlock, false>::iterator;\n  using const_iterator =\n      DominanceFrontierBase<BasicBlock, false>::const_iterator;\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n};\n\nclass DominanceFrontierWrapperPass : public FunctionPass {\n  DominanceFrontier DF;\n\npublic:\n  static char ID; // Pass ID, replacement for typeid\n\n  DominanceFrontierWrapperPass();\n\n  DominanceFrontier &getDominanceFrontier() { return DF; }\n  const DominanceFrontier &getDominanceFrontier() const { return DF;  }\n\n  void releaseMemory() override;\n\n  bool runOnFunction(Function &) override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  void print(raw_ostream &OS, const Module * = nullptr) const override;\n\n  void dump() const;\n};\n\nextern template class DominanceFrontierBase<BasicBlock, false>;\nextern template class DominanceFrontierBase<BasicBlock, true>;\nextern template class ForwardDominanceFrontierBase<BasicBlock>;\n\n/// Analysis pass which computes a \\c DominanceFrontier.\nclass DominanceFrontierAnalysis\n    : public AnalysisInfoMixin<DominanceFrontierAnalysis> {\n  friend AnalysisInfoMixin<DominanceFrontierAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result type for this analysis pass.\n  using Result = DominanceFrontier;\n\n  /// Run the analysis pass over a function and produce a dominator tree.\n  DominanceFrontier run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c DominanceFrontier.\nclass DominanceFrontierPrinterPass\n    : public PassInfoMixin<DominanceFrontierPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit DominanceFrontierPrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_DOMINANCEFRONTIER_H\n"}, "37": {"id": 37, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/FunctionPropertiesAnalysis.h", "content": "//=- FunctionPropertiesAnalysis.h - Function Properties Analysis --*- C++ -*-=//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the FunctionPropertiesInfo and FunctionPropertiesAnalysis\n// classes used to extract function properties.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_FUNCTIONPROPERTIESANALYSIS_H\n#define LLVM_ANALYSIS_FUNCTIONPROPERTIESANALYSIS_H\n\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass Function;\n\nclass FunctionPropertiesInfo {\npublic:\n  static FunctionPropertiesInfo getFunctionPropertiesInfo(const Function &F,\n                                                          const LoopInfo &LI);\n\n  void print(raw_ostream &OS) const;\n\n  /// Number of basic blocks\n  int64_t BasicBlockCount = 0;\n\n  /// Number of blocks reached from a conditional instruction, or that are\n  /// 'cases' of a SwitchInstr.\n  // FIXME: We may want to replace this with a more meaningful metric, like\n  // number of conditionally executed blocks:\n  // 'if (a) s();' would be counted here as 2 blocks, just like\n  // 'if (a) s(); else s2(); s3();' would.\n  int64_t BlocksReachedFromConditionalInstruction = 0;\n\n  /// Number of uses of this function, plus 1 if the function is callable\n  /// outside the module.\n  int64_t Uses = 0;\n\n  /// Number of direct calls made from this function to other functions\n  /// defined in this module.\n  int64_t DirectCallsToDefinedFunctions = 0;\n\n  // Load Instruction Count\n  int64_t LoadInstCount = 0;\n\n  // Store Instruction Count\n  int64_t StoreInstCount = 0;\n\n  // Maximum Loop Depth in the Function\n  int64_t MaxLoopDepth = 0;\n\n  // Number of Top Level Loops in the Function\n  int64_t TopLevelLoopCount = 0;\n};\n\n// Analysis pass\nclass FunctionPropertiesAnalysis\n    : public AnalysisInfoMixin<FunctionPropertiesAnalysis> {\n\npublic:\n  static AnalysisKey Key;\n\n  using Result = FunctionPropertiesInfo;\n\n  Result run(Function &F, FunctionAnalysisManager &FAM);\n};\n\n/// Printer pass for the FunctionPropertiesAnalysis results.\nclass FunctionPropertiesPrinterPass\n    : public PassInfoMixin<FunctionPropertiesPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit FunctionPropertiesPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // namespace llvm\n#endif // LLVM_ANALYSIS_FUNCTIONPROPERTIESANALYSIS_H\n"}, "38": {"id": 38, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/GlobalsModRef.h", "content": "//===- GlobalsModRef.h - Simple Mod/Ref AA for Globals ----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This is the interface for a simple mod/ref and alias analysis over globals.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_GLOBALSMODREF_H\n#define LLVM_ANALYSIS_GLOBALSMODREF_H\n\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n#include <list>\n\nnamespace llvm {\nclass CallGraph;\n\n/// An alias analysis result set for globals.\n///\n/// This focuses on handling aliasing properties of globals and interprocedural\n/// function call mod/ref information.\nclass GlobalsAAResult : public AAResultBase<GlobalsAAResult> {\n  friend AAResultBase<GlobalsAAResult>;\n\n  class FunctionInfo;\n\n  const DataLayout &DL;\n  std::function<const TargetLibraryInfo &(Function &F)> GetTLI;\n\n  /// The globals that do not have their addresses taken.\n  SmallPtrSet<const GlobalValue *, 8> NonAddressTakenGlobals;\n\n  /// Are there functions with local linkage that may modify globals.\n  bool UnknownFunctionsWithLocalLinkage = false;\n\n  /// IndirectGlobals - The memory pointed to by this global is known to be\n  /// 'owned' by the global.\n  SmallPtrSet<const GlobalValue *, 8> IndirectGlobals;\n\n  /// AllocsForIndirectGlobals - If an instruction allocates memory for an\n  /// indirect global, this map indicates which one.\n  DenseMap<const Value *, const GlobalValue *> AllocsForIndirectGlobals;\n\n  /// For each function, keep track of what globals are modified or read.\n  DenseMap<const Function *, FunctionInfo> FunctionInfos;\n\n  /// A map of functions to SCC. The SCCs are described by a simple integer\n  /// ID that is only useful for comparing for equality (are two functions\n  /// in the same SCC or not?)\n  DenseMap<const Function *, unsigned> FunctionToSCCMap;\n\n  /// Handle to clear this analysis on deletion of values.\n  struct DeletionCallbackHandle final : CallbackVH {\n    GlobalsAAResult *GAR;\n    std::list<DeletionCallbackHandle>::iterator I;\n\n    DeletionCallbackHandle(GlobalsAAResult &GAR, Value *V)\n        : CallbackVH(V), GAR(&GAR) {}\n\n    void deleted() override;\n  };\n\n  /// List of callbacks for globals being tracked by this analysis. Note that\n  /// these objects are quite large, but we only anticipate having one per\n  /// global tracked by this analysis. There are numerous optimizations we\n  /// could perform to the memory utilization here if this becomes a problem.\n  std::list<DeletionCallbackHandle> Handles;\n\n  explicit GlobalsAAResult(\n      const DataLayout &DL,\n      std::function<const TargetLibraryInfo &(Function &F)> GetTLI);\n\npublic:\n  GlobalsAAResult(GlobalsAAResult &&Arg);\n  ~GlobalsAAResult();\n\n  bool invalidate(Module &M, const PreservedAnalyses &PA,\n                  ModuleAnalysisManager::Invalidator &);\n\n  static GlobalsAAResult\n  analyzeModule(Module &M,\n                std::function<const TargetLibraryInfo &(Function &F)> GetTLI,\n                CallGraph &CG);\n\n  //------------------------------------------------\n  // Implement the AliasAnalysis API\n  //\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n\n  using AAResultBase::getModRefInfo;\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n\n  /// getModRefBehavior - Return the behavior of the specified function if\n  /// called from the specified call site.  The call site may be null in which\n  /// case the most generic behavior of this function should be returned.\n  FunctionModRefBehavior getModRefBehavior(const Function *F);\n\n  /// getModRefBehavior - Return the behavior of the specified function if\n  /// called from the specified call site.  The call site may be null in which\n  /// case the most generic behavior of this function should be returned.\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call);\n\nprivate:\n  FunctionInfo *getFunctionInfo(const Function *F);\n\n  void AnalyzeGlobals(Module &M);\n  void AnalyzeCallGraph(CallGraph &CG, Module &M);\n  bool AnalyzeUsesOfPointer(Value *V,\n                            SmallPtrSetImpl<Function *> *Readers = nullptr,\n                            SmallPtrSetImpl<Function *> *Writers = nullptr,\n                            GlobalValue *OkayStoreDest = nullptr);\n  bool AnalyzeIndirectGlobalMemory(GlobalVariable *GV);\n  void CollectSCCMembership(CallGraph &CG);\n\n  bool isNonEscapingGlobalNoAlias(const GlobalValue *GV, const Value *V);\n  ModRefInfo getModRefInfoForArgument(const CallBase *Call,\n                                      const GlobalValue *GV, AAQueryInfo &AAQI);\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\nclass GlobalsAA : public AnalysisInfoMixin<GlobalsAA> {\n  friend AnalysisInfoMixin<GlobalsAA>;\n  static AnalysisKey Key;\n\npublic:\n  typedef GlobalsAAResult Result;\n\n  GlobalsAAResult run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the GlobalsAAResult object.\nclass GlobalsAAWrapperPass : public ModulePass {\n  std::unique_ptr<GlobalsAAResult> Result;\n\npublic:\n  static char ID;\n\n  GlobalsAAWrapperPass();\n\n  GlobalsAAResult &getResult() { return *Result; }\n  const GlobalsAAResult &getResult() const { return *Result; }\n\n  bool runOnModule(Module &M) override;\n  bool doFinalization(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n//===--------------------------------------------------------------------===//\n//\n// createGlobalsAAWrapperPass - This pass provides alias and mod/ref info for\n// global values that do not have their addresses taken.\n//\nModulePass *createGlobalsAAWrapperPass();\n}\n\n#endif\n"}, "39": {"id": 39, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/IRSimilarityIdentifier.h", "content": "//===- IRSimilarityIdentifier.h - Find similarity in a module --------------==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// Interface file for the IRSimilarityIdentifier for identifying similarities in\n// IR including the IRInstructionMapper, which maps an Instruction to unsigned\n// integers.\n//\n// Two sequences of instructions are called \"similar\" if they perform the same\n// series of operations for all inputs.\n//\n// \\code\n// %1 = add i32 %a, 10\n// %2 = add i32 %a, %1\n// %3 = icmp slt icmp %1, %2\n// \\endcode\n//\n// and\n//\n// \\code\n// %1 = add i32 11, %a\n// %2 = sub i32 %a, %1\n// %3 = icmp sgt icmp %2, %1\n// \\endcode\n//\n// ultimately have the same result, even if the inputs, and structure are\n// slightly different.\n//\n// For instructions, we do not worry about operands that do not have fixed\n// semantic meaning to the program.  We consider the opcode that the instruction\n// has, the types, parameters, and extra information such as the function name,\n// or comparison predicate.  These are used to create a hash to map instructions\n// to integers to be used in similarity matching in sequences of instructions\n//\n// Terminology:\n// An IRSimilarityCandidate is a region of IRInstructionData (wrapped\n// Instructions), usually used to denote a region of similarity has been found.\n//\n// A SimilarityGroup is a set of IRSimilarityCandidates that are structurally\n// similar to one another.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_IRSIMILARITYIDENTIFIER_H\n#define LLVM_ANALYSIS_IRSIMILARITYIDENTIFIER_H\n\n#include \"llvm/IR/InstVisitor.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Allocator.h\"\n\nnamespace llvm {\nnamespace IRSimilarity {\n\nstruct IRInstructionDataList;\n\n/// This represents what is and is not supported when finding similarity in\n/// Instructions.\n///\n/// Legal Instructions are considered when looking at similarity between\n/// Instructions.\n///\n/// Illegal Instructions cannot be considered when looking for similarity\n/// between Instructions. They act as boundaries between similarity regions.\n///\n/// Invisible Instructions are skipped over during analysis.\n// TODO: Shared with MachineOutliner\nenum InstrType { Legal, Illegal, Invisible };\n\n/// This provides the utilities for hashing an Instruction to an unsigned\n/// integer. Two IRInstructionDatas produce the same hash value when their\n/// underlying Instructions perform the same operation (even if they don't have\n/// the same input operands.)\n/// As a more concrete example, consider the following:\n///\n/// \\code\n/// %add1 = add i32 %a, %b\n/// %add2 = add i32 %c, %d\n/// %add3 = add i64 %e, %f\n/// \\endcode\n///\n// Then the IRInstructionData wrappers for these Instructions may be hashed like\n/// so:\n///\n/// \\code\n/// ; These two adds have the same types and operand types, so they hash to the\n/// ; same number.\n/// %add1 = add i32 %a, %b ; Hash: 1\n/// %add2 = add i32 %c, %d ; Hash: 1\n/// ; This add produces an i64. This differentiates it from %add1 and %add2. So,\n/// ; it hashes to a different number.\n/// %add3 = add i64 %e, %f; Hash: 2\n/// \\endcode\n///\n///\n/// This hashing scheme will be used to represent the program as a very long\n/// string. This string can then be placed in a data structure which can be used\n/// for similarity queries.\n///\n/// TODO: Handle types of Instructions which can be equal even with different\n/// operands. (E.g. comparisons with swapped predicates.)\n/// TODO: Handle CallInsts, which are only checked for function type\n/// by \\ref isSameOperationAs.\n/// TODO: Handle GetElementPtrInsts, as some of the operands have to be the\n/// exact same, and some do not.\nstruct IRInstructionData : ilist_node<IRInstructionData> {\n\n  /// The source Instruction that is being wrapped.\n  Instruction *Inst = nullptr;\n  /// The values of the operands in the Instruction.\n  SmallVector<Value *, 4> OperVals;\n  /// The legality of the wrapped instruction. This is informed by InstrType,\n  /// and is used when checking when two instructions are considered similar.\n  /// If either instruction is not legal, the instructions are automatically not\n  /// considered similar.\n  bool Legal;\n\n  /// This is only relevant if we are wrapping a CmpInst where we needed to\n  /// change the predicate of a compare instruction from a greater than form\n  /// to a less than form.  It is None otherwise.\n  Optional<CmpInst::Predicate> RevisedPredicate;\n\n  /// Gather the information that is difficult to gather for an Instruction, or\n  /// is changed. i.e. the operands of an Instruction and the Types of those\n  /// operands. This extra information allows for similarity matching to make\n  /// assertions that allow for more flexibility when checking for whether an\n  /// Instruction performs the same operation.\n  IRInstructionData(Instruction &I, bool Legality, IRInstructionDataList &IDL);\n\n  /// Get the predicate that the compare instruction is using for hashing the\n  /// instruction. the IRInstructionData must be wrapping a CmpInst.\n  CmpInst::Predicate getPredicate() const;\n\n  /// A function that swaps the predicates to their less than form if they are\n  /// in a greater than form. Otherwise, the predicate is unchanged.\n  ///\n  /// \\param CI - The comparison operation to find a consistent preidcate for.\n  /// \\return the consistent comparison predicate. \n  static CmpInst::Predicate predicateForConsistency(CmpInst *CI);\n\n  /// Hashes \\p Value based on its opcode, types, and operand types.\n  /// Two IRInstructionData instances produce the same hash when they perform\n  /// the same operation.\n  ///\n  /// As a simple example, consider the following instructions.\n  ///\n  /// \\code\n  /// %add1 = add i32 %x1, %y1\n  /// %add2 = add i32 %x2, %y2\n  ///\n  /// %sub = sub i32 %x1, %y1\n  ///\n  /// %add_i64 = add i64 %x2, %y2\n  /// \\endcode\n  ///\n  /// Because the first two adds operate the same types, and are performing the\n  /// same action, they will be hashed to the same value.\n  ///\n  /// However, the subtraction instruction is not the same as an addition, and\n  /// will be hashed to a different value.\n  ///\n  /// Finally, the last add has a different type compared to the first two add\n  /// instructions, so it will also be hashed to a different value that any of\n  /// the previous instructions.\n  ///\n  /// \\param [in] ID - The IRInstructionData instance to be hashed.\n  /// \\returns A hash_value of the IRInstructionData.\n  friend hash_code hash_value(const IRInstructionData &ID) {\n    SmallVector<Type *, 4> OperTypes;\n    for (Value *V : ID.OperVals)\n      OperTypes.push_back(V->getType());\n\n    if (isa<CmpInst>(ID.Inst))\n      return llvm::hash_combine(\n          llvm::hash_value(ID.Inst->getOpcode()),\n          llvm::hash_value(ID.Inst->getType()),\n          llvm::hash_value(ID.getPredicate()),\n          llvm::hash_combine_range(OperTypes.begin(), OperTypes.end()));\n    else if (CallInst *CI = dyn_cast<CallInst>(ID.Inst))\n      return llvm::hash_combine(\n          llvm::hash_value(ID.Inst->getOpcode()),\n          llvm::hash_value(ID.Inst->getType()),\n          llvm::hash_value(CI->getCalledFunction()->getName().str()),\n          llvm::hash_combine_range(OperTypes.begin(), OperTypes.end()));\n    return llvm::hash_combine(\n        llvm::hash_value(ID.Inst->getOpcode()),\n        llvm::hash_value(ID.Inst->getType()),\n        llvm::hash_combine_range(OperTypes.begin(), OperTypes.end()));\n  }\n\n  IRInstructionDataList *IDL = nullptr;\n};\n\nstruct IRInstructionDataList : simple_ilist<IRInstructionData> {};\n\n/// Compare one IRInstructionData class to another IRInstructionData class for\n/// whether they are performing a the same operation, and can mapped to the\n/// same value. For regular instructions if the hash value is the same, then\n/// they will also be close.\n///\n/// \\param A - The first IRInstructionData class to compare\n/// \\param B - The second IRInstructionData class to compare\n/// \\returns true if \\p A and \\p B are similar enough to be mapped to the same\n/// value.\nbool isClose(const IRInstructionData &A, const IRInstructionData &B);\n\nstruct IRInstructionDataTraits : DenseMapInfo<IRInstructionData *> {\n  static inline IRInstructionData *getEmptyKey() { return nullptr; }\n  static inline IRInstructionData *getTombstoneKey() {\n    return reinterpret_cast<IRInstructionData *>(-1);\n  }\n\n  static unsigned getHashValue(const IRInstructionData *E) {\n    using llvm::hash_value;\n    assert(E && \"IRInstructionData is a nullptr?\");\n    return hash_value(*E);\n  }\n\n  static bool isEqual(const IRInstructionData *LHS,\n                      const IRInstructionData *RHS) {\n    if (RHS == getEmptyKey() || RHS == getTombstoneKey() ||\n        LHS == getEmptyKey() || LHS == getTombstoneKey())\n      return LHS == RHS;\n\n    assert(LHS && RHS && \"nullptr should have been caught by getEmptyKey?\");\n    return isClose(*LHS, *RHS);\n  }\n};\n\n/// Helper struct for converting the Instructions in a Module into a vector of\n/// unsigned integers. This vector of unsigned integers can be thought of as a\n/// \"numeric string\". This numeric string can then be queried by, for example,\n/// data structures that find repeated substrings.\n///\n/// This hashing is done per BasicBlock in the module. To hash Instructions\n/// based off of their operations, each Instruction is wrapped in an\n/// IRInstructionData struct. The unsigned integer for an IRInstructionData\n/// depends on:\n/// - The hash provided by the IRInstructionData.\n/// - Which member of InstrType the IRInstructionData is classified as.\n// See InstrType for more details on the possible classifications, and how they\n// manifest in the numeric string.\n///\n/// The numeric string for an individual BasicBlock is terminated by an unique\n/// unsigned integer. This prevents data structures which rely on repetition\n/// from matching across BasicBlocks. (For example, the SuffixTree.)\n/// As a concrete example, if we have the following two BasicBlocks:\n/// \\code\n/// bb0:\n/// %add1 = add i32 %a, %b\n/// %add2 = add i32 %c, %d\n/// %add3 = add i64 %e, %f\n/// bb1:\n/// %sub = sub i32 %c, %d\n/// \\endcode\n/// We may hash the Instructions like this (via IRInstructionData):\n/// \\code\n/// bb0:\n/// %add1 = add i32 %a, %b ; Hash: 1\n/// %add2 = add i32 %c, %d; Hash: 1\n/// %add3 = add i64 %e, %f; Hash: 2\n/// bb1:\n/// %sub = sub i32 %c, %d; Hash: 3\n/// %add4 = add i32 %c, %d ; Hash: 1\n/// \\endcode\n/// And produce a \"numeric string representation\" like so:\n/// 1, 1, 2, unique_integer_1, 3, 1, unique_integer_2\n///\n/// TODO: This is very similar to the MachineOutliner, and should be\n/// consolidated into the same interface.\nstruct IRInstructionMapper {\n  /// The starting illegal instruction number to map to.\n  ///\n  /// Set to -3 for compatibility with DenseMapInfo<unsigned>.\n  unsigned IllegalInstrNumber = static_cast<unsigned>(-3);\n\n  /// The next available integer to assign to a legal Instruction to.\n  unsigned LegalInstrNumber = 0;\n\n  /// Correspondence from IRInstructionData to unsigned integers.\n  DenseMap<IRInstructionData *, unsigned, IRInstructionDataTraits>\n      InstructionIntegerMap;\n\n  /// Set if we added an illegal number in the previous step.\n  /// Since each illegal number is unique, we only need one of them between\n  /// each range of legal numbers. This lets us make sure we don't add more\n  /// than one illegal number per range.\n  bool AddedIllegalLastTime = false;\n\n  /// Marks whether we found a illegal instruction in the previous step.\n  bool CanCombineWithPrevInstr = false;\n\n  /// Marks whether we have found a set of instructions that is long enough\n  /// to be considered for similarity.\n  bool HaveLegalRange = false;\n\n  /// This allocator pointer is in charge of holding on to the IRInstructionData\n  /// so it is not deallocated until whatever external tool is using it is done\n  /// with the information.\n  SpecificBumpPtrAllocator<IRInstructionData> *InstDataAllocator = nullptr;\n\n  /// This allocator pointer is in charge of creating the IRInstructionDataList\n  /// so it is not deallocated until whatever external tool is using it is done\n  /// with the information.\n  SpecificBumpPtrAllocator<IRInstructionDataList> *IDLAllocator = nullptr;\n\n  /// Get an allocated IRInstructionData struct using the InstDataAllocator.\n  ///\n  /// \\param I - The Instruction to wrap with IRInstructionData.\n  /// \\param Legality - A boolean value that is true if the instruction is to\n  /// be considered for similarity, and false if not.\n  /// \\param IDL - The InstructionDataList that the IRInstructionData is\n  /// inserted into.\n  /// \\returns An allocated IRInstructionData struct.\n  IRInstructionData *allocateIRInstructionData(Instruction &I, bool Legality,\n                                               IRInstructionDataList &IDL);\n\n  /// Get an allocated IRInstructionDataList object using the IDLAllocator.\n  ///\n  /// \\returns An allocated IRInstructionDataList object.\n  IRInstructionDataList *allocateIRInstructionDataList();\n\n  IRInstructionDataList *IDL = nullptr;\n\n  /// Maps the Instructions in a BasicBlock \\p BB to legal or illegal integers\n  /// determined by \\p InstrType. Two Instructions are mapped to the same value\n  /// if they are close as defined by the InstructionData class above.\n  ///\n  /// \\param [in] BB - The BasicBlock to be mapped to integers.\n  /// \\param [in,out] InstrList - Vector of IRInstructionData to append to.\n  /// \\param [in,out] IntegerMapping - Vector of unsigned integers to append to.\n  void convertToUnsignedVec(BasicBlock &BB,\n                            std::vector<IRInstructionData *> &InstrList,\n                            std::vector<unsigned> &IntegerMapping);\n\n  /// Maps an Instruction to a legal integer.\n  ///\n  /// \\param [in] It - The Instruction to be mapped to an integer.\n  /// \\param [in,out] IntegerMappingForBB - Vector of unsigned integers to\n  /// append to.\n  /// \\param [in,out] InstrListForBB - Vector of InstructionData to append to.\n  /// \\returns The integer \\p It was mapped to.\n  unsigned mapToLegalUnsigned(BasicBlock::iterator &It,\n                              std::vector<unsigned> &IntegerMappingForBB,\n                              std::vector<IRInstructionData *> &InstrListForBB);\n\n  /// Maps an Instruction to an illegal integer.\n  ///\n  /// \\param [in] It - The \\p Instruction to be mapped to an integer.\n  /// \\param [in,out] IntegerMappingForBB - Vector of unsigned integers to\n  /// append to.\n  /// \\param [in,out] InstrListForBB - Vector of IRInstructionData to append to.\n  /// \\param End - true if creating a dummy IRInstructionData at the end of a\n  /// basic block.\n  /// \\returns The integer \\p It was mapped to.\n  unsigned mapToIllegalUnsigned(\n      BasicBlock::iterator &It, std::vector<unsigned> &IntegerMappingForBB,\n      std::vector<IRInstructionData *> &InstrListForBB, bool End = false);\n\n  IRInstructionMapper(SpecificBumpPtrAllocator<IRInstructionData> *IDA,\n                      SpecificBumpPtrAllocator<IRInstructionDataList> *IDLA)\n      : InstDataAllocator(IDA), IDLAllocator(IDLA) {\n    // Make sure that the implementation of DenseMapInfo<unsigned> hasn't\n    // changed.\n    assert(DenseMapInfo<unsigned>::getEmptyKey() == static_cast<unsigned>(-1) &&\n           \"DenseMapInfo<unsigned>'s empty key isn't -1!\");\n    assert(DenseMapInfo<unsigned>::getTombstoneKey() ==\n               static_cast<unsigned>(-2) &&\n           \"DenseMapInfo<unsigned>'s tombstone key isn't -2!\");\n\n    IDL = new (IDLAllocator->Allocate())\n        IRInstructionDataList();\n  }\n\n  /// Custom InstVisitor to classify different instructions for whether it can\n  /// be analyzed for similarity.\n  struct InstructionClassification\n      : public InstVisitor<InstructionClassification, InstrType> {\n    InstructionClassification() {}\n\n    // TODO: Determine a scheme to resolve when the label is similar enough.\n    InstrType visitBranchInst(BranchInst &BI) { return Illegal; }\n    // TODO: Determine a scheme to resolve when the labels are similar enough.\n    InstrType visitPHINode(PHINode &PN) { return Illegal; }\n    // TODO: Handle allocas.\n    InstrType visitAllocaInst(AllocaInst &AI) { return Illegal; }\n    // We exclude variable argument instructions since variable arguments\n    // requires extra checking of the argument list.\n    InstrType visitVAArgInst(VAArgInst &VI) { return Illegal; }\n    // We exclude all exception handling cases since they are so context\n    // dependent.\n    InstrType visitLandingPadInst(LandingPadInst &LPI) { return Illegal; }\n    InstrType visitFuncletPadInst(FuncletPadInst &FPI) { return Illegal; }\n    // DebugInfo should be included in the regions, but should not be\n    // analyzed for similarity as it has no bearing on the outcome of the\n    // program.\n    InstrType visitDbgInfoIntrinsic(DbgInfoIntrinsic &DII) { return Invisible; }\n    // TODO: Handle specific intrinsics.\n    InstrType visitIntrinsicInst(IntrinsicInst &II) { return Illegal; }\n    // We only allow call instructions where the function has a name and\n    // is not an indirect call.\n    InstrType visitCallInst(CallInst &CI) {\n      Function *F = CI.getCalledFunction();\n      if (!F || CI.isIndirectCall() || !F->hasName())\n        return Illegal;\n      return Legal;\n    }\n    // TODO: We do not current handle similarity that changes the control flow.\n    InstrType visitInvokeInst(InvokeInst &II) { return Illegal; }\n    // TODO: We do not current handle similarity that changes the control flow.\n    InstrType visitCallBrInst(CallBrInst &CBI) { return Illegal; }\n    // TODO: Handle interblock similarity.\n    InstrType visitTerminator(Instruction &I) { return Illegal; }\n    InstrType visitInstruction(Instruction &I) { return Legal; }\n  };\n\n  /// Maps an Instruction to a member of InstrType.\n  InstructionClassification InstClassifier;\n};\n\n/// This is a class that wraps a range of IRInstructionData from one point to\n/// another in the vector of IRInstructionData, which is a region of the\n/// program.  It is also responsible for defining the structure within this\n/// region of instructions.\n///\n/// The structure of a region is defined through a value numbering system\n/// assigned to each unique value in a region at the creation of the\n/// IRSimilarityCandidate.\n///\n/// For example, for each Instruction we add a mapping for each new\n/// value seen in that Instruction.\n/// IR:                    Mapping Added:\n/// %add1 = add i32 %a, c1    %add1 -> 3, %a -> 1, c1 -> 2\n/// %add2 = add i32 %a, %1    %add2 -> 4\n/// %add3 = add i32 c2, c1    %add3 -> 6, c2 -> 5\n///\n/// We can compare IRSimilarityCandidates against one another.\n/// The \\ref isSimilar function compares each IRInstructionData against one\n/// another and if we have the same sequences of IRInstructionData that would\n/// create the same hash, we have similar IRSimilarityCandidates.\n///\n/// We can also compare the structure of IRSimilarityCandidates. If we can\n/// create a mapping of registers in the region contained by one\n/// IRSimilarityCandidate to the region contained by different\n/// IRSimilarityCandidate, they can be considered structurally similar.\n///\n/// IRSimilarityCandidate1:   IRSimilarityCandidate2:\n/// %add1 = add i32 %a, %b    %add1 = add i32 %d, %e\n/// %add2 = add i32 %a, %c    %add2 = add i32 %d, %f\n/// %add3 = add i32 c1, c2    %add3 = add i32 c3, c4\n///\n/// Can have the following mapping from candidate to candidate of:\n/// %a -> %d, %b -> %e, %c -> %f, c1 -> c3, c2 -> c4\n/// and can be considered similar.\n///\n/// IRSimilarityCandidate1:   IRSimilarityCandidate2:\n/// %add1 = add i32 %a, %b    %add1 = add i32 %d, c4\n/// %add2 = add i32 %a, %c    %add2 = add i32 %d, %f\n/// %add3 = add i32 c1, c2    %add3 = add i32 c3, c4\n///\n/// We cannot create the same mapping since the use of c4 is not used in the\n/// same way as %b or c2.\nclass IRSimilarityCandidate {\nprivate:\n  /// The start index of this IRSimilarityCandidate in the instruction list.\n  unsigned StartIdx = 0;\n\n  /// The number of instructions in this IRSimilarityCandidate.\n  unsigned Len = 0;\n\n  /// The first instruction in this IRSimilarityCandidate.\n  IRInstructionData *FirstInst = nullptr;\n\n  /// The last instruction in this IRSimilarityCandidate.\n  IRInstructionData *LastInst = nullptr;\n\n  /// Global Value Numbering structures\n  /// @{\n  /// Stores the mapping of the value to the number assigned to it in the\n  /// IRSimilarityCandidate.\n  DenseMap<Value *, unsigned> ValueToNumber;\n  /// Stores the mapping of the number to the value assigned this number.\n  DenseMap<unsigned, Value *> NumberToValue;\n  /// @}\n\npublic:\n  /// \\param StartIdx - The starting location of the region.\n  /// \\param Len - The length of the region.\n  /// \\param FirstInstIt - The starting IRInstructionData of the region.\n  /// \\param LastInstIt - The ending IRInstructionData of the region.\n  IRSimilarityCandidate(unsigned StartIdx, unsigned Len,\n                        IRInstructionData *FirstInstIt,\n                        IRInstructionData *LastInstIt);\n\n  /// \\param A - The first IRInstructionCandidate to compare.\n  /// \\param B - The second IRInstructionCandidate to compare.\n  /// \\returns True when every IRInstructionData in \\p A is similar to every\n  /// IRInstructionData in \\p B.\n  static bool isSimilar(const IRSimilarityCandidate &A,\n                        const IRSimilarityCandidate &B);\n\n  /// \\param A - The first IRInstructionCandidate to compare.\n  /// \\param B - The second IRInstructionCandidate to compare.\n  /// \\returns True when every IRInstructionData in \\p A is structurally similar\n  /// to \\p B.\n  static bool compareStructure(const IRSimilarityCandidate &A,\n                               const IRSimilarityCandidate &B);\n\n  struct OperandMapping {\n    /// The IRSimilarityCandidate that holds the instruction the OperVals were\n    /// pulled from.\n    const IRSimilarityCandidate &IRSC;\n\n    /// The operand values to be analyzed.\n    ArrayRef<Value *> &OperVals;\n\n    /// The current mapping of global value numbers from one IRSimilarityCandidate\n    /// to another IRSimilarityCandidate.\n    DenseMap<unsigned, DenseSet<unsigned>> &ValueNumberMapping;\n  };\n\n  /// Compare the operands in \\p A and \\p B and check that the current mapping\n  /// of global value numbers from \\p A to \\p B and \\p B to \\A is consistent.\n  ///\n  /// \\param A - The first IRInstructionCandidate, operand values, and current\n  /// operand mappings to compare.\n  /// \\param B - The second IRInstructionCandidate, operand values, and current\n  /// operand mappings to compare.\n  /// \\returns true if the IRSimilarityCandidates operands are compatible.\n  static bool compareNonCommutativeOperandMapping(OperandMapping A,\n                                                  OperandMapping B);\n\n  /// Compare the operands in \\p A and \\p B and check that the current mapping\n  /// of global value numbers from \\p A to \\p B and \\p B to \\A is consistent\n  /// given that the operands are commutative.\n  ///\n  /// \\param A - The first IRInstructionCandidate, operand values, and current\n  /// operand mappings to compare.\n  /// \\param B - The second IRInstructionCandidate, operand values, and current\n  /// operand mappings to compare.\n  /// \\returns true if the IRSimilarityCandidates operands are compatible.\n  static bool compareCommutativeOperandMapping(OperandMapping A,\n                                               OperandMapping B);\n\n  /// Compare the start and end indices of the two IRSimilarityCandidates for\n  /// whether they overlap. If the start instruction of one\n  /// IRSimilarityCandidate is less than the end instruction of the other, and\n  /// the start instruction of one is greater than the start instruction of the\n  /// other, they overlap.\n  ///\n  /// \\returns true if the IRSimilarityCandidates do not have overlapping\n  /// instructions.\n  static bool overlap(const IRSimilarityCandidate &A,\n                      const IRSimilarityCandidate &B);\n\n  /// \\returns the number of instructions in this Candidate.\n  unsigned getLength() const { return Len; }\n\n  /// \\returns the start index of this IRSimilarityCandidate.\n  unsigned getStartIdx() const { return StartIdx; }\n\n  /// \\returns the end index of this IRSimilarityCandidate.\n  unsigned getEndIdx() const { return StartIdx + Len - 1; }\n\n  /// \\returns The first IRInstructionData.\n  IRInstructionData *front() const { return FirstInst; }\n  /// \\returns The last IRInstructionData.\n  IRInstructionData *back() const { return LastInst; }\n\n  /// \\returns The first Instruction.\n  Instruction *frontInstruction() { return FirstInst->Inst; }\n  /// \\returns The last Instruction\n  Instruction *backInstruction() { return LastInst->Inst; }\n\n  /// \\returns The BasicBlock the IRSimilarityCandidate starts in.\n  BasicBlock *getStartBB() { return FirstInst->Inst->getParent(); }\n  /// \\returns The BasicBlock the IRSimilarityCandidate ends in.\n  BasicBlock *getEndBB() { return LastInst->Inst->getParent(); }\n\n  /// \\returns The Function that the IRSimilarityCandidate is located in.\n  Function *getFunction() { return getStartBB()->getParent(); }\n\n  /// Finds the positive number associated with \\p V if it has been mapped.\n  /// \\param [in] V - the Value to find.\n  /// \\returns The positive number corresponding to the value.\n  /// \\returns None if not present.\n  Optional<unsigned> getGVN(Value *V) {\n    assert(V != nullptr && \"Value is a nullptr?\");\n    DenseMap<Value *, unsigned>::iterator VNIt = ValueToNumber.find(V);\n    if (VNIt == ValueToNumber.end())\n      return None;\n    return VNIt->second;\n  }\n\n  /// Finds the Value associate with \\p Num if it exists.\n  /// \\param [in] Num - the number to find.\n  /// \\returns The Value associated with the number.\n  /// \\returns None if not present.\n  Optional<Value *> fromGVN(unsigned Num) {\n    DenseMap<unsigned, Value *>::iterator VNIt = NumberToValue.find(Num);\n    if (VNIt == NumberToValue.end())\n      return None;\n    assert(VNIt->second != nullptr && \"Found value is a nullptr!\");\n    return VNIt->second;\n  }\n\n  /// \\param RHS -The IRSimilarityCandidate to compare against\n  /// \\returns true if the IRSimilarityCandidate is occurs after the\n  /// IRSimilarityCandidate in the program.\n  bool operator<(const IRSimilarityCandidate &RHS) const {\n    return getStartIdx() > RHS.getStartIdx();\n  }\n\n  using iterator = IRInstructionDataList::iterator;\n  iterator begin() const { return iterator(front()); }\n  iterator end() const { return std::next(iterator(back())); }\n};\n\ntypedef std::vector<IRSimilarityCandidate> SimilarityGroup;\ntypedef std::vector<SimilarityGroup> SimilarityGroupList;\n\n/// This class puts all the pieces of the IRInstructionData,\n/// IRInstructionMapper, IRSimilarityCandidate together.\n///\n/// It first feeds the Module or vector of Modules into the IRInstructionMapper,\n/// and puts all the mapped instructions into a single long list of\n/// IRInstructionData.\n///\n/// The list of unsigned integers is given to the Suffix Tree or similar data\n/// structure to find repeated subsequences.  We construct an\n/// IRSimilarityCandidate for each instance of the subsequence.  We compare them\n/// against one another since  These repeated subsequences can have different\n/// structure.  For each different kind of structure found, we create a\n/// similarity group.\n///\n/// If we had four IRSimilarityCandidates A, B, C, and D where A, B and D are\n/// structurally similar to one another, while C is different we would have two\n/// SimilarityGroups:\n///\n/// SimilarityGroup 1:  SimilarityGroup 2\n/// A, B, D             C\n///\n/// A list of the different similarity groups is then returned after\n/// analyzing the module.\nclass IRSimilarityIdentifier {\npublic:\n  IRSimilarityIdentifier()\n      : Mapper(&InstDataAllocator, &InstDataListAllocator) {}\n\n  /// \\param M the module to find similarity in.\n  explicit IRSimilarityIdentifier(Module &M)\n      : Mapper(&InstDataAllocator, &InstDataListAllocator) {\n    findSimilarity(M);\n  }\n\nprivate:\n  /// Map the instructions in the module to unsigned integers, using mapping\n  /// already present in the Mapper if possible.\n  ///\n  /// \\param [in] M Module - To map to integers.\n  /// \\param [in,out] InstrList - The vector to append IRInstructionData to.\n  /// \\param [in,out] IntegerMapping - The vector to append integers to.\n  void populateMapper(Module &M, std::vector<IRInstructionData *> &InstrList,\n                      std::vector<unsigned> &IntegerMapping);\n\n  /// Map the instructions in the modules vector to unsigned integers, using\n  /// mapping already present in the mapper if possible.\n  ///\n  /// \\param [in] Modules - The list of modules to use to populate the mapper\n  /// \\param [in,out] InstrList - The vector to append IRInstructionData to.\n  /// \\param [in,out] IntegerMapping - The vector to append integers to.\n  void populateMapper(ArrayRef<std::unique_ptr<Module>> &Modules,\n                      std::vector<IRInstructionData *> &InstrList,\n                      std::vector<unsigned> &IntegerMapping);\n\n  /// Find the similarity candidates in \\p InstrList and corresponding\n  /// \\p UnsignedVec\n  ///\n  /// \\param [in,out] InstrList - The vector to append IRInstructionData to.\n  /// \\param [in,out] IntegerMapping - The vector to append integers to.\n  /// candidates found in the program.\n  void findCandidates(std::vector<IRInstructionData *> &InstrList,\n                      std::vector<unsigned> &IntegerMapping);\n\npublic:\n  // Find the IRSimilarityCandidates in the \\p Modules and group by structural\n  // similarity in a SimilarityGroup, each group is returned in a\n  // SimilarityGroupList.\n  //\n  // \\param [in] Modules - the modules to analyze.\n  // \\returns The groups of similarity ranges found in the modules.\n  SimilarityGroupList &\n  findSimilarity(ArrayRef<std::unique_ptr<Module>> Modules);\n\n  // Find the IRSimilarityCandidates in the given Module grouped by structural\n  // similarity in a SimilarityGroup, contained inside a SimilarityGroupList.\n  //\n  // \\param [in] M - the module to analyze.\n  // \\returns The groups of similarity ranges found in the module.\n  SimilarityGroupList &findSimilarity(Module &M);\n\n  // Clears \\ref SimilarityCandidates if it is already filled by a previous run.\n  void resetSimilarityCandidates() {\n    // If we've already analyzed a Module or set of Modules, so we must clear\n    // the SimilarityCandidates to make sure we do not have only old values\n    // hanging around.\n    if (SimilarityCandidates.hasValue())\n      SimilarityCandidates->clear();\n    else\n      SimilarityCandidates = SimilarityGroupList();\n  }\n\n  // \\returns The groups of similarity ranges found in the most recently passed\n  // set of modules.\n  Optional<SimilarityGroupList> &getSimilarity() {\n    return SimilarityCandidates;\n  }\n\nprivate:\n  /// The allocator for IRInstructionData.\n  SpecificBumpPtrAllocator<IRInstructionData> InstDataAllocator;\n\n  /// The allocator for IRInstructionDataLists.\n  SpecificBumpPtrAllocator<IRInstructionDataList> InstDataListAllocator;\n\n  /// Map Instructions to unsigned integers and wraps the Instruction in an\n  /// instance of IRInstructionData.\n  IRInstructionMapper Mapper;\n\n  /// The SimilarityGroups found with the most recent run of \\ref\n  /// findSimilarity. None if there is no recent run.\n  Optional<SimilarityGroupList> SimilarityCandidates;\n};\n\n} // end namespace IRSimilarity\n\n/// An analysis pass based on legacy pass manager that runs and returns\n/// IRSimilarityIdentifier run on the Module.\nclass IRSimilarityIdentifierWrapperPass : public ModulePass {\n  std::unique_ptr<IRSimilarity::IRSimilarityIdentifier> IRSI;\n\npublic:\n  static char ID;\n  IRSimilarityIdentifierWrapperPass();\n\n  IRSimilarity::IRSimilarityIdentifier &getIRSI() { return *IRSI; }\n  const IRSimilarity::IRSimilarityIdentifier &getIRSI() const { return *IRSI; }\n\n  bool doInitialization(Module &M) override;\n  bool doFinalization(Module &M) override;\n  bool runOnModule(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override {\n    AU.setPreservesAll();\n  }\n};\n\n/// An analysis pass that runs and returns the IRSimilarityIdentifier run on the\n/// Module.\nclass IRSimilarityAnalysis : public AnalysisInfoMixin<IRSimilarityAnalysis> {\npublic:\n  typedef IRSimilarity::IRSimilarityIdentifier Result;\n\n  Result run(Module &M, ModuleAnalysisManager &);\n\nprivate:\n  friend AnalysisInfoMixin<IRSimilarityAnalysis>;\n  static AnalysisKey Key;\n};\n\n/// Printer pass that uses \\c IRSimilarityAnalysis.\nclass IRSimilarityAnalysisPrinterPass\n    : public PassInfoMixin<IRSimilarityAnalysisPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit IRSimilarityAnalysisPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_IRSIMILARITYIDENTIFIER_H\n"}, "40": {"id": 40, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/IVUsers.h", "content": "//===- llvm/Analysis/IVUsers.h - Induction Variable Users -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements bookkeeping for \"interesting\" users of expressions\n// computed from induction variables.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_IVUSERS_H\n#define LLVM_ANALYSIS_IVUSERS_H\n\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/Analysis/LoopPass.h\"\n#include \"llvm/Analysis/ScalarEvolutionNormalization.h\"\n#include \"llvm/IR/ValueHandle.h\"\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass DominatorTree;\nclass Instruction;\nclass Value;\nclass ScalarEvolution;\nclass SCEV;\nclass IVUsers;\nclass DataLayout;\n\n/// IVStrideUse - Keep track of one use of a strided induction variable.\n/// The Expr member keeps track of the expression, User is the actual user\n/// instruction of the operand, and 'OperandValToReplace' is the operand of\n/// the User that is the use.\nclass IVStrideUse final : public CallbackVH, public ilist_node<IVStrideUse> {\n  friend class IVUsers;\npublic:\n  IVStrideUse(IVUsers *P, Instruction* U, Value *O)\n    : CallbackVH(U), Parent(P), OperandValToReplace(O) {\n  }\n\n  /// getUser - Return the user instruction for this use.\n  Instruction *getUser() const {\n    return cast<Instruction>(getValPtr());\n  }\n\n  /// setUser - Assign a new user instruction for this use.\n  void setUser(Instruction *NewUser) {\n    setValPtr(NewUser);\n  }\n\n  /// getOperandValToReplace - Return the Value of the operand in the user\n  /// instruction that this IVStrideUse is representing.\n  Value *getOperandValToReplace() const {\n    return OperandValToReplace;\n  }\n\n  /// setOperandValToReplace - Assign a new Value as the operand value\n  /// to replace.\n  void setOperandValToReplace(Value *Op) {\n    OperandValToReplace = Op;\n  }\n\n  /// getPostIncLoops - Return the set of loops for which the expression has\n  /// been adjusted to use post-inc mode.\n  const PostIncLoopSet &getPostIncLoops() const {\n    return PostIncLoops;\n  }\n\n  /// transformToPostInc - Transform the expression to post-inc form for the\n  /// given loop.\n  void transformToPostInc(const Loop *L);\n\nprivate:\n  /// Parent - a pointer to the IVUsers that owns this IVStrideUse.\n  IVUsers *Parent;\n\n  /// OperandValToReplace - The Value of the operand in the user instruction\n  /// that this IVStrideUse is representing.\n  WeakTrackingVH OperandValToReplace;\n\n  /// PostIncLoops - The set of loops for which Expr has been adjusted to\n  /// use post-inc mode. This corresponds with SCEVExpander's post-inc concept.\n  PostIncLoopSet PostIncLoops;\n\n  /// Deleted - Implementation of CallbackVH virtual function to\n  /// receive notification when the User is deleted.\n  void deleted() override;\n};\n\nclass IVUsers {\n  friend class IVStrideUse;\n  Loop *L;\n  AssumptionCache *AC;\n  LoopInfo *LI;\n  DominatorTree *DT;\n  ScalarEvolution *SE;\n  SmallPtrSet<Instruction*, 16> Processed;\n\n  /// IVUses - A list of all tracked IV uses of induction variable expressions\n  /// we are interested in.\n  ilist<IVStrideUse> IVUses;\n\n  // Ephemeral values used by @llvm.assume in this function.\n  SmallPtrSet<const Value *, 32> EphValues;\n\npublic:\n  IVUsers(Loop *L, AssumptionCache *AC, LoopInfo *LI, DominatorTree *DT,\n          ScalarEvolution *SE);\n\n  IVUsers(IVUsers &&X)\n      : L(std::move(X.L)), AC(std::move(X.AC)), DT(std::move(X.DT)),\n        SE(std::move(X.SE)), Processed(std::move(X.Processed)),\n        IVUses(std::move(X.IVUses)), EphValues(std::move(X.EphValues)) {\n    for (IVStrideUse &U : IVUses)\n      U.Parent = this;\n  }\n  IVUsers(const IVUsers &) = delete;\n  IVUsers &operator=(IVUsers &&) = delete;\n  IVUsers &operator=(const IVUsers &) = delete;\n\n  Loop *getLoop() const { return L; }\n\n  /// AddUsersIfInteresting - Inspect the specified Instruction.  If it is a\n  /// reducible SCEV, recursively add its users to the IVUsesByStride set and\n  /// return true.  Otherwise, return false.\n  bool AddUsersIfInteresting(Instruction *I);\n\n  IVStrideUse &AddUser(Instruction *User, Value *Operand);\n\n  /// getReplacementExpr - Return a SCEV expression which computes the\n  /// value of the OperandValToReplace of the given IVStrideUse.\n  const SCEV *getReplacementExpr(const IVStrideUse &IU) const;\n\n  /// getExpr - Return the expression for the use.\n  const SCEV *getExpr(const IVStrideUse &IU) const;\n\n  const SCEV *getStride(const IVStrideUse &IU, const Loop *L) const;\n\n  typedef ilist<IVStrideUse>::iterator iterator;\n  typedef ilist<IVStrideUse>::const_iterator const_iterator;\n  iterator begin() { return IVUses.begin(); }\n  iterator end()   { return IVUses.end(); }\n  const_iterator begin() const { return IVUses.begin(); }\n  const_iterator end() const   { return IVUses.end(); }\n  bool empty() const { return IVUses.empty(); }\n\n  bool isIVUserOrOperand(Instruction *Inst) const {\n    return Processed.count(Inst);\n  }\n\n  void releaseMemory();\n\n  void print(raw_ostream &OS, const Module * = nullptr) const;\n\n  /// dump - This method is used for debugging.\n  void dump() const;\n\nprotected:\n  bool AddUsersImpl(Instruction *I, SmallPtrSetImpl<Loop*> &SimpleLoopNests);\n};\n\nPass *createIVUsersPass();\n\nclass IVUsersWrapperPass : public LoopPass {\n  std::unique_ptr<IVUsers> IU;\n\npublic:\n  static char ID;\n\n  IVUsersWrapperPass();\n\n  IVUsers &getIU() { return *IU; }\n  const IVUsers &getIU() const { return *IU; }\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  bool runOnLoop(Loop *L, LPPassManager &LPM) override;\n\n  void releaseMemory() override;\n\n  void print(raw_ostream &OS, const Module * = nullptr) const override;\n};\n\n/// Analysis pass that exposes the \\c IVUsers for a loop.\nclass IVUsersAnalysis : public AnalysisInfoMixin<IVUsersAnalysis> {\n  friend AnalysisInfoMixin<IVUsersAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  typedef IVUsers Result;\n\n  IVUsers run(Loop &L, LoopAnalysisManager &AM,\n              LoopStandardAnalysisResults &AR);\n};\n\n}\n\n#endif\n"}, "42": {"id": 42, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/InlineCost.h", "content": "//===- InlineCost.h - Cost analysis for inliner -----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements heuristics for inlining decisions.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_INLINECOST_H\n#define LLVM_ANALYSIS_INLINECOST_H\n\n#include \"llvm/Analysis/AssumptionCache.h\"\n#include \"llvm/Analysis/CallGraphSCCPass.h\"\n#include \"llvm/Analysis/OptimizationRemarkEmitter.h\"\n#include <cassert>\n#include <climits>\n\nnamespace llvm {\nclass AssumptionCacheTracker;\nclass BlockFrequencyInfo;\nclass CallBase;\nclass DataLayout;\nclass Function;\nclass ProfileSummaryInfo;\nclass TargetTransformInfo;\nclass TargetLibraryInfo;\n\nnamespace InlineConstants {\n// Various thresholds used by inline cost analysis.\n/// Use when optsize (-Os) is specified.\nconst int OptSizeThreshold = 50;\n\n/// Use when minsize (-Oz) is specified.\nconst int OptMinSizeThreshold = 5;\n\n/// Use when -O3 is specified.\nconst int OptAggressiveThreshold = 250;\n\n// Various magic constants used to adjust heuristics.\nconst int InstrCost = 5;\nconst int IndirectCallThreshold = 100;\nconst int CallPenalty = 25;\nconst int LastCallToStaticBonus = 15000;\nconst int ColdccPenalty = 2000;\n/// Do not inline functions which allocate this many bytes on the stack\n/// when the caller is recursive.\nconst unsigned TotalAllocaSizeRecursiveCaller = 1024;\n/// Do not inline dynamic allocas that have been constant propagated to be\n/// static allocas above this amount in bytes.\nconst uint64_t MaxSimplifiedDynamicAllocaToInline = 65536;\n} // namespace InlineConstants\n\n/// Represents the cost of inlining a function.\n///\n/// This supports special values for functions which should \"always\" or\n/// \"never\" be inlined. Otherwise, the cost represents a unitless amount;\n/// smaller values increase the likelihood of the function being inlined.\n///\n/// Objects of this type also provide the adjusted threshold for inlining\n/// based on the information available for a particular callsite. They can be\n/// directly tested to determine if inlining should occur given the cost and\n/// threshold for this cost metric.\nclass InlineCost {\n  enum SentinelValues { AlwaysInlineCost = INT_MIN, NeverInlineCost = INT_MAX };\n\n  /// The estimated cost of inlining this callsite.\n  int Cost = 0;\n\n  /// The adjusted threshold against which this cost was computed.\n  int Threshold = 0;\n\n  /// Must be set for Always and Never instances.\n  const char *Reason = nullptr;\n\n  // Trivial constructor, interesting logic in the factory functions below.\n  InlineCost(int Cost, int Threshold, const char *Reason = nullptr)\n      : Cost(Cost), Threshold(Threshold), Reason(Reason) {\n    assert((isVariable() || Reason) &&\n           \"Reason must be provided for Never or Always\");\n  }\n\npublic:\n  static InlineCost get(int Cost, int Threshold) {\n    assert(Cost > AlwaysInlineCost && \"Cost crosses sentinel value\");\n    assert(Cost < NeverInlineCost && \"Cost crosses sentinel value\");\n    return InlineCost(Cost, Threshold);\n  }\n  static InlineCost getAlways(const char *Reason) {\n    return InlineCost(AlwaysInlineCost, 0, Reason);\n  }\n  static InlineCost getNever(const char *Reason) {\n    return InlineCost(NeverInlineCost, 0, Reason);\n  }\n\n  /// Test whether the inline cost is low enough for inlining.\n  explicit operator bool() const { return Cost < Threshold; }\n\n  bool isAlways() const { return Cost == AlwaysInlineCost; }\n  bool isNever() const { return Cost == NeverInlineCost; }\n  bool isVariable() const { return !isAlways() && !isNever(); }\n\n  /// Get the inline cost estimate.\n  /// It is an error to call this on an \"always\" or \"never\" InlineCost.\n  int getCost() const {\n    assert(isVariable() && \"Invalid access of InlineCost\");\n    return Cost;\n  }\n\n  /// Get the threshold against which the cost was computed\n  int getThreshold() const {\n    assert(isVariable() && \"Invalid access of InlineCost\");\n    return Threshold;\n  }\n\n  /// Get the reason of Always or Never.\n  const char *getReason() const {\n    assert((Reason || isVariable()) &&\n           \"InlineCost reason must be set for Always or Never\");\n    return Reason;\n  }\n\n  /// Get the cost delta from the threshold for inlining.\n  /// Only valid if the cost is of the variable kind. Returns a negative\n  /// value if the cost is too high to inline.\n  int getCostDelta() const { return Threshold - getCost(); }\n};\n\n/// InlineResult is basically true or false. For false results the message\n/// describes a reason.\nclass InlineResult {\n  const char *Message = nullptr;\n  InlineResult(const char *Message = nullptr) : Message(Message) {}\n\npublic:\n  static InlineResult success() { return {}; }\n  static InlineResult failure(const char *Reason) {\n    return InlineResult(Reason);\n  }\n  bool isSuccess() const { return Message == nullptr; }\n  const char *getFailureReason() const {\n    assert(!isSuccess() &&\n           \"getFailureReason should only be called in failure cases\");\n    return Message;\n  }\n};\n\n/// Thresholds to tune inline cost analysis. The inline cost analysis decides\n/// the condition to apply a threshold and applies it. Otherwise,\n/// DefaultThreshold is used. If a threshold is Optional, it is applied only\n/// when it has a valid value. Typically, users of inline cost analysis\n/// obtain an InlineParams object through one of the \\c getInlineParams methods\n/// and pass it to \\c getInlineCost. Some specialized versions of inliner\n/// (such as the pre-inliner) might have custom logic to compute \\c InlineParams\n/// object.\n\nstruct InlineParams {\n  /// The default threshold to start with for a callee.\n  int DefaultThreshold = -1;\n\n  /// Threshold to use for callees with inline hint.\n  Optional<int> HintThreshold;\n\n  /// Threshold to use for cold callees.\n  Optional<int> ColdThreshold;\n\n  /// Threshold to use when the caller is optimized for size.\n  Optional<int> OptSizeThreshold;\n\n  /// Threshold to use when the caller is optimized for minsize.\n  Optional<int> OptMinSizeThreshold;\n\n  /// Threshold to use when the callsite is considered hot.\n  Optional<int> HotCallSiteThreshold;\n\n  /// Threshold to use when the callsite is considered hot relative to function\n  /// entry.\n  Optional<int> LocallyHotCallSiteThreshold;\n\n  /// Threshold to use when the callsite is considered cold.\n  Optional<int> ColdCallSiteThreshold;\n\n  /// Compute inline cost even when the cost has exceeded the threshold.\n  Optional<bool> ComputeFullInlineCost;\n\n  /// Indicate whether we should allow inline deferral.\n  Optional<bool> EnableDeferral = true;\n};\n\n/// Generate the parameters to tune the inline cost analysis based only on the\n/// commandline options.\nInlineParams getInlineParams();\n\n/// Generate the parameters to tune the inline cost analysis based on command\n/// line options. If -inline-threshold option is not explicitly passed,\n/// \\p Threshold is used as the default threshold.\nInlineParams getInlineParams(int Threshold);\n\n/// Generate the parameters to tune the inline cost analysis based on command\n/// line options. If -inline-threshold option is not explicitly passed,\n/// the default threshold is computed from \\p OptLevel and \\p SizeOptLevel.\n/// An \\p OptLevel value above 3 is considered an aggressive optimization mode.\n/// \\p SizeOptLevel of 1 corresponds to the -Os flag and 2 corresponds to\n/// the -Oz flag.\nInlineParams getInlineParams(unsigned OptLevel, unsigned SizeOptLevel);\n\n/// Return the cost associated with a callsite, including parameter passing\n/// and the call/return instruction.\nint getCallsiteCost(CallBase &Call, const DataLayout &DL);\n\n/// Get an InlineCost object representing the cost of inlining this\n/// callsite.\n///\n/// Note that a default threshold is passed into this function. This threshold\n/// could be modified based on callsite's properties and only costs below this\n/// new threshold are computed with any accuracy. The new threshold can be\n/// used to bound the computation necessary to determine whether the cost is\n/// sufficiently low to warrant inlining.\n///\n/// Also note that calling this function *dynamically* computes the cost of\n/// inlining the callsite. It is an expensive, heavyweight call.\nInlineCost\ngetInlineCost(CallBase &Call, const InlineParams &Params,\n              TargetTransformInfo &CalleeTTI,\n              function_ref<AssumptionCache &(Function &)> GetAssumptionCache,\n              function_ref<const TargetLibraryInfo &(Function &)> GetTLI,\n              function_ref<BlockFrequencyInfo &(Function &)> GetBFI = nullptr,\n              ProfileSummaryInfo *PSI = nullptr,\n              OptimizationRemarkEmitter *ORE = nullptr);\n\n/// Get an InlineCost with the callee explicitly specified.\n/// This allows you to calculate the cost of inlining a function via a\n/// pointer. This behaves exactly as the version with no explicit callee\n/// parameter in all other respects.\n//\nInlineCost\ngetInlineCost(CallBase &Call, Function *Callee, const InlineParams &Params,\n              TargetTransformInfo &CalleeTTI,\n              function_ref<AssumptionCache &(Function &)> GetAssumptionCache,\n              function_ref<const TargetLibraryInfo &(Function &)> GetTLI,\n              function_ref<BlockFrequencyInfo &(Function &)> GetBFI = nullptr,\n              ProfileSummaryInfo *PSI = nullptr,\n              OptimizationRemarkEmitter *ORE = nullptr);\n\n/// Returns InlineResult::success() if the call site should be always inlined\n/// because of user directives, and the inlining is viable. Returns\n/// InlineResult::failure() if the inlining may never happen because of user\n/// directives or incompatibilities detectable without needing callee traversal.\n/// Otherwise returns None, meaning that inlining should be decided based on\n/// other criteria (e.g. cost modeling).\nOptional<InlineResult> getAttributeBasedInliningDecision(\n    CallBase &Call, Function *Callee, TargetTransformInfo &CalleeTTI,\n    function_ref<const TargetLibraryInfo &(Function &)> GetTLI);\n\n/// Get the cost estimate ignoring thresholds. This is similar to getInlineCost\n/// when passed InlineParams::ComputeFullInlineCost, or a non-null ORE. It\n/// uses default InlineParams otherwise.\n/// Contrary to getInlineCost, which makes a threshold-based final evaluation of\n/// should/shouldn't inline, captured in InlineResult, getInliningCostEstimate\n/// returns:\n/// - None, if the inlining cannot happen (is illegal)\n/// - an integer, representing the cost.\nOptional<int> getInliningCostEstimate(\n    CallBase &Call, TargetTransformInfo &CalleeTTI,\n    function_ref<AssumptionCache &(Function &)> GetAssumptionCache,\n    function_ref<BlockFrequencyInfo &(Function &)> GetBFI = nullptr,\n    ProfileSummaryInfo *PSI = nullptr,\n    OptimizationRemarkEmitter *ORE = nullptr);\n\n/// Minimal filter to detect invalid constructs for inlining.\nInlineResult isInlineViable(Function &Callee);\n\n// This pass is used to annotate instructions during the inline process for\n// debugging and analysis. The main purpose of the pass is to see and test\n// inliner's decisions when creating new optimizations to InlineCost.\nstruct InlineCostAnnotationPrinterPass\n    : PassInfoMixin<InlineCostAnnotationPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit InlineCostAnnotationPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n};\n} // namespace llvm\n\n#endif\n"}, "43": {"id": 43, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/InstCount.h", "content": "//===- InstCount.h - Collects the count of all instructions -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass collects the count of all instructions and reports them\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_INSTCOUNT_H\n#define LLVM_ANALYSIS_INSTCOUNT_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nstruct InstCountPass : PassInfoMixin<InstCountPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_INSTCOUNT_H\n"}, "44": {"id": 44, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LazyCallGraph.h", "content": "//===- LazyCallGraph.h - Analysis of a Module's call graph ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// Implements a lazy call graph analysis and related passes for the new pass\n/// manager.\n///\n/// NB: This is *not* a traditional call graph! It is a graph which models both\n/// the current calls and potential calls. As a consequence there are many\n/// edges in this call graph that do not correspond to a 'call' or 'invoke'\n/// instruction.\n///\n/// The primary use cases of this graph analysis is to facilitate iterating\n/// across the functions of a module in ways that ensure all callees are\n/// visited prior to a caller (given any SCC constraints), or vice versa. As\n/// such is it particularly well suited to organizing CGSCC optimizations such\n/// as inlining, outlining, argument promotion, etc. That is its primary use\n/// case and motivates the design. It may not be appropriate for other\n/// purposes. The use graph of functions or some other conservative analysis of\n/// call instructions may be interesting for optimizations and subsequent\n/// analyses which don't work in the context of an overly specified\n/// potential-call-edge graph.\n///\n/// To understand the specific rules and nature of this call graph analysis,\n/// see the documentation of the \\c LazyCallGraph below.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_LAZYCALLGRAPH_H\n#define LLVM_ANALYSIS_LAZYCALLGRAPH_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/iterator.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Analysis/TargetLibraryInfo.h\"\n#include \"llvm/IR/Constant.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/Allocator.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <cassert>\n#include <iterator>\n#include <string>\n#include <utility>\n\nnamespace llvm {\n\nclass Module;\nclass Value;\n\n/// A lazily constructed view of the call graph of a module.\n///\n/// With the edges of this graph, the motivating constraint that we are\n/// attempting to maintain is that function-local optimization, CGSCC-local\n/// optimizations, and optimizations transforming a pair of functions connected\n/// by an edge in the graph, do not invalidate a bottom-up traversal of the SCC\n/// DAG. That is, no optimizations will delete, remove, or add an edge such\n/// that functions already visited in a bottom-up order of the SCC DAG are no\n/// longer valid to have visited, or such that functions not yet visited in\n/// a bottom-up order of the SCC DAG are not required to have already been\n/// visited.\n///\n/// Within this constraint, the desire is to minimize the merge points of the\n/// SCC DAG. The greater the fanout of the SCC DAG and the fewer merge points\n/// in the SCC DAG, the more independence there is in optimizing within it.\n/// There is a strong desire to enable parallelization of optimizations over\n/// the call graph, and both limited fanout and merge points will (artificially\n/// in some cases) limit the scaling of such an effort.\n///\n/// To this end, graph represents both direct and any potential resolution to\n/// an indirect call edge. Another way to think about it is that it represents\n/// both the direct call edges and any direct call edges that might be formed\n/// through static optimizations. Specifically, it considers taking the address\n/// of a function to be an edge in the call graph because this might be\n/// forwarded to become a direct call by some subsequent function-local\n/// optimization. The result is that the graph closely follows the use-def\n/// edges for functions. Walking \"up\" the graph can be done by looking at all\n/// of the uses of a function.\n///\n/// The roots of the call graph are the external functions and functions\n/// escaped into global variables. Those functions can be called from outside\n/// of the module or via unknowable means in the IR -- we may not be able to\n/// form even a potential call edge from a function body which may dynamically\n/// load the function and call it.\n///\n/// This analysis still requires updates to remain valid after optimizations\n/// which could potentially change the set of potential callees. The\n/// constraints it operates under only make the traversal order remain valid.\n///\n/// The entire analysis must be re-computed if full interprocedural\n/// optimizations run at any point. For example, globalopt completely\n/// invalidates the information in this analysis.\n///\n/// FIXME: This class is named LazyCallGraph in a lame attempt to distinguish\n/// it from the existing CallGraph. At some point, it is expected that this\n/// will be the only call graph and it will be renamed accordingly.\nclass LazyCallGraph {\npublic:\n  class Node;\n  class EdgeSequence;\n  class SCC;\n  class RefSCC;\n\n  /// A class used to represent edges in the call graph.\n  ///\n  /// The lazy call graph models both *call* edges and *reference* edges. Call\n  /// edges are much what you would expect, and exist when there is a 'call' or\n  /// 'invoke' instruction of some function. Reference edges are also tracked\n  /// along side these, and exist whenever any instruction (transitively\n  /// through its operands) references a function. All call edges are\n  /// inherently reference edges, and so the reference graph forms a superset\n  /// of the formal call graph.\n  ///\n  /// All of these forms of edges are fundamentally represented as outgoing\n  /// edges. The edges are stored in the source node and point at the target\n  /// node. This allows the edge structure itself to be a very compact data\n  /// structure: essentially a tagged pointer.\n  class Edge {\n  public:\n    /// The kind of edge in the graph.\n    enum Kind : bool { Ref = false, Call = true };\n\n    Edge();\n    explicit Edge(Node &N, Kind K);\n\n    /// Test whether the edge is null.\n    ///\n    /// This happens when an edge has been deleted. We leave the edge objects\n    /// around but clear them.\n    explicit operator bool() const;\n\n    /// Returnss the \\c Kind of the edge.\n    Kind getKind() const;\n\n    /// Test whether the edge represents a direct call to a function.\n    ///\n    /// This requires that the edge is not null.\n    bool isCall() const;\n\n    /// Get the call graph node referenced by this edge.\n    ///\n    /// This requires that the edge is not null.\n    Node &getNode() const;\n\n    /// Get the function referenced by this edge.\n    ///\n    /// This requires that the edge is not null.\n    Function &getFunction() const;\n\n  private:\n    friend class LazyCallGraph::EdgeSequence;\n    friend class LazyCallGraph::RefSCC;\n\n    PointerIntPair<Node *, 1, Kind> Value;\n\n    void setKind(Kind K) { Value.setInt(K); }\n  };\n\n  /// The edge sequence object.\n  ///\n  /// This typically exists entirely within the node but is exposed as\n  /// a separate type because a node doesn't initially have edges. An explicit\n  /// population step is required to produce this sequence at first and it is\n  /// then cached in the node. It is also used to represent edges entering the\n  /// graph from outside the module to model the graph's roots.\n  ///\n  /// The sequence itself both iterable and indexable. The indexes remain\n  /// stable even as the sequence mutates (including removal).\n  class EdgeSequence {\n    friend class LazyCallGraph;\n    friend class LazyCallGraph::Node;\n    friend class LazyCallGraph::RefSCC;\n\n    using VectorT = SmallVector<Edge, 4>;\n    using VectorImplT = SmallVectorImpl<Edge>;\n\n  public:\n    /// An iterator used for the edges to both entry nodes and child nodes.\n    class iterator\n        : public iterator_adaptor_base<iterator, VectorImplT::iterator,\n                                       std::forward_iterator_tag> {\n      friend class LazyCallGraph;\n      friend class LazyCallGraph::Node;\n\n      VectorImplT::iterator E;\n\n      // Build the iterator for a specific position in the edge list.\n      iterator(VectorImplT::iterator BaseI, VectorImplT::iterator E)\n          : iterator_adaptor_base(BaseI), E(E) {\n        while (I != E && !*I)\n          ++I;\n      }\n\n    public:\n      iterator() = default;\n\n      using iterator_adaptor_base::operator++;\n      iterator &operator++() {\n        do {\n          ++I;\n        } while (I != E && !*I);\n        return *this;\n      }\n    };\n\n    /// An iterator over specifically call edges.\n    ///\n    /// This has the same iteration properties as the \\c iterator, but\n    /// restricts itself to edges which represent actual calls.\n    class call_iterator\n        : public iterator_adaptor_base<call_iterator, VectorImplT::iterator,\n                                       std::forward_iterator_tag> {\n      friend class LazyCallGraph;\n      friend class LazyCallGraph::Node;\n\n      VectorImplT::iterator E;\n\n      /// Advance the iterator to the next valid, call edge.\n      void advanceToNextEdge() {\n        while (I != E && (!*I || !I->isCall()))\n          ++I;\n      }\n\n      // Build the iterator for a specific position in the edge list.\n      call_iterator(VectorImplT::iterator BaseI, VectorImplT::iterator E)\n          : iterator_adaptor_base(BaseI), E(E) {\n        advanceToNextEdge();\n      }\n\n    public:\n      call_iterator() = default;\n\n      using iterator_adaptor_base::operator++;\n      call_iterator &operator++() {\n        ++I;\n        advanceToNextEdge();\n        return *this;\n      }\n    };\n\n    iterator begin() { return iterator(Edges.begin(), Edges.end()); }\n    iterator end() { return iterator(Edges.end(), Edges.end()); }\n\n    Edge &operator[](Node &N) {\n      assert(EdgeIndexMap.find(&N) != EdgeIndexMap.end() && \"No such edge!\");\n      auto &E = Edges[EdgeIndexMap.find(&N)->second];\n      assert(E && \"Dead or null edge!\");\n      return E;\n    }\n\n    Edge *lookup(Node &N) {\n      auto EI = EdgeIndexMap.find(&N);\n      if (EI == EdgeIndexMap.end())\n        return nullptr;\n      auto &E = Edges[EI->second];\n      return E ? &E : nullptr;\n    }\n\n    call_iterator call_begin() {\n      return call_iterator(Edges.begin(), Edges.end());\n    }\n    call_iterator call_end() { return call_iterator(Edges.end(), Edges.end()); }\n\n    iterator_range<call_iterator> calls() {\n      return make_range(call_begin(), call_end());\n    }\n\n    bool empty() {\n      for (auto &E : Edges)\n        if (E)\n          return false;\n\n      return true;\n    }\n\n  private:\n    VectorT Edges;\n    DenseMap<Node *, int> EdgeIndexMap;\n\n    EdgeSequence() = default;\n\n    /// Internal helper to insert an edge to a node.\n    void insertEdgeInternal(Node &ChildN, Edge::Kind EK);\n\n    /// Internal helper to change an edge kind.\n    void setEdgeKind(Node &ChildN, Edge::Kind EK);\n\n    /// Internal helper to remove the edge to the given function.\n    bool removeEdgeInternal(Node &ChildN);\n  };\n\n  /// A node in the call graph.\n  ///\n  /// This represents a single node. It's primary roles are to cache the list of\n  /// callees, de-duplicate and provide fast testing of whether a function is\n  /// a callee, and facilitate iteration of child nodes in the graph.\n  ///\n  /// The node works much like an optional in order to lazily populate the\n  /// edges of each node. Until populated, there are no edges. Once populated,\n  /// you can access the edges by dereferencing the node or using the `->`\n  /// operator as if the node was an `Optional<EdgeSequence>`.\n  class Node {\n    friend class LazyCallGraph;\n    friend class LazyCallGraph::RefSCC;\n\n  public:\n    LazyCallGraph &getGraph() const { return *G; }\n\n    Function &getFunction() const { return *F; }\n\n    StringRef getName() const { return F->getName(); }\n\n    /// Equality is defined as address equality.\n    bool operator==(const Node &N) const { return this == &N; }\n    bool operator!=(const Node &N) const { return !operator==(N); }\n\n    /// Tests whether the node has been populated with edges.\n    bool isPopulated() const { return Edges.hasValue(); }\n\n    /// Tests whether this is actually a dead node and no longer valid.\n    ///\n    /// Users rarely interact with nodes in this state and other methods are\n    /// invalid. This is used to model a node in an edge list where the\n    /// function has been completely removed.\n    bool isDead() const {\n      assert(!G == !F &&\n             \"Both graph and function pointers should be null or non-null.\");\n      return !G;\n    }\n\n    // We allow accessing the edges by dereferencing or using the arrow\n    // operator, essentially wrapping the internal optional.\n    EdgeSequence &operator*() const {\n      // Rip const off because the node itself isn't changing here.\n      return const_cast<EdgeSequence &>(*Edges);\n    }\n    EdgeSequence *operator->() const { return &**this; }\n\n    /// Populate the edges of this node if necessary.\n    ///\n    /// The first time this is called it will populate the edges for this node\n    /// in the graph. It does this by scanning the underlying function, so once\n    /// this is done, any changes to that function must be explicitly reflected\n    /// in updates to the graph.\n    ///\n    /// \\returns the populated \\c EdgeSequence to simplify walking it.\n    ///\n    /// This will not update or re-scan anything if called repeatedly. Instead,\n    /// the edge sequence is cached and returned immediately on subsequent\n    /// calls.\n    EdgeSequence &populate() {\n      if (Edges)\n        return *Edges;\n\n      return populateSlow();\n    }\n\n  private:\n    LazyCallGraph *G;\n    Function *F;\n\n    // We provide for the DFS numbering and Tarjan walk lowlink numbers to be\n    // stored directly within the node. These are both '-1' when nodes are part\n    // of an SCC (or RefSCC), or '0' when not yet reached in a DFS walk.\n    int DFSNumber = 0;\n    int LowLink = 0;\n\n    Optional<EdgeSequence> Edges;\n\n    /// Basic constructor implements the scanning of F into Edges and\n    /// EdgeIndexMap.\n    Node(LazyCallGraph &G, Function &F) : G(&G), F(&F) {}\n\n    /// Implementation of the scan when populating.\n    EdgeSequence &populateSlow();\n\n    /// Internal helper to directly replace the function with a new one.\n    ///\n    /// This is used to facilitate tranfsormations which need to replace the\n    /// formal Function object but directly move the body and users from one to\n    /// the other.\n    void replaceFunction(Function &NewF);\n\n    void clear() { Edges.reset(); }\n\n    /// Print the name of this node's function.\n    friend raw_ostream &operator<<(raw_ostream &OS, const Node &N) {\n      return OS << N.F->getName();\n    }\n\n    /// Dump the name of this node's function to stderr.\n    void dump() const;\n  };\n\n  /// An SCC of the call graph.\n  ///\n  /// This represents a Strongly Connected Component of the direct call graph\n  /// -- ignoring indirect calls and function references. It stores this as\n  /// a collection of call graph nodes. While the order of nodes in the SCC is\n  /// stable, it is not any particular order.\n  ///\n  /// The SCCs are nested within a \\c RefSCC, see below for details about that\n  /// outer structure. SCCs do not support mutation of the call graph, that\n  /// must be done through the containing \\c RefSCC in order to fully reason\n  /// about the ordering and connections of the graph.\n  class SCC {\n    friend class LazyCallGraph;\n    friend class LazyCallGraph::Node;\n\n    RefSCC *OuterRefSCC;\n    SmallVector<Node *, 1> Nodes;\n\n    template <typename NodeRangeT>\n    SCC(RefSCC &OuterRefSCC, NodeRangeT &&Nodes)\n        : OuterRefSCC(&OuterRefSCC), Nodes(std::forward<NodeRangeT>(Nodes)) {}\n\n    void clear() {\n      OuterRefSCC = nullptr;\n      Nodes.clear();\n    }\n\n    /// Print a short descrtiption useful for debugging or logging.\n    ///\n    /// We print the function names in the SCC wrapped in '()'s and skipping\n    /// the middle functions if there are a large number.\n    //\n    // Note: this is defined inline to dodge issues with GCC's interpretation\n    // of enclosing namespaces for friend function declarations.\n    friend raw_ostream &operator<<(raw_ostream &OS, const SCC &C) {\n      OS << '(';\n      int i = 0;\n      for (LazyCallGraph::Node &N : C) {\n        if (i > 0)\n          OS << \", \";\n        // Elide the inner elements if there are too many.\n        if (i > 8) {\n          OS << \"..., \" << *C.Nodes.back();\n          break;\n        }\n        OS << N;\n        ++i;\n      }\n      OS << ')';\n      return OS;\n    }\n\n    /// Dump a short description of this SCC to stderr.\n    void dump() const;\n\n#ifndef NDEBUG\n    /// Verify invariants about the SCC.\n    ///\n    /// This will attempt to validate all of the basic invariants within an\n    /// SCC, but not that it is a strongly connected componet per-se. Primarily\n    /// useful while building and updating the graph to check that basic\n    /// properties are in place rather than having inexplicable crashes later.\n    void verify();\n#endif\n\n  public:\n    using iterator = pointee_iterator<SmallVectorImpl<Node *>::const_iterator>;\n\n    iterator begin() const { return Nodes.begin(); }\n    iterator end() const { return Nodes.end(); }\n\n    int size() const { return Nodes.size(); }\n\n    RefSCC &getOuterRefSCC() const { return *OuterRefSCC; }\n\n    /// Test if this SCC is a parent of \\a C.\n    ///\n    /// Note that this is linear in the number of edges departing the current\n    /// SCC.\n    bool isParentOf(const SCC &C) const;\n\n    /// Test if this SCC is an ancestor of \\a C.\n    ///\n    /// Note that in the worst case this is linear in the number of edges\n    /// departing the current SCC and every SCC in the entire graph reachable\n    /// from this SCC. Thus this very well may walk every edge in the entire\n    /// call graph! Do not call this in a tight loop!\n    bool isAncestorOf(const SCC &C) const;\n\n    /// Test if this SCC is a child of \\a C.\n    ///\n    /// See the comments for \\c isParentOf for detailed notes about the\n    /// complexity of this routine.\n    bool isChildOf(const SCC &C) const { return C.isParentOf(*this); }\n\n    /// Test if this SCC is a descendant of \\a C.\n    ///\n    /// See the comments for \\c isParentOf for detailed notes about the\n    /// complexity of this routine.\n    bool isDescendantOf(const SCC &C) const { return C.isAncestorOf(*this); }\n\n    /// Provide a short name by printing this SCC to a std::string.\n    ///\n    /// This copes with the fact that we don't have a name per-se for an SCC\n    /// while still making the use of this in debugging and logging useful.\n    std::string getName() const {\n      std::string Name;\n      raw_string_ostream OS(Name);\n      OS << *this;\n      OS.flush();\n      return Name;\n    }\n  };\n\n  /// A RefSCC of the call graph.\n  ///\n  /// This models a Strongly Connected Component of function reference edges in\n  /// the call graph. As opposed to actual SCCs, these can be used to scope\n  /// subgraphs of the module which are independent from other subgraphs of the\n  /// module because they do not reference it in any way. This is also the unit\n  /// where we do mutation of the graph in order to restrict mutations to those\n  /// which don't violate this independence.\n  ///\n  /// A RefSCC contains a DAG of actual SCCs. All the nodes within the RefSCC\n  /// are necessarily within some actual SCC that nests within it. Since\n  /// a direct call *is* a reference, there will always be at least one RefSCC\n  /// around any SCC.\n  class RefSCC {\n    friend class LazyCallGraph;\n    friend class LazyCallGraph::Node;\n\n    LazyCallGraph *G;\n\n    /// A postorder list of the inner SCCs.\n    SmallVector<SCC *, 4> SCCs;\n\n    /// A map from SCC to index in the postorder list.\n    SmallDenseMap<SCC *, int, 4> SCCIndices;\n\n    /// Fast-path constructor. RefSCCs should instead be constructed by calling\n    /// formRefSCCFast on the graph itself.\n    RefSCC(LazyCallGraph &G);\n\n    void clear() {\n      SCCs.clear();\n      SCCIndices.clear();\n    }\n\n    /// Print a short description useful for debugging or logging.\n    ///\n    /// We print the SCCs wrapped in '[]'s and skipping the middle SCCs if\n    /// there are a large number.\n    //\n    // Note: this is defined inline to dodge issues with GCC's interpretation\n    // of enclosing namespaces for friend function declarations.\n    friend raw_ostream &operator<<(raw_ostream &OS, const RefSCC &RC) {\n      OS << '[';\n      int i = 0;\n      for (LazyCallGraph::SCC &C : RC) {\n        if (i > 0)\n          OS << \", \";\n        // Elide the inner elements if there are too many.\n        if (i > 4) {\n          OS << \"..., \" << *RC.SCCs.back();\n          break;\n        }\n        OS << C;\n        ++i;\n      }\n      OS << ']';\n      return OS;\n    }\n\n    /// Dump a short description of this RefSCC to stderr.\n    void dump() const;\n\n#ifndef NDEBUG\n    /// Verify invariants about the RefSCC and all its SCCs.\n    ///\n    /// This will attempt to validate all of the invariants *within* the\n    /// RefSCC, but not that it is a strongly connected component of the larger\n    /// graph. This makes it useful even when partially through an update.\n    ///\n    /// Invariants checked:\n    /// - SCCs and their indices match.\n    /// - The SCCs list is in fact in post-order.\n    void verify();\n#endif\n\n  public:\n    using iterator = pointee_iterator<SmallVectorImpl<SCC *>::const_iterator>;\n    using range = iterator_range<iterator>;\n    using parent_iterator =\n        pointee_iterator<SmallPtrSetImpl<RefSCC *>::const_iterator>;\n\n    iterator begin() const { return SCCs.begin(); }\n    iterator end() const { return SCCs.end(); }\n\n    ssize_t size() const { return SCCs.size(); }\n\n    SCC &operator[](int Idx) { return *SCCs[Idx]; }\n\n    iterator find(SCC &C) const {\n      return SCCs.begin() + SCCIndices.find(&C)->second;\n    }\n\n    /// Test if this RefSCC is a parent of \\a RC.\n    ///\n    /// CAUTION: This method walks every edge in the \\c RefSCC, it can be very\n    /// expensive.\n    bool isParentOf(const RefSCC &RC) const;\n\n    /// Test if this RefSCC is an ancestor of \\a RC.\n    ///\n    /// CAUTION: This method walks the directed graph of edges as far as\n    /// necessary to find a possible path to the argument. In the worst case\n    /// this may walk the entire graph and can be extremely expensive.\n    bool isAncestorOf(const RefSCC &RC) const;\n\n    /// Test if this RefSCC is a child of \\a RC.\n    ///\n    /// CAUTION: This method walks every edge in the argument \\c RefSCC, it can\n    /// be very expensive.\n    bool isChildOf(const RefSCC &RC) const { return RC.isParentOf(*this); }\n\n    /// Test if this RefSCC is a descendant of \\a RC.\n    ///\n    /// CAUTION: This method walks the directed graph of edges as far as\n    /// necessary to find a possible path from the argument. In the worst case\n    /// this may walk the entire graph and can be extremely expensive.\n    bool isDescendantOf(const RefSCC &RC) const {\n      return RC.isAncestorOf(*this);\n    }\n\n    /// Provide a short name by printing this RefSCC to a std::string.\n    ///\n    /// This copes with the fact that we don't have a name per-se for an RefSCC\n    /// while still making the use of this in debugging and logging useful.\n    std::string getName() const {\n      std::string Name;\n      raw_string_ostream OS(Name);\n      OS << *this;\n      OS.flush();\n      return Name;\n    }\n\n    ///@{\n    /// \\name Mutation API\n    ///\n    /// These methods provide the core API for updating the call graph in the\n    /// presence of (potentially still in-flight) DFS-found RefSCCs and SCCs.\n    ///\n    /// Note that these methods sometimes have complex runtimes, so be careful\n    /// how you call them.\n\n    /// Make an existing internal ref edge into a call edge.\n    ///\n    /// This may form a larger cycle and thus collapse SCCs into TargetN's SCC.\n    /// If that happens, the optional callback \\p MergedCB will be invoked (if\n    /// provided) on the SCCs being merged away prior to actually performing\n    /// the merge. Note that this will never include the target SCC as that\n    /// will be the SCC functions are merged into to resolve the cycle. Once\n    /// this function returns, these merged SCCs are not in a valid state but\n    /// the pointers will remain valid until destruction of the parent graph\n    /// instance for the purpose of clearing cached information. This function\n    /// also returns 'true' if a cycle was formed and some SCCs merged away as\n    /// a convenience.\n    ///\n    /// After this operation, both SourceN's SCC and TargetN's SCC may move\n    /// position within this RefSCC's postorder list. Any SCCs merged are\n    /// merged into the TargetN's SCC in order to preserve reachability analyses\n    /// which took place on that SCC.\n    bool switchInternalEdgeToCall(\n        Node &SourceN, Node &TargetN,\n        function_ref<void(ArrayRef<SCC *> MergedSCCs)> MergeCB = {});\n\n    /// Make an existing internal call edge between separate SCCs into a ref\n    /// edge.\n    ///\n    /// If SourceN and TargetN in separate SCCs within this RefSCC, changing\n    /// the call edge between them to a ref edge is a trivial operation that\n    /// does not require any structural changes to the call graph.\n    void switchTrivialInternalEdgeToRef(Node &SourceN, Node &TargetN);\n\n    /// Make an existing internal call edge within a single SCC into a ref\n    /// edge.\n    ///\n    /// Since SourceN and TargetN are part of a single SCC, this SCC may be\n    /// split up due to breaking a cycle in the call edges that formed it. If\n    /// that happens, then this routine will insert new SCCs into the postorder\n    /// list *before* the SCC of TargetN (previously the SCC of both). This\n    /// preserves postorder as the TargetN can reach all of the other nodes by\n    /// definition of previously being in a single SCC formed by the cycle from\n    /// SourceN to TargetN.\n    ///\n    /// The newly added SCCs are added *immediately* and contiguously\n    /// prior to the TargetN SCC and return the range covering the new SCCs in\n    /// the RefSCC's postorder sequence. You can directly iterate the returned\n    /// range to observe all of the new SCCs in postorder.\n    ///\n    /// Note that if SourceN and TargetN are in separate SCCs, the simpler\n    /// routine `switchTrivialInternalEdgeToRef` should be used instead.\n    iterator_range<iterator> switchInternalEdgeToRef(Node &SourceN,\n                                                     Node &TargetN);\n\n    /// Make an existing outgoing ref edge into a call edge.\n    ///\n    /// Note that this is trivial as there are no cyclic impacts and there\n    /// remains a reference edge.\n    void switchOutgoingEdgeToCall(Node &SourceN, Node &TargetN);\n\n    /// Make an existing outgoing call edge into a ref edge.\n    ///\n    /// This is trivial as there are no cyclic impacts and there remains\n    /// a reference edge.\n    void switchOutgoingEdgeToRef(Node &SourceN, Node &TargetN);\n\n    /// Insert a ref edge from one node in this RefSCC to another in this\n    /// RefSCC.\n    ///\n    /// This is always a trivial operation as it doesn't change any part of the\n    /// graph structure besides connecting the two nodes.\n    ///\n    /// Note that we don't support directly inserting internal *call* edges\n    /// because that could change the graph structure and requires returning\n    /// information about what became invalid. As a consequence, the pattern\n    /// should be to first insert the necessary ref edge, and then to switch it\n    /// to a call edge if needed and handle any invalidation that results. See\n    /// the \\c switchInternalEdgeToCall routine for details.\n    void insertInternalRefEdge(Node &SourceN, Node &TargetN);\n\n    /// Insert an edge whose parent is in this RefSCC and child is in some\n    /// child RefSCC.\n    ///\n    /// There must be an existing path from the \\p SourceN to the \\p TargetN.\n    /// This operation is inexpensive and does not change the set of SCCs and\n    /// RefSCCs in the graph.\n    void insertOutgoingEdge(Node &SourceN, Node &TargetN, Edge::Kind EK);\n\n    /// Insert an edge whose source is in a descendant RefSCC and target is in\n    /// this RefSCC.\n    ///\n    /// There must be an existing path from the target to the source in this\n    /// case.\n    ///\n    /// NB! This is has the potential to be a very expensive function. It\n    /// inherently forms a cycle in the prior RefSCC DAG and we have to merge\n    /// RefSCCs to resolve that cycle. But finding all of the RefSCCs which\n    /// participate in the cycle can in the worst case require traversing every\n    /// RefSCC in the graph. Every attempt is made to avoid that, but passes\n    /// must still exercise caution calling this routine repeatedly.\n    ///\n    /// Also note that this can only insert ref edges. In order to insert\n    /// a call edge, first insert a ref edge and then switch it to a call edge.\n    /// These are intentionally kept as separate interfaces because each step\n    /// of the operation invalidates a different set of data structures.\n    ///\n    /// This returns all the RefSCCs which were merged into the this RefSCC\n    /// (the target's). This allows callers to invalidate any cached\n    /// information.\n    ///\n    /// FIXME: We could possibly optimize this quite a bit for cases where the\n    /// caller and callee are very nearby in the graph. See comments in the\n    /// implementation for details, but that use case might impact users.\n    SmallVector<RefSCC *, 1> insertIncomingRefEdge(Node &SourceN,\n                                                   Node &TargetN);\n\n    /// Remove an edge whose source is in this RefSCC and target is *not*.\n    ///\n    /// This removes an inter-RefSCC edge. All inter-RefSCC edges originating\n    /// from this SCC have been fully explored by any in-flight DFS graph\n    /// formation, so this is always safe to call once you have the source\n    /// RefSCC.\n    ///\n    /// This operation does not change the cyclic structure of the graph and so\n    /// is very inexpensive. It may change the connectivity graph of the SCCs\n    /// though, so be careful calling this while iterating over them.\n    void removeOutgoingEdge(Node &SourceN, Node &TargetN);\n\n    /// Remove a list of ref edges which are entirely within this RefSCC.\n    ///\n    /// Both the \\a SourceN and all of the \\a TargetNs must be within this\n    /// RefSCC. Removing these edges may break cycles that form this RefSCC and\n    /// thus this operation may change the RefSCC graph significantly. In\n    /// particular, this operation will re-form new RefSCCs based on the\n    /// remaining connectivity of the graph. The following invariants are\n    /// guaranteed to hold after calling this method:\n    ///\n    /// 1) If a ref-cycle remains after removal, it leaves this RefSCC intact\n    ///    and in the graph. No new RefSCCs are built.\n    /// 2) Otherwise, this RefSCC will be dead after this call and no longer in\n    ///    the graph or the postorder traversal of the call graph. Any iterator\n    ///    pointing at this RefSCC will become invalid.\n    /// 3) All newly formed RefSCCs will be returned and the order of the\n    ///    RefSCCs returned will be a valid postorder traversal of the new\n    ///    RefSCCs.\n    /// 4) No RefSCC other than this RefSCC has its member set changed (this is\n    ///    inherent in the definition of removing such an edge).\n    ///\n    /// These invariants are very important to ensure that we can build\n    /// optimization pipelines on top of the CGSCC pass manager which\n    /// intelligently update the RefSCC graph without invalidating other parts\n    /// of the RefSCC graph.\n    ///\n    /// Note that we provide no routine to remove a *call* edge. Instead, you\n    /// must first switch it to a ref edge using \\c switchInternalEdgeToRef.\n    /// This split API is intentional as each of these two steps can invalidate\n    /// a different aspect of the graph structure and needs to have the\n    /// invalidation handled independently.\n    ///\n    /// The runtime complexity of this method is, in the worst case, O(V+E)\n    /// where V is the number of nodes in this RefSCC and E is the number of\n    /// edges leaving the nodes in this RefSCC. Note that E includes both edges\n    /// within this RefSCC and edges from this RefSCC to child RefSCCs. Some\n    /// effort has been made to minimize the overhead of common cases such as\n    /// self-edges and edge removals which result in a spanning tree with no\n    /// more cycles.\n    SmallVector<RefSCC *, 1> removeInternalRefEdge(Node &SourceN,\n                                                   ArrayRef<Node *> TargetNs);\n\n    /// A convenience wrapper around the above to handle trivial cases of\n    /// inserting a new call edge.\n    ///\n    /// This is trivial whenever the target is in the same SCC as the source or\n    /// the edge is an outgoing edge to some descendant SCC. In these cases\n    /// there is no change to the cyclic structure of SCCs or RefSCCs.\n    ///\n    /// To further make calling this convenient, it also handles inserting\n    /// already existing edges.\n    void insertTrivialCallEdge(Node &SourceN, Node &TargetN);\n\n    /// A convenience wrapper around the above to handle trivial cases of\n    /// inserting a new ref edge.\n    ///\n    /// This is trivial whenever the target is in the same RefSCC as the source\n    /// or the edge is an outgoing edge to some descendant RefSCC. In these\n    /// cases there is no change to the cyclic structure of the RefSCCs.\n    ///\n    /// To further make calling this convenient, it also handles inserting\n    /// already existing edges.\n    void insertTrivialRefEdge(Node &SourceN, Node &TargetN);\n\n    /// Directly replace a node's function with a new function.\n    ///\n    /// This should be used when moving the body and users of a function to\n    /// a new formal function object but not otherwise changing the call graph\n    /// structure in any way.\n    ///\n    /// It requires that the old function in the provided node have zero uses\n    /// and the new function must have calls and references to it establishing\n    /// an equivalent graph.\n    void replaceNodeFunction(Node &N, Function &NewF);\n\n    ///@}\n  };\n\n  /// A post-order depth-first RefSCC iterator over the call graph.\n  ///\n  /// This iterator walks the cached post-order sequence of RefSCCs. However,\n  /// it trades stability for flexibility. It is restricted to a forward\n  /// iterator but will survive mutations which insert new RefSCCs and continue\n  /// to point to the same RefSCC even if it moves in the post-order sequence.\n  class postorder_ref_scc_iterator\n      : public iterator_facade_base<postorder_ref_scc_iterator,\n                                    std::forward_iterator_tag, RefSCC> {\n    friend class LazyCallGraph;\n    friend class LazyCallGraph::Node;\n\n    /// Nonce type to select the constructor for the end iterator.\n    struct IsAtEndT {};\n\n    LazyCallGraph *G;\n    RefSCC *RC = nullptr;\n\n    /// Build the begin iterator for a node.\n    postorder_ref_scc_iterator(LazyCallGraph &G) : G(&G), RC(getRC(G, 0)) {}\n\n    /// Build the end iterator for a node. This is selected purely by overload.\n    postorder_ref_scc_iterator(LazyCallGraph &G, IsAtEndT /*Nonce*/) : G(&G) {}\n\n    /// Get the post-order RefSCC at the given index of the postorder walk,\n    /// populating it if necessary.\n    static RefSCC *getRC(LazyCallGraph &G, int Index) {\n      if (Index == (int)G.PostOrderRefSCCs.size())\n        // We're at the end.\n        return nullptr;\n\n      return G.PostOrderRefSCCs[Index];\n    }\n\n  public:\n    bool operator==(const postorder_ref_scc_iterator &Arg) const {\n      return G == Arg.G && RC == Arg.RC;\n    }\n\n    reference operator*() const { return *RC; }\n\n    using iterator_facade_base::operator++;\n    postorder_ref_scc_iterator &operator++() {\n      assert(RC && \"Cannot increment the end iterator!\");\n      RC = getRC(*G, G->RefSCCIndices.find(RC)->second + 1);\n      return *this;\n    }\n  };\n\n  /// Construct a graph for the given module.\n  ///\n  /// This sets up the graph and computes all of the entry points of the graph.\n  /// No function definitions are scanned until their nodes in the graph are\n  /// requested during traversal.\n  LazyCallGraph(Module &M,\n                function_ref<TargetLibraryInfo &(Function &)> GetTLI);\n\n  LazyCallGraph(LazyCallGraph &&G);\n  LazyCallGraph &operator=(LazyCallGraph &&RHS);\n\n  bool invalidate(Module &, const PreservedAnalyses &PA,\n                  ModuleAnalysisManager::Invalidator &);\n\n  EdgeSequence::iterator begin() { return EntryEdges.begin(); }\n  EdgeSequence::iterator end() { return EntryEdges.end(); }\n\n  void buildRefSCCs();\n\n  postorder_ref_scc_iterator postorder_ref_scc_begin() {\n    if (!EntryEdges.empty())\n      assert(!PostOrderRefSCCs.empty() &&\n             \"Must form RefSCCs before iterating them!\");\n    return postorder_ref_scc_iterator(*this);\n  }\n  postorder_ref_scc_iterator postorder_ref_scc_end() {\n    if (!EntryEdges.empty())\n      assert(!PostOrderRefSCCs.empty() &&\n             \"Must form RefSCCs before iterating them!\");\n    return postorder_ref_scc_iterator(*this,\n                                      postorder_ref_scc_iterator::IsAtEndT());\n  }\n\n  iterator_range<postorder_ref_scc_iterator> postorder_ref_sccs() {\n    return make_range(postorder_ref_scc_begin(), postorder_ref_scc_end());\n  }\n\n  /// Lookup a function in the graph which has already been scanned and added.\n  Node *lookup(const Function &F) const { return NodeMap.lookup(&F); }\n\n  /// Lookup a function's SCC in the graph.\n  ///\n  /// \\returns null if the function hasn't been assigned an SCC via the RefSCC\n  /// iterator walk.\n  SCC *lookupSCC(Node &N) const { return SCCMap.lookup(&N); }\n\n  /// Lookup a function's RefSCC in the graph.\n  ///\n  /// \\returns null if the function hasn't been assigned a RefSCC via the\n  /// RefSCC iterator walk.\n  RefSCC *lookupRefSCC(Node &N) const {\n    if (SCC *C = lookupSCC(N))\n      return &C->getOuterRefSCC();\n\n    return nullptr;\n  }\n\n  /// Get a graph node for a given function, scanning it to populate the graph\n  /// data as necessary.\n  Node &get(Function &F) {\n    Node *&N = NodeMap[&F];\n    if (N)\n      return *N;\n\n    return insertInto(F, N);\n  }\n\n  /// Get the sequence of known and defined library functions.\n  ///\n  /// These functions, because they are known to LLVM, can have calls\n  /// introduced out of thin air from arbitrary IR.\n  ArrayRef<Function *> getLibFunctions() const {\n    return LibFunctions.getArrayRef();\n  }\n\n  /// Test whether a function is a known and defined library function tracked by\n  /// the call graph.\n  ///\n  /// Because these functions are known to LLVM they are specially modeled in\n  /// the call graph and even when all IR-level references have been removed\n  /// remain active and reachable.\n  bool isLibFunction(Function &F) const { return LibFunctions.count(&F); }\n\n  ///@{\n  /// \\name Pre-SCC Mutation API\n  ///\n  /// These methods are only valid to call prior to forming any SCCs for this\n  /// call graph. They can be used to update the core node-graph during\n  /// a node-based inorder traversal that precedes any SCC-based traversal.\n  ///\n  /// Once you begin manipulating a call graph's SCCs, most mutation of the\n  /// graph must be performed via a RefSCC method. There are some exceptions\n  /// below.\n\n  /// Update the call graph after inserting a new edge.\n  void insertEdge(Node &SourceN, Node &TargetN, Edge::Kind EK);\n\n  /// Update the call graph after inserting a new edge.\n  void insertEdge(Function &Source, Function &Target, Edge::Kind EK) {\n    return insertEdge(get(Source), get(Target), EK);\n  }\n\n  /// Update the call graph after deleting an edge.\n  void removeEdge(Node &SourceN, Node &TargetN);\n\n  /// Update the call graph after deleting an edge.\n  void removeEdge(Function &Source, Function &Target) {\n    return removeEdge(get(Source), get(Target));\n  }\n\n  ///@}\n\n  ///@{\n  /// \\name General Mutation API\n  ///\n  /// There are a very limited set of mutations allowed on the graph as a whole\n  /// once SCCs have started to be formed. These routines have strict contracts\n  /// but may be called at any point.\n\n  /// Remove a dead function from the call graph (typically to delete it).\n  ///\n  /// Note that the function must have an empty use list, and the call graph\n  /// must be up-to-date prior to calling this. That means it is by itself in\n  /// a maximal SCC which is by itself in a maximal RefSCC, etc. No structural\n  /// changes result from calling this routine other than potentially removing\n  /// entry points into the call graph.\n  ///\n  /// If SCC formation has begun, this function must not be part of the current\n  /// DFS in order to call this safely. Typically, the function will have been\n  /// fully visited by the DFS prior to calling this routine.\n  void removeDeadFunction(Function &F);\n\n  /// Add a new function split/outlined from an existing function.\n  ///\n  /// The new function may only reference other functions that the original\n  /// function did.\n  ///\n  /// The original function must reference (either directly or indirectly) the\n  /// new function.\n  ///\n  /// The new function may also reference the original function.\n  /// It may end up in a parent SCC in the case that the original function's\n  /// edge to the new function is a ref edge, and the edge back is a call edge.\n  void addSplitFunction(Function &OriginalFunction, Function &NewFunction);\n\n  /// Add new ref-recursive functions split/outlined from an existing function.\n  ///\n  /// The new functions may only reference other functions that the original\n  /// function did. The new functions may reference (not call) the original\n  /// function.\n  ///\n  /// The original function must reference (not call) all new functions.\n  /// All new functions must reference (not call) each other.\n  void addSplitRefRecursiveFunctions(Function &OriginalFunction,\n                                     ArrayRef<Function *> NewFunctions);\n\n  ///@}\n\n  ///@{\n  /// \\name Static helpers for code doing updates to the call graph.\n  ///\n  /// These helpers are used to implement parts of the call graph but are also\n  /// useful to code doing updates or otherwise wanting to walk the IR in the\n  /// same patterns as when we build the call graph.\n\n  /// Recursively visits the defined functions whose address is reachable from\n  /// every constant in the \\p Worklist.\n  ///\n  /// Doesn't recurse through any constants already in the \\p Visited set, and\n  /// updates that set with every constant visited.\n  ///\n  /// For each defined function, calls \\p Callback with that function.\n  template <typename CallbackT>\n  static void visitReferences(SmallVectorImpl<Constant *> &Worklist,\n                              SmallPtrSetImpl<Constant *> &Visited,\n                              CallbackT Callback) {\n    while (!Worklist.empty()) {\n      Constant *C = Worklist.pop_back_val();\n\n      if (Function *F = dyn_cast<Function>(C)) {\n        if (!F->isDeclaration())\n          Callback(*F);\n        continue;\n      }\n\n      // The blockaddress constant expression is a weird special case, we can't\n      // generically walk its operands the way we do for all other constants.\n      if (BlockAddress *BA = dyn_cast<BlockAddress>(C)) {\n        // If we've already visited the function referred to by the block\n        // address, we don't need to revisit it.\n        if (Visited.count(BA->getFunction()))\n          continue;\n\n        // If all of the blockaddress' users are instructions within the\n        // referred to function, we don't need to insert a cycle.\n        if (llvm::all_of(BA->users(), [&](User *U) {\n              if (Instruction *I = dyn_cast<Instruction>(U))\n                return I->getFunction() == BA->getFunction();\n              return false;\n            }))\n          continue;\n\n        // Otherwise we should go visit the referred to function.\n        Visited.insert(BA->getFunction());\n        Worklist.push_back(BA->getFunction());\n        continue;\n      }\n\n      for (Value *Op : C->operand_values())\n        if (Visited.insert(cast<Constant>(Op)).second)\n          Worklist.push_back(cast<Constant>(Op));\n    }\n  }\n\n  ///@}\n\nprivate:\n  using node_stack_iterator = SmallVectorImpl<Node *>::reverse_iterator;\n  using node_stack_range = iterator_range<node_stack_iterator>;\n\n  /// Allocator that holds all the call graph nodes.\n  SpecificBumpPtrAllocator<Node> BPA;\n\n  /// Maps function->node for fast lookup.\n  DenseMap<const Function *, Node *> NodeMap;\n\n  /// The entry edges into the graph.\n  ///\n  /// These edges are from \"external\" sources. Put another way, they\n  /// escape at the module scope.\n  EdgeSequence EntryEdges;\n\n  /// Allocator that holds all the call graph SCCs.\n  SpecificBumpPtrAllocator<SCC> SCCBPA;\n\n  /// Maps Function -> SCC for fast lookup.\n  DenseMap<Node *, SCC *> SCCMap;\n\n  /// Allocator that holds all the call graph RefSCCs.\n  SpecificBumpPtrAllocator<RefSCC> RefSCCBPA;\n\n  /// The post-order sequence of RefSCCs.\n  ///\n  /// This list is lazily formed the first time we walk the graph.\n  SmallVector<RefSCC *, 16> PostOrderRefSCCs;\n\n  /// A map from RefSCC to the index for it in the postorder sequence of\n  /// RefSCCs.\n  DenseMap<RefSCC *, int> RefSCCIndices;\n\n  /// Defined functions that are also known library functions which the\n  /// optimizer can reason about and therefore might introduce calls to out of\n  /// thin air.\n  SmallSetVector<Function *, 4> LibFunctions;\n\n  /// Helper to insert a new function, with an already looked-up entry in\n  /// the NodeMap.\n  Node &insertInto(Function &F, Node *&MappedN);\n\n  /// Helper to initialize a new node created outside of creating SCCs and add\n  /// it to the NodeMap if necessary. For example, useful when a function is\n  /// split.\n  Node &initNode(Function &F);\n\n  /// Helper to update pointers back to the graph object during moves.\n  void updateGraphPtrs();\n\n  /// Allocates an SCC and constructs it using the graph allocator.\n  ///\n  /// The arguments are forwarded to the constructor.\n  template <typename... Ts> SCC *createSCC(Ts &&... Args) {\n    return new (SCCBPA.Allocate()) SCC(std::forward<Ts>(Args)...);\n  }\n\n  /// Allocates a RefSCC and constructs it using the graph allocator.\n  ///\n  /// The arguments are forwarded to the constructor.\n  template <typename... Ts> RefSCC *createRefSCC(Ts &&... Args) {\n    return new (RefSCCBPA.Allocate()) RefSCC(std::forward<Ts>(Args)...);\n  }\n\n  /// Common logic for building SCCs from a sequence of roots.\n  ///\n  /// This is a very generic implementation of the depth-first walk and SCC\n  /// formation algorithm. It uses a generic sequence of roots and generic\n  /// callbacks for each step. This is designed to be used to implement both\n  /// the RefSCC formation and SCC formation with shared logic.\n  ///\n  /// Currently this is a relatively naive implementation of Tarjan's DFS\n  /// algorithm to form the SCCs.\n  ///\n  /// FIXME: We should consider newer variants such as Nuutila.\n  template <typename RootsT, typename GetBeginT, typename GetEndT,\n            typename GetNodeT, typename FormSCCCallbackT>\n  static void buildGenericSCCs(RootsT &&Roots, GetBeginT &&GetBegin,\n                               GetEndT &&GetEnd, GetNodeT &&GetNode,\n                               FormSCCCallbackT &&FormSCC);\n\n  /// Build the SCCs for a RefSCC out of a list of nodes.\n  void buildSCCs(RefSCC &RC, node_stack_range Nodes);\n\n  /// Get the index of a RefSCC within the postorder traversal.\n  ///\n  /// Requires that this RefSCC is a valid one in the (perhaps partial)\n  /// postorder traversed part of the graph.\n  int getRefSCCIndex(RefSCC &RC) {\n    auto IndexIt = RefSCCIndices.find(&RC);\n    assert(IndexIt != RefSCCIndices.end() && \"RefSCC doesn't have an index!\");\n    assert(PostOrderRefSCCs[IndexIt->second] == &RC &&\n           \"Index does not point back at RC!\");\n    return IndexIt->second;\n  }\n};\n\ninline LazyCallGraph::Edge::Edge() : Value() {}\ninline LazyCallGraph::Edge::Edge(Node &N, Kind K) : Value(&N, K) {}\n\ninline LazyCallGraph::Edge::operator bool() const {\n  return Value.getPointer() && !Value.getPointer()->isDead();\n}\n\ninline LazyCallGraph::Edge::Kind LazyCallGraph::Edge::getKind() const {\n  assert(*this && \"Queried a null edge!\");\n  return Value.getInt();\n}\n\ninline bool LazyCallGraph::Edge::isCall() const {\n  assert(*this && \"Queried a null edge!\");\n  return getKind() == Call;\n}\n\ninline LazyCallGraph::Node &LazyCallGraph::Edge::getNode() const {\n  assert(*this && \"Queried a null edge!\");\n  return *Value.getPointer();\n}\n\ninline Function &LazyCallGraph::Edge::getFunction() const {\n  assert(*this && \"Queried a null edge!\");\n  return getNode().getFunction();\n}\n\n// Provide GraphTraits specializations for call graphs.\ntemplate <> struct GraphTraits<LazyCallGraph::Node *> {\n  using NodeRef = LazyCallGraph::Node *;\n  using ChildIteratorType = LazyCallGraph::EdgeSequence::iterator;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) { return (*N)->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return (*N)->end(); }\n};\ntemplate <> struct GraphTraits<LazyCallGraph *> {\n  using NodeRef = LazyCallGraph::Node *;\n  using ChildIteratorType = LazyCallGraph::EdgeSequence::iterator;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) { return (*N)->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return (*N)->end(); }\n};\n\n/// An analysis pass which computes the call graph for a module.\nclass LazyCallGraphAnalysis : public AnalysisInfoMixin<LazyCallGraphAnalysis> {\n  friend AnalysisInfoMixin<LazyCallGraphAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// Inform generic clients of the result type.\n  using Result = LazyCallGraph;\n\n  /// Compute the \\c LazyCallGraph for the module \\c M.\n  ///\n  /// This just builds the set of entry points to the call graph. The rest is\n  /// built lazily as it is walked.\n  LazyCallGraph run(Module &M, ModuleAnalysisManager &AM) {\n    FunctionAnalysisManager &FAM =\n        AM.getResult<FunctionAnalysisManagerModuleProxy>(M).getManager();\n    auto GetTLI = [&FAM](Function &F) -> TargetLibraryInfo & {\n      return FAM.getResult<TargetLibraryAnalysis>(F);\n    };\n    return LazyCallGraph(M, GetTLI);\n  }\n};\n\n/// A pass which prints the call graph to a \\c raw_ostream.\n///\n/// This is primarily useful for testing the analysis.\nclass LazyCallGraphPrinterPass\n    : public PassInfoMixin<LazyCallGraphPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit LazyCallGraphPrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// A pass which prints the call graph as a DOT file to a \\c raw_ostream.\n///\n/// This is primarily useful for visualization purposes.\nclass LazyCallGraphDOTPrinterPass\n    : public PassInfoMixin<LazyCallGraphDOTPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit LazyCallGraphDOTPrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_LAZYCALLGRAPH_H\n"}, "45": {"id": 45, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LazyValueInfo.h", "content": "//===- LazyValueInfo.h - Value constraint analysis --------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the interface for lazy computation of value constraint\n// information.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_LAZYVALUEINFO_H\n#define LLVM_ANALYSIS_LAZYVALUEINFO_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n  class AssumptionCache;\n  class Constant;\n  class ConstantRange;\n  class DataLayout;\n  class DominatorTree;\n  class Instruction;\n  class TargetLibraryInfo;\n  class Value;\n\n/// This pass computes, caches, and vends lazy value constraint information.\nclass LazyValueInfo {\n  friend class LazyValueInfoWrapperPass;\n  AssumptionCache *AC = nullptr;\n  const DataLayout *DL = nullptr;\n  class TargetLibraryInfo *TLI = nullptr;\n  void *PImpl = nullptr;\n  LazyValueInfo(const LazyValueInfo&) = delete;\n  void operator=(const LazyValueInfo&) = delete;\npublic:\n  ~LazyValueInfo();\n  LazyValueInfo() {}\n  LazyValueInfo(AssumptionCache *AC_, const DataLayout *DL_,\n                TargetLibraryInfo *TLI_)\n      : AC(AC_), DL(DL_), TLI(TLI_) {}\n  LazyValueInfo(LazyValueInfo &&Arg)\n      : AC(Arg.AC), DL(Arg.DL), TLI(Arg.TLI), PImpl(Arg.PImpl) {\n    Arg.PImpl = nullptr;\n  }\n  LazyValueInfo &operator=(LazyValueInfo &&Arg) {\n    releaseMemory();\n    AC = Arg.AC;\n    DL = Arg.DL;\n    TLI = Arg.TLI;\n    PImpl = Arg.PImpl;\n    Arg.PImpl = nullptr;\n    return *this;\n  }\n\n  /// This is used to return true/false/dunno results.\n  enum Tristate {\n    Unknown = -1, False = 0, True = 1\n  };\n\n  // Public query interface.\n\n  /// Determine whether the specified value comparison with a constant is known\n  /// to be true or false on the specified CFG edge.\n  /// Pred is a CmpInst predicate.\n  Tristate getPredicateOnEdge(unsigned Pred, Value *V, Constant *C,\n                              BasicBlock *FromBB, BasicBlock *ToBB,\n                              Instruction *CxtI = nullptr);\n\n  /// Determine whether the specified value comparison with a constant is known\n  /// to be true or false at the specified instruction.\n  /// \\p Pred is a CmpInst predicate. If \\p UseBlockValue is true, the block\n  /// value is also taken into account.\n  Tristate getPredicateAt(unsigned Pred, Value *V, Constant *C,\n                          Instruction *CxtI, bool UseBlockValue = false);\n\n  /// Determine whether the specified value is known to be a constant at the\n  /// specified instruction. Return null if not.\n  Constant *getConstant(Value *V, Instruction *CxtI);\n\n  /// Return the ConstantRange constraint that is known to hold for the\n  /// specified value at the specified instruction. This may only be called\n  /// on integer-typed Values.\n  ConstantRange getConstantRange(Value *V, Instruction *CxtI,\n                                 bool UndefAllowed = true);\n\n  /// Determine whether the specified value is known to be a\n  /// constant on the specified edge.  Return null if not.\n  Constant *getConstantOnEdge(Value *V, BasicBlock *FromBB, BasicBlock *ToBB,\n                              Instruction *CxtI = nullptr);\n\n  /// Return the ConstantRage constraint that is known to hold for the\n  /// specified value on the specified edge. This may be only be called\n  /// on integer-typed Values.\n  ConstantRange getConstantRangeOnEdge(Value *V, BasicBlock *FromBB,\n                                       BasicBlock *ToBB,\n                                       Instruction *CxtI = nullptr);\n\n  /// Inform the analysis cache that we have threaded an edge from\n  /// PredBB to OldSucc to be from PredBB to NewSucc instead.\n  void threadEdge(BasicBlock *PredBB, BasicBlock *OldSucc, BasicBlock *NewSucc);\n\n  /// Inform the analysis cache that we have erased a block.\n  void eraseBlock(BasicBlock *BB);\n\n  /// Print the \\LazyValueInfo Analysis.\n  /// We pass in the DTree that is required for identifying which basic blocks\n  /// we can solve/print for, in the LVIPrinter.\n  void printLVI(Function &F, DominatorTree &DTree, raw_ostream &OS);\n\n  // For old PM pass. Delete once LazyValueInfoWrapperPass is gone.\n  void releaseMemory();\n\n  /// Handle invalidation events in the new pass manager.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n};\n\n/// Analysis to compute lazy value information.\nclass LazyValueAnalysis : public AnalysisInfoMixin<LazyValueAnalysis> {\npublic:\n  typedef LazyValueInfo Result;\n  Result run(Function &F, FunctionAnalysisManager &FAM);\n\nprivate:\n  static AnalysisKey Key;\n  friend struct AnalysisInfoMixin<LazyValueAnalysis>;\n};\n\n/// Wrapper around LazyValueInfo.\nclass LazyValueInfoWrapperPass : public FunctionPass {\n  LazyValueInfoWrapperPass(const LazyValueInfoWrapperPass&) = delete;\n  void operator=(const LazyValueInfoWrapperPass&) = delete;\npublic:\n  static char ID;\n  LazyValueInfoWrapperPass();\n  ~LazyValueInfoWrapperPass() override {\n    assert(!Info.PImpl && \"releaseMemory not called\");\n  }\n\n  LazyValueInfo &getLVI();\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  void releaseMemory() override;\n  bool runOnFunction(Function &F) override;\nprivate:\n  LazyValueInfo Info;\n};\n\n}  // end namespace llvm\n\n#endif\n\n"}, "46": {"id": 46, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/Lint.h", "content": "//===-- llvm/Analysis/Lint.h - LLVM IR Lint ---------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines lint interfaces that can be used for some sanity checking\n// of input to the system, and for checking that transformations\n// haven't done something bad. In contrast to the Verifier, the Lint checker\n// checks for undefined behavior or constructions with likely unintended\n// behavior.\n//\n// To see what specifically is checked, look at Lint.cpp\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_LINT_H\n#define LLVM_ANALYSIS_LINT_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass FunctionPass;\nclass Module;\nclass Function;\n\nFunctionPass *createLintLegacyPassPass();\n\n/// Lint a module.\n///\n/// This should only be used for debugging, because it plays games with\n/// PassManagers and stuff.\nvoid lintModule(const Module &M);\n\n// Lint a function.\nvoid lintFunction(const Function &F);\n\nclass LintPass : public PassInfoMixin<LintPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // namespace llvm\n\n#endif // LLVM_ANALYSIS_LINT_H\n"}, "47": {"id": 47, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopAccessAnalysis.h", "content": "//===- llvm/Analysis/LoopAccessAnalysis.h -----------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the interface for the loop memory dependence framework that\n// was originally developed for the Loop Vectorizer.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_LOOPACCESSANALYSIS_H\n#define LLVM_ANALYSIS_LOOPACCESSANALYSIS_H\n\n#include \"llvm/ADT/EquivalenceClasses.h\"\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/Analysis/ScalarEvolutionExpressions.h\"\n#include \"llvm/IR/DiagnosticInfo.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass AAResults;\nclass DataLayout;\nclass Loop;\nclass LoopAccessInfo;\nclass OptimizationRemarkEmitter;\nclass raw_ostream;\nclass SCEV;\nclass SCEVUnionPredicate;\nclass Value;\n\n/// Collection of parameters shared beetween the Loop Vectorizer and the\n/// Loop Access Analysis.\nstruct VectorizerParams {\n  /// Maximum SIMD width.\n  static const unsigned MaxVectorWidth;\n\n  /// VF as overridden by the user.\n  static unsigned VectorizationFactor;\n  /// Interleave factor as overridden by the user.\n  static unsigned VectorizationInterleave;\n  /// True if force-vector-interleave was specified by the user.\n  static bool isInterleaveForced();\n\n  /// \\When performing memory disambiguation checks at runtime do not\n  /// make more than this number of comparisons.\n  static unsigned RuntimeMemoryCheckThreshold;\n};\n\n/// Checks memory dependences among accesses to the same underlying\n/// object to determine whether there vectorization is legal or not (and at\n/// which vectorization factor).\n///\n/// Note: This class will compute a conservative dependence for access to\n/// different underlying pointers. Clients, such as the loop vectorizer, will\n/// sometimes deal these potential dependencies by emitting runtime checks.\n///\n/// We use the ScalarEvolution framework to symbolically evalutate access\n/// functions pairs. Since we currently don't restructure the loop we can rely\n/// on the program order of memory accesses to determine their safety.\n/// At the moment we will only deem accesses as safe for:\n///  * A negative constant distance assuming program order.\n///\n///      Safe: tmp = a[i + 1];     OR     a[i + 1] = x;\n///            a[i] = tmp;                y = a[i];\n///\n///   The latter case is safe because later checks guarantuee that there can't\n///   be a cycle through a phi node (that is, we check that \"x\" and \"y\" is not\n///   the same variable: a header phi can only be an induction or a reduction, a\n///   reduction can't have a memory sink, an induction can't have a memory\n///   source). This is important and must not be violated (or we have to\n///   resort to checking for cycles through memory).\n///\n///  * A positive constant distance assuming program order that is bigger\n///    than the biggest memory access.\n///\n///     tmp = a[i]        OR              b[i] = x\n///     a[i+2] = tmp                      y = b[i+2];\n///\n///     Safe distance: 2 x sizeof(a[0]), and 2 x sizeof(b[0]), respectively.\n///\n///  * Zero distances and all accesses have the same size.\n///\nclass MemoryDepChecker {\npublic:\n  typedef PointerIntPair<Value *, 1, bool> MemAccessInfo;\n  typedef SmallVector<MemAccessInfo, 8> MemAccessInfoList;\n  /// Set of potential dependent memory accesses.\n  typedef EquivalenceClasses<MemAccessInfo> DepCandidates;\n\n  /// Type to keep track of the status of the dependence check. The order of\n  /// the elements is important and has to be from most permissive to least\n  /// permissive.\n  enum class VectorizationSafetyStatus {\n    // Can vectorize safely without RT checks. All dependences are known to be\n    // safe.\n    Safe,\n    // Can possibly vectorize with RT checks to overcome unknown dependencies.\n    PossiblySafeWithRtChecks,\n    // Cannot vectorize due to known unsafe dependencies.\n    Unsafe,\n  };\n\n  /// Dependece between memory access instructions.\n  struct Dependence {\n    /// The type of the dependence.\n    enum DepType {\n      // No dependence.\n      NoDep,\n      // We couldn't determine the direction or the distance.\n      Unknown,\n      // Lexically forward.\n      //\n      // FIXME: If we only have loop-independent forward dependences (e.g. a\n      // read and write of A[i]), LAA will locally deem the dependence \"safe\"\n      // without querying the MemoryDepChecker.  Therefore we can miss\n      // enumerating loop-independent forward dependences in\n      // getDependences.  Note that as soon as there are different\n      // indices used to access the same array, the MemoryDepChecker *is*\n      // queried and the dependence list is complete.\n      Forward,\n      // Forward, but if vectorized, is likely to prevent store-to-load\n      // forwarding.\n      ForwardButPreventsForwarding,\n      // Lexically backward.\n      Backward,\n      // Backward, but the distance allows a vectorization factor of\n      // MaxSafeDepDistBytes.\n      BackwardVectorizable,\n      // Same, but may prevent store-to-load forwarding.\n      BackwardVectorizableButPreventsForwarding\n    };\n\n    /// String version of the types.\n    static const char *DepName[];\n\n    /// Index of the source of the dependence in the InstMap vector.\n    unsigned Source;\n    /// Index of the destination of the dependence in the InstMap vector.\n    unsigned Destination;\n    /// The type of the dependence.\n    DepType Type;\n\n    Dependence(unsigned Source, unsigned Destination, DepType Type)\n        : Source(Source), Destination(Destination), Type(Type) {}\n\n    /// Return the source instruction of the dependence.\n    Instruction *getSource(const LoopAccessInfo &LAI) const;\n    /// Return the destination instruction of the dependence.\n    Instruction *getDestination(const LoopAccessInfo &LAI) const;\n\n    /// Dependence types that don't prevent vectorization.\n    static VectorizationSafetyStatus isSafeForVectorization(DepType Type);\n\n    /// Lexically forward dependence.\n    bool isForward() const;\n    /// Lexically backward dependence.\n    bool isBackward() const;\n\n    /// May be a lexically backward dependence type (includes Unknown).\n    bool isPossiblyBackward() const;\n\n    /// Print the dependence.  \\p Instr is used to map the instruction\n    /// indices to instructions.\n    void print(raw_ostream &OS, unsigned Depth,\n               const SmallVectorImpl<Instruction *> &Instrs) const;\n  };\n\n  MemoryDepChecker(PredicatedScalarEvolution &PSE, const Loop *L)\n      : PSE(PSE), InnermostLoop(L), AccessIdx(0), MaxSafeDepDistBytes(0),\n        MaxSafeVectorWidthInBits(-1U),\n        FoundNonConstantDistanceDependence(false),\n        Status(VectorizationSafetyStatus::Safe), RecordDependences(true) {}\n\n  /// Register the location (instructions are given increasing numbers)\n  /// of a write access.\n  void addAccess(StoreInst *SI) {\n    Value *Ptr = SI->getPointerOperand();\n    Accesses[MemAccessInfo(Ptr, true)].push_back(AccessIdx);\n    InstMap.push_back(SI);\n    ++AccessIdx;\n  }\n\n  /// Register the location (instructions are given increasing numbers)\n  /// of a write access.\n  void addAccess(LoadInst *LI) {\n    Value *Ptr = LI->getPointerOperand();\n    Accesses[MemAccessInfo(Ptr, false)].push_back(AccessIdx);\n    InstMap.push_back(LI);\n    ++AccessIdx;\n  }\n\n  /// Check whether the dependencies between the accesses are safe.\n  ///\n  /// Only checks sets with elements in \\p CheckDeps.\n  bool areDepsSafe(DepCandidates &AccessSets, MemAccessInfoList &CheckDeps,\n                   const ValueToValueMap &Strides);\n\n  /// No memory dependence was encountered that would inhibit\n  /// vectorization.\n  bool isSafeForVectorization() const {\n    return Status == VectorizationSafetyStatus::Safe;\n  }\n\n  /// Return true if the number of elements that are safe to operate on\n  /// simultaneously is not bounded.\n  bool isSafeForAnyVectorWidth() const {\n    return MaxSafeVectorWidthInBits == UINT_MAX;\n  }\n\n  /// The maximum number of bytes of a vector register we can vectorize\n  /// the accesses safely with.\n  uint64_t getMaxSafeDepDistBytes() { return MaxSafeDepDistBytes; }\n\n  /// Return the number of elements that are safe to operate on\n  /// simultaneously, multiplied by the size of the element in bits.\n  uint64_t getMaxSafeVectorWidthInBits() const {\n    return MaxSafeVectorWidthInBits;\n  }\n\n  /// In same cases when the dependency check fails we can still\n  /// vectorize the loop with a dynamic array access check.\n  bool shouldRetryWithRuntimeCheck() const {\n    return FoundNonConstantDistanceDependence &&\n           Status == VectorizationSafetyStatus::PossiblySafeWithRtChecks;\n  }\n\n  /// Returns the memory dependences.  If null is returned we exceeded\n  /// the MaxDependences threshold and this information is not\n  /// available.\n  const SmallVectorImpl<Dependence> *getDependences() const {\n    return RecordDependences ? &Dependences : nullptr;\n  }\n\n  void clearDependences() { Dependences.clear(); }\n\n  /// The vector of memory access instructions.  The indices are used as\n  /// instruction identifiers in the Dependence class.\n  const SmallVectorImpl<Instruction *> &getMemoryInstructions() const {\n    return InstMap;\n  }\n\n  /// Generate a mapping between the memory instructions and their\n  /// indices according to program order.\n  DenseMap<Instruction *, unsigned> generateInstructionOrderMap() const {\n    DenseMap<Instruction *, unsigned> OrderMap;\n\n    for (unsigned I = 0; I < InstMap.size(); ++I)\n      OrderMap[InstMap[I]] = I;\n\n    return OrderMap;\n  }\n\n  /// Find the set of instructions that read or write via \\p Ptr.\n  SmallVector<Instruction *, 4> getInstructionsForAccess(Value *Ptr,\n                                                         bool isWrite) const;\n\nprivate:\n  /// A wrapper around ScalarEvolution, used to add runtime SCEV checks, and\n  /// applies dynamic knowledge to simplify SCEV expressions and convert them\n  /// to a more usable form. We need this in case assumptions about SCEV\n  /// expressions need to be made in order to avoid unknown dependences. For\n  /// example we might assume a unit stride for a pointer in order to prove\n  /// that a memory access is strided and doesn't wrap.\n  PredicatedScalarEvolution &PSE;\n  const Loop *InnermostLoop;\n\n  /// Maps access locations (ptr, read/write) to program order.\n  DenseMap<MemAccessInfo, std::vector<unsigned> > Accesses;\n\n  /// Memory access instructions in program order.\n  SmallVector<Instruction *, 16> InstMap;\n\n  /// The program order index to be used for the next instruction.\n  unsigned AccessIdx;\n\n  // We can access this many bytes in parallel safely.\n  uint64_t MaxSafeDepDistBytes;\n\n  /// Number of elements (from consecutive iterations) that are safe to\n  /// operate on simultaneously, multiplied by the size of the element in bits.\n  /// The size of the element is taken from the memory access that is most\n  /// restrictive.\n  uint64_t MaxSafeVectorWidthInBits;\n\n  /// If we see a non-constant dependence distance we can still try to\n  /// vectorize this loop with runtime checks.\n  bool FoundNonConstantDistanceDependence;\n\n  /// Result of the dependence checks, indicating whether the checked\n  /// dependences are safe for vectorization, require RT checks or are known to\n  /// be unsafe.\n  VectorizationSafetyStatus Status;\n\n  //// True if Dependences reflects the dependences in the\n  //// loop.  If false we exceeded MaxDependences and\n  //// Dependences is invalid.\n  bool RecordDependences;\n\n  /// Memory dependences collected during the analysis.  Only valid if\n  /// RecordDependences is true.\n  SmallVector<Dependence, 8> Dependences;\n\n  /// Check whether there is a plausible dependence between the two\n  /// accesses.\n  ///\n  /// Access \\p A must happen before \\p B in program order. The two indices\n  /// identify the index into the program order map.\n  ///\n  /// This function checks  whether there is a plausible dependence (or the\n  /// absence of such can't be proved) between the two accesses. If there is a\n  /// plausible dependence but the dependence distance is bigger than one\n  /// element access it records this distance in \\p MaxSafeDepDistBytes (if this\n  /// distance is smaller than any other distance encountered so far).\n  /// Otherwise, this function returns true signaling a possible dependence.\n  Dependence::DepType isDependent(const MemAccessInfo &A, unsigned AIdx,\n                                  const MemAccessInfo &B, unsigned BIdx,\n                                  const ValueToValueMap &Strides);\n\n  /// Check whether the data dependence could prevent store-load\n  /// forwarding.\n  ///\n  /// \\return false if we shouldn't vectorize at all or avoid larger\n  /// vectorization factors by limiting MaxSafeDepDistBytes.\n  bool couldPreventStoreLoadForward(uint64_t Distance, uint64_t TypeByteSize);\n\n  /// Updates the current safety status with \\p S. We can go from Safe to\n  /// either PossiblySafeWithRtChecks or Unsafe and from\n  /// PossiblySafeWithRtChecks to Unsafe.\n  void mergeInStatus(VectorizationSafetyStatus S);\n};\n\nclass RuntimePointerChecking;\n/// A grouping of pointers. A single memcheck is required between\n/// two groups.\nstruct RuntimeCheckingPtrGroup {\n  /// Create a new pointer checking group containing a single\n  /// pointer, with index \\p Index in RtCheck.\n  RuntimeCheckingPtrGroup(unsigned Index, RuntimePointerChecking &RtCheck);\n\n  /// Tries to add the pointer recorded in RtCheck at index\n  /// \\p Index to this pointer checking group. We can only add a pointer\n  /// to a checking group if we will still be able to get\n  /// the upper and lower bounds of the check. Returns true in case\n  /// of success, false otherwise.\n  bool addPointer(unsigned Index);\n\n  /// Constitutes the context of this pointer checking group. For each\n  /// pointer that is a member of this group we will retain the index\n  /// at which it appears in RtCheck.\n  RuntimePointerChecking &RtCheck;\n  /// The SCEV expression which represents the upper bound of all the\n  /// pointers in this group.\n  const SCEV *High;\n  /// The SCEV expression which represents the lower bound of all the\n  /// pointers in this group.\n  const SCEV *Low;\n  /// Indices of all the pointers that constitute this grouping.\n  SmallVector<unsigned, 2> Members;\n};\n\n/// A memcheck which made up of a pair of grouped pointers.\ntypedef std::pair<const RuntimeCheckingPtrGroup *,\n                  const RuntimeCheckingPtrGroup *>\n    RuntimePointerCheck;\n\n/// Holds information about the memory runtime legality checks to verify\n/// that a group of pointers do not overlap.\nclass RuntimePointerChecking {\n  friend struct RuntimeCheckingPtrGroup;\n\npublic:\n  struct PointerInfo {\n    /// Holds the pointer value that we need to check.\n    TrackingVH<Value> PointerValue;\n    /// Holds the smallest byte address accessed by the pointer throughout all\n    /// iterations of the loop.\n    const SCEV *Start;\n    /// Holds the largest byte address accessed by the pointer throughout all\n    /// iterations of the loop, plus 1.\n    const SCEV *End;\n    /// Holds the information if this pointer is used for writing to memory.\n    bool IsWritePtr;\n    /// Holds the id of the set of pointers that could be dependent because of a\n    /// shared underlying object.\n    unsigned DependencySetId;\n    /// Holds the id of the disjoint alias set to which this pointer belongs.\n    unsigned AliasSetId;\n    /// SCEV for the access.\n    const SCEV *Expr;\n\n    PointerInfo(Value *PointerValue, const SCEV *Start, const SCEV *End,\n                bool IsWritePtr, unsigned DependencySetId, unsigned AliasSetId,\n                const SCEV *Expr)\n        : PointerValue(PointerValue), Start(Start), End(End),\n          IsWritePtr(IsWritePtr), DependencySetId(DependencySetId),\n          AliasSetId(AliasSetId), Expr(Expr) {}\n  };\n\n  RuntimePointerChecking(ScalarEvolution *SE) : Need(false), SE(SE) {}\n\n  /// Reset the state of the pointer runtime information.\n  void reset() {\n    Need = false;\n    Pointers.clear();\n    Checks.clear();\n  }\n\n  /// Insert a pointer and calculate the start and end SCEVs.\n  /// We need \\p PSE in order to compute the SCEV expression of the pointer\n  /// according to the assumptions that we've made during the analysis.\n  /// The method might also version the pointer stride according to \\p Strides,\n  /// and add new predicates to \\p PSE.\n  void insert(Loop *Lp, Value *Ptr, bool WritePtr, unsigned DepSetId,\n              unsigned ASId, const ValueToValueMap &Strides,\n              PredicatedScalarEvolution &PSE);\n\n  /// No run-time memory checking is necessary.\n  bool empty() const { return Pointers.empty(); }\n\n  /// Generate the checks and store it.  This also performs the grouping\n  /// of pointers to reduce the number of memchecks necessary.\n  void generateChecks(MemoryDepChecker::DepCandidates &DepCands,\n                      bool UseDependencies);\n\n  /// Returns the checks that generateChecks created.\n  const SmallVectorImpl<RuntimePointerCheck> &getChecks() const {\n    return Checks;\n  }\n\n  /// Decide if we need to add a check between two groups of pointers,\n  /// according to needsChecking.\n  bool needsChecking(const RuntimeCheckingPtrGroup &M,\n                     const RuntimeCheckingPtrGroup &N) const;\n\n  /// Returns the number of run-time checks required according to\n  /// needsChecking.\n  unsigned getNumberOfChecks() const { return Checks.size(); }\n\n  /// Print the list run-time memory checks necessary.\n  void print(raw_ostream &OS, unsigned Depth = 0) const;\n\n  /// Print \\p Checks.\n  void printChecks(raw_ostream &OS,\n                   const SmallVectorImpl<RuntimePointerCheck> &Checks,\n                   unsigned Depth = 0) const;\n\n  /// This flag indicates if we need to add the runtime check.\n  bool Need;\n\n  /// Information about the pointers that may require checking.\n  SmallVector<PointerInfo, 2> Pointers;\n\n  /// Holds a partitioning of pointers into \"check groups\".\n  SmallVector<RuntimeCheckingPtrGroup, 2> CheckingGroups;\n\n  /// Check if pointers are in the same partition\n  ///\n  /// \\p PtrToPartition contains the partition number for pointers (-1 if the\n  /// pointer belongs to multiple partitions).\n  static bool\n  arePointersInSamePartition(const SmallVectorImpl<int> &PtrToPartition,\n                             unsigned PtrIdx1, unsigned PtrIdx2);\n\n  /// Decide whether we need to issue a run-time check for pointer at\n  /// index \\p I and \\p J to prove their independence.\n  bool needsChecking(unsigned I, unsigned J) const;\n\n  /// Return PointerInfo for pointer at index \\p PtrIdx.\n  const PointerInfo &getPointerInfo(unsigned PtrIdx) const {\n    return Pointers[PtrIdx];\n  }\n\n  ScalarEvolution *getSE() const { return SE; }\n\nprivate:\n  /// Groups pointers such that a single memcheck is required\n  /// between two different groups. This will clear the CheckingGroups vector\n  /// and re-compute it. We will only group dependecies if \\p UseDependencies\n  /// is true, otherwise we will create a separate group for each pointer.\n  void groupChecks(MemoryDepChecker::DepCandidates &DepCands,\n                   bool UseDependencies);\n\n  /// Generate the checks and return them.\n  SmallVector<RuntimePointerCheck, 4> generateChecks() const;\n\n  /// Holds a pointer to the ScalarEvolution analysis.\n  ScalarEvolution *SE;\n\n  /// Set of run-time checks required to establish independence of\n  /// otherwise may-aliasing pointers in the loop.\n  SmallVector<RuntimePointerCheck, 4> Checks;\n};\n\n/// Drive the analysis of memory accesses in the loop\n///\n/// This class is responsible for analyzing the memory accesses of a loop.  It\n/// collects the accesses and then its main helper the AccessAnalysis class\n/// finds and categorizes the dependences in buildDependenceSets.\n///\n/// For memory dependences that can be analyzed at compile time, it determines\n/// whether the dependence is part of cycle inhibiting vectorization.  This work\n/// is delegated to the MemoryDepChecker class.\n///\n/// For memory dependences that cannot be determined at compile time, it\n/// generates run-time checks to prove independence.  This is done by\n/// AccessAnalysis::canCheckPtrAtRT and the checks are maintained by the\n/// RuntimePointerCheck class.\n///\n/// If pointers can wrap or can't be expressed as affine AddRec expressions by\n/// ScalarEvolution, we will generate run-time checks by emitting a\n/// SCEVUnionPredicate.\n///\n/// Checks for both memory dependences and the SCEV predicates contained in the\n/// PSE must be emitted in order for the results of this analysis to be valid.\nclass LoopAccessInfo {\npublic:\n  LoopAccessInfo(Loop *L, ScalarEvolution *SE, const TargetLibraryInfo *TLI,\n                 AAResults *AA, DominatorTree *DT, LoopInfo *LI);\n\n  /// Return true we can analyze the memory accesses in the loop and there are\n  /// no memory dependence cycles.\n  bool canVectorizeMemory() const { return CanVecMem; }\n\n  /// Return true if there is a convergent operation in the loop. There may\n  /// still be reported runtime pointer checks that would be required, but it is\n  /// not legal to insert them.\n  bool hasConvergentOp() const { return HasConvergentOp; }\n\n  const RuntimePointerChecking *getRuntimePointerChecking() const {\n    return PtrRtChecking.get();\n  }\n\n  /// Number of memchecks required to prove independence of otherwise\n  /// may-alias pointers.\n  unsigned getNumRuntimePointerChecks() const {\n    return PtrRtChecking->getNumberOfChecks();\n  }\n\n  /// Return true if the block BB needs to be predicated in order for the loop\n  /// to be vectorized.\n  static bool blockNeedsPredication(BasicBlock *BB, Loop *TheLoop,\n                                    DominatorTree *DT);\n\n  /// Returns true if the value V is uniform within the loop.\n  bool isUniform(Value *V) const;\n\n  uint64_t getMaxSafeDepDistBytes() const { return MaxSafeDepDistBytes; }\n  unsigned getNumStores() const { return NumStores; }\n  unsigned getNumLoads() const { return NumLoads;}\n\n  /// The diagnostics report generated for the analysis.  E.g. why we\n  /// couldn't analyze the loop.\n  const OptimizationRemarkAnalysis *getReport() const { return Report.get(); }\n\n  /// the Memory Dependence Checker which can determine the\n  /// loop-independent and loop-carried dependences between memory accesses.\n  const MemoryDepChecker &getDepChecker() const { return *DepChecker; }\n\n  /// Return the list of instructions that use \\p Ptr to read or write\n  /// memory.\n  SmallVector<Instruction *, 4> getInstructionsForAccess(Value *Ptr,\n                                                         bool isWrite) const {\n    return DepChecker->getInstructionsForAccess(Ptr, isWrite);\n  }\n\n  /// If an access has a symbolic strides, this maps the pointer value to\n  /// the stride symbol.\n  const ValueToValueMap &getSymbolicStrides() const { return SymbolicStrides; }\n\n  /// Pointer has a symbolic stride.\n  bool hasStride(Value *V) const { return StrideSet.count(V); }\n\n  /// Print the information about the memory accesses in the loop.\n  void print(raw_ostream &OS, unsigned Depth = 0) const;\n\n  /// If the loop has memory dependence involving an invariant address, i.e. two\n  /// stores or a store and a load, then return true, else return false.\n  bool hasDependenceInvolvingLoopInvariantAddress() const {\n    return HasDependenceInvolvingLoopInvariantAddress;\n  }\n\n  /// Used to add runtime SCEV checks. Simplifies SCEV expressions and converts\n  /// them to a more usable form.  All SCEV expressions during the analysis\n  /// should be re-written (and therefore simplified) according to PSE.\n  /// A user of LoopAccessAnalysis will need to emit the runtime checks\n  /// associated with this predicate.\n  const PredicatedScalarEvolution &getPSE() const { return *PSE; }\n\nprivate:\n  /// Analyze the loop.\n  void analyzeLoop(AAResults *AA, LoopInfo *LI,\n                   const TargetLibraryInfo *TLI, DominatorTree *DT);\n\n  /// Check if the structure of the loop allows it to be analyzed by this\n  /// pass.\n  bool canAnalyzeLoop();\n\n  /// Save the analysis remark.\n  ///\n  /// LAA does not directly emits the remarks.  Instead it stores it which the\n  /// client can retrieve and presents as its own analysis\n  /// (e.g. -Rpass-analysis=loop-vectorize).\n  OptimizationRemarkAnalysis &recordAnalysis(StringRef RemarkName,\n                                             Instruction *Instr = nullptr);\n\n  /// Collect memory access with loop invariant strides.\n  ///\n  /// Looks for accesses like \"a[i * StrideA]\" where \"StrideA\" is loop\n  /// invariant.\n  void collectStridedAccess(Value *LoadOrStoreInst);\n\n  std::unique_ptr<PredicatedScalarEvolution> PSE;\n\n  /// We need to check that all of the pointers in this list are disjoint\n  /// at runtime. Using std::unique_ptr to make using move ctor simpler.\n  std::unique_ptr<RuntimePointerChecking> PtrRtChecking;\n\n  /// the Memory Dependence Checker which can determine the\n  /// loop-independent and loop-carried dependences between memory accesses.\n  std::unique_ptr<MemoryDepChecker> DepChecker;\n\n  Loop *TheLoop;\n\n  unsigned NumLoads;\n  unsigned NumStores;\n\n  uint64_t MaxSafeDepDistBytes;\n\n  /// Cache the result of analyzeLoop.\n  bool CanVecMem;\n  bool HasConvergentOp;\n\n  /// Indicator that there are non vectorizable stores to a uniform address.\n  bool HasDependenceInvolvingLoopInvariantAddress;\n\n  /// The diagnostics report generated for the analysis.  E.g. why we\n  /// couldn't analyze the loop.\n  std::unique_ptr<OptimizationRemarkAnalysis> Report;\n\n  /// If an access has a symbolic strides, this maps the pointer value to\n  /// the stride symbol.\n  ValueToValueMap SymbolicStrides;\n\n  /// Set of symbolic strides values.\n  SmallPtrSet<Value *, 8> StrideSet;\n};\n\nValue *stripIntegerCast(Value *V);\n\n/// Return the SCEV corresponding to a pointer with the symbolic stride\n/// replaced with constant one, assuming the SCEV predicate associated with\n/// \\p PSE is true.\n///\n/// If necessary this method will version the stride of the pointer according\n/// to \\p PtrToStride and therefore add further predicates to \\p PSE.\n///\n/// If \\p OrigPtr is not null, use it to look up the stride value instead of \\p\n/// Ptr.  \\p PtrToStride provides the mapping between the pointer value and its\n/// stride as collected by LoopVectorizationLegality::collectStridedAccess.\nconst SCEV *replaceSymbolicStrideSCEV(PredicatedScalarEvolution &PSE,\n                                      const ValueToValueMap &PtrToStride,\n                                      Value *Ptr, Value *OrigPtr = nullptr);\n\n/// If the pointer has a constant stride return it in units of its\n/// element size.  Otherwise return zero.\n///\n/// Ensure that it does not wrap in the address space, assuming the predicate\n/// associated with \\p PSE is true.\n///\n/// If necessary this method will version the stride of the pointer according\n/// to \\p PtrToStride and therefore add further predicates to \\p PSE.\n/// The \\p Assume parameter indicates if we are allowed to make additional\n/// run-time assumptions.\nint64_t getPtrStride(PredicatedScalarEvolution &PSE, Value *Ptr, const Loop *Lp,\n                     const ValueToValueMap &StridesMap = ValueToValueMap(),\n                     bool Assume = false, bool ShouldCheckWrap = true);\n\n/// Attempt to sort the pointers in \\p VL and return the sorted indices\n/// in \\p SortedIndices, if reordering is required.\n///\n/// Returns 'true' if sorting is legal, otherwise returns 'false'.\n///\n/// For example, for a given \\p VL of memory accesses in program order, a[i+4],\n/// a[i+0], a[i+1] and a[i+7], this function will sort the \\p VL and save the\n/// sorted indices in \\p SortedIndices as a[i+0], a[i+1], a[i+4], a[i+7] and\n/// saves the mask for actual memory accesses in program order in\n/// \\p SortedIndices as <1,2,0,3>\nbool sortPtrAccesses(ArrayRef<Value *> VL, const DataLayout &DL,\n                     ScalarEvolution &SE,\n                     SmallVectorImpl<unsigned> &SortedIndices);\n\n/// Returns true if the memory operations \\p A and \\p B are consecutive.\n/// This is a simple API that does not depend on the analysis pass.\nbool isConsecutiveAccess(Value *A, Value *B, const DataLayout &DL,\n                         ScalarEvolution &SE, bool CheckType = true);\n\n/// This analysis provides dependence information for the memory accesses\n/// of a loop.\n///\n/// It runs the analysis for a loop on demand.  This can be initiated by\n/// querying the loop access info via LAA::getInfo.  getInfo return a\n/// LoopAccessInfo object.  See this class for the specifics of what information\n/// is provided.\nclass LoopAccessLegacyAnalysis : public FunctionPass {\npublic:\n  static char ID;\n\n  LoopAccessLegacyAnalysis();\n\n  bool runOnFunction(Function &F) override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  /// Query the result of the loop access information for the loop \\p L.\n  ///\n  /// If there is no cached result available run the analysis.\n  const LoopAccessInfo &getInfo(Loop *L);\n\n  void releaseMemory() override {\n    // Invalidate the cache when the pass is freed.\n    LoopAccessInfoMap.clear();\n  }\n\n  /// Print the result of the analysis when invoked with -analyze.\n  void print(raw_ostream &OS, const Module *M = nullptr) const override;\n\nprivate:\n  /// The cache.\n  DenseMap<Loop *, std::unique_ptr<LoopAccessInfo>> LoopAccessInfoMap;\n\n  // The used analysis passes.\n  ScalarEvolution *SE = nullptr;\n  const TargetLibraryInfo *TLI = nullptr;\n  AAResults *AA = nullptr;\n  DominatorTree *DT = nullptr;\n  LoopInfo *LI = nullptr;\n};\n\n/// This analysis provides dependence information for the memory\n/// accesses of a loop.\n///\n/// It runs the analysis for a loop on demand.  This can be initiated by\n/// querying the loop access info via AM.getResult<LoopAccessAnalysis>.\n/// getResult return a LoopAccessInfo object.  See this class for the\n/// specifics of what information is provided.\nclass LoopAccessAnalysis\n    : public AnalysisInfoMixin<LoopAccessAnalysis> {\n  friend AnalysisInfoMixin<LoopAccessAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  typedef LoopAccessInfo Result;\n\n  Result run(Loop &L, LoopAnalysisManager &AM, LoopStandardAnalysisResults &AR);\n};\n\ninline Instruction *MemoryDepChecker::Dependence::getSource(\n    const LoopAccessInfo &LAI) const {\n  return LAI.getDepChecker().getMemoryInstructions()[Source];\n}\n\ninline Instruction *MemoryDepChecker::Dependence::getDestination(\n    const LoopAccessInfo &LAI) const {\n  return LAI.getDepChecker().getMemoryInstructions()[Destination];\n}\n\n} // End llvm namespace\n\n#endif\n"}, "48": {"id": 48, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "content": "//===- llvm/Analysis/LoopInfo.h - Natural Loop Calculator -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the LoopInfo class that is used to identify natural loops\n// and determine the loop depth of various nodes of the CFG.  A natural loop\n// has exactly one entry-point, which is called the header. Note that natural\n// loops may actually be several loops that share the same header node.\n//\n// This analysis calculates the nesting structure of loops in a function.  For\n// each natural loop identified, this analysis identifies natural loops\n// contained entirely within the loop and the basic blocks the make up the loop.\n//\n// It can calculate on the fly various bits of information, for example:\n//\n//  * whether there is a preheader for the loop\n//  * the number of back edges to the header\n//  * whether or not a particular block branches out of the loop\n//  * the successor blocks of the loop\n//  * the loop depth\n//  * etc...\n//\n// Note that this analysis specifically identifies *Loops* not cycles or SCCs\n// in the CFG.  There can be strongly connected components in the CFG which\n// this analysis will not recognize and that will not be represented by a Loop\n// instance.  In particular, a Loop might be inside such a non-loop SCC, or a\n// non-loop SCC might contain a sub-SCC which is a Loop.\n//\n// For an overview of terminology used in this API (and thus all of our loop\n// analyses or transforms), see docs/LoopTerminology.rst.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_LOOPINFO_H\n#define LLVM_ANALYSIS_LOOPINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Allocator.h\"\n#include <algorithm>\n#include <utility>\n\nnamespace llvm {\n\nclass DominatorTree;\nclass LoopInfo;\nclass Loop;\nclass InductionDescriptor;\nclass MDNode;\nclass MemorySSAUpdater;\nclass ScalarEvolution;\nclass raw_ostream;\ntemplate <class N, bool IsPostDom> class DominatorTreeBase;\ntemplate <class N, class M> class LoopInfoBase;\ntemplate <class N, class M> class LoopBase;\n\n//===----------------------------------------------------------------------===//\n/// Instances of this class are used to represent loops that are detected in the\n/// flow graph.\n///\ntemplate <class BlockT, class LoopT> class LoopBase {\n  LoopT *ParentLoop;\n  // Loops contained entirely within this one.\n  std::vector<LoopT *> SubLoops;\n\n  // The list of blocks in this loop. First entry is the header node.\n  std::vector<BlockT *> Blocks;\n\n  SmallPtrSet<const BlockT *, 8> DenseBlockSet;\n\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n  /// Indicator that this loop is no longer a valid loop.\n  bool IsInvalid = false;\n#endif\n\n  LoopBase(const LoopBase<BlockT, LoopT> &) = delete;\n  const LoopBase<BlockT, LoopT> &\n  operator=(const LoopBase<BlockT, LoopT> &) = delete;\n\npublic:\n  /// Return the nesting level of this loop.  An outer-most loop has depth 1,\n  /// for consistency with loop depth values used for basic blocks, where depth\n  /// 0 is used for blocks not inside any loops.\n  unsigned getLoopDepth() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    unsigned D = 1;\n    for (const LoopT *CurLoop = ParentLoop; CurLoop;\n         CurLoop = CurLoop->ParentLoop)\n      ++D;\n    return D;\n  }\n  BlockT *getHeader() const { return getBlocks().front(); }\n  /// Return the parent loop if it exists or nullptr for top\n  /// level loops.\n\n  /// A loop is either top-level in a function (that is, it is not\n  /// contained in any other loop) or it is entirely enclosed in\n  /// some other loop.\n  /// If a loop is top-level, it has no parent, otherwise its\n  /// parent is the innermost loop in which it is enclosed.\n  LoopT *getParentLoop() const { return ParentLoop; }\n\n  /// This is a raw interface for bypassing addChildLoop.\n  void setParentLoop(LoopT *L) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    ParentLoop = L;\n  }\n\n  /// Return true if the specified loop is contained within in this loop.\n  bool contains(const LoopT *L) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    if (L == this)\n      return true;\n    if (!L)\n      return false;\n    return contains(L->getParentLoop());\n  }\n\n  /// Return true if the specified basic block is in this loop.\n  bool contains(const BlockT *BB) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return DenseBlockSet.count(BB);\n  }\n\n  /// Return true if the specified instruction is in this loop.\n  template <class InstT> bool contains(const InstT *Inst) const {\n    return contains(Inst->getParent());\n  }\n\n  /// Return the loops contained entirely within this loop.\n  const std::vector<LoopT *> &getSubLoops() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return SubLoops;\n  }\n  std::vector<LoopT *> &getSubLoopsVector() {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return SubLoops;\n  }\n  typedef typename std::vector<LoopT *>::const_iterator iterator;\n  typedef\n      typename std::vector<LoopT *>::const_reverse_iterator reverse_iterator;\n  iterator begin() const { return getSubLoops().begin(); }\n  iterator end() const { return getSubLoops().end(); }\n  reverse_iterator rbegin() const { return getSubLoops().rbegin(); }\n  reverse_iterator rend() const { return getSubLoops().rend(); }\n\n  // LoopInfo does not detect irreducible control flow, just natural\n  // loops. That is, it is possible that there is cyclic control\n  // flow within the \"innermost loop\" or around the \"outermost\n  // loop\".\n\n  /// Return true if the loop does not contain any (natural) loops.\n  bool isInnermost() const { return getSubLoops().empty(); }\n  /// Return true if the loop does not have a parent (natural) loop\n  // (i.e. it is outermost, which is the same as top-level).\n  bool isOutermost() const { return getParentLoop() == nullptr; }\n\n  /// Get a list of the basic blocks which make up this loop.\n  ArrayRef<BlockT *> getBlocks() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return Blocks;\n  }\n  typedef typename ArrayRef<BlockT *>::const_iterator block_iterator;\n  block_iterator block_begin() const { return getBlocks().begin(); }\n  block_iterator block_end() const { return getBlocks().end(); }\n  inline iterator_range<block_iterator> blocks() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return make_range(block_begin(), block_end());\n  }\n\n  /// Get the number of blocks in this loop in constant time.\n  /// Invalidate the loop, indicating that it is no longer a loop.\n  unsigned getNumBlocks() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return Blocks.size();\n  }\n\n  /// Return a direct, mutable handle to the blocks vector so that we can\n  /// mutate it efficiently with techniques like `std::remove`.\n  std::vector<BlockT *> &getBlocksVector() {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return Blocks;\n  }\n  /// Return a direct, mutable handle to the blocks set so that we can\n  /// mutate it efficiently.\n  SmallPtrSetImpl<const BlockT *> &getBlocksSet() {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return DenseBlockSet;\n  }\n\n  /// Return a direct, immutable handle to the blocks set.\n  const SmallPtrSetImpl<const BlockT *> &getBlocksSet() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    return DenseBlockSet;\n  }\n\n  /// Return true if this loop is no longer valid.  The only valid use of this\n  /// helper is \"assert(L.isInvalid())\" or equivalent, since IsInvalid is set to\n  /// true by the destructor.  In other words, if this accessor returns true,\n  /// the caller has already triggered UB by calling this accessor; and so it\n  /// can only be called in a context where a return value of true indicates a\n  /// programmer error.\n  bool isInvalid() const {\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    return IsInvalid;\n#else\n    return false;\n#endif\n  }\n\n  /// True if terminator in the block can branch to another block that is\n  /// outside of the current loop. \\p BB must be inside the loop.\n  bool isLoopExiting(const BlockT *BB) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(contains(BB) && \"Exiting block must be part of the loop\");\n    for (const auto *Succ : children<const BlockT *>(BB)) {\n      if (!contains(Succ))\n        return true;\n    }\n    return false;\n  }\n\n  /// Returns true if \\p BB is a loop-latch.\n  /// A latch block is a block that contains a branch back to the header.\n  /// This function is useful when there are multiple latches in a loop\n  /// because \\fn getLoopLatch will return nullptr in that case.\n  bool isLoopLatch(const BlockT *BB) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(contains(BB) && \"block does not belong to the loop\");\n\n    BlockT *Header = getHeader();\n    auto PredBegin = GraphTraits<Inverse<BlockT *>>::child_begin(Header);\n    auto PredEnd = GraphTraits<Inverse<BlockT *>>::child_end(Header);\n    return std::find(PredBegin, PredEnd, BB) != PredEnd;\n  }\n\n  /// Calculate the number of back edges to the loop header.\n  unsigned getNumBackEdges() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    unsigned NumBackEdges = 0;\n    BlockT *H = getHeader();\n\n    for (const auto Pred : children<Inverse<BlockT *>>(H))\n      if (contains(Pred))\n        ++NumBackEdges;\n\n    return NumBackEdges;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // APIs for simple analysis of the loop.\n  //\n  // Note that all of these methods can fail on general loops (ie, there may not\n  // be a preheader, etc).  For best success, the loop simplification and\n  // induction variable canonicalization pass should be used to normalize loops\n  // for easy analysis.  These methods assume canonical loops.\n\n  /// Return all blocks inside the loop that have successors outside of the\n  /// loop. These are the blocks _inside of the current loop_ which branch out.\n  /// The returned list is always unique.\n  void getExitingBlocks(SmallVectorImpl<BlockT *> &ExitingBlocks) const;\n\n  /// If getExitingBlocks would return exactly one block, return that block.\n  /// Otherwise return null.\n  BlockT *getExitingBlock() const;\n\n  /// Return all of the successor blocks of this loop. These are the blocks\n  /// _outside of the current loop_ which are branched to.\n  void getExitBlocks(SmallVectorImpl<BlockT *> &ExitBlocks) const;\n\n  /// If getExitBlocks would return exactly one block, return that block.\n  /// Otherwise return null.\n  BlockT *getExitBlock() const;\n\n  /// Return true if no exit block for the loop has a predecessor that is\n  /// outside the loop.\n  bool hasDedicatedExits() const;\n\n  /// Return all unique successor blocks of this loop.\n  /// These are the blocks _outside of the current loop_ which are branched to.\n  void getUniqueExitBlocks(SmallVectorImpl<BlockT *> &ExitBlocks) const;\n\n  /// Return all unique successor blocks of this loop except successors from\n  /// Latch block are not considered. If the exit comes from Latch has also\n  /// non Latch predecessor in a loop it will be added to ExitBlocks.\n  /// These are the blocks _outside of the current loop_ which are branched to.\n  void getUniqueNonLatchExitBlocks(SmallVectorImpl<BlockT *> &ExitBlocks) const;\n\n  /// If getUniqueExitBlocks would return exactly one block, return that block.\n  /// Otherwise return null.\n  BlockT *getUniqueExitBlock() const;\n\n  /// Return true if this loop does not have any exit blocks.\n  bool hasNoExitBlocks() const;\n\n  /// Edge type.\n  typedef std::pair<BlockT *, BlockT *> Edge;\n\n  /// Return all pairs of (_inside_block_,_outside_block_).\n  void getExitEdges(SmallVectorImpl<Edge> &ExitEdges) const;\n\n  /// If there is a preheader for this loop, return it. A loop has a preheader\n  /// if there is only one edge to the header of the loop from outside of the\n  /// loop. If this is the case, the block branching to the header of the loop\n  /// is the preheader node.\n  ///\n  /// This method returns null if there is no preheader for the loop.\n  BlockT *getLoopPreheader() const;\n\n  /// If the given loop's header has exactly one unique predecessor outside the\n  /// loop, return it. Otherwise return null.\n  ///  This is less strict that the loop \"preheader\" concept, which requires\n  /// the predecessor to have exactly one successor.\n  BlockT *getLoopPredecessor() const;\n\n  /// If there is a single latch block for this loop, return it.\n  /// A latch block is a block that contains a branch back to the header.\n  BlockT *getLoopLatch() const;\n\n  /// Return all loop latch blocks of this loop. A latch block is a block that\n  /// contains a branch back to the header.\n  void getLoopLatches(SmallVectorImpl<BlockT *> &LoopLatches) const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    BlockT *H = getHeader();\n    for (const auto Pred : children<Inverse<BlockT *>>(H))\n      if (contains(Pred))\n        LoopLatches.push_back(Pred);\n  }\n\n  /// Return all inner loops in the loop nest rooted by the loop in preorder,\n  /// with siblings in forward program order.\n  template <class Type>\n  static void getInnerLoopsInPreorder(const LoopT &L,\n                                      SmallVectorImpl<Type> &PreOrderLoops) {\n    SmallVector<LoopT *, 4> PreOrderWorklist;\n    PreOrderWorklist.append(L.rbegin(), L.rend());\n\n    while (!PreOrderWorklist.empty()) {\n      LoopT *L = PreOrderWorklist.pop_back_val();\n      // Sub-loops are stored in forward program order, but will process the\n      // worklist backwards so append them in reverse order.\n      PreOrderWorklist.append(L->rbegin(), L->rend());\n      PreOrderLoops.push_back(L);\n    }\n  }\n\n  /// Return all loops in the loop nest rooted by the loop in preorder, with\n  /// siblings in forward program order.\n  SmallVector<const LoopT *, 4> getLoopsInPreorder() const {\n    SmallVector<const LoopT *, 4> PreOrderLoops;\n    const LoopT *CurLoop = static_cast<const LoopT *>(this);\n    PreOrderLoops.push_back(CurLoop);\n    getInnerLoopsInPreorder(*CurLoop, PreOrderLoops);\n    return PreOrderLoops;\n  }\n  SmallVector<LoopT *, 4> getLoopsInPreorder() {\n    SmallVector<LoopT *, 4> PreOrderLoops;\n    LoopT *CurLoop = static_cast<LoopT *>(this);\n    PreOrderLoops.push_back(CurLoop);\n    getInnerLoopsInPreorder(*CurLoop, PreOrderLoops);\n    return PreOrderLoops;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // APIs for updating loop information after changing the CFG\n  //\n\n  /// This method is used by other analyses to update loop information.\n  /// NewBB is set to be a new member of the current loop.\n  /// Because of this, it is added as a member of all parent loops, and is added\n  /// to the specified LoopInfo object as being in the current basic block.  It\n  /// is not valid to replace the loop header with this method.\n  void addBasicBlockToLoop(BlockT *NewBB, LoopInfoBase<BlockT, LoopT> &LI);\n\n  /// This is used when splitting loops up. It replaces the OldChild entry in\n  /// our children list with NewChild, and updates the parent pointer of\n  /// OldChild to be null and the NewChild to be this loop.\n  /// This updates the loop depth of the new child.\n  void replaceChildLoopWith(LoopT *OldChild, LoopT *NewChild);\n\n  /// Add the specified loop to be a child of this loop.\n  /// This updates the loop depth of the new child.\n  void addChildLoop(LoopT *NewChild) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(!NewChild->ParentLoop && \"NewChild already has a parent!\");\n    NewChild->ParentLoop = static_cast<LoopT *>(this);\n    SubLoops.push_back(NewChild);\n  }\n\n  /// This removes the specified child from being a subloop of this loop. The\n  /// loop is not deleted, as it will presumably be inserted into another loop.\n  LoopT *removeChildLoop(iterator I) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    assert(I != SubLoops.end() && \"Cannot remove end iterator!\");\n    LoopT *Child = *I;\n    assert(Child->ParentLoop == this && \"Child is not a child of this loop!\");\n    SubLoops.erase(SubLoops.begin() + (I - begin()));\n    Child->ParentLoop = nullptr;\n    return Child;\n  }\n\n  /// This removes the specified child from being a subloop of this loop. The\n  /// loop is not deleted, as it will presumably be inserted into another loop.\n  LoopT *removeChildLoop(LoopT *Child) {\n    return removeChildLoop(llvm::find(*this, Child));\n  }\n\n  /// This adds a basic block directly to the basic block list.\n  /// This should only be used by transformations that create new loops.  Other\n  /// transformations should use addBasicBlockToLoop.\n  void addBlockEntry(BlockT *BB) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    Blocks.push_back(BB);\n    DenseBlockSet.insert(BB);\n  }\n\n  /// interface to reverse Blocks[from, end of loop] in this loop\n  void reverseBlock(unsigned from) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    std::reverse(Blocks.begin() + from, Blocks.end());\n  }\n\n  /// interface to do reserve() for Blocks\n  void reserveBlocks(unsigned size) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    Blocks.reserve(size);\n  }\n\n  /// This method is used to move BB (which must be part of this loop) to be the\n  /// loop header of the loop (the block that dominates all others).\n  void moveToHeader(BlockT *BB) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    if (Blocks[0] == BB)\n      return;\n    for (unsigned i = 0;; ++i) {\n      assert(i != Blocks.size() && \"Loop does not contain BB!\");\n      if (Blocks[i] == BB) {\n        Blocks[i] = Blocks[0];\n        Blocks[0] = BB;\n        return;\n      }\n    }\n  }\n\n  /// This removes the specified basic block from the current loop, updating the\n  /// Blocks as appropriate. This does not update the mapping in the LoopInfo\n  /// class.\n  void removeBlockFromLoop(BlockT *BB) {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    auto I = find(Blocks, BB);\n    assert(I != Blocks.end() && \"N is not in this list!\");\n    Blocks.erase(I);\n\n    DenseBlockSet.erase(BB);\n  }\n\n  /// Verify loop structure\n  void verifyLoop() const;\n\n  /// Verify loop structure of this loop and all nested loops.\n  void verifyLoopNest(DenseSet<const LoopT *> *Loops) const;\n\n  /// Returns true if the loop is annotated parallel.\n  ///\n  /// Derived classes can override this method using static template\n  /// polymorphism.\n  bool isAnnotatedParallel() const { return false; }\n\n  /// Print loop with all the BBs inside it.\n  void print(raw_ostream &OS, unsigned Depth = 0, bool Verbose = false) const;\n\nprotected:\n  friend class LoopInfoBase<BlockT, LoopT>;\n\n  /// This creates an empty loop.\n  LoopBase() : ParentLoop(nullptr) {}\n\n  explicit LoopBase(BlockT *BB) : ParentLoop(nullptr) {\n    Blocks.push_back(BB);\n    DenseBlockSet.insert(BB);\n  }\n\n  // Since loop passes like SCEV are allowed to key analysis results off of\n  // `Loop` pointers, we cannot re-use pointers within a loop pass manager.\n  // This means loop passes should not be `delete` ing `Loop` objects directly\n  // (and risk a later `Loop` allocation re-using the address of a previous one)\n  // but should be using LoopInfo::markAsRemoved, which keeps around the `Loop`\n  // pointer till the end of the lifetime of the `LoopInfo` object.\n  //\n  // To make it easier to follow this rule, we mark the destructor as\n  // non-public.\n  ~LoopBase() {\n    for (auto *SubLoop : SubLoops)\n      SubLoop->~LoopT();\n\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    IsInvalid = true;\n#endif\n    SubLoops.clear();\n    Blocks.clear();\n    DenseBlockSet.clear();\n    ParentLoop = nullptr;\n  }\n};\n\ntemplate <class BlockT, class LoopT>\nraw_ostream &operator<<(raw_ostream &OS, const LoopBase<BlockT, LoopT> &Loop) {\n  Loop.print(OS);\n  return OS;\n}\n\n// Implementation in LoopInfoImpl.h\nextern template class LoopBase<BasicBlock, Loop>;\n\n/// Represents a single loop in the control flow graph.  Note that not all SCCs\n/// in the CFG are necessarily loops.\nclass Loop : public LoopBase<BasicBlock, Loop> {\npublic:\n  /// A range representing the start and end location of a loop.\n  class LocRange {\n    DebugLoc Start;\n    DebugLoc End;\n\n  public:\n    LocRange() {}\n    LocRange(DebugLoc Start) : Start(Start), End(Start) {}\n    LocRange(DebugLoc Start, DebugLoc End)\n        : Start(std::move(Start)), End(std::move(End)) {}\n\n    const DebugLoc &getStart() const { return Start; }\n    const DebugLoc &getEnd() const { return End; }\n\n    /// Check for null.\n    ///\n    explicit operator bool() const { return Start && End; }\n  };\n\n  /// Return true if the specified value is loop invariant.\n  bool isLoopInvariant(const Value *V) const;\n\n  /// Return true if all the operands of the specified instruction are loop\n  /// invariant.\n  bool hasLoopInvariantOperands(const Instruction *I) const;\n\n  /// If the given value is an instruction inside of the loop and it can be\n  /// hoisted, do so to make it trivially loop-invariant.\n  /// Return true if the value after any hoisting is loop invariant. This\n  /// function can be used as a slightly more aggressive replacement for\n  /// isLoopInvariant.\n  ///\n  /// If InsertPt is specified, it is the point to hoist instructions to.\n  /// If null, the terminator of the loop preheader is used.\n  bool makeLoopInvariant(Value *V, bool &Changed,\n                         Instruction *InsertPt = nullptr,\n                         MemorySSAUpdater *MSSAU = nullptr) const;\n\n  /// If the given instruction is inside of the loop and it can be hoisted, do\n  /// so to make it trivially loop-invariant.\n  /// Return true if the instruction after any hoisting is loop invariant. This\n  /// function can be used as a slightly more aggressive replacement for\n  /// isLoopInvariant.\n  ///\n  /// If InsertPt is specified, it is the point to hoist instructions to.\n  /// If null, the terminator of the loop preheader is used.\n  ///\n  bool makeLoopInvariant(Instruction *I, bool &Changed,\n                         Instruction *InsertPt = nullptr,\n                         MemorySSAUpdater *MSSAU = nullptr) const;\n\n  /// Check to see if the loop has a canonical induction variable: an integer\n  /// recurrence that starts at 0 and increments by one each time through the\n  /// loop. If so, return the phi node that corresponds to it.\n  ///\n  /// The IndVarSimplify pass transforms loops to have a canonical induction\n  /// variable.\n  ///\n  PHINode *getCanonicalInductionVariable() const;\n\n  /// Obtain the unique incoming and back edge. Return false if they are\n  /// non-unique or the loop is dead; otherwise, return true.\n  bool getIncomingAndBackEdge(BasicBlock *&Incoming,\n                              BasicBlock *&Backedge) const;\n\n  /// Below are some utilities to get the loop guard, loop bounds and induction\n  /// variable, and to check if a given phinode is an auxiliary induction\n  /// variable, if the loop is guarded, and if the loop is canonical.\n  ///\n  /// Here is an example:\n  /// \\code\n  /// for (int i = lb; i < ub; i+=step)\n  ///   <loop body>\n  /// --- pseudo LLVMIR ---\n  /// beforeloop:\n  ///   guardcmp = (lb < ub)\n  ///   if (guardcmp) goto preheader; else goto afterloop\n  /// preheader:\n  /// loop:\n  ///   i_1 = phi[{lb, preheader}, {i_2, latch}]\n  ///   <loop body>\n  ///   i_2 = i_1 + step\n  /// latch:\n  ///   cmp = (i_2 < ub)\n  ///   if (cmp) goto loop\n  /// exit:\n  /// afterloop:\n  /// \\endcode\n  ///\n  /// - getBounds\n  ///   - getInitialIVValue      --> lb\n  ///   - getStepInst            --> i_2 = i_1 + step\n  ///   - getStepValue           --> step\n  ///   - getFinalIVValue        --> ub\n  ///   - getCanonicalPredicate  --> '<'\n  ///   - getDirection           --> Increasing\n  ///\n  /// - getInductionVariable            --> i_1\n  /// - isAuxiliaryInductionVariable(x) --> true if x == i_1\n  /// - getLoopGuardBranch()\n  ///                 --> `if (guardcmp) goto preheader; else goto afterloop`\n  /// - isGuarded()                     --> true\n  /// - isCanonical                     --> false\n  struct LoopBounds {\n    /// Return the LoopBounds object if\n    /// - the given \\p IndVar is an induction variable\n    /// - the initial value of the induction variable can be found\n    /// - the step instruction of the induction variable can be found\n    /// - the final value of the induction variable can be found\n    ///\n    /// Else None.\n    static Optional<Loop::LoopBounds> getBounds(const Loop &L, PHINode &IndVar,\n                                                ScalarEvolution &SE);\n\n    /// Get the initial value of the loop induction variable.\n    Value &getInitialIVValue() const { return InitialIVValue; }\n\n    /// Get the instruction that updates the loop induction variable.\n    Instruction &getStepInst() const { return StepInst; }\n\n    /// Get the step that the loop induction variable gets updated by in each\n    /// loop iteration. Return nullptr if not found.\n    Value *getStepValue() const { return StepValue; }\n\n    /// Get the final value of the loop induction variable.\n    Value &getFinalIVValue() const { return FinalIVValue; }\n\n    /// Return the canonical predicate for the latch compare instruction, if\n    /// able to be calcuated. Else BAD_ICMP_PREDICATE.\n    ///\n    /// A predicate is considered as canonical if requirements below are all\n    /// satisfied:\n    /// 1. The first successor of the latch branch is the loop header\n    ///    If not, inverse the predicate.\n    /// 2. One of the operands of the latch comparison is StepInst\n    ///    If not, and\n    ///    - if the current calcuated predicate is not ne or eq, flip the\n    ///      predicate.\n    ///    - else if the loop is increasing, return slt\n    ///      (notice that it is safe to change from ne or eq to sign compare)\n    ///    - else if the loop is decreasing, return sgt\n    ///      (notice that it is safe to change from ne or eq to sign compare)\n    ///\n    /// Here is an example when both (1) and (2) are not satisfied:\n    /// \\code\n    /// loop.header:\n    ///  %iv = phi [%initialiv, %loop.preheader], [%inc, %loop.header]\n    ///  %inc = add %iv, %step\n    ///  %cmp = slt %iv, %finaliv\n    ///  br %cmp, %loop.exit, %loop.header\n    /// loop.exit:\n    /// \\endcode\n    /// - The second successor of the latch branch is the loop header instead\n    ///   of the first successor (slt -> sge)\n    /// - The first operand of the latch comparison (%cmp) is the IndVar (%iv)\n    ///   instead of the StepInst (%inc) (sge -> sgt)\n    ///\n    /// The predicate would be sgt if both (1) and (2) are satisfied.\n    /// getCanonicalPredicate() returns sgt for this example.\n    /// Note: The IR is not changed.\n    ICmpInst::Predicate getCanonicalPredicate() const;\n\n    /// An enum for the direction of the loop\n    /// - for (int i = 0; i < ub; ++i)  --> Increasing\n    /// - for (int i = ub; i > 0; --i)  --> Descresing\n    /// - for (int i = x; i != y; i+=z) --> Unknown\n    enum class Direction { Increasing, Decreasing, Unknown };\n\n    /// Get the direction of the loop.\n    Direction getDirection() const;\n\n  private:\n    LoopBounds(const Loop &Loop, Value &I, Instruction &SI, Value *SV, Value &F,\n               ScalarEvolution &SE)\n        : L(Loop), InitialIVValue(I), StepInst(SI), StepValue(SV),\n          FinalIVValue(F), SE(SE) {}\n\n    const Loop &L;\n\n    // The initial value of the loop induction variable\n    Value &InitialIVValue;\n\n    // The instruction that updates the loop induction variable\n    Instruction &StepInst;\n\n    // The value that the loop induction variable gets updated by in each loop\n    // iteration\n    Value *StepValue;\n\n    // The final value of the loop induction variable\n    Value &FinalIVValue;\n\n    ScalarEvolution &SE;\n  };\n\n  /// Return the struct LoopBounds collected if all struct members are found,\n  /// else None.\n  Optional<LoopBounds> getBounds(ScalarEvolution &SE) const;\n\n  /// Return the loop induction variable if found, else return nullptr.\n  /// An instruction is considered as the loop induction variable if\n  /// - it is an induction variable of the loop; and\n  /// - it is used to determine the condition of the branch in the loop latch\n  ///\n  /// Note: the induction variable doesn't need to be canonical, i.e. starts at\n  /// zero and increments by one each time through the loop (but it can be).\n  PHINode *getInductionVariable(ScalarEvolution &SE) const;\n\n  /// Get the loop induction descriptor for the loop induction variable. Return\n  /// true if the loop induction variable is found.\n  bool getInductionDescriptor(ScalarEvolution &SE,\n                              InductionDescriptor &IndDesc) const;\n\n  /// Return true if the given PHINode \\p AuxIndVar is\n  /// - in the loop header\n  /// - not used outside of the loop\n  /// - incremented by a loop invariant step for each loop iteration\n  /// - step instruction opcode should be add or sub\n  /// Note: auxiliary induction variable is not required to be used in the\n  ///       conditional branch in the loop latch. (but it can be)\n  bool isAuxiliaryInductionVariable(PHINode &AuxIndVar,\n                                    ScalarEvolution &SE) const;\n\n  /// Return the loop guard branch, if it exists.\n  ///\n  /// This currently only works on simplified loop, as it requires a preheader\n  /// and a latch to identify the guard. It will work on loops of the form:\n  /// \\code\n  /// GuardBB:\n  ///   br cond1, Preheader, ExitSucc <== GuardBranch\n  /// Preheader:\n  ///   br Header\n  /// Header:\n  ///  ...\n  ///   br Latch\n  /// Latch:\n  ///   br cond2, Header, ExitBlock\n  /// ExitBlock:\n  ///   br ExitSucc\n  /// ExitSucc:\n  /// \\endcode\n  BranchInst *getLoopGuardBranch() const;\n\n  /// Return true iff the loop is\n  /// - in simplify rotated form, and\n  /// - guarded by a loop guard branch.\n  bool isGuarded() const { return (getLoopGuardBranch() != nullptr); }\n\n  /// Return true if the loop is in rotated form.\n  ///\n  /// This does not check if the loop was rotated by loop rotation, instead it\n  /// only checks if the loop is in rotated form (has a valid latch that exists\n  /// the loop).\n  bool isRotatedForm() const {\n    assert(!isInvalid() && \"Loop not in a valid state!\");\n    BasicBlock *Latch = getLoopLatch();\n    return Latch && isLoopExiting(Latch);\n  }\n\n  /// Return true if the loop induction variable starts at zero and increments\n  /// by one each time through the loop.\n  bool isCanonical(ScalarEvolution &SE) const;\n\n  /// Return true if the Loop is in LCSSA form.\n  bool isLCSSAForm(const DominatorTree &DT) const;\n\n  /// Return true if this Loop and all inner subloops are in LCSSA form.\n  bool isRecursivelyLCSSAForm(const DominatorTree &DT,\n                              const LoopInfo &LI) const;\n\n  /// Return true if the Loop is in the form that the LoopSimplify form\n  /// transforms loops to, which is sometimes called normal form.\n  bool isLoopSimplifyForm() const;\n\n  /// Return true if the loop body is safe to clone in practice.\n  bool isSafeToClone() const;\n\n  /// Returns true if the loop is annotated parallel.\n  ///\n  /// A parallel loop can be assumed to not contain any dependencies between\n  /// iterations by the compiler. That is, any loop-carried dependency checking\n  /// can be skipped completely when parallelizing the loop on the target\n  /// machine. Thus, if the parallel loop information originates from the\n  /// programmer, e.g. via the OpenMP parallel for pragma, it is the\n  /// programmer's responsibility to ensure there are no loop-carried\n  /// dependencies. The final execution order of the instructions across\n  /// iterations is not guaranteed, thus, the end result might or might not\n  /// implement actual concurrent execution of instructions across multiple\n  /// iterations.\n  bool isAnnotatedParallel() const;\n\n  /// Return the llvm.loop loop id metadata node for this loop if it is present.\n  ///\n  /// If this loop contains the same llvm.loop metadata on each branch to the\n  /// header then the node is returned. If any latch instruction does not\n  /// contain llvm.loop or if multiple latches contain different nodes then\n  /// 0 is returned.\n  MDNode *getLoopID() const;\n  /// Set the llvm.loop loop id metadata for this loop.\n  ///\n  /// The LoopID metadata node will be added to each terminator instruction in\n  /// the loop that branches to the loop header.\n  ///\n  /// The LoopID metadata node should have one or more operands and the first\n  /// operand should be the node itself.\n  void setLoopID(MDNode *LoopID) const;\n\n  /// Add llvm.loop.unroll.disable to this loop's loop id metadata.\n  ///\n  /// Remove existing unroll metadata and add unroll disable metadata to\n  /// indicate the loop has already been unrolled.  This prevents a loop\n  /// from being unrolled more than is directed by a pragma if the loop\n  /// unrolling pass is run more than once (which it generally is).\n  void setLoopAlreadyUnrolled();\n\n  /// Add llvm.loop.mustprogress to this loop's loop id metadata.\n  void setLoopMustProgress();\n\n  void dump() const;\n  void dumpVerbose() const;\n\n  /// Return the debug location of the start of this loop.\n  /// This looks for a BB terminating instruction with a known debug\n  /// location by looking at the preheader and header blocks. If it\n  /// cannot find a terminating instruction with location information,\n  /// it returns an unknown location.\n  DebugLoc getStartLoc() const;\n\n  /// Return the source code span of the loop.\n  LocRange getLocRange() const;\n\n  StringRef getName() const {\n    if (BasicBlock *Header = getHeader())\n      if (Header->hasName())\n        return Header->getName();\n    return \"<unnamed loop>\";\n  }\n\nprivate:\n  Loop() = default;\n\n  friend class LoopInfoBase<BasicBlock, Loop>;\n  friend class LoopBase<BasicBlock, Loop>;\n  explicit Loop(BasicBlock *BB) : LoopBase<BasicBlock, Loop>(BB) {}\n  ~Loop() = default;\n};\n\n//===----------------------------------------------------------------------===//\n/// This class builds and contains all of the top-level loop\n/// structures in the specified function.\n///\n\ntemplate <class BlockT, class LoopT> class LoopInfoBase {\n  // BBMap - Mapping of basic blocks to the inner most loop they occur in\n  DenseMap<const BlockT *, LoopT *> BBMap;\n  std::vector<LoopT *> TopLevelLoops;\n  BumpPtrAllocator LoopAllocator;\n\n  friend class LoopBase<BlockT, LoopT>;\n  friend class LoopInfo;\n\n  void operator=(const LoopInfoBase &) = delete;\n  LoopInfoBase(const LoopInfoBase &) = delete;\n\npublic:\n  LoopInfoBase() {}\n  ~LoopInfoBase() { releaseMemory(); }\n\n  LoopInfoBase(LoopInfoBase &&Arg)\n      : BBMap(std::move(Arg.BBMap)),\n        TopLevelLoops(std::move(Arg.TopLevelLoops)),\n        LoopAllocator(std::move(Arg.LoopAllocator)) {\n    // We have to clear the arguments top level loops as we've taken ownership.\n    Arg.TopLevelLoops.clear();\n  }\n  LoopInfoBase &operator=(LoopInfoBase &&RHS) {\n    BBMap = std::move(RHS.BBMap);\n\n    for (auto *L : TopLevelLoops)\n      L->~LoopT();\n\n    TopLevelLoops = std::move(RHS.TopLevelLoops);\n    LoopAllocator = std::move(RHS.LoopAllocator);\n    RHS.TopLevelLoops.clear();\n    return *this;\n  }\n\n  void releaseMemory() {\n    BBMap.clear();\n\n    for (auto *L : TopLevelLoops)\n      L->~LoopT();\n    TopLevelLoops.clear();\n    LoopAllocator.Reset();\n  }\n\n  template <typename... ArgsTy> LoopT *AllocateLoop(ArgsTy &&... Args) {\n    LoopT *Storage = LoopAllocator.Allocate<LoopT>();\n    return new (Storage) LoopT(std::forward<ArgsTy>(Args)...);\n  }\n\n  /// iterator/begin/end - The interface to the top-level loops in the current\n  /// function.\n  ///\n  typedef typename std::vector<LoopT *>::const_iterator iterator;\n  typedef\n      typename std::vector<LoopT *>::const_reverse_iterator reverse_iterator;\n  iterator begin() const { return TopLevelLoops.begin(); }\n  iterator end() const { return TopLevelLoops.end(); }\n  reverse_iterator rbegin() const { return TopLevelLoops.rbegin(); }\n  reverse_iterator rend() const { return TopLevelLoops.rend(); }\n  bool empty() const { return TopLevelLoops.empty(); }\n\n  /// Return all of the loops in the function in preorder across the loop\n  /// nests, with siblings in forward program order.\n  ///\n  /// Note that because loops form a forest of trees, preorder is equivalent to\n  /// reverse postorder.\n  SmallVector<LoopT *, 4> getLoopsInPreorder();\n\n  /// Return all of the loops in the function in preorder across the loop\n  /// nests, with siblings in *reverse* program order.\n  ///\n  /// Note that because loops form a forest of trees, preorder is equivalent to\n  /// reverse postorder.\n  ///\n  /// Also note that this is *not* a reverse preorder. Only the siblings are in\n  /// reverse program order.\n  SmallVector<LoopT *, 4> getLoopsInReverseSiblingPreorder();\n\n  /// Return the inner most loop that BB lives in. If a basic block is in no\n  /// loop (for example the entry node), null is returned.\n  LoopT *getLoopFor(const BlockT *BB) const { return BBMap.lookup(BB); }\n\n  /// Same as getLoopFor.\n  const LoopT *operator[](const BlockT *BB) const { return getLoopFor(BB); }\n\n  /// Return the loop nesting level of the specified block. A depth of 0 means\n  /// the block is not inside any loop.\n  unsigned getLoopDepth(const BlockT *BB) const {\n    const LoopT *L = getLoopFor(BB);\n    return L ? L->getLoopDepth() : 0;\n  }\n\n  // True if the block is a loop header node\n  bool isLoopHeader(const BlockT *BB) const {\n    const LoopT *L = getLoopFor(BB);\n    return L && L->getHeader() == BB;\n  }\n\n  /// Return the top-level loops.\n  const std::vector<LoopT *> &getTopLevelLoops() const { return TopLevelLoops; }\n\n  /// Return the top-level loops.\n  std::vector<LoopT *> &getTopLevelLoopsVector() { return TopLevelLoops; }\n\n  /// This removes the specified top-level loop from this loop info object.\n  /// The loop is not deleted, as it will presumably be inserted into\n  /// another loop.\n  LoopT *removeLoop(iterator I) {\n    assert(I != end() && \"Cannot remove end iterator!\");\n    LoopT *L = *I;\n    assert(L->isOutermost() && \"Not a top-level loop!\");\n    TopLevelLoops.erase(TopLevelLoops.begin() + (I - begin()));\n    return L;\n  }\n\n  /// Change the top-level loop that contains BB to the specified loop.\n  /// This should be used by transformations that restructure the loop hierarchy\n  /// tree.\n  void changeLoopFor(BlockT *BB, LoopT *L) {\n    if (!L) {\n      BBMap.erase(BB);\n      return;\n    }\n    BBMap[BB] = L;\n  }\n\n  /// Replace the specified loop in the top-level loops list with the indicated\n  /// loop.\n  void changeTopLevelLoop(LoopT *OldLoop, LoopT *NewLoop) {\n    auto I = find(TopLevelLoops, OldLoop);\n    assert(I != TopLevelLoops.end() && \"Old loop not at top level!\");\n    *I = NewLoop;\n    assert(!NewLoop->ParentLoop && !OldLoop->ParentLoop &&\n           \"Loops already embedded into a subloop!\");\n  }\n\n  /// This adds the specified loop to the collection of top-level loops.\n  void addTopLevelLoop(LoopT *New) {\n    assert(New->isOutermost() && \"Loop already in subloop!\");\n    TopLevelLoops.push_back(New);\n  }\n\n  /// This method completely removes BB from all data structures,\n  /// including all of the Loop objects it is nested in and our mapping from\n  /// BasicBlocks to loops.\n  void removeBlock(BlockT *BB) {\n    auto I = BBMap.find(BB);\n    if (I != BBMap.end()) {\n      for (LoopT *L = I->second; L; L = L->getParentLoop())\n        L->removeBlockFromLoop(BB);\n\n      BBMap.erase(I);\n    }\n  }\n\n  // Internals\n\n  static bool isNotAlreadyContainedIn(const LoopT *SubLoop,\n                                      const LoopT *ParentLoop) {\n    if (!SubLoop)\n      return true;\n    if (SubLoop == ParentLoop)\n      return false;\n    return isNotAlreadyContainedIn(SubLoop->getParentLoop(), ParentLoop);\n  }\n\n  /// Create the loop forest using a stable algorithm.\n  void analyze(const DominatorTreeBase<BlockT, false> &DomTree);\n\n  // Debugging\n  void print(raw_ostream &OS) const;\n\n  void verify(const DominatorTreeBase<BlockT, false> &DomTree) const;\n\n  /// Destroy a loop that has been removed from the `LoopInfo` nest.\n  ///\n  /// This runs the destructor of the loop object making it invalid to\n  /// reference afterward. The memory is retained so that the *pointer* to the\n  /// loop remains valid.\n  ///\n  /// The caller is responsible for removing this loop from the loop nest and\n  /// otherwise disconnecting it from the broader `LoopInfo` data structures.\n  /// Callers that don't naturally handle this themselves should probably call\n  /// `erase' instead.\n  void destroy(LoopT *L) {\n    L->~LoopT();\n\n    // Since LoopAllocator is a BumpPtrAllocator, this Deallocate only poisons\n    // \\c L, but the pointer remains valid for non-dereferencing uses.\n    LoopAllocator.Deallocate(L);\n  }\n};\n\n// Implementation in LoopInfoImpl.h\nextern template class LoopInfoBase<BasicBlock, Loop>;\n\nclass LoopInfo : public LoopInfoBase<BasicBlock, Loop> {\n  typedef LoopInfoBase<BasicBlock, Loop> BaseT;\n\n  friend class LoopBase<BasicBlock, Loop>;\n\n  void operator=(const LoopInfo &) = delete;\n  LoopInfo(const LoopInfo &) = delete;\n\npublic:\n  LoopInfo() {}\n  explicit LoopInfo(const DominatorTreeBase<BasicBlock, false> &DomTree);\n\n  LoopInfo(LoopInfo &&Arg) : BaseT(std::move(static_cast<BaseT &>(Arg))) {}\n  LoopInfo &operator=(LoopInfo &&RHS) {\n    BaseT::operator=(std::move(static_cast<BaseT &>(RHS)));\n    return *this;\n  }\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // Most of the public interface is provided via LoopInfoBase.\n\n  /// Update LoopInfo after removing the last backedge from a loop. This updates\n  /// the loop forest and parent loops for each block so that \\c L is no longer\n  /// referenced, but does not actually delete \\c L immediately. The pointer\n  /// will remain valid until this LoopInfo's memory is released.\n  void erase(Loop *L);\n\n  /// Returns true if replacing From with To everywhere is guaranteed to\n  /// preserve LCSSA form.\n  bool replacementPreservesLCSSAForm(Instruction *From, Value *To) {\n    // Preserving LCSSA form is only problematic if the replacing value is an\n    // instruction.\n    Instruction *I = dyn_cast<Instruction>(To);\n    if (!I)\n      return true;\n    // If both instructions are defined in the same basic block then replacement\n    // cannot break LCSSA form.\n    if (I->getParent() == From->getParent())\n      return true;\n    // If the instruction is not defined in a loop then it can safely replace\n    // anything.\n    Loop *ToLoop = getLoopFor(I->getParent());\n    if (!ToLoop)\n      return true;\n    // If the replacing instruction is defined in the same loop as the original\n    // instruction, or in a loop that contains it as an inner loop, then using\n    // it as a replacement will not break LCSSA form.\n    return ToLoop->contains(getLoopFor(From->getParent()));\n  }\n\n  /// Checks if moving a specific instruction can break LCSSA in any loop.\n  ///\n  /// Return true if moving \\p Inst to before \\p NewLoc will break LCSSA,\n  /// assuming that the function containing \\p Inst and \\p NewLoc is currently\n  /// in LCSSA form.\n  bool movementPreservesLCSSAForm(Instruction *Inst, Instruction *NewLoc) {\n    assert(Inst->getFunction() == NewLoc->getFunction() &&\n           \"Can't reason about IPO!\");\n\n    auto *OldBB = Inst->getParent();\n    auto *NewBB = NewLoc->getParent();\n\n    // Movement within the same loop does not break LCSSA (the equality check is\n    // to avoid doing a hashtable lookup in case of intra-block movement).\n    if (OldBB == NewBB)\n      return true;\n\n    auto *OldLoop = getLoopFor(OldBB);\n    auto *NewLoop = getLoopFor(NewBB);\n\n    if (OldLoop == NewLoop)\n      return true;\n\n    // Check if Outer contains Inner; with the null loop counting as the\n    // \"outermost\" loop.\n    auto Contains = [](const Loop *Outer, const Loop *Inner) {\n      return !Outer || Outer->contains(Inner);\n    };\n\n    // To check that the movement of Inst to before NewLoc does not break LCSSA,\n    // we need to check two sets of uses for possible LCSSA violations at\n    // NewLoc: the users of NewInst, and the operands of NewInst.\n\n    // If we know we're hoisting Inst out of an inner loop to an outer loop,\n    // then the uses *of* Inst don't need to be checked.\n\n    if (!Contains(NewLoop, OldLoop)) {\n      for (Use &U : Inst->uses()) {\n        auto *UI = cast<Instruction>(U.getUser());\n        auto *UBB = isa<PHINode>(UI) ? cast<PHINode>(UI)->getIncomingBlock(U)\n                                     : UI->getParent();\n        if (UBB != NewBB && getLoopFor(UBB) != NewLoop)\n          return false;\n      }\n    }\n\n    // If we know we're sinking Inst from an outer loop into an inner loop, then\n    // the *operands* of Inst don't need to be checked.\n\n    if (!Contains(OldLoop, NewLoop)) {\n      // See below on why we can't handle phi nodes here.\n      if (isa<PHINode>(Inst))\n        return false;\n\n      for (Use &U : Inst->operands()) {\n        auto *DefI = dyn_cast<Instruction>(U.get());\n        if (!DefI)\n          return false;\n\n        // This would need adjustment if we allow Inst to be a phi node -- the\n        // new use block won't simply be NewBB.\n\n        auto *DefBlock = DefI->getParent();\n        if (DefBlock != NewBB && getLoopFor(DefBlock) != NewLoop)\n          return false;\n      }\n    }\n\n    return true;\n  }\n};\n\n// Allow clients to walk the list of nested loops...\ntemplate <> struct GraphTraits<const Loop *> {\n  typedef const Loop *NodeRef;\n  typedef LoopInfo::iterator ChildIteratorType;\n\n  static NodeRef getEntryNode(const Loop *L) { return L; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->end(); }\n};\n\ntemplate <> struct GraphTraits<Loop *> {\n  typedef Loop *NodeRef;\n  typedef LoopInfo::iterator ChildIteratorType;\n\n  static NodeRef getEntryNode(Loop *L) { return L; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->end(); }\n};\n\n/// Analysis pass that exposes the \\c LoopInfo for a function.\nclass LoopAnalysis : public AnalysisInfoMixin<LoopAnalysis> {\n  friend AnalysisInfoMixin<LoopAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  typedef LoopInfo Result;\n\n  LoopInfo run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c LoopAnalysis results.\nclass LoopPrinterPass : public PassInfoMixin<LoopPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit LoopPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c LoopAnalysis results.\nstruct LoopVerifierPass : public PassInfoMixin<LoopVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// The legacy pass manager's analysis pass to compute loop information.\nclass LoopInfoWrapperPass : public FunctionPass {\n  LoopInfo LI;\n\npublic:\n  static char ID; // Pass identification, replacement for typeid\n\n  LoopInfoWrapperPass();\n\n  LoopInfo &getLoopInfo() { return LI; }\n  const LoopInfo &getLoopInfo() const { return LI; }\n\n  /// Calculate the natural loop information for a given function.\n  bool runOnFunction(Function &F) override;\n\n  void verifyAnalysis() const override;\n\n  void releaseMemory() override { LI.releaseMemory(); }\n\n  void print(raw_ostream &O, const Module *M = nullptr) const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n/// Function to print a loop's contents as LLVM's text IR assembly.\nvoid printLoop(Loop &L, raw_ostream &OS, const std::string &Banner = \"\");\n\n/// Find and return the loop attribute node for the attribute @p Name in\n/// @p LoopID. Return nullptr if there is no such attribute.\nMDNode *findOptionMDForLoopID(MDNode *LoopID, StringRef Name);\n\n/// Find string metadata for a loop.\n///\n/// Returns the MDNode where the first operand is the metadata's name. The\n/// following operands are the metadata's values. If no metadata with @p Name is\n/// found, return nullptr.\nMDNode *findOptionMDForLoop(const Loop *TheLoop, StringRef Name);\n\n/// Return whether an MDNode might represent an access group.\n///\n/// Access group metadata nodes have to be distinct and empty. Being\n/// always-empty ensures that it never needs to be changed (which -- because\n/// MDNodes are designed immutable -- would require creating a new MDNode). Note\n/// that this is not a sufficient condition: not every distinct and empty NDNode\n/// is representing an access group.\nbool isValidAsAccessGroup(MDNode *AccGroup);\n\n/// Create a new LoopID after the loop has been transformed.\n///\n/// This can be used when no follow-up loop attributes are defined\n/// (llvm::makeFollowupLoopID returning None) to stop transformations to be\n/// applied again.\n///\n/// @param Context        The LLVMContext in which to create the new LoopID.\n/// @param OrigLoopID     The original LoopID; can be nullptr if the original\n///                       loop has no LoopID.\n/// @param RemovePrefixes Remove all loop attributes that have these prefixes.\n///                       Use to remove metadata of the transformation that has\n///                       been applied.\n/// @param AddAttrs       Add these loop attributes to the new LoopID.\n///\n/// @return A new LoopID that can be applied using Loop::setLoopID().\nllvm::MDNode *\nmakePostTransformationMetadata(llvm::LLVMContext &Context, MDNode *OrigLoopID,\n                               llvm::ArrayRef<llvm::StringRef> RemovePrefixes,\n                               llvm::ArrayRef<llvm::MDNode *> AddAttrs);\n\n} // End llvm namespace\n\n#endif\n"}, "51": {"id": 51, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h", "content": "//===- MemorySSA.h - Build Memory SSA ---------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This file exposes an interface to building/using memory SSA to\n/// walk memory instructions using a use/def graph.\n///\n/// Memory SSA class builds an SSA form that links together memory access\n/// instructions such as loads, stores, atomics, and calls. Additionally, it\n/// does a trivial form of \"heap versioning\" Every time the memory state changes\n/// in the program, we generate a new heap version. It generates\n/// MemoryDef/Uses/Phis that are overlayed on top of the existing instructions.\n///\n/// As a trivial example,\n/// define i32 @main() #0 {\n/// entry:\n///   %call = call noalias i8* @_Znwm(i64 4) #2\n///   %0 = bitcast i8* %call to i32*\n///   %call1 = call noalias i8* @_Znwm(i64 4) #2\n///   %1 = bitcast i8* %call1 to i32*\n///   store i32 5, i32* %0, align 4\n///   store i32 7, i32* %1, align 4\n///   %2 = load i32* %0, align 4\n///   %3 = load i32* %1, align 4\n///   %add = add nsw i32 %2, %3\n///   ret i32 %add\n/// }\n///\n/// Will become\n/// define i32 @main() #0 {\n/// entry:\n///   ; 1 = MemoryDef(0)\n///   %call = call noalias i8* @_Znwm(i64 4) #3\n///   %2 = bitcast i8* %call to i32*\n///   ; 2 = MemoryDef(1)\n///   %call1 = call noalias i8* @_Znwm(i64 4) #3\n///   %4 = bitcast i8* %call1 to i32*\n///   ; 3 = MemoryDef(2)\n///   store i32 5, i32* %2, align 4\n///   ; 4 = MemoryDef(3)\n///   store i32 7, i32* %4, align 4\n///   ; MemoryUse(3)\n///   %7 = load i32* %2, align 4\n///   ; MemoryUse(4)\n///   %8 = load i32* %4, align 4\n///   %add = add nsw i32 %7, %8\n///   ret i32 %add\n/// }\n///\n/// Given this form, all the stores that could ever effect the load at %8 can be\n/// gotten by using the MemoryUse associated with it, and walking from use to\n/// def until you hit the top of the function.\n///\n/// Each def also has a list of users associated with it, so you can walk from\n/// both def to users, and users to defs. Note that we disambiguate MemoryUses,\n/// but not the RHS of MemoryDefs. You can see this above at %7, which would\n/// otherwise be a MemoryUse(4). Being disambiguated means that for a given\n/// store, all the MemoryUses on its use lists are may-aliases of that store\n/// (but the MemoryDefs on its use list may not be).\n///\n/// MemoryDefs are not disambiguated because it would require multiple reaching\n/// definitions, which would require multiple phis, and multiple memoryaccesses\n/// per instruction.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_MEMORYSSA_H\n#define LLVM_ANALYSIS_MEMORYSSA_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/ilist.h\"\n#include \"llvm/ADT/ilist_node.h\"\n#include \"llvm/ADT/iterator.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/ADT/simple_ilist.h\"\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/Analysis/MemoryLocation.h\"\n#include \"llvm/Analysis/PHITransAddr.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/DerivedUser.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/Operator.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/IR/Use.h\"\n#include \"llvm/IR/User.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/CommandLine.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstddef>\n#include <iterator>\n#include <memory>\n#include <utility>\n\nnamespace llvm {\n\n/// Enables memory ssa as a dependency for loop passes.\nextern cl::opt<bool> EnableMSSALoopDependency;\n\nclass AllocaInst;\nclass Function;\nclass Instruction;\nclass MemoryAccess;\nclass MemorySSAWalker;\nclass LLVMContext;\nclass raw_ostream;\n\nnamespace MSSAHelpers {\n\nstruct AllAccessTag {};\nstruct DefsOnlyTag {};\n\n} // end namespace MSSAHelpers\n\nenum : unsigned {\n  // Used to signify what the default invalid ID is for MemoryAccess's\n  // getID()\n  INVALID_MEMORYACCESS_ID = -1U\n};\n\ntemplate <class T> class memoryaccess_def_iterator_base;\nusing memoryaccess_def_iterator = memoryaccess_def_iterator_base<MemoryAccess>;\nusing const_memoryaccess_def_iterator =\n    memoryaccess_def_iterator_base<const MemoryAccess>;\n\n// The base for all memory accesses. All memory accesses in a block are\n// linked together using an intrusive list.\nclass MemoryAccess\n    : public DerivedUser,\n      public ilist_node<MemoryAccess, ilist_tag<MSSAHelpers::AllAccessTag>>,\n      public ilist_node<MemoryAccess, ilist_tag<MSSAHelpers::DefsOnlyTag>> {\npublic:\n  using AllAccessType =\n      ilist_node<MemoryAccess, ilist_tag<MSSAHelpers::AllAccessTag>>;\n  using DefsOnlyType =\n      ilist_node<MemoryAccess, ilist_tag<MSSAHelpers::DefsOnlyTag>>;\n\n  MemoryAccess(const MemoryAccess &) = delete;\n  MemoryAccess &operator=(const MemoryAccess &) = delete;\n\n  void *operator new(size_t) = delete;\n\n  // Methods for support type inquiry through isa, cast, and\n  // dyn_cast\n  static bool classof(const Value *V) {\n    unsigned ID = V->getValueID();\n    return ID == MemoryUseVal || ID == MemoryPhiVal || ID == MemoryDefVal;\n  }\n\n  BasicBlock *getBlock() const { return Block; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\n  /// The user iterators for a memory access\n  using iterator = user_iterator;\n  using const_iterator = const_user_iterator;\n\n  /// This iterator walks over all of the defs in a given\n  /// MemoryAccess. For MemoryPhi nodes, this walks arguments. For\n  /// MemoryUse/MemoryDef, this walks the defining access.\n  memoryaccess_def_iterator defs_begin();\n  const_memoryaccess_def_iterator defs_begin() const;\n  memoryaccess_def_iterator defs_end();\n  const_memoryaccess_def_iterator defs_end() const;\n\n  /// Get the iterators for the all access list and the defs only list\n  /// We default to the all access list.\n  AllAccessType::self_iterator getIterator() {\n    return this->AllAccessType::getIterator();\n  }\n  AllAccessType::const_self_iterator getIterator() const {\n    return this->AllAccessType::getIterator();\n  }\n  AllAccessType::reverse_self_iterator getReverseIterator() {\n    return this->AllAccessType::getReverseIterator();\n  }\n  AllAccessType::const_reverse_self_iterator getReverseIterator() const {\n    return this->AllAccessType::getReverseIterator();\n  }\n  DefsOnlyType::self_iterator getDefsIterator() {\n    return this->DefsOnlyType::getIterator();\n  }\n  DefsOnlyType::const_self_iterator getDefsIterator() const {\n    return this->DefsOnlyType::getIterator();\n  }\n  DefsOnlyType::reverse_self_iterator getReverseDefsIterator() {\n    return this->DefsOnlyType::getReverseIterator();\n  }\n  DefsOnlyType::const_reverse_self_iterator getReverseDefsIterator() const {\n    return this->DefsOnlyType::getReverseIterator();\n  }\n\nprotected:\n  friend class MemoryDef;\n  friend class MemoryPhi;\n  friend class MemorySSA;\n  friend class MemoryUse;\n  friend class MemoryUseOrDef;\n\n  /// Used by MemorySSA to change the block of a MemoryAccess when it is\n  /// moved.\n  void setBlock(BasicBlock *BB) { Block = BB; }\n\n  /// Used for debugging and tracking things about MemoryAccesses.\n  /// Guaranteed unique among MemoryAccesses, no guarantees otherwise.\n  inline unsigned getID() const;\n\n  MemoryAccess(LLVMContext &C, unsigned Vty, DeleteValueTy DeleteValue,\n               BasicBlock *BB, unsigned NumOperands)\n      : DerivedUser(Type::getVoidTy(C), Vty, nullptr, NumOperands, DeleteValue),\n        Block(BB) {}\n\n  // Use deleteValue() to delete a generic MemoryAccess.\n  ~MemoryAccess() = default;\n\nprivate:\n  BasicBlock *Block;\n};\n\ntemplate <>\nstruct ilist_alloc_traits<MemoryAccess> {\n  static void deleteNode(MemoryAccess *MA) { MA->deleteValue(); }\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const MemoryAccess &MA) {\n  MA.print(OS);\n  return OS;\n}\n\n/// Class that has the common methods + fields of memory uses/defs. It's\n/// a little awkward to have, but there are many cases where we want either a\n/// use or def, and there are many cases where uses are needed (defs aren't\n/// acceptable), and vice-versa.\n///\n/// This class should never be instantiated directly; make a MemoryUse or\n/// MemoryDef instead.\nclass MemoryUseOrDef : public MemoryAccess {\npublic:\n  void *operator new(size_t) = delete;\n\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(MemoryAccess);\n\n  /// Get the instruction that this MemoryUse represents.\n  Instruction *getMemoryInst() const { return MemoryInstruction; }\n\n  /// Get the access that produces the memory state used by this Use.\n  MemoryAccess *getDefiningAccess() const { return getOperand(0); }\n\n  static bool classof(const Value *MA) {\n    return MA->getValueID() == MemoryUseVal || MA->getValueID() == MemoryDefVal;\n  }\n\n  // Sadly, these have to be public because they are needed in some of the\n  // iterators.\n  inline bool isOptimized() const;\n  inline MemoryAccess *getOptimized() const;\n  inline void setOptimized(MemoryAccess *);\n\n  // Retrieve AliasResult type of the optimized access. Ideally this would be\n  // returned by the caching walker and may go away in the future.\n  Optional<AliasResult> getOptimizedAccessType() const {\n    return isOptimized() ? OptimizedAccessAlias : None;\n  }\n\n  /// Reset the ID of what this MemoryUse was optimized to, causing it to\n  /// be rewalked by the walker if necessary.\n  /// This really should only be called by tests.\n  inline void resetOptimized();\n\nprotected:\n  friend class MemorySSA;\n  friend class MemorySSAUpdater;\n\n  MemoryUseOrDef(LLVMContext &C, MemoryAccess *DMA, unsigned Vty,\n                 DeleteValueTy DeleteValue, Instruction *MI, BasicBlock *BB,\n                 unsigned NumOperands)\n      : MemoryAccess(C, Vty, DeleteValue, BB, NumOperands),\n        MemoryInstruction(MI), OptimizedAccessAlias(MayAlias) {\n    setDefiningAccess(DMA);\n  }\n\n  // Use deleteValue() to delete a generic MemoryUseOrDef.\n  ~MemoryUseOrDef() = default;\n\n  void setOptimizedAccessType(Optional<AliasResult> AR) {\n    OptimizedAccessAlias = AR;\n  }\n\n  void setDefiningAccess(MemoryAccess *DMA, bool Optimized = false,\n                         Optional<AliasResult> AR = MayAlias) {\n    if (!Optimized) {\n      setOperand(0, DMA);\n      return;\n    }\n    setOptimized(DMA);\n    setOptimizedAccessType(AR);\n  }\n\nprivate:\n  Instruction *MemoryInstruction;\n  Optional<AliasResult> OptimizedAccessAlias;\n};\n\n/// Represents read-only accesses to memory\n///\n/// In particular, the set of Instructions that will be represented by\n/// MemoryUse's is exactly the set of Instructions for which\n/// AliasAnalysis::getModRefInfo returns \"Ref\".\nclass MemoryUse final : public MemoryUseOrDef {\npublic:\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(MemoryAccess);\n\n  MemoryUse(LLVMContext &C, MemoryAccess *DMA, Instruction *MI, BasicBlock *BB)\n      : MemoryUseOrDef(C, DMA, MemoryUseVal, deleteMe, MI, BB,\n                       /*NumOperands=*/1) {}\n\n  // allocate space for exactly one operand\n  void *operator new(size_t s) { return User::operator new(s, 1); }\n\n  static bool classof(const Value *MA) {\n    return MA->getValueID() == MemoryUseVal;\n  }\n\n  void print(raw_ostream &OS) const;\n\n  void setOptimized(MemoryAccess *DMA) {\n    OptimizedID = DMA->getID();\n    setOperand(0, DMA);\n  }\n\n  bool isOptimized() const {\n    return getDefiningAccess() && OptimizedID == getDefiningAccess()->getID();\n  }\n\n  MemoryAccess *getOptimized() const {\n    return getDefiningAccess();\n  }\n\n  void resetOptimized() {\n    OptimizedID = INVALID_MEMORYACCESS_ID;\n  }\n\nprotected:\n  friend class MemorySSA;\n\nprivate:\n  static void deleteMe(DerivedUser *Self);\n\n  unsigned OptimizedID = INVALID_MEMORYACCESS_ID;\n};\n\ntemplate <>\nstruct OperandTraits<MemoryUse> : public FixedNumOperandTraits<MemoryUse, 1> {};\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(MemoryUse, MemoryAccess)\n\n/// Represents a read-write access to memory, whether it is a must-alias,\n/// or a may-alias.\n///\n/// In particular, the set of Instructions that will be represented by\n/// MemoryDef's is exactly the set of Instructions for which\n/// AliasAnalysis::getModRefInfo returns \"Mod\" or \"ModRef\".\n/// Note that, in order to provide def-def chains, all defs also have a use\n/// associated with them. This use points to the nearest reaching\n/// MemoryDef/MemoryPhi.\nclass MemoryDef final : public MemoryUseOrDef {\npublic:\n  friend class MemorySSA;\n\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(MemoryAccess);\n\n  MemoryDef(LLVMContext &C, MemoryAccess *DMA, Instruction *MI, BasicBlock *BB,\n            unsigned Ver)\n      : MemoryUseOrDef(C, DMA, MemoryDefVal, deleteMe, MI, BB,\n                       /*NumOperands=*/2),\n        ID(Ver) {}\n\n  // allocate space for exactly two operands\n  void *operator new(size_t s) { return User::operator new(s, 2); }\n\n  static bool classof(const Value *MA) {\n    return MA->getValueID() == MemoryDefVal;\n  }\n\n  void setOptimized(MemoryAccess *MA) {\n    setOperand(1, MA);\n    OptimizedID = MA->getID();\n  }\n\n  MemoryAccess *getOptimized() const {\n    return cast_or_null<MemoryAccess>(getOperand(1));\n  }\n\n  bool isOptimized() const {\n    return getOptimized() && OptimizedID == getOptimized()->getID();\n  }\n\n  void resetOptimized() {\n    OptimizedID = INVALID_MEMORYACCESS_ID;\n    setOperand(1, nullptr);\n  }\n\n  void print(raw_ostream &OS) const;\n\n  unsigned getID() const { return ID; }\n\nprivate:\n  static void deleteMe(DerivedUser *Self);\n\n  const unsigned ID;\n  unsigned OptimizedID = INVALID_MEMORYACCESS_ID;\n};\n\ntemplate <>\nstruct OperandTraits<MemoryDef> : public FixedNumOperandTraits<MemoryDef, 2> {};\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(MemoryDef, MemoryAccess)\n\ntemplate <>\nstruct OperandTraits<MemoryUseOrDef> {\n  static Use *op_begin(MemoryUseOrDef *MUD) {\n    if (auto *MU = dyn_cast<MemoryUse>(MUD))\n      return OperandTraits<MemoryUse>::op_begin(MU);\n    return OperandTraits<MemoryDef>::op_begin(cast<MemoryDef>(MUD));\n  }\n\n  static Use *op_end(MemoryUseOrDef *MUD) {\n    if (auto *MU = dyn_cast<MemoryUse>(MUD))\n      return OperandTraits<MemoryUse>::op_end(MU);\n    return OperandTraits<MemoryDef>::op_end(cast<MemoryDef>(MUD));\n  }\n\n  static unsigned operands(const MemoryUseOrDef *MUD) {\n    if (const auto *MU = dyn_cast<MemoryUse>(MUD))\n      return OperandTraits<MemoryUse>::operands(MU);\n    return OperandTraits<MemoryDef>::operands(cast<MemoryDef>(MUD));\n  }\n};\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(MemoryUseOrDef, MemoryAccess)\n\n/// Represents phi nodes for memory accesses.\n///\n/// These have the same semantic as regular phi nodes, with the exception that\n/// only one phi will ever exist in a given basic block.\n/// Guaranteeing one phi per block means guaranteeing there is only ever one\n/// valid reaching MemoryDef/MemoryPHI along each path to the phi node.\n/// This is ensured by not allowing disambiguation of the RHS of a MemoryDef or\n/// a MemoryPhi's operands.\n/// That is, given\n/// if (a) {\n///   store %a\n///   store %b\n/// }\n/// it *must* be transformed into\n/// if (a) {\n///    1 = MemoryDef(liveOnEntry)\n///    store %a\n///    2 = MemoryDef(1)\n///    store %b\n/// }\n/// and *not*\n/// if (a) {\n///    1 = MemoryDef(liveOnEntry)\n///    store %a\n///    2 = MemoryDef(liveOnEntry)\n///    store %b\n/// }\n/// even if the two stores do not conflict. Otherwise, both 1 and 2 reach the\n/// end of the branch, and if there are not two phi nodes, one will be\n/// disconnected completely from the SSA graph below that point.\n/// Because MemoryUse's do not generate new definitions, they do not have this\n/// issue.\nclass MemoryPhi final : public MemoryAccess {\n  // allocate space for exactly zero operands\n  void *operator new(size_t s) { return User::operator new(s); }\n\npublic:\n  /// Provide fast operand accessors\n  DECLARE_TRANSPARENT_OPERAND_ACCESSORS(MemoryAccess);\n\n  MemoryPhi(LLVMContext &C, BasicBlock *BB, unsigned Ver, unsigned NumPreds = 0)\n      : MemoryAccess(C, MemoryPhiVal, deleteMe, BB, 0), ID(Ver),\n        ReservedSpace(NumPreds) {\n    allocHungoffUses(ReservedSpace);\n  }\n\n  // Block iterator interface. This provides access to the list of incoming\n  // basic blocks, which parallels the list of incoming values.\n  using block_iterator = BasicBlock **;\n  using const_block_iterator = BasicBlock *const *;\n\n  block_iterator block_begin() {\n    return reinterpret_cast<block_iterator>(op_begin() + ReservedSpace);\n  }\n\n  const_block_iterator block_begin() const {\n    return reinterpret_cast<const_block_iterator>(op_begin() + ReservedSpace);\n  }\n\n  block_iterator block_end() { return block_begin() + getNumOperands(); }\n\n  const_block_iterator block_end() const {\n    return block_begin() + getNumOperands();\n  }\n\n  iterator_range<block_iterator> blocks() {\n    return make_range(block_begin(), block_end());\n  }\n\n  iterator_range<const_block_iterator> blocks() const {\n    return make_range(block_begin(), block_end());\n  }\n\n  op_range incoming_values() { return operands(); }\n\n  const_op_range incoming_values() const { return operands(); }\n\n  /// Return the number of incoming edges\n  unsigned getNumIncomingValues() const { return getNumOperands(); }\n\n  /// Return incoming value number x\n  MemoryAccess *getIncomingValue(unsigned I) const { return getOperand(I); }\n  void setIncomingValue(unsigned I, MemoryAccess *V) {\n    assert(V && \"PHI node got a null value!\");\n    setOperand(I, V);\n  }\n\n  static unsigned getOperandNumForIncomingValue(unsigned I) { return I; }\n  static unsigned getIncomingValueNumForOperand(unsigned I) { return I; }\n\n  /// Return incoming basic block number @p i.\n  BasicBlock *getIncomingBlock(unsigned I) const { return block_begin()[I]; }\n\n  /// Return incoming basic block corresponding\n  /// to an operand of the PHI.\n  BasicBlock *getIncomingBlock(const Use &U) const {\n    assert(this == U.getUser() && \"Iterator doesn't point to PHI's Uses?\");\n    return getIncomingBlock(unsigned(&U - op_begin()));\n  }\n\n  /// Return incoming basic block corresponding\n  /// to value use iterator.\n  BasicBlock *getIncomingBlock(MemoryAccess::const_user_iterator I) const {\n    return getIncomingBlock(I.getUse());\n  }\n\n  void setIncomingBlock(unsigned I, BasicBlock *BB) {\n    assert(BB && \"PHI node got a null basic block!\");\n    block_begin()[I] = BB;\n  }\n\n  /// Add an incoming value to the end of the PHI list\n  void addIncoming(MemoryAccess *V, BasicBlock *BB) {\n    if (getNumOperands() == ReservedSpace)\n      growOperands(); // Get more space!\n    // Initialize some new operands.\n    setNumHungOffUseOperands(getNumOperands() + 1);\n    setIncomingValue(getNumOperands() - 1, V);\n    setIncomingBlock(getNumOperands() - 1, BB);\n  }\n\n  /// Return the first index of the specified basic\n  /// block in the value list for this PHI.  Returns -1 if no instance.\n  int getBasicBlockIndex(const BasicBlock *BB) const {\n    for (unsigned I = 0, E = getNumOperands(); I != E; ++I)\n      if (block_begin()[I] == BB)\n        return I;\n    return -1;\n  }\n\n  MemoryAccess *getIncomingValueForBlock(const BasicBlock *BB) const {\n    int Idx = getBasicBlockIndex(BB);\n    assert(Idx >= 0 && \"Invalid basic block argument!\");\n    return getIncomingValue(Idx);\n  }\n\n  // After deleting incoming position I, the order of incoming may be changed.\n  void unorderedDeleteIncoming(unsigned I) {\n    unsigned E = getNumOperands();\n    assert(I < E && \"Cannot remove out of bounds Phi entry.\");\n    // MemoryPhi must have at least two incoming values, otherwise the MemoryPhi\n    // itself should be deleted.\n    assert(E >= 2 && \"Cannot only remove incoming values in MemoryPhis with \"\n                     \"at least 2 values.\");\n    setIncomingValue(I, getIncomingValue(E - 1));\n    setIncomingBlock(I, block_begin()[E - 1]);\n    setOperand(E - 1, nullptr);\n    block_begin()[E - 1] = nullptr;\n    setNumHungOffUseOperands(getNumOperands() - 1);\n  }\n\n  // After deleting entries that satisfy Pred, remaining entries may have\n  // changed order.\n  template <typename Fn> void unorderedDeleteIncomingIf(Fn &&Pred) {\n    for (unsigned I = 0, E = getNumOperands(); I != E; ++I)\n      if (Pred(getIncomingValue(I), getIncomingBlock(I))) {\n        unorderedDeleteIncoming(I);\n        E = getNumOperands();\n        --I;\n      }\n    assert(getNumOperands() >= 1 &&\n           \"Cannot remove all incoming blocks in a MemoryPhi.\");\n  }\n\n  // After deleting incoming block BB, the incoming blocks order may be changed.\n  void unorderedDeleteIncomingBlock(const BasicBlock *BB) {\n    unorderedDeleteIncomingIf(\n        [&](const MemoryAccess *, const BasicBlock *B) { return BB == B; });\n  }\n\n  // After deleting incoming memory access MA, the incoming accesses order may\n  // be changed.\n  void unorderedDeleteIncomingValue(const MemoryAccess *MA) {\n    unorderedDeleteIncomingIf(\n        [&](const MemoryAccess *M, const BasicBlock *) { return MA == M; });\n  }\n\n  static bool classof(const Value *V) {\n    return V->getValueID() == MemoryPhiVal;\n  }\n\n  void print(raw_ostream &OS) const;\n\n  unsigned getID() const { return ID; }\n\nprotected:\n  friend class MemorySSA;\n\n  /// this is more complicated than the generic\n  /// User::allocHungoffUses, because we have to allocate Uses for the incoming\n  /// values and pointers to the incoming blocks, all in one allocation.\n  void allocHungoffUses(unsigned N) {\n    User::allocHungoffUses(N, /* IsPhi */ true);\n  }\n\nprivate:\n  // For debugging only\n  const unsigned ID;\n  unsigned ReservedSpace;\n\n  /// This grows the operand list in response to a push_back style of\n  /// operation.  This grows the number of ops by 1.5 times.\n  void growOperands() {\n    unsigned E = getNumOperands();\n    // 2 op PHI nodes are VERY common, so reserve at least enough for that.\n    ReservedSpace = std::max(E + E / 2, 2u);\n    growHungoffUses(ReservedSpace, /* IsPhi */ true);\n  }\n\n  static void deleteMe(DerivedUser *Self);\n};\n\ninline unsigned MemoryAccess::getID() const {\n  assert((isa<MemoryDef>(this) || isa<MemoryPhi>(this)) &&\n         \"only memory defs and phis have ids\");\n  if (const auto *MD = dyn_cast<MemoryDef>(this))\n    return MD->getID();\n  return cast<MemoryPhi>(this)->getID();\n}\n\ninline bool MemoryUseOrDef::isOptimized() const {\n  if (const auto *MD = dyn_cast<MemoryDef>(this))\n    return MD->isOptimized();\n  return cast<MemoryUse>(this)->isOptimized();\n}\n\ninline MemoryAccess *MemoryUseOrDef::getOptimized() const {\n  if (const auto *MD = dyn_cast<MemoryDef>(this))\n    return MD->getOptimized();\n  return cast<MemoryUse>(this)->getOptimized();\n}\n\ninline void MemoryUseOrDef::setOptimized(MemoryAccess *MA) {\n  if (auto *MD = dyn_cast<MemoryDef>(this))\n    MD->setOptimized(MA);\n  else\n    cast<MemoryUse>(this)->setOptimized(MA);\n}\n\ninline void MemoryUseOrDef::resetOptimized() {\n  if (auto *MD = dyn_cast<MemoryDef>(this))\n    MD->resetOptimized();\n  else\n    cast<MemoryUse>(this)->resetOptimized();\n}\n\ntemplate <> struct OperandTraits<MemoryPhi> : public HungoffOperandTraits<2> {};\nDEFINE_TRANSPARENT_OPERAND_ACCESSORS(MemoryPhi, MemoryAccess)\n\n/// Encapsulates MemorySSA, including all data associated with memory\n/// accesses.\nclass MemorySSA {\npublic:\n  MemorySSA(Function &, AliasAnalysis *, DominatorTree *);\n\n  // MemorySSA must remain where it's constructed; Walkers it creates store\n  // pointers to it.\n  MemorySSA(MemorySSA &&) = delete;\n\n  ~MemorySSA();\n\n  MemorySSAWalker *getWalker();\n  MemorySSAWalker *getSkipSelfWalker();\n\n  /// Given a memory Mod/Ref'ing instruction, get the MemorySSA\n  /// access associated with it. If passed a basic block gets the memory phi\n  /// node that exists for that block, if there is one. Otherwise, this will get\n  /// a MemoryUseOrDef.\n  MemoryUseOrDef *getMemoryAccess(const Instruction *I) const {\n    return cast_or_null<MemoryUseOrDef>(ValueToMemoryAccess.lookup(I));\n  }\n\n  MemoryPhi *getMemoryAccess(const BasicBlock *BB) const {\n    return cast_or_null<MemoryPhi>(ValueToMemoryAccess.lookup(cast<Value>(BB)));\n  }\n\n  DominatorTree &getDomTree() const { return *DT; }\n\n  void dump() const;\n  void print(raw_ostream &) const;\n\n  /// Return true if \\p MA represents the live on entry value\n  ///\n  /// Loads and stores from pointer arguments and other global values may be\n  /// defined by memory operations that do not occur in the current function, so\n  /// they may be live on entry to the function. MemorySSA represents such\n  /// memory state by the live on entry definition, which is guaranteed to occur\n  /// before any other memory access in the function.\n  inline bool isLiveOnEntryDef(const MemoryAccess *MA) const {\n    return MA == LiveOnEntryDef.get();\n  }\n\n  inline MemoryAccess *getLiveOnEntryDef() const {\n    return LiveOnEntryDef.get();\n  }\n\n  // Sadly, iplists, by default, owns and deletes pointers added to the\n  // list. It's not currently possible to have two iplists for the same type,\n  // where one owns the pointers, and one does not. This is because the traits\n  // are per-type, not per-tag.  If this ever changes, we should make the\n  // DefList an iplist.\n  using AccessList = iplist<MemoryAccess, ilist_tag<MSSAHelpers::AllAccessTag>>;\n  using DefsList =\n      simple_ilist<MemoryAccess, ilist_tag<MSSAHelpers::DefsOnlyTag>>;\n\n  /// Return the list of MemoryAccess's for a given basic block.\n  ///\n  /// This list is not modifiable by the user.\n  const AccessList *getBlockAccesses(const BasicBlock *BB) const {\n    return getWritableBlockAccesses(BB);\n  }\n\n  /// Return the list of MemoryDef's and MemoryPhi's for a given basic\n  /// block.\n  ///\n  /// This list is not modifiable by the user.\n  const DefsList *getBlockDefs(const BasicBlock *BB) const {\n    return getWritableBlockDefs(BB);\n  }\n\n  /// Given two memory accesses in the same basic block, determine\n  /// whether MemoryAccess \\p A dominates MemoryAccess \\p B.\n  bool locallyDominates(const MemoryAccess *A, const MemoryAccess *B) const;\n\n  /// Given two memory accesses in potentially different blocks,\n  /// determine whether MemoryAccess \\p A dominates MemoryAccess \\p B.\n  bool dominates(const MemoryAccess *A, const MemoryAccess *B) const;\n\n  /// Given a MemoryAccess and a Use, determine whether MemoryAccess \\p A\n  /// dominates Use \\p B.\n  bool dominates(const MemoryAccess *A, const Use &B) const;\n\n  /// Verify that MemorySSA is self consistent (IE definitions dominate\n  /// all uses, uses appear in the right places).  This is used by unit tests.\n  void verifyMemorySSA() const;\n\n  /// Used in various insertion functions to specify whether we are talking\n  /// about the beginning or end of a block.\n  enum InsertionPlace { Beginning, End, BeforeTerminator };\n\nprotected:\n  // Used by Memory SSA annotater, dumpers, and wrapper pass\n  friend class MemorySSAAnnotatedWriter;\n  friend class MemorySSAPrinterLegacyPass;\n  friend class MemorySSAUpdater;\n\n  void verifyOrderingDominationAndDefUses(Function &F) const;\n  void verifyDominationNumbers(const Function &F) const;\n  void verifyPrevDefInPhis(Function &F) const;\n\n  // This is used by the use optimizer and updater.\n  AccessList *getWritableBlockAccesses(const BasicBlock *BB) const {\n    auto It = PerBlockAccesses.find(BB);\n    return It == PerBlockAccesses.end() ? nullptr : It->second.get();\n  }\n\n  // This is used by the use optimizer and updater.\n  DefsList *getWritableBlockDefs(const BasicBlock *BB) const {\n    auto It = PerBlockDefs.find(BB);\n    return It == PerBlockDefs.end() ? nullptr : It->second.get();\n  }\n\n  // These is used by the updater to perform various internal MemorySSA\n  // machinsations.  They do not always leave the IR in a correct state, and\n  // relies on the updater to fixup what it breaks, so it is not public.\n\n  void moveTo(MemoryUseOrDef *What, BasicBlock *BB, AccessList::iterator Where);\n  void moveTo(MemoryAccess *What, BasicBlock *BB, InsertionPlace Point);\n\n  // Rename the dominator tree branch rooted at BB.\n  void renamePass(BasicBlock *BB, MemoryAccess *IncomingVal,\n                  SmallPtrSetImpl<BasicBlock *> &Visited) {\n    renamePass(DT->getNode(BB), IncomingVal, Visited, true, true);\n  }\n\n  void removeFromLookups(MemoryAccess *);\n  void removeFromLists(MemoryAccess *, bool ShouldDelete = true);\n  void insertIntoListsForBlock(MemoryAccess *, const BasicBlock *,\n                               InsertionPlace);\n  void insertIntoListsBefore(MemoryAccess *, const BasicBlock *,\n                             AccessList::iterator);\n  MemoryUseOrDef *createDefinedAccess(Instruction *, MemoryAccess *,\n                                      const MemoryUseOrDef *Template = nullptr,\n                                      bool CreationMustSucceed = true);\n\nprivate:\n  template <class AliasAnalysisType> class ClobberWalkerBase;\n  template <class AliasAnalysisType> class CachingWalker;\n  template <class AliasAnalysisType> class SkipSelfWalker;\n  class OptimizeUses;\n\n  CachingWalker<AliasAnalysis> *getWalkerImpl();\n  void buildMemorySSA(BatchAAResults &BAA);\n\n  void prepareForMoveTo(MemoryAccess *, BasicBlock *);\n  void verifyUseInDefs(MemoryAccess *, MemoryAccess *) const;\n\n  using AccessMap = DenseMap<const BasicBlock *, std::unique_ptr<AccessList>>;\n  using DefsMap = DenseMap<const BasicBlock *, std::unique_ptr<DefsList>>;\n\n  void markUnreachableAsLiveOnEntry(BasicBlock *BB);\n  MemoryPhi *createMemoryPhi(BasicBlock *BB);\n  template <typename AliasAnalysisType>\n  MemoryUseOrDef *createNewAccess(Instruction *, AliasAnalysisType *,\n                                  const MemoryUseOrDef *Template = nullptr);\n  void placePHINodes(const SmallPtrSetImpl<BasicBlock *> &);\n  MemoryAccess *renameBlock(BasicBlock *, MemoryAccess *, bool);\n  void renameSuccessorPhis(BasicBlock *, MemoryAccess *, bool);\n  void renamePass(DomTreeNode *, MemoryAccess *IncomingVal,\n                  SmallPtrSetImpl<BasicBlock *> &Visited,\n                  bool SkipVisited = false, bool RenameAllUses = false);\n  AccessList *getOrCreateAccessList(const BasicBlock *);\n  DefsList *getOrCreateDefsList(const BasicBlock *);\n  void renumberBlock(const BasicBlock *) const;\n  AliasAnalysis *AA;\n  DominatorTree *DT;\n  Function &F;\n\n  // Memory SSA mappings\n  DenseMap<const Value *, MemoryAccess *> ValueToMemoryAccess;\n\n  // These two mappings contain the main block to access/def mappings for\n  // MemorySSA. The list contained in PerBlockAccesses really owns all the\n  // MemoryAccesses.\n  // Both maps maintain the invariant that if a block is found in them, the\n  // corresponding list is not empty, and if a block is not found in them, the\n  // corresponding list is empty.\n  AccessMap PerBlockAccesses;\n  DefsMap PerBlockDefs;\n  std::unique_ptr<MemoryAccess, ValueDeleter> LiveOnEntryDef;\n\n  // Domination mappings\n  // Note that the numbering is local to a block, even though the map is\n  // global.\n  mutable SmallPtrSet<const BasicBlock *, 16> BlockNumberingValid;\n  mutable DenseMap<const MemoryAccess *, unsigned long> BlockNumbering;\n\n  // Memory SSA building info\n  std::unique_ptr<ClobberWalkerBase<AliasAnalysis>> WalkerBase;\n  std::unique_ptr<CachingWalker<AliasAnalysis>> Walker;\n  std::unique_ptr<SkipSelfWalker<AliasAnalysis>> SkipWalker;\n  unsigned NextID;\n};\n\n// Internal MemorySSA utils, for use by MemorySSA classes and walkers\nclass MemorySSAUtil {\nprotected:\n  friend class GVNHoist;\n  friend class MemorySSAWalker;\n\n  // This function should not be used by new passes.\n  static bool defClobbersUseOrDef(MemoryDef *MD, const MemoryUseOrDef *MU,\n                                  AliasAnalysis &AA);\n};\n\n// This pass does eager building and then printing of MemorySSA. It is used by\n// the tests to be able to build, dump, and verify Memory SSA.\nclass MemorySSAPrinterLegacyPass : public FunctionPass {\npublic:\n  MemorySSAPrinterLegacyPass();\n\n  bool runOnFunction(Function &) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  static char ID;\n};\n\n/// An analysis that produces \\c MemorySSA for a function.\n///\nclass MemorySSAAnalysis : public AnalysisInfoMixin<MemorySSAAnalysis> {\n  friend AnalysisInfoMixin<MemorySSAAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  // Wrap MemorySSA result to ensure address stability of internal MemorySSA\n  // pointers after construction.  Use a wrapper class instead of plain\n  // unique_ptr<MemorySSA> to avoid build breakage on MSVC.\n  struct Result {\n    Result(std::unique_ptr<MemorySSA> &&MSSA) : MSSA(std::move(MSSA)) {}\n\n    MemorySSA &getMSSA() { return *MSSA.get(); }\n\n    std::unique_ptr<MemorySSA> MSSA;\n\n    bool invalidate(Function &F, const PreservedAnalyses &PA,\n                    FunctionAnalysisManager::Invalidator &Inv);\n  };\n\n  Result run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for \\c MemorySSA.\nclass MemorySSAPrinterPass : public PassInfoMixin<MemorySSAPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit MemorySSAPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for \\c MemorySSA.\nstruct MemorySSAVerifierPass : PassInfoMixin<MemorySSAVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy analysis pass which computes \\c MemorySSA.\nclass MemorySSAWrapperPass : public FunctionPass {\npublic:\n  MemorySSAWrapperPass();\n\n  static char ID;\n\n  bool runOnFunction(Function &) override;\n  void releaseMemory() override;\n  MemorySSA &getMSSA() { return *MSSA; }\n  const MemorySSA &getMSSA() const { return *MSSA; }\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  void verifyAnalysis() const override;\n  void print(raw_ostream &OS, const Module *M = nullptr) const override;\n\nprivate:\n  std::unique_ptr<MemorySSA> MSSA;\n};\n\n/// This is the generic walker interface for walkers of MemorySSA.\n/// Walkers are used to be able to further disambiguate the def-use chains\n/// MemorySSA gives you, or otherwise produce better info than MemorySSA gives\n/// you.\n/// In particular, while the def-use chains provide basic information, and are\n/// guaranteed to give, for example, the nearest may-aliasing MemoryDef for a\n/// MemoryUse as AliasAnalysis considers it, a user mant want better or other\n/// information. In particular, they may want to use SCEV info to further\n/// disambiguate memory accesses, or they may want the nearest dominating\n/// may-aliasing MemoryDef for a call or a store. This API enables a\n/// standardized interface to getting and using that info.\nclass MemorySSAWalker {\npublic:\n  MemorySSAWalker(MemorySSA *);\n  virtual ~MemorySSAWalker() = default;\n\n  using MemoryAccessSet = SmallVector<MemoryAccess *, 8>;\n\n  /// Given a memory Mod/Ref/ModRef'ing instruction, calling this\n  /// will give you the nearest dominating MemoryAccess that Mod's the location\n  /// the instruction accesses (by skipping any def which AA can prove does not\n  /// alias the location(s) accessed by the instruction given).\n  ///\n  /// Note that this will return a single access, and it must dominate the\n  /// Instruction, so if an operand of a MemoryPhi node Mod's the instruction,\n  /// this will return the MemoryPhi, not the operand. This means that\n  /// given:\n  /// if (a) {\n  ///   1 = MemoryDef(liveOnEntry)\n  ///   store %a\n  /// } else {\n  ///   2 = MemoryDef(liveOnEntry)\n  ///   store %b\n  /// }\n  /// 3 = MemoryPhi(2, 1)\n  /// MemoryUse(3)\n  /// load %a\n  ///\n  /// calling this API on load(%a) will return the MemoryPhi, not the MemoryDef\n  /// in the if (a) branch.\n  MemoryAccess *getClobberingMemoryAccess(const Instruction *I) {\n    MemoryAccess *MA = MSSA->getMemoryAccess(I);\n    assert(MA && \"Handed an instruction that MemorySSA doesn't recognize?\");\n    return getClobberingMemoryAccess(MA);\n  }\n\n  /// Does the same thing as getClobberingMemoryAccess(const Instruction *I),\n  /// but takes a MemoryAccess instead of an Instruction.\n  virtual MemoryAccess *getClobberingMemoryAccess(MemoryAccess *) = 0;\n\n  /// Given a potentially clobbering memory access and a new location,\n  /// calling this will give you the nearest dominating clobbering MemoryAccess\n  /// (by skipping non-aliasing def links).\n  ///\n  /// This version of the function is mainly used to disambiguate phi translated\n  /// pointers, where the value of a pointer may have changed from the initial\n  /// memory access. Note that this expects to be handed either a MemoryUse,\n  /// or an already potentially clobbering access. Unlike the above API, if\n  /// given a MemoryDef that clobbers the pointer as the starting access, it\n  /// will return that MemoryDef, whereas the above would return the clobber\n  /// starting from the use side of  the memory def.\n  virtual MemoryAccess *getClobberingMemoryAccess(MemoryAccess *,\n                                                  const MemoryLocation &) = 0;\n\n  /// Given a memory access, invalidate anything this walker knows about\n  /// that access.\n  /// This API is used by walkers that store information to perform basic cache\n  /// invalidation.  This will be called by MemorySSA at appropriate times for\n  /// the walker it uses or returns.\n  virtual void invalidateInfo(MemoryAccess *) {}\n\nprotected:\n  friend class MemorySSA; // For updating MSSA pointer in MemorySSA move\n                          // constructor.\n  MemorySSA *MSSA;\n};\n\n/// A MemorySSAWalker that does no alias queries, or anything else. It\n/// simply returns the links as they were constructed by the builder.\nclass DoNothingMemorySSAWalker final : public MemorySSAWalker {\npublic:\n  // Keep the overrides below from hiding the Instruction overload of\n  // getClobberingMemoryAccess.\n  using MemorySSAWalker::getClobberingMemoryAccess;\n\n  MemoryAccess *getClobberingMemoryAccess(MemoryAccess *) override;\n  MemoryAccess *getClobberingMemoryAccess(MemoryAccess *,\n                                          const MemoryLocation &) override;\n};\n\nusing MemoryAccessPair = std::pair<MemoryAccess *, MemoryLocation>;\nusing ConstMemoryAccessPair = std::pair<const MemoryAccess *, MemoryLocation>;\n\n/// Iterator base class used to implement const and non-const iterators\n/// over the defining accesses of a MemoryAccess.\ntemplate <class T>\nclass memoryaccess_def_iterator_base\n    : public iterator_facade_base<memoryaccess_def_iterator_base<T>,\n                                  std::forward_iterator_tag, T, ptrdiff_t, T *,\n                                  T *> {\n  using BaseT = typename memoryaccess_def_iterator_base::iterator_facade_base;\n\npublic:\n  memoryaccess_def_iterator_base(T *Start) : Access(Start) {}\n  memoryaccess_def_iterator_base() = default;\n\n  bool operator==(const memoryaccess_def_iterator_base &Other) const {\n    return Access == Other.Access && (!Access || ArgNo == Other.ArgNo);\n  }\n\n  // This is a bit ugly, but for MemoryPHI's, unlike PHINodes, you can't get the\n  // block from the operand in constant time (In a PHINode, the uselist has\n  // both, so it's just subtraction). We provide it as part of the\n  // iterator to avoid callers having to linear walk to get the block.\n  // If the operation becomes constant time on MemoryPHI's, this bit of\n  // abstraction breaking should be removed.\n  BasicBlock *getPhiArgBlock() const {\n    MemoryPhi *MP = dyn_cast<MemoryPhi>(Access);\n    assert(MP && \"Tried to get phi arg block when not iterating over a PHI\");\n    return MP->getIncomingBlock(ArgNo);\n  }\n\n  typename BaseT::iterator::pointer operator*() const {\n    assert(Access && \"Tried to access past the end of our iterator\");\n    // Go to the first argument for phis, and the defining access for everything\n    // else.\n    if (const MemoryPhi *MP = dyn_cast<MemoryPhi>(Access))\n      return MP->getIncomingValue(ArgNo);\n    return cast<MemoryUseOrDef>(Access)->getDefiningAccess();\n  }\n\n  using BaseT::operator++;\n  memoryaccess_def_iterator_base &operator++() {\n    assert(Access && \"Hit end of iterator\");\n    if (const MemoryPhi *MP = dyn_cast<MemoryPhi>(Access)) {\n      if (++ArgNo >= MP->getNumIncomingValues()) {\n        ArgNo = 0;\n        Access = nullptr;\n      }\n    } else {\n      Access = nullptr;\n    }\n    return *this;\n  }\n\nprivate:\n  T *Access = nullptr;\n  unsigned ArgNo = 0;\n};\n\ninline memoryaccess_def_iterator MemoryAccess::defs_begin() {\n  return memoryaccess_def_iterator(this);\n}\n\ninline const_memoryaccess_def_iterator MemoryAccess::defs_begin() const {\n  return const_memoryaccess_def_iterator(this);\n}\n\ninline memoryaccess_def_iterator MemoryAccess::defs_end() {\n  return memoryaccess_def_iterator();\n}\n\ninline const_memoryaccess_def_iterator MemoryAccess::defs_end() const {\n  return const_memoryaccess_def_iterator();\n}\n\n/// GraphTraits for a MemoryAccess, which walks defs in the normal case,\n/// and uses in the inverse case.\ntemplate <> struct GraphTraits<MemoryAccess *> {\n  using NodeRef = MemoryAccess *;\n  using ChildIteratorType = memoryaccess_def_iterator;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->defs_begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->defs_end(); }\n};\n\ntemplate <> struct GraphTraits<Inverse<MemoryAccess *>> {\n  using NodeRef = MemoryAccess *;\n  using ChildIteratorType = MemoryAccess::iterator;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->user_begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->user_end(); }\n};\n\n/// Provide an iterator that walks defs, giving both the memory access,\n/// and the current pointer location, updating the pointer location as it\n/// changes due to phi node translation.\n///\n/// This iterator, while somewhat specialized, is what most clients actually\n/// want when walking upwards through MemorySSA def chains. It takes a pair of\n/// <MemoryAccess,MemoryLocation>, and walks defs, properly translating the\n/// memory location through phi nodes for the user.\nclass upward_defs_iterator\n    : public iterator_facade_base<upward_defs_iterator,\n                                  std::forward_iterator_tag,\n                                  const MemoryAccessPair> {\n  using BaseT = upward_defs_iterator::iterator_facade_base;\n\npublic:\n  upward_defs_iterator(const MemoryAccessPair &Info, DominatorTree *DT,\n                       bool *PerformedPhiTranslation = nullptr)\n      : DefIterator(Info.first), Location(Info.second),\n        OriginalAccess(Info.first), DT(DT),\n        PerformedPhiTranslation(PerformedPhiTranslation) {\n    CurrentPair.first = nullptr;\n\n    WalkingPhi = Info.first && isa<MemoryPhi>(Info.first);\n    fillInCurrentPair();\n  }\n\n  upward_defs_iterator() { CurrentPair.first = nullptr; }\n\n  bool operator==(const upward_defs_iterator &Other) const {\n    return DefIterator == Other.DefIterator;\n  }\n\n  BaseT::iterator::reference operator*() const {\n    assert(DefIterator != OriginalAccess->defs_end() &&\n           \"Tried to access past the end of our iterator\");\n    return CurrentPair;\n  }\n\n  using BaseT::operator++;\n  upward_defs_iterator &operator++() {\n    assert(DefIterator != OriginalAccess->defs_end() &&\n           \"Tried to access past the end of the iterator\");\n    ++DefIterator;\n    if (DefIterator != OriginalAccess->defs_end())\n      fillInCurrentPair();\n    return *this;\n  }\n\n  BasicBlock *getPhiArgBlock() const { return DefIterator.getPhiArgBlock(); }\n\nprivate:\n  /// Returns true if \\p Ptr is guaranteed to be loop invariant for any possible\n  /// loop. In particular, this guarantees that it only references a single\n  /// MemoryLocation during execution of the containing function.\n  bool IsGuaranteedLoopInvariant(Value *Ptr) const;\n\n  void fillInCurrentPair() {\n    CurrentPair.first = *DefIterator;\n    CurrentPair.second = Location;\n    if (WalkingPhi && Location.Ptr) {\n      // Mark size as unknown, if the location is not guaranteed to be\n      // loop-invariant for any possible loop in the function. Setting the size\n      // to unknown guarantees that any memory accesses that access locations\n      // after the pointer are considered as clobbers, which is important to\n      // catch loop carried dependences.\n      if (Location.Ptr &&\n          !IsGuaranteedLoopInvariant(const_cast<Value *>(Location.Ptr)))\n        CurrentPair.second =\n            Location.getWithNewSize(LocationSize::beforeOrAfterPointer());\n      PHITransAddr Translator(\n          const_cast<Value *>(Location.Ptr),\n          OriginalAccess->getBlock()->getModule()->getDataLayout(), nullptr);\n\n      if (!Translator.PHITranslateValue(OriginalAccess->getBlock(),\n                                        DefIterator.getPhiArgBlock(), DT,\n                                        true)) {\n        Value *TransAddr = Translator.getAddr();\n        if (TransAddr != Location.Ptr) {\n          CurrentPair.second = CurrentPair.second.getWithNewPtr(TransAddr);\n\n          if (TransAddr &&\n              !IsGuaranteedLoopInvariant(const_cast<Value *>(TransAddr)))\n            CurrentPair.second = CurrentPair.second.getWithNewSize(\n                LocationSize::beforeOrAfterPointer());\n\n          if (PerformedPhiTranslation)\n            *PerformedPhiTranslation = true;\n        }\n      }\n    }\n  }\n\n  MemoryAccessPair CurrentPair;\n  memoryaccess_def_iterator DefIterator;\n  MemoryLocation Location;\n  MemoryAccess *OriginalAccess = nullptr;\n  DominatorTree *DT = nullptr;\n  bool WalkingPhi = false;\n  bool *PerformedPhiTranslation = nullptr;\n};\n\ninline upward_defs_iterator\nupward_defs_begin(const MemoryAccessPair &Pair, DominatorTree &DT,\n                  bool *PerformedPhiTranslation = nullptr) {\n  return upward_defs_iterator(Pair, &DT, PerformedPhiTranslation);\n}\n\ninline upward_defs_iterator upward_defs_end() { return upward_defs_iterator(); }\n\ninline iterator_range<upward_defs_iterator>\nupward_defs(const MemoryAccessPair &Pair, DominatorTree &DT) {\n  return make_range(upward_defs_begin(Pair, DT), upward_defs_end());\n}\n\n/// Walks the defining accesses of MemoryDefs. Stops after we hit something that\n/// has no defining use (e.g. a MemoryPhi or liveOnEntry). Note that, when\n/// comparing against a null def_chain_iterator, this will compare equal only\n/// after walking said Phi/liveOnEntry.\n///\n/// The UseOptimizedChain flag specifies whether to walk the clobbering\n/// access chain, or all the accesses.\n///\n/// Normally, MemoryDef are all just def/use linked together, so a def_chain on\n/// a MemoryDef will walk all MemoryDefs above it in the program until it hits\n/// a phi node.  The optimized chain walks the clobbering access of a store.\n/// So if you are just trying to find, given a store, what the next\n/// thing that would clobber the same memory is, you want the optimized chain.\ntemplate <class T, bool UseOptimizedChain = false>\nstruct def_chain_iterator\n    : public iterator_facade_base<def_chain_iterator<T, UseOptimizedChain>,\n                                  std::forward_iterator_tag, MemoryAccess *> {\n  def_chain_iterator() : MA(nullptr) {}\n  def_chain_iterator(T MA) : MA(MA) {}\n\n  T operator*() const { return MA; }\n\n  def_chain_iterator &operator++() {\n    // N.B. liveOnEntry has a null defining access.\n    if (auto *MUD = dyn_cast<MemoryUseOrDef>(MA)) {\n      if (UseOptimizedChain && MUD->isOptimized())\n        MA = MUD->getOptimized();\n      else\n        MA = MUD->getDefiningAccess();\n    } else {\n      MA = nullptr;\n    }\n\n    return *this;\n  }\n\n  bool operator==(const def_chain_iterator &O) const { return MA == O.MA; }\n\nprivate:\n  T MA;\n};\n\ntemplate <class T>\ninline iterator_range<def_chain_iterator<T>>\ndef_chain(T MA, MemoryAccess *UpTo = nullptr) {\n#ifdef EXPENSIVE_CHECKS\n  assert((!UpTo || find(def_chain(MA), UpTo) != def_chain_iterator<T>()) &&\n         \"UpTo isn't in the def chain!\");\n#endif\n  return make_range(def_chain_iterator<T>(MA), def_chain_iterator<T>(UpTo));\n}\n\ntemplate <class T>\ninline iterator_range<def_chain_iterator<T, true>> optimized_def_chain(T MA) {\n  return make_range(def_chain_iterator<T, true>(MA),\n                    def_chain_iterator<T, true>(nullptr));\n}\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_MEMORYSSA_H\n"}, "52": {"id": 52, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ModuleSummaryAnalysis.h", "content": "//===- ModuleSummaryAnalysis.h - Module summary index builder ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This is the interface to build a ModuleSummaryIndex for a module.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_MODULESUMMARYANALYSIS_H\n#define LLVM_ANALYSIS_MODULESUMMARYANALYSIS_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/IR/ModuleSummaryIndex.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include <functional>\n\nnamespace llvm {\n\nclass BlockFrequencyInfo;\nclass Function;\nclass Module;\nclass ProfileSummaryInfo;\nclass StackSafetyInfo;\n\n/// Direct function to compute a \\c ModuleSummaryIndex from a given module.\n///\n/// If operating within a pass manager which has defined ways to compute the \\c\n/// BlockFrequencyInfo for a given function, that can be provided via\n/// a std::function callback. Otherwise, this routine will manually construct\n/// that information.\nModuleSummaryIndex buildModuleSummaryIndex(\n    const Module &M,\n    std::function<BlockFrequencyInfo *(const Function &F)> GetBFICallback,\n    ProfileSummaryInfo *PSI,\n    std::function<const StackSafetyInfo *(const Function &F)> GetSSICallback =\n        [](const Function &F) -> const StackSafetyInfo * { return nullptr; });\n\n/// Analysis pass to provide the ModuleSummaryIndex object.\nclass ModuleSummaryIndexAnalysis\n    : public AnalysisInfoMixin<ModuleSummaryIndexAnalysis> {\n  friend AnalysisInfoMixin<ModuleSummaryIndexAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = ModuleSummaryIndex;\n\n  Result run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the ModuleSummaryIndex object.\nclass ModuleSummaryIndexWrapperPass : public ModulePass {\n  Optional<ModuleSummaryIndex> Index;\n\npublic:\n  static char ID;\n\n  ModuleSummaryIndexWrapperPass();\n\n  /// Get the index built by pass\n  ModuleSummaryIndex &getIndex() { return *Index; }\n  const ModuleSummaryIndex &getIndex() const { return *Index; }\n\n  bool runOnModule(Module &M) override;\n  bool doFinalization(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n//===--------------------------------------------------------------------===//\n//\n// createModuleSummaryIndexWrapperPass - This pass builds a ModuleSummaryIndex\n// object for the module, to be written to bitcode or LLVM assembly.\n//\nModulePass *createModuleSummaryIndexWrapperPass();\n\n/// Legacy wrapper pass to provide the ModuleSummaryIndex object.\nclass ImmutableModuleSummaryIndexWrapperPass : public ImmutablePass {\n  const ModuleSummaryIndex *Index;\n\npublic:\n  static char ID;\n\n  ImmutableModuleSummaryIndexWrapperPass(\n      const ModuleSummaryIndex *Index = nullptr);\n  const ModuleSummaryIndex *getIndex() const { return Index; }\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n//===--------------------------------------------------------------------===//\n//\n// ImmutableModuleSummaryIndexWrapperPass - This pass wrap provided\n// ModuleSummaryIndex object for the module, to be used by other passes.\n//\nImmutablePass *\ncreateImmutableModuleSummaryIndexWrapperPass(const ModuleSummaryIndex *Index);\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_MODULESUMMARYANALYSIS_H\n"}, "53": {"id": 53, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ObjCARCAliasAnalysis.h", "content": "//===- ObjCARCAliasAnalysis.h - ObjC ARC Alias Analysis ---------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This file declares a simple ARC-aware AliasAnalysis using special knowledge\n/// of Objective C to enhance other optimization passes which rely on the Alias\n/// Analysis infrastructure.\n///\n/// WARNING: This file knows about certain library functions. It recognizes them\n/// by name, and hardwires knowledge of their semantics.\n///\n/// WARNING: This file knows about how certain Objective-C library functions are\n/// used. Naive LLVM IR transformations which would otherwise be\n/// behavior-preserving may break these assumptions.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_OBJCARCALIASANALYSIS_H\n#define LLVM_ANALYSIS_OBJCARCALIASANALYSIS_H\n\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\nnamespace objcarc {\n\n/// This is a simple alias analysis implementation that uses knowledge\n/// of ARC constructs to answer queries.\n///\n/// TODO: This class could be generalized to know about other ObjC-specific\n/// tricks. Such as knowing that ivars in the non-fragile ABI are non-aliasing\n/// even though their offsets are dynamic.\nclass ObjCARCAAResult : public AAResultBase<ObjCARCAAResult> {\n  friend AAResultBase<ObjCARCAAResult>;\n\n  const DataLayout &DL;\n\npublic:\n  explicit ObjCARCAAResult(const DataLayout &DL) : AAResultBase(), DL(DL) {}\n  ObjCARCAAResult(ObjCARCAAResult &&Arg)\n      : AAResultBase(std::move(Arg)), DL(Arg.DL) {}\n\n  /// Handle invalidation events from the new pass manager.\n  ///\n  /// By definition, this result is stateless and so remains valid.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n  bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                              bool OrLocal);\n\n  using AAResultBase::getModRefBehavior;\n  FunctionModRefBehavior getModRefBehavior(const Function *F);\n\n  using AAResultBase::getModRefInfo;\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\nclass ObjCARCAA : public AnalysisInfoMixin<ObjCARCAA> {\n  friend AnalysisInfoMixin<ObjCARCAA>;\n  static AnalysisKey Key;\n\npublic:\n  typedef ObjCARCAAResult Result;\n\n  ObjCARCAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the ObjCARCAAResult object.\nclass ObjCARCAAWrapperPass : public ImmutablePass {\n  std::unique_ptr<ObjCARCAAResult> Result;\n\npublic:\n  static char ID;\n\n  ObjCARCAAWrapperPass();\n\n  ObjCARCAAResult &getResult() { return *Result; }\n  const ObjCARCAAResult &getResult() const { return *Result; }\n\n  bool doInitialization(Module &M) override;\n  bool doFinalization(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n} // namespace objcarc\n} // namespace llvm\n\n#endif\n"}, "54": {"id": 54, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/OptimizationRemarkEmitter.h", "content": "//===- OptimizationRemarkEmitter.h - Optimization Diagnostic ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Optimization diagnostic interfaces.  It's packaged as an analysis pass so\n// that by using this service passes become dependent on BFI as well.  BFI is\n// used to compute the \"hotness\" of the diagnostic message.\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_OPTIMIZATIONREMARKEMITTER_H\n#define LLVM_ANALYSIS_OPTIMIZATIONREMARKEMITTER_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/Analysis/BlockFrequencyInfo.h\"\n#include \"llvm/IR/DiagnosticInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\nclass Function;\nclass Value;\n\n/// The optimization diagnostic interface.\n///\n/// It allows reporting when optimizations are performed and when they are not\n/// along with the reasons for it.  Hotness information of the corresponding\n/// code region can be included in the remark if DiagnosticsHotnessRequested is\n/// enabled in the LLVM context.\nclass OptimizationRemarkEmitter {\npublic:\n  OptimizationRemarkEmitter(const Function *F, BlockFrequencyInfo *BFI)\n      : F(F), BFI(BFI) {}\n\n  /// This variant can be used to generate ORE on demand (without the\n  /// analysis pass).\n  ///\n  /// Note that this ctor has a very different cost depending on whether\n  /// F->getContext().getDiagnosticsHotnessRequested() is on or not.  If it's off\n  /// the operation is free.\n  ///\n  /// Whereas if DiagnosticsHotnessRequested is on, it is fairly expensive\n  /// operation since BFI and all its required analyses are computed.  This is\n  /// for example useful for CGSCC passes that can't use function analyses\n  /// passes in the old PM.\n  OptimizationRemarkEmitter(const Function *F);\n\n  OptimizationRemarkEmitter(OptimizationRemarkEmitter &&Arg)\n      : F(Arg.F), BFI(Arg.BFI) {}\n\n  OptimizationRemarkEmitter &operator=(OptimizationRemarkEmitter &&RHS) {\n    F = RHS.F;\n    BFI = RHS.BFI;\n    return *this;\n  }\n\n  /// Handle invalidation events in the new pass manager.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\n  /// Output the remark via the diagnostic handler and to the\n  /// optimization record file.\n  void emit(DiagnosticInfoOptimizationBase &OptDiag);\n\n  /// Take a lambda that returns a remark which will be emitted.  Second\n  /// argument is only used to restrict this to functions.\n  template <typename T>\n  void emit(T RemarkBuilder, decltype(RemarkBuilder()) * = nullptr) {\n    // Avoid building the remark unless we know there are at least *some*\n    // remarks enabled. We can't currently check whether remarks are requested\n    // for the calling pass since that requires actually building the remark.\n\n    if (F->getContext().getLLVMRemarkStreamer() ||\n        F->getContext().getDiagHandlerPtr()->isAnyRemarkEnabled()) {\n      auto R = RemarkBuilder();\n      emit((DiagnosticInfoOptimizationBase &)R);\n    }\n  }\n\n  /// Whether we allow for extra compile-time budget to perform more\n  /// analysis to produce fewer false positives.\n  ///\n  /// This is useful when reporting missed optimizations.  In this case we can\n  /// use the extra analysis (1) to filter trivial false positives or (2) to\n  /// provide more context so that non-trivial false positives can be quickly\n  /// detected by the user.\n  bool allowExtraAnalysis(StringRef PassName) const {\n    return OptimizationRemarkEmitter::allowExtraAnalysis(*F, PassName);\n  }\n  static bool allowExtraAnalysis(const Function &F, StringRef PassName) {\n    return allowExtraAnalysis(F.getContext(), PassName);\n  }\n  static bool allowExtraAnalysis(LLVMContext &Ctx, StringRef PassName) {\n    return Ctx.getLLVMRemarkStreamer() ||\n           Ctx.getDiagHandlerPtr()->isAnyRemarkEnabled(PassName);\n  }\n\nprivate:\n  const Function *F;\n\n  BlockFrequencyInfo *BFI;\n\n  /// If we generate BFI on demand, we need to free it when ORE is freed.\n  std::unique_ptr<BlockFrequencyInfo> OwnedBFI;\n\n  /// Compute hotness from IR value (currently assumed to be a block) if PGO is\n  /// available.\n  Optional<uint64_t> computeHotness(const Value *V);\n\n  /// Similar but use value from \\p OptDiag and update hotness there.\n  void computeHotness(DiagnosticInfoIROptimization &OptDiag);\n\n  /// Only allow verbose messages if we know we're filtering by hotness\n  /// (BFI is only set in this case).\n  bool shouldEmitVerbose() { return BFI != nullptr; }\n\n  OptimizationRemarkEmitter(const OptimizationRemarkEmitter &) = delete;\n  void operator=(const OptimizationRemarkEmitter &) = delete;\n};\n\n/// Add a small namespace to avoid name clashes with the classes used in\n/// the streaming interface.  We want these to be short for better\n/// write/readability.\nnamespace ore {\nusing NV = DiagnosticInfoOptimizationBase::Argument;\nusing setIsVerbose = DiagnosticInfoOptimizationBase::setIsVerbose;\nusing setExtraArgs = DiagnosticInfoOptimizationBase::setExtraArgs;\n}\n\n/// OptimizationRemarkEmitter legacy analysis pass\n///\n/// Note that this pass shouldn't generally be marked as preserved by other\n/// passes.  It's holding onto BFI, so if the pass does not preserve BFI, BFI\n/// could be freed.\nclass OptimizationRemarkEmitterWrapperPass : public FunctionPass {\n  std::unique_ptr<OptimizationRemarkEmitter> ORE;\n\npublic:\n  OptimizationRemarkEmitterWrapperPass();\n\n  bool runOnFunction(Function &F) override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  OptimizationRemarkEmitter &getORE() {\n    assert(ORE && \"pass not run yet\");\n    return *ORE;\n  }\n\n  static char ID;\n};\n\nclass OptimizationRemarkEmitterAnalysis\n    : public AnalysisInfoMixin<OptimizationRemarkEmitterAnalysis> {\n  friend AnalysisInfoMixin<OptimizationRemarkEmitterAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result typedef for this analysis pass.\n  typedef OptimizationRemarkEmitter Result;\n\n  /// Run the analysis pass over a function and produce BFI.\n  Result run(Function &F, FunctionAnalysisManager &AM);\n};\n}\n#endif // LLVM_ANALYSIS_OPTIMIZATIONREMARKEMITTER_H\n"}, "55": {"id": 55, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/PhiValues.h", "content": "//===- PhiValues.h - Phi Value Analysis -------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the PhiValues class, and associated passes, which can be\n// used to find the underlying values of the phis in a function, i.e. the\n// non-phi values that can be found by traversing the phi graph.\n//\n// This information is computed lazily and cached. If new phis are added to the\n// function they are handled correctly, but if an existing phi has its operands\n// modified PhiValues has to be notified by calling invalidateValue.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_PHIVALUES_H\n#define LLVM_ANALYSIS_PHIVALUES_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass Value;\nclass PHINode;\nclass Function;\n\n/// Class for calculating and caching the underlying values of phis in a\n/// function.\n///\n/// Initially the PhiValues is empty, and gets incrementally populated whenever\n/// it is queried.\nclass PhiValues {\npublic:\n  using ValueSet = SmallSetVector<Value *, 4>;\n\n  /// Construct an empty PhiValues.\n  PhiValues(const Function &F) : F(F) {}\n\n  /// Get the underlying values of a phi.\n  ///\n  /// This returns the cached value if PN has previously been processed,\n  /// otherwise it processes it first.\n  const ValueSet &getValuesForPhi(const PHINode *PN);\n\n  /// Notify PhiValues that the cached information using V is no longer valid\n  ///\n  /// Whenever a phi has its operands modified the cached values for that phi\n  /// (and the phis that use that phi) become invalid. A user of PhiValues has\n  /// to notify it of this by calling invalidateValue on either the operand or\n  /// the phi, which will then clear the relevant cached information.\n  void invalidateValue(const Value *V);\n\n  /// Free the memory used by this class.\n  void releaseMemory();\n\n  /// Print out the values currently in the cache.\n  void print(raw_ostream &OS) const;\n\n  /// Handle invalidation events in the new pass manager.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &);\n\nprivate:\n  using ConstValueSet = SmallSetVector<const Value *, 4>;\n\n  /// The next depth number to be used by processPhi.\n  unsigned int NextDepthNumber = 1;\n\n  /// Depth numbers of phis. Phis with the same depth number are part of the\n  /// same strongly connected component.\n  DenseMap<const PHINode *, unsigned int> DepthMap;\n\n  /// Non-phi values reachable from each component.\n  DenseMap<unsigned int, ValueSet> NonPhiReachableMap;\n\n  /// All values reachable from each component.\n  DenseMap<unsigned int, ConstValueSet> ReachableMap;\n\n  /// A CallbackVH to notify PhiValues when a value is deleted or replaced, so\n  /// that the cached information for that value can be cleared to avoid\n  /// dangling pointers to invalid values.\n  class PhiValuesCallbackVH final : public CallbackVH {\n    PhiValues *PV;\n    void deleted() override;\n    void allUsesReplacedWith(Value *New) override;\n\n  public:\n    PhiValuesCallbackVH(Value *V, PhiValues *PV = nullptr)\n        : CallbackVH(V), PV(PV) {}\n  };\n\n  /// A set of callbacks to the values that processPhi has seen.\n  DenseSet<PhiValuesCallbackVH, DenseMapInfo<Value *>> TrackedValues;\n\n  /// The function that the PhiValues is for.\n  const Function &F;\n\n  /// Process a phi so that its entries in the depth and reachable maps are\n  /// fully populated.\n  void processPhi(const PHINode *PN, SmallVectorImpl<const PHINode *> &Stack);\n};\n\n/// The analysis pass which yields a PhiValues\n///\n/// The analysis does nothing by itself, and just returns an empty PhiValues\n/// which will get filled in as it's used.\nclass PhiValuesAnalysis : public AnalysisInfoMixin<PhiValuesAnalysis> {\n  friend AnalysisInfoMixin<PhiValuesAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  using Result = PhiValues;\n  PhiValues run(Function &F, FunctionAnalysisManager &);\n};\n\n/// A pass for printing the PhiValues for a function.\n///\n/// This pass doesn't print whatever information the PhiValues happens to hold,\n/// but instead first uses the PhiValues to analyze all the phis in the function\n/// so the complete information is printed.\nclass PhiValuesPrinterPass : public PassInfoMixin<PhiValuesPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit PhiValuesPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Wrapper pass for the legacy pass manager\nclass PhiValuesWrapperPass : public FunctionPass {\n  std::unique_ptr<PhiValues> Result;\n\npublic:\n  static char ID;\n  PhiValuesWrapperPass();\n\n  PhiValues &getResult() { return *Result; }\n  const PhiValues &getResult() const { return *Result; }\n\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n} // namespace llvm\n\n#endif\n"}, "56": {"id": 56, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/PostDominators.h", "content": "//=- llvm/Analysis/PostDominators.h - Post Dominator Calculation --*- C++ -*-=//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file exposes interfaces to post dominance information.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_POSTDOMINATORS_H\n#define LLVM_ANALYSIS_POSTDOMINATORS_H\n\n#include \"llvm/ADT/DepthFirstIterator.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass Function;\nclass raw_ostream;\n\n/// PostDominatorTree Class - Concrete subclass of DominatorTree that is used to\n/// compute the post-dominator tree.\nclass PostDominatorTree : public PostDomTreeBase<BasicBlock> {\npublic:\n  using Base = PostDomTreeBase<BasicBlock>;\n\n  PostDominatorTree() = default;\n  explicit PostDominatorTree(Function &F) { recalculate(F); }\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // Ensure base-class overloads are visible.\n  using Base::dominates;\n\n  /// Return true if \\p I1 dominates \\p I2. This checks if \\p I2 comes before\n  /// \\p I1 if they belongs to the same basic block.\n  bool dominates(const Instruction *I1, const Instruction *I2) const;\n};\n\n/// Analysis pass which computes a \\c PostDominatorTree.\nclass PostDominatorTreeAnalysis\n    : public AnalysisInfoMixin<PostDominatorTreeAnalysis> {\n  friend AnalysisInfoMixin<PostDominatorTreeAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result type for this analysis pass.\n  using Result = PostDominatorTree;\n\n  /// Run the analysis pass over a function and produce a post dominator\n  ///        tree.\n  PostDominatorTree run(Function &F, FunctionAnalysisManager &);\n};\n\n/// Printer pass for the \\c PostDominatorTree.\nclass PostDominatorTreePrinterPass\n    : public PassInfoMixin<PostDominatorTreePrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit PostDominatorTreePrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nstruct PostDominatorTreeWrapperPass : public FunctionPass {\n  static char ID; // Pass identification, replacement for typeid\n\n  PostDominatorTree DT;\n\n  PostDominatorTreeWrapperPass();\n\n  PostDominatorTree &getPostDomTree() { return DT; }\n  const PostDominatorTree &getPostDomTree() const { return DT; }\n\n  bool runOnFunction(Function &F) override;\n\n  void verifyAnalysis() const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override {\n    AU.setPreservesAll();\n  }\n\n  void releaseMemory() override { DT.reset(); }\n\n  void print(raw_ostream &OS, const Module*) const override;\n};\n\nFunctionPass* createPostDomTree();\n\ntemplate <> struct GraphTraits<PostDominatorTree*>\n  : public GraphTraits<DomTreeNode*> {\n  static NodeRef getEntryNode(PostDominatorTree *DT) {\n    return DT->getRootNode();\n  }\n\n  static nodes_iterator nodes_begin(PostDominatorTree *N) {\n    if (getEntryNode(N))\n      return df_begin(getEntryNode(N));\n    else\n      return df_end(getEntryNode(N));\n  }\n\n  static nodes_iterator nodes_end(PostDominatorTree *N) {\n    return df_end(getEntryNode(N));\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_POSTDOMINATORS_H\n"}, "57": {"id": 57, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ProfileSummaryInfo.h", "content": "//===- llvm/Analysis/ProfileSummaryInfo.h - profile summary ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file contains a pass that provides access to profile summary\n// information.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_PROFILESUMMARYINFO_H\n#define LLVM_ANALYSIS_PROFILESUMMARYINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ProfileSummary.h\"\n#include \"llvm/Pass.h\"\n#include <memory>\n\nnamespace llvm {\nclass BasicBlock;\nclass BlockFrequencyInfo;\nclass CallBase;\nclass Function;\n\n/// Analysis providing profile information.\n///\n/// This is an immutable analysis pass that provides ability to query global\n/// (program-level) profile information. The main APIs are isHotCount and\n/// isColdCount that tells whether a given profile count is considered hot/cold\n/// based on the profile summary. This also provides convenience methods to\n/// check whether a function is hot or cold.\n\n// FIXME: Provide convenience methods to determine hotness/coldness of other IR\n// units. This would require making this depend on BFI.\nclass ProfileSummaryInfo {\nprivate:\n  const Module &M;\n  std::unique_ptr<ProfileSummary> Summary;\n  void computeThresholds();\n  // Count thresholds to answer isHotCount and isColdCount queries.\n  Optional<uint64_t> HotCountThreshold, ColdCountThreshold;\n  // True if the working set size of the code is considered huge,\n  // because the number of profile counts required to reach the hot\n  // percentile is above a huge threshold.\n  Optional<bool> HasHugeWorkingSetSize;\n  // True if the working set size of the code is considered large,\n  // because the number of profile counts required to reach the hot\n  // percentile is above a large threshold.\n  Optional<bool> HasLargeWorkingSetSize;\n  // Compute the threshold for a given cutoff.\n  Optional<uint64_t> computeThreshold(int PercentileCutoff) const;\n  // The map that caches the threshold values. The keys are the percentile\n  // cutoff values and the values are the corresponding threshold values.\n  mutable DenseMap<int, uint64_t> ThresholdCache;\n\npublic:\n  ProfileSummaryInfo(const Module &M) : M(M) { refresh(); }\n\n  ProfileSummaryInfo(ProfileSummaryInfo &&Arg) = default;\n\n  /// If no summary is present, attempt to refresh.\n  void refresh();\n\n  /// Returns true if profile summary is available.\n  bool hasProfileSummary() const { return Summary != nullptr; }\n\n  /// Returns true if module \\c M has sample profile.\n  bool hasSampleProfile() const {\n    return hasProfileSummary() &&\n           Summary->getKind() == ProfileSummary::PSK_Sample;\n  }\n\n  /// Returns true if module \\c M has instrumentation profile.\n  bool hasInstrumentationProfile() const {\n    return hasProfileSummary() &&\n           Summary->getKind() == ProfileSummary::PSK_Instr;\n  }\n\n  /// Returns true if module \\c M has context sensitive instrumentation profile.\n  bool hasCSInstrumentationProfile() const {\n    return hasProfileSummary() &&\n           Summary->getKind() == ProfileSummary::PSK_CSInstr;\n  }\n\n  /// Handle the invalidation of this information.\n  ///\n  /// When used as a result of \\c ProfileSummaryAnalysis this method will be\n  /// called when the module this was computed for changes. Since profile\n  /// summary is immutable after it is annotated on the module, we return false\n  /// here.\n  bool invalidate(Module &, const PreservedAnalyses &,\n                  ModuleAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  /// Returns the profile count for \\p CallInst.\n  Optional<uint64_t> getProfileCount(const CallBase &CallInst,\n                                     BlockFrequencyInfo *BFI,\n                                     bool AllowSynthetic = false) const;\n  /// Returns true if module \\c M has partial-profile sample profile.\n  bool hasPartialSampleProfile() const;\n  /// Returns true if the working set size of the code is considered huge.\n  bool hasHugeWorkingSetSize() const;\n  /// Returns true if the working set size of the code is considered large.\n  bool hasLargeWorkingSetSize() const;\n  /// Returns true if \\p F has hot function entry.\n  bool isFunctionEntryHot(const Function *F) const;\n  /// Returns true if \\p F contains hot code.\n  bool isFunctionHotInCallGraph(const Function *F,\n                                BlockFrequencyInfo &BFI) const;\n  /// Returns true if \\p F has cold function entry.\n  bool isFunctionEntryCold(const Function *F) const;\n  /// Returns true if \\p F contains only cold code.\n  bool isFunctionColdInCallGraph(const Function *F,\n                                 BlockFrequencyInfo &BFI) const;\n  /// Returns true if the hotness of \\p F is unknown.\n  bool isFunctionHotnessUnknown(const Function &F) const;\n  /// Returns true if \\p F contains hot code with regard to a given hot\n  /// percentile cutoff value.\n  bool isFunctionHotInCallGraphNthPercentile(int PercentileCutoff,\n                                             const Function *F,\n                                             BlockFrequencyInfo &BFI) const;\n  /// Returns true if \\p F contains cold code with regard to a given cold\n  /// percentile cutoff value.\n  bool isFunctionColdInCallGraphNthPercentile(int PercentileCutoff,\n                                              const Function *F,\n                                              BlockFrequencyInfo &BFI) const;\n  /// Returns true if count \\p C is considered hot.\n  bool isHotCount(uint64_t C) const;\n  /// Returns true if count \\p C is considered cold.\n  bool isColdCount(uint64_t C) const;\n  /// Returns true if count \\p C is considered hot with regard to a given\n  /// hot percentile cutoff value.\n  bool isHotCountNthPercentile(int PercentileCutoff, uint64_t C) const;\n  /// Returns true if count \\p C is considered cold with regard to a given\n  /// cold percentile cutoff value.\n  bool isColdCountNthPercentile(int PercentileCutoff, uint64_t C) const;\n  /// Returns true if BasicBlock \\p BB is considered hot.\n  bool isHotBlock(const BasicBlock *BB, BlockFrequencyInfo *BFI) const;\n  /// Returns true if BasicBlock \\p BB is considered cold.\n  bool isColdBlock(const BasicBlock *BB, BlockFrequencyInfo *BFI) const;\n  /// Returns true if BasicBlock \\p BB is considered hot with regard to a given\n  /// hot percentile cutoff value.\n  bool isHotBlockNthPercentile(int PercentileCutoff, const BasicBlock *BB,\n                               BlockFrequencyInfo *BFI) const;\n  /// Returns true if BasicBlock \\p BB is considered cold with regard to a given\n  /// cold percentile cutoff value.\n  bool isColdBlockNthPercentile(int PercentileCutoff, const BasicBlock *BB,\n                                BlockFrequencyInfo *BFI) const;\n  /// Returns true if the call site \\p CB is considered hot.\n  bool isHotCallSite(const CallBase &CB, BlockFrequencyInfo *BFI) const;\n  /// Returns true if call site \\p CB is considered cold.\n  bool isColdCallSite(const CallBase &CB, BlockFrequencyInfo *BFI) const;\n  /// Returns HotCountThreshold if set. Recompute HotCountThreshold\n  /// if not set.\n  uint64_t getOrCompHotCountThreshold() const;\n  /// Returns ColdCountThreshold if set. Recompute HotCountThreshold\n  /// if not set.\n  uint64_t getOrCompColdCountThreshold() const;\n  /// Returns HotCountThreshold if set.\n  uint64_t getHotCountThreshold() const {\n    return HotCountThreshold ? HotCountThreshold.getValue() : 0;\n  }\n  /// Returns ColdCountThreshold if set.\n  uint64_t getColdCountThreshold() const {\n    return ColdCountThreshold ? ColdCountThreshold.getValue() : 0;\n  }\n\n private:\n   template <bool isHot>\n   bool isFunctionHotOrColdInCallGraphNthPercentile(\n       int PercentileCutoff, const Function *F, BlockFrequencyInfo &BFI) const;\n   template <bool isHot>\n   bool isHotOrColdCountNthPercentile(int PercentileCutoff, uint64_t C) const;\n   template <bool isHot>\n   bool isHotOrColdBlockNthPercentile(int PercentileCutoff,\n                                      const BasicBlock *BB,\n                                      BlockFrequencyInfo *BFI) const;\n};\n\n/// An analysis pass based on legacy pass manager to deliver ProfileSummaryInfo.\nclass ProfileSummaryInfoWrapperPass : public ImmutablePass {\n  std::unique_ptr<ProfileSummaryInfo> PSI;\n\npublic:\n  static char ID;\n  ProfileSummaryInfoWrapperPass();\n\n  ProfileSummaryInfo &getPSI() { return *PSI; }\n  const ProfileSummaryInfo &getPSI() const { return *PSI; }\n\n  bool doInitialization(Module &M) override;\n  bool doFinalization(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override {\n    AU.setPreservesAll();\n  }\n};\n\n/// An analysis pass based on the new PM to deliver ProfileSummaryInfo.\nclass ProfileSummaryAnalysis\n    : public AnalysisInfoMixin<ProfileSummaryAnalysis> {\npublic:\n  typedef ProfileSummaryInfo Result;\n\n  Result run(Module &M, ModuleAnalysisManager &);\n\nprivate:\n  friend AnalysisInfoMixin<ProfileSummaryAnalysis>;\n  static AnalysisKey Key;\n};\n\n/// Printer pass that uses \\c ProfileSummaryAnalysis.\nclass ProfileSummaryPrinterPass\n    : public PassInfoMixin<ProfileSummaryPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit ProfileSummaryPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif\n"}, "58": {"id": 58, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "content": "//===- RegionInfo.h - SESE region analysis ----------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Calculate a program structure tree built out of single entry single exit\n// regions.\n// The basic ideas are taken from \"The Program Structure Tree - Richard Johnson,\n// David Pearson, Keshav Pingali - 1994\", however enriched with ideas from \"The\n// Refined Process Structure Tree - Jussi Vanhatalo, Hagen Voelyer, Jana\n// Koehler - 2009\".\n// The algorithm to calculate these data structures however is completely\n// different, as it takes advantage of existing information already available\n// in (Post)dominace tree and dominance frontier passes. This leads to a simpler\n// and in practice hopefully better performing algorithm. The runtime of the\n// algorithms described in the papers above are both linear in graph size,\n// O(V+E), whereas this algorithm is not, as the dominance frontier information\n// itself is not, but in practice runtime seems to be in the order of magnitude\n// of dominance tree calculation.\n//\n// WARNING: LLVM is generally very concerned about compile time such that\n//          the use of additional analysis passes in the default\n//          optimization sequence is avoided as much as possible.\n//          Specifically, if you do not need the RegionInfo, but dominance\n//          information could be sufficient please base your work only on\n//          the dominator tree. Most passes maintain it, such that using\n//          it has often near zero cost. In contrast RegionInfo is by\n//          default not available, is not maintained by existing\n//          transformations and there is no intention to do so.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_REGIONINFO_H\n#define LLVM_ANALYSIS_REGIONINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DepthFirstIterator.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Config/llvm-config.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <algorithm>\n#include <cassert>\n#include <map>\n#include <memory>\n#include <set>\n#include <string>\n#include <type_traits>\n#include <vector>\n\nnamespace llvm {\n\nclass DominanceFrontier;\nclass Loop;\nclass LoopInfo;\nclass PostDominatorTree;\nclass Region;\ntemplate <class RegionTr> class RegionBase;\nclass RegionInfo;\ntemplate <class RegionTr> class RegionInfoBase;\nclass RegionNode;\n\n// Class to be specialized for different users of RegionInfo\n// (i.e. BasicBlocks or MachineBasicBlocks). This is only to avoid needing to\n// pass around an unreasonable number of template parameters.\ntemplate <class FuncT_>\nstruct RegionTraits {\n  // FuncT\n  // BlockT\n  // RegionT\n  // RegionNodeT\n  // RegionInfoT\n  using BrokenT = typename FuncT_::UnknownRegionTypeError;\n};\n\ntemplate <>\nstruct RegionTraits<Function> {\n  using FuncT = Function;\n  using BlockT = BasicBlock;\n  using RegionT = Region;\n  using RegionNodeT = RegionNode;\n  using RegionInfoT = RegionInfo;\n  using DomTreeT = DominatorTree;\n  using DomTreeNodeT = DomTreeNode;\n  using DomFrontierT = DominanceFrontier;\n  using PostDomTreeT = PostDominatorTree;\n  using InstT = Instruction;\n  using LoopT = Loop;\n  using LoopInfoT = LoopInfo;\n\n  static unsigned getNumSuccessors(BasicBlock *BB) {\n    return BB->getTerminator()->getNumSuccessors();\n  }\n};\n\n/// Marker class to iterate over the elements of a Region in flat mode.\n///\n/// The class is used to either iterate in Flat mode or by not using it to not\n/// iterate in Flat mode.  During a Flat mode iteration all Regions are entered\n/// and the iteration returns every BasicBlock.  If the Flat mode is not\n/// selected for SubRegions just one RegionNode containing the subregion is\n/// returned.\ntemplate <class GraphType>\nclass FlatIt {};\n\n/// A RegionNode represents a subregion or a BasicBlock that is part of a\n/// Region.\ntemplate <class Tr>\nclass RegionNodeBase {\n  friend class RegionBase<Tr>;\n\npublic:\n  using BlockT = typename Tr::BlockT;\n  using RegionT = typename Tr::RegionT;\n\nprivate:\n  /// This is the entry basic block that starts this region node.  If this is a\n  /// BasicBlock RegionNode, then entry is just the basic block, that this\n  /// RegionNode represents.  Otherwise it is the entry of this (Sub)RegionNode.\n  ///\n  /// In the BBtoRegionNode map of the parent of this node, BB will always map\n  /// to this node no matter which kind of node this one is.\n  ///\n  /// The node can hold either a Region or a BasicBlock.\n  /// Use one bit to save, if this RegionNode is a subregion or BasicBlock\n  /// RegionNode.\n  PointerIntPair<BlockT *, 1, bool> entry;\n\n  /// The parent Region of this RegionNode.\n  /// @see getParent()\n  RegionT *parent;\n\nprotected:\n  /// Create a RegionNode.\n  ///\n  /// @param Parent      The parent of this RegionNode.\n  /// @param Entry       The entry BasicBlock of the RegionNode.  If this\n  ///                    RegionNode represents a BasicBlock, this is the\n  ///                    BasicBlock itself.  If it represents a subregion, this\n  ///                    is the entry BasicBlock of the subregion.\n  /// @param isSubRegion If this RegionNode represents a SubRegion.\n  inline RegionNodeBase(RegionT *Parent, BlockT *Entry,\n                        bool isSubRegion = false)\n      : entry(Entry, isSubRegion), parent(Parent) {}\n\npublic:\n  RegionNodeBase(const RegionNodeBase &) = delete;\n  RegionNodeBase &operator=(const RegionNodeBase &) = delete;\n\n  /// Get the parent Region of this RegionNode.\n  ///\n  /// The parent Region is the Region this RegionNode belongs to. If for\n  /// example a BasicBlock is element of two Regions, there exist two\n  /// RegionNodes for this BasicBlock. Each with the getParent() function\n  /// pointing to the Region this RegionNode belongs to.\n  ///\n  /// @return Get the parent Region of this RegionNode.\n  inline RegionT *getParent() const { return parent; }\n\n  /// Get the entry BasicBlock of this RegionNode.\n  ///\n  /// If this RegionNode represents a BasicBlock this is just the BasicBlock\n  /// itself, otherwise we return the entry BasicBlock of the Subregion\n  ///\n  /// @return The entry BasicBlock of this RegionNode.\n  inline BlockT *getEntry() const { return entry.getPointer(); }\n\n  /// Get the content of this RegionNode.\n  ///\n  /// This can be either a BasicBlock or a subregion. Before calling getNodeAs()\n  /// check the type of the content with the isSubRegion() function call.\n  ///\n  /// @return The content of this RegionNode.\n  template <class T> inline T *getNodeAs() const;\n\n  /// Is this RegionNode a subregion?\n  ///\n  /// @return True if it contains a subregion. False if it contains a\n  ///         BasicBlock.\n  inline bool isSubRegion() const { return entry.getInt(); }\n};\n\n//===----------------------------------------------------------------------===//\n/// A single entry single exit Region.\n///\n/// A Region is a connected subgraph of a control flow graph that has exactly\n/// two connections to the remaining graph. It can be used to analyze or\n/// optimize parts of the control flow graph.\n///\n/// A <em> simple Region </em> is connected to the remaining graph by just two\n/// edges. One edge entering the Region and another one leaving the Region.\n///\n/// An <em> extended Region </em> (or just Region) is a subgraph that can be\n/// transform into a simple Region. The transformation is done by adding\n/// BasicBlocks that merge several entry or exit edges so that after the merge\n/// just one entry and one exit edge exists.\n///\n/// The \\e Entry of a Region is the first BasicBlock that is passed after\n/// entering the Region. It is an element of the Region. The entry BasicBlock\n/// dominates all BasicBlocks in the Region.\n///\n/// The \\e Exit of a Region is the first BasicBlock that is passed after\n/// leaving the Region. It is not an element of the Region. The exit BasicBlock,\n/// postdominates all BasicBlocks in the Region.\n///\n/// A <em> canonical Region </em> cannot be constructed by combining smaller\n/// Regions.\n///\n/// Region A is the \\e parent of Region B, if B is completely contained in A.\n///\n/// Two canonical Regions either do not intersect at all or one is\n/// the parent of the other.\n///\n/// The <em> Program Structure Tree</em> is a graph (V, E) where V is the set of\n/// Regions in the control flow graph and E is the \\e parent relation of these\n/// Regions.\n///\n/// Example:\n///\n/// \\verbatim\n/// A simple control flow graph, that contains two regions.\n///\n///        1\n///       / |\n///      2   |\n///     / \\   3\n///    4   5  |\n///    |   |  |\n///    6   7  8\n///     \\  | /\n///      \\ |/       Region A: 1 -> 9 {1,2,3,4,5,6,7,8}\n///        9        Region B: 2 -> 9 {2,4,5,6,7}\n/// \\endverbatim\n///\n/// You can obtain more examples by either calling\n///\n/// <tt> \"opt -regions -analyze anyprogram.ll\" </tt>\n/// or\n/// <tt> \"opt -view-regions-only anyprogram.ll\" </tt>\n///\n/// on any LLVM file you are interested in.\n///\n/// The first call returns a textual representation of the program structure\n/// tree, the second one creates a graphical representation using graphviz.\ntemplate <class Tr>\nclass RegionBase : public RegionNodeBase<Tr> {\n  friend class RegionInfoBase<Tr>;\n\n  using FuncT = typename Tr::FuncT;\n  using BlockT = typename Tr::BlockT;\n  using RegionInfoT = typename Tr::RegionInfoT;\n  using RegionT = typename Tr::RegionT;\n  using RegionNodeT = typename Tr::RegionNodeT;\n  using DomTreeT = typename Tr::DomTreeT;\n  using LoopT = typename Tr::LoopT;\n  using LoopInfoT = typename Tr::LoopInfoT;\n  using InstT = typename Tr::InstT;\n\n  using BlockTraits = GraphTraits<BlockT *>;\n  using InvBlockTraits = GraphTraits<Inverse<BlockT *>>;\n  using SuccIterTy = typename BlockTraits::ChildIteratorType;\n  using PredIterTy = typename InvBlockTraits::ChildIteratorType;\n\n  // Information necessary to manage this Region.\n  RegionInfoT *RI;\n  DomTreeT *DT;\n\n  // The exit BasicBlock of this region.\n  // (The entry BasicBlock is part of RegionNode)\n  BlockT *exit;\n\n  using RegionSet = std::vector<std::unique_ptr<RegionT>>;\n\n  // The subregions of this region.\n  RegionSet children;\n\n  using BBNodeMapT = std::map<BlockT *, std::unique_ptr<RegionNodeT>>;\n\n  // Save the BasicBlock RegionNodes that are element of this Region.\n  mutable BBNodeMapT BBNodeMap;\n\n  /// Check if a BB is in this Region. This check also works\n  /// if the region is incorrectly built. (EXPENSIVE!)\n  void verifyBBInRegion(BlockT *BB) const;\n\n  /// Walk over all the BBs of the region starting from BB and\n  /// verify that all reachable basic blocks are elements of the region.\n  /// (EXPENSIVE!)\n  void verifyWalk(BlockT *BB, std::set<BlockT *> *visitedBB) const;\n\n  /// Verify if the region and its children are valid regions (EXPENSIVE!)\n  void verifyRegionNest() const;\n\npublic:\n  /// Create a new region.\n  ///\n  /// @param Entry  The entry basic block of the region.\n  /// @param Exit   The exit basic block of the region.\n  /// @param RI     The region info object that is managing this region.\n  /// @param DT     The dominator tree of the current function.\n  /// @param Parent The surrounding region or NULL if this is a top level\n  ///               region.\n  RegionBase(BlockT *Entry, BlockT *Exit, RegionInfoT *RI, DomTreeT *DT,\n             RegionT *Parent = nullptr);\n\n  RegionBase(const RegionBase &) = delete;\n  RegionBase &operator=(const RegionBase &) = delete;\n\n  /// Delete the Region and all its subregions.\n  ~RegionBase();\n\n  /// Get the entry BasicBlock of the Region.\n  /// @return The entry BasicBlock of the region.\n  BlockT *getEntry() const {\n    return RegionNodeBase<Tr>::getEntry();\n  }\n\n  /// Replace the entry basic block of the region with the new basic\n  ///        block.\n  ///\n  /// @param BB  The new entry basic block of the region.\n  void replaceEntry(BlockT *BB);\n\n  /// Replace the exit basic block of the region with the new basic\n  ///        block.\n  ///\n  /// @param BB  The new exit basic block of the region.\n  void replaceExit(BlockT *BB);\n\n  /// Recursively replace the entry basic block of the region.\n  ///\n  /// This function replaces the entry basic block with a new basic block. It\n  /// also updates all child regions that have the same entry basic block as\n  /// this region.\n  ///\n  /// @param NewEntry The new entry basic block.\n  void replaceEntryRecursive(BlockT *NewEntry);\n\n  /// Recursively replace the exit basic block of the region.\n  ///\n  /// This function replaces the exit basic block with a new basic block. It\n  /// also updates all child regions that have the same exit basic block as\n  /// this region.\n  ///\n  /// @param NewExit The new exit basic block.\n  void replaceExitRecursive(BlockT *NewExit);\n\n  /// Get the exit BasicBlock of the Region.\n  /// @return The exit BasicBlock of the Region, NULL if this is the TopLevel\n  ///         Region.\n  BlockT *getExit() const { return exit; }\n\n  /// Get the parent of the Region.\n  /// @return The parent of the Region or NULL if this is a top level\n  ///         Region.\n  RegionT *getParent() const {\n    return RegionNodeBase<Tr>::getParent();\n  }\n\n  /// Get the RegionNode representing the current Region.\n  /// @return The RegionNode representing the current Region.\n  RegionNodeT *getNode() const {\n    return const_cast<RegionNodeT *>(\n        reinterpret_cast<const RegionNodeT *>(this));\n  }\n\n  /// Get the nesting level of this Region.\n  ///\n  /// An toplevel Region has depth 0.\n  ///\n  /// @return The depth of the region.\n  unsigned getDepth() const;\n\n  /// Check if a Region is the TopLevel region.\n  ///\n  /// The toplevel region represents the whole function.\n  bool isTopLevelRegion() const { return exit == nullptr; }\n\n  /// Return a new (non-canonical) region, that is obtained by joining\n  ///        this region with its predecessors.\n  ///\n  /// @return A region also starting at getEntry(), but reaching to the next\n  ///         basic block that forms with getEntry() a (non-canonical) region.\n  ///         NULL if such a basic block does not exist.\n  RegionT *getExpandedRegion() const;\n\n  /// Return the first block of this region's single entry edge,\n  ///        if existing.\n  ///\n  /// @return The BasicBlock starting this region's single entry edge,\n  ///         else NULL.\n  BlockT *getEnteringBlock() const;\n\n  /// Return the first block of this region's single exit edge,\n  ///        if existing.\n  ///\n  /// @return The BasicBlock starting this region's single exit edge,\n  ///         else NULL.\n  BlockT *getExitingBlock() const;\n\n  /// Collect all blocks of this region's single exit edge, if existing.\n  ///\n  /// @return True if this region contains all the predecessors of the exit.\n  bool getExitingBlocks(SmallVectorImpl<BlockT *> &Exitings) const;\n\n  /// Is this a simple region?\n  ///\n  /// A region is simple if it has exactly one exit and one entry edge.\n  ///\n  /// @return True if the Region is simple.\n  bool isSimple() const;\n\n  /// Returns the name of the Region.\n  /// @return The Name of the Region.\n  std::string getNameStr() const;\n\n  /// Return the RegionInfo object, that belongs to this Region.\n  RegionInfoT *getRegionInfo() const { return RI; }\n\n  /// PrintStyle - Print region in difference ways.\n  enum PrintStyle { PrintNone, PrintBB, PrintRN };\n\n  /// Print the region.\n  ///\n  /// @param OS The output stream the Region is printed to.\n  /// @param printTree Print also the tree of subregions.\n  /// @param level The indentation level used for printing.\n  void print(raw_ostream &OS, bool printTree = true, unsigned level = 0,\n             PrintStyle Style = PrintNone) const;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print the region to stderr.\n  void dump() const;\n#endif\n\n  /// Check if the region contains a BasicBlock.\n  ///\n  /// @param BB The BasicBlock that might be contained in this Region.\n  /// @return True if the block is contained in the region otherwise false.\n  bool contains(const BlockT *BB) const;\n\n  /// Check if the region contains another region.\n  ///\n  /// @param SubRegion The region that might be contained in this Region.\n  /// @return True if SubRegion is contained in the region otherwise false.\n  bool contains(const RegionT *SubRegion) const {\n    // Toplevel Region.\n    if (!getExit())\n      return true;\n\n    return contains(SubRegion->getEntry()) &&\n           (contains(SubRegion->getExit()) ||\n            SubRegion->getExit() == getExit());\n  }\n\n  /// Check if the region contains an Instruction.\n  ///\n  /// @param Inst The Instruction that might be contained in this region.\n  /// @return True if the Instruction is contained in the region otherwise\n  /// false.\n  bool contains(const InstT *Inst) const { return contains(Inst->getParent()); }\n\n  /// Check if the region contains a loop.\n  ///\n  /// @param L The loop that might be contained in this region.\n  /// @return True if the loop is contained in the region otherwise false.\n  ///         In case a NULL pointer is passed to this function the result\n  ///         is false, except for the region that describes the whole function.\n  ///         In that case true is returned.\n  bool contains(const LoopT *L) const;\n\n  /// Get the outermost loop in the region that contains a loop.\n  ///\n  /// Find for a Loop L the outermost loop OuterL that is a parent loop of L\n  /// and is itself contained in the region.\n  ///\n  /// @param L The loop the lookup is started.\n  /// @return The outermost loop in the region, NULL if such a loop does not\n  ///         exist or if the region describes the whole function.\n  LoopT *outermostLoopInRegion(LoopT *L) const;\n\n  /// Get the outermost loop in the region that contains a basic block.\n  ///\n  /// Find for a basic block BB the outermost loop L that contains BB and is\n  /// itself contained in the region.\n  ///\n  /// @param LI A pointer to a LoopInfo analysis.\n  /// @param BB The basic block surrounded by the loop.\n  /// @return The outermost loop in the region, NULL if such a loop does not\n  ///         exist or if the region describes the whole function.\n  LoopT *outermostLoopInRegion(LoopInfoT *LI, BlockT *BB) const;\n\n  /// Get the subregion that starts at a BasicBlock\n  ///\n  /// @param BB The BasicBlock the subregion should start.\n  /// @return The Subregion if available, otherwise NULL.\n  RegionT *getSubRegionNode(BlockT *BB) const;\n\n  /// Get the RegionNode for a BasicBlock\n  ///\n  /// @param BB The BasicBlock at which the RegionNode should start.\n  /// @return If available, the RegionNode that represents the subregion\n  ///         starting at BB. If no subregion starts at BB, the RegionNode\n  ///         representing BB.\n  RegionNodeT *getNode(BlockT *BB) const;\n\n  /// Get the BasicBlock RegionNode for a BasicBlock\n  ///\n  /// @param BB The BasicBlock for which the RegionNode is requested.\n  /// @return The RegionNode representing the BB.\n  RegionNodeT *getBBNode(BlockT *BB) const;\n\n  /// Add a new subregion to this Region.\n  ///\n  /// @param SubRegion The new subregion that will be added.\n  /// @param moveChildren Move the children of this region, that are also\n  ///                     contained in SubRegion into SubRegion.\n  void addSubRegion(RegionT *SubRegion, bool moveChildren = false);\n\n  /// Remove a subregion from this Region.\n  ///\n  /// The subregion is not deleted, as it will probably be inserted into another\n  /// region.\n  /// @param SubRegion The SubRegion that will be removed.\n  RegionT *removeSubRegion(RegionT *SubRegion);\n\n  /// Move all direct child nodes of this Region to another Region.\n  ///\n  /// @param To The Region the child nodes will be transferred to.\n  void transferChildrenTo(RegionT *To);\n\n  /// Verify if the region is a correct region.\n  ///\n  /// Check if this is a correctly build Region. This is an expensive check, as\n  /// the complete CFG of the Region will be walked.\n  void verifyRegion() const;\n\n  /// Clear the cache for BB RegionNodes.\n  ///\n  /// After calling this function the BasicBlock RegionNodes will be stored at\n  /// different memory locations. RegionNodes obtained before this function is\n  /// called are therefore not comparable to RegionNodes abtained afterwords.\n  void clearNodeCache();\n\n  /// @name Subregion Iterators\n  ///\n  /// These iterators iterator over all subregions of this Region.\n  //@{\n  using iterator = typename RegionSet::iterator;\n  using const_iterator = typename RegionSet::const_iterator;\n\n  iterator begin() { return children.begin(); }\n  iterator end() { return children.end(); }\n\n  const_iterator begin() const { return children.begin(); }\n  const_iterator end() const { return children.end(); }\n  //@}\n\n  /// @name BasicBlock Iterators\n  ///\n  /// These iterators iterate over all BasicBlocks that are contained in this\n  /// Region. The iterator also iterates over BasicBlocks that are elements of\n  /// a subregion of this Region. It is therefore called a flat iterator.\n  //@{\n  template <bool IsConst>\n  class block_iterator_wrapper\n      : public df_iterator<\n            std::conditional_t<IsConst, const BlockT, BlockT> *> {\n    using super =\n        df_iterator<std::conditional_t<IsConst, const BlockT, BlockT> *>;\n\n  public:\n    using Self = block_iterator_wrapper<IsConst>;\n    using value_type = typename super::value_type;\n\n    // Construct the begin iterator.\n    block_iterator_wrapper(value_type Entry, value_type Exit)\n        : super(df_begin(Entry)) {\n      // Mark the exit of the region as visited, so that the children of the\n      // exit and the exit itself, i.e. the block outside the region will never\n      // be visited.\n      super::Visited.insert(Exit);\n    }\n\n    // Construct the end iterator.\n    block_iterator_wrapper() : super(df_end<value_type>((BlockT *)nullptr)) {}\n\n    /*implicit*/ block_iterator_wrapper(super I) : super(I) {}\n\n    // FIXME: Even a const_iterator returns a non-const BasicBlock pointer.\n    //        This was introduced for backwards compatibility, but should\n    //        be removed as soon as all users are fixed.\n    BlockT *operator*() const {\n      return const_cast<BlockT *>(super::operator*());\n    }\n  };\n\n  using block_iterator = block_iterator_wrapper<false>;\n  using const_block_iterator = block_iterator_wrapper<true>;\n\n  block_iterator block_begin() { return block_iterator(getEntry(), getExit()); }\n\n  block_iterator block_end() { return block_iterator(); }\n\n  const_block_iterator block_begin() const {\n    return const_block_iterator(getEntry(), getExit());\n  }\n  const_block_iterator block_end() const { return const_block_iterator(); }\n\n  using block_range = iterator_range<block_iterator>;\n  using const_block_range = iterator_range<const_block_iterator>;\n\n  /// Returns a range view of the basic blocks in the region.\n  inline block_range blocks() {\n    return block_range(block_begin(), block_end());\n  }\n\n  /// Returns a range view of the basic blocks in the region.\n  ///\n  /// This is the 'const' version of the range view.\n  inline const_block_range blocks() const {\n    return const_block_range(block_begin(), block_end());\n  }\n  //@}\n\n  /// @name Element Iterators\n  ///\n  /// These iterators iterate over all BasicBlock and subregion RegionNodes that\n  /// are direct children of this Region. It does not iterate over any\n  /// RegionNodes that are also element of a subregion of this Region.\n  //@{\n  using element_iterator =\n      df_iterator<RegionNodeT *, df_iterator_default_set<RegionNodeT *>, false,\n                  GraphTraits<RegionNodeT *>>;\n\n  using const_element_iterator =\n      df_iterator<const RegionNodeT *,\n                  df_iterator_default_set<const RegionNodeT *>, false,\n                  GraphTraits<const RegionNodeT *>>;\n\n  element_iterator element_begin();\n  element_iterator element_end();\n  iterator_range<element_iterator> elements() {\n    return make_range(element_begin(), element_end());\n  }\n\n  const_element_iterator element_begin() const;\n  const_element_iterator element_end() const;\n  iterator_range<const_element_iterator> elements() const {\n    return make_range(element_begin(), element_end());\n  }\n  //@}\n};\n\n/// Print a RegionNode.\ntemplate <class Tr>\ninline raw_ostream &operator<<(raw_ostream &OS, const RegionNodeBase<Tr> &Node);\n\n//===----------------------------------------------------------------------===//\n/// Analysis that detects all canonical Regions.\n///\n/// The RegionInfo pass detects all canonical regions in a function. The Regions\n/// are connected using the parent relation. This builds a Program Structure\n/// Tree.\ntemplate <class Tr>\nclass RegionInfoBase {\n  friend class RegionInfo;\n  friend class MachineRegionInfo;\n\n  using BlockT = typename Tr::BlockT;\n  using FuncT = typename Tr::FuncT;\n  using RegionT = typename Tr::RegionT;\n  using RegionInfoT = typename Tr::RegionInfoT;\n  using DomTreeT = typename Tr::DomTreeT;\n  using DomTreeNodeT = typename Tr::DomTreeNodeT;\n  using PostDomTreeT = typename Tr::PostDomTreeT;\n  using DomFrontierT = typename Tr::DomFrontierT;\n  using BlockTraits = GraphTraits<BlockT *>;\n  using InvBlockTraits = GraphTraits<Inverse<BlockT *>>;\n  using SuccIterTy = typename BlockTraits::ChildIteratorType;\n  using PredIterTy = typename InvBlockTraits::ChildIteratorType;\n\n  using BBtoBBMap = DenseMap<BlockT *, BlockT *>;\n  using BBtoRegionMap = DenseMap<BlockT *, RegionT *>;\n\n  RegionInfoBase();\n\n  RegionInfoBase(RegionInfoBase &&Arg)\n    : DT(std::move(Arg.DT)), PDT(std::move(Arg.PDT)), DF(std::move(Arg.DF)),\n      TopLevelRegion(std::move(Arg.TopLevelRegion)),\n      BBtoRegion(std::move(Arg.BBtoRegion)) {\n    Arg.wipe();\n  }\n\n  RegionInfoBase &operator=(RegionInfoBase &&RHS) {\n    DT = std::move(RHS.DT);\n    PDT = std::move(RHS.PDT);\n    DF = std::move(RHS.DF);\n    TopLevelRegion = std::move(RHS.TopLevelRegion);\n    BBtoRegion = std::move(RHS.BBtoRegion);\n    RHS.wipe();\n    return *this;\n  }\n\n  virtual ~RegionInfoBase();\n\n  DomTreeT *DT;\n  PostDomTreeT *PDT;\n  DomFrontierT *DF;\n\n  /// The top level region.\n  RegionT *TopLevelRegion = nullptr;\n\n  /// Map every BB to the smallest region, that contains BB.\n  BBtoRegionMap BBtoRegion;\n\nprotected:\n  /// Update refences to a RegionInfoT held by the RegionT managed here\n  ///\n  /// This is a post-move helper. Regions hold references to the owning\n  /// RegionInfo object. After a move these need to be fixed.\n  template<typename TheRegionT>\n  void updateRegionTree(RegionInfoT &RI, TheRegionT *R) {\n    if (!R)\n      return;\n    R->RI = &RI;\n    for (auto &SubR : *R)\n      updateRegionTree(RI, SubR.get());\n  }\n\nprivate:\n  /// Wipe this region tree's state without releasing any resources.\n  ///\n  /// This is essentially a post-move helper only. It leaves the object in an\n  /// assignable and destroyable state, but otherwise invalid.\n  void wipe() {\n    DT = nullptr;\n    PDT = nullptr;\n    DF = nullptr;\n    TopLevelRegion = nullptr;\n    BBtoRegion.clear();\n  }\n\n  // Check whether the entries of BBtoRegion for the BBs of region\n  // SR are correct. Triggers an assertion if not. Calls itself recursively for\n  // subregions.\n  void verifyBBMap(const RegionT *SR) const;\n\n  // Returns true if BB is in the dominance frontier of\n  // entry, because it was inherited from exit. In the other case there is an\n  // edge going from entry to BB without passing exit.\n  bool isCommonDomFrontier(BlockT *BB, BlockT *entry, BlockT *exit) const;\n\n  // Check if entry and exit surround a valid region, based on\n  // dominance tree and dominance frontier.\n  bool isRegion(BlockT *entry, BlockT *exit) const;\n\n  // Saves a shortcut pointing from entry to exit.\n  // This function may extend this shortcut if possible.\n  void insertShortCut(BlockT *entry, BlockT *exit, BBtoBBMap *ShortCut) const;\n\n  // Returns the next BB that postdominates N, while skipping\n  // all post dominators that cannot finish a canonical region.\n  DomTreeNodeT *getNextPostDom(DomTreeNodeT *N, BBtoBBMap *ShortCut) const;\n\n  // A region is trivial, if it contains only one BB.\n  bool isTrivialRegion(BlockT *entry, BlockT *exit) const;\n\n  // Creates a single entry single exit region.\n  RegionT *createRegion(BlockT *entry, BlockT *exit);\n\n  // Detect all regions starting with bb 'entry'.\n  void findRegionsWithEntry(BlockT *entry, BBtoBBMap *ShortCut);\n\n  // Detects regions in F.\n  void scanForRegions(FuncT &F, BBtoBBMap *ShortCut);\n\n  // Get the top most parent with the same entry block.\n  RegionT *getTopMostParent(RegionT *region);\n\n  // Build the region hierarchy after all region detected.\n  void buildRegionsTree(DomTreeNodeT *N, RegionT *region);\n\n  // Update statistic about created regions.\n  virtual void updateStatistics(RegionT *R) = 0;\n\n  // Detect all regions in function and build the region tree.\n  void calculate(FuncT &F);\n\npublic:\n  RegionInfoBase(const RegionInfoBase &) = delete;\n  RegionInfoBase &operator=(const RegionInfoBase &) = delete;\n\n  static bool VerifyRegionInfo;\n  static typename RegionT::PrintStyle printStyle;\n\n  void print(raw_ostream &OS) const;\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  void dump() const;\n#endif\n\n  void releaseMemory();\n\n  /// Get the smallest region that contains a BasicBlock.\n  ///\n  /// @param BB The basic block.\n  /// @return The smallest region, that contains BB or NULL, if there is no\n  /// region containing BB.\n  RegionT *getRegionFor(BlockT *BB) const;\n\n  ///  Set the smallest region that surrounds a basic block.\n  ///\n  /// @param BB The basic block surrounded by a region.\n  /// @param R The smallest region that surrounds BB.\n  void setRegionFor(BlockT *BB, RegionT *R);\n\n  /// A shortcut for getRegionFor().\n  ///\n  /// @param BB The basic block.\n  /// @return The smallest region, that contains BB or NULL, if there is no\n  /// region containing BB.\n  RegionT *operator[](BlockT *BB) const;\n\n  /// Return the exit of the maximal refined region, that starts at a\n  /// BasicBlock.\n  ///\n  /// @param BB The BasicBlock the refined region starts.\n  BlockT *getMaxRegionExit(BlockT *BB) const;\n\n  /// Find the smallest region that contains two regions.\n  ///\n  /// @param A The first region.\n  /// @param B The second region.\n  /// @return The smallest region containing A and B.\n  RegionT *getCommonRegion(RegionT *A, RegionT *B) const;\n\n  /// Find the smallest region that contains two basic blocks.\n  ///\n  /// @param A The first basic block.\n  /// @param B The second basic block.\n  /// @return The smallest region that contains A and B.\n  RegionT *getCommonRegion(BlockT *A, BlockT *B) const {\n    return getCommonRegion(getRegionFor(A), getRegionFor(B));\n  }\n\n  /// Find the smallest region that contains a set of regions.\n  ///\n  /// @param Regions A vector of regions.\n  /// @return The smallest region that contains all regions in Regions.\n  RegionT *getCommonRegion(SmallVectorImpl<RegionT *> &Regions) const;\n\n  /// Find the smallest region that contains a set of basic blocks.\n  ///\n  /// @param BBs A vector of basic blocks.\n  /// @return The smallest region that contains all basic blocks in BBS.\n  RegionT *getCommonRegion(SmallVectorImpl<BlockT *> &BBs) const;\n\n  RegionT *getTopLevelRegion() const { return TopLevelRegion; }\n\n  /// Clear the Node Cache for all Regions.\n  ///\n  /// @see Region::clearNodeCache()\n  void clearNodeCache() {\n    if (TopLevelRegion)\n      TopLevelRegion->clearNodeCache();\n  }\n\n  void verifyAnalysis() const;\n};\n\nclass RegionNode : public RegionNodeBase<RegionTraits<Function>> {\npublic:\n  inline RegionNode(Region *Parent, BasicBlock *Entry, bool isSubRegion = false)\n      : RegionNodeBase<RegionTraits<Function>>(Parent, Entry, isSubRegion) {}\n\n  bool operator==(const Region &RN) const {\n    return this == reinterpret_cast<const RegionNode *>(&RN);\n  }\n};\n\nclass Region : public RegionBase<RegionTraits<Function>> {\npublic:\n  Region(BasicBlock *Entry, BasicBlock *Exit, RegionInfo *RI, DominatorTree *DT,\n         Region *Parent = nullptr);\n  ~Region();\n\n  bool operator==(const RegionNode &RN) const {\n    return &RN == reinterpret_cast<const RegionNode *>(this);\n  }\n};\n\nclass RegionInfo : public RegionInfoBase<RegionTraits<Function>> {\npublic:\n  using Base = RegionInfoBase<RegionTraits<Function>>;\n\n  explicit RegionInfo();\n\n  RegionInfo(RegionInfo &&Arg) : Base(std::move(static_cast<Base &>(Arg))) {\n    updateRegionTree(*this, TopLevelRegion);\n  }\n\n  RegionInfo &operator=(RegionInfo &&RHS) {\n    Base::operator=(std::move(static_cast<Base &>(RHS)));\n    updateRegionTree(*this, TopLevelRegion);\n    return *this;\n  }\n\n  ~RegionInfo() override;\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // updateStatistics - Update statistic about created regions.\n  void updateStatistics(Region *R) final;\n\n  void recalculate(Function &F, DominatorTree *DT, PostDominatorTree *PDT,\n                   DominanceFrontier *DF);\n\n#ifndef NDEBUG\n  /// Opens a viewer to show the GraphViz visualization of the regions.\n  ///\n  /// Useful during debugging as an alternative to dump().\n  void view();\n\n  /// Opens a viewer to show the GraphViz visualization of this region\n  /// without instructions in the BasicBlocks.\n  ///\n  /// Useful during debugging as an alternative to dump().\n  void viewOnly();\n#endif\n};\n\nclass RegionInfoPass : public FunctionPass {\n  RegionInfo RI;\n\npublic:\n  static char ID;\n\n  explicit RegionInfoPass();\n  ~RegionInfoPass() override;\n\n  RegionInfo &getRegionInfo() { return RI; }\n\n  const RegionInfo &getRegionInfo() const { return RI; }\n\n  /// @name FunctionPass interface\n  //@{\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void verifyAnalysis() const override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  void print(raw_ostream &OS, const Module *) const override;\n  void dump() const;\n  //@}\n};\n\n/// Analysis pass that exposes the \\c RegionInfo for a function.\nclass RegionInfoAnalysis : public AnalysisInfoMixin<RegionInfoAnalysis> {\n  friend AnalysisInfoMixin<RegionInfoAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = RegionInfo;\n\n  RegionInfo run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c RegionInfo.\nclass RegionInfoPrinterPass : public PassInfoMixin<RegionInfoPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit RegionInfoPrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c RegionInfo.\nstruct RegionInfoVerifierPass : PassInfoMixin<RegionInfoVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\ntemplate <>\ntemplate <>\ninline BasicBlock *\nRegionNodeBase<RegionTraits<Function>>::getNodeAs<BasicBlock>() const {\n  assert(!isSubRegion() && \"This is not a BasicBlock RegionNode!\");\n  return getEntry();\n}\n\ntemplate <>\ntemplate <>\ninline Region *\nRegionNodeBase<RegionTraits<Function>>::getNodeAs<Region>() const {\n  assert(isSubRegion() && \"This is not a subregion RegionNode!\");\n  auto Unconst = const_cast<RegionNodeBase<RegionTraits<Function>> *>(this);\n  return reinterpret_cast<Region *>(Unconst);\n}\n\ntemplate <class Tr>\ninline raw_ostream &operator<<(raw_ostream &OS,\n                               const RegionNodeBase<Tr> &Node) {\n  using BlockT = typename Tr::BlockT;\n  using RegionT = typename Tr::RegionT;\n\n  if (Node.isSubRegion())\n    return OS << Node.template getNodeAs<RegionT>()->getNameStr();\n  else\n    return OS << Node.template getNodeAs<BlockT>()->getName();\n}\n\nextern template class RegionBase<RegionTraits<Function>>;\nextern template class RegionNodeBase<RegionTraits<Function>>;\nextern template class RegionInfoBase<RegionTraits<Function>>;\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_REGIONINFO_H\n"}, "59": {"id": 59, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "content": "//===- llvm/Analysis/ScalarEvolution.h - Scalar Evolution -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// The ScalarEvolution class is an LLVM pass which can be used to analyze and\n// categorize scalar expressions in loops.  It specializes in recognizing\n// general induction variables, representing them with the abstract and opaque\n// SCEV class.  Given this analysis, trip counts of loops and other important\n// properties can be obtained.\n//\n// This analysis is primarily useful for induction variable substitution and\n// strength reduction.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_SCALAREVOLUTION_H\n#define LLVM_ANALYSIS_SCALAREVOLUTION_H\n\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/ADT/Hashing.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/ConstantRange.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/Operator.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/IR/ValueMap.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Allocator.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/Compiler.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstdint>\n#include <memory>\n#include <utility>\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass BasicBlock;\nclass Constant;\nclass ConstantInt;\nclass DataLayout;\nclass DominatorTree;\nclass GEPOperator;\nclass Instruction;\nclass LLVMContext;\nclass Loop;\nclass LoopInfo;\nclass raw_ostream;\nclass ScalarEvolution;\nclass SCEVAddRecExpr;\nclass SCEVUnknown;\nclass StructType;\nclass TargetLibraryInfo;\nclass Type;\nclass Value;\nenum SCEVTypes : unsigned short;\n\n/// This class represents an analyzed expression in the program.  These are\n/// opaque objects that the client is not allowed to do much with directly.\n///\nclass SCEV : public FoldingSetNode {\n  friend struct FoldingSetTrait<SCEV>;\n\n  /// A reference to an Interned FoldingSetNodeID for this node.  The\n  /// ScalarEvolution's BumpPtrAllocator holds the data.\n  FoldingSetNodeIDRef FastID;\n\n  // The SCEV baseclass this node corresponds to\n  const SCEVTypes SCEVType;\n\nprotected:\n  // Estimated complexity of this node's expression tree size.\n  const unsigned short ExpressionSize;\n\n  /// This field is initialized to zero and may be used in subclasses to store\n  /// miscellaneous information.\n  unsigned short SubclassData = 0;\n\npublic:\n  /// NoWrapFlags are bitfield indices into SubclassData.\n  ///\n  /// Add and Mul expressions may have no-unsigned-wrap <NUW> or\n  /// no-signed-wrap <NSW> properties, which are derived from the IR\n  /// operator. NSW is a misnomer that we use to mean no signed overflow or\n  /// underflow.\n  ///\n  /// AddRec expressions may have a no-self-wraparound <NW> property if, in\n  /// the integer domain, abs(step) * max-iteration(loop) <=\n  /// unsigned-max(bitwidth).  This means that the recurrence will never reach\n  /// its start value if the step is non-zero.  Computing the same value on\n  /// each iteration is not considered wrapping, and recurrences with step = 0\n  /// are trivially <NW>.  <NW> is independent of the sign of step and the\n  /// value the add recurrence starts with.\n  ///\n  /// Note that NUW and NSW are also valid properties of a recurrence, and\n  /// either implies NW. For convenience, NW will be set for a recurrence\n  /// whenever either NUW or NSW are set.\n  enum NoWrapFlags {\n    FlagAnyWrap = 0,    // No guarantee.\n    FlagNW = (1 << 0),  // No self-wrap.\n    FlagNUW = (1 << 1), // No unsigned wrap.\n    FlagNSW = (1 << 2), // No signed wrap.\n    NoWrapMask = (1 << 3) - 1\n  };\n\n  explicit SCEV(const FoldingSetNodeIDRef ID, SCEVTypes SCEVTy,\n                unsigned short ExpressionSize)\n      : FastID(ID), SCEVType(SCEVTy), ExpressionSize(ExpressionSize) {}\n  SCEV(const SCEV &) = delete;\n  SCEV &operator=(const SCEV &) = delete;\n\n  SCEVTypes getSCEVType() const { return SCEVType; }\n\n  /// Return the LLVM type of this SCEV expression.\n  Type *getType() const;\n\n  /// Return true if the expression is a constant zero.\n  bool isZero() const;\n\n  /// Return true if the expression is a constant one.\n  bool isOne() const;\n\n  /// Return true if the expression is a constant all-ones value.\n  bool isAllOnesValue() const;\n\n  /// Return true if the specified scev is negated, but not a constant.\n  bool isNonConstantNegative() const;\n\n  // Returns estimated size of the mathematical expression represented by this\n  // SCEV. The rules of its calculation are following:\n  // 1) Size of a SCEV without operands (like constants and SCEVUnknown) is 1;\n  // 2) Size SCEV with operands Op1, Op2, ..., OpN is calculated by formula:\n  //    (1 + Size(Op1) + ... + Size(OpN)).\n  // This value gives us an estimation of time we need to traverse through this\n  // SCEV and all its operands recursively. We may use it to avoid performing\n  // heavy transformations on SCEVs of excessive size for sake of saving the\n  // compilation time.\n  unsigned short getExpressionSize() const {\n    return ExpressionSize;\n  }\n\n  /// Print out the internal representation of this scalar to the specified\n  /// stream.  This should really only be used for debugging purposes.\n  void print(raw_ostream &OS) const;\n\n  /// This method is used for debugging.\n  void dump() const;\n};\n\n// Specialize FoldingSetTrait for SCEV to avoid needing to compute\n// temporary FoldingSetNodeID values.\ntemplate <> struct FoldingSetTrait<SCEV> : DefaultFoldingSetTrait<SCEV> {\n  static void Profile(const SCEV &X, FoldingSetNodeID &ID) { ID = X.FastID; }\n\n  static bool Equals(const SCEV &X, const FoldingSetNodeID &ID, unsigned IDHash,\n                     FoldingSetNodeID &TempID) {\n    return ID == X.FastID;\n  }\n\n  static unsigned ComputeHash(const SCEV &X, FoldingSetNodeID &TempID) {\n    return X.FastID.ComputeHash();\n  }\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const SCEV &S) {\n  S.print(OS);\n  return OS;\n}\n\n/// An object of this class is returned by queries that could not be answered.\n/// For example, if you ask for the number of iterations of a linked-list\n/// traversal loop, you will get one of these.  None of the standard SCEV\n/// operations are valid on this class, it is just a marker.\nstruct SCEVCouldNotCompute : public SCEV {\n  SCEVCouldNotCompute();\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEV *S);\n};\n\n/// This class represents an assumption made using SCEV expressions which can\n/// be checked at run-time.\nclass SCEVPredicate : public FoldingSetNode {\n  friend struct FoldingSetTrait<SCEVPredicate>;\n\n  /// A reference to an Interned FoldingSetNodeID for this node.  The\n  /// ScalarEvolution's BumpPtrAllocator holds the data.\n  FoldingSetNodeIDRef FastID;\n\npublic:\n  enum SCEVPredicateKind { P_Union, P_Equal, P_Wrap };\n\nprotected:\n  SCEVPredicateKind Kind;\n  ~SCEVPredicate() = default;\n  SCEVPredicate(const SCEVPredicate &) = default;\n  SCEVPredicate &operator=(const SCEVPredicate &) = default;\n\npublic:\n  SCEVPredicate(const FoldingSetNodeIDRef ID, SCEVPredicateKind Kind);\n\n  SCEVPredicateKind getKind() const { return Kind; }\n\n  /// Returns the estimated complexity of this predicate.  This is roughly\n  /// measured in the number of run-time checks required.\n  virtual unsigned getComplexity() const { return 1; }\n\n  /// Returns true if the predicate is always true. This means that no\n  /// assumptions were made and nothing needs to be checked at run-time.\n  virtual bool isAlwaysTrue() const = 0;\n\n  /// Returns true if this predicate implies \\p N.\n  virtual bool implies(const SCEVPredicate *N) const = 0;\n\n  /// Prints a textual representation of this predicate with an indentation of\n  /// \\p Depth.\n  virtual void print(raw_ostream &OS, unsigned Depth = 0) const = 0;\n\n  /// Returns the SCEV to which this predicate applies, or nullptr if this is\n  /// a SCEVUnionPredicate.\n  virtual const SCEV *getExpr() const = 0;\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const SCEVPredicate &P) {\n  P.print(OS);\n  return OS;\n}\n\n// Specialize FoldingSetTrait for SCEVPredicate to avoid needing to compute\n// temporary FoldingSetNodeID values.\ntemplate <>\nstruct FoldingSetTrait<SCEVPredicate> : DefaultFoldingSetTrait<SCEVPredicate> {\n  static void Profile(const SCEVPredicate &X, FoldingSetNodeID &ID) {\n    ID = X.FastID;\n  }\n\n  static bool Equals(const SCEVPredicate &X, const FoldingSetNodeID &ID,\n                     unsigned IDHash, FoldingSetNodeID &TempID) {\n    return ID == X.FastID;\n  }\n\n  static unsigned ComputeHash(const SCEVPredicate &X,\n                              FoldingSetNodeID &TempID) {\n    return X.FastID.ComputeHash();\n  }\n};\n\n/// This class represents an assumption that two SCEV expressions are equal,\n/// and this can be checked at run-time.\nclass SCEVEqualPredicate final : public SCEVPredicate {\n  /// We assume that LHS == RHS.\n  const SCEV *LHS;\n  const SCEV *RHS;\n\npublic:\n  SCEVEqualPredicate(const FoldingSetNodeIDRef ID, const SCEV *LHS,\n                     const SCEV *RHS);\n\n  /// Implementation of the SCEVPredicate interface\n  bool implies(const SCEVPredicate *N) const override;\n  void print(raw_ostream &OS, unsigned Depth = 0) const override;\n  bool isAlwaysTrue() const override;\n  const SCEV *getExpr() const override;\n\n  /// Returns the left hand side of the equality.\n  const SCEV *getLHS() const { return LHS; }\n\n  /// Returns the right hand side of the equality.\n  const SCEV *getRHS() const { return RHS; }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEVPredicate *P) {\n    return P->getKind() == P_Equal;\n  }\n};\n\n/// This class represents an assumption made on an AddRec expression. Given an\n/// affine AddRec expression {a,+,b}, we assume that it has the nssw or nusw\n/// flags (defined below) in the first X iterations of the loop, where X is a\n/// SCEV expression returned by getPredicatedBackedgeTakenCount).\n///\n/// Note that this does not imply that X is equal to the backedge taken\n/// count. This means that if we have a nusw predicate for i32 {0,+,1} with a\n/// predicated backedge taken count of X, we only guarantee that {0,+,1} has\n/// nusw in the first X iterations. {0,+,1} may still wrap in the loop if we\n/// have more than X iterations.\nclass SCEVWrapPredicate final : public SCEVPredicate {\npublic:\n  /// Similar to SCEV::NoWrapFlags, but with slightly different semantics\n  /// for FlagNUSW. The increment is considered to be signed, and a + b\n  /// (where b is the increment) is considered to wrap if:\n  ///    zext(a + b) != zext(a) + sext(b)\n  ///\n  /// If Signed is a function that takes an n-bit tuple and maps to the\n  /// integer domain as the tuples value interpreted as twos complement,\n  /// and Unsigned a function that takes an n-bit tuple and maps to the\n  /// integer domain as as the base two value of input tuple, then a + b\n  /// has IncrementNUSW iff:\n  ///\n  /// 0 <= Unsigned(a) + Signed(b) < 2^n\n  ///\n  /// The IncrementNSSW flag has identical semantics with SCEV::FlagNSW.\n  ///\n  /// Note that the IncrementNUSW flag is not commutative: if base + inc\n  /// has IncrementNUSW, then inc + base doesn't neccessarily have this\n  /// property. The reason for this is that this is used for sign/zero\n  /// extending affine AddRec SCEV expressions when a SCEVWrapPredicate is\n  /// assumed. A {base,+,inc} expression is already non-commutative with\n  /// regards to base and inc, since it is interpreted as:\n  ///     (((base + inc) + inc) + inc) ...\n  enum IncrementWrapFlags {\n    IncrementAnyWrap = 0,     // No guarantee.\n    IncrementNUSW = (1 << 0), // No unsigned with signed increment wrap.\n    IncrementNSSW = (1 << 1), // No signed with signed increment wrap\n                              // (equivalent with SCEV::NSW)\n    IncrementNoWrapMask = (1 << 2) - 1\n  };\n\n  /// Convenient IncrementWrapFlags manipulation methods.\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  clearFlags(SCEVWrapPredicate::IncrementWrapFlags Flags,\n             SCEVWrapPredicate::IncrementWrapFlags OffFlags) {\n    assert((Flags & IncrementNoWrapMask) == Flags && \"Invalid flags value!\");\n    assert((OffFlags & IncrementNoWrapMask) == OffFlags &&\n           \"Invalid flags value!\");\n    return (SCEVWrapPredicate::IncrementWrapFlags)(Flags & ~OffFlags);\n  }\n\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  maskFlags(SCEVWrapPredicate::IncrementWrapFlags Flags, int Mask) {\n    assert((Flags & IncrementNoWrapMask) == Flags && \"Invalid flags value!\");\n    assert((Mask & IncrementNoWrapMask) == Mask && \"Invalid mask value!\");\n\n    return (SCEVWrapPredicate::IncrementWrapFlags)(Flags & Mask);\n  }\n\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  setFlags(SCEVWrapPredicate::IncrementWrapFlags Flags,\n           SCEVWrapPredicate::IncrementWrapFlags OnFlags) {\n    assert((Flags & IncrementNoWrapMask) == Flags && \"Invalid flags value!\");\n    assert((OnFlags & IncrementNoWrapMask) == OnFlags &&\n           \"Invalid flags value!\");\n\n    return (SCEVWrapPredicate::IncrementWrapFlags)(Flags | OnFlags);\n  }\n\n  /// Returns the set of SCEVWrapPredicate no wrap flags implied by a\n  /// SCEVAddRecExpr.\n  LLVM_NODISCARD static SCEVWrapPredicate::IncrementWrapFlags\n  getImpliedFlags(const SCEVAddRecExpr *AR, ScalarEvolution &SE);\n\nprivate:\n  const SCEVAddRecExpr *AR;\n  IncrementWrapFlags Flags;\n\npublic:\n  explicit SCEVWrapPredicate(const FoldingSetNodeIDRef ID,\n                             const SCEVAddRecExpr *AR,\n                             IncrementWrapFlags Flags);\n\n  /// Returns the set assumed no overflow flags.\n  IncrementWrapFlags getFlags() const { return Flags; }\n\n  /// Implementation of the SCEVPredicate interface\n  const SCEV *getExpr() const override;\n  bool implies(const SCEVPredicate *N) const override;\n  void print(raw_ostream &OS, unsigned Depth = 0) const override;\n  bool isAlwaysTrue() const override;\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEVPredicate *P) {\n    return P->getKind() == P_Wrap;\n  }\n};\n\n/// This class represents a composition of other SCEV predicates, and is the\n/// class that most clients will interact with.  This is equivalent to a\n/// logical \"AND\" of all the predicates in the union.\n///\n/// NB! Unlike other SCEVPredicate sub-classes this class does not live in the\n/// ScalarEvolution::Preds folding set.  This is why the \\c add function is sound.\nclass SCEVUnionPredicate final : public SCEVPredicate {\nprivate:\n  using PredicateMap =\n      DenseMap<const SCEV *, SmallVector<const SCEVPredicate *, 4>>;\n\n  /// Vector with references to all predicates in this union.\n  SmallVector<const SCEVPredicate *, 16> Preds;\n\n  /// Maps SCEVs to predicates for quick look-ups.\n  PredicateMap SCEVToPreds;\n\npublic:\n  SCEVUnionPredicate();\n\n  const SmallVectorImpl<const SCEVPredicate *> &getPredicates() const {\n    return Preds;\n  }\n\n  /// Adds a predicate to this union.\n  void add(const SCEVPredicate *N);\n\n  /// Returns a reference to a vector containing all predicates which apply to\n  /// \\p Expr.\n  ArrayRef<const SCEVPredicate *> getPredicatesForExpr(const SCEV *Expr);\n\n  /// Implementation of the SCEVPredicate interface\n  bool isAlwaysTrue() const override;\n  bool implies(const SCEVPredicate *N) const override;\n  void print(raw_ostream &OS, unsigned Depth) const override;\n  const SCEV *getExpr() const override;\n\n  /// We estimate the complexity of a union predicate as the size number of\n  /// predicates in the union.\n  unsigned getComplexity() const override { return Preds.size(); }\n\n  /// Methods for support type inquiry through isa, cast, and dyn_cast:\n  static bool classof(const SCEVPredicate *P) {\n    return P->getKind() == P_Union;\n  }\n};\n\n/// The main scalar evolution driver. Because client code (intentionally)\n/// can't do much with the SCEV objects directly, they must ask this class\n/// for services.\nclass ScalarEvolution {\n  friend class ScalarEvolutionsTest;\n\npublic:\n  /// An enum describing the relationship between a SCEV and a loop.\n  enum LoopDisposition {\n    LoopVariant,   ///< The SCEV is loop-variant (unknown).\n    LoopInvariant, ///< The SCEV is loop-invariant.\n    LoopComputable ///< The SCEV varies predictably with the loop.\n  };\n\n  /// An enum describing the relationship between a SCEV and a basic block.\n  enum BlockDisposition {\n    DoesNotDominateBlock,  ///< The SCEV does not dominate the block.\n    DominatesBlock,        ///< The SCEV dominates the block.\n    ProperlyDominatesBlock ///< The SCEV properly dominates the block.\n  };\n\n  /// Convenient NoWrapFlags manipulation that hides enum casts and is\n  /// visible in the ScalarEvolution name space.\n  LLVM_NODISCARD static SCEV::NoWrapFlags maskFlags(SCEV::NoWrapFlags Flags,\n                                                    int Mask) {\n    return (SCEV::NoWrapFlags)(Flags & Mask);\n  }\n  LLVM_NODISCARD static SCEV::NoWrapFlags setFlags(SCEV::NoWrapFlags Flags,\n                                                   SCEV::NoWrapFlags OnFlags) {\n    return (SCEV::NoWrapFlags)(Flags | OnFlags);\n  }\n  LLVM_NODISCARD static SCEV::NoWrapFlags\n  clearFlags(SCEV::NoWrapFlags Flags, SCEV::NoWrapFlags OffFlags) {\n    return (SCEV::NoWrapFlags)(Flags & ~OffFlags);\n  }\n\n  ScalarEvolution(Function &F, TargetLibraryInfo &TLI, AssumptionCache &AC,\n                  DominatorTree &DT, LoopInfo &LI);\n  ScalarEvolution(ScalarEvolution &&Arg);\n  ~ScalarEvolution();\n\n  LLVMContext &getContext() const { return F.getContext(); }\n\n  /// Test if values of the given type are analyzable within the SCEV\n  /// framework. This primarily includes integer types, and it can optionally\n  /// include pointer types if the ScalarEvolution class has access to\n  /// target-specific information.\n  bool isSCEVable(Type *Ty) const;\n\n  /// Return the size in bits of the specified type, for which isSCEVable must\n  /// return true.\n  uint64_t getTypeSizeInBits(Type *Ty) const;\n\n  /// Return a type with the same bitwidth as the given type and which\n  /// represents how SCEV will treat the given type, for which isSCEVable must\n  /// return true. For pointer types, this is the pointer-sized integer type.\n  Type *getEffectiveSCEVType(Type *Ty) const;\n\n  // Returns a wider type among {Ty1, Ty2}.\n  Type *getWiderType(Type *Ty1, Type *Ty2) const;\n\n  /// Return true if the SCEV is a scAddRecExpr or it contains\n  /// scAddRecExpr. The result will be cached in HasRecMap.\n  bool containsAddRecurrence(const SCEV *S);\n\n  /// Erase Value from ValueExprMap and ExprValueMap.\n  void eraseValueFromMap(Value *V);\n\n  /// Return a SCEV expression for the full generality of the specified\n  /// expression.\n  const SCEV *getSCEV(Value *V);\n\n  const SCEV *getConstant(ConstantInt *V);\n  const SCEV *getConstant(const APInt &Val);\n  const SCEV *getConstant(Type *Ty, uint64_t V, bool isSigned = false);\n  const SCEV *getPtrToIntExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getTruncateExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getZeroExtendExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getSignExtendExpr(const SCEV *Op, Type *Ty, unsigned Depth = 0);\n  const SCEV *getAnyExtendExpr(const SCEV *Op, Type *Ty);\n  const SCEV *getAddExpr(SmallVectorImpl<const SCEV *> &Ops,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0);\n  const SCEV *getAddExpr(const SCEV *LHS, const SCEV *RHS,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 2> Ops = {LHS, RHS};\n    return getAddExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getAddExpr(const SCEV *Op0, const SCEV *Op1, const SCEV *Op2,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 3> Ops = {Op0, Op1, Op2};\n    return getAddExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getMulExpr(SmallVectorImpl<const SCEV *> &Ops,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0);\n  const SCEV *getMulExpr(const SCEV *LHS, const SCEV *RHS,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 2> Ops = {LHS, RHS};\n    return getMulExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getMulExpr(const SCEV *Op0, const SCEV *Op1, const SCEV *Op2,\n                         SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                         unsigned Depth = 0) {\n    SmallVector<const SCEV *, 3> Ops = {Op0, Op1, Op2};\n    return getMulExpr(Ops, Flags, Depth);\n  }\n  const SCEV *getUDivExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getUDivExactExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getURemExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getAddRecExpr(const SCEV *Start, const SCEV *Step, const Loop *L,\n                            SCEV::NoWrapFlags Flags);\n  const SCEV *getAddRecExpr(SmallVectorImpl<const SCEV *> &Operands,\n                            const Loop *L, SCEV::NoWrapFlags Flags);\n  const SCEV *getAddRecExpr(const SmallVectorImpl<const SCEV *> &Operands,\n                            const Loop *L, SCEV::NoWrapFlags Flags) {\n    SmallVector<const SCEV *, 4> NewOp(Operands.begin(), Operands.end());\n    return getAddRecExpr(NewOp, L, Flags);\n  }\n\n  /// Checks if \\p SymbolicPHI can be rewritten as an AddRecExpr under some\n  /// Predicates. If successful return these <AddRecExpr, Predicates>;\n  /// The function is intended to be called from PSCEV (the caller will decide\n  /// whether to actually add the predicates and carry out the rewrites).\n  Optional<std::pair<const SCEV *, SmallVector<const SCEVPredicate *, 3>>>\n  createAddRecFromPHIWithCasts(const SCEVUnknown *SymbolicPHI);\n\n  /// Returns an expression for a GEP\n  ///\n  /// \\p GEP The GEP. The indices contained in the GEP itself are ignored,\n  /// instead we use IndexExprs.\n  /// \\p IndexExprs The expressions for the indices.\n  const SCEV *getGEPExpr(GEPOperator *GEP,\n                         const SmallVectorImpl<const SCEV *> &IndexExprs);\n  const SCEV *getAbsExpr(const SCEV *Op, bool IsNSW);\n  const SCEV *getSignumExpr(const SCEV *Op);\n  const SCEV *getMinMaxExpr(SCEVTypes Kind,\n                            SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getSMaxExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getSMaxExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getUMaxExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getUMaxExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getSMinExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getSMinExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getUMinExpr(const SCEV *LHS, const SCEV *RHS);\n  const SCEV *getUMinExpr(SmallVectorImpl<const SCEV *> &Operands);\n  const SCEV *getUnknown(Value *V);\n  const SCEV *getCouldNotCompute();\n\n  /// Return a SCEV for the constant 0 of a specific type.\n  const SCEV *getZero(Type *Ty) { return getConstant(Ty, 0); }\n\n  /// Return a SCEV for the constant 1 of a specific type.\n  const SCEV *getOne(Type *Ty) { return getConstant(Ty, 1); }\n\n  /// Return a SCEV for the constant -1 of a specific type.\n  const SCEV *getMinusOne(Type *Ty) {\n    return getConstant(Ty, -1, /*isSigned=*/true);\n  }\n\n  /// Return an expression for sizeof ScalableTy that is type IntTy, where\n  /// ScalableTy is a scalable vector type.\n  const SCEV *getSizeOfScalableVectorExpr(Type *IntTy,\n                                          ScalableVectorType *ScalableTy);\n\n  /// Return an expression for the alloc size of AllocTy that is type IntTy\n  const SCEV *getSizeOfExpr(Type *IntTy, Type *AllocTy);\n\n  /// Return an expression for the store size of StoreTy that is type IntTy\n  const SCEV *getStoreSizeOfExpr(Type *IntTy, Type *StoreTy);\n\n  /// Return an expression for offsetof on the given field with type IntTy\n  const SCEV *getOffsetOfExpr(Type *IntTy, StructType *STy, unsigned FieldNo);\n\n  /// Return the SCEV object corresponding to -V.\n  const SCEV *getNegativeSCEV(const SCEV *V,\n                              SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap);\n\n  /// Return the SCEV object corresponding to ~V.\n  const SCEV *getNotSCEV(const SCEV *V);\n\n  /// Return LHS-RHS.  Minus is represented in SCEV as A+B*-1.\n  const SCEV *getMinusSCEV(const SCEV *LHS, const SCEV *RHS,\n                           SCEV::NoWrapFlags Flags = SCEV::FlagAnyWrap,\n                           unsigned Depth = 0);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is zero extended.\n  const SCEV *getTruncateOrZeroExtend(const SCEV *V, Type *Ty,\n                                      unsigned Depth = 0);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is sign extended.\n  const SCEV *getTruncateOrSignExtend(const SCEV *V, Type *Ty,\n                                      unsigned Depth = 0);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is zero extended.  The\n  /// conversion must not be narrowing.\n  const SCEV *getNoopOrZeroExtend(const SCEV *V, Type *Ty);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  If the type must be extended, it is sign extended.  The\n  /// conversion must not be narrowing.\n  const SCEV *getNoopOrSignExtend(const SCEV *V, Type *Ty);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type. If the type must be extended, it is extended with\n  /// unspecified bits. The conversion must not be narrowing.\n  const SCEV *getNoopOrAnyExtend(const SCEV *V, Type *Ty);\n\n  /// Return a SCEV corresponding to a conversion of the input value to the\n  /// specified type.  The conversion must not be widening.\n  const SCEV *getTruncateOrNoop(const SCEV *V, Type *Ty);\n\n  /// Promote the operands to the wider of the types using zero-extension, and\n  /// then perform a umax operation with them.\n  const SCEV *getUMaxFromMismatchedTypes(const SCEV *LHS, const SCEV *RHS);\n\n  /// Promote the operands to the wider of the types using zero-extension, and\n  /// then perform a umin operation with them.\n  const SCEV *getUMinFromMismatchedTypes(const SCEV *LHS, const SCEV *RHS);\n\n  /// Promote the operands to the wider of the types using zero-extension, and\n  /// then perform a umin operation with them. N-ary function.\n  const SCEV *getUMinFromMismatchedTypes(SmallVectorImpl<const SCEV *> &Ops);\n\n  /// Transitively follow the chain of pointer-type operands until reaching a\n  /// SCEV that does not have a single pointer operand. This returns a\n  /// SCEVUnknown pointer for well-formed pointer-type expressions, but corner\n  /// cases do exist.\n  const SCEV *getPointerBase(const SCEV *V);\n\n  /// Return a SCEV expression for the specified value at the specified scope\n  /// in the program.  The L value specifies a loop nest to evaluate the\n  /// expression at, where null is the top-level or a specified loop is\n  /// immediately inside of the loop.\n  ///\n  /// This method can be used to compute the exit value for a variable defined\n  /// in a loop by querying what the value will hold in the parent loop.\n  ///\n  /// In the case that a relevant loop exit value cannot be computed, the\n  /// original value V is returned.\n  const SCEV *getSCEVAtScope(const SCEV *S, const Loop *L);\n\n  /// This is a convenience function which does getSCEVAtScope(getSCEV(V), L).\n  const SCEV *getSCEVAtScope(Value *V, const Loop *L);\n\n  /// Test whether entry to the loop is protected by a conditional between LHS\n  /// and RHS.  This is used to help avoid max expressions in loop trip\n  /// counts, and to eliminate casts.\n  bool isLoopEntryGuardedByCond(const Loop *L, ICmpInst::Predicate Pred,\n                                const SCEV *LHS, const SCEV *RHS);\n\n  /// Test whether entry to the basic block is protected by a conditional\n  /// between LHS and RHS.\n  bool isBasicBlockEntryGuardedByCond(const BasicBlock *BB,\n                                      ICmpInst::Predicate Pred, const SCEV *LHS,\n                                      const SCEV *RHS);\n\n  /// Test whether the backedge of the loop is protected by a conditional\n  /// between LHS and RHS.  This is used to eliminate casts.\n  bool isLoopBackedgeGuardedByCond(const Loop *L, ICmpInst::Predicate Pred,\n                                   const SCEV *LHS, const SCEV *RHS);\n\n  /// Returns the maximum trip count of the loop if it is a single-exit\n  /// loop and we can compute a small maximum for that loop.\n  ///\n  /// Implemented in terms of the \\c getSmallConstantTripCount overload with\n  /// the single exiting block passed to it. See that routine for details.\n  unsigned getSmallConstantTripCount(const Loop *L);\n\n  /// Returns the maximum trip count of this loop as a normal unsigned\n  /// value. Returns 0 if the trip count is unknown or not constant. This\n  /// \"trip count\" assumes that control exits via ExitingBlock. More\n  /// precisely, it is the number of times that control may reach ExitingBlock\n  /// before taking the branch. For loops with multiple exits, it may not be\n  /// the number times that the loop header executes if the loop exits\n  /// prematurely via another branch.\n  unsigned getSmallConstantTripCount(const Loop *L,\n                                     const BasicBlock *ExitingBlock);\n\n  /// Returns the upper bound of the loop trip count as a normal unsigned\n  /// value.\n  /// Returns 0 if the trip count is unknown or not constant.\n  unsigned getSmallConstantMaxTripCount(const Loop *L);\n\n  /// Returns the largest constant divisor of the trip count of the\n  /// loop if it is a single-exit loop and we can compute a small maximum for\n  /// that loop.\n  ///\n  /// Implemented in terms of the \\c getSmallConstantTripMultiple overload with\n  /// the single exiting block passed to it. See that routine for details.\n  unsigned getSmallConstantTripMultiple(const Loop *L);\n\n  /// Returns the largest constant divisor of the trip count of this loop as a\n  /// normal unsigned value, if possible. This means that the actual trip\n  /// count is always a multiple of the returned value (don't forget the trip\n  /// count could very well be zero as well!). As explained in the comments\n  /// for getSmallConstantTripCount, this assumes that control exits the loop\n  /// via ExitingBlock.\n  unsigned getSmallConstantTripMultiple(const Loop *L,\n                                        const BasicBlock *ExitingBlock);\n\n  /// The terms \"backedge taken count\" and \"exit count\" are used\n  /// interchangeably to refer to the number of times the backedge of a loop \n  /// has executed before the loop is exited.\n  enum ExitCountKind {\n    /// An expression exactly describing the number of times the backedge has\n    /// executed when a loop is exited.\n    Exact,\n    /// A constant which provides an upper bound on the exact trip count.\n    ConstantMaximum,\n    /// An expression which provides an upper bound on the exact trip count.\n    SymbolicMaximum,\n  };\n\n  /// Return the number of times the backedge executes before the given exit\n  /// would be taken; if not exactly computable, return SCEVCouldNotCompute. \n  /// For a single exit loop, this value is equivelent to the result of\n  /// getBackedgeTakenCount.  The loop is guaranteed to exit (via *some* exit)\n  /// before the backedge is executed (ExitCount + 1) times.  Note that there\n  /// is no guarantee about *which* exit is taken on the exiting iteration.\n  const SCEV *getExitCount(const Loop *L, const BasicBlock *ExitingBlock,\n                           ExitCountKind Kind = Exact);\n\n  /// If the specified loop has a predictable backedge-taken count, return it,\n  /// otherwise return a SCEVCouldNotCompute object. The backedge-taken count is\n  /// the number of times the loop header will be branched to from within the\n  /// loop, assuming there are no abnormal exists like exception throws. This is\n  /// one less than the trip count of the loop, since it doesn't count the first\n  /// iteration, when the header is branched to from outside the loop.\n  ///\n  /// Note that it is not valid to call this method on a loop without a\n  /// loop-invariant backedge-taken count (see\n  /// hasLoopInvariantBackedgeTakenCount).\n  const SCEV *getBackedgeTakenCount(const Loop *L, ExitCountKind Kind = Exact);\n\n  /// Similar to getBackedgeTakenCount, except it will add a set of\n  /// SCEV predicates to Predicates that are required to be true in order for\n  /// the answer to be correct. Predicates can be checked with run-time\n  /// checks and can be used to perform loop versioning.\n  const SCEV *getPredicatedBackedgeTakenCount(const Loop *L,\n                                              SCEVUnionPredicate &Predicates);\n\n  /// When successful, this returns a SCEVConstant that is greater than or equal\n  /// to (i.e. a \"conservative over-approximation\") of the value returend by\n  /// getBackedgeTakenCount.  If such a value cannot be computed, it returns the\n  /// SCEVCouldNotCompute object.\n  const SCEV *getConstantMaxBackedgeTakenCount(const Loop *L) {\n    return getBackedgeTakenCount(L, ConstantMaximum);\n  }\n\n  /// When successful, this returns a SCEV that is greater than or equal\n  /// to (i.e. a \"conservative over-approximation\") of the value returend by\n  /// getBackedgeTakenCount.  If such a value cannot be computed, it returns the\n  /// SCEVCouldNotCompute object.\n  const SCEV *getSymbolicMaxBackedgeTakenCount(const Loop *L) {\n    return getBackedgeTakenCount(L, SymbolicMaximum);\n  }\n\n  /// Return true if the backedge taken count is either the value returned by\n  /// getConstantMaxBackedgeTakenCount or zero.\n  bool isBackedgeTakenCountMaxOrZero(const Loop *L);\n\n  /// Return true if the specified loop has an analyzable loop-invariant\n  /// backedge-taken count.\n  bool hasLoopInvariantBackedgeTakenCount(const Loop *L);\n\n  // This method should be called by the client when it made any change that\n  // would invalidate SCEV's answers, and the client wants to remove all loop\n  // information held internally by ScalarEvolution. This is intended to be used\n  // when the alternative to forget a loop is too expensive (i.e. large loop\n  // bodies).\n  void forgetAllLoops();\n\n  /// This method should be called by the client when it has changed a loop in\n  /// a way that may effect ScalarEvolution's ability to compute a trip count,\n  /// or if the loop is deleted.  This call is potentially expensive for large\n  /// loop bodies.\n  void forgetLoop(const Loop *L);\n\n  // This method invokes forgetLoop for the outermost loop of the given loop\n  // \\p L, making ScalarEvolution forget about all this subtree. This needs to\n  // be done whenever we make a transform that may affect the parameters of the\n  // outer loop, such as exit counts for branches.\n  void forgetTopmostLoop(const Loop *L);\n\n  /// This method should be called by the client when it has changed a value\n  /// in a way that may effect its value, or which may disconnect it from a\n  /// def-use chain linking it to a loop.\n  void forgetValue(Value *V);\n\n  /// Called when the client has changed the disposition of values in\n  /// this loop.\n  ///\n  /// We don't have a way to invalidate per-loop dispositions. Clear and\n  /// recompute is simpler.\n  void forgetLoopDispositions(const Loop *L);\n\n  /// Determine the minimum number of zero bits that S is guaranteed to end in\n  /// (at every loop iteration).  It is, at the same time, the minimum number\n  /// of times S is divisible by 2.  For example, given {4,+,8} it returns 2.\n  /// If S is guaranteed to be 0, it returns the bitwidth of S.\n  uint32_t GetMinTrailingZeros(const SCEV *S);\n\n  /// Determine the unsigned range for a particular SCEV.\n  /// NOTE: This returns a copy of the reference returned by getRangeRef.\n  ConstantRange getUnsignedRange(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_UNSIGNED);\n  }\n\n  /// Determine the min of the unsigned range for a particular SCEV.\n  APInt getUnsignedRangeMin(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_UNSIGNED).getUnsignedMin();\n  }\n\n  /// Determine the max of the unsigned range for a particular SCEV.\n  APInt getUnsignedRangeMax(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_UNSIGNED).getUnsignedMax();\n  }\n\n  /// Determine the signed range for a particular SCEV.\n  /// NOTE: This returns a copy of the reference returned by getRangeRef.\n  ConstantRange getSignedRange(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_SIGNED);\n  }\n\n  /// Determine the min of the signed range for a particular SCEV.\n  APInt getSignedRangeMin(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_SIGNED).getSignedMin();\n  }\n\n  /// Determine the max of the signed range for a particular SCEV.\n  APInt getSignedRangeMax(const SCEV *S) {\n    return getRangeRef(S, HINT_RANGE_SIGNED).getSignedMax();\n  }\n\n  /// Test if the given expression is known to be negative.\n  bool isKnownNegative(const SCEV *S);\n\n  /// Test if the given expression is known to be positive.\n  bool isKnownPositive(const SCEV *S);\n\n  /// Test if the given expression is known to be non-negative.\n  bool isKnownNonNegative(const SCEV *S);\n\n  /// Test if the given expression is known to be non-positive.\n  bool isKnownNonPositive(const SCEV *S);\n\n  /// Test if the given expression is known to be non-zero.\n  bool isKnownNonZero(const SCEV *S);\n\n  /// Splits SCEV expression \\p S into two SCEVs. One of them is obtained from\n  /// \\p S by substitution of all AddRec sub-expression related to loop \\p L\n  /// with initial value of that SCEV. The second is obtained from \\p S by\n  /// substitution of all AddRec sub-expressions related to loop \\p L with post\n  /// increment of this AddRec in the loop \\p L. In both cases all other AddRec\n  /// sub-expressions (not related to \\p L) remain the same.\n  /// If the \\p S contains non-invariant unknown SCEV the function returns\n  /// CouldNotCompute SCEV in both values of std::pair.\n  /// For example, for SCEV S={0, +, 1}<L1> + {0, +, 1}<L2> and loop L=L1\n  /// the function returns pair:\n  /// first = {0, +, 1}<L2>\n  /// second = {1, +, 1}<L1> + {0, +, 1}<L2>\n  /// We can see that for the first AddRec sub-expression it was replaced with\n  /// 0 (initial value) for the first element and to {1, +, 1}<L1> (post\n  /// increment value) for the second one. In both cases AddRec expression\n  /// related to L2 remains the same.\n  std::pair<const SCEV *, const SCEV *> SplitIntoInitAndPostInc(const Loop *L,\n                                                                const SCEV *S);\n\n  /// We'd like to check the predicate on every iteration of the most dominated\n  /// loop between loops used in LHS and RHS.\n  /// To do this we use the following list of steps:\n  /// 1. Collect set S all loops on which either LHS or RHS depend.\n  /// 2. If S is non-empty\n  /// a. Let PD be the element of S which is dominated by all other elements.\n  /// b. Let E(LHS) be value of LHS on entry of PD.\n  ///    To get E(LHS), we should just take LHS and replace all AddRecs that are\n  ///    attached to PD on with their entry values.\n  ///    Define E(RHS) in the same way.\n  /// c. Let B(LHS) be value of L on backedge of PD.\n  ///    To get B(LHS), we should just take LHS and replace all AddRecs that are\n  ///    attached to PD on with their backedge values.\n  ///    Define B(RHS) in the same way.\n  /// d. Note that E(LHS) and E(RHS) are automatically available on entry of PD,\n  ///    so we can assert on that.\n  /// e. Return true if isLoopEntryGuardedByCond(Pred, E(LHS), E(RHS)) &&\n  ///                   isLoopBackedgeGuardedByCond(Pred, B(LHS), B(RHS))\n  bool isKnownViaInduction(ICmpInst::Predicate Pred, const SCEV *LHS,\n                           const SCEV *RHS);\n\n  /// Test if the given expression is known to satisfy the condition described\n  /// by Pred, LHS, and RHS.\n  bool isKnownPredicate(ICmpInst::Predicate Pred, const SCEV *LHS,\n                        const SCEV *RHS);\n\n  /// Test if the given expression is known to satisfy the condition described\n  /// by Pred, LHS, and RHS in the given Context.\n  bool isKnownPredicateAt(ICmpInst::Predicate Pred, const SCEV *LHS,\n                        const SCEV *RHS, const Instruction *Context);\n\n  /// Test if the condition described by Pred, LHS, RHS is known to be true on\n  /// every iteration of the loop of the recurrency LHS.\n  bool isKnownOnEveryIteration(ICmpInst::Predicate Pred,\n                               const SCEVAddRecExpr *LHS, const SCEV *RHS);\n\n  /// A predicate is said to be monotonically increasing if may go from being\n  /// false to being true as the loop iterates, but never the other way\n  /// around.  A predicate is said to be monotonically decreasing if may go\n  /// from being true to being false as the loop iterates, but never the other\n  /// way around.\n  enum MonotonicPredicateType {\n    MonotonicallyIncreasing,\n    MonotonicallyDecreasing\n  };\n\n  /// If, for all loop invariant X, the predicate \"LHS `Pred` X\" is\n  /// monotonically increasing or decreasing, returns\n  /// Some(MonotonicallyIncreasing) and Some(MonotonicallyDecreasing)\n  /// respectively. If we could not prove either of these facts, returns None.\n  Optional<MonotonicPredicateType>\n  getMonotonicPredicateType(const SCEVAddRecExpr *LHS,\n                            ICmpInst::Predicate Pred);\n\n  struct LoopInvariantPredicate {\n    ICmpInst::Predicate Pred;\n    const SCEV *LHS;\n    const SCEV *RHS;\n\n    LoopInvariantPredicate(ICmpInst::Predicate Pred, const SCEV *LHS,\n                           const SCEV *RHS)\n        : Pred(Pred), LHS(LHS), RHS(RHS) {}\n  };\n  /// If the result of the predicate LHS `Pred` RHS is loop invariant with\n  /// respect to L, return a LoopInvariantPredicate with LHS and RHS being\n  /// invariants, available at L's entry. Otherwise, return None.\n  Optional<LoopInvariantPredicate>\n  getLoopInvariantPredicate(ICmpInst::Predicate Pred, const SCEV *LHS,\n                            const SCEV *RHS, const Loop *L);\n\n  /// If the result of the predicate LHS `Pred` RHS is loop invariant with\n  /// respect to L at given Context during at least first MaxIter iterations,\n  /// return a LoopInvariantPredicate with LHS and RHS being invariants,\n  /// available at L's entry. Otherwise, return None. The predicate should be\n  /// the loop's exit condition.\n  Optional<LoopInvariantPredicate>\n  getLoopInvariantExitCondDuringFirstIterations(ICmpInst::Predicate Pred,\n                                                const SCEV *LHS,\n                                                const SCEV *RHS, const Loop *L,\n                                                const Instruction *Context,\n                                                const SCEV *MaxIter);\n\n  /// Simplify LHS and RHS in a comparison with predicate Pred. Return true\n  /// iff any changes were made. If the operands are provably equal or\n  /// unequal, LHS and RHS are set to the same value and Pred is set to either\n  /// ICMP_EQ or ICMP_NE.\n  bool SimplifyICmpOperands(ICmpInst::Predicate &Pred, const SCEV *&LHS,\n                            const SCEV *&RHS, unsigned Depth = 0);\n\n  /// Return the \"disposition\" of the given SCEV with respect to the given\n  /// loop.\n  LoopDisposition getLoopDisposition(const SCEV *S, const Loop *L);\n\n  /// Return true if the value of the given SCEV is unchanging in the\n  /// specified loop.\n  bool isLoopInvariant(const SCEV *S, const Loop *L);\n\n  /// Determine if the SCEV can be evaluated at loop's entry. It is true if it\n  /// doesn't depend on a SCEVUnknown of an instruction which is dominated by\n  /// the header of loop L.\n  bool isAvailableAtLoopEntry(const SCEV *S, const Loop *L);\n\n  /// Return true if the given SCEV changes value in a known way in the\n  /// specified loop.  This property being true implies that the value is\n  /// variant in the loop AND that we can emit an expression to compute the\n  /// value of the expression at any particular loop iteration.\n  bool hasComputableLoopEvolution(const SCEV *S, const Loop *L);\n\n  /// Return the \"disposition\" of the given SCEV with respect to the given\n  /// block.\n  BlockDisposition getBlockDisposition(const SCEV *S, const BasicBlock *BB);\n\n  /// Return true if elements that makes up the given SCEV dominate the\n  /// specified basic block.\n  bool dominates(const SCEV *S, const BasicBlock *BB);\n\n  /// Return true if elements that makes up the given SCEV properly dominate\n  /// the specified basic block.\n  bool properlyDominates(const SCEV *S, const BasicBlock *BB);\n\n  /// Test whether the given SCEV has Op as a direct or indirect operand.\n  bool hasOperand(const SCEV *S, const SCEV *Op) const;\n\n  /// Return the size of an element read or written by Inst.\n  const SCEV *getElementSize(Instruction *Inst);\n\n  /// Compute the array dimensions Sizes from the set of Terms extracted from\n  /// the memory access function of this SCEVAddRecExpr (second step of\n  /// delinearization).\n  void findArrayDimensions(SmallVectorImpl<const SCEV *> &Terms,\n                           SmallVectorImpl<const SCEV *> &Sizes,\n                           const SCEV *ElementSize);\n\n  void print(raw_ostream &OS) const;\n  void verify() const;\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &Inv);\n\n  /// Collect parametric terms occurring in step expressions (first step of\n  /// delinearization).\n  void collectParametricTerms(const SCEV *Expr,\n                              SmallVectorImpl<const SCEV *> &Terms);\n\n  /// Return in Subscripts the access functions for each dimension in Sizes\n  /// (third step of delinearization).\n  void computeAccessFunctions(const SCEV *Expr,\n                              SmallVectorImpl<const SCEV *> &Subscripts,\n                              SmallVectorImpl<const SCEV *> &Sizes);\n\n  /// Gathers the individual index expressions from a GEP instruction.\n  ///\n  /// This function optimistically assumes the GEP references into a fixed size\n  /// array. If this is actually true, this function returns a list of array\n  /// subscript expressions in \\p Subscripts and a list of integers describing\n  /// the size of the individual array dimensions in \\p Sizes. Both lists have\n  /// either equal length or the size list is one element shorter in case there\n  /// is no known size available for the outermost array dimension. Returns true\n  /// if successful and false otherwise.\n  bool getIndexExpressionsFromGEP(const GetElementPtrInst *GEP,\n                                  SmallVectorImpl<const SCEV *> &Subscripts,\n                                  SmallVectorImpl<int> &Sizes);\n\n  /// Split this SCEVAddRecExpr into two vectors of SCEVs representing the\n  /// subscripts and sizes of an array access.\n  ///\n  /// The delinearization is a 3 step process: the first two steps compute the\n  /// sizes of each subscript and the third step computes the access functions\n  /// for the delinearized array:\n  ///\n  /// 1. Find the terms in the step functions\n  /// 2. Compute the array size\n  /// 3. Compute the access function: divide the SCEV by the array size\n  ///    starting with the innermost dimensions found in step 2. The Quotient\n  ///    is the SCEV to be divided in the next step of the recursion. The\n  ///    Remainder is the subscript of the innermost dimension. Loop over all\n  ///    array dimensions computed in step 2.\n  ///\n  /// To compute a uniform array size for several memory accesses to the same\n  /// object, one can collect in step 1 all the step terms for all the memory\n  /// accesses, and compute in step 2 a unique array shape. This guarantees\n  /// that the array shape will be the same across all memory accesses.\n  ///\n  /// FIXME: We could derive the result of steps 1 and 2 from a description of\n  /// the array shape given in metadata.\n  ///\n  /// Example:\n  ///\n  /// A[][n][m]\n  ///\n  /// for i\n  ///   for j\n  ///     for k\n  ///       A[j+k][2i][5i] =\n  ///\n  /// The initial SCEV:\n  ///\n  /// A[{{{0,+,2*m+5}_i, +, n*m}_j, +, n*m}_k]\n  ///\n  /// 1. Find the different terms in the step functions:\n  /// -> [2*m, 5, n*m, n*m]\n  ///\n  /// 2. Compute the array size: sort and unique them\n  /// -> [n*m, 2*m, 5]\n  /// find the GCD of all the terms = 1\n  /// divide by the GCD and erase constant terms\n  /// -> [n*m, 2*m]\n  /// GCD = m\n  /// divide by GCD -> [n, 2]\n  /// remove constant terms\n  /// -> [n]\n  /// size of the array is A[unknown][n][m]\n  ///\n  /// 3. Compute the access function\n  /// a. Divide {{{0,+,2*m+5}_i, +, n*m}_j, +, n*m}_k by the innermost size m\n  /// Quotient: {{{0,+,2}_i, +, n}_j, +, n}_k\n  /// Remainder: {{{0,+,5}_i, +, 0}_j, +, 0}_k\n  /// The remainder is the subscript of the innermost array dimension: [5i].\n  ///\n  /// b. Divide Quotient: {{{0,+,2}_i, +, n}_j, +, n}_k by next outer size n\n  /// Quotient: {{{0,+,0}_i, +, 1}_j, +, 1}_k\n  /// Remainder: {{{0,+,2}_i, +, 0}_j, +, 0}_k\n  /// The Remainder is the subscript of the next array dimension: [2i].\n  ///\n  /// The subscript of the outermost dimension is the Quotient: [j+k].\n  ///\n  /// Overall, we have: A[][n][m], and the access function: A[j+k][2i][5i].\n  void delinearize(const SCEV *Expr, SmallVectorImpl<const SCEV *> &Subscripts,\n                   SmallVectorImpl<const SCEV *> &Sizes,\n                   const SCEV *ElementSize);\n\n  /// Return the DataLayout associated with the module this SCEV instance is\n  /// operating on.\n  const DataLayout &getDataLayout() const {\n    return F.getParent()->getDataLayout();\n  }\n\n  const SCEVPredicate *getEqualPredicate(const SCEV *LHS, const SCEV *RHS);\n\n  const SCEVPredicate *\n  getWrapPredicate(const SCEVAddRecExpr *AR,\n                   SCEVWrapPredicate::IncrementWrapFlags AddedFlags);\n\n  /// Re-writes the SCEV according to the Predicates in \\p A.\n  const SCEV *rewriteUsingPredicate(const SCEV *S, const Loop *L,\n                                    SCEVUnionPredicate &A);\n  /// Tries to convert the \\p S expression to an AddRec expression,\n  /// adding additional predicates to \\p Preds as required.\n  const SCEVAddRecExpr *convertSCEVToAddRecWithPredicates(\n      const SCEV *S, const Loop *L,\n      SmallPtrSetImpl<const SCEVPredicate *> &Preds);\n\n  /// Compute \\p LHS - \\p RHS and returns the result as an APInt if it is a\n  /// constant, and None if it isn't.\n  ///\n  /// This is intended to be a cheaper version of getMinusSCEV.  We can be\n  /// frugal here since we just bail out of actually constructing and\n  /// canonicalizing an expression in the cases where the result isn't going\n  /// to be a constant.\n  Optional<APInt> computeConstantDifference(const SCEV *LHS, const SCEV *RHS);\n\n  /// Update no-wrap flags of an AddRec. This may drop the cached info about\n  /// this AddRec (such as range info) in case if new flags may potentially\n  /// sharpen it.\n  void setNoWrapFlags(SCEVAddRecExpr *AddRec, SCEV::NoWrapFlags Flags);\n\n  /// Try to apply information from loop guards for \\p L to \\p Expr.\n  const SCEV *applyLoopGuards(const SCEV *Expr, const Loop *L);\n\nprivate:\n  /// A CallbackVH to arrange for ScalarEvolution to be notified whenever a\n  /// Value is deleted.\n  class SCEVCallbackVH final : public CallbackVH {\n    ScalarEvolution *SE;\n\n    void deleted() override;\n    void allUsesReplacedWith(Value *New) override;\n\n  public:\n    SCEVCallbackVH(Value *V, ScalarEvolution *SE = nullptr);\n  };\n\n  friend class SCEVCallbackVH;\n  friend class SCEVExpander;\n  friend class SCEVUnknown;\n\n  /// The function we are analyzing.\n  Function &F;\n\n  /// Does the module have any calls to the llvm.experimental.guard intrinsic\n  /// at all?  If this is false, we avoid doing work that will only help if\n  /// thare are guards present in the IR.\n  bool HasGuards;\n\n  /// The target library information for the target we are targeting.\n  TargetLibraryInfo &TLI;\n\n  /// The tracker for \\@llvm.assume intrinsics in this function.\n  AssumptionCache &AC;\n\n  /// The dominator tree.\n  DominatorTree &DT;\n\n  /// The loop information for the function we are currently analyzing.\n  LoopInfo &LI;\n\n  /// This SCEV is used to represent unknown trip counts and things.\n  std::unique_ptr<SCEVCouldNotCompute> CouldNotCompute;\n\n  /// The type for HasRecMap.\n  using HasRecMapType = DenseMap<const SCEV *, bool>;\n\n  /// This is a cache to record whether a SCEV contains any scAddRecExpr.\n  HasRecMapType HasRecMap;\n\n  /// The type for ExprValueMap.\n  using ValueOffsetPair = std::pair<Value *, ConstantInt *>;\n  using ExprValueMapType = DenseMap<const SCEV *, SetVector<ValueOffsetPair>>;\n\n  /// ExprValueMap -- This map records the original values from which\n  /// the SCEV expr is generated from.\n  ///\n  /// We want to represent the mapping as SCEV -> ValueOffsetPair instead\n  /// of SCEV -> Value:\n  /// Suppose we know S1 expands to V1, and\n  ///  S1 = S2 + C_a\n  ///  S3 = S2 + C_b\n  /// where C_a and C_b are different SCEVConstants. Then we'd like to\n  /// expand S3 as V1 - C_a + C_b instead of expanding S2 literally.\n  /// It is helpful when S2 is a complex SCEV expr.\n  ///\n  /// In order to do that, we represent ExprValueMap as a mapping from\n  /// SCEV to ValueOffsetPair. We will save both S1->{V1, 0} and\n  /// S2->{V1, C_a} into the map when we create SCEV for V1. When S3\n  /// is expanded, it will first expand S2 to V1 - C_a because of\n  /// S2->{V1, C_a} in the map, then expand S3 to V1 - C_a + C_b.\n  ///\n  /// Note: S->{V, Offset} in the ExprValueMap means S can be expanded\n  /// to V - Offset.\n  ExprValueMapType ExprValueMap;\n\n  /// The type for ValueExprMap.\n  using ValueExprMapType =\n      DenseMap<SCEVCallbackVH, const SCEV *, DenseMapInfo<Value *>>;\n\n  /// This is a cache of the values we have analyzed so far.\n  ValueExprMapType ValueExprMap;\n\n  /// Mark predicate values currently being processed by isImpliedCond.\n  SmallPtrSet<const Value *, 6> PendingLoopPredicates;\n\n  /// Mark SCEVUnknown Phis currently being processed by getRangeRef.\n  SmallPtrSet<const PHINode *, 6> PendingPhiRanges;\n\n  // Mark SCEVUnknown Phis currently being processed by isImpliedViaMerge.\n  SmallPtrSet<const PHINode *, 6> PendingMerges;\n\n  /// Set to true by isLoopBackedgeGuardedByCond when we're walking the set of\n  /// conditions dominating the backedge of a loop.\n  bool WalkingBEDominatingConds = false;\n\n  /// Set to true by isKnownPredicateViaSplitting when we're trying to prove a\n  /// predicate by splitting it into a set of independent predicates.\n  bool ProvingSplitPredicate = false;\n\n  /// Memoized values for the GetMinTrailingZeros\n  DenseMap<const SCEV *, uint32_t> MinTrailingZerosCache;\n\n  /// Return the Value set from which the SCEV expr is generated.\n  SetVector<ValueOffsetPair> *getSCEVValues(const SCEV *S);\n\n  /// Private helper method for the GetMinTrailingZeros method\n  uint32_t GetMinTrailingZerosImpl(const SCEV *S);\n\n  /// Information about the number of loop iterations for which a loop exit's\n  /// branch condition evaluates to the not-taken path.  This is a temporary\n  /// pair of exact and max expressions that are eventually summarized in\n  /// ExitNotTakenInfo and BackedgeTakenInfo.\n  struct ExitLimit {\n    const SCEV *ExactNotTaken; // The exit is not taken exactly this many times\n    const SCEV *MaxNotTaken; // The exit is not taken at most this many times\n\n    // Not taken either exactly MaxNotTaken or zero times\n    bool MaxOrZero = false;\n\n    /// A set of predicate guards for this ExitLimit. The result is only valid\n    /// if all of the predicates in \\c Predicates evaluate to 'true' at\n    /// run-time.\n    SmallPtrSet<const SCEVPredicate *, 4> Predicates;\n\n    void addPredicate(const SCEVPredicate *P) {\n      assert(!isa<SCEVUnionPredicate>(P) && \"Only add leaf predicates here!\");\n      Predicates.insert(P);\n    }\n\n    /// Construct either an exact exit limit from a constant, or an unknown\n    /// one from a SCEVCouldNotCompute.  No other types of SCEVs are allowed\n    /// as arguments and asserts enforce that internally.\n    /*implicit*/ ExitLimit(const SCEV *E);\n\n    ExitLimit(\n        const SCEV *E, const SCEV *M, bool MaxOrZero,\n        ArrayRef<const SmallPtrSetImpl<const SCEVPredicate *> *> PredSetList);\n\n    ExitLimit(const SCEV *E, const SCEV *M, bool MaxOrZero,\n              const SmallPtrSetImpl<const SCEVPredicate *> &PredSet);\n\n    ExitLimit(const SCEV *E, const SCEV *M, bool MaxOrZero);\n\n    /// Test whether this ExitLimit contains any computed information, or\n    /// whether it's all SCEVCouldNotCompute values.\n    bool hasAnyInfo() const {\n      return !isa<SCEVCouldNotCompute>(ExactNotTaken) ||\n             !isa<SCEVCouldNotCompute>(MaxNotTaken);\n    }\n\n    bool hasOperand(const SCEV *S) const;\n\n    /// Test whether this ExitLimit contains all information.\n    bool hasFullInfo() const {\n      return !isa<SCEVCouldNotCompute>(ExactNotTaken);\n    }\n  };\n\n  /// Information about the number of times a particular loop exit may be\n  /// reached before exiting the loop.\n  struct ExitNotTakenInfo {\n    PoisoningVH<BasicBlock> ExitingBlock;\n    const SCEV *ExactNotTaken;\n    const SCEV *MaxNotTaken;\n    std::unique_ptr<SCEVUnionPredicate> Predicate;\n\n    explicit ExitNotTakenInfo(PoisoningVH<BasicBlock> ExitingBlock,\n                              const SCEV *ExactNotTaken,\n                              const SCEV *MaxNotTaken,\n                              std::unique_ptr<SCEVUnionPredicate> Predicate)\n      : ExitingBlock(ExitingBlock), ExactNotTaken(ExactNotTaken),\n        MaxNotTaken(ExactNotTaken), Predicate(std::move(Predicate)) {}\n\n    bool hasAlwaysTruePredicate() const {\n      return !Predicate || Predicate->isAlwaysTrue();\n    }\n  };\n\n  /// Information about the backedge-taken count of a loop. This currently\n  /// includes an exact count and a maximum count.\n  ///\n  class BackedgeTakenInfo {\n    /// A list of computable exits and their not-taken counts.  Loops almost\n    /// never have more than one computable exit.\n    SmallVector<ExitNotTakenInfo, 1> ExitNotTaken;\n\n    /// Expression indicating the least constant maximum backedge-taken count of\n    /// the loop that is known, or a SCEVCouldNotCompute. This expression is\n    /// only valid if the redicates associated with all loop exits are true.\n    const SCEV *ConstantMax;\n\n    /// Indicating if \\c ExitNotTaken has an element for every exiting block in\n    /// the loop.\n    bool IsComplete;\n\n    /// Expression indicating the least maximum backedge-taken count of the loop\n    /// that is known, or a SCEVCouldNotCompute. Lazily computed on first query.\n    const SCEV *SymbolicMax = nullptr;\n\n    /// True iff the backedge is taken either exactly Max or zero times.\n    bool MaxOrZero = false;\n\n    bool isComplete() const { return IsComplete; }\n    const SCEV *getConstantMax() const { return ConstantMax; }\n\n  public:\n    BackedgeTakenInfo() : ConstantMax(nullptr), IsComplete(false) {}\n    BackedgeTakenInfo(BackedgeTakenInfo &&) = default;\n    BackedgeTakenInfo &operator=(BackedgeTakenInfo &&) = default;\n\n    using EdgeExitInfo = std::pair<BasicBlock *, ExitLimit>;\n\n    /// Initialize BackedgeTakenInfo from a list of exact exit counts.\n    BackedgeTakenInfo(ArrayRef<EdgeExitInfo> ExitCounts, bool IsComplete,\n                      const SCEV *ConstantMax, bool MaxOrZero);\n\n    /// Test whether this BackedgeTakenInfo contains any computed information,\n    /// or whether it's all SCEVCouldNotCompute values.\n    bool hasAnyInfo() const {\n      return !ExitNotTaken.empty() ||\n             !isa<SCEVCouldNotCompute>(getConstantMax());\n    }\n\n    /// Test whether this BackedgeTakenInfo contains complete information.\n    bool hasFullInfo() const { return isComplete(); }\n\n    /// Return an expression indicating the exact *backedge-taken*\n    /// count of the loop if it is known or SCEVCouldNotCompute\n    /// otherwise.  If execution makes it to the backedge on every\n    /// iteration (i.e. there are no abnormal exists like exception\n    /// throws and thread exits) then this is the number of times the\n    /// loop header will execute minus one.\n    ///\n    /// If the SCEV predicate associated with the answer can be different\n    /// from AlwaysTrue, we must add a (non null) Predicates argument.\n    /// The SCEV predicate associated with the answer will be added to\n    /// Predicates. A run-time check needs to be emitted for the SCEV\n    /// predicate in order for the answer to be valid.\n    ///\n    /// Note that we should always know if we need to pass a predicate\n    /// argument or not from the way the ExitCounts vector was computed.\n    /// If we allowed SCEV predicates to be generated when populating this\n    /// vector, this information can contain them and therefore a\n    /// SCEVPredicate argument should be added to getExact.\n    const SCEV *getExact(const Loop *L, ScalarEvolution *SE,\n                         SCEVUnionPredicate *Predicates = nullptr) const;\n\n    /// Return the number of times this loop exit may fall through to the back\n    /// edge, or SCEVCouldNotCompute. The loop is guaranteed not to exit via\n    /// this block before this number of iterations, but may exit via another\n    /// block.\n    const SCEV *getExact(const BasicBlock *ExitingBlock,\n                         ScalarEvolution *SE) const;\n\n    /// Get the constant max backedge taken count for the loop.\n    const SCEV *getConstantMax(ScalarEvolution *SE) const;\n\n    /// Get the constant max backedge taken count for the particular loop exit.\n    const SCEV *getConstantMax(const BasicBlock *ExitingBlock,\n                               ScalarEvolution *SE) const;\n\n    /// Get the symbolic max backedge taken count for the loop.\n    const SCEV *getSymbolicMax(const Loop *L, ScalarEvolution *SE);\n\n    /// Return true if the number of times this backedge is taken is either the\n    /// value returned by getConstantMax or zero.\n    bool isConstantMaxOrZero(ScalarEvolution *SE) const;\n\n    /// Return true if any backedge taken count expressions refer to the given\n    /// subexpression.\n    bool hasOperand(const SCEV *S, ScalarEvolution *SE) const;\n\n    /// Invalidate this result and free associated memory.\n    void clear();\n  };\n\n  /// Cache the backedge-taken count of the loops for this function as they\n  /// are computed.\n  DenseMap<const Loop *, BackedgeTakenInfo> BackedgeTakenCounts;\n\n  /// Cache the predicated backedge-taken count of the loops for this\n  /// function as they are computed.\n  DenseMap<const Loop *, BackedgeTakenInfo> PredicatedBackedgeTakenCounts;\n\n  /// This map contains entries for all of the PHI instructions that we\n  /// attempt to compute constant evolutions for.  This allows us to avoid\n  /// potentially expensive recomputation of these properties.  An instruction\n  /// maps to null if we are unable to compute its exit value.\n  DenseMap<PHINode *, Constant *> ConstantEvolutionLoopExitValue;\n\n  /// This map contains entries for all the expressions that we attempt to\n  /// compute getSCEVAtScope information for, which can be expensive in\n  /// extreme cases.\n  DenseMap<const SCEV *, SmallVector<std::pair<const Loop *, const SCEV *>, 2>>\n      ValuesAtScopes;\n\n  /// Memoized computeLoopDisposition results.\n  DenseMap<const SCEV *,\n           SmallVector<PointerIntPair<const Loop *, 2, LoopDisposition>, 2>>\n      LoopDispositions;\n\n  struct LoopProperties {\n    /// Set to true if the loop contains no instruction that can have side\n    /// effects (i.e. via throwing an exception, volatile or atomic access).\n    bool HasNoAbnormalExits;\n\n    /// Set to true if the loop contains no instruction that can abnormally exit\n    /// the loop (i.e. via throwing an exception, by terminating the thread\n    /// cleanly or by infinite looping in a called function).  Strictly\n    /// speaking, the last one is not leaving the loop, but is identical to\n    /// leaving the loop for reasoning about undefined behavior.\n    bool HasNoSideEffects;\n  };\n\n  /// Cache for \\c getLoopProperties.\n  DenseMap<const Loop *, LoopProperties> LoopPropertiesCache;\n\n  /// Return a \\c LoopProperties instance for \\p L, creating one if necessary.\n  LoopProperties getLoopProperties(const Loop *L);\n\n  bool loopHasNoSideEffects(const Loop *L) {\n    return getLoopProperties(L).HasNoSideEffects;\n  }\n\n  bool loopHasNoAbnormalExits(const Loop *L) {\n    return getLoopProperties(L).HasNoAbnormalExits;\n  }\n\n  /// Compute a LoopDisposition value.\n  LoopDisposition computeLoopDisposition(const SCEV *S, const Loop *L);\n\n  /// Memoized computeBlockDisposition results.\n  DenseMap<\n      const SCEV *,\n      SmallVector<PointerIntPair<const BasicBlock *, 2, BlockDisposition>, 2>>\n      BlockDispositions;\n\n  /// Compute a BlockDisposition value.\n  BlockDisposition computeBlockDisposition(const SCEV *S, const BasicBlock *BB);\n\n  /// Memoized results from getRange\n  DenseMap<const SCEV *, ConstantRange> UnsignedRanges;\n\n  /// Memoized results from getRange\n  DenseMap<const SCEV *, ConstantRange> SignedRanges;\n\n  /// Used to parameterize getRange\n  enum RangeSignHint { HINT_RANGE_UNSIGNED, HINT_RANGE_SIGNED };\n\n  /// Set the memoized range for the given SCEV.\n  const ConstantRange &setRange(const SCEV *S, RangeSignHint Hint,\n                                ConstantRange CR) {\n    DenseMap<const SCEV *, ConstantRange> &Cache =\n        Hint == HINT_RANGE_UNSIGNED ? UnsignedRanges : SignedRanges;\n\n    auto Pair = Cache.try_emplace(S, std::move(CR));\n    if (!Pair.second)\n      Pair.first->second = std::move(CR);\n    return Pair.first->second;\n  }\n\n  /// Determine the range for a particular SCEV.\n  /// NOTE: This returns a reference to an entry in a cache. It must be\n  /// copied if its needed for longer.\n  const ConstantRange &getRangeRef(const SCEV *S, RangeSignHint Hint);\n\n  /// Determines the range for the affine SCEVAddRecExpr {\\p Start,+,\\p Stop}.\n  /// Helper for \\c getRange.\n  ConstantRange getRangeForAffineAR(const SCEV *Start, const SCEV *Stop,\n                                    const SCEV *MaxBECount, unsigned BitWidth);\n\n  /// Determines the range for the affine non-self-wrapping SCEVAddRecExpr {\\p\n  /// Start,+,\\p Stop}<nw>.\n  ConstantRange getRangeForAffineNoSelfWrappingAR(const SCEVAddRecExpr *AddRec,\n                                                  const SCEV *MaxBECount,\n                                                  unsigned BitWidth,\n                                                  RangeSignHint SignHint);\n\n  /// Try to compute a range for the affine SCEVAddRecExpr {\\p Start,+,\\p\n  /// Stop} by \"factoring out\" a ternary expression from the add recurrence.\n  /// Helper called by \\c getRange.\n  ConstantRange getRangeViaFactoring(const SCEV *Start, const SCEV *Stop,\n                                     const SCEV *MaxBECount, unsigned BitWidth);\n\n  /// We know that there is no SCEV for the specified value.  Analyze the\n  /// expression.\n  const SCEV *createSCEV(Value *V);\n\n  /// Provide the special handling we need to analyze PHI SCEVs.\n  const SCEV *createNodeForPHI(PHINode *PN);\n\n  /// Helper function called from createNodeForPHI.\n  const SCEV *createAddRecFromPHI(PHINode *PN);\n\n  /// A helper function for createAddRecFromPHI to handle simple cases.\n  const SCEV *createSimpleAffineAddRec(PHINode *PN, Value *BEValueV,\n                                            Value *StartValueV);\n\n  /// Helper function called from createNodeForPHI.\n  const SCEV *createNodeFromSelectLikePHI(PHINode *PN);\n\n  /// Provide special handling for a select-like instruction (currently this\n  /// is either a select instruction or a phi node).  \\p I is the instruction\n  /// being processed, and it is assumed equivalent to \"Cond ? TrueVal :\n  /// FalseVal\".\n  const SCEV *createNodeForSelectOrPHI(Instruction *I, Value *Cond,\n                                       Value *TrueVal, Value *FalseVal);\n\n  /// Provide the special handling we need to analyze GEP SCEVs.\n  const SCEV *createNodeForGEP(GEPOperator *GEP);\n\n  /// Implementation code for getSCEVAtScope; called at most once for each\n  /// SCEV+Loop pair.\n  const SCEV *computeSCEVAtScope(const SCEV *S, const Loop *L);\n\n  /// This looks up computed SCEV values for all instructions that depend on\n  /// the given instruction and removes them from the ValueExprMap map if they\n  /// reference SymName. This is used during PHI resolution.\n  void forgetSymbolicName(Instruction *I, const SCEV *SymName);\n\n  /// Return the BackedgeTakenInfo for the given loop, lazily computing new\n  /// values if the loop hasn't been analyzed yet. The returned result is\n  /// guaranteed not to be predicated.\n  BackedgeTakenInfo &getBackedgeTakenInfo(const Loop *L);\n\n  /// Similar to getBackedgeTakenInfo, but will add predicates as required\n  /// with the purpose of returning complete information.\n  const BackedgeTakenInfo &getPredicatedBackedgeTakenInfo(const Loop *L);\n\n  /// Compute the number of times the specified loop will iterate.\n  /// If AllowPredicates is set, we will create new SCEV predicates as\n  /// necessary in order to return an exact answer.\n  BackedgeTakenInfo computeBackedgeTakenCount(const Loop *L,\n                                              bool AllowPredicates = false);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if it exits via the specified block. If AllowPredicates is set,\n  /// this call will try to use a minimal set of SCEV predicates in order to\n  /// return an exact answer.\n  ExitLimit computeExitLimit(const Loop *L, BasicBlock *ExitingBlock,\n                             bool AllowPredicates = false);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if its exit condition were a conditional branch of ExitCond.\n  ///\n  /// \\p ControlsExit is true if ExitCond directly controls the exit\n  /// branch. In this case, we can assume that the loop exits only if the\n  /// condition is true and can infer that failing to meet the condition prior\n  /// to integer wraparound results in undefined behavior.\n  ///\n  /// If \\p AllowPredicates is set, this call will try to use a minimal set of\n  /// SCEV predicates in order to return an exact answer.\n  ExitLimit computeExitLimitFromCond(const Loop *L, Value *ExitCond,\n                                     bool ExitIfTrue, bool ControlsExit,\n                                     bool AllowPredicates = false);\n\n  /// Return a symbolic upper bound for the backedge taken count of the loop.\n  /// This is more general than getConstantMaxBackedgeTakenCount as it returns\n  /// an arbitrary expression as opposed to only constants.\n  const SCEV *computeSymbolicMaxBackedgeTakenCount(const Loop *L);\n\n  // Helper functions for computeExitLimitFromCond to avoid exponential time\n  // complexity.\n\n  class ExitLimitCache {\n    // It may look like we need key on the whole (L, ExitIfTrue, ControlsExit,\n    // AllowPredicates) tuple, but recursive calls to\n    // computeExitLimitFromCondCached from computeExitLimitFromCondImpl only\n    // vary the in \\c ExitCond and \\c ControlsExit parameters.  We remember the\n    // initial values of the other values to assert our assumption.\n    SmallDenseMap<PointerIntPair<Value *, 1>, ExitLimit> TripCountMap;\n\n    const Loop *L;\n    bool ExitIfTrue;\n    bool AllowPredicates;\n\n  public:\n    ExitLimitCache(const Loop *L, bool ExitIfTrue, bool AllowPredicates)\n        : L(L), ExitIfTrue(ExitIfTrue), AllowPredicates(AllowPredicates) {}\n\n    Optional<ExitLimit> find(const Loop *L, Value *ExitCond, bool ExitIfTrue,\n                             bool ControlsExit, bool AllowPredicates);\n\n    void insert(const Loop *L, Value *ExitCond, bool ExitIfTrue,\n                bool ControlsExit, bool AllowPredicates, const ExitLimit &EL);\n  };\n\n  using ExitLimitCacheTy = ExitLimitCache;\n\n  ExitLimit computeExitLimitFromCondCached(ExitLimitCacheTy &Cache,\n                                           const Loop *L, Value *ExitCond,\n                                           bool ExitIfTrue,\n                                           bool ControlsExit,\n                                           bool AllowPredicates);\n  ExitLimit computeExitLimitFromCondImpl(ExitLimitCacheTy &Cache, const Loop *L,\n                                         Value *ExitCond, bool ExitIfTrue,\n                                         bool ControlsExit,\n                                         bool AllowPredicates);\n  Optional<ScalarEvolution::ExitLimit>\n  computeExitLimitFromCondFromBinOp(ExitLimitCacheTy &Cache, const Loop *L,\n                                    Value *ExitCond, bool ExitIfTrue,\n                                    bool ControlsExit, bool AllowPredicates);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if its exit condition were a conditional branch of the ICmpInst\n  /// ExitCond and ExitIfTrue. If AllowPredicates is set, this call will try\n  /// to use a minimal set of SCEV predicates in order to return an exact\n  /// answer.\n  ExitLimit computeExitLimitFromICmp(const Loop *L, ICmpInst *ExitCond,\n                                     bool ExitIfTrue,\n                                     bool IsSubExpr,\n                                     bool AllowPredicates = false);\n\n  /// Compute the number of times the backedge of the specified loop will\n  /// execute if its exit condition were a switch with a single exiting case\n  /// to ExitingBB.\n  ExitLimit computeExitLimitFromSingleExitSwitch(const Loop *L,\n                                                 SwitchInst *Switch,\n                                                 BasicBlock *ExitingBB,\n                                                 bool IsSubExpr);\n\n  /// Given an exit condition of 'icmp op load X, cst', try to see if we can\n  /// compute the backedge-taken count.\n  ExitLimit computeLoadConstantCompareExitLimit(LoadInst *LI, Constant *RHS,\n                                                const Loop *L,\n                                                ICmpInst::Predicate p);\n\n  /// Compute the exit limit of a loop that is controlled by a\n  /// \"(IV >> 1) != 0\" type comparison.  We cannot compute the exact trip\n  /// count in these cases (since SCEV has no way of expressing them), but we\n  /// can still sometimes compute an upper bound.\n  ///\n  /// Return an ExitLimit for a loop whose backedge is guarded by `LHS Pred\n  /// RHS`.\n  ExitLimit computeShiftCompareExitLimit(Value *LHS, Value *RHS, const Loop *L,\n                                         ICmpInst::Predicate Pred);\n\n  /// If the loop is known to execute a constant number of times (the\n  /// condition evolves only from constants), try to evaluate a few iterations\n  /// of the loop until we get the exit condition gets a value of ExitWhen\n  /// (true or false).  If we cannot evaluate the exit count of the loop,\n  /// return CouldNotCompute.\n  const SCEV *computeExitCountExhaustively(const Loop *L, Value *Cond,\n                                           bool ExitWhen);\n\n  /// Return the number of times an exit condition comparing the specified\n  /// value to zero will execute.  If not computable, return CouldNotCompute.\n  /// If AllowPredicates is set, this call will try to use a minimal set of\n  /// SCEV predicates in order to return an exact answer.\n  ExitLimit howFarToZero(const SCEV *V, const Loop *L, bool IsSubExpr,\n                         bool AllowPredicates = false);\n\n  /// Return the number of times an exit condition checking the specified\n  /// value for nonzero will execute.  If not computable, return\n  /// CouldNotCompute.\n  ExitLimit howFarToNonZero(const SCEV *V, const Loop *L);\n\n  /// Return the number of times an exit condition containing the specified\n  /// less-than comparison will execute.  If not computable, return\n  /// CouldNotCompute.\n  ///\n  /// \\p isSigned specifies whether the less-than is signed.\n  ///\n  /// \\p ControlsExit is true when the LHS < RHS condition directly controls\n  /// the branch (loops exits only if condition is true). In this case, we can\n  /// use NoWrapFlags to skip overflow checks.\n  ///\n  /// If \\p AllowPredicates is set, this call will try to use a minimal set of\n  /// SCEV predicates in order to return an exact answer.\n  ExitLimit howManyLessThans(const SCEV *LHS, const SCEV *RHS, const Loop *L,\n                             bool isSigned, bool ControlsExit,\n                             bool AllowPredicates = false);\n\n  ExitLimit howManyGreaterThans(const SCEV *LHS, const SCEV *RHS, const Loop *L,\n                                bool isSigned, bool IsSubExpr,\n                                bool AllowPredicates = false);\n\n  /// Return a predecessor of BB (which may not be an immediate predecessor)\n  /// which has exactly one successor from which BB is reachable, or null if\n  /// no such block is found.\n  std::pair<const BasicBlock *, const BasicBlock *>\n  getPredecessorWithUniqueSuccessorForBB(const BasicBlock *BB) const;\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the given FoundCondValue value evaluates to true in given\n  /// Context. If Context is nullptr, then the found predicate is true\n  /// everywhere. LHS and FoundLHS may have different type width.\n  bool isImpliedCond(ICmpInst::Predicate Pred, const SCEV *LHS, const SCEV *RHS,\n                     const Value *FoundCondValue, bool Inverse,\n                     const Instruction *Context = nullptr);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the given FoundCondValue value evaluates to true in given\n  /// Context. If Context is nullptr, then the found predicate is true\n  /// everywhere. LHS and FoundLHS must have same type width.\n  bool isImpliedCondBalancedTypes(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                  const SCEV *RHS,\n                                  ICmpInst::Predicate FoundPred,\n                                  const SCEV *FoundLHS, const SCEV *FoundRHS,\n                                  const Instruction *Context);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by FoundPred, FoundLHS, FoundRHS is\n  /// true in given Context. If Context is nullptr, then the found predicate is\n  /// true everywhere.\n  bool isImpliedCond(ICmpInst::Predicate Pred, const SCEV *LHS, const SCEV *RHS,\n                     ICmpInst::Predicate FoundPred, const SCEV *FoundLHS,\n                     const SCEV *FoundRHS,\n                     const Instruction *Context = nullptr);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true in given Context. If Context is nullptr, then the found predicate is\n  /// true everywhere.\n  bool isImpliedCondOperands(ICmpInst::Predicate Pred, const SCEV *LHS,\n                             const SCEV *RHS, const SCEV *FoundLHS,\n                             const SCEV *FoundRHS,\n                             const Instruction *Context = nullptr);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true. Here LHS is an operation that includes FoundLHS as one of its\n  /// arguments.\n  bool isImpliedViaOperations(ICmpInst::Predicate Pred,\n                              const SCEV *LHS, const SCEV *RHS,\n                              const SCEV *FoundLHS, const SCEV *FoundRHS,\n                              unsigned Depth = 0);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true.\n  /// Use only simple non-recursive types of checks, such as range analysis etc.\n  bool isKnownViaNonRecursiveReasoning(ICmpInst::Predicate Pred,\n                                       const SCEV *LHS, const SCEV *RHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  bool isImpliedCondOperandsHelper(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                   const SCEV *RHS, const SCEV *FoundLHS,\n                                   const SCEV *FoundRHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.  Utility function used by isImpliedCondOperands.  Tries to get\n  /// cases like \"X `sgt` 0 => X - 1 `sgt` -1\".\n  bool isImpliedCondOperandsViaRanges(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                      const SCEV *RHS, const SCEV *FoundLHS,\n                                      const SCEV *FoundRHS);\n\n  /// Return true if the condition denoted by \\p LHS \\p Pred \\p RHS is implied\n  /// by a call to @llvm.experimental.guard in \\p BB.\n  bool isImpliedViaGuard(const BasicBlock *BB, ICmpInst::Predicate Pred,\n                         const SCEV *LHS, const SCEV *RHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  ///\n  /// This routine tries to rule out certain kinds of integer overflow, and\n  /// then tries to reason about arithmetic properties of the predicates.\n  bool isImpliedCondOperandsViaNoOverflow(ICmpInst::Predicate Pred,\n                                          const SCEV *LHS, const SCEV *RHS,\n                                          const SCEV *FoundLHS,\n                                          const SCEV *FoundRHS);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  ///\n  /// This routine tries to weaken the known condition basing on fact that\n  /// FoundLHS is an AddRec.\n  bool isImpliedCondOperandsViaAddRecStart(ICmpInst::Predicate Pred,\n                                           const SCEV *LHS, const SCEV *RHS,\n                                           const SCEV *FoundLHS,\n                                           const SCEV *FoundRHS,\n                                           const Instruction *Context);\n\n  /// Test whether the condition described by Pred, LHS, and RHS is true\n  /// whenever the condition described by Pred, FoundLHS, and FoundRHS is\n  /// true.\n  ///\n  /// This routine tries to figure out predicate for Phis which are SCEVUnknown\n  /// if it is true for every possible incoming value from their respective\n  /// basic blocks.\n  bool isImpliedViaMerge(ICmpInst::Predicate Pred,\n                         const SCEV *LHS, const SCEV *RHS,\n                         const SCEV *FoundLHS, const SCEV *FoundRHS,\n                         unsigned Depth);\n\n  /// If we know that the specified Phi is in the header of its containing\n  /// loop, we know the loop executes a constant number of times, and the PHI\n  /// node is just a recurrence involving constants, fold it.\n  Constant *getConstantEvolutionLoopExitValue(PHINode *PN, const APInt &BEs,\n                                              const Loop *L);\n\n  /// Test if the given expression is known to satisfy the condition described\n  /// by Pred and the known constant ranges of LHS and RHS.\n  bool isKnownPredicateViaConstantRanges(ICmpInst::Predicate Pred,\n                                         const SCEV *LHS, const SCEV *RHS);\n\n  /// Try to prove the condition described by \"LHS Pred RHS\" by ruling out\n  /// integer overflow.\n  ///\n  /// For instance, this will return true for \"A s< (A + C)<nsw>\" if C is\n  /// positive.\n  bool isKnownPredicateViaNoOverflow(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                     const SCEV *RHS);\n\n  /// Try to split Pred LHS RHS into logical conjunctions (and's) and try to\n  /// prove them individually.\n  bool isKnownPredicateViaSplitting(ICmpInst::Predicate Pred, const SCEV *LHS,\n                                    const SCEV *RHS);\n\n  /// Try to match the Expr as \"(L + R)<Flags>\".\n  bool splitBinaryAdd(const SCEV *Expr, const SCEV *&L, const SCEV *&R,\n                      SCEV::NoWrapFlags &Flags);\n\n  /// Drop memoized information computed for S.\n  void forgetMemoizedResults(const SCEV *S);\n\n  /// Return an existing SCEV for V if there is one, otherwise return nullptr.\n  const SCEV *getExistingSCEV(Value *V);\n\n  /// Return false iff given SCEV contains a SCEVUnknown with NULL value-\n  /// pointer.\n  bool checkValidity(const SCEV *S) const;\n\n  /// Return true if `ExtendOpTy`({`Start`,+,`Step`}) can be proved to be\n  /// equal to {`ExtendOpTy`(`Start`),+,`ExtendOpTy`(`Step`)}.  This is\n  /// equivalent to proving no signed (resp. unsigned) wrap in\n  /// {`Start`,+,`Step`} if `ExtendOpTy` is `SCEVSignExtendExpr`\n  /// (resp. `SCEVZeroExtendExpr`).\n  template <typename ExtendOpTy>\n  bool proveNoWrapByVaryingStart(const SCEV *Start, const SCEV *Step,\n                                 const Loop *L);\n\n  /// Try to prove NSW or NUW on \\p AR relying on ConstantRange manipulation.\n  SCEV::NoWrapFlags proveNoWrapViaConstantRanges(const SCEVAddRecExpr *AR);\n\n  /// Try to prove NSW on \\p AR by proving facts about conditions known  on\n  /// entry and backedge.\n  SCEV::NoWrapFlags proveNoSignedWrapViaInduction(const SCEVAddRecExpr *AR);\n\n  /// Try to prove NUW on \\p AR by proving facts about conditions known on\n  /// entry and backedge.\n  SCEV::NoWrapFlags proveNoUnsignedWrapViaInduction(const SCEVAddRecExpr *AR);\n\n  Optional<MonotonicPredicateType>\n  getMonotonicPredicateTypeImpl(const SCEVAddRecExpr *LHS,\n                                ICmpInst::Predicate Pred);\n\n  /// Return SCEV no-wrap flags that can be proven based on reasoning about\n  /// how poison produced from no-wrap flags on this value (e.g. a nuw add)\n  /// would trigger undefined behavior on overflow.\n  SCEV::NoWrapFlags getNoWrapFlagsFromUB(const Value *V);\n\n  /// Return true if the SCEV corresponding to \\p I is never poison.  Proving\n  /// this is more complex than proving that just \\p I is never poison, since\n  /// SCEV commons expressions across control flow, and you can have cases\n  /// like:\n  ///\n  ///   idx0 = a + b;\n  ///   ptr[idx0] = 100;\n  ///   if (<condition>) {\n  ///     idx1 = a +nsw b;\n  ///     ptr[idx1] = 200;\n  ///   }\n  ///\n  /// where the SCEV expression (+ a b) is guaranteed to not be poison (and\n  /// hence not sign-overflow) only if \"<condition>\" is true.  Since both\n  /// `idx0` and `idx1` will be mapped to the same SCEV expression, (+ a b),\n  /// it is not okay to annotate (+ a b) with <nsw> in the above example.\n  bool isSCEVExprNeverPoison(const Instruction *I);\n\n  /// This is like \\c isSCEVExprNeverPoison but it specifically works for\n  /// instructions that will get mapped to SCEV add recurrences.  Return true\n  /// if \\p I will never generate poison under the assumption that \\p I is an\n  /// add recurrence on the loop \\p L.\n  bool isAddRecNeverPoison(const Instruction *I, const Loop *L);\n\n  /// Similar to createAddRecFromPHI, but with the additional flexibility of\n  /// suggesting runtime overflow checks in case casts are encountered.\n  /// If successful, the analysis records that for this loop, \\p SymbolicPHI,\n  /// which is the UnknownSCEV currently representing the PHI, can be rewritten\n  /// into an AddRec, assuming some predicates; The function then returns the\n  /// AddRec and the predicates as a pair, and caches this pair in\n  /// PredicatedSCEVRewrites.\n  /// If the analysis is not successful, a mapping from the \\p SymbolicPHI to\n  /// itself (with no predicates) is recorded, and a nullptr with an empty\n  /// predicates vector is returned as a pair.\n  Optional<std::pair<const SCEV *, SmallVector<const SCEVPredicate *, 3>>>\n  createAddRecFromPHIWithCastsImpl(const SCEVUnknown *SymbolicPHI);\n\n  /// Compute the backedge taken count knowing the interval difference, the\n  /// stride and presence of the equality in the comparison.\n  const SCEV *computeBECount(const SCEV *Delta, const SCEV *Stride,\n                             bool Equality);\n\n  /// Compute the maximum backedge count based on the range of values\n  /// permitted by Start, End, and Stride. This is for loops of the form\n  /// {Start, +, Stride} LT End.\n  ///\n  /// Precondition: the induction variable is known to be positive.  We *don't*\n  /// assert these preconditions so please be careful.\n  const SCEV *computeMaxBECountForLT(const SCEV *Start, const SCEV *Stride,\n                                     const SCEV *End, unsigned BitWidth,\n                                     bool IsSigned);\n\n  /// Verify if an linear IV with positive stride can overflow when in a\n  /// less-than comparison, knowing the invariant term of the comparison,\n  /// the stride and the knowledge of NSW/NUW flags on the recurrence.\n  bool doesIVOverflowOnLT(const SCEV *RHS, const SCEV *Stride, bool IsSigned,\n                          bool NoWrap);\n\n  /// Verify if an linear IV with negative stride can overflow when in a\n  /// greater-than comparison, knowing the invariant term of the comparison,\n  /// the stride and the knowledge of NSW/NUW flags on the recurrence.\n  bool doesIVOverflowOnGT(const SCEV *RHS, const SCEV *Stride, bool IsSigned,\n                          bool NoWrap);\n\n  /// Get add expr already created or create a new one.\n  const SCEV *getOrCreateAddExpr(ArrayRef<const SCEV *> Ops,\n                                 SCEV::NoWrapFlags Flags);\n\n  /// Get mul expr already created or create a new one.\n  const SCEV *getOrCreateMulExpr(ArrayRef<const SCEV *> Ops,\n                                 SCEV::NoWrapFlags Flags);\n\n  // Get addrec expr already created or create a new one.\n  const SCEV *getOrCreateAddRecExpr(ArrayRef<const SCEV *> Ops,\n                                    const Loop *L, SCEV::NoWrapFlags Flags);\n\n  /// Return x if \\p Val is f(x) where f is a 1-1 function.\n  const SCEV *stripInjectiveFunctions(const SCEV *Val) const;\n\n  /// Find all of the loops transitively used in \\p S, and fill \\p LoopsUsed.\n  /// A loop is considered \"used\" by an expression if it contains\n  /// an add rec on said loop.\n  void getUsedLoops(const SCEV *S, SmallPtrSetImpl<const Loop *> &LoopsUsed);\n\n  /// Find all of the loops transitively used in \\p S, and update \\c LoopUsers\n  /// accordingly.\n  void addToLoopUseLists(const SCEV *S);\n\n  /// Try to match the pattern generated by getURemExpr(A, B). If successful,\n  /// Assign A and B to LHS and RHS, respectively.\n  bool matchURem(const SCEV *Expr, const SCEV *&LHS, const SCEV *&RHS);\n\n  /// Look for a SCEV expression with type `SCEVType` and operands `Ops` in\n  /// `UniqueSCEVs`.\n  ///\n  /// The first component of the returned tuple is the SCEV if found and null\n  /// otherwise.  The second component is the `FoldingSetNodeID` that was\n  /// constructed to look up the SCEV and the third component is the insertion\n  /// point.\n  std::tuple<SCEV *, FoldingSetNodeID, void *>\n  findExistingSCEVInCache(SCEVTypes SCEVType, ArrayRef<const SCEV *> Ops);\n\n  FoldingSet<SCEV> UniqueSCEVs;\n  FoldingSet<SCEVPredicate> UniquePreds;\n  BumpPtrAllocator SCEVAllocator;\n\n  /// This maps loops to a list of SCEV expressions that (transitively) use said\n  /// loop.\n  DenseMap<const Loop *, SmallVector<const SCEV *, 4>> LoopUsers;\n\n  /// Cache tentative mappings from UnknownSCEVs in a Loop, to a SCEV expression\n  /// they can be rewritten into under certain predicates.\n  DenseMap<std::pair<const SCEVUnknown *, const Loop *>,\n           std::pair<const SCEV *, SmallVector<const SCEVPredicate *, 3>>>\n      PredicatedSCEVRewrites;\n\n  /// The head of a linked list of all SCEVUnknown values that have been\n  /// allocated. This is used by releaseMemory to locate them all and call\n  /// their destructors.\n  SCEVUnknown *FirstUnknown = nullptr;\n};\n\n/// Analysis pass that exposes the \\c ScalarEvolution for a function.\nclass ScalarEvolutionAnalysis\n    : public AnalysisInfoMixin<ScalarEvolutionAnalysis> {\n  friend AnalysisInfoMixin<ScalarEvolutionAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = ScalarEvolution;\n\n  ScalarEvolution run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c ScalarEvolutionAnalysis results.\nclass ScalarEvolutionVerifierPass\n    : public PassInfoMixin<ScalarEvolutionVerifierPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c ScalarEvolutionAnalysis results.\nclass ScalarEvolutionPrinterPass\n    : public PassInfoMixin<ScalarEvolutionPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit ScalarEvolutionPrinterPass(raw_ostream &OS) : OS(OS) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass ScalarEvolutionWrapperPass : public FunctionPass {\n  std::unique_ptr<ScalarEvolution> SE;\n\npublic:\n  static char ID;\n\n  ScalarEvolutionWrapperPass();\n\n  ScalarEvolution &getSE() { return *SE; }\n  const ScalarEvolution &getSE() const { return *SE; }\n\n  bool runOnFunction(Function &F) override;\n  void releaseMemory() override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  void print(raw_ostream &OS, const Module * = nullptr) const override;\n  void verifyAnalysis() const override;\n};\n\n/// An interface layer with SCEV used to manage how we see SCEV expressions\n/// for values in the context of existing predicates. We can add new\n/// predicates, but we cannot remove them.\n///\n/// This layer has multiple purposes:\n///   - provides a simple interface for SCEV versioning.\n///   - guarantees that the order of transformations applied on a SCEV\n///     expression for a single Value is consistent across two different\n///     getSCEV calls. This means that, for example, once we've obtained\n///     an AddRec expression for a certain value through expression\n///     rewriting, we will continue to get an AddRec expression for that\n///     Value.\n///   - lowers the number of expression rewrites.\nclass PredicatedScalarEvolution {\npublic:\n  PredicatedScalarEvolution(ScalarEvolution &SE, Loop &L);\n\n  const SCEVUnionPredicate &getUnionPredicate() const;\n\n  /// Returns the SCEV expression of V, in the context of the current SCEV\n  /// predicate.  The order of transformations applied on the expression of V\n  /// returned by ScalarEvolution is guaranteed to be preserved, even when\n  /// adding new predicates.\n  const SCEV *getSCEV(Value *V);\n\n  /// Get the (predicated) backedge count for the analyzed loop.\n  const SCEV *getBackedgeTakenCount();\n\n  /// Adds a new predicate.\n  void addPredicate(const SCEVPredicate &Pred);\n\n  /// Attempts to produce an AddRecExpr for V by adding additional SCEV\n  /// predicates. If we can't transform the expression into an AddRecExpr we\n  /// return nullptr and not add additional SCEV predicates to the current\n  /// context.\n  const SCEVAddRecExpr *getAsAddRec(Value *V);\n\n  /// Proves that V doesn't overflow by adding SCEV predicate.\n  void setNoOverflow(Value *V, SCEVWrapPredicate::IncrementWrapFlags Flags);\n\n  /// Returns true if we've proved that V doesn't wrap by means of a SCEV\n  /// predicate.\n  bool hasNoOverflow(Value *V, SCEVWrapPredicate::IncrementWrapFlags Flags);\n\n  /// Returns the ScalarEvolution analysis used.\n  ScalarEvolution *getSE() const { return &SE; }\n\n  /// We need to explicitly define the copy constructor because of FlagsMap.\n  PredicatedScalarEvolution(const PredicatedScalarEvolution &);\n\n  /// Print the SCEV mappings done by the Predicated Scalar Evolution.\n  /// The printed text is indented by \\p Depth.\n  void print(raw_ostream &OS, unsigned Depth) const;\n\n  /// Check if \\p AR1 and \\p AR2 are equal, while taking into account\n  /// Equal predicates in Preds.\n  bool areAddRecsEqualWithPreds(const SCEVAddRecExpr *AR1,\n                                const SCEVAddRecExpr *AR2) const;\n\nprivate:\n  /// Increments the version number of the predicate.  This needs to be called\n  /// every time the SCEV predicate changes.\n  void updateGeneration();\n\n  /// Holds a SCEV and the version number of the SCEV predicate used to\n  /// perform the rewrite of the expression.\n  using RewriteEntry = std::pair<unsigned, const SCEV *>;\n\n  /// Maps a SCEV to the rewrite result of that SCEV at a certain version\n  /// number. If this number doesn't match the current Generation, we will\n  /// need to do a rewrite. To preserve the transformation order of previous\n  /// rewrites, we will rewrite the previous result instead of the original\n  /// SCEV.\n  DenseMap<const SCEV *, RewriteEntry> RewriteMap;\n\n  /// Records what NoWrap flags we've added to a Value *.\n  ValueMap<Value *, SCEVWrapPredicate::IncrementWrapFlags> FlagsMap;\n\n  /// The ScalarEvolution analysis.\n  ScalarEvolution &SE;\n\n  /// The analyzed Loop.\n  const Loop &L;\n\n  /// The SCEVPredicate that forms our context. We will rewrite all\n  /// expressions assuming that this predicate true.\n  SCEVUnionPredicate Preds;\n\n  /// Marks the version of the SCEV predicate used. When rewriting a SCEV\n  /// expression we mark it with the version of the predicate. We use this to\n  /// figure out if the predicate has changed from the last rewrite of the\n  /// SCEV. If so, we need to perform a new rewrite.\n  unsigned Generation = 0;\n\n  /// The backedge taken count.\n  const SCEV *BackedgeCount = nullptr;\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_SCALAREVOLUTION_H\n"}, "60": {"id": 60, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionAliasAnalysis.h", "content": "//===- ScalarEvolutionAliasAnalysis.h - SCEV-based AA -----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This is the interface for a SCEV-based alias analysis.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_SCALAREVOLUTIONALIASANALYSIS_H\n#define LLVM_ANALYSIS_SCALAREVOLUTIONALIASANALYSIS_H\n\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/Analysis/ScalarEvolutionExpressions.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\n/// A simple alias analysis implementation that uses ScalarEvolution to answer\n/// queries.\nclass SCEVAAResult : public AAResultBase<SCEVAAResult> {\n  ScalarEvolution &SE;\n\npublic:\n  explicit SCEVAAResult(ScalarEvolution &SE) : AAResultBase(), SE(SE) {}\n  SCEVAAResult(SCEVAAResult &&Arg) : AAResultBase(std::move(Arg)), SE(Arg.SE) {}\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n\nprivate:\n  Value *GetBaseValue(const SCEV *S);\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\nclass SCEVAA : public AnalysisInfoMixin<SCEVAA> {\n  friend AnalysisInfoMixin<SCEVAA>;\n  static AnalysisKey Key;\n\npublic:\n  typedef SCEVAAResult Result;\n\n  SCEVAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the SCEVAAResult object.\nclass SCEVAAWrapperPass : public FunctionPass {\n  std::unique_ptr<SCEVAAResult> Result;\n\npublic:\n  static char ID;\n\n  SCEVAAWrapperPass();\n\n  SCEVAAResult &getResult() { return *Result; }\n  const SCEVAAResult &getResult() const { return *Result; }\n\n  bool runOnFunction(Function &F) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n/// Creates an instance of \\c SCEVAAWrapperPass.\nFunctionPass *createSCEVAAWrapperPass();\n\n}\n\n#endif\n"}, "61": {"id": 61, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScopedNoAliasAA.h", "content": "//===- ScopedNoAliasAA.h - Scoped No-Alias Alias Analysis -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This is the interface for a metadata-based scoped no-alias analysis.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_SCOPEDNOALIASAA_H\n#define LLVM_ANALYSIS_SCOPEDNOALIASAA_H\n\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include <memory>\n\nnamespace llvm {\n\nclass Function;\nclass MDNode;\nclass MemoryLocation;\n\n/// A simple AA result which uses scoped-noalias metadata to answer queries.\nclass ScopedNoAliasAAResult : public AAResultBase<ScopedNoAliasAAResult> {\n  friend AAResultBase<ScopedNoAliasAAResult>;\n\npublic:\n  /// Handle invalidation events from the new pass manager.\n  ///\n  /// By definition, this result is stateless and so remains valid.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                           AAQueryInfo &AAQI);\n\nprivate:\n  bool mayAliasInScopes(const MDNode *Scopes, const MDNode *NoAlias) const;\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\nclass ScopedNoAliasAA : public AnalysisInfoMixin<ScopedNoAliasAA> {\n  friend AnalysisInfoMixin<ScopedNoAliasAA>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = ScopedNoAliasAAResult;\n\n  ScopedNoAliasAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the ScopedNoAliasAAResult object.\nclass ScopedNoAliasAAWrapperPass : public ImmutablePass {\n  std::unique_ptr<ScopedNoAliasAAResult> Result;\n\npublic:\n  static char ID;\n\n  ScopedNoAliasAAWrapperPass();\n\n  ScopedNoAliasAAResult &getResult() { return *Result; }\n  const ScopedNoAliasAAResult &getResult() const { return *Result; }\n\n  bool doInitialization(Module &M) override;\n  bool doFinalization(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n//===--------------------------------------------------------------------===//\n//\n// createScopedNoAliasAAWrapperPass - This pass implements metadata-based\n// scoped noalias analysis.\n//\nImmutablePass *createScopedNoAliasAAWrapperPass();\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_SCOPEDNOALIASAA_H\n"}, "62": {"id": 62, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/StackLifetime.h", "content": "//===- StackLifetime.h - Alloca Lifetime Analysis --------------*- C++ -*--===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_STACKLIFETIME_H\n#define LLVM_ANALYSIS_STACKLIFETIME_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/BitVector.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/StringExtras.h\"\n#include \"llvm/IR/IntrinsicInst.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <cassert>\n#include <utility>\n\nnamespace llvm {\n\nclass AllocaInst;\nclass BasicBlock;\nclass Function;\nclass Instruction;\n\n/// Compute live ranges of allocas.\n/// Live ranges are represented as sets of \"interesting\" instructions, which are\n/// defined as instructions that may start or end an alloca's lifetime. These\n/// are:\n/// * lifetime.start and lifetime.end intrinsics\n/// * first instruction of any basic block\n/// Interesting instructions are numbered in the depth-first walk of the CFG,\n/// and in the program order inside each basic block.\nclass StackLifetime {\n  /// A class representing liveness information for a single basic block.\n  /// Each bit in the BitVector represents the liveness property\n  /// for a different stack slot.\n  struct BlockLifetimeInfo {\n    explicit BlockLifetimeInfo(unsigned Size)\n        : Begin(Size), End(Size), LiveIn(Size), LiveOut(Size) {}\n\n    /// Which slots BEGINs in each basic block.\n    BitVector Begin;\n\n    /// Which slots ENDs in each basic block.\n    BitVector End;\n\n    /// Which slots are marked as LIVE_IN, coming into each basic block.\n    BitVector LiveIn;\n\n    /// Which slots are marked as LIVE_OUT, coming out of each basic block.\n    BitVector LiveOut;\n  };\n\npublic:\n  class LifetimeAnnotationWriter;\n\n  /// This class represents a set of interesting instructions where an alloca is\n  /// live.\n  class LiveRange {\n    BitVector Bits;\n    friend raw_ostream &operator<<(raw_ostream &OS,\n                                   const StackLifetime::LiveRange &R);\n\n  public:\n    LiveRange(unsigned Size, bool Set = false) : Bits(Size, Set) {}\n    void addRange(unsigned Start, unsigned End) { Bits.set(Start, End); }\n\n    bool overlaps(const LiveRange &Other) const {\n      return Bits.anyCommon(Other.Bits);\n    }\n\n    void join(const LiveRange &Other) { Bits |= Other.Bits; }\n\n    bool test(unsigned Idx) const { return Bits.test(Idx); }\n  };\n\n  // Controls what is \"alive\" if control flow may reach the instruction\n  // with a different liveness of the alloca.\n  enum class LivenessType {\n    May,  // May be alive on some path.\n    Must, // Must be alive on every path.\n  };\n\nprivate:\n  const Function &F;\n  LivenessType Type;\n\n  /// Maps active slots (per bit) for each basic block.\n  using LivenessMap = DenseMap<const BasicBlock *, BlockLifetimeInfo>;\n  LivenessMap BlockLiveness;\n\n  /// Interesting instructions. Instructions of the same block are adjustent\n  /// preserve in-block order.\n  SmallVector<const IntrinsicInst *, 64> Instructions;\n\n  /// A range [Start, End) of instruction ids for each basic block.\n  /// Instructions inside each BB have monotonic and consecutive ids.\n  DenseMap<const BasicBlock *, std::pair<unsigned, unsigned>> BlockInstRange;\n\n  ArrayRef<const AllocaInst *> Allocas;\n  unsigned NumAllocas;\n  DenseMap<const AllocaInst *, unsigned> AllocaNumbering;\n\n  /// LiveRange for allocas.\n  SmallVector<LiveRange, 8> LiveRanges;\n\n  /// The set of allocas that have at least one lifetime.start. All other\n  /// allocas get LiveRange that corresponds to the entire function.\n  BitVector InterestingAllocas;\n\n  struct Marker {\n    unsigned AllocaNo;\n    bool IsStart;\n  };\n\n  /// List of {InstNo, {AllocaNo, IsStart}} for each BB, ordered by InstNo.\n  DenseMap<const BasicBlock *, SmallVector<std::pair<unsigned, Marker>, 4>>\n      BBMarkers;\n\n  bool HasUnknownLifetimeStartOrEnd = false;\n\n  void dumpAllocas() const;\n  void dumpBlockLiveness() const;\n  void dumpLiveRanges() const;\n\n  void collectMarkers();\n  void calculateLocalLiveness();\n  void calculateLiveIntervals();\n\npublic:\n  StackLifetime(const Function &F, ArrayRef<const AllocaInst *> Allocas,\n                LivenessType Type);\n\n  void run();\n\n  iterator_range<\n      filter_iterator<ArrayRef<const IntrinsicInst *>::const_iterator,\n                      std::function<bool(const IntrinsicInst *)>>>\n  getMarkers() const {\n    std::function<bool(const IntrinsicInst *)> NotNull(\n        [](const IntrinsicInst *I) -> bool { return I; });\n    return make_filter_range(Instructions, NotNull);\n  }\n\n  /// Returns a set of \"interesting\" instructions where the given alloca is\n  /// live. Not all instructions in a function are interesting: we pick a set\n  /// that is large enough for LiveRange::Overlaps to be correct.\n  const LiveRange &getLiveRange(const AllocaInst *AI) const;\n\n  /// Returns true if instruction is reachable from entry.\n  bool isReachable(const Instruction *I) const;\n\n  /// Returns true if the alloca is alive after the instruction.\n  bool isAliveAfter(const AllocaInst *AI, const Instruction *I) const;\n\n  /// Returns a live range that represents an alloca that is live throughout the\n  /// entire function.\n  LiveRange getFullLiveRange() const {\n    return LiveRange(Instructions.size(), true);\n  }\n\n  void print(raw_ostream &O);\n};\n\nstatic inline raw_ostream &operator<<(raw_ostream &OS, const BitVector &V) {\n  OS << \"{\";\n  ListSeparator LS;\n  for (int Idx = V.find_first(); Idx >= 0; Idx = V.find_next(Idx))\n    OS << LS << Idx;\n  OS << \"}\";\n  return OS;\n}\n\ninline raw_ostream &operator<<(raw_ostream &OS,\n                               const StackLifetime::LiveRange &R) {\n  return OS << R.Bits;\n}\n\n/// Printer pass for testing.\nclass StackLifetimePrinterPass\n    : public PassInfoMixin<StackLifetimePrinterPass> {\n  StackLifetime::LivenessType Type;\n  raw_ostream &OS;\n\npublic:\n  StackLifetimePrinterPass(raw_ostream &OS, StackLifetime::LivenessType Type)\n      : Type(Type), OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_STACKLIFETIME_H\n"}, "63": {"id": 63, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/StackSafetyAnalysis.h", "content": "//===- StackSafetyAnalysis.h - Stack memory safety analysis -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Stack Safety Analysis detects allocas and arguments with safe access.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_STACKSAFETYANALYSIS_H\n#define LLVM_ANALYSIS_STACKSAFETYANALYSIS_H\n\n#include \"llvm/IR/ModuleSummaryIndex.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass AllocaInst;\nclass ScalarEvolution;\n\n/// Interface to access stack safety analysis results for single function.\nclass StackSafetyInfo {\npublic:\n  struct InfoTy;\n\nprivate:\n  Function *F = nullptr;\n  std::function<ScalarEvolution &()> GetSE;\n  mutable std::unique_ptr<InfoTy> Info;\n\npublic:\n  StackSafetyInfo();\n  StackSafetyInfo(Function *F, std::function<ScalarEvolution &()> GetSE);\n  StackSafetyInfo(StackSafetyInfo &&);\n  StackSafetyInfo &operator=(StackSafetyInfo &&);\n  ~StackSafetyInfo();\n\n  const InfoTy &getInfo() const;\n\n  // TODO: Add useful for client methods.\n  void print(raw_ostream &O) const;\n\n  /// Parameters use for a FunctionSummary.\n  /// Function collects access information of all pointer parameters.\n  /// Information includes a range of direct access of parameters by the\n  /// functions and all call sites accepting the parameter.\n  /// StackSafety assumes that missing parameter information means possibility\n  /// of access to the parameter with any offset, so we can correctly link\n  /// code without StackSafety information, e.g. non-ThinLTO.\n  std::vector<FunctionSummary::ParamAccess>\n  getParamAccesses(ModuleSummaryIndex &Index) const;\n};\n\nclass StackSafetyGlobalInfo {\npublic:\n  struct InfoTy;\n\nprivate:\n  Module *M = nullptr;\n  std::function<const StackSafetyInfo &(Function &F)> GetSSI;\n  const ModuleSummaryIndex *Index = nullptr;\n  mutable std::unique_ptr<InfoTy> Info;\n  const InfoTy &getInfo() const;\n\npublic:\n  StackSafetyGlobalInfo();\n  StackSafetyGlobalInfo(\n      Module *M, std::function<const StackSafetyInfo &(Function &F)> GetSSI,\n      const ModuleSummaryIndex *Index);\n  StackSafetyGlobalInfo(StackSafetyGlobalInfo &&);\n  StackSafetyGlobalInfo &operator=(StackSafetyGlobalInfo &&);\n  ~StackSafetyGlobalInfo();\n\n  bool isSafe(const AllocaInst &AI) const;\n  void print(raw_ostream &O) const;\n  void dump() const;\n};\n\n/// StackSafetyInfo wrapper for the new pass manager.\nclass StackSafetyAnalysis : public AnalysisInfoMixin<StackSafetyAnalysis> {\n  friend AnalysisInfoMixin<StackSafetyAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  using Result = StackSafetyInfo;\n  StackSafetyInfo run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c StackSafetyAnalysis results.\nclass StackSafetyPrinterPass : public PassInfoMixin<StackSafetyPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit StackSafetyPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// StackSafetyInfo wrapper for the legacy pass manager\nclass StackSafetyInfoWrapperPass : public FunctionPass {\n  StackSafetyInfo SSI;\n\npublic:\n  static char ID;\n  StackSafetyInfoWrapperPass();\n\n  const StackSafetyInfo &getResult() const { return SSI; }\n\n  void print(raw_ostream &O, const Module *M) const override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  bool runOnFunction(Function &F) override;\n};\n\n/// This pass performs the global (interprocedural) stack safety analysis (new\n/// pass manager).\nclass StackSafetyGlobalAnalysis\n    : public AnalysisInfoMixin<StackSafetyGlobalAnalysis> {\n  friend AnalysisInfoMixin<StackSafetyGlobalAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  using Result = StackSafetyGlobalInfo;\n  Result run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// Printer pass for the \\c StackSafetyGlobalAnalysis results.\nclass StackSafetyGlobalPrinterPass\n    : public PassInfoMixin<StackSafetyGlobalPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit StackSafetyGlobalPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// This pass performs the global (interprocedural) stack safety analysis\n/// (legacy pass manager).\nclass StackSafetyGlobalInfoWrapperPass : public ModulePass {\n  StackSafetyGlobalInfo SSGI;\n\npublic:\n  static char ID;\n\n  StackSafetyGlobalInfoWrapperPass();\n  ~StackSafetyGlobalInfoWrapperPass();\n\n  const StackSafetyGlobalInfo &getResult() const { return SSGI; }\n\n  void print(raw_ostream &O, const Module *M) const override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  bool runOnModule(Module &M) override;\n};\n\nbool needsParamAccessSummary(const Module &M);\n\nvoid generateParamAccessSummary(ModuleSummaryIndex &Index);\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_STACKSAFETYANALYSIS_H\n"}, "64": {"id": 64, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/TypeBasedAliasAnalysis.h", "content": "//===- TypeBasedAliasAnalysis.h - Type-Based Alias Analysis -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This is the interface for a metadata-based TBAA. See the source file for\n/// details on the algorithm.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ANALYSIS_TYPEBASEDALIASANALYSIS_H\n#define LLVM_ANALYSIS_TYPEBASEDALIASANALYSIS_H\n\n#include \"llvm/Analysis/AliasAnalysis.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include <memory>\n\nnamespace llvm {\n\nclass CallBase;\nclass Function;\nclass MDNode;\nclass MemoryLocation;\n\n/// A simple AA result that uses TBAA metadata to answer queries.\nclass TypeBasedAAResult : public AAResultBase<TypeBasedAAResult> {\n  friend AAResultBase<TypeBasedAAResult>;\n\npublic:\n  /// Handle invalidation events from the new pass manager.\n  ///\n  /// By definition, this result is stateless and so remains valid.\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\n  AliasResult alias(const MemoryLocation &LocA, const MemoryLocation &LocB,\n                    AAQueryInfo &AAQI);\n  bool pointsToConstantMemory(const MemoryLocation &Loc, AAQueryInfo &AAQI,\n                              bool OrLocal);\n  FunctionModRefBehavior getModRefBehavior(const CallBase *Call);\n  FunctionModRefBehavior getModRefBehavior(const Function *F);\n  ModRefInfo getModRefInfo(const CallBase *Call, const MemoryLocation &Loc,\n                           AAQueryInfo &AAQI);\n  ModRefInfo getModRefInfo(const CallBase *Call1, const CallBase *Call2,\n                           AAQueryInfo &AAQI);\n\nprivate:\n  bool Aliases(const MDNode *A, const MDNode *B) const;\n};\n\n/// Analysis pass providing a never-invalidated alias analysis result.\nclass TypeBasedAA : public AnalysisInfoMixin<TypeBasedAA> {\n  friend AnalysisInfoMixin<TypeBasedAA>;\n\n  static AnalysisKey Key;\n\npublic:\n  using Result = TypeBasedAAResult;\n\n  TypeBasedAAResult run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy wrapper pass to provide the TypeBasedAAResult object.\nclass TypeBasedAAWrapperPass : public ImmutablePass {\n  std::unique_ptr<TypeBasedAAResult> Result;\n\npublic:\n  static char ID;\n\n  TypeBasedAAWrapperPass();\n\n  TypeBasedAAResult &getResult() { return *Result; }\n  const TypeBasedAAResult &getResult() const { return *Result; }\n\n  bool doInitialization(Module &M) override;\n  bool doFinalization(Module &M) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n//===--------------------------------------------------------------------===//\n//\n// createTypeBasedAAWrapperPass - This pass implements metadata-based\n// type-based alias analysis.\n//\nImmutablePass *createTypeBasedAAWrapperPass();\n\n} // end namespace llvm\n\n#endif // LLVM_ANALYSIS_TYPEBASEDALIASANALYSIS_H\n"}, "73": {"id": 73, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Dominators.h", "content": "//===- Dominators.h - Dominator Info Calculation ----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the DominatorTree class, which provides fast and efficient\n// dominance queries.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_DOMINATORS_H\n#define LLVM_IR_DOMINATORS_H\n\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/ADT/DepthFirstIterator.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/Hashing.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/CFG.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/GenericDomTree.h\"\n#include <utility>\n\nnamespace llvm {\n\nclass Function;\nclass Instruction;\nclass Module;\nclass raw_ostream;\n\nextern template class DomTreeNodeBase<BasicBlock>;\nextern template class DominatorTreeBase<BasicBlock, false>; // DomTree\nextern template class DominatorTreeBase<BasicBlock, true>; // PostDomTree\n\nextern template class cfg::Update<BasicBlock *>;\n\nnamespace DomTreeBuilder {\nusing BBDomTree = DomTreeBase<BasicBlock>;\nusing BBPostDomTree = PostDomTreeBase<BasicBlock>;\n\nusing BBUpdates = ArrayRef<llvm::cfg::Update<BasicBlock *>>;\n\nusing BBDomTreeGraphDiff = GraphDiff<BasicBlock *, false>;\nusing BBPostDomTreeGraphDiff = GraphDiff<BasicBlock *, true>;\n\nextern template void Calculate<BBDomTree>(BBDomTree &DT);\nextern template void CalculateWithUpdates<BBDomTree>(BBDomTree &DT,\n                                                     BBUpdates U);\n\nextern template void Calculate<BBPostDomTree>(BBPostDomTree &DT);\n\nextern template void InsertEdge<BBDomTree>(BBDomTree &DT, BasicBlock *From,\n                                           BasicBlock *To);\nextern template void InsertEdge<BBPostDomTree>(BBPostDomTree &DT,\n                                               BasicBlock *From,\n                                               BasicBlock *To);\n\nextern template void DeleteEdge<BBDomTree>(BBDomTree &DT, BasicBlock *From,\n                                           BasicBlock *To);\nextern template void DeleteEdge<BBPostDomTree>(BBPostDomTree &DT,\n                                               BasicBlock *From,\n                                               BasicBlock *To);\n\nextern template void ApplyUpdates<BBDomTree>(BBDomTree &DT,\n                                             BBDomTreeGraphDiff &,\n                                             BBDomTreeGraphDiff *);\nextern template void ApplyUpdates<BBPostDomTree>(BBPostDomTree &DT,\n                                                 BBPostDomTreeGraphDiff &,\n                                                 BBPostDomTreeGraphDiff *);\n\nextern template bool Verify<BBDomTree>(const BBDomTree &DT,\n                                       BBDomTree::VerificationLevel VL);\nextern template bool Verify<BBPostDomTree>(const BBPostDomTree &DT,\n                                           BBPostDomTree::VerificationLevel VL);\n}  // namespace DomTreeBuilder\n\nusing DomTreeNode = DomTreeNodeBase<BasicBlock>;\n\nclass BasicBlockEdge {\n  const BasicBlock *Start;\n  const BasicBlock *End;\n\npublic:\n  BasicBlockEdge(const BasicBlock *Start_, const BasicBlock *End_) :\n    Start(Start_), End(End_) {}\n\n  BasicBlockEdge(const std::pair<BasicBlock *, BasicBlock *> &Pair)\n      : Start(Pair.first), End(Pair.second) {}\n\n  BasicBlockEdge(const std::pair<const BasicBlock *, const BasicBlock *> &Pair)\n      : Start(Pair.first), End(Pair.second) {}\n\n  const BasicBlock *getStart() const {\n    return Start;\n  }\n\n  const BasicBlock *getEnd() const {\n    return End;\n  }\n\n  /// Check if this is the only edge between Start and End.\n  bool isSingleEdge() const;\n};\n\ntemplate <> struct DenseMapInfo<BasicBlockEdge> {\n  using BBInfo = DenseMapInfo<const BasicBlock *>;\n\n  static unsigned getHashValue(const BasicBlockEdge *V);\n\n  static inline BasicBlockEdge getEmptyKey() {\n    return BasicBlockEdge(BBInfo::getEmptyKey(), BBInfo::getEmptyKey());\n  }\n\n  static inline BasicBlockEdge getTombstoneKey() {\n    return BasicBlockEdge(BBInfo::getTombstoneKey(), BBInfo::getTombstoneKey());\n  }\n\n  static unsigned getHashValue(const BasicBlockEdge &Edge) {\n    return hash_combine(BBInfo::getHashValue(Edge.getStart()),\n                        BBInfo::getHashValue(Edge.getEnd()));\n  }\n\n  static bool isEqual(const BasicBlockEdge &LHS, const BasicBlockEdge &RHS) {\n    return BBInfo::isEqual(LHS.getStart(), RHS.getStart()) &&\n           BBInfo::isEqual(LHS.getEnd(), RHS.getEnd());\n  }\n};\n\n/// Concrete subclass of DominatorTreeBase that is used to compute a\n/// normal dominator tree.\n///\n/// Definition: A block is said to be forward statically reachable if there is\n/// a path from the entry of the function to the block.  A statically reachable\n/// block may become statically unreachable during optimization.\n///\n/// A forward unreachable block may appear in the dominator tree, or it may\n/// not.  If it does, dominance queries will return results as if all reachable\n/// blocks dominate it.  When asking for a Node corresponding to a potentially\n/// unreachable block, calling code must handle the case where the block was\n/// unreachable and the result of getNode() is nullptr.\n///\n/// Generally, a block known to be unreachable when the dominator tree is\n/// constructed will not be in the tree.  One which becomes unreachable after\n/// the dominator tree is initially constructed may still exist in the tree,\n/// even if the tree is properly updated. Calling code should not rely on the\n/// preceding statements; this is stated only to assist human understanding.\nclass DominatorTree : public DominatorTreeBase<BasicBlock, false> {\n public:\n  using Base = DominatorTreeBase<BasicBlock, false>;\n\n  DominatorTree() = default;\n  explicit DominatorTree(Function &F) { recalculate(F); }\n  explicit DominatorTree(DominatorTree &DT, DomTreeBuilder::BBUpdates U) {\n    recalculate(*DT.Parent, U);\n  }\n\n  /// Handle invalidation explicitly.\n  bool invalidate(Function &F, const PreservedAnalyses &PA,\n                  FunctionAnalysisManager::Invalidator &);\n\n  // Ensure base-class overloads are visible.\n  using Base::dominates;\n\n  /// Return true if the (end of the) basic block BB dominates the use U.\n  bool dominates(const BasicBlock *BB, const Use &U) const;\n\n  /// Return true if value Def dominates use U, in the sense that Def is\n  /// available at U, and could be substituted as the used value without\n  /// violating the SSA dominance requirement.\n  ///\n  /// In particular, it is worth noting that:\n  ///  * Non-instruction Defs dominate everything.\n  ///  * Def does not dominate a use in Def itself (outside of degenerate cases\n  ///    like unreachable code or trivial phi cycles).\n  ///  * Invoke/callbr Defs only dominate uses in their default destination.\n  bool dominates(const Value *Def, const Use &U) const;\n  /// Return true if value Def dominates all possible uses inside instruction\n  /// User. Same comments as for the Use-based API apply.\n  bool dominates(const Value *Def, const Instruction *User) const;\n  // Does not accept Value to avoid ambiguity with dominance checks between\n  // two basic blocks.\n  bool dominates(const Instruction *Def, const BasicBlock *BB) const;\n\n  /// Return true if an edge dominates a use.\n  ///\n  /// If BBE is not a unique edge between start and end of the edge, it can\n  /// never dominate the use.\n  bool dominates(const BasicBlockEdge &BBE, const Use &U) const;\n  bool dominates(const BasicBlockEdge &BBE, const BasicBlock *BB) const;\n  /// Returns true if edge \\p BBE1 dominates edge \\p BBE2.\n  bool dominates(const BasicBlockEdge &BBE1, const BasicBlockEdge &BBE2) const;\n\n  // Ensure base class overloads are visible.\n  using Base::isReachableFromEntry;\n\n  /// Provide an overload for a Use.\n  bool isReachableFromEntry(const Use &U) const;\n\n  // Pop up a GraphViz/gv window with the Dominator Tree rendered using `dot`.\n  void viewGraph(const Twine &Name, const Twine &Title);\n  void viewGraph();\n};\n\n//===-------------------------------------\n// DominatorTree GraphTraits specializations so the DominatorTree can be\n// iterable by generic graph iterators.\n\ntemplate <class Node, class ChildIterator> struct DomTreeGraphTraitsBase {\n  using NodeRef = Node *;\n  using ChildIteratorType = ChildIterator;\n  using nodes_iterator = df_iterator<Node *, df_iterator_default_set<Node*>>;\n\n  static NodeRef getEntryNode(NodeRef N) { return N; }\n  static ChildIteratorType child_begin(NodeRef N) { return N->begin(); }\n  static ChildIteratorType child_end(NodeRef N) { return N->end(); }\n\n  static nodes_iterator nodes_begin(NodeRef N) {\n    return df_begin(getEntryNode(N));\n  }\n\n  static nodes_iterator nodes_end(NodeRef N) { return df_end(getEntryNode(N)); }\n};\n\ntemplate <>\nstruct GraphTraits<DomTreeNode *>\n    : public DomTreeGraphTraitsBase<DomTreeNode, DomTreeNode::const_iterator> {\n};\n\ntemplate <>\nstruct GraphTraits<const DomTreeNode *>\n    : public DomTreeGraphTraitsBase<const DomTreeNode,\n                                    DomTreeNode::const_iterator> {};\n\ntemplate <> struct GraphTraits<DominatorTree*>\n  : public GraphTraits<DomTreeNode*> {\n  static NodeRef getEntryNode(DominatorTree *DT) { return DT->getRootNode(); }\n\n  static nodes_iterator nodes_begin(DominatorTree *N) {\n    return df_begin(getEntryNode(N));\n  }\n\n  static nodes_iterator nodes_end(DominatorTree *N) {\n    return df_end(getEntryNode(N));\n  }\n};\n\n/// Analysis pass which computes a \\c DominatorTree.\nclass DominatorTreeAnalysis : public AnalysisInfoMixin<DominatorTreeAnalysis> {\n  friend AnalysisInfoMixin<DominatorTreeAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  /// Provide the result typedef for this analysis pass.\n  using Result = DominatorTree;\n\n  /// Run the analysis pass over a function and produce a dominator tree.\n  DominatorTree run(Function &F, FunctionAnalysisManager &);\n};\n\n/// Printer pass for the \\c DominatorTree.\nclass DominatorTreePrinterPass\n    : public PassInfoMixin<DominatorTreePrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit DominatorTreePrinterPass(raw_ostream &OS);\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for the \\c DominatorTree.\nstruct DominatorTreeVerifierPass : PassInfoMixin<DominatorTreeVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Legacy analysis pass which computes a \\c DominatorTree.\nclass DominatorTreeWrapperPass : public FunctionPass {\n  DominatorTree DT;\n\npublic:\n  static char ID;\n\n  DominatorTreeWrapperPass();\n\n  DominatorTree &getDomTree() { return DT; }\n  const DominatorTree &getDomTree() const { return DT; }\n\n  bool runOnFunction(Function &F) override;\n\n  void verifyAnalysis() const override;\n\n  void getAnalysisUsage(AnalysisUsage &AU) const override {\n    AU.setPreservesAll();\n  }\n\n  void releaseMemory() override { DT.reset(); }\n\n  void print(raw_ostream &OS, const Module *M = nullptr) const override;\n};\n} // end namespace llvm\n\n#endif // LLVM_IR_DOMINATORS_H\n"}, "85": {"id": 85, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/PassManager.h", "content": "//===- PassManager.h - Pass management infrastructure -----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// This header defines various interfaces for pass management in LLVM. There\n/// is no \"pass\" interface in LLVM per se. Instead, an instance of any class\n/// which supports a method to 'run' it over a unit of IR can be used as\n/// a pass. A pass manager is generally a tool to collect a sequence of passes\n/// which run over a particular IR construct, and run each of them in sequence\n/// over each such construct in the containing IR construct. As there is no\n/// containing IR construct for a Module, a manager for passes over modules\n/// forms the base case which runs its managed passes in sequence over the\n/// single module provided.\n///\n/// The core IR library provides managers for running passes over\n/// modules and functions.\n///\n/// * FunctionPassManager can run over a Module, runs each pass over\n///   a Function.\n/// * ModulePassManager must be directly run, runs each pass over the Module.\n///\n/// Note that the implementations of the pass managers use concept-based\n/// polymorphism as outlined in the \"Value Semantics and Concept-based\n/// Polymorphism\" talk (or its abbreviated sibling \"Inheritance Is The Base\n/// Class of Evil\") by Sean Parent:\n/// * http://github.com/sean-parent/sean-parent.github.com/wiki/Papers-and-Presentations\n/// * http://www.youtube.com/watch?v=_BpMYeUFXv8\n/// * http://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_PASSMANAGER_H\n#define LLVM_IR_PASSMANAGER_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/TinyPtrVector.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassInstrumentation.h\"\n#include \"llvm/IR/PassManagerInternal.h\"\n#include \"llvm/Pass.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Support/TimeProfiler.h\"\n#include \"llvm/Support/TypeName.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstring>\n#include <iterator>\n#include <list>\n#include <memory>\n#include <tuple>\n#include <type_traits>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\n/// A special type used by analysis passes to provide an address that\n/// identifies that particular analysis pass type.\n///\n/// Analysis passes should have a static data member of this type and derive\n/// from the \\c AnalysisInfoMixin to get a static ID method used to identify\n/// the analysis in the pass management infrastructure.\nstruct alignas(8) AnalysisKey {};\n\n/// A special type used to provide an address that identifies a set of related\n/// analyses.  These sets are primarily used below to mark sets of analyses as\n/// preserved.\n///\n/// For example, a transformation can indicate that it preserves the CFG of a\n/// function by preserving the appropriate AnalysisSetKey.  An analysis that\n/// depends only on the CFG can then check if that AnalysisSetKey is preserved;\n/// if it is, the analysis knows that it itself is preserved.\nstruct alignas(8) AnalysisSetKey {};\n\n/// This templated class represents \"all analyses that operate over \\<a\n/// particular IR unit\\>\" (e.g. a Function or a Module) in instances of\n/// PreservedAnalysis.\n///\n/// This lets a transformation say e.g. \"I preserved all function analyses\".\n///\n/// Note that you must provide an explicit instantiation declaration and\n/// definition for this template in order to get the correct behavior on\n/// Windows. Otherwise, the address of SetKey will not be stable.\ntemplate <typename IRUnitT> class AllAnalysesOn {\npublic:\n  static AnalysisSetKey *ID() { return &SetKey; }\n\nprivate:\n  static AnalysisSetKey SetKey;\n};\n\ntemplate <typename IRUnitT> AnalysisSetKey AllAnalysesOn<IRUnitT>::SetKey;\n\nextern template class AllAnalysesOn<Module>;\nextern template class AllAnalysesOn<Function>;\n\n/// Represents analyses that only rely on functions' control flow.\n///\n/// This can be used with \\c PreservedAnalyses to mark the CFG as preserved and\n/// to query whether it has been preserved.\n///\n/// The CFG of a function is defined as the set of basic blocks and the edges\n/// between them. Changing the set of basic blocks in a function is enough to\n/// mutate the CFG. Mutating the condition of a branch or argument of an\n/// invoked function does not mutate the CFG, but changing the successor labels\n/// of those instructions does.\nclass CFGAnalyses {\npublic:\n  static AnalysisSetKey *ID() { return &SetKey; }\n\nprivate:\n  static AnalysisSetKey SetKey;\n};\n\n/// A set of analyses that are preserved following a run of a transformation\n/// pass.\n///\n/// Transformation passes build and return these objects to communicate which\n/// analyses are still valid after the transformation. For most passes this is\n/// fairly simple: if they don't change anything all analyses are preserved,\n/// otherwise only a short list of analyses that have been explicitly updated\n/// are preserved.\n///\n/// This class also lets transformation passes mark abstract *sets* of analyses\n/// as preserved. A transformation that (say) does not alter the CFG can\n/// indicate such by marking a particular AnalysisSetKey as preserved, and\n/// then analyses can query whether that AnalysisSetKey is preserved.\n///\n/// Finally, this class can represent an \"abandoned\" analysis, which is\n/// not preserved even if it would be covered by some abstract set of analyses.\n///\n/// Given a `PreservedAnalyses` object, an analysis will typically want to\n/// figure out whether it is preserved. In the example below, MyAnalysisType is\n/// preserved if it's not abandoned, and (a) it's explicitly marked as\n/// preserved, (b), the set AllAnalysesOn<MyIRUnit> is preserved, or (c) both\n/// AnalysisSetA and AnalysisSetB are preserved.\n///\n/// ```\n///   auto PAC = PA.getChecker<MyAnalysisType>();\n///   if (PAC.preserved() || PAC.preservedSet<AllAnalysesOn<MyIRUnit>>() ||\n///       (PAC.preservedSet<AnalysisSetA>() &&\n///        PAC.preservedSet<AnalysisSetB>())) {\n///     // The analysis has been successfully preserved ...\n///   }\n/// ```\nclass PreservedAnalyses {\npublic:\n  /// Convenience factory function for the empty preserved set.\n  static PreservedAnalyses none() { return PreservedAnalyses(); }\n\n  /// Construct a special preserved set that preserves all passes.\n  static PreservedAnalyses all() {\n    PreservedAnalyses PA;\n    PA.PreservedIDs.insert(&AllAnalysesKey);\n    return PA;\n  }\n\n  /// Construct a preserved analyses object with a single preserved set.\n  template <typename AnalysisSetT>\n  static PreservedAnalyses allInSet() {\n    PreservedAnalyses PA;\n    PA.preserveSet<AnalysisSetT>();\n    return PA;\n  }\n\n  /// Mark an analysis as preserved.\n  template <typename AnalysisT> void preserve() { preserve(AnalysisT::ID()); }\n\n  /// Given an analysis's ID, mark the analysis as preserved, adding it\n  /// to the set.\n  void preserve(AnalysisKey *ID) {\n    // Clear this ID from the explicit not-preserved set if present.\n    NotPreservedAnalysisIDs.erase(ID);\n\n    // If we're not already preserving all analyses (other than those in\n    // NotPreservedAnalysisIDs).\n    if (!areAllPreserved())\n      PreservedIDs.insert(ID);\n  }\n\n  /// Mark an analysis set as preserved.\n  template <typename AnalysisSetT> void preserveSet() {\n    preserveSet(AnalysisSetT::ID());\n  }\n\n  /// Mark an analysis set as preserved using its ID.\n  void preserveSet(AnalysisSetKey *ID) {\n    // If we're not already in the saturated 'all' state, add this set.\n    if (!areAllPreserved())\n      PreservedIDs.insert(ID);\n  }\n\n  /// Mark an analysis as abandoned.\n  ///\n  /// An abandoned analysis is not preserved, even if it is nominally covered\n  /// by some other set or was previously explicitly marked as preserved.\n  ///\n  /// Note that you can only abandon a specific analysis, not a *set* of\n  /// analyses.\n  template <typename AnalysisT> void abandon() { abandon(AnalysisT::ID()); }\n\n  /// Mark an analysis as abandoned using its ID.\n  ///\n  /// An abandoned analysis is not preserved, even if it is nominally covered\n  /// by some other set or was previously explicitly marked as preserved.\n  ///\n  /// Note that you can only abandon a specific analysis, not a *set* of\n  /// analyses.\n  void abandon(AnalysisKey *ID) {\n    PreservedIDs.erase(ID);\n    NotPreservedAnalysisIDs.insert(ID);\n  }\n\n  /// Intersect this set with another in place.\n  ///\n  /// This is a mutating operation on this preserved set, removing all\n  /// preserved passes which are not also preserved in the argument.\n  void intersect(const PreservedAnalyses &Arg) {\n    if (Arg.areAllPreserved())\n      return;\n    if (areAllPreserved()) {\n      *this = Arg;\n      return;\n    }\n    // The intersection requires the *union* of the explicitly not-preserved\n    // IDs and the *intersection* of the preserved IDs.\n    for (auto ID : Arg.NotPreservedAnalysisIDs) {\n      PreservedIDs.erase(ID);\n      NotPreservedAnalysisIDs.insert(ID);\n    }\n    for (auto ID : PreservedIDs)\n      if (!Arg.PreservedIDs.count(ID))\n        PreservedIDs.erase(ID);\n  }\n\n  /// Intersect this set with a temporary other set in place.\n  ///\n  /// This is a mutating operation on this preserved set, removing all\n  /// preserved passes which are not also preserved in the argument.\n  void intersect(PreservedAnalyses &&Arg) {\n    if (Arg.areAllPreserved())\n      return;\n    if (areAllPreserved()) {\n      *this = std::move(Arg);\n      return;\n    }\n    // The intersection requires the *union* of the explicitly not-preserved\n    // IDs and the *intersection* of the preserved IDs.\n    for (auto ID : Arg.NotPreservedAnalysisIDs) {\n      PreservedIDs.erase(ID);\n      NotPreservedAnalysisIDs.insert(ID);\n    }\n    for (auto ID : PreservedIDs)\n      if (!Arg.PreservedIDs.count(ID))\n        PreservedIDs.erase(ID);\n  }\n\n  /// A checker object that makes it easy to query for whether an analysis or\n  /// some set covering it is preserved.\n  class PreservedAnalysisChecker {\n    friend class PreservedAnalyses;\n\n    const PreservedAnalyses &PA;\n    AnalysisKey *const ID;\n    const bool IsAbandoned;\n\n    /// A PreservedAnalysisChecker is tied to a particular Analysis because\n    /// `preserved()` and `preservedSet()` both return false if the Analysis\n    /// was abandoned.\n    PreservedAnalysisChecker(const PreservedAnalyses &PA, AnalysisKey *ID)\n        : PA(PA), ID(ID), IsAbandoned(PA.NotPreservedAnalysisIDs.count(ID)) {}\n\n  public:\n    /// Returns true if the checker's analysis was not abandoned and either\n    ///  - the analysis is explicitly preserved or\n    ///  - all analyses are preserved.\n    bool preserved() {\n      return !IsAbandoned && (PA.PreservedIDs.count(&AllAnalysesKey) ||\n                              PA.PreservedIDs.count(ID));\n    }\n\n    /// Return true if the checker's analysis was not abandoned, i.e. it was not\n    /// explicitly invalidated. Even if the analysis is not explicitly\n    /// preserved, if the analysis is known stateless, then it is preserved.\n    bool preservedWhenStateless() {\n      return !IsAbandoned;\n    }\n\n    /// Returns true if the checker's analysis was not abandoned and either\n    ///  - \\p AnalysisSetT is explicitly preserved or\n    ///  - all analyses are preserved.\n    template <typename AnalysisSetT> bool preservedSet() {\n      AnalysisSetKey *SetID = AnalysisSetT::ID();\n      return !IsAbandoned && (PA.PreservedIDs.count(&AllAnalysesKey) ||\n                              PA.PreservedIDs.count(SetID));\n    }\n  };\n\n  /// Build a checker for this `PreservedAnalyses` and the specified analysis\n  /// type.\n  ///\n  /// You can use the returned object to query whether an analysis was\n  /// preserved. See the example in the comment on `PreservedAnalysis`.\n  template <typename AnalysisT> PreservedAnalysisChecker getChecker() const {\n    return PreservedAnalysisChecker(*this, AnalysisT::ID());\n  }\n\n  /// Build a checker for this `PreservedAnalyses` and the specified analysis\n  /// ID.\n  ///\n  /// You can use the returned object to query whether an analysis was\n  /// preserved. See the example in the comment on `PreservedAnalysis`.\n  PreservedAnalysisChecker getChecker(AnalysisKey *ID) const {\n    return PreservedAnalysisChecker(*this, ID);\n  }\n\n  /// Test whether all analyses are preserved (and none are abandoned).\n  ///\n  /// This is used primarily to optimize for the common case of a transformation\n  /// which makes no changes to the IR.\n  bool areAllPreserved() const {\n    return NotPreservedAnalysisIDs.empty() &&\n           PreservedIDs.count(&AllAnalysesKey);\n  }\n\n  /// Directly test whether a set of analyses is preserved.\n  ///\n  /// This is only true when no analyses have been explicitly abandoned.\n  template <typename AnalysisSetT> bool allAnalysesInSetPreserved() const {\n    return allAnalysesInSetPreserved(AnalysisSetT::ID());\n  }\n\n  /// Directly test whether a set of analyses is preserved.\n  ///\n  /// This is only true when no analyses have been explicitly abandoned.\n  bool allAnalysesInSetPreserved(AnalysisSetKey *SetID) const {\n    return NotPreservedAnalysisIDs.empty() &&\n           (PreservedIDs.count(&AllAnalysesKey) || PreservedIDs.count(SetID));\n  }\n\nprivate:\n  /// A special key used to indicate all analyses.\n  static AnalysisSetKey AllAnalysesKey;\n\n  /// The IDs of analyses and analysis sets that are preserved.\n  SmallPtrSet<void *, 2> PreservedIDs;\n\n  /// The IDs of explicitly not-preserved analyses.\n  ///\n  /// If an analysis in this set is covered by a set in `PreservedIDs`, we\n  /// consider it not-preserved. That is, `NotPreservedAnalysisIDs` always\n  /// \"wins\" over analysis sets in `PreservedIDs`.\n  ///\n  /// Also, a given ID should never occur both here and in `PreservedIDs`.\n  SmallPtrSet<AnalysisKey *, 2> NotPreservedAnalysisIDs;\n};\n\n// Forward declare the analysis manager template.\ntemplate <typename IRUnitT, typename... ExtraArgTs> class AnalysisManager;\n\n/// A CRTP mix-in to automatically provide informational APIs needed for\n/// passes.\n///\n/// This provides some boilerplate for types that are passes.\ntemplate <typename DerivedT> struct PassInfoMixin {\n  /// Gets the name of the pass we are mixed into.\n  static StringRef name() {\n    static_assert(std::is_base_of<PassInfoMixin, DerivedT>::value,\n                  \"Must pass the derived type as the template argument!\");\n    StringRef Name = getTypeName<DerivedT>();\n    if (Name.startswith(\"llvm::\"))\n      Name = Name.drop_front(strlen(\"llvm::\"));\n    return Name;\n  }\n};\n\n/// A CRTP mix-in that provides informational APIs needed for analysis passes.\n///\n/// This provides some boilerplate for types that are analysis passes. It\n/// automatically mixes in \\c PassInfoMixin.\ntemplate <typename DerivedT>\nstruct AnalysisInfoMixin : PassInfoMixin<DerivedT> {\n  /// Returns an opaque, unique ID for this analysis type.\n  ///\n  /// This ID is a pointer type that is guaranteed to be 8-byte aligned and thus\n  /// suitable for use in sets, maps, and other data structures that use the low\n  /// bits of pointers.\n  ///\n  /// Note that this requires the derived type provide a static \\c AnalysisKey\n  /// member called \\c Key.\n  ///\n  /// FIXME: The only reason the mixin type itself can't declare the Key value\n  /// is that some compilers cannot correctly unique a templated static variable\n  /// so it has the same addresses in each instantiation. The only currently\n  /// known platform with this limitation is Windows DLL builds, specifically\n  /// building each part of LLVM as a DLL. If we ever remove that build\n  /// configuration, this mixin can provide the static key as well.\n  static AnalysisKey *ID() {\n    static_assert(std::is_base_of<AnalysisInfoMixin, DerivedT>::value,\n                  \"Must pass the derived type as the template argument!\");\n    return &DerivedT::Key;\n  }\n};\n\nnamespace detail {\n\n/// Actual unpacker of extra arguments in getAnalysisResult,\n/// passes only those tuple arguments that are mentioned in index_sequence.\ntemplate <typename PassT, typename IRUnitT, typename AnalysisManagerT,\n          typename... ArgTs, size_t... Ns>\ntypename PassT::Result\ngetAnalysisResultUnpackTuple(AnalysisManagerT &AM, IRUnitT &IR,\n                             std::tuple<ArgTs...> Args,\n                             std::index_sequence<Ns...>) {\n  (void)Args;\n  return AM.template getResult<PassT>(IR, std::get<Ns>(Args)...);\n}\n\n/// Helper for *partial* unpacking of extra arguments in getAnalysisResult.\n///\n/// Arguments passed in tuple come from PassManager, so they might have extra\n/// arguments after those AnalysisManager's ExtraArgTs ones that we need to\n/// pass to getResult.\ntemplate <typename PassT, typename IRUnitT, typename... AnalysisArgTs,\n          typename... MainArgTs>\ntypename PassT::Result\ngetAnalysisResult(AnalysisManager<IRUnitT, AnalysisArgTs...> &AM, IRUnitT &IR,\n                  std::tuple<MainArgTs...> Args) {\n  return (getAnalysisResultUnpackTuple<\n          PassT, IRUnitT>)(AM, IR, Args,\n                           std::index_sequence_for<AnalysisArgTs...>{});\n}\n\n} // namespace detail\n\n// Forward declare the pass instrumentation analysis explicitly queried in\n// generic PassManager code.\n// FIXME: figure out a way to move PassInstrumentationAnalysis into its own\n// header.\nclass PassInstrumentationAnalysis;\n\n/// Manages a sequence of passes over a particular unit of IR.\n///\n/// A pass manager contains a sequence of passes to run over a particular unit\n/// of IR (e.g. Functions, Modules). It is itself a valid pass over that unit of\n/// IR, and when run over some given IR will run each of its contained passes in\n/// sequence. Pass managers are the primary and most basic building block of a\n/// pass pipeline.\n///\n/// When you run a pass manager, you provide an \\c AnalysisManager<IRUnitT>\n/// argument. The pass manager will propagate that analysis manager to each\n/// pass it runs, and will call the analysis manager's invalidation routine with\n/// the PreservedAnalyses of each pass it runs.\ntemplate <typename IRUnitT,\n          typename AnalysisManagerT = AnalysisManager<IRUnitT>,\n          typename... ExtraArgTs>\nclass PassManager : public PassInfoMixin<\n                        PassManager<IRUnitT, AnalysisManagerT, ExtraArgTs...>> {\npublic:\n  /// Construct a pass manager.\n  ///\n  /// If \\p DebugLogging is true, we'll log our progress to llvm::dbgs().\n  explicit PassManager(bool DebugLogging = false) : DebugLogging(DebugLogging) {}\n\n  // FIXME: These are equivalent to the default move constructor/move\n  // assignment. However, using = default triggers linker errors due to the\n  // explicit instantiations below. Find away to use the default and remove the\n  // duplicated code here.\n  PassManager(PassManager &&Arg)\n      : Passes(std::move(Arg.Passes)),\n        DebugLogging(std::move(Arg.DebugLogging)) {}\n\n  PassManager &operator=(PassManager &&RHS) {\n    Passes = std::move(RHS.Passes);\n    DebugLogging = std::move(RHS.DebugLogging);\n    return *this;\n  }\n\n  /// Run all of the passes in this manager over the given unit of IR.\n  /// ExtraArgs are passed to each pass.\n  PreservedAnalyses run(IRUnitT &IR, AnalysisManagerT &AM,\n                        ExtraArgTs... ExtraArgs) {\n    PreservedAnalyses PA = PreservedAnalyses::all();\n\n    // Request PassInstrumentation from analysis manager, will use it to run\n    // instrumenting callbacks for the passes later.\n    // Here we use std::tuple wrapper over getResult which helps to extract\n    // AnalysisManager's arguments out of the whole ExtraArgs set.\n    PassInstrumentation PI =\n        detail::getAnalysisResult<PassInstrumentationAnalysis>(\n            AM, IR, std::tuple<ExtraArgTs...>(ExtraArgs...));\n\n    if (DebugLogging)\n      dbgs() << \"Starting \" << getTypeName<IRUnitT>() << \" pass manager run.\\n\";\n\n    for (unsigned Idx = 0, Size = Passes.size(); Idx != Size; ++Idx) {\n      auto *P = Passes[Idx].get();\n\n      // Check the PassInstrumentation's BeforePass callbacks before running the\n      // pass, skip its execution completely if asked to (callback returns\n      // false).\n      if (!PI.runBeforePass<IRUnitT>(*P, IR))\n        continue;\n\n      PreservedAnalyses PassPA;\n      {\n        TimeTraceScope TimeScope(P->name(), IR.getName());\n        PassPA = P->run(IR, AM, ExtraArgs...);\n      }\n\n      // Call onto PassInstrumentation's AfterPass callbacks immediately after\n      // running the pass.\n      PI.runAfterPass<IRUnitT>(*P, IR, PassPA);\n\n      // Update the analysis manager as each pass runs and potentially\n      // invalidates analyses.\n      AM.invalidate(IR, PassPA);\n\n      // Finally, intersect the preserved analyses to compute the aggregate\n      // preserved set for this pass manager.\n      PA.intersect(std::move(PassPA));\n\n      // FIXME: Historically, the pass managers all called the LLVM context's\n      // yield function here. We don't have a generic way to acquire the\n      // context and it isn't yet clear what the right pattern is for yielding\n      // in the new pass manager so it is currently omitted.\n      //IR.getContext().yield();\n    }\n\n    // Invalidation was handled after each pass in the above loop for the\n    // current unit of IR. Therefore, the remaining analysis results in the\n    // AnalysisManager are preserved. We mark this with a set so that we don't\n    // need to inspect each one individually.\n    PA.preserveSet<AllAnalysesOn<IRUnitT>>();\n\n    if (DebugLogging)\n      dbgs() << \"Finished \" << getTypeName<IRUnitT>() << \" pass manager run.\\n\";\n\n    return PA;\n  }\n\n  template <typename PassT>\n  std::enable_if_t<!std::is_same<PassT, PassManager>::value>\n  addPass(PassT Pass) {\n    using PassModelT =\n        detail::PassModel<IRUnitT, PassT, PreservedAnalyses, AnalysisManagerT,\n                          ExtraArgTs...>;\n\n    Passes.emplace_back(new PassModelT(std::move(Pass)));\n  }\n\n  /// When adding a pass manager pass that has the same type as this pass\n  /// manager, simply move the passes over. This is because we don't have use\n  /// cases rely on executing nested pass managers. Doing this could reduce\n  /// implementation complexity and avoid potential invalidation issues that may\n  /// happen with nested pass managers of the same type.\n  template <typename PassT>\n  std::enable_if_t<std::is_same<PassT, PassManager>::value>\n  addPass(PassT &&Pass) {\n    for (auto &P : Pass.Passes)\n      Passes.emplace_back(std::move(P));\n  }\n\n  /// Returns if the pass manager contains any passes.\n  bool isEmpty() const { return Passes.empty(); }\n\n  static bool isRequired() { return true; }\n\nprotected:\n  using PassConceptT =\n      detail::PassConcept<IRUnitT, AnalysisManagerT, ExtraArgTs...>;\n\n  std::vector<std::unique_ptr<PassConceptT>> Passes;\n\n  /// Flag indicating whether we should do debug logging.\n  bool DebugLogging;\n};\n\nextern template class PassManager<Module>;\n\n/// Convenience typedef for a pass manager over modules.\nusing ModulePassManager = PassManager<Module>;\n\nextern template class PassManager<Function>;\n\n/// Convenience typedef for a pass manager over functions.\nusing FunctionPassManager = PassManager<Function>;\n\n/// Pseudo-analysis pass that exposes the \\c PassInstrumentation to pass\n/// managers. Goes before AnalysisManager definition to provide its\n/// internals (e.g PassInstrumentationAnalysis::ID) for use there if needed.\n/// FIXME: figure out a way to move PassInstrumentationAnalysis into its own\n/// header.\nclass PassInstrumentationAnalysis\n    : public AnalysisInfoMixin<PassInstrumentationAnalysis> {\n  friend AnalysisInfoMixin<PassInstrumentationAnalysis>;\n  static AnalysisKey Key;\n\n  PassInstrumentationCallbacks *Callbacks;\n\npublic:\n  /// PassInstrumentationCallbacks object is shared, owned by something else,\n  /// not this analysis.\n  PassInstrumentationAnalysis(PassInstrumentationCallbacks *Callbacks = nullptr)\n      : Callbacks(Callbacks) {}\n\n  using Result = PassInstrumentation;\n\n  template <typename IRUnitT, typename AnalysisManagerT, typename... ExtraArgTs>\n  Result run(IRUnitT &, AnalysisManagerT &, ExtraArgTs &&...) {\n    return PassInstrumentation(Callbacks);\n  }\n};\n\n/// A container for analyses that lazily runs them and caches their\n/// results.\n///\n/// This class can manage analyses for any IR unit where the address of the IR\n/// unit sufficies as its identity.\ntemplate <typename IRUnitT, typename... ExtraArgTs> class AnalysisManager {\npublic:\n  class Invalidator;\n\nprivate:\n  // Now that we've defined our invalidator, we can define the concept types.\n  using ResultConceptT =\n      detail::AnalysisResultConcept<IRUnitT, PreservedAnalyses, Invalidator>;\n  using PassConceptT =\n      detail::AnalysisPassConcept<IRUnitT, PreservedAnalyses, Invalidator,\n                                  ExtraArgTs...>;\n\n  /// List of analysis pass IDs and associated concept pointers.\n  ///\n  /// Requires iterators to be valid across appending new entries and arbitrary\n  /// erases. Provides the analysis ID to enable finding iterators to a given\n  /// entry in maps below, and provides the storage for the actual result\n  /// concept.\n  using AnalysisResultListT =\n      std::list<std::pair<AnalysisKey *, std::unique_ptr<ResultConceptT>>>;\n\n  /// Map type from IRUnitT pointer to our custom list type.\n  using AnalysisResultListMapT = DenseMap<IRUnitT *, AnalysisResultListT>;\n\n  /// Map type from a pair of analysis ID and IRUnitT pointer to an\n  /// iterator into a particular result list (which is where the actual analysis\n  /// result is stored).\n  using AnalysisResultMapT =\n      DenseMap<std::pair<AnalysisKey *, IRUnitT *>,\n               typename AnalysisResultListT::iterator>;\n\npublic:\n  /// API to communicate dependencies between analyses during invalidation.\n  ///\n  /// When an analysis result embeds handles to other analysis results, it\n  /// needs to be invalidated both when its own information isn't preserved and\n  /// when any of its embedded analysis results end up invalidated. We pass an\n  /// \\c Invalidator object as an argument to \\c invalidate() in order to let\n  /// the analysis results themselves define the dependency graph on the fly.\n  /// This lets us avoid building an explicit representation of the\n  /// dependencies between analysis results.\n  class Invalidator {\n  public:\n    /// Trigger the invalidation of some other analysis pass if not already\n    /// handled and return whether it was in fact invalidated.\n    ///\n    /// This is expected to be called from within a given analysis result's \\c\n    /// invalidate method to trigger a depth-first walk of all inter-analysis\n    /// dependencies. The same \\p IR unit and \\p PA passed to that result's \\c\n    /// invalidate method should in turn be provided to this routine.\n    ///\n    /// The first time this is called for a given analysis pass, it will call\n    /// the corresponding result's \\c invalidate method.  Subsequent calls will\n    /// use a cache of the results of that initial call.  It is an error to form\n    /// cyclic dependencies between analysis results.\n    ///\n    /// This returns true if the given analysis's result is invalid. Any\n    /// dependecies on it will become invalid as a result.\n    template <typename PassT>\n    bool invalidate(IRUnitT &IR, const PreservedAnalyses &PA) {\n      using ResultModelT =\n          detail::AnalysisResultModel<IRUnitT, PassT, typename PassT::Result,\n                                      PreservedAnalyses, Invalidator>;\n\n      return invalidateImpl<ResultModelT>(PassT::ID(), IR, PA);\n    }\n\n    /// A type-erased variant of the above invalidate method with the same core\n    /// API other than passing an analysis ID rather than an analysis type\n    /// parameter.\n    ///\n    /// This is sadly less efficient than the above routine, which leverages\n    /// the type parameter to avoid the type erasure overhead.\n    bool invalidate(AnalysisKey *ID, IRUnitT &IR, const PreservedAnalyses &PA) {\n      return invalidateImpl<>(ID, IR, PA);\n    }\n\n  private:\n    friend class AnalysisManager;\n\n    template <typename ResultT = ResultConceptT>\n    bool invalidateImpl(AnalysisKey *ID, IRUnitT &IR,\n                        const PreservedAnalyses &PA) {\n      // If we've already visited this pass, return true if it was invalidated\n      // and false otherwise.\n      auto IMapI = IsResultInvalidated.find(ID);\n      if (IMapI != IsResultInvalidated.end())\n        return IMapI->second;\n\n      // Otherwise look up the result object.\n      auto RI = Results.find({ID, &IR});\n      assert(RI != Results.end() &&\n             \"Trying to invalidate a dependent result that isn't in the \"\n             \"manager's cache is always an error, likely due to a stale result \"\n             \"handle!\");\n\n      auto &Result = static_cast<ResultT &>(*RI->second->second);\n\n      // Insert into the map whether the result should be invalidated and return\n      // that. Note that we cannot reuse IMapI and must do a fresh insert here,\n      // as calling invalidate could (recursively) insert things into the map,\n      // making any iterator or reference invalid.\n      bool Inserted;\n      std::tie(IMapI, Inserted) =\n          IsResultInvalidated.insert({ID, Result.invalidate(IR, PA, *this)});\n      (void)Inserted;\n      assert(Inserted && \"Should not have already inserted this ID, likely \"\n                         \"indicates a dependency cycle!\");\n      return IMapI->second;\n    }\n\n    Invalidator(SmallDenseMap<AnalysisKey *, bool, 8> &IsResultInvalidated,\n                const AnalysisResultMapT &Results)\n        : IsResultInvalidated(IsResultInvalidated), Results(Results) {}\n\n    SmallDenseMap<AnalysisKey *, bool, 8> &IsResultInvalidated;\n    const AnalysisResultMapT &Results;\n  };\n\n  /// Construct an empty analysis manager.\n  ///\n  /// If \\p DebugLogging is true, we'll log our progress to llvm::dbgs().\n  AnalysisManager(bool DebugLogging = false);\n  AnalysisManager(AnalysisManager &&);\n  AnalysisManager &operator=(AnalysisManager &&);\n\n  /// Returns true if the analysis manager has an empty results cache.\n  bool empty() const {\n    assert(AnalysisResults.empty() == AnalysisResultLists.empty() &&\n           \"The storage and index of analysis results disagree on how many \"\n           \"there are!\");\n    return AnalysisResults.empty();\n  }\n\n  /// Clear any cached analysis results for a single unit of IR.\n  ///\n  /// This doesn't invalidate, but instead simply deletes, the relevant results.\n  /// It is useful when the IR is being removed and we want to clear out all the\n  /// memory pinned for it.\n  void clear(IRUnitT &IR, llvm::StringRef Name);\n\n  /// Clear all analysis results cached by this AnalysisManager.\n  ///\n  /// Like \\c clear(IRUnitT&), this doesn't invalidate the results; it simply\n  /// deletes them.  This lets you clean up the AnalysisManager when the set of\n  /// IR units itself has potentially changed, and thus we can't even look up a\n  /// a result and invalidate/clear it directly.\n  void clear() {\n    AnalysisResults.clear();\n    AnalysisResultLists.clear();\n  }\n\n  /// Get the result of an analysis pass for a given IR unit.\n  ///\n  /// Runs the analysis if a cached result is not available.\n  template <typename PassT>\n  typename PassT::Result &getResult(IRUnitT &IR, ExtraArgTs... ExtraArgs) {\n    assert(AnalysisPasses.count(PassT::ID()) &&\n           \"This analysis pass was not registered prior to being queried\");\n    ResultConceptT &ResultConcept =\n        getResultImpl(PassT::ID(), IR, ExtraArgs...);\n\n    using ResultModelT =\n        detail::AnalysisResultModel<IRUnitT, PassT, typename PassT::Result,\n                                    PreservedAnalyses, Invalidator>;\n\n    return static_cast<ResultModelT &>(ResultConcept).Result;\n  }\n\n  /// Get the cached result of an analysis pass for a given IR unit.\n  ///\n  /// This method never runs the analysis.\n  ///\n  /// \\returns null if there is no cached result.\n  template <typename PassT>\n  typename PassT::Result *getCachedResult(IRUnitT &IR) const {\n    assert(AnalysisPasses.count(PassT::ID()) &&\n           \"This analysis pass was not registered prior to being queried\");\n\n    ResultConceptT *ResultConcept = getCachedResultImpl(PassT::ID(), IR);\n    if (!ResultConcept)\n      return nullptr;\n\n    using ResultModelT =\n        detail::AnalysisResultModel<IRUnitT, PassT, typename PassT::Result,\n                                    PreservedAnalyses, Invalidator>;\n\n    return &static_cast<ResultModelT *>(ResultConcept)->Result;\n  }\n\n  /// Verify that the given Result cannot be invalidated, assert otherwise.\n  template <typename PassT>\n  void verifyNotInvalidated(IRUnitT &IR, typename PassT::Result *Result) const {\n    PreservedAnalyses PA = PreservedAnalyses::none();\n    SmallDenseMap<AnalysisKey *, bool, 8> IsResultInvalidated;\n    Invalidator Inv(IsResultInvalidated, AnalysisResults);\n    assert(!Result->invalidate(IR, PA, Inv) &&\n           \"Cached result cannot be invalidated\");\n  }\n\n  /// Register an analysis pass with the manager.\n  ///\n  /// The parameter is a callable whose result is an analysis pass. This allows\n  /// passing in a lambda to construct the analysis.\n  ///\n  /// The analysis type to register is the type returned by calling the \\c\n  /// PassBuilder argument. If that type has already been registered, then the\n  /// argument will not be called and this function will return false.\n  /// Otherwise, we register the analysis returned by calling \\c PassBuilder(),\n  /// and this function returns true.\n  ///\n  /// (Note: Although the return value of this function indicates whether or not\n  /// an analysis was previously registered, there intentionally isn't a way to\n  /// query this directly.  Instead, you should just register all the analyses\n  /// you might want and let this class run them lazily.  This idiom lets us\n  /// minimize the number of times we have to look up analyses in our\n  /// hashtable.)\n  template <typename PassBuilderT>\n  bool registerPass(PassBuilderT &&PassBuilder) {\n    using PassT = decltype(PassBuilder());\n    using PassModelT =\n        detail::AnalysisPassModel<IRUnitT, PassT, PreservedAnalyses,\n                                  Invalidator, ExtraArgTs...>;\n\n    auto &PassPtr = AnalysisPasses[PassT::ID()];\n    if (PassPtr)\n      // Already registered this pass type!\n      return false;\n\n    // Construct a new model around the instance returned by the builder.\n    PassPtr.reset(new PassModelT(PassBuilder()));\n    return true;\n  }\n\n  /// Invalidate a specific analysis pass for an IR unit.\n  ///\n  /// Note that the analysis result can disregard invalidation, if it determines\n  /// it is in fact still valid.\n  template <typename PassT> void invalidate(IRUnitT &IR) {\n    assert(AnalysisPasses.count(PassT::ID()) &&\n           \"This analysis pass was not registered prior to being invalidated\");\n    invalidateImpl(PassT::ID(), IR);\n  }\n\n  /// Invalidate cached analyses for an IR unit.\n  ///\n  /// Walk through all of the analyses pertaining to this unit of IR and\n  /// invalidate them, unless they are preserved by the PreservedAnalyses set.\n  void invalidate(IRUnitT &IR, const PreservedAnalyses &PA);\n\nprivate:\n  /// Look up a registered analysis pass.\n  PassConceptT &lookUpPass(AnalysisKey *ID) {\n    typename AnalysisPassMapT::iterator PI = AnalysisPasses.find(ID);\n    assert(PI != AnalysisPasses.end() &&\n           \"Analysis passes must be registered prior to being queried!\");\n    return *PI->second;\n  }\n\n  /// Look up a registered analysis pass.\n  const PassConceptT &lookUpPass(AnalysisKey *ID) const {\n    typename AnalysisPassMapT::const_iterator PI = AnalysisPasses.find(ID);\n    assert(PI != AnalysisPasses.end() &&\n           \"Analysis passes must be registered prior to being queried!\");\n    return *PI->second;\n  }\n\n  /// Get an analysis result, running the pass if necessary.\n  ResultConceptT &getResultImpl(AnalysisKey *ID, IRUnitT &IR,\n                                ExtraArgTs... ExtraArgs);\n\n  /// Get a cached analysis result or return null.\n  ResultConceptT *getCachedResultImpl(AnalysisKey *ID, IRUnitT &IR) const {\n    typename AnalysisResultMapT::const_iterator RI =\n        AnalysisResults.find({ID, &IR});\n    return RI == AnalysisResults.end() ? nullptr : &*RI->second->second;\n  }\n\n  /// Invalidate a pass result for a IR unit.\n  void invalidateImpl(AnalysisKey *ID, IRUnitT &IR) {\n    typename AnalysisResultMapT::iterator RI =\n        AnalysisResults.find({ID, &IR});\n    if (RI == AnalysisResults.end())\n      return;\n\n    if (DebugLogging)\n      dbgs() << \"Invalidating analysis: \" << this->lookUpPass(ID).name()\n             << \" on \" << IR.getName() << \"\\n\";\n    AnalysisResultLists[&IR].erase(RI->second);\n    AnalysisResults.erase(RI);\n  }\n\n  /// Map type from analysis pass ID to pass concept pointer.\n  using AnalysisPassMapT =\n      DenseMap<AnalysisKey *, std::unique_ptr<PassConceptT>>;\n\n  /// Collection of analysis passes, indexed by ID.\n  AnalysisPassMapT AnalysisPasses;\n\n  /// Map from IR unit to a list of analysis results.\n  ///\n  /// Provides linear time removal of all analysis results for a IR unit and\n  /// the ultimate storage for a particular cached analysis result.\n  AnalysisResultListMapT AnalysisResultLists;\n\n  /// Map from an analysis ID and IR unit to a particular cached\n  /// analysis result.\n  AnalysisResultMapT AnalysisResults;\n\n  /// Indicates whether we log to \\c llvm::dbgs().\n  bool DebugLogging;\n};\n\nextern template class AnalysisManager<Module>;\n\n/// Convenience typedef for the Module analysis manager.\nusing ModuleAnalysisManager = AnalysisManager<Module>;\n\nextern template class AnalysisManager<Function>;\n\n/// Convenience typedef for the Function analysis manager.\nusing FunctionAnalysisManager = AnalysisManager<Function>;\n\n/// An analysis over an \"outer\" IR unit that provides access to an\n/// analysis manager over an \"inner\" IR unit.  The inner unit must be contained\n/// in the outer unit.\n///\n/// For example, InnerAnalysisManagerProxy<FunctionAnalysisManager, Module> is\n/// an analysis over Modules (the \"outer\" unit) that provides access to a\n/// Function analysis manager.  The FunctionAnalysisManager is the \"inner\"\n/// manager being proxied, and Functions are the \"inner\" unit.  The inner/outer\n/// relationship is valid because each Function is contained in one Module.\n///\n/// If you're (transitively) within a pass manager for an IR unit U that\n/// contains IR unit V, you should never use an analysis manager over V, except\n/// via one of these proxies.\n///\n/// Note that the proxy's result is a move-only RAII object.  The validity of\n/// the analyses in the inner analysis manager is tied to its lifetime.\ntemplate <typename AnalysisManagerT, typename IRUnitT, typename... ExtraArgTs>\nclass InnerAnalysisManagerProxy\n    : public AnalysisInfoMixin<\n          InnerAnalysisManagerProxy<AnalysisManagerT, IRUnitT>> {\npublic:\n  class Result {\n  public:\n    explicit Result(AnalysisManagerT &InnerAM) : InnerAM(&InnerAM) {}\n\n    Result(Result &&Arg) : InnerAM(std::move(Arg.InnerAM)) {\n      // We have to null out the analysis manager in the moved-from state\n      // because we are taking ownership of the responsibilty to clear the\n      // analysis state.\n      Arg.InnerAM = nullptr;\n    }\n\n    ~Result() {\n      // InnerAM is cleared in a moved from state where there is nothing to do.\n      if (!InnerAM)\n        return;\n\n      // Clear out the analysis manager if we're being destroyed -- it means we\n      // didn't even see an invalidate call when we got invalidated.\n      InnerAM->clear();\n    }\n\n    Result &operator=(Result &&RHS) {\n      InnerAM = RHS.InnerAM;\n      // We have to null out the analysis manager in the moved-from state\n      // because we are taking ownership of the responsibilty to clear the\n      // analysis state.\n      RHS.InnerAM = nullptr;\n      return *this;\n    }\n\n    /// Accessor for the analysis manager.\n    AnalysisManagerT &getManager() { return *InnerAM; }\n\n    /// Handler for invalidation of the outer IR unit, \\c IRUnitT.\n    ///\n    /// If the proxy analysis itself is not preserved, we assume that the set of\n    /// inner IR objects contained in IRUnit may have changed.  In this case,\n    /// we have to call \\c clear() on the inner analysis manager, as it may now\n    /// have stale pointers to its inner IR objects.\n    ///\n    /// Regardless of whether the proxy analysis is marked as preserved, all of\n    /// the analyses in the inner analysis manager are potentially invalidated\n    /// based on the set of preserved analyses.\n    bool invalidate(\n        IRUnitT &IR, const PreservedAnalyses &PA,\n        typename AnalysisManager<IRUnitT, ExtraArgTs...>::Invalidator &Inv);\n\n  private:\n    AnalysisManagerT *InnerAM;\n  };\n\n  explicit InnerAnalysisManagerProxy(AnalysisManagerT &InnerAM)\n      : InnerAM(&InnerAM) {}\n\n  /// Run the analysis pass and create our proxy result object.\n  ///\n  /// This doesn't do any interesting work; it is primarily used to insert our\n  /// proxy result object into the outer analysis cache so that we can proxy\n  /// invalidation to the inner analysis manager.\n  Result run(IRUnitT &IR, AnalysisManager<IRUnitT, ExtraArgTs...> &AM,\n             ExtraArgTs...) {\n    return Result(*InnerAM);\n  }\n\nprivate:\n  friend AnalysisInfoMixin<\n      InnerAnalysisManagerProxy<AnalysisManagerT, IRUnitT>>;\n\n  static AnalysisKey Key;\n\n  AnalysisManagerT *InnerAM;\n};\n\ntemplate <typename AnalysisManagerT, typename IRUnitT, typename... ExtraArgTs>\nAnalysisKey\n    InnerAnalysisManagerProxy<AnalysisManagerT, IRUnitT, ExtraArgTs...>::Key;\n\n/// Provide the \\c FunctionAnalysisManager to \\c Module proxy.\nusing FunctionAnalysisManagerModuleProxy =\n    InnerAnalysisManagerProxy<FunctionAnalysisManager, Module>;\n\n/// Specialization of the invalidate method for the \\c\n/// FunctionAnalysisManagerModuleProxy's result.\ntemplate <>\nbool FunctionAnalysisManagerModuleProxy::Result::invalidate(\n    Module &M, const PreservedAnalyses &PA,\n    ModuleAnalysisManager::Invalidator &Inv);\n\n// Ensure the \\c FunctionAnalysisManagerModuleProxy is provided as an extern\n// template.\nextern template class InnerAnalysisManagerProxy<FunctionAnalysisManager,\n                                                Module>;\n\n/// An analysis over an \"inner\" IR unit that provides access to an\n/// analysis manager over a \"outer\" IR unit.  The inner unit must be contained\n/// in the outer unit.\n///\n/// For example OuterAnalysisManagerProxy<ModuleAnalysisManager, Function> is an\n/// analysis over Functions (the \"inner\" unit) which provides access to a Module\n/// analysis manager.  The ModuleAnalysisManager is the \"outer\" manager being\n/// proxied, and Modules are the \"outer\" IR unit.  The inner/outer relationship\n/// is valid because each Function is contained in one Module.\n///\n/// This proxy only exposes the const interface of the outer analysis manager,\n/// to indicate that you cannot cause an outer analysis to run from within an\n/// inner pass.  Instead, you must rely on the \\c getCachedResult API.  This is\n/// due to keeping potential future concurrency in mind. To give an example,\n/// running a module analysis before any function passes may give a different\n/// result than running it in a function pass. Both may be valid, but it would\n/// produce non-deterministic results. GlobalsAA is a good analysis example,\n/// because the cached information has the mod/ref info for all memory for each\n/// function at the time the analysis was computed. The information is still\n/// valid after a function transformation, but it may be *different* if\n/// recomputed after that transform. GlobalsAA is never invalidated.\n\n///\n/// This proxy doesn't manage invalidation in any way -- that is handled by the\n/// recursive return path of each layer of the pass manager.  A consequence of\n/// this is the outer analyses may be stale.  We invalidate the outer analyses\n/// only when we're done running passes over the inner IR units.\ntemplate <typename AnalysisManagerT, typename IRUnitT, typename... ExtraArgTs>\nclass OuterAnalysisManagerProxy\n    : public AnalysisInfoMixin<\n          OuterAnalysisManagerProxy<AnalysisManagerT, IRUnitT, ExtraArgTs...>> {\npublic:\n  /// Result proxy object for \\c OuterAnalysisManagerProxy.\n  class Result {\n  public:\n    explicit Result(const AnalysisManagerT &OuterAM) : OuterAM(&OuterAM) {}\n\n    /// Get a cached analysis. If the analysis can be invalidated, this will\n    /// assert.\n    template <typename PassT, typename IRUnitTParam>\n    typename PassT::Result *getCachedResult(IRUnitTParam &IR) const {\n      typename PassT::Result *Res =\n          OuterAM->template getCachedResult<PassT>(IR);\n      if (Res)\n        OuterAM->template verifyNotInvalidated<PassT>(IR, Res);\n      return Res;\n    }\n\n    /// Method provided for unit testing, not intended for general use.\n    template <typename PassT, typename IRUnitTParam>\n    bool cachedResultExists(IRUnitTParam &IR) const {\n      typename PassT::Result *Res =\n          OuterAM->template getCachedResult<PassT>(IR);\n      return Res != nullptr;\n    }\n\n    /// When invalidation occurs, remove any registered invalidation events.\n    bool invalidate(\n        IRUnitT &IRUnit, const PreservedAnalyses &PA,\n        typename AnalysisManager<IRUnitT, ExtraArgTs...>::Invalidator &Inv) {\n      // Loop over the set of registered outer invalidation mappings and if any\n      // of them map to an analysis that is now invalid, clear it out.\n      SmallVector<AnalysisKey *, 4> DeadKeys;\n      for (auto &KeyValuePair : OuterAnalysisInvalidationMap) {\n        AnalysisKey *OuterID = KeyValuePair.first;\n        auto &InnerIDs = KeyValuePair.second;\n        llvm::erase_if(InnerIDs, [&](AnalysisKey *InnerID) {\n          return Inv.invalidate(InnerID, IRUnit, PA);\n        });\n        if (InnerIDs.empty())\n          DeadKeys.push_back(OuterID);\n      }\n\n      for (auto OuterID : DeadKeys)\n        OuterAnalysisInvalidationMap.erase(OuterID);\n\n      // The proxy itself remains valid regardless of anything else.\n      return false;\n    }\n\n    /// Register a deferred invalidation event for when the outer analysis\n    /// manager processes its invalidations.\n    template <typename OuterAnalysisT, typename InvalidatedAnalysisT>\n    void registerOuterAnalysisInvalidation() {\n      AnalysisKey *OuterID = OuterAnalysisT::ID();\n      AnalysisKey *InvalidatedID = InvalidatedAnalysisT::ID();\n\n      auto &InvalidatedIDList = OuterAnalysisInvalidationMap[OuterID];\n      // Note, this is a linear scan. If we end up with large numbers of\n      // analyses that all trigger invalidation on the same outer analysis,\n      // this entire system should be changed to some other deterministic\n      // data structure such as a `SetVector` of a pair of pointers.\n      if (!llvm::is_contained(InvalidatedIDList, InvalidatedID))\n        InvalidatedIDList.push_back(InvalidatedID);\n    }\n\n    /// Access the map from outer analyses to deferred invalidation requiring\n    /// analyses.\n    const SmallDenseMap<AnalysisKey *, TinyPtrVector<AnalysisKey *>, 2> &\n    getOuterInvalidations() const {\n      return OuterAnalysisInvalidationMap;\n    }\n\n  private:\n    const AnalysisManagerT *OuterAM;\n\n    /// A map from an outer analysis ID to the set of this IR-unit's analyses\n    /// which need to be invalidated.\n    SmallDenseMap<AnalysisKey *, TinyPtrVector<AnalysisKey *>, 2>\n        OuterAnalysisInvalidationMap;\n  };\n\n  OuterAnalysisManagerProxy(const AnalysisManagerT &OuterAM)\n      : OuterAM(&OuterAM) {}\n\n  /// Run the analysis pass and create our proxy result object.\n  /// Nothing to see here, it just forwards the \\c OuterAM reference into the\n  /// result.\n  Result run(IRUnitT &, AnalysisManager<IRUnitT, ExtraArgTs...> &,\n             ExtraArgTs...) {\n    return Result(*OuterAM);\n  }\n\nprivate:\n  friend AnalysisInfoMixin<\n      OuterAnalysisManagerProxy<AnalysisManagerT, IRUnitT, ExtraArgTs...>>;\n\n  static AnalysisKey Key;\n\n  const AnalysisManagerT *OuterAM;\n};\n\ntemplate <typename AnalysisManagerT, typename IRUnitT, typename... ExtraArgTs>\nAnalysisKey\n    OuterAnalysisManagerProxy<AnalysisManagerT, IRUnitT, ExtraArgTs...>::Key;\n\nextern template class OuterAnalysisManagerProxy<ModuleAnalysisManager,\n                                                Function>;\n/// Provide the \\c ModuleAnalysisManager to \\c Function proxy.\nusing ModuleAnalysisManagerFunctionProxy =\n    OuterAnalysisManagerProxy<ModuleAnalysisManager, Function>;\n\n/// Trivial adaptor that maps from a module to its functions.\n///\n/// Designed to allow composition of a FunctionPass(Manager) and\n/// a ModulePassManager, by running the FunctionPass(Manager) over every\n/// function in the module.\n///\n/// Function passes run within this adaptor can rely on having exclusive access\n/// to the function they are run over. They should not read or modify any other\n/// functions! Other threads or systems may be manipulating other functions in\n/// the module, and so their state should never be relied on.\n/// FIXME: Make the above true for all of LLVM's actual passes, some still\n/// violate this principle.\n///\n/// Function passes can also read the module containing the function, but they\n/// should not modify that module outside of the use lists of various globals.\n/// For example, a function pass is not permitted to add functions to the\n/// module.\n/// FIXME: Make the above true for all of LLVM's actual passes, some still\n/// violate this principle.\n///\n/// Note that although function passes can access module analyses, module\n/// analyses are not invalidated while the function passes are running, so they\n/// may be stale.  Function analyses will not be stale.\nclass ModuleToFunctionPassAdaptor\n    : public PassInfoMixin<ModuleToFunctionPassAdaptor> {\npublic:\n  using PassConceptT = detail::PassConcept<Function, FunctionAnalysisManager>;\n\n  explicit ModuleToFunctionPassAdaptor(std::unique_ptr<PassConceptT> Pass)\n      : Pass(std::move(Pass)) {}\n\n  /// Runs the function pass across every function in the module.\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n\n  static bool isRequired() { return true; }\n\nprivate:\n  std::unique_ptr<PassConceptT> Pass;\n};\n\n/// A function to deduce a function pass type and wrap it in the\n/// templated adaptor.\ntemplate <typename FunctionPassT>\nModuleToFunctionPassAdaptor\ncreateModuleToFunctionPassAdaptor(FunctionPassT Pass) {\n  using PassModelT =\n      detail::PassModel<Function, FunctionPassT, PreservedAnalyses,\n                        FunctionAnalysisManager>;\n\n  return ModuleToFunctionPassAdaptor(\n      std::make_unique<PassModelT>(std::move(Pass)));\n}\n\n/// A utility pass template to force an analysis result to be available.\n///\n/// If there are extra arguments at the pass's run level there may also be\n/// extra arguments to the analysis manager's \\c getResult routine. We can't\n/// guess how to effectively map the arguments from one to the other, and so\n/// this specialization just ignores them.\n///\n/// Specific patterns of run-method extra arguments and analysis manager extra\n/// arguments will have to be defined as appropriate specializations.\ntemplate <typename AnalysisT, typename IRUnitT,\n          typename AnalysisManagerT = AnalysisManager<IRUnitT>,\n          typename... ExtraArgTs>\nstruct RequireAnalysisPass\n    : PassInfoMixin<RequireAnalysisPass<AnalysisT, IRUnitT, AnalysisManagerT,\n                                        ExtraArgTs...>> {\n  /// Run this pass over some unit of IR.\n  ///\n  /// This pass can be run over any unit of IR and use any analysis manager\n  /// provided they satisfy the basic API requirements. When this pass is\n  /// created, these methods can be instantiated to satisfy whatever the\n  /// context requires.\n  PreservedAnalyses run(IRUnitT &Arg, AnalysisManagerT &AM,\n                        ExtraArgTs &&... Args) {\n    (void)AM.template getResult<AnalysisT>(Arg,\n                                           std::forward<ExtraArgTs>(Args)...);\n\n    return PreservedAnalyses::all();\n  }\n  static bool isRequired() { return true; }\n};\n\n/// A no-op pass template which simply forces a specific analysis result\n/// to be invalidated.\ntemplate <typename AnalysisT>\nstruct InvalidateAnalysisPass\n    : PassInfoMixin<InvalidateAnalysisPass<AnalysisT>> {\n  /// Run this pass over some unit of IR.\n  ///\n  /// This pass can be run over any unit of IR and use any analysis manager,\n  /// provided they satisfy the basic API requirements. When this pass is\n  /// created, these methods can be instantiated to satisfy whatever the\n  /// context requires.\n  template <typename IRUnitT, typename AnalysisManagerT, typename... ExtraArgTs>\n  PreservedAnalyses run(IRUnitT &Arg, AnalysisManagerT &AM, ExtraArgTs &&...) {\n    auto PA = PreservedAnalyses::all();\n    PA.abandon<AnalysisT>();\n    return PA;\n  }\n};\n\n/// A utility pass that does nothing, but preserves no analyses.\n///\n/// Because this preserves no analyses, any analysis passes queried after this\n/// pass runs will recompute fresh results.\nstruct InvalidateAllAnalysesPass : PassInfoMixin<InvalidateAllAnalysesPass> {\n  /// Run this pass over some unit of IR.\n  template <typename IRUnitT, typename AnalysisManagerT, typename... ExtraArgTs>\n  PreservedAnalyses run(IRUnitT &, AnalysisManagerT &, ExtraArgTs &&...) {\n    return PreservedAnalyses::none();\n  }\n};\n\n/// A utility pass template that simply runs another pass multiple times.\n///\n/// This can be useful when debugging or testing passes. It also serves as an\n/// example of how to extend the pass manager in ways beyond composition.\ntemplate <typename PassT>\nclass RepeatedPass : public PassInfoMixin<RepeatedPass<PassT>> {\npublic:\n  RepeatedPass(int Count, PassT P) : Count(Count), P(std::move(P)) {}\n\n  template <typename IRUnitT, typename AnalysisManagerT, typename... Ts>\n  PreservedAnalyses run(IRUnitT &IR, AnalysisManagerT &AM, Ts &&... Args) {\n\n    // Request PassInstrumentation from analysis manager, will use it to run\n    // instrumenting callbacks for the passes later.\n    // Here we use std::tuple wrapper over getResult which helps to extract\n    // AnalysisManager's arguments out of the whole Args set.\n    PassInstrumentation PI =\n        detail::getAnalysisResult<PassInstrumentationAnalysis>(\n            AM, IR, std::tuple<Ts...>(Args...));\n\n    auto PA = PreservedAnalyses::all();\n    for (int i = 0; i < Count; ++i) {\n      // Check the PassInstrumentation's BeforePass callbacks before running the\n      // pass, skip its execution completely if asked to (callback returns\n      // false).\n      if (!PI.runBeforePass<IRUnitT>(P, IR))\n        continue;\n      PreservedAnalyses IterPA = P.run(IR, AM, std::forward<Ts>(Args)...);\n      PA.intersect(IterPA);\n      PI.runAfterPass(P, IR, IterPA);\n    }\n    return PA;\n  }\n\nprivate:\n  int Count;\n  PassT P;\n};\n\ntemplate <typename PassT>\nRepeatedPass<PassT> createRepeatedPass(int Count, PassT P) {\n  return RepeatedPass<PassT>(Count, std::move(P));\n}\n\n} // end namespace llvm\n\n#endif // LLVM_IR_PASSMANAGER_H\n"}, "87": {"id": 87, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Verifier.h", "content": "//===- Verifier.h - LLVM IR Verifier ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the function verifier interface, that can be used for some\n// sanity checking of input to the system, and for checking that transformations\n// haven't done something bad.\n//\n// Note that this does not provide full 'java style' security and verifications,\n// instead it just tries to ensure that code is well formed.\n//\n// To see what specifically is checked, look at the top of Verifier.cpp\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_VERIFIER_H\n#define LLVM_IR_VERIFIER_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/IR/PassManager.h\"\n#include <utility>\n\nnamespace llvm {\n\nclass APInt;\nclass Function;\nclass FunctionPass;\nclass Instruction;\nclass MDNode;\nclass Module;\nclass raw_ostream;\nstruct VerifierSupport;\n\n/// Verify that the TBAA Metadatas are valid.\nclass TBAAVerifier {\n  VerifierSupport *Diagnostic = nullptr;\n\n  /// Helper to diagnose a failure\n  template <typename... Tys> void CheckFailed(Tys &&... Args);\n\n  /// Cache of TBAA base nodes that have already been visited.  This cachce maps\n  /// a node that has been visited to a pair (IsInvalid, BitWidth) where\n  ///\n  ///  \\c IsInvalid is true iff the node is invalid.\n  ///  \\c BitWidth, if non-zero, is the bitwidth of the integer used to denoting\n  ///    the offset of the access.  If zero, only a zero offset is allowed.\n  ///\n  /// \\c BitWidth has no meaning if \\c IsInvalid is true.\n  using TBAABaseNodeSummary = std::pair<bool, unsigned>;\n  DenseMap<const MDNode *, TBAABaseNodeSummary> TBAABaseNodes;\n\n  /// Maps an alleged scalar TBAA node to a boolean that is true if the said\n  /// TBAA node is a valid scalar TBAA node or false otherwise.\n  DenseMap<const MDNode *, bool> TBAAScalarNodes;\n\n  /// \\name Helper functions used by \\c visitTBAAMetadata.\n  /// @{\n  MDNode *getFieldNodeFromTBAABaseNode(Instruction &I, const MDNode *BaseNode,\n                                       APInt &Offset, bool IsNewFormat);\n  TBAAVerifier::TBAABaseNodeSummary verifyTBAABaseNode(Instruction &I,\n                                                       const MDNode *BaseNode,\n                                                       bool IsNewFormat);\n  TBAABaseNodeSummary verifyTBAABaseNodeImpl(Instruction &I,\n                                             const MDNode *BaseNode,\n                                             bool IsNewFormat);\n\n  bool isValidScalarTBAANode(const MDNode *MD);\n  /// @}\n\npublic:\n  TBAAVerifier(VerifierSupport *Diagnostic = nullptr)\n      : Diagnostic(Diagnostic) {}\n  /// Visit an instruction and return true if it is valid, return false if an\n  /// invalid TBAA is attached.\n  bool visitTBAAMetadata(Instruction &I, const MDNode *MD);\n};\n\n/// Check a function for errors, useful for use when debugging a\n/// pass.\n///\n/// If there are no errors, the function returns false. If an error is found,\n/// a message describing the error is written to OS (if non-null) and true is\n/// returned.\nbool verifyFunction(const Function &F, raw_ostream *OS = nullptr);\n\n/// Check a module for errors.\n///\n/// If there are no errors, the function returns false. If an error is\n/// found, a message describing the error is written to OS (if\n/// non-null) and true is returned.\n///\n/// \\return true if the module is broken. If BrokenDebugInfo is\n/// supplied, DebugInfo verification failures won't be considered as\n/// error and instead *BrokenDebugInfo will be set to true. Debug\n/// info errors can be \"recovered\" from by stripping the debug info.\nbool verifyModule(const Module &M, raw_ostream *OS = nullptr,\n                  bool *BrokenDebugInfo = nullptr);\n\nFunctionPass *createVerifierPass(bool FatalErrors = true);\n\n/// Check a module for errors, and report separate error states for IR\n/// and debug info errors.\nclass VerifierAnalysis : public AnalysisInfoMixin<VerifierAnalysis> {\n  friend AnalysisInfoMixin<VerifierAnalysis>;\n\n  static AnalysisKey Key;\n\npublic:\n  struct Result {\n    bool IRBroken, DebugInfoBroken;\n  };\n\n  Result run(Module &M, ModuleAnalysisManager &);\n  Result run(Function &F, FunctionAnalysisManager &);\n  static bool isRequired() { return true; }\n};\n\n/// Check a module for errors, but report debug info errors separately.\n/// Otherwise behaves as the normal verifyModule. Debug info errors can be\n/// \"recovered\" from by stripping the debug info.\nbool verifyModule(bool &BrokenDebugInfo, const Module &M, raw_ostream *OS);\n\n/// Create a verifier pass.\n///\n/// Check a module or function for validity. This is essentially a pass wrapped\n/// around the above verifyFunction and verifyModule routines and\n/// functionality. When the pass detects a verification error it is always\n/// printed to stderr, and by default they are fatal. You can override that by\n/// passing \\c false to \\p FatalErrors.\n///\n/// Note that this creates a pass suitable for the legacy pass manager. It has\n/// nothing to do with \\c VerifierPass.\nclass VerifierPass : public PassInfoMixin<VerifierPass> {\n  bool FatalErrors;\n\npublic:\n  explicit VerifierPass(bool FatalErrors = true) : FatalErrors(FatalErrors) {}\n\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_IR_VERIFIER_H\n"}, "89": {"id": 89, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Passes/PassBuilder.h", "content": "//===- Parsing, selection, and construction of pass pipelines --*- C++ -*--===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// Interfaces for registering analysis passes, producing common pass manager\n/// configurations, and parsing of pass pipelines.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_PASSES_PASSBUILDER_H\n#define LLVM_PASSES_PASSBUILDER_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/Analysis/CGSCCPassManager.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/Error.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/Transforms/IPO/Inliner.h\"\n#include \"llvm/Transforms/Instrumentation.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n#include <vector>\n\nnamespace llvm {\nclass StringRef;\nclass AAManager;\nclass TargetMachine;\nclass ModuleSummaryIndex;\n\n/// A struct capturing PGO tunables.\nstruct PGOOptions {\n  enum PGOAction { NoAction, IRInstr, IRUse, SampleUse };\n  enum CSPGOAction { NoCSAction, CSIRInstr, CSIRUse };\n  PGOOptions(std::string ProfileFile = \"\", std::string CSProfileGenFile = \"\",\n             std::string ProfileRemappingFile = \"\", PGOAction Action = NoAction,\n             CSPGOAction CSAction = NoCSAction,\n             bool DebugInfoForProfiling = false,\n             bool PseudoProbeForProfiling = false)\n      : ProfileFile(ProfileFile), CSProfileGenFile(CSProfileGenFile),\n        ProfileRemappingFile(ProfileRemappingFile), Action(Action),\n        CSAction(CSAction), DebugInfoForProfiling(DebugInfoForProfiling ||\n                                                  (Action == SampleUse &&\n                                                   !PseudoProbeForProfiling)),\n        PseudoProbeForProfiling(PseudoProbeForProfiling) {\n    // Note, we do allow ProfileFile.empty() for Action=IRUse LTO can\n    // callback with IRUse action without ProfileFile.\n\n    // If there is a CSAction, PGOAction cannot be IRInstr or SampleUse.\n    assert(this->CSAction == NoCSAction ||\n           (this->Action != IRInstr && this->Action != SampleUse));\n\n    // For CSIRInstr, CSProfileGenFile also needs to be nonempty.\n    assert(this->CSAction != CSIRInstr || !this->CSProfileGenFile.empty());\n\n    // If CSAction is CSIRUse, PGOAction needs to be IRUse as they share\n    // a profile.\n    assert(this->CSAction != CSIRUse || this->Action == IRUse);\n\n    // If neither Action nor CSAction, DebugInfoForProfiling or\n    // PseudoProbeForProfiling needs to be true.\n    assert(this->Action != NoAction || this->CSAction != NoCSAction ||\n           this->DebugInfoForProfiling || this->PseudoProbeForProfiling);\n\n    // Pseudo probe emission does not work with -fdebug-info-for-profiling since\n    // they both use the discriminator field of debug lines but for different\n    // purposes.\n    if (this->DebugInfoForProfiling && this->PseudoProbeForProfiling) {\n      report_fatal_error(\n          \"Pseudo probes cannot be used with -debug-info-for-profiling\", false);\n    }\n  }\n  std::string ProfileFile;\n  std::string CSProfileGenFile;\n  std::string ProfileRemappingFile;\n  PGOAction Action;\n  CSPGOAction CSAction;\n  bool DebugInfoForProfiling;\n  bool PseudoProbeForProfiling;\n};\n\n/// Tunable parameters for passes in the default pipelines.\nclass PipelineTuningOptions {\npublic:\n  /// Constructor sets pipeline tuning defaults based on cl::opts. Each option\n  /// can be set in the PassBuilder when using a LLVM as a library.\n  PipelineTuningOptions();\n\n  /// Tuning option to set loop interleaving on/off, set based on opt level.\n  bool LoopInterleaving;\n\n  /// Tuning option to enable/disable loop vectorization, set based on opt\n  /// level.\n  bool LoopVectorization;\n\n  /// Tuning option to enable/disable slp loop vectorization, set based on opt\n  /// level.\n  bool SLPVectorization;\n\n  /// Tuning option to enable/disable loop unrolling. Its default value is true.\n  bool LoopUnrolling;\n\n  /// Tuning option to forget all SCEV loops in LoopUnroll. Its default value\n  /// is that of the flag: `-forget-scev-loop-unroll`.\n  bool ForgetAllSCEVInLoopUnroll;\n\n  /// Tuning option to enable/disable coroutine intrinsic lowering. Its default\n  /// value is false. Frontends such as Clang may enable this conditionally. For\n  /// example, Clang enables this option if the flags `-std=c++2a` or above, or\n  /// `-fcoroutines-ts`, have been specified.\n  bool Coroutines;\n\n  /// Tuning option to cap the number of calls to retrive clobbering accesses in\n  /// MemorySSA, in LICM.\n  unsigned LicmMssaOptCap;\n\n  /// Tuning option to disable promotion to scalars in LICM with MemorySSA, if\n  /// the number of access is too large.\n  unsigned LicmMssaNoAccForPromotionCap;\n\n  /// Tuning option to enable/disable call graph profile. Its default value is\n  /// that of the flag: `-enable-npm-call-graph-profile`.\n  bool CallGraphProfile;\n\n  /// Tuning option to enable/disable function merging. Its default value is\n  /// false.\n  bool MergeFunctions;\n};\n\n/// This class provides access to building LLVM's passes.\n///\n/// Its members provide the baseline state available to passes during their\n/// construction. The \\c PassRegistry.def file specifies how to construct all\n/// of the built-in passes, and those may reference these members during\n/// construction.\nclass PassBuilder {\n  bool DebugLogging;\n  TargetMachine *TM;\n  PipelineTuningOptions PTO;\n  Optional<PGOOptions> PGOOpt;\n  PassInstrumentationCallbacks *PIC;\n\npublic:\n  /// A struct to capture parsed pass pipeline names.\n  ///\n  /// A pipeline is defined as a series of names, each of which may in itself\n  /// recursively contain a nested pipeline. A name is either the name of a pass\n  /// (e.g. \"instcombine\") or the name of a pipeline type (e.g. \"cgscc\"). If the\n  /// name is the name of a pass, the InnerPipeline is empty, since passes\n  /// cannot contain inner pipelines. See parsePassPipeline() for a more\n  /// detailed description of the textual pipeline format.\n  struct PipelineElement {\n    StringRef Name;\n    std::vector<PipelineElement> InnerPipeline;\n  };\n\n  /// LLVM-provided high-level optimization levels.\n  ///\n  /// This enumerates the LLVM-provided high-level optimization levels. Each\n  /// level has a specific goal and rationale.\n  class OptimizationLevel final {\n    unsigned SpeedLevel = 2;\n    unsigned SizeLevel = 0;\n    OptimizationLevel(unsigned SpeedLevel, unsigned SizeLevel)\n        : SpeedLevel(SpeedLevel), SizeLevel(SizeLevel) {\n      // Check that only valid combinations are passed.\n      assert(SpeedLevel <= 3 &&\n             \"Optimization level for speed should be 0, 1, 2, or 3\");\n      assert(SizeLevel <= 2 &&\n             \"Optimization level for size should be 0, 1, or 2\");\n      assert((SizeLevel == 0 || SpeedLevel == 2) &&\n             \"Optimize for size should be encoded with speedup level == 2\");\n    }\n\n  public:\n    OptimizationLevel() = default;\n    /// Disable as many optimizations as possible. This doesn't completely\n    /// disable the optimizer in all cases, for example always_inline functions\n    /// can be required to be inlined for correctness.\n    static const OptimizationLevel O0;\n\n    /// Optimize quickly without destroying debuggability.\n    ///\n    /// This level is tuned to produce a result from the optimizer as quickly\n    /// as possible and to avoid destroying debuggability. This tends to result\n    /// in a very good development mode where the compiled code will be\n    /// immediately executed as part of testing. As a consequence, where\n    /// possible, we would like to produce efficient-to-execute code, but not\n    /// if it significantly slows down compilation or would prevent even basic\n    /// debugging of the resulting binary.\n    ///\n    /// As an example, complex loop transformations such as versioning,\n    /// vectorization, or fusion don't make sense here due to the degree to\n    /// which the executed code differs from the source code, and the compile\n    /// time cost.\n    static const OptimizationLevel O1;\n    /// Optimize for fast execution as much as possible without triggering\n    /// significant incremental compile time or code size growth.\n    ///\n    /// The key idea is that optimizations at this level should \"pay for\n    /// themselves\". So if an optimization increases compile time by 5% or\n    /// increases code size by 5% for a particular benchmark, that benchmark\n    /// should also be one which sees a 5% runtime improvement. If the compile\n    /// time or code size penalties happen on average across a diverse range of\n    /// LLVM users' benchmarks, then the improvements should as well.\n    ///\n    /// And no matter what, the compile time needs to not grow superlinearly\n    /// with the size of input to LLVM so that users can control the runtime of\n    /// the optimizer in this mode.\n    ///\n    /// This is expected to be a good default optimization level for the vast\n    /// majority of users.\n    static const OptimizationLevel O2;\n    /// Optimize for fast execution as much as possible.\n    ///\n    /// This mode is significantly more aggressive in trading off compile time\n    /// and code size to get execution time improvements. The core idea is that\n    /// this mode should include any optimization that helps execution time on\n    /// balance across a diverse collection of benchmarks, even if it increases\n    /// code size or compile time for some benchmarks without corresponding\n    /// improvements to execution time.\n    ///\n    /// Despite being willing to trade more compile time off to get improved\n    /// execution time, this mode still tries to avoid superlinear growth in\n    /// order to make even significantly slower compile times at least scale\n    /// reasonably. This does not preclude very substantial constant factor\n    /// costs though.\n    static const OptimizationLevel O3;\n    /// Similar to \\c O2 but tries to optimize for small code size instead of\n    /// fast execution without triggering significant incremental execution\n    /// time slowdowns.\n    ///\n    /// The logic here is exactly the same as \\c O2, but with code size and\n    /// execution time metrics swapped.\n    ///\n    /// A consequence of the different core goal is that this should in general\n    /// produce substantially smaller executables that still run in\n    /// a reasonable amount of time.\n    static const OptimizationLevel Os;\n    /// A very specialized mode that will optimize for code size at any and all\n    /// costs.\n    ///\n    /// This is useful primarily when there are absolute size limitations and\n    /// any effort taken to reduce the size is worth it regardless of the\n    /// execution time impact. You should expect this level to produce rather\n    /// slow, but very small, code.\n    static const OptimizationLevel Oz;\n\n    bool isOptimizingForSpeed() const {\n      return SizeLevel == 0 && SpeedLevel > 0;\n    }\n\n    bool isOptimizingForSize() const { return SizeLevel > 0; }\n\n    bool operator==(const OptimizationLevel &Other) const {\n      return SizeLevel == Other.SizeLevel && SpeedLevel == Other.SpeedLevel;\n    }\n    bool operator!=(const OptimizationLevel &Other) const {\n      return SizeLevel != Other.SizeLevel || SpeedLevel != Other.SpeedLevel;\n    }\n\n    unsigned getSpeedupLevel() const { return SpeedLevel; }\n\n    unsigned getSizeLevel() const { return SizeLevel; }\n  };\n\n  explicit PassBuilder(bool DebugLogging = false, TargetMachine *TM = nullptr,\n                       PipelineTuningOptions PTO = PipelineTuningOptions(),\n                       Optional<PGOOptions> PGOOpt = None,\n                       PassInstrumentationCallbacks *PIC = nullptr);\n\n  /// Cross register the analysis managers through their proxies.\n  ///\n  /// This is an interface that can be used to cross register each\n  /// AnalysisManager with all the others analysis managers.\n  void crossRegisterProxies(LoopAnalysisManager &LAM,\n                            FunctionAnalysisManager &FAM,\n                            CGSCCAnalysisManager &CGAM,\n                            ModuleAnalysisManager &MAM);\n\n  /// Registers all available module analysis passes.\n  ///\n  /// This is an interface that can be used to populate a \\c\n  /// ModuleAnalysisManager with all registered module analyses. Callers can\n  /// still manually register any additional analyses. Callers can also\n  /// pre-register analyses and this will not override those.\n  void registerModuleAnalyses(ModuleAnalysisManager &MAM);\n\n  /// Registers all available CGSCC analysis passes.\n  ///\n  /// This is an interface that can be used to populate a \\c CGSCCAnalysisManager\n  /// with all registered CGSCC analyses. Callers can still manually register any\n  /// additional analyses. Callers can also pre-register analyses and this will\n  /// not override those.\n  void registerCGSCCAnalyses(CGSCCAnalysisManager &CGAM);\n\n  /// Registers all available function analysis passes.\n  ///\n  /// This is an interface that can be used to populate a \\c\n  /// FunctionAnalysisManager with all registered function analyses. Callers can\n  /// still manually register any additional analyses. Callers can also\n  /// pre-register analyses and this will not override those.\n  void registerFunctionAnalyses(FunctionAnalysisManager &FAM);\n\n  /// Registers all available loop analysis passes.\n  ///\n  /// This is an interface that can be used to populate a \\c LoopAnalysisManager\n  /// with all registered loop analyses. Callers can still manually register any\n  /// additional analyses.\n  void registerLoopAnalyses(LoopAnalysisManager &LAM);\n\n  /// Construct the core LLVM function canonicalization and simplification\n  /// pipeline.\n  ///\n  /// This is a long pipeline and uses most of the per-function optimization\n  /// passes in LLVM to canonicalize and simplify the IR. It is suitable to run\n  /// repeatedly over the IR and is not expected to destroy important\n  /// information about the semantics of the IR.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ///\n  /// \\p Phase indicates the current ThinLTO phase.\n  FunctionPassManager\n  buildFunctionSimplificationPipeline(OptimizationLevel Level,\n                                      ThinOrFullLTOPhase Phase);\n\n  /// Construct the core LLVM module canonicalization and simplification\n  /// pipeline.\n  ///\n  /// This pipeline focuses on canonicalizing and simplifying the entire module\n  /// of IR. Much like the function simplification pipeline above, it is\n  /// suitable to run repeatedly over the IR and is not expected to destroy\n  /// important information. It does, however, perform inlining and other\n  /// heuristic based simplifications that are not strictly reversible.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ///\n  /// \\p Phase indicates the current ThinLTO phase.\n  ModulePassManager buildModuleSimplificationPipeline(OptimizationLevel Level,\n                                                      ThinOrFullLTOPhase Phase);\n\n  /// Construct the module pipeline that performs inlining as well as\n  /// the inlining-driven cleanups.\n  ModuleInlinerWrapperPass buildInlinerPipeline(OptimizationLevel Level,\n                                                ThinOrFullLTOPhase Phase);\n\n  /// Construct the core LLVM module optimization pipeline.\n  ///\n  /// This pipeline focuses on optimizing the execution speed of the IR. It\n  /// uses cost modeling and thresholds to balance code growth against runtime\n  /// improvements. It includes vectorization and other information destroying\n  /// transformations. It also cannot generally be run repeatedly on a module\n  /// without potentially seriously regressing either runtime performance of\n  /// the code or serious code size growth.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ModulePassManager buildModuleOptimizationPipeline(OptimizationLevel Level,\n                                                    bool LTOPreLink = false);\n\n  /// Build a per-module default optimization pipeline.\n  ///\n  /// This provides a good default optimization pipeline for per-module\n  /// optimization and code generation without any link-time optimization. It\n  /// typically correspond to frontend \"-O[123]\" options for optimization\n  /// levels \\c O1, \\c O2 and \\c O3 resp.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ModulePassManager buildPerModuleDefaultPipeline(OptimizationLevel Level,\n                                                  bool LTOPreLink = false);\n\n  /// Build a pre-link, ThinLTO-targeting default optimization pipeline to\n  /// a pass manager.\n  ///\n  /// This adds the pre-link optimizations tuned to prepare a module for\n  /// a ThinLTO run. It works to minimize the IR which needs to be analyzed\n  /// without making irreversible decisions which could be made better during\n  /// the LTO run.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ModulePassManager buildThinLTOPreLinkDefaultPipeline(OptimizationLevel Level);\n\n  /// Build an ThinLTO default optimization pipeline to a pass manager.\n  ///\n  /// This provides a good default optimization pipeline for link-time\n  /// optimization and code generation. It is particularly tuned to fit well\n  /// when IR coming into the LTO phase was first run through \\c\n  /// addPreLinkLTODefaultPipeline, and the two coordinate closely.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ModulePassManager\n  buildThinLTODefaultPipeline(OptimizationLevel Level,\n                              const ModuleSummaryIndex *ImportSummary);\n\n  /// Build a pre-link, LTO-targeting default optimization pipeline to a pass\n  /// manager.\n  ///\n  /// This adds the pre-link optimizations tuned to work well with a later LTO\n  /// run. It works to minimize the IR which needs to be analyzed without\n  /// making irreversible decisions which could be made better during the LTO\n  /// run.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ModulePassManager buildLTOPreLinkDefaultPipeline(OptimizationLevel Level);\n\n  /// Build an LTO default optimization pipeline to a pass manager.\n  ///\n  /// This provides a good default optimization pipeline for link-time\n  /// optimization and code generation. It is particularly tuned to fit well\n  /// when IR coming into the LTO phase was first run through \\c\n  /// addPreLinkLTODefaultPipeline, and the two coordinate closely.\n  ///\n  /// Note that \\p Level cannot be `O0` here. The pipelines produced are\n  /// only intended for use when attempting to optimize code. If frontends\n  /// require some transformations for semantic reasons, they should explicitly\n  /// build them.\n  ModulePassManager buildLTODefaultPipeline(OptimizationLevel Level,\n                                            ModuleSummaryIndex *ExportSummary);\n\n  /// Build an O0 pipeline with the minimal semantically required passes.\n  ///\n  /// This should only be used for non-LTO and LTO pre-link pipelines.\n  ModulePassManager buildO0DefaultPipeline(OptimizationLevel Level,\n                                           bool LTOPreLink = false);\n\n  /// Build the default `AAManager` with the default alias analysis pipeline\n  /// registered.\n  ///\n  /// This also adds target-specific alias analyses registered via\n  /// TargetMachine::registerDefaultAliasAnalyses().\n  AAManager buildDefaultAAPipeline();\n\n  /// Parse a textual pass pipeline description into a \\c\n  /// ModulePassManager.\n  ///\n  /// The format of the textual pass pipeline description looks something like:\n  ///\n  ///   module(function(instcombine,sroa),dce,cgscc(inliner,function(...)),...)\n  ///\n  /// Pass managers have ()s describing the nest structure of passes. All passes\n  /// are comma separated. As a special shortcut, if the very first pass is not\n  /// a module pass (as a module pass manager is), this will automatically form\n  /// the shortest stack of pass managers that allow inserting that first pass.\n  /// So, assuming function passes 'fpassN', CGSCC passes 'cgpassN', and loop\n  /// passes 'lpassN', all of these are valid:\n  ///\n  ///   fpass1,fpass2,fpass3\n  ///   cgpass1,cgpass2,cgpass3\n  ///   lpass1,lpass2,lpass3\n  ///\n  /// And they are equivalent to the following (resp.):\n  ///\n  ///   module(function(fpass1,fpass2,fpass3))\n  ///   module(cgscc(cgpass1,cgpass2,cgpass3))\n  ///   module(function(loop(lpass1,lpass2,lpass3)))\n  ///\n  /// This shortcut is especially useful for debugging and testing small pass\n  /// combinations.\n  ///\n  /// The sequence of passes aren't necessarily the exact same kind of pass.\n  /// You can mix different levels implicitly if adaptor passes are defined to\n  /// make them work. For example,\n  ///\n  ///   mpass1,fpass1,fpass2,mpass2,lpass1\n  ///\n  /// This pipeline uses only one pass manager: the top-level module manager.\n  /// fpass1,fpass2 and lpass1 are added into the the top-level module manager\n  /// using only adaptor passes. No nested function/loop pass managers are\n  /// added. The purpose is to allow easy pass testing when the user\n  /// specifically want the pass to run under a adaptor directly. This is\n  /// preferred when a pipeline is largely of one type, but one or just a few\n  /// passes are of different types(See PassBuilder.cpp for examples).\n  Error parsePassPipeline(ModulePassManager &MPM, StringRef PipelineText);\n\n  /// {{@ Parse a textual pass pipeline description into a specific PassManager\n  ///\n  /// Automatic deduction of an appropriate pass manager stack is not supported.\n  /// For example, to insert a loop pass 'lpass' into a FunctionPassManager,\n  /// this is the valid pipeline text:\n  ///\n  ///   function(lpass)\n  Error parsePassPipeline(CGSCCPassManager &CGPM, StringRef PipelineText);\n  Error parsePassPipeline(FunctionPassManager &FPM, StringRef PipelineText);\n  Error parsePassPipeline(LoopPassManager &LPM, StringRef PipelineText);\n  /// @}}\n\n  /// Parse a textual alias analysis pipeline into the provided AA manager.\n  ///\n  /// The format of the textual AA pipeline is a comma separated list of AA\n  /// pass names:\n  ///\n  ///   basic-aa,globals-aa,...\n  ///\n  /// The AA manager is set up such that the provided alias analyses are tried\n  /// in the order specified. See the \\c AAManaager documentation for details\n  /// about the logic used. This routine just provides the textual mapping\n  /// between AA names and the analyses to register with the manager.\n  ///\n  /// Returns false if the text cannot be parsed cleanly. The specific state of\n  /// the \\p AA manager is unspecified if such an error is encountered and this\n  /// returns false.\n  Error parseAAPipeline(AAManager &AA, StringRef PipelineText);\n\n  /// Returns true if the pass name is the name of an alias analysis pass.\n  bool isAAPassName(StringRef PassName);\n\n  /// Returns true if the pass name is the name of a (non-alias) analysis pass.\n  bool isAnalysisPassName(StringRef PassName);\n\n  /// Print pass names.\n  void printPassNames(raw_ostream &OS);\n\n  /// Register a callback for a default optimizer pipeline extension\n  /// point\n  ///\n  /// This extension point allows adding passes that perform peephole\n  /// optimizations similar to the instruction combiner. These passes will be\n  /// inserted after each instance of the instruction combiner pass.\n  void registerPeepholeEPCallback(\n      const std::function<void(FunctionPassManager &, OptimizationLevel)> &C) {\n    PeepholeEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension\n  /// point\n  ///\n  /// This extension point allows adding late loop canonicalization and\n  /// simplification passes. This is the last point in the loop optimization\n  /// pipeline before loop deletion. Each pass added\n  /// here must be an instance of LoopPass.\n  /// This is the place to add passes that can remove loops, such as target-\n  /// specific loop idiom recognition.\n  void registerLateLoopOptimizationsEPCallback(\n      const std::function<void(LoopPassManager &, OptimizationLevel)> &C) {\n    LateLoopOptimizationsEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension\n  /// point\n  ///\n  /// This extension point allows adding loop passes to the end of the loop\n  /// optimizer.\n  void registerLoopOptimizerEndEPCallback(\n      const std::function<void(LoopPassManager &, OptimizationLevel)> &C) {\n    LoopOptimizerEndEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension\n  /// point\n  ///\n  /// This extension point allows adding optimization passes after most of the\n  /// main optimizations, but before the last cleanup-ish optimizations.\n  void registerScalarOptimizerLateEPCallback(\n      const std::function<void(FunctionPassManager &, OptimizationLevel)> &C) {\n    ScalarOptimizerLateEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension\n  /// point\n  ///\n  /// This extension point allows adding CallGraphSCC passes at the end of the\n  /// main CallGraphSCC passes and before any function simplification passes run\n  /// by CGPassManager.\n  void registerCGSCCOptimizerLateEPCallback(\n      const std::function<void(CGSCCPassManager &, OptimizationLevel)> &C) {\n    CGSCCOptimizerLateEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension\n  /// point\n  ///\n  /// This extension point allows adding optimization passes before the\n  /// vectorizer and other highly target specific optimization passes are\n  /// executed.\n  void registerVectorizerStartEPCallback(\n      const std::function<void(FunctionPassManager &, OptimizationLevel)> &C) {\n    VectorizerStartEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension point.\n  ///\n  /// This extension point allows adding optimization once at the start of the\n  /// pipeline. This does not apply to 'backend' compiles (LTO and ThinLTO\n  /// link-time pipelines).\n  void registerPipelineStartEPCallback(\n      const std::function<void(ModulePassManager &, OptimizationLevel)> &C) {\n    PipelineStartEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension point.\n  ///\n  /// This extension point allows adding optimization right after passes that do\n  /// basic simplification of the input IR.\n  void registerPipelineEarlySimplificationEPCallback(\n      const std::function<void(ModulePassManager &, OptimizationLevel)> &C) {\n    PipelineEarlySimplificationEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for a default optimizer pipeline extension point\n  ///\n  /// This extension point allows adding optimizations at the very end of the\n  /// function optimization pipeline.\n  void registerOptimizerLastEPCallback(\n      const std::function<void(ModulePassManager &, OptimizationLevel)> &C) {\n    OptimizerLastEPCallbacks.push_back(C);\n  }\n\n  /// Register a callback for parsing an AliasAnalysis Name to populate\n  /// the given AAManager \\p AA\n  void registerParseAACallback(\n      const std::function<bool(StringRef Name, AAManager &AA)> &C) {\n    AAParsingCallbacks.push_back(C);\n  }\n\n  /// {{@ Register callbacks for analysis registration with this PassBuilder\n  /// instance.\n  /// Callees register their analyses with the given AnalysisManager objects.\n  void registerAnalysisRegistrationCallback(\n      const std::function<void(CGSCCAnalysisManager &)> &C) {\n    CGSCCAnalysisRegistrationCallbacks.push_back(C);\n  }\n  void registerAnalysisRegistrationCallback(\n      const std::function<void(FunctionAnalysisManager &)> &C) {\n    FunctionAnalysisRegistrationCallbacks.push_back(C);\n  }\n  void registerAnalysisRegistrationCallback(\n      const std::function<void(LoopAnalysisManager &)> &C) {\n    LoopAnalysisRegistrationCallbacks.push_back(C);\n  }\n  void registerAnalysisRegistrationCallback(\n      const std::function<void(ModuleAnalysisManager &)> &C) {\n    ModuleAnalysisRegistrationCallbacks.push_back(C);\n  }\n  /// @}}\n\n  /// {{@ Register pipeline parsing callbacks with this pass builder instance.\n  /// Using these callbacks, callers can parse both a single pass name, as well\n  /// as entire sub-pipelines, and populate the PassManager instance\n  /// accordingly.\n  void registerPipelineParsingCallback(\n      const std::function<bool(StringRef Name, CGSCCPassManager &,\n                               ArrayRef<PipelineElement>)> &C) {\n    CGSCCPipelineParsingCallbacks.push_back(C);\n  }\n  void registerPipelineParsingCallback(\n      const std::function<bool(StringRef Name, FunctionPassManager &,\n                               ArrayRef<PipelineElement>)> &C) {\n    FunctionPipelineParsingCallbacks.push_back(C);\n  }\n  void registerPipelineParsingCallback(\n      const std::function<bool(StringRef Name, LoopPassManager &,\n                               ArrayRef<PipelineElement>)> &C) {\n    LoopPipelineParsingCallbacks.push_back(C);\n  }\n  void registerPipelineParsingCallback(\n      const std::function<bool(StringRef Name, ModulePassManager &,\n                               ArrayRef<PipelineElement>)> &C) {\n    ModulePipelineParsingCallbacks.push_back(C);\n  }\n  /// @}}\n\n  /// Register a callback for a top-level pipeline entry.\n  ///\n  /// If the PassManager type is not given at the top level of the pipeline\n  /// text, this Callback should be used to determine the appropriate stack of\n  /// PassManagers and populate the passed ModulePassManager.\n  void registerParseTopLevelPipelineCallback(\n      const std::function<bool(ModulePassManager &, ArrayRef<PipelineElement>,\n                               bool DebugLogging)> &C);\n\n  /// Add PGOInstrumenation passes for O0 only.\n  void addPGOInstrPassesForO0(ModulePassManager &MPM, bool RunProfileGen,\n                              bool IsCS, std::string ProfileFile,\n                              std::string ProfileRemappingFile);\n\n  /// Returns PIC. External libraries can use this to register pass\n  /// instrumentation callbacks.\n  PassInstrumentationCallbacks *getPassInstrumentationCallbacks() const {\n    return PIC;\n  }\n\nprivate:\n  // O1 pass pipeline\n  FunctionPassManager\n  buildO1FunctionSimplificationPipeline(OptimizationLevel Level,\n                                        ThinOrFullLTOPhase Phase);\n\n  void addRequiredLTOPreLinkPasses(ModulePassManager &MPM);\n\n  static Optional<std::vector<PipelineElement>>\n  parsePipelineText(StringRef Text);\n\n  Error parseModulePass(ModulePassManager &MPM, const PipelineElement &E);\n  Error parseCGSCCPass(CGSCCPassManager &CGPM, const PipelineElement &E);\n  Error parseFunctionPass(FunctionPassManager &FPM, const PipelineElement &E);\n  Error parseLoopPass(LoopPassManager &LPM, const PipelineElement &E);\n  bool parseAAPassName(AAManager &AA, StringRef Name);\n\n  Error parseLoopPassPipeline(LoopPassManager &LPM,\n                              ArrayRef<PipelineElement> Pipeline);\n  Error parseFunctionPassPipeline(FunctionPassManager &FPM,\n                                  ArrayRef<PipelineElement> Pipeline);\n  Error parseCGSCCPassPipeline(CGSCCPassManager &CGPM,\n                               ArrayRef<PipelineElement> Pipeline);\n  Error parseModulePassPipeline(ModulePassManager &MPM,\n                                ArrayRef<PipelineElement> Pipeline);\n\n  void addPGOInstrPasses(ModulePassManager &MPM, OptimizationLevel Level,\n                         bool RunProfileGen, bool IsCS, std::string ProfileFile,\n                         std::string ProfileRemappingFile);\n  void invokePeepholeEPCallbacks(FunctionPassManager &, OptimizationLevel);\n\n  // Extension Point callbacks\n  SmallVector<std::function<void(FunctionPassManager &, OptimizationLevel)>, 2>\n      PeepholeEPCallbacks;\n  SmallVector<std::function<void(LoopPassManager &, OptimizationLevel)>, 2>\n      LateLoopOptimizationsEPCallbacks;\n  SmallVector<std::function<void(LoopPassManager &, OptimizationLevel)>, 2>\n      LoopOptimizerEndEPCallbacks;\n  SmallVector<std::function<void(FunctionPassManager &, OptimizationLevel)>, 2>\n      ScalarOptimizerLateEPCallbacks;\n  SmallVector<std::function<void(CGSCCPassManager &, OptimizationLevel)>, 2>\n      CGSCCOptimizerLateEPCallbacks;\n  SmallVector<std::function<void(FunctionPassManager &, OptimizationLevel)>, 2>\n      VectorizerStartEPCallbacks;\n  SmallVector<std::function<void(ModulePassManager &, OptimizationLevel)>, 2>\n      OptimizerLastEPCallbacks;\n  // Module callbacks\n  SmallVector<std::function<void(ModulePassManager &, OptimizationLevel)>, 2>\n      PipelineStartEPCallbacks;\n  SmallVector<std::function<void(ModulePassManager &, OptimizationLevel)>, 2>\n      PipelineEarlySimplificationEPCallbacks;\n\n  SmallVector<std::function<void(ModuleAnalysisManager &)>, 2>\n      ModuleAnalysisRegistrationCallbacks;\n  SmallVector<std::function<bool(StringRef, ModulePassManager &,\n                                 ArrayRef<PipelineElement>)>,\n              2>\n      ModulePipelineParsingCallbacks;\n  SmallVector<std::function<bool(ModulePassManager &, ArrayRef<PipelineElement>,\n                                 bool DebugLogging)>,\n              2>\n      TopLevelPipelineParsingCallbacks;\n  // CGSCC callbacks\n  SmallVector<std::function<void(CGSCCAnalysisManager &)>, 2>\n      CGSCCAnalysisRegistrationCallbacks;\n  SmallVector<std::function<bool(StringRef, CGSCCPassManager &,\n                                 ArrayRef<PipelineElement>)>,\n              2>\n      CGSCCPipelineParsingCallbacks;\n  // Function callbacks\n  SmallVector<std::function<void(FunctionAnalysisManager &)>, 2>\n      FunctionAnalysisRegistrationCallbacks;\n  SmallVector<std::function<bool(StringRef, FunctionPassManager &,\n                                 ArrayRef<PipelineElement>)>,\n              2>\n      FunctionPipelineParsingCallbacks;\n  // Loop callbacks\n  SmallVector<std::function<void(LoopAnalysisManager &)>, 2>\n      LoopAnalysisRegistrationCallbacks;\n  SmallVector<std::function<bool(StringRef, LoopPassManager &,\n                                 ArrayRef<PipelineElement>)>,\n              2>\n      LoopPipelineParsingCallbacks;\n  // AA callbacks\n  SmallVector<std::function<bool(StringRef Name, AAManager &AA)>, 2>\n      AAParsingCallbacks;\n};\n\n/// This utility template takes care of adding require<> and invalidate<>\n/// passes for an analysis to a given \\c PassManager. It is intended to be used\n/// during parsing of a pass pipeline when parsing a single PipelineName.\n/// When registering a new function analysis FancyAnalysis with the pass\n/// pipeline name \"fancy-analysis\", a matching ParsePipelineCallback could look\n/// like this:\n///\n/// static bool parseFunctionPipeline(StringRef Name, FunctionPassManager &FPM,\n///                                   ArrayRef<PipelineElement> P) {\n///   if (parseAnalysisUtilityPasses<FancyAnalysis>(\"fancy-analysis\", Name,\n///                                                 FPM))\n///     return true;\n///   return false;\n/// }\ntemplate <typename AnalysisT, typename IRUnitT, typename AnalysisManagerT,\n          typename... ExtraArgTs>\nbool parseAnalysisUtilityPasses(\n    StringRef AnalysisName, StringRef PipelineName,\n    PassManager<IRUnitT, AnalysisManagerT, ExtraArgTs...> &PM) {\n  if (!PipelineName.endswith(\">\"))\n    return false;\n  // See if this is an invalidate<> pass name\n  if (PipelineName.startswith(\"invalidate<\")) {\n    PipelineName = PipelineName.substr(11, PipelineName.size() - 12);\n    if (PipelineName != AnalysisName)\n      return false;\n    PM.addPass(InvalidateAnalysisPass<AnalysisT>());\n    return true;\n  }\n\n  // See if this is a require<> pass name\n  if (PipelineName.startswith(\"require<\")) {\n    PipelineName = PipelineName.substr(8, PipelineName.size() - 9);\n    if (PipelineName != AnalysisName)\n      return false;\n    PM.addPass(RequireAnalysisPass<AnalysisT, IRUnitT, AnalysisManagerT,\n                                   ExtraArgTs...>());\n    return true;\n  }\n\n  return false;\n}\n}\n\n#endif\n"}, "111": {"id": 111, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/AggressiveInstCombine/AggressiveInstCombine.h", "content": "//===- AggressiveInstCombine.h - AggressiveInstCombine pass -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// This file provides the primary interface to the aggressive instcombine pass.\n/// This pass is suitable for use in the new pass manager. For a pass that works\n/// with the legacy pass manager, please use\n/// \\c createAggressiveInstCombinerPass().\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_AGGRESSIVEINSTCOMBINE_AGGRESSIVEINSTCOMBINE_H\n#define LLVM_TRANSFORMS_AGGRESSIVEINSTCOMBINE_AGGRESSIVEINSTCOMBINE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass AggressiveInstCombinePass\n    : public PassInfoMixin<AggressiveInstCombinePass> {\n\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n//===----------------------------------------------------------------------===//\n//\n// AggressiveInstCombiner - Combine expression patterns to form expressions with\n// fewer, simple instructions. This pass does not modify the CFG.\n//\nFunctionPass *createAggressiveInstCombinerPass();\n}\n\n#endif\n"}, "112": {"id": 112, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroCleanup.h", "content": "//===-- CoroCleanup.h - Lower all coroutine related intrinsics --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// This file delcares a pass that lowers all remaining coroutine intrinsics.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_COROUTINES_COROCLEANUP_H\n#define LLVM_TRANSFORMS_COROUTINES_COROCLEANUP_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nstruct CoroCleanupPass : PassInfoMixin<CoroCleanupPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_COROUTINES_COROCLEANUP_H\n"}, "113": {"id": 113, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroEarly.h", "content": "//===---- CoroEarly.h - Lower early coroutine intrinsics --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// This file provides the interface to the early coroutine intrinsic lowering\n// pass. This pass lowers coroutine intrinsics that hide the details of the\n// exact calling convention for coroutine resume and destroy functions and\n// details of the structure of the coroutine frame.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_COROUTINES_COROEARLY_H\n#define LLVM_TRANSFORMS_COROUTINES_COROEARLY_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nstruct CoroEarlyPass : PassInfoMixin<CoroEarlyPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_COROUTINES_COROEARLY_H\n"}, "114": {"id": 114, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroElide.h", "content": "//===---- CoroElide.h - Coroutine frame allocation elision ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// This file declares a pass that replaces dynamic allocation of coroutine\n// frames with alloca and replaces calls to llvm.coro.resume and\n// llvm.coro.destroy with direct calls to coroutine sub-functions.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_COROUTINES_COROELIDE_H\n#define LLVM_TRANSFORMS_COROUTINES_COROELIDE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nstruct CoroElidePass : PassInfoMixin<CoroElidePass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_COROUTINES_COROELIDE_H\n"}, "115": {"id": 115, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/Annotation2Metadata.h", "content": "//===- Annotation2Metadata.h - Add !annotation metadata. --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// New pass manager pass to convert @llvm.global.annotations to !annotation\n// metadata.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_ANNOTATION2METADATA_H\n#define LLVM_TRANSFORMS_IPO_ANNOTATION2METADATA_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// Pass to convert @llvm.global.annotations to !annotation metadata.\nstruct Annotation2MetadataPass : public PassInfoMixin<Annotation2MetadataPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_ANNOTATION2METADATA_H\n"}, "116": {"id": 116, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/Attributor.h", "content": "//===- Attributor.h --- Module-wide attribute deduction ---------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Attributor: An inter procedural (abstract) \"attribute\" deduction framework.\n//\n// The Attributor framework is an inter procedural abstract analysis (fixpoint\n// iteration analysis). The goal is to allow easy deduction of new attributes as\n// well as information exchange between abstract attributes in-flight.\n//\n// The Attributor class is the driver and the link between the various abstract\n// attributes. The Attributor will iterate until a fixpoint state is reached by\n// all abstract attributes in-flight, or until it will enforce a pessimistic fix\n// point because an iteration limit is reached.\n//\n// Abstract attributes, derived from the AbstractAttribute class, actually\n// describe properties of the code. They can correspond to actual LLVM-IR\n// attributes, or they can be more general, ultimately unrelated to LLVM-IR\n// attributes. The latter is useful when an abstract attributes provides\n// information to other abstract attributes in-flight but we might not want to\n// manifest the information. The Attributor allows to query in-flight abstract\n// attributes through the `Attributor::getAAFor` method (see the method\n// description for an example). If the method is used by an abstract attribute\n// P, and it results in an abstract attribute Q, the Attributor will\n// automatically capture a potential dependence from Q to P. This dependence\n// will cause P to be reevaluated whenever Q changes in the future.\n//\n// The Attributor will only reevaluate abstract attributes that might have\n// changed since the last iteration. That means that the Attribute will not\n// revisit all instructions/blocks/functions in the module but only query\n// an update from a subset of the abstract attributes.\n//\n// The update method `AbstractAttribute::updateImpl` is implemented by the\n// specific \"abstract attribute\" subclasses. The method is invoked whenever the\n// currently assumed state (see the AbstractState class) might not be valid\n// anymore. This can, for example, happen if the state was dependent on another\n// abstract attribute that changed. In every invocation, the update method has\n// to adjust the internal state of an abstract attribute to a point that is\n// justifiable by the underlying IR and the current state of abstract attributes\n// in-flight. Since the IR is given and assumed to be valid, the information\n// derived from it can be assumed to hold. However, information derived from\n// other abstract attributes is conditional on various things. If the justifying\n// state changed, the `updateImpl` has to revisit the situation and potentially\n// find another justification or limit the optimistic assumes made.\n//\n// Change is the key in this framework. Until a state of no-change, thus a\n// fixpoint, is reached, the Attributor will query the abstract attributes\n// in-flight to re-evaluate their state. If the (current) state is too\n// optimistic, hence it cannot be justified anymore through other abstract\n// attributes or the state of the IR, the state of the abstract attribute will\n// have to change. Generally, we assume abstract attribute state to be a finite\n// height lattice and the update function to be monotone. However, these\n// conditions are not enforced because the iteration limit will guarantee\n// termination. If an optimistic fixpoint is reached, or a pessimistic fix\n// point is enforced after a timeout, the abstract attributes are tasked to\n// manifest their result in the IR for passes to come.\n//\n// Attribute manifestation is not mandatory. If desired, there is support to\n// generate a single or multiple LLVM-IR attributes already in the helper struct\n// IRAttribute. In the simplest case, a subclass inherits from IRAttribute with\n// a proper Attribute::AttrKind as template parameter. The Attributor\n// manifestation framework will then create and place a new attribute if it is\n// allowed to do so (based on the abstract state). Other use cases can be\n// achieved by overloading AbstractAttribute or IRAttribute methods.\n//\n//\n// The \"mechanics\" of adding a new \"abstract attribute\":\n// - Define a class (transitively) inheriting from AbstractAttribute and one\n//   (which could be the same) that (transitively) inherits from AbstractState.\n//   For the latter, consider the already available BooleanState and\n//   {Inc,Dec,Bit}IntegerState if they fit your needs, e.g., you require only a\n//   number tracking or bit-encoding.\n// - Implement all pure methods. Also use overloading if the attribute is not\n//   conforming with the \"default\" behavior: A (set of) LLVM-IR attribute(s) for\n//   an argument, call site argument, function return value, or function. See\n//   the class and method descriptions for more information on the two\n//   \"Abstract\" classes and their respective methods.\n// - Register opportunities for the new abstract attribute in the\n//   `Attributor::identifyDefaultAbstractAttributes` method if it should be\n//   counted as a 'default' attribute.\n// - Add sufficient tests.\n// - Add a Statistics object for bookkeeping. If it is a simple (set of)\n//   attribute(s) manifested through the Attributor manifestation framework, see\n//   the bookkeeping function in Attributor.cpp.\n// - If instructions with a certain opcode are interesting to the attribute, add\n//   that opcode to the switch in `Attributor::identifyAbstractAttributes`. This\n//   will make it possible to query all those instructions through the\n//   `InformationCache::getOpcodeInstMapForFunction` interface and eliminate the\n//   need to traverse the IR repeatedly.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_ATTRIBUTOR_H\n#define LLVM_TRANSFORMS_IPO_ATTRIBUTOR_H\n\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/GraphTraits.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/Analysis/AssumeBundleQueries.h\"\n#include \"llvm/Analysis/CFG.h\"\n#include \"llvm/Analysis/CGSCCPassManager.h\"\n#include \"llvm/Analysis/LazyCallGraph.h\"\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/Analysis/MustExecute.h\"\n#include \"llvm/Analysis/PostDominators.h\"\n#include \"llvm/Analysis/TargetLibraryInfo.h\"\n#include \"llvm/IR/AbstractCallSite.h\"\n#include \"llvm/IR/ConstantRange.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/Allocator.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/TimeProfiler.h\"\n#include \"llvm/Transforms/Utils/CallGraphUpdater.h\"\n\nnamespace llvm {\n\nstruct AADepGraphNode;\nstruct AADepGraph;\nstruct Attributor;\nstruct AbstractAttribute;\nstruct InformationCache;\nstruct AAIsDead;\n\nclass AAManager;\nclass AAResults;\nclass Function;\n\n/// The value passed to the line option that defines the maximal initialization\n/// chain length.\nextern unsigned MaxInitializationChainLength;\n\n///{\nenum class ChangeStatus {\n  CHANGED,\n  UNCHANGED,\n};\n\nChangeStatus operator|(ChangeStatus l, ChangeStatus r);\nChangeStatus operator&(ChangeStatus l, ChangeStatus r);\n\nenum class DepClassTy {\n  REQUIRED, ///< The target cannot be valid if the source is not.\n  OPTIONAL, ///< The target may be valid if the source is not.\n  NONE,     ///< Do not track a dependence between source and target.\n};\n///}\n\n/// The data structure for the nodes of a dependency graph\nstruct AADepGraphNode {\npublic:\n  virtual ~AADepGraphNode(){};\n  using DepTy = PointerIntPair<AADepGraphNode *, 1>;\n\nprotected:\n  /// Set of dependency graph nodes which should be updated if this one\n  /// is updated. The bit encodes if it is optional.\n  TinyPtrVector<DepTy> Deps;\n\n  static AADepGraphNode *DepGetVal(DepTy &DT) { return DT.getPointer(); }\n  static AbstractAttribute *DepGetValAA(DepTy &DT) {\n    return cast<AbstractAttribute>(DT.getPointer());\n  }\n\n  operator AbstractAttribute *() { return cast<AbstractAttribute>(this); }\n\npublic:\n  using iterator =\n      mapped_iterator<TinyPtrVector<DepTy>::iterator, decltype(&DepGetVal)>;\n  using aaiterator =\n      mapped_iterator<TinyPtrVector<DepTy>::iterator, decltype(&DepGetValAA)>;\n\n  aaiterator begin() { return aaiterator(Deps.begin(), &DepGetValAA); }\n  aaiterator end() { return aaiterator(Deps.end(), &DepGetValAA); }\n  iterator child_begin() { return iterator(Deps.begin(), &DepGetVal); }\n  iterator child_end() { return iterator(Deps.end(), &DepGetVal); }\n\n  virtual void print(raw_ostream &OS) const { OS << \"AADepNode Impl\\n\"; }\n  TinyPtrVector<DepTy> &getDeps() { return Deps; }\n\n  friend struct Attributor;\n  friend struct AADepGraph;\n};\n\n/// The data structure for the dependency graph\n///\n/// Note that in this graph if there is an edge from A to B (A -> B),\n/// then it means that B depends on A, and when the state of A is\n/// updated, node B should also be updated\nstruct AADepGraph {\n  AADepGraph() {}\n  ~AADepGraph() {}\n\n  using DepTy = AADepGraphNode::DepTy;\n  static AADepGraphNode *DepGetVal(DepTy &DT) { return DT.getPointer(); }\n  using iterator =\n      mapped_iterator<TinyPtrVector<DepTy>::iterator, decltype(&DepGetVal)>;\n\n  /// There is no root node for the dependency graph. But the SCCIterator\n  /// requires a single entry point, so we maintain a fake(\"synthetic\") root\n  /// node that depends on every node.\n  AADepGraphNode SyntheticRoot;\n  AADepGraphNode *GetEntryNode() { return &SyntheticRoot; }\n\n  iterator begin() { return SyntheticRoot.child_begin(); }\n  iterator end() { return SyntheticRoot.child_end(); }\n\n  void viewGraph();\n\n  /// Dump graph to file\n  void dumpGraph();\n\n  /// Print dependency graph\n  void print();\n};\n\n/// Helper to describe and deal with positions in the LLVM-IR.\n///\n/// A position in the IR is described by an anchor value and an \"offset\" that\n/// could be the argument number, for call sites and arguments, or an indicator\n/// of the \"position kind\". The kinds, specified in the Kind enum below, include\n/// the locations in the attribute list, i.a., function scope and return value,\n/// as well as a distinction between call sites and functions. Finally, there\n/// are floating values that do not have a corresponding attribute list\n/// position.\nstruct IRPosition {\n  // NOTE: In the future this definition can be changed to support recursive\n  // functions.\n  using CallBaseContext = CallBase;\n\n  /// The positions we distinguish in the IR.\n  enum Kind : char {\n    IRP_INVALID,  ///< An invalid position.\n    IRP_FLOAT,    ///< A position that is not associated with a spot suitable\n                  ///< for attributes. This could be any value or instruction.\n    IRP_RETURNED, ///< An attribute for the function return value.\n    IRP_CALL_SITE_RETURNED, ///< An attribute for a call site return value.\n    IRP_FUNCTION,           ///< An attribute for a function (scope).\n    IRP_CALL_SITE,          ///< An attribute for a call site (function scope).\n    IRP_ARGUMENT,           ///< An attribute for a function argument.\n    IRP_CALL_SITE_ARGUMENT, ///< An attribute for a call site argument.\n  };\n\n  /// Default constructor available to create invalid positions implicitly. All\n  /// other positions need to be created explicitly through the appropriate\n  /// static member function.\n  IRPosition() : Enc(nullptr, ENC_VALUE) { verify(); }\n\n  /// Create a position describing the value of \\p V.\n  static const IRPosition value(const Value &V,\n                                const CallBaseContext *CBContext = nullptr) {\n    if (auto *Arg = dyn_cast<Argument>(&V))\n      return IRPosition::argument(*Arg, CBContext);\n    if (auto *CB = dyn_cast<CallBase>(&V))\n      return IRPosition::callsite_returned(*CB);\n    return IRPosition(const_cast<Value &>(V), IRP_FLOAT, CBContext);\n  }\n\n  /// Create a position describing the function scope of \\p F.\n  /// \\p CBContext is used for call base specific analysis.\n  static const IRPosition function(const Function &F,\n                                   const CallBaseContext *CBContext = nullptr) {\n    return IRPosition(const_cast<Function &>(F), IRP_FUNCTION, CBContext);\n  }\n\n  /// Create a position describing the returned value of \\p F.\n  /// \\p CBContext is used for call base specific analysis.\n  static const IRPosition returned(const Function &F,\n                                   const CallBaseContext *CBContext = nullptr) {\n    return IRPosition(const_cast<Function &>(F), IRP_RETURNED, CBContext);\n  }\n\n  /// Create a position describing the argument \\p Arg.\n  /// \\p CBContext is used for call base specific analysis.\n  static const IRPosition argument(const Argument &Arg,\n                                   const CallBaseContext *CBContext = nullptr) {\n    return IRPosition(const_cast<Argument &>(Arg), IRP_ARGUMENT, CBContext);\n  }\n\n  /// Create a position describing the function scope of \\p CB.\n  static const IRPosition callsite_function(const CallBase &CB) {\n    return IRPosition(const_cast<CallBase &>(CB), IRP_CALL_SITE);\n  }\n\n  /// Create a position describing the returned value of \\p CB.\n  static const IRPosition callsite_returned(const CallBase &CB) {\n    return IRPosition(const_cast<CallBase &>(CB), IRP_CALL_SITE_RETURNED);\n  }\n\n  /// Create a position describing the argument of \\p CB at position \\p ArgNo.\n  static const IRPosition callsite_argument(const CallBase &CB,\n                                            unsigned ArgNo) {\n    return IRPosition(const_cast<Use &>(CB.getArgOperandUse(ArgNo)),\n                      IRP_CALL_SITE_ARGUMENT);\n  }\n\n  /// Create a position describing the argument of \\p ACS at position \\p ArgNo.\n  static const IRPosition callsite_argument(AbstractCallSite ACS,\n                                            unsigned ArgNo) {\n    if (ACS.getNumArgOperands() <= ArgNo)\n      return IRPosition();\n    int CSArgNo = ACS.getCallArgOperandNo(ArgNo);\n    if (CSArgNo >= 0)\n      return IRPosition::callsite_argument(\n          cast<CallBase>(*ACS.getInstruction()), CSArgNo);\n    return IRPosition();\n  }\n\n  /// Create a position with function scope matching the \"context\" of \\p IRP.\n  /// If \\p IRP is a call site (see isAnyCallSitePosition()) then the result\n  /// will be a call site position, otherwise the function position of the\n  /// associated function.\n  static const IRPosition\n  function_scope(const IRPosition &IRP,\n                 const CallBaseContext *CBContext = nullptr) {\n    if (IRP.isAnyCallSitePosition()) {\n      return IRPosition::callsite_function(\n          cast<CallBase>(IRP.getAnchorValue()));\n    }\n    assert(IRP.getAssociatedFunction());\n    return IRPosition::function(*IRP.getAssociatedFunction(), CBContext);\n  }\n\n  bool operator==(const IRPosition &RHS) const {\n    return Enc == RHS.Enc && RHS.CBContext == CBContext;\n  }\n  bool operator!=(const IRPosition &RHS) const { return !(*this == RHS); }\n\n  /// Return the value this abstract attribute is anchored with.\n  ///\n  /// The anchor value might not be the associated value if the latter is not\n  /// sufficient to determine where arguments will be manifested. This is, so\n  /// far, only the case for call site arguments as the value is not sufficient\n  /// to pinpoint them. Instead, we can use the call site as an anchor.\n  Value &getAnchorValue() const {\n    switch (getEncodingBits()) {\n    case ENC_VALUE:\n    case ENC_RETURNED_VALUE:\n    case ENC_FLOATING_FUNCTION:\n      return *getAsValuePtr();\n    case ENC_CALL_SITE_ARGUMENT_USE:\n      return *(getAsUsePtr()->getUser());\n    default:\n      llvm_unreachable(\"Unkown encoding!\");\n    };\n  }\n\n  /// Return the associated function, if any.\n  Function *getAssociatedFunction() const {\n    if (auto *CB = dyn_cast<CallBase>(&getAnchorValue())) {\n      // We reuse the logic that associates callback calles to arguments of a\n      // call site here to identify the callback callee as the associated\n      // function.\n      if (Argument *Arg = getAssociatedArgument())\n        return Arg->getParent();\n      return CB->getCalledFunction();\n    }\n    return getAnchorScope();\n  }\n\n  /// Return the associated argument, if any.\n  Argument *getAssociatedArgument() const;\n\n  /// Return true if the position refers to a function interface, that is the\n  /// function scope, the function return, or an argument.\n  bool isFnInterfaceKind() const {\n    switch (getPositionKind()) {\n    case IRPosition::IRP_FUNCTION:\n    case IRPosition::IRP_RETURNED:\n    case IRPosition::IRP_ARGUMENT:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  /// Return the Function surrounding the anchor value.\n  Function *getAnchorScope() const {\n    Value &V = getAnchorValue();\n    if (isa<Function>(V))\n      return &cast<Function>(V);\n    if (isa<Argument>(V))\n      return cast<Argument>(V).getParent();\n    if (isa<Instruction>(V))\n      return cast<Instruction>(V).getFunction();\n    return nullptr;\n  }\n\n  /// Return the context instruction, if any.\n  Instruction *getCtxI() const {\n    Value &V = getAnchorValue();\n    if (auto *I = dyn_cast<Instruction>(&V))\n      return I;\n    if (auto *Arg = dyn_cast<Argument>(&V))\n      if (!Arg->getParent()->isDeclaration())\n        return &Arg->getParent()->getEntryBlock().front();\n    if (auto *F = dyn_cast<Function>(&V))\n      if (!F->isDeclaration())\n        return &(F->getEntryBlock().front());\n    return nullptr;\n  }\n\n  /// Return the value this abstract attribute is associated with.\n  Value &getAssociatedValue() const {\n    if (getCallSiteArgNo() < 0 || isa<Argument>(&getAnchorValue()))\n      return getAnchorValue();\n    assert(isa<CallBase>(&getAnchorValue()) && \"Expected a call base!\");\n    return *cast<CallBase>(&getAnchorValue())\n                ->getArgOperand(getCallSiteArgNo());\n  }\n\n  /// Return the type this abstract attribute is associated with.\n  Type *getAssociatedType() const {\n    if (getPositionKind() == IRPosition::IRP_RETURNED)\n      return getAssociatedFunction()->getReturnType();\n    return getAssociatedValue().getType();\n  }\n\n  /// Return the callee argument number of the associated value if it is an\n  /// argument or call site argument, otherwise a negative value. In contrast to\n  /// `getCallSiteArgNo` this method will always return the \"argument number\"\n  /// from the perspective of the callee. This may not the same as the call site\n  /// if this is a callback call.\n  int getCalleeArgNo() const {\n    return getArgNo(/* CallbackCalleeArgIfApplicable */ true);\n  }\n\n  /// Return the call site argument number of the associated value if it is an\n  /// argument or call site argument, otherwise a negative value. In contrast to\n  /// `getCalleArgNo` this method will always return the \"operand number\" from\n  /// the perspective of the call site. This may not the same as the callee\n  /// perspective if this is a callback call.\n  int getCallSiteArgNo() const {\n    return getArgNo(/* CallbackCalleeArgIfApplicable */ false);\n  }\n\n  /// Return the index in the attribute list for this position.\n  unsigned getAttrIdx() const {\n    switch (getPositionKind()) {\n    case IRPosition::IRP_INVALID:\n    case IRPosition::IRP_FLOAT:\n      break;\n    case IRPosition::IRP_FUNCTION:\n    case IRPosition::IRP_CALL_SITE:\n      return AttributeList::FunctionIndex;\n    case IRPosition::IRP_RETURNED:\n    case IRPosition::IRP_CALL_SITE_RETURNED:\n      return AttributeList::ReturnIndex;\n    case IRPosition::IRP_ARGUMENT:\n    case IRPosition::IRP_CALL_SITE_ARGUMENT:\n      return getCallSiteArgNo() + AttributeList::FirstArgIndex;\n    }\n    llvm_unreachable(\n        \"There is no attribute index for a floating or invalid position!\");\n  }\n\n  /// Return the associated position kind.\n  Kind getPositionKind() const {\n    char EncodingBits = getEncodingBits();\n    if (EncodingBits == ENC_CALL_SITE_ARGUMENT_USE)\n      return IRP_CALL_SITE_ARGUMENT;\n    if (EncodingBits == ENC_FLOATING_FUNCTION)\n      return IRP_FLOAT;\n\n    Value *V = getAsValuePtr();\n    if (!V)\n      return IRP_INVALID;\n    if (isa<Argument>(V))\n      return IRP_ARGUMENT;\n    if (isa<Function>(V))\n      return isReturnPosition(EncodingBits) ? IRP_RETURNED : IRP_FUNCTION;\n    if (isa<CallBase>(V))\n      return isReturnPosition(EncodingBits) ? IRP_CALL_SITE_RETURNED\n                                            : IRP_CALL_SITE;\n    return IRP_FLOAT;\n  }\n\n  /// TODO: Figure out if the attribute related helper functions should live\n  ///       here or somewhere else.\n\n  /// Return true if any kind in \\p AKs existing in the IR at a position that\n  /// will affect this one. See also getAttrs(...).\n  /// \\param IgnoreSubsumingPositions Flag to determine if subsuming positions,\n  ///                                 e.g., the function position if this is an\n  ///                                 argument position, should be ignored.\n  bool hasAttr(ArrayRef<Attribute::AttrKind> AKs,\n               bool IgnoreSubsumingPositions = false,\n               Attributor *A = nullptr) const;\n\n  /// Return the attributes of any kind in \\p AKs existing in the IR at a\n  /// position that will affect this one. While each position can only have a\n  /// single attribute of any kind in \\p AKs, there are \"subsuming\" positions\n  /// that could have an attribute as well. This method returns all attributes\n  /// found in \\p Attrs.\n  /// \\param IgnoreSubsumingPositions Flag to determine if subsuming positions,\n  ///                                 e.g., the function position if this is an\n  ///                                 argument position, should be ignored.\n  void getAttrs(ArrayRef<Attribute::AttrKind> AKs,\n                SmallVectorImpl<Attribute> &Attrs,\n                bool IgnoreSubsumingPositions = false,\n                Attributor *A = nullptr) const;\n\n  /// Remove the attribute of kind \\p AKs existing in the IR at this position.\n  void removeAttrs(ArrayRef<Attribute::AttrKind> AKs) const {\n    if (getPositionKind() == IRP_INVALID || getPositionKind() == IRP_FLOAT)\n      return;\n\n    AttributeList AttrList;\n    auto *CB = dyn_cast<CallBase>(&getAnchorValue());\n    if (CB)\n      AttrList = CB->getAttributes();\n    else\n      AttrList = getAssociatedFunction()->getAttributes();\n\n    LLVMContext &Ctx = getAnchorValue().getContext();\n    for (Attribute::AttrKind AK : AKs)\n      AttrList = AttrList.removeAttribute(Ctx, getAttrIdx(), AK);\n\n    if (CB)\n      CB->setAttributes(AttrList);\n    else\n      getAssociatedFunction()->setAttributes(AttrList);\n  }\n\n  bool isAnyCallSitePosition() const {\n    switch (getPositionKind()) {\n    case IRPosition::IRP_CALL_SITE:\n    case IRPosition::IRP_CALL_SITE_RETURNED:\n    case IRPosition::IRP_CALL_SITE_ARGUMENT:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  /// Return true if the position is an argument or call site argument.\n  bool isArgumentPosition() const {\n    switch (getPositionKind()) {\n    case IRPosition::IRP_ARGUMENT:\n    case IRPosition::IRP_CALL_SITE_ARGUMENT:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  /// Return the same position without the call base context.\n  IRPosition stripCallBaseContext() const {\n    IRPosition Result = *this;\n    Result.CBContext = nullptr;\n    return Result;\n  }\n\n  /// Get the call base context from the position.\n  const CallBaseContext *getCallBaseContext() const { return CBContext; }\n\n  /// Check if the position has any call base context.\n  bool hasCallBaseContext() const { return CBContext != nullptr; }\n\n  /// Special DenseMap key values.\n  ///\n  ///{\n  static const IRPosition EmptyKey;\n  static const IRPosition TombstoneKey;\n  ///}\n\n  /// Conversion into a void * to allow reuse of pointer hashing.\n  operator void *() const { return Enc.getOpaqueValue(); }\n\nprivate:\n  /// Private constructor for special values only!\n  explicit IRPosition(void *Ptr, const CallBaseContext *CBContext = nullptr)\n      : CBContext(CBContext) {\n    Enc.setFromOpaqueValue(Ptr);\n  }\n\n  /// IRPosition anchored at \\p AnchorVal with kind/argument numbet \\p PK.\n  explicit IRPosition(Value &AnchorVal, Kind PK,\n                      const CallBaseContext *CBContext = nullptr)\n      : CBContext(CBContext) {\n    switch (PK) {\n    case IRPosition::IRP_INVALID:\n      llvm_unreachable(\"Cannot create invalid IRP with an anchor value!\");\n      break;\n    case IRPosition::IRP_FLOAT:\n      // Special case for floating functions.\n      if (isa<Function>(AnchorVal))\n        Enc = {&AnchorVal, ENC_FLOATING_FUNCTION};\n      else\n        Enc = {&AnchorVal, ENC_VALUE};\n      break;\n    case IRPosition::IRP_FUNCTION:\n    case IRPosition::IRP_CALL_SITE:\n      Enc = {&AnchorVal, ENC_VALUE};\n      break;\n    case IRPosition::IRP_RETURNED:\n    case IRPosition::IRP_CALL_SITE_RETURNED:\n      Enc = {&AnchorVal, ENC_RETURNED_VALUE};\n      break;\n    case IRPosition::IRP_ARGUMENT:\n      Enc = {&AnchorVal, ENC_VALUE};\n      break;\n    case IRPosition::IRP_CALL_SITE_ARGUMENT:\n      llvm_unreachable(\n          \"Cannot create call site argument IRP with an anchor value!\");\n      break;\n    }\n    verify();\n  }\n\n  /// Return the callee argument number of the associated value if it is an\n  /// argument or call site argument. See also `getCalleeArgNo` and\n  /// `getCallSiteArgNo`.\n  int getArgNo(bool CallbackCalleeArgIfApplicable) const {\n    if (CallbackCalleeArgIfApplicable)\n      if (Argument *Arg = getAssociatedArgument())\n        return Arg->getArgNo();\n    switch (getPositionKind()) {\n    case IRPosition::IRP_ARGUMENT:\n      return cast<Argument>(getAsValuePtr())->getArgNo();\n    case IRPosition::IRP_CALL_SITE_ARGUMENT: {\n      Use &U = *getAsUsePtr();\n      return cast<CallBase>(U.getUser())->getArgOperandNo(&U);\n    }\n    default:\n      return -1;\n    }\n  }\n\n  /// IRPosition for the use \\p U. The position kind \\p PK needs to be\n  /// IRP_CALL_SITE_ARGUMENT, the anchor value is the user, the associated value\n  /// the used value.\n  explicit IRPosition(Use &U, Kind PK) {\n    assert(PK == IRP_CALL_SITE_ARGUMENT &&\n           \"Use constructor is for call site arguments only!\");\n    Enc = {&U, ENC_CALL_SITE_ARGUMENT_USE};\n    verify();\n  }\n\n  /// Verify internal invariants.\n  void verify();\n\n  /// Return the attributes of kind \\p AK existing in the IR as attribute.\n  bool getAttrsFromIRAttr(Attribute::AttrKind AK,\n                          SmallVectorImpl<Attribute> &Attrs) const;\n\n  /// Return the attributes of kind \\p AK existing in the IR as operand bundles\n  /// of an llvm.assume.\n  bool getAttrsFromAssumes(Attribute::AttrKind AK,\n                           SmallVectorImpl<Attribute> &Attrs,\n                           Attributor &A) const;\n\n  /// Return the underlying pointer as Value *, valid for all positions but\n  /// IRP_CALL_SITE_ARGUMENT.\n  Value *getAsValuePtr() const {\n    assert(getEncodingBits() != ENC_CALL_SITE_ARGUMENT_USE &&\n           \"Not a value pointer!\");\n    return reinterpret_cast<Value *>(Enc.getPointer());\n  }\n\n  /// Return the underlying pointer as Use *, valid only for\n  /// IRP_CALL_SITE_ARGUMENT positions.\n  Use *getAsUsePtr() const {\n    assert(getEncodingBits() == ENC_CALL_SITE_ARGUMENT_USE &&\n           \"Not a value pointer!\");\n    return reinterpret_cast<Use *>(Enc.getPointer());\n  }\n\n  /// Return true if \\p EncodingBits describe a returned or call site returned\n  /// position.\n  static bool isReturnPosition(char EncodingBits) {\n    return EncodingBits == ENC_RETURNED_VALUE;\n  }\n\n  /// Return true if the encoding bits describe a returned or call site returned\n  /// position.\n  bool isReturnPosition() const { return isReturnPosition(getEncodingBits()); }\n\n  /// The encoding of the IRPosition is a combination of a pointer and two\n  /// encoding bits. The values of the encoding bits are defined in the enum\n  /// below. The pointer is either a Value* (for the first three encoding bit\n  /// combinations) or Use* (for ENC_CALL_SITE_ARGUMENT_USE).\n  ///\n  ///{\n  enum {\n    ENC_VALUE = 0b00,\n    ENC_RETURNED_VALUE = 0b01,\n    ENC_FLOATING_FUNCTION = 0b10,\n    ENC_CALL_SITE_ARGUMENT_USE = 0b11,\n  };\n\n  // Reserve the maximal amount of bits so there is no need to mask out the\n  // remaining ones. We will not encode anything else in the pointer anyway.\n  static constexpr int NumEncodingBits =\n      PointerLikeTypeTraits<void *>::NumLowBitsAvailable;\n  static_assert(NumEncodingBits >= 2, \"At least two bits are required!\");\n\n  /// The pointer with the encoding bits.\n  PointerIntPair<void *, NumEncodingBits, char> Enc;\n  ///}\n\n  /// Call base context. Used for callsite specific analysis.\n  const CallBaseContext *CBContext = nullptr;\n\n  /// Return the encoding bits.\n  char getEncodingBits() const { return Enc.getInt(); }\n};\n\n/// Helper that allows IRPosition as a key in a DenseMap.\ntemplate <> struct DenseMapInfo<IRPosition> {\n  static inline IRPosition getEmptyKey() { return IRPosition::EmptyKey; }\n  static inline IRPosition getTombstoneKey() {\n    return IRPosition::TombstoneKey;\n  }\n  static unsigned getHashValue(const IRPosition &IRP) {\n    return (DenseMapInfo<void *>::getHashValue(IRP) << 4) ^\n           (DenseMapInfo<Value *>::getHashValue(IRP.getCallBaseContext()));\n  }\n\n  static bool isEqual(const IRPosition &a, const IRPosition &b) {\n    return a == b;\n  }\n};\n\n/// A visitor class for IR positions.\n///\n/// Given a position P, the SubsumingPositionIterator allows to visit \"subsuming\n/// positions\" wrt. attributes/information. Thus, if a piece of information\n/// holds for a subsuming position, it also holds for the position P.\n///\n/// The subsuming positions always include the initial position and then,\n/// depending on the position kind, additionally the following ones:\n/// - for IRP_RETURNED:\n///   - the function (IRP_FUNCTION)\n/// - for IRP_ARGUMENT:\n///   - the function (IRP_FUNCTION)\n/// - for IRP_CALL_SITE:\n///   - the callee (IRP_FUNCTION), if known\n/// - for IRP_CALL_SITE_RETURNED:\n///   - the callee (IRP_RETURNED), if known\n///   - the call site (IRP_FUNCTION)\n///   - the callee (IRP_FUNCTION), if known\n/// - for IRP_CALL_SITE_ARGUMENT:\n///   - the argument of the callee (IRP_ARGUMENT), if known\n///   - the callee (IRP_FUNCTION), if known\n///   - the position the call site argument is associated with if it is not\n///     anchored to the call site, e.g., if it is an argument then the argument\n///     (IRP_ARGUMENT)\nclass SubsumingPositionIterator {\n  SmallVector<IRPosition, 4> IRPositions;\n  using iterator = decltype(IRPositions)::iterator;\n\npublic:\n  SubsumingPositionIterator(const IRPosition &IRP);\n  iterator begin() { return IRPositions.begin(); }\n  iterator end() { return IRPositions.end(); }\n};\n\n/// Wrapper for FunctoinAnalysisManager.\nstruct AnalysisGetter {\n  template <typename Analysis>\n  typename Analysis::Result *getAnalysis(const Function &F) {\n    if (!FAM || !F.getParent())\n      return nullptr;\n    return &FAM->getResult<Analysis>(const_cast<Function &>(F));\n  }\n\n  AnalysisGetter(FunctionAnalysisManager &FAM) : FAM(&FAM) {}\n  AnalysisGetter() {}\n\nprivate:\n  FunctionAnalysisManager *FAM = nullptr;\n};\n\n/// Data structure to hold cached (LLVM-IR) information.\n///\n/// All attributes are given an InformationCache object at creation time to\n/// avoid inspection of the IR by all of them individually. This default\n/// InformationCache will hold information required by 'default' attributes,\n/// thus the ones deduced when Attributor::identifyDefaultAbstractAttributes(..)\n/// is called.\n///\n/// If custom abstract attributes, registered manually through\n/// Attributor::registerAA(...), need more information, especially if it is not\n/// reusable, it is advised to inherit from the InformationCache and cast the\n/// instance down in the abstract attributes.\nstruct InformationCache {\n  InformationCache(const Module &M, AnalysisGetter &AG,\n                   BumpPtrAllocator &Allocator, SetVector<Function *> *CGSCC)\n      : DL(M.getDataLayout()), Allocator(Allocator),\n        Explorer(\n            /* ExploreInterBlock */ true, /* ExploreCFGForward */ true,\n            /* ExploreCFGBackward */ true,\n            /* LIGetter */\n            [&](const Function &F) { return AG.getAnalysis<LoopAnalysis>(F); },\n            /* DTGetter */\n            [&](const Function &F) {\n              return AG.getAnalysis<DominatorTreeAnalysis>(F);\n            },\n            /* PDTGetter */\n            [&](const Function &F) {\n              return AG.getAnalysis<PostDominatorTreeAnalysis>(F);\n            }),\n        AG(AG), CGSCC(CGSCC) {\n    if (CGSCC)\n      initializeModuleSlice(*CGSCC);\n  }\n\n  ~InformationCache() {\n    // The FunctionInfo objects are allocated via a BumpPtrAllocator, we call\n    // the destructor manually.\n    for (auto &It : FuncInfoMap)\n      It.getSecond()->~FunctionInfo();\n  }\n\n  /// Apply \\p CB to all uses of \\p F. If \\p LookThroughConstantExprUses is\n  /// true, constant expression users are not given to \\p CB but their uses are\n  /// traversed transitively.\n  template <typename CBTy>\n  static void foreachUse(Function &F, CBTy CB,\n                         bool LookThroughConstantExprUses = true) {\n    SmallVector<Use *, 8> Worklist(make_pointer_range(F.uses()));\n\n    for (unsigned Idx = 0; Idx < Worklist.size(); ++Idx) {\n      Use &U = *Worklist[Idx];\n\n      // Allow use in constant bitcasts and simply look through them.\n      if (LookThroughConstantExprUses && isa<ConstantExpr>(U.getUser())) {\n        for (Use &CEU : cast<ConstantExpr>(U.getUser())->uses())\n          Worklist.push_back(&CEU);\n        continue;\n      }\n\n      CB(U);\n    }\n  }\n\n  /// Initialize the ModuleSlice member based on \\p SCC. ModuleSlices contains\n  /// (a subset of) all functions that we can look at during this SCC traversal.\n  /// This includes functions (transitively) called from the SCC and the\n  /// (transitive) callers of SCC functions. We also can look at a function if\n  /// there is a \"reference edge\", i.a., if the function somehow uses (!=calls)\n  /// a function in the SCC or a caller of a function in the SCC.\n  void initializeModuleSlice(SetVector<Function *> &SCC) {\n    ModuleSlice.insert(SCC.begin(), SCC.end());\n\n    SmallPtrSet<Function *, 16> Seen;\n    SmallVector<Function *, 16> Worklist(SCC.begin(), SCC.end());\n    while (!Worklist.empty()) {\n      Function *F = Worklist.pop_back_val();\n      ModuleSlice.insert(F);\n\n      for (Instruction &I : instructions(*F))\n        if (auto *CB = dyn_cast<CallBase>(&I))\n          if (Function *Callee = CB->getCalledFunction())\n            if (Seen.insert(Callee).second)\n              Worklist.push_back(Callee);\n    }\n\n    Seen.clear();\n    Worklist.append(SCC.begin(), SCC.end());\n    while (!Worklist.empty()) {\n      Function *F = Worklist.pop_back_val();\n      ModuleSlice.insert(F);\n\n      // Traverse all transitive uses.\n      foreachUse(*F, [&](Use &U) {\n        if (auto *UsrI = dyn_cast<Instruction>(U.getUser()))\n          if (Seen.insert(UsrI->getFunction()).second)\n            Worklist.push_back(UsrI->getFunction());\n      });\n    }\n  }\n\n  /// The slice of the module we are allowed to look at.\n  SmallPtrSet<Function *, 8> ModuleSlice;\n\n  /// A vector type to hold instructions.\n  using InstructionVectorTy = SmallVector<Instruction *, 8>;\n\n  /// A map type from opcodes to instructions with this opcode.\n  using OpcodeInstMapTy = DenseMap<unsigned, InstructionVectorTy *>;\n\n  /// Return the map that relates \"interesting\" opcodes with all instructions\n  /// with that opcode in \\p F.\n  OpcodeInstMapTy &getOpcodeInstMapForFunction(const Function &F) {\n    return getFunctionInfo(F).OpcodeInstMap;\n  }\n\n  /// Return the instructions in \\p F that may read or write memory.\n  InstructionVectorTy &getReadOrWriteInstsForFunction(const Function &F) {\n    return getFunctionInfo(F).RWInsts;\n  }\n\n  /// Return MustBeExecutedContextExplorer\n  MustBeExecutedContextExplorer &getMustBeExecutedContextExplorer() {\n    return Explorer;\n  }\n\n  /// Return TargetLibraryInfo for function \\p F.\n  TargetLibraryInfo *getTargetLibraryInfoForFunction(const Function &F) {\n    return AG.getAnalysis<TargetLibraryAnalysis>(F);\n  }\n\n  /// Return AliasAnalysis Result for function \\p F.\n  AAResults *getAAResultsForFunction(const Function &F);\n\n  /// Return true if \\p Arg is involved in a must-tail call, thus the argument\n  /// of the caller or callee.\n  bool isInvolvedInMustTailCall(const Argument &Arg) {\n    FunctionInfo &FI = getFunctionInfo(*Arg.getParent());\n    return FI.CalledViaMustTail || FI.ContainsMustTailCall;\n  }\n\n  /// Return the analysis result from a pass \\p AP for function \\p F.\n  template <typename AP>\n  typename AP::Result *getAnalysisResultForFunction(const Function &F) {\n    return AG.getAnalysis<AP>(F);\n  }\n\n  /// Return SCC size on call graph for function \\p F or 0 if unknown.\n  unsigned getSccSize(const Function &F) {\n    if (CGSCC && CGSCC->count(const_cast<Function *>(&F)))\n      return CGSCC->size();\n    return 0;\n  }\n\n  /// Return datalayout used in the module.\n  const DataLayout &getDL() { return DL; }\n\n  /// Return the map conaining all the knowledge we have from `llvm.assume`s.\n  const RetainedKnowledgeMap &getKnowledgeMap() const { return KnowledgeMap; }\n\n  /// Return if \\p To is potentially reachable form \\p From or not\n  /// If the same query was answered, return cached result\n  bool getPotentiallyReachable(const Instruction &From, const Instruction &To) {\n    auto KeyPair = std::make_pair(&From, &To);\n    auto Iter = PotentiallyReachableMap.find(KeyPair);\n    if (Iter != PotentiallyReachableMap.end())\n      return Iter->second;\n    const Function &F = *From.getFunction();\n    bool Result = isPotentiallyReachable(\n        &From, &To, nullptr, AG.getAnalysis<DominatorTreeAnalysis>(F),\n        AG.getAnalysis<LoopAnalysis>(F));\n    PotentiallyReachableMap.insert(std::make_pair(KeyPair, Result));\n    return Result;\n  }\n\n  /// Check whether \\p F is part of module slice.\n  bool isInModuleSlice(const Function &F) {\n    return ModuleSlice.count(const_cast<Function *>(&F));\n  }\n\nprivate:\n  struct FunctionInfo {\n    ~FunctionInfo();\n\n    /// A nested map that remembers all instructions in a function with a\n    /// certain instruction opcode (Instruction::getOpcode()).\n    OpcodeInstMapTy OpcodeInstMap;\n\n    /// A map from functions to their instructions that may read or write\n    /// memory.\n    InstructionVectorTy RWInsts;\n\n    /// Function is called by a `musttail` call.\n    bool CalledViaMustTail;\n\n    /// Function contains a `musttail` call.\n    bool ContainsMustTailCall;\n  };\n\n  /// A map type from functions to informatio about it.\n  DenseMap<const Function *, FunctionInfo *> FuncInfoMap;\n\n  /// Return information about the function \\p F, potentially by creating it.\n  FunctionInfo &getFunctionInfo(const Function &F) {\n    FunctionInfo *&FI = FuncInfoMap[&F];\n    if (!FI) {\n      FI = new (Allocator) FunctionInfo();\n      initializeInformationCache(F, *FI);\n    }\n    return *FI;\n  }\n\n  /// Initialize the function information cache \\p FI for the function \\p F.\n  ///\n  /// This method needs to be called for all function that might be looked at\n  /// through the information cache interface *prior* to looking at them.\n  void initializeInformationCache(const Function &F, FunctionInfo &FI);\n\n  /// The datalayout used in the module.\n  const DataLayout &DL;\n\n  /// The allocator used to allocate memory, e.g. for `FunctionInfo`s.\n  BumpPtrAllocator &Allocator;\n\n  /// MustBeExecutedContextExplorer\n  MustBeExecutedContextExplorer Explorer;\n\n  /// A map with knowledge retained in `llvm.assume` instructions.\n  RetainedKnowledgeMap KnowledgeMap;\n\n  /// Getters for analysis.\n  AnalysisGetter &AG;\n\n  /// The underlying CGSCC, or null if not available.\n  SetVector<Function *> *CGSCC;\n\n  /// Set of inlineable functions\n  SmallPtrSet<const Function *, 8> InlineableFunctions;\n\n  /// A map for caching results of queries for isPotentiallyReachable\n  DenseMap<std::pair<const Instruction *, const Instruction *>, bool>\n      PotentiallyReachableMap;\n\n  /// Give the Attributor access to the members so\n  /// Attributor::identifyDefaultAbstractAttributes(...) can initialize them.\n  friend struct Attributor;\n};\n\n/// The fixpoint analysis framework that orchestrates the attribute deduction.\n///\n/// The Attributor provides a general abstract analysis framework (guided\n/// fixpoint iteration) as well as helper functions for the deduction of\n/// (LLVM-IR) attributes. However, also other code properties can be deduced,\n/// propagated, and ultimately manifested through the Attributor framework. This\n/// is particularly useful if these properties interact with attributes and a\n/// co-scheduled deduction allows to improve the solution. Even if not, thus if\n/// attributes/properties are completely isolated, they should use the\n/// Attributor framework to reduce the number of fixpoint iteration frameworks\n/// in the code base. Note that the Attributor design makes sure that isolated\n/// attributes are not impacted, in any way, by others derived at the same time\n/// if there is no cross-reasoning performed.\n///\n/// The public facing interface of the Attributor is kept simple and basically\n/// allows abstract attributes to one thing, query abstract attributes\n/// in-flight. There are two reasons to do this:\n///    a) The optimistic state of one abstract attribute can justify an\n///       optimistic state of another, allowing to framework to end up with an\n///       optimistic (=best possible) fixpoint instead of one based solely on\n///       information in the IR.\n///    b) This avoids reimplementing various kinds of lookups, e.g., to check\n///       for existing IR attributes, in favor of a single lookups interface\n///       provided by an abstract attribute subclass.\n///\n/// NOTE: The mechanics of adding a new \"concrete\" abstract attribute are\n///       described in the file comment.\nstruct Attributor {\n  /// Constructor\n  ///\n  /// \\param Functions The set of functions we are deriving attributes for.\n  /// \\param InfoCache Cache to hold various information accessible for\n  ///                  the abstract attributes.\n  /// \\param CGUpdater Helper to update an underlying call graph.\n  /// \\param Allowed If not null, a set limiting the attribute opportunities.\n  /// \\param DeleteFns Whether to delete functions\n  Attributor(SetVector<Function *> &Functions, InformationCache &InfoCache,\n             CallGraphUpdater &CGUpdater,\n             DenseSet<const char *> *Allowed = nullptr, bool DeleteFns = true)\n      : Allocator(InfoCache.Allocator), Functions(Functions),\n        InfoCache(InfoCache), CGUpdater(CGUpdater), Allowed(Allowed),\n        DeleteFns(DeleteFns) {}\n\n  ~Attributor();\n\n  /// Run the analyses until a fixpoint is reached or enforced (timeout).\n  ///\n  /// The attributes registered with this Attributor can be used after as long\n  /// as the Attributor is not destroyed (it owns the attributes now).\n  ///\n  /// \\Returns CHANGED if the IR was changed, otherwise UNCHANGED.\n  ChangeStatus run();\n\n  /// Lookup an abstract attribute of type \\p AAType at position \\p IRP. While\n  /// no abstract attribute is found equivalent positions are checked, see\n  /// SubsumingPositionIterator. Thus, the returned abstract attribute\n  /// might be anchored at a different position, e.g., the callee if \\p IRP is a\n  /// call base.\n  ///\n  /// This method is the only (supported) way an abstract attribute can retrieve\n  /// information from another abstract attribute. As an example, take an\n  /// abstract attribute that determines the memory access behavior for a\n  /// argument (readnone, readonly, ...). It should use `getAAFor` to get the\n  /// most optimistic information for other abstract attributes in-flight, e.g.\n  /// the one reasoning about the \"captured\" state for the argument or the one\n  /// reasoning on the memory access behavior of the function as a whole.\n  ///\n  /// If the DepClass enum is set to `DepClassTy::None` the dependence from\n  /// \\p QueryingAA to the return abstract attribute is not automatically\n  /// recorded. This should only be used if the caller will record the\n  /// dependence explicitly if necessary, thus if it the returned abstract\n  /// attribute is used for reasoning. To record the dependences explicitly use\n  /// the `Attributor::recordDependence` method.\n  template <typename AAType>\n  const AAType &getAAFor(const AbstractAttribute &QueryingAA,\n                         const IRPosition &IRP, DepClassTy DepClass) {\n    return getOrCreateAAFor<AAType>(IRP, &QueryingAA, DepClass,\n                                    /* ForceUpdate */ false);\n  }\n\n  /// Similar to getAAFor but the return abstract attribute will be updated (via\n  /// `AbstractAttribute::update`) even if it is found in the cache. This is\n  /// especially useful for AAIsDead as changes in liveness can make updates\n  /// possible/useful that were not happening before as the abstract attribute\n  /// was assumed dead.\n  template <typename AAType>\n  const AAType &getAndUpdateAAFor(const AbstractAttribute &QueryingAA,\n                                  const IRPosition &IRP, DepClassTy DepClass) {\n    return getOrCreateAAFor<AAType>(IRP, &QueryingAA, DepClass,\n                                    /* ForceUpdate */ true);\n  }\n\n  /// The version of getAAFor that allows to omit a querying abstract\n  /// attribute. Using this after Attributor started running is restricted to\n  /// only the Attributor itself. Initial seeding of AAs can be done via this\n  /// function.\n  /// NOTE: ForceUpdate is ignored in any stage other than the update stage.\n  template <typename AAType>\n  const AAType &\n  getOrCreateAAFor(IRPosition IRP, const AbstractAttribute *QueryingAA,\n                   DepClassTy DepClass, bool ForceUpdate = false) {\n#ifdef EXPENSIVE_CHECKS\n    // Don't allow callbase information to leak.\n    if (auto CBContext = IRP.getCallBaseContext()) {\n      assert(\n          ((CBContext->getCalledFunction() == IRP.getAnchorScope() ||\n            QueryingAA ||\n            !QueryingAA.getIRPosition().isAnyCallSitePosition())) &&\n          \"non callsite positions are not allowed to propagate CallBaseContext \"\n          \"across functions\");\n    }\n#endif\n    if (!shouldPropagateCallBaseContext(IRP))\n      IRP = IRP.stripCallBaseContext();\n\n    if (AAType *AAPtr = lookupAAFor<AAType>(IRP, QueryingAA, DepClass)) {\n      if (ForceUpdate && Phase == AttributorPhase::UPDATE)\n        updateAA(*AAPtr);\n      return *AAPtr;\n    }\n\n    // No matching attribute found, create one.\n    // Use the static create method.\n    auto &AA = AAType::createForPosition(IRP, *this);\n\n    // If we are currenty seeding attributes, enforce seeding rules.\n    if (Phase == AttributorPhase::SEEDING && !shouldSeedAttribute(AA)) {\n      AA.getState().indicatePessimisticFixpoint();\n      return AA;\n    }\n\n    registerAA(AA);\n\n    // For now we ignore naked and optnone functions.\n    bool Invalidate = Allowed && !Allowed->count(&AAType::ID);\n    const Function *FnScope = IRP.getAnchorScope();\n    if (FnScope)\n      Invalidate |= FnScope->hasFnAttribute(Attribute::Naked) ||\n                    FnScope->hasFnAttribute(Attribute::OptimizeNone);\n\n    // Avoid too many nested initializations to prevent a stack overflow.\n    Invalidate |= InitializationChainLength > MaxInitializationChainLength;\n\n    // Bootstrap the new attribute with an initial update to propagate\n    // information, e.g., function -> call site. If it is not on a given\n    // Allowed we will not perform updates at all.\n    if (Invalidate) {\n      AA.getState().indicatePessimisticFixpoint();\n      return AA;\n    }\n\n    {\n      TimeTraceScope TimeScope(AA.getName() + \"::initialize\");\n      ++InitializationChainLength;\n      AA.initialize(*this);\n      --InitializationChainLength;\n    }\n\n    // Initialize and update is allowed for code outside of the current function\n    // set, but only if it is part of module slice we are allowed to look at.\n    // Only exception is AAIsDeadFunction whose initialization is prevented\n    // directly, since we don't to compute it twice.\n    if (FnScope && !Functions.count(const_cast<Function *>(FnScope))) {\n      if (!getInfoCache().isInModuleSlice(*FnScope)) {\n        AA.getState().indicatePessimisticFixpoint();\n        return AA;\n      }\n    }\n\n    // If this is queried in the manifest stage, we force the AA to indicate\n    // pessimistic fixpoint immediately.\n    if (Phase == AttributorPhase::MANIFEST) {\n      AA.getState().indicatePessimisticFixpoint();\n      return AA;\n    }\n\n    // Allow seeded attributes to declare dependencies.\n    // Remember the seeding state.\n    AttributorPhase OldPhase = Phase;\n    Phase = AttributorPhase::UPDATE;\n\n    updateAA(AA);\n\n    Phase = OldPhase;\n\n    if (QueryingAA && AA.getState().isValidState())\n      recordDependence(AA, const_cast<AbstractAttribute &>(*QueryingAA),\n                       DepClass);\n    return AA;\n  }\n  template <typename AAType>\n  const AAType &getOrCreateAAFor(const IRPosition &IRP) {\n    return getOrCreateAAFor<AAType>(IRP, /* QueryingAA */ nullptr,\n                                    DepClassTy::NONE);\n  }\n\n  /// Return the attribute of \\p AAType for \\p IRP if existing. This also allows\n  /// non-AA users lookup.\n  template <typename AAType>\n  AAType *lookupAAFor(const IRPosition &IRP,\n                      const AbstractAttribute *QueryingAA = nullptr,\n                      DepClassTy DepClass = DepClassTy::OPTIONAL) {\n    static_assert(std::is_base_of<AbstractAttribute, AAType>::value,\n                  \"Cannot query an attribute with a type not derived from \"\n                  \"'AbstractAttribute'!\");\n    // Lookup the abstract attribute of type AAType. If found, return it after\n    // registering a dependence of QueryingAA on the one returned attribute.\n    AbstractAttribute *AAPtr = AAMap.lookup({&AAType::ID, IRP});\n    if (!AAPtr)\n      return nullptr;\n\n    AAType *AA = static_cast<AAType *>(AAPtr);\n\n    // Do not register a dependence on an attribute with an invalid state.\n    if (DepClass != DepClassTy::NONE && QueryingAA &&\n        AA->getState().isValidState())\n      recordDependence(*AA, const_cast<AbstractAttribute &>(*QueryingAA),\n                       DepClass);\n    return AA;\n  }\n\n  /// Explicitly record a dependence from \\p FromAA to \\p ToAA, that is if\n  /// \\p FromAA changes \\p ToAA should be updated as well.\n  ///\n  /// This method should be used in conjunction with the `getAAFor` method and\n  /// with the DepClass enum passed to the method set to None. This can\n  /// be beneficial to avoid false dependences but it requires the users of\n  /// `getAAFor` to explicitly record true dependences through this method.\n  /// The \\p DepClass flag indicates if the dependence is striclty necessary.\n  /// That means for required dependences, if \\p FromAA changes to an invalid\n  /// state, \\p ToAA can be moved to a pessimistic fixpoint because it required\n  /// information from \\p FromAA but none are available anymore.\n  void recordDependence(const AbstractAttribute &FromAA,\n                        const AbstractAttribute &ToAA, DepClassTy DepClass);\n\n  /// Introduce a new abstract attribute into the fixpoint analysis.\n  ///\n  /// Note that ownership of the attribute is given to the Attributor. It will\n  /// invoke delete for the Attributor on destruction of the Attributor.\n  ///\n  /// Attributes are identified by their IR position (AAType::getIRPosition())\n  /// and the address of their static member (see AAType::ID).\n  template <typename AAType> AAType &registerAA(AAType &AA) {\n    static_assert(std::is_base_of<AbstractAttribute, AAType>::value,\n                  \"Cannot register an attribute with a type not derived from \"\n                  \"'AbstractAttribute'!\");\n    // Put the attribute in the lookup map structure and the container we use to\n    // keep track of all attributes.\n    const IRPosition &IRP = AA.getIRPosition();\n    AbstractAttribute *&AAPtr = AAMap[{&AAType::ID, IRP}];\n\n    assert(!AAPtr && \"Attribute already in map!\");\n    AAPtr = &AA;\n\n    // Register AA with the synthetic root only before the manifest stage.\n    if (Phase == AttributorPhase::SEEDING || Phase == AttributorPhase::UPDATE)\n      DG.SyntheticRoot.Deps.push_back(\n          AADepGraphNode::DepTy(&AA, unsigned(DepClassTy::REQUIRED)));\n\n    return AA;\n  }\n\n  /// Return the internal information cache.\n  InformationCache &getInfoCache() { return InfoCache; }\n\n  /// Return true if this is a module pass, false otherwise.\n  bool isModulePass() const {\n    return !Functions.empty() &&\n           Functions.size() == Functions.front()->getParent()->size();\n  }\n\n  /// Return true if we derive attributes for \\p Fn\n  bool isRunOn(Function &Fn) const {\n    return Functions.empty() || Functions.count(&Fn);\n  }\n\n  /// Determine opportunities to derive 'default' attributes in \\p F and create\n  /// abstract attribute objects for them.\n  ///\n  /// \\param F The function that is checked for attribute opportunities.\n  ///\n  /// Note that abstract attribute instances are generally created even if the\n  /// IR already contains the information they would deduce. The most important\n  /// reason for this is the single interface, the one of the abstract attribute\n  /// instance, which can be queried without the need to look at the IR in\n  /// various places.\n  void identifyDefaultAbstractAttributes(Function &F);\n\n  /// Determine whether the function \\p F is IPO amendable\n  ///\n  /// If a function is exactly defined or it has alwaysinline attribute\n  /// and is viable to be inlined, we say it is IPO amendable\n  bool isFunctionIPOAmendable(const Function &F) {\n    return F.hasExactDefinition() || InfoCache.InlineableFunctions.count(&F);\n  }\n\n  /// Mark the internal function \\p F as live.\n  ///\n  /// This will trigger the identification and initialization of attributes for\n  /// \\p F.\n  void markLiveInternalFunction(const Function &F) {\n    assert(F.hasLocalLinkage() &&\n           \"Only local linkage is assumed dead initially.\");\n\n    identifyDefaultAbstractAttributes(const_cast<Function &>(F));\n  }\n\n  /// Helper function to remove callsite.\n  void removeCallSite(CallInst *CI) {\n    if (!CI)\n      return;\n\n    CGUpdater.removeCallSite(*CI);\n  }\n\n  /// Record that \\p U is to be replaces with \\p NV after information was\n  /// manifested. This also triggers deletion of trivially dead istructions.\n  bool changeUseAfterManifest(Use &U, Value &NV) {\n    Value *&V = ToBeChangedUses[&U];\n    if (V && (V->stripPointerCasts() == NV.stripPointerCasts() ||\n              isa_and_nonnull<UndefValue>(V)))\n      return false;\n    assert((!V || V == &NV || isa<UndefValue>(NV)) &&\n           \"Use was registered twice for replacement with different values!\");\n    V = &NV;\n    return true;\n  }\n\n  /// Helper function to replace all uses of \\p V with \\p NV. Return true if\n  /// there is any change. The flag \\p ChangeDroppable indicates if dropppable\n  /// uses should be changed too.\n  bool changeValueAfterManifest(Value &V, Value &NV,\n                                bool ChangeDroppable = true) {\n    bool Changed = false;\n    for (auto &U : V.uses())\n      if (ChangeDroppable || !U.getUser()->isDroppable())\n        Changed |= changeUseAfterManifest(U, NV);\n\n    return Changed;\n  }\n\n  /// Record that \\p I is to be replaced with `unreachable` after information\n  /// was manifested.\n  void changeToUnreachableAfterManifest(Instruction *I) {\n    ToBeChangedToUnreachableInsts.insert(I);\n  }\n\n  /// Record that \\p II has at least one dead successor block. This information\n  /// is used, e.g., to replace \\p II with a call, after information was\n  /// manifested.\n  void registerInvokeWithDeadSuccessor(InvokeInst &II) {\n    InvokeWithDeadSuccessor.push_back(&II);\n  }\n\n  /// Record that \\p I is deleted after information was manifested. This also\n  /// triggers deletion of trivially dead istructions.\n  void deleteAfterManifest(Instruction &I) { ToBeDeletedInsts.insert(&I); }\n\n  /// Record that \\p BB is deleted after information was manifested. This also\n  /// triggers deletion of trivially dead istructions.\n  void deleteAfterManifest(BasicBlock &BB) { ToBeDeletedBlocks.insert(&BB); }\n\n  /// Record that \\p F is deleted after information was manifested.\n  void deleteAfterManifest(Function &F) {\n    if (DeleteFns)\n      ToBeDeletedFunctions.insert(&F);\n  }\n\n  /// If \\p V is assumed to be a constant, return it, if it is unclear yet,\n  /// return None, otherwise return `nullptr`.\n  Optional<Constant *> getAssumedConstant(const Value &V,\n                                          const AbstractAttribute &AA,\n                                          bool &UsedAssumedInformation);\n\n  /// Return true if \\p AA (or its context instruction) is assumed dead.\n  ///\n  /// If \\p LivenessAA is not provided it is queried.\n  bool isAssumedDead(const AbstractAttribute &AA, const AAIsDead *LivenessAA,\n                     bool CheckBBLivenessOnly = false,\n                     DepClassTy DepClass = DepClassTy::OPTIONAL);\n\n  /// Return true if \\p I is assumed dead.\n  ///\n  /// If \\p LivenessAA is not provided it is queried.\n  bool isAssumedDead(const Instruction &I, const AbstractAttribute *QueryingAA,\n                     const AAIsDead *LivenessAA,\n                     bool CheckBBLivenessOnly = false,\n                     DepClassTy DepClass = DepClassTy::OPTIONAL);\n\n  /// Return true if \\p U is assumed dead.\n  ///\n  /// If \\p FnLivenessAA is not provided it is queried.\n  bool isAssumedDead(const Use &U, const AbstractAttribute *QueryingAA,\n                     const AAIsDead *FnLivenessAA,\n                     bool CheckBBLivenessOnly = false,\n                     DepClassTy DepClass = DepClassTy::OPTIONAL);\n\n  /// Return true if \\p IRP is assumed dead.\n  ///\n  /// If \\p FnLivenessAA is not provided it is queried.\n  bool isAssumedDead(const IRPosition &IRP, const AbstractAttribute *QueryingAA,\n                     const AAIsDead *FnLivenessAA,\n                     bool CheckBBLivenessOnly = false,\n                     DepClassTy DepClass = DepClassTy::OPTIONAL);\n\n  /// Check \\p Pred on all (transitive) uses of \\p V.\n  ///\n  /// This method will evaluate \\p Pred on all (transitive) uses of the\n  /// associated value and return true if \\p Pred holds every time.\n  bool checkForAllUses(function_ref<bool(const Use &, bool &)> Pred,\n                       const AbstractAttribute &QueryingAA, const Value &V,\n                       DepClassTy LivenessDepClass = DepClassTy::OPTIONAL);\n\n  /// Helper struct used in the communication between an abstract attribute (AA)\n  /// that wants to change the signature of a function and the Attributor which\n  /// applies the changes. The struct is partially initialized with the\n  /// information from the AA (see the constructor). All other members are\n  /// provided by the Attributor prior to invoking any callbacks.\n  struct ArgumentReplacementInfo {\n    /// Callee repair callback type\n    ///\n    /// The function repair callback is invoked once to rewire the replacement\n    /// arguments in the body of the new function. The argument replacement info\n    /// is passed, as build from the registerFunctionSignatureRewrite call, as\n    /// well as the replacement function and an iteratore to the first\n    /// replacement argument.\n    using CalleeRepairCBTy = std::function<void(\n        const ArgumentReplacementInfo &, Function &, Function::arg_iterator)>;\n\n    /// Abstract call site (ACS) repair callback type\n    ///\n    /// The abstract call site repair callback is invoked once on every abstract\n    /// call site of the replaced function (\\see ReplacedFn). The callback needs\n    /// to provide the operands for the call to the new replacement function.\n    /// The number and type of the operands appended to the provided vector\n    /// (second argument) is defined by the number and types determined through\n    /// the replacement type vector (\\see ReplacementTypes). The first argument\n    /// is the ArgumentReplacementInfo object registered with the Attributor\n    /// through the registerFunctionSignatureRewrite call.\n    using ACSRepairCBTy =\n        std::function<void(const ArgumentReplacementInfo &, AbstractCallSite,\n                           SmallVectorImpl<Value *> &)>;\n\n    /// Simple getters, see the corresponding members for details.\n    ///{\n\n    Attributor &getAttributor() const { return A; }\n    const Function &getReplacedFn() const { return ReplacedFn; }\n    const Argument &getReplacedArg() const { return ReplacedArg; }\n    unsigned getNumReplacementArgs() const { return ReplacementTypes.size(); }\n    const SmallVectorImpl<Type *> &getReplacementTypes() const {\n      return ReplacementTypes;\n    }\n\n    ///}\n\n  private:\n    /// Constructor that takes the argument to be replaced, the types of\n    /// the replacement arguments, as well as callbacks to repair the call sites\n    /// and new function after the replacement happened.\n    ArgumentReplacementInfo(Attributor &A, Argument &Arg,\n                            ArrayRef<Type *> ReplacementTypes,\n                            CalleeRepairCBTy &&CalleeRepairCB,\n                            ACSRepairCBTy &&ACSRepairCB)\n        : A(A), ReplacedFn(*Arg.getParent()), ReplacedArg(Arg),\n          ReplacementTypes(ReplacementTypes.begin(), ReplacementTypes.end()),\n          CalleeRepairCB(std::move(CalleeRepairCB)),\n          ACSRepairCB(std::move(ACSRepairCB)) {}\n\n    /// Reference to the attributor to allow access from the callbacks.\n    Attributor &A;\n\n    /// The \"old\" function replaced by ReplacementFn.\n    const Function &ReplacedFn;\n\n    /// The \"old\" argument replaced by new ones defined via ReplacementTypes.\n    const Argument &ReplacedArg;\n\n    /// The types of the arguments replacing ReplacedArg.\n    const SmallVector<Type *, 8> ReplacementTypes;\n\n    /// Callee repair callback, see CalleeRepairCBTy.\n    const CalleeRepairCBTy CalleeRepairCB;\n\n    /// Abstract call site (ACS) repair callback, see ACSRepairCBTy.\n    const ACSRepairCBTy ACSRepairCB;\n\n    /// Allow access to the private members from the Attributor.\n    friend struct Attributor;\n  };\n\n  /// Check if we can rewrite a function signature.\n  ///\n  /// The argument \\p Arg is replaced with new ones defined by the number,\n  /// order, and types in \\p ReplacementTypes.\n  ///\n  /// \\returns True, if the replacement can be registered, via\n  /// registerFunctionSignatureRewrite, false otherwise.\n  bool isValidFunctionSignatureRewrite(Argument &Arg,\n                                       ArrayRef<Type *> ReplacementTypes);\n\n  /// Register a rewrite for a function signature.\n  ///\n  /// The argument \\p Arg is replaced with new ones defined by the number,\n  /// order, and types in \\p ReplacementTypes. The rewiring at the call sites is\n  /// done through \\p ACSRepairCB and at the callee site through\n  /// \\p CalleeRepairCB.\n  ///\n  /// \\returns True, if the replacement was registered, false otherwise.\n  bool registerFunctionSignatureRewrite(\n      Argument &Arg, ArrayRef<Type *> ReplacementTypes,\n      ArgumentReplacementInfo::CalleeRepairCBTy &&CalleeRepairCB,\n      ArgumentReplacementInfo::ACSRepairCBTy &&ACSRepairCB);\n\n  /// Check \\p Pred on all function call sites.\n  ///\n  /// This method will evaluate \\p Pred on call sites and return\n  /// true if \\p Pred holds in every call sites. However, this is only possible\n  /// all call sites are known, hence the function has internal linkage.\n  /// If true is returned, \\p AllCallSitesKnown is set if all possible call\n  /// sites of the function have been visited.\n  bool checkForAllCallSites(function_ref<bool(AbstractCallSite)> Pred,\n                            const AbstractAttribute &QueryingAA,\n                            bool RequireAllCallSites, bool &AllCallSitesKnown);\n\n  /// Check \\p Pred on all values potentially returned by \\p F.\n  ///\n  /// This method will evaluate \\p Pred on all values potentially returned by\n  /// the function associated with \\p QueryingAA. The returned values are\n  /// matched with their respective return instructions. Returns true if \\p Pred\n  /// holds on all of them.\n  bool checkForAllReturnedValuesAndReturnInsts(\n      function_ref<bool(Value &, const SmallSetVector<ReturnInst *, 4> &)> Pred,\n      const AbstractAttribute &QueryingAA);\n\n  /// Check \\p Pred on all values potentially returned by the function\n  /// associated with \\p QueryingAA.\n  ///\n  /// This is the context insensitive version of the method above.\n  bool checkForAllReturnedValues(function_ref<bool(Value &)> Pred,\n                                 const AbstractAttribute &QueryingAA);\n\n  /// Check \\p Pred on all instructions with an opcode present in \\p Opcodes.\n  ///\n  /// This method will evaluate \\p Pred on all instructions with an opcode\n  /// present in \\p Opcode and return true if \\p Pred holds on all of them.\n  bool checkForAllInstructions(function_ref<bool(Instruction &)> Pred,\n                               const AbstractAttribute &QueryingAA,\n                               const ArrayRef<unsigned> &Opcodes,\n                               bool CheckBBLivenessOnly = false);\n\n  /// Check \\p Pred on all call-like instructions (=CallBased derived).\n  ///\n  /// See checkForAllCallLikeInstructions(...) for more information.\n  bool checkForAllCallLikeInstructions(function_ref<bool(Instruction &)> Pred,\n                                       const AbstractAttribute &QueryingAA) {\n    return checkForAllInstructions(Pred, QueryingAA,\n                                   {(unsigned)Instruction::Invoke,\n                                    (unsigned)Instruction::CallBr,\n                                    (unsigned)Instruction::Call});\n  }\n\n  /// Check \\p Pred on all Read/Write instructions.\n  ///\n  /// This method will evaluate \\p Pred on all instructions that read or write\n  /// to memory present in the information cache and return true if \\p Pred\n  /// holds on all of them.\n  bool checkForAllReadWriteInstructions(function_ref<bool(Instruction &)> Pred,\n                                        AbstractAttribute &QueryingAA);\n\n  /// Create a shallow wrapper for \\p F such that \\p F has internal linkage\n  /// afterwards. It also sets the original \\p F 's name to anonymous\n  ///\n  /// A wrapper is a function with the same type (and attributes) as \\p F\n  /// that will only call \\p F and return the result, if any.\n  ///\n  /// Assuming the declaration of looks like:\n  ///   rty F(aty0 arg0, ..., atyN argN);\n  ///\n  /// The wrapper will then look as follows:\n  ///   rty wrapper(aty0 arg0, ..., atyN argN) {\n  ///     return F(arg0, ..., argN);\n  ///   }\n  ///\n  static void createShallowWrapper(Function &F);\n\n  /// Return the data layout associated with the anchor scope.\n  const DataLayout &getDataLayout() const { return InfoCache.DL; }\n\n  /// The allocator used to allocate memory, e.g. for `AbstractAttribute`s.\n  BumpPtrAllocator &Allocator;\n\nprivate:\n  /// This method will do fixpoint iteration until fixpoint or the\n  /// maximum iteration count is reached.\n  ///\n  /// If the maximum iteration count is reached, This method will\n  /// indicate pessimistic fixpoint on attributes that transitively depend\n  /// on attributes that were scheduled for an update.\n  void runTillFixpoint();\n\n  /// Gets called after scheduling, manifests attributes to the LLVM IR.\n  ChangeStatus manifestAttributes();\n\n  /// Gets called after attributes have been manifested, cleans up the IR.\n  /// Deletes dead functions, blocks and instructions.\n  /// Rewrites function signitures and updates the call graph.\n  ChangeStatus cleanupIR();\n\n  /// Identify internal functions that are effectively dead, thus not reachable\n  /// from a live entry point. The functions are added to ToBeDeletedFunctions.\n  void identifyDeadInternalFunctions();\n\n  /// Run `::update` on \\p AA and track the dependences queried while doing so.\n  /// Also adjust the state if we know further updates are not necessary.\n  ChangeStatus updateAA(AbstractAttribute &AA);\n\n  /// Remember the dependences on the top of the dependence stack such that they\n  /// may trigger further updates. (\\see DependenceStack)\n  void rememberDependences();\n\n  /// Check \\p Pred on all call sites of \\p Fn.\n  ///\n  /// This method will evaluate \\p Pred on call sites and return\n  /// true if \\p Pred holds in every call sites. However, this is only possible\n  /// all call sites are known, hence the function has internal linkage.\n  /// If true is returned, \\p AllCallSitesKnown is set if all possible call\n  /// sites of the function have been visited.\n  bool checkForAllCallSites(function_ref<bool(AbstractCallSite)> Pred,\n                            const Function &Fn, bool RequireAllCallSites,\n                            const AbstractAttribute *QueryingAA,\n                            bool &AllCallSitesKnown);\n\n  /// Determine if CallBase context in \\p IRP should be propagated.\n  bool shouldPropagateCallBaseContext(const IRPosition &IRP);\n\n  /// Apply all requested function signature rewrites\n  /// (\\see registerFunctionSignatureRewrite) and return Changed if the module\n  /// was altered.\n  ChangeStatus\n  rewriteFunctionSignatures(SmallPtrSetImpl<Function *> &ModifiedFns);\n\n  /// Check if the Attribute \\p AA should be seeded.\n  /// See getOrCreateAAFor.\n  bool shouldSeedAttribute(AbstractAttribute &AA);\n\n  /// A nested map to lookup abstract attributes based on the argument position\n  /// on the outer level, and the addresses of the static member (AAType::ID) on\n  /// the inner level.\n  ///{\n  using AAMapKeyTy = std::pair<const char *, IRPosition>;\n  DenseMap<AAMapKeyTy, AbstractAttribute *> AAMap;\n  ///}\n\n  /// Map to remember all requested signature changes (= argument replacements).\n  DenseMap<Function *, SmallVector<std::unique_ptr<ArgumentReplacementInfo>, 8>>\n      ArgumentReplacementMap;\n\n  /// The set of functions we are deriving attributes for.\n  SetVector<Function *> &Functions;\n\n  /// The information cache that holds pre-processed (LLVM-IR) information.\n  InformationCache &InfoCache;\n\n  /// Helper to update an underlying call graph.\n  CallGraphUpdater &CGUpdater;\n\n  /// Abstract Attribute dependency graph\n  AADepGraph DG;\n\n  /// Set of functions for which we modified the content such that it might\n  /// impact the call graph.\n  SmallPtrSet<Function *, 8> CGModifiedFunctions;\n\n  /// Information about a dependence. If FromAA is changed ToAA needs to be\n  /// updated as well.\n  struct DepInfo {\n    const AbstractAttribute *FromAA;\n    const AbstractAttribute *ToAA;\n    DepClassTy DepClass;\n  };\n\n  /// The dependence stack is used to track dependences during an\n  /// `AbstractAttribute::update` call. As `AbstractAttribute::update` can be\n  /// recursive we might have multiple vectors of dependences in here. The stack\n  /// size, should be adjusted according to the expected recursion depth and the\n  /// inner dependence vector size to the expected number of dependences per\n  /// abstract attribute. Since the inner vectors are actually allocated on the\n  /// stack we can be generous with their size.\n  using DependenceVector = SmallVector<DepInfo, 8>;\n  SmallVector<DependenceVector *, 16> DependenceStack;\n\n  /// If not null, a set limiting the attribute opportunities.\n  const DenseSet<const char *> *Allowed;\n\n  /// Whether to delete functions.\n  const bool DeleteFns;\n\n  /// A set to remember the functions we already assume to be live and visited.\n  DenseSet<const Function *> VisitedFunctions;\n\n  /// Uses we replace with a new value after manifest is done. We will remove\n  /// then trivially dead instructions as well.\n  DenseMap<Use *, Value *> ToBeChangedUses;\n\n  /// Instructions we replace with `unreachable` insts after manifest is done.\n  SmallDenseSet<WeakVH, 16> ToBeChangedToUnreachableInsts;\n\n  /// Invoke instructions with at least a single dead successor block.\n  SmallVector<WeakVH, 16> InvokeWithDeadSuccessor;\n\n  /// A flag that indicates which stage of the process we are in. Initially, the\n  /// phase is SEEDING. Phase is changed in `Attributor::run()`\n  enum class AttributorPhase {\n    SEEDING,\n    UPDATE,\n    MANIFEST,\n    CLEANUP,\n  } Phase = AttributorPhase::SEEDING;\n\n  /// The current initialization chain length. Tracked to avoid stack overflows.\n  unsigned InitializationChainLength = 0;\n\n  /// Functions, blocks, and instructions we delete after manifest is done.\n  ///\n  ///{\n  SmallPtrSet<Function *, 8> ToBeDeletedFunctions;\n  SmallPtrSet<BasicBlock *, 8> ToBeDeletedBlocks;\n  SmallDenseSet<WeakVH, 8> ToBeDeletedInsts;\n  ///}\n\n  friend AADepGraph;\n};\n\n/// An interface to query the internal state of an abstract attribute.\n///\n/// The abstract state is a minimal interface that allows the Attributor to\n/// communicate with the abstract attributes about their internal state without\n/// enforcing or exposing implementation details, e.g., the (existence of an)\n/// underlying lattice.\n///\n/// It is sufficient to be able to query if a state is (1) valid or invalid, (2)\n/// at a fixpoint, and to indicate to the state that (3) an optimistic fixpoint\n/// was reached or (4) a pessimistic fixpoint was enforced.\n///\n/// All methods need to be implemented by the subclass. For the common use case,\n/// a single boolean state or a bit-encoded state, the BooleanState and\n/// {Inc,Dec,Bit}IntegerState classes are already provided. An abstract\n/// attribute can inherit from them to get the abstract state interface and\n/// additional methods to directly modify the state based if needed. See the\n/// class comments for help.\nstruct AbstractState {\n  virtual ~AbstractState() {}\n\n  /// Return if this abstract state is in a valid state. If false, no\n  /// information provided should be used.\n  virtual bool isValidState() const = 0;\n\n  /// Return if this abstract state is fixed, thus does not need to be updated\n  /// if information changes as it cannot change itself.\n  virtual bool isAtFixpoint() const = 0;\n\n  /// Indicate that the abstract state should converge to the optimistic state.\n  ///\n  /// This will usually make the optimistically assumed state the known to be\n  /// true state.\n  ///\n  /// \\returns ChangeStatus::UNCHANGED as the assumed value should not change.\n  virtual ChangeStatus indicateOptimisticFixpoint() = 0;\n\n  /// Indicate that the abstract state should converge to the pessimistic state.\n  ///\n  /// This will usually revert the optimistically assumed state to the known to\n  /// be true state.\n  ///\n  /// \\returns ChangeStatus::CHANGED as the assumed value may change.\n  virtual ChangeStatus indicatePessimisticFixpoint() = 0;\n};\n\n/// Simple state with integers encoding.\n///\n/// The interface ensures that the assumed bits are always a subset of the known\n/// bits. Users can only add known bits and, except through adding known bits,\n/// they can only remove assumed bits. This should guarantee monotoniticy and\n/// thereby the existence of a fixpoint (if used corretly). The fixpoint is\n/// reached when the assumed and known state/bits are equal. Users can\n/// force/inidicate a fixpoint. If an optimistic one is indicated, the known\n/// state will catch up with the assumed one, for a pessimistic fixpoint it is\n/// the other way around.\ntemplate <typename base_ty, base_ty BestState, base_ty WorstState>\nstruct IntegerStateBase : public AbstractState {\n  using base_t = base_ty;\n\n  IntegerStateBase() {}\n  IntegerStateBase(base_t Assumed) : Assumed(Assumed) {}\n\n  /// Return the best possible representable state.\n  static constexpr base_t getBestState() { return BestState; }\n  static constexpr base_t getBestState(const IntegerStateBase &) {\n    return getBestState();\n  }\n\n  /// Return the worst possible representable state.\n  static constexpr base_t getWorstState() { return WorstState; }\n  static constexpr base_t getWorstState(const IntegerStateBase &) {\n    return getWorstState();\n  }\n\n  /// See AbstractState::isValidState()\n  /// NOTE: For now we simply pretend that the worst possible state is invalid.\n  bool isValidState() const override { return Assumed != getWorstState(); }\n\n  /// See AbstractState::isAtFixpoint()\n  bool isAtFixpoint() const override { return Assumed == Known; }\n\n  /// See AbstractState::indicateOptimisticFixpoint(...)\n  ChangeStatus indicateOptimisticFixpoint() override {\n    Known = Assumed;\n    return ChangeStatus::UNCHANGED;\n  }\n\n  /// See AbstractState::indicatePessimisticFixpoint(...)\n  ChangeStatus indicatePessimisticFixpoint() override {\n    Assumed = Known;\n    return ChangeStatus::CHANGED;\n  }\n\n  /// Return the known state encoding\n  base_t getKnown() const { return Known; }\n\n  /// Return the assumed state encoding.\n  base_t getAssumed() const { return Assumed; }\n\n  /// Equality for IntegerStateBase.\n  bool\n  operator==(const IntegerStateBase<base_t, BestState, WorstState> &R) const {\n    return this->getAssumed() == R.getAssumed() &&\n           this->getKnown() == R.getKnown();\n  }\n\n  /// Inequality for IntegerStateBase.\n  bool\n  operator!=(const IntegerStateBase<base_t, BestState, WorstState> &R) const {\n    return !(*this == R);\n  }\n\n  /// \"Clamp\" this state with \\p R. The result is subtype dependent but it is\n  /// intended that only information assumed in both states will be assumed in\n  /// this one afterwards.\n  void operator^=(const IntegerStateBase<base_t, BestState, WorstState> &R) {\n    handleNewAssumedValue(R.getAssumed());\n  }\n\n  /// \"Clamp\" this state with \\p R. The result is subtype dependent but it is\n  /// intended that information known in either state will be known in\n  /// this one afterwards.\n  void operator+=(const IntegerStateBase<base_t, BestState, WorstState> &R) {\n    handleNewKnownValue(R.getKnown());\n  }\n\n  void operator|=(const IntegerStateBase<base_t, BestState, WorstState> &R) {\n    joinOR(R.getAssumed(), R.getKnown());\n  }\n\n  void operator&=(const IntegerStateBase<base_t, BestState, WorstState> &R) {\n    joinAND(R.getAssumed(), R.getKnown());\n  }\n\nprotected:\n  /// Handle a new assumed value \\p Value. Subtype dependent.\n  virtual void handleNewAssumedValue(base_t Value) = 0;\n\n  /// Handle a new known value \\p Value. Subtype dependent.\n  virtual void handleNewKnownValue(base_t Value) = 0;\n\n  /// Handle a  value \\p Value. Subtype dependent.\n  virtual void joinOR(base_t AssumedValue, base_t KnownValue) = 0;\n\n  /// Handle a new assumed value \\p Value. Subtype dependent.\n  virtual void joinAND(base_t AssumedValue, base_t KnownValue) = 0;\n\n  /// The known state encoding in an integer of type base_t.\n  base_t Known = getWorstState();\n\n  /// The assumed state encoding in an integer of type base_t.\n  base_t Assumed = getBestState();\n};\n\n/// Specialization of the integer state for a bit-wise encoding.\ntemplate <typename base_ty = uint32_t, base_ty BestState = ~base_ty(0),\n          base_ty WorstState = 0>\nstruct BitIntegerState\n    : public IntegerStateBase<base_ty, BestState, WorstState> {\n  using base_t = base_ty;\n\n  /// Return true if the bits set in \\p BitsEncoding are \"known bits\".\n  bool isKnown(base_t BitsEncoding) const {\n    return (this->Known & BitsEncoding) == BitsEncoding;\n  }\n\n  /// Return true if the bits set in \\p BitsEncoding are \"assumed bits\".\n  bool isAssumed(base_t BitsEncoding) const {\n    return (this->Assumed & BitsEncoding) == BitsEncoding;\n  }\n\n  /// Add the bits in \\p BitsEncoding to the \"known bits\".\n  BitIntegerState &addKnownBits(base_t Bits) {\n    // Make sure we never miss any \"known bits\".\n    this->Assumed |= Bits;\n    this->Known |= Bits;\n    return *this;\n  }\n\n  /// Remove the bits in \\p BitsEncoding from the \"assumed bits\" if not known.\n  BitIntegerState &removeAssumedBits(base_t BitsEncoding) {\n    return intersectAssumedBits(~BitsEncoding);\n  }\n\n  /// Remove the bits in \\p BitsEncoding from the \"known bits\".\n  BitIntegerState &removeKnownBits(base_t BitsEncoding) {\n    this->Known = (this->Known & ~BitsEncoding);\n    return *this;\n  }\n\n  /// Keep only \"assumed bits\" also set in \\p BitsEncoding but all known ones.\n  BitIntegerState &intersectAssumedBits(base_t BitsEncoding) {\n    // Make sure we never loose any \"known bits\".\n    this->Assumed = (this->Assumed & BitsEncoding) | this->Known;\n    return *this;\n  }\n\nprivate:\n  void handleNewAssumedValue(base_t Value) override {\n    intersectAssumedBits(Value);\n  }\n  void handleNewKnownValue(base_t Value) override { addKnownBits(Value); }\n  void joinOR(base_t AssumedValue, base_t KnownValue) override {\n    this->Known |= KnownValue;\n    this->Assumed |= AssumedValue;\n  }\n  void joinAND(base_t AssumedValue, base_t KnownValue) override {\n    this->Known &= KnownValue;\n    this->Assumed &= AssumedValue;\n  }\n};\n\n/// Specialization of the integer state for an increasing value, hence ~0u is\n/// the best state and 0 the worst.\ntemplate <typename base_ty = uint32_t, base_ty BestState = ~base_ty(0),\n          base_ty WorstState = 0>\nstruct IncIntegerState\n    : public IntegerStateBase<base_ty, BestState, WorstState> {\n  using super = IntegerStateBase<base_ty, BestState, WorstState>;\n  using base_t = base_ty;\n\n  IncIntegerState() : super() {}\n  IncIntegerState(base_t Assumed) : super(Assumed) {}\n\n  /// Return the best possible representable state.\n  static constexpr base_t getBestState() { return BestState; }\n  static constexpr base_t\n  getBestState(const IncIntegerState<base_ty, BestState, WorstState> &) {\n    return getBestState();\n  }\n\n  /// Take minimum of assumed and \\p Value.\n  IncIntegerState &takeAssumedMinimum(base_t Value) {\n    // Make sure we never loose \"known value\".\n    this->Assumed = std::max(std::min(this->Assumed, Value), this->Known);\n    return *this;\n  }\n\n  /// Take maximum of known and \\p Value.\n  IncIntegerState &takeKnownMaximum(base_t Value) {\n    // Make sure we never loose \"known value\".\n    this->Assumed = std::max(Value, this->Assumed);\n    this->Known = std::max(Value, this->Known);\n    return *this;\n  }\n\nprivate:\n  void handleNewAssumedValue(base_t Value) override {\n    takeAssumedMinimum(Value);\n  }\n  void handleNewKnownValue(base_t Value) override { takeKnownMaximum(Value); }\n  void joinOR(base_t AssumedValue, base_t KnownValue) override {\n    this->Known = std::max(this->Known, KnownValue);\n    this->Assumed = std::max(this->Assumed, AssumedValue);\n  }\n  void joinAND(base_t AssumedValue, base_t KnownValue) override {\n    this->Known = std::min(this->Known, KnownValue);\n    this->Assumed = std::min(this->Assumed, AssumedValue);\n  }\n};\n\n/// Specialization of the integer state for a decreasing value, hence 0 is the\n/// best state and ~0u the worst.\ntemplate <typename base_ty = uint32_t>\nstruct DecIntegerState : public IntegerStateBase<base_ty, 0, ~base_ty(0)> {\n  using base_t = base_ty;\n\n  /// Take maximum of assumed and \\p Value.\n  DecIntegerState &takeAssumedMaximum(base_t Value) {\n    // Make sure we never loose \"known value\".\n    this->Assumed = std::min(std::max(this->Assumed, Value), this->Known);\n    return *this;\n  }\n\n  /// Take minimum of known and \\p Value.\n  DecIntegerState &takeKnownMinimum(base_t Value) {\n    // Make sure we never loose \"known value\".\n    this->Assumed = std::min(Value, this->Assumed);\n    this->Known = std::min(Value, this->Known);\n    return *this;\n  }\n\nprivate:\n  void handleNewAssumedValue(base_t Value) override {\n    takeAssumedMaximum(Value);\n  }\n  void handleNewKnownValue(base_t Value) override { takeKnownMinimum(Value); }\n  void joinOR(base_t AssumedValue, base_t KnownValue) override {\n    this->Assumed = std::min(this->Assumed, KnownValue);\n    this->Assumed = std::min(this->Assumed, AssumedValue);\n  }\n  void joinAND(base_t AssumedValue, base_t KnownValue) override {\n    this->Assumed = std::max(this->Assumed, KnownValue);\n    this->Assumed = std::max(this->Assumed, AssumedValue);\n  }\n};\n\n/// Simple wrapper for a single bit (boolean) state.\nstruct BooleanState : public IntegerStateBase<bool, 1, 0> {\n  using super = IntegerStateBase<bool, 1, 0>;\n  using base_t = IntegerStateBase::base_t;\n\n  BooleanState() : super() {}\n  BooleanState(base_t Assumed) : super(Assumed) {}\n\n  /// Set the assumed value to \\p Value but never below the known one.\n  void setAssumed(bool Value) { Assumed &= (Known | Value); }\n\n  /// Set the known and asssumed value to \\p Value.\n  void setKnown(bool Value) {\n    Known |= Value;\n    Assumed |= Value;\n  }\n\n  /// Return true if the state is assumed to hold.\n  bool isAssumed() const { return getAssumed(); }\n\n  /// Return true if the state is known to hold.\n  bool isKnown() const { return getKnown(); }\n\nprivate:\n  void handleNewAssumedValue(base_t Value) override {\n    if (!Value)\n      Assumed = Known;\n  }\n  void handleNewKnownValue(base_t Value) override {\n    if (Value)\n      Known = (Assumed = Value);\n  }\n  void joinOR(base_t AssumedValue, base_t KnownValue) override {\n    Known |= KnownValue;\n    Assumed |= AssumedValue;\n  }\n  void joinAND(base_t AssumedValue, base_t KnownValue) override {\n    Known &= KnownValue;\n    Assumed &= AssumedValue;\n  }\n};\n\n/// State for an integer range.\nstruct IntegerRangeState : public AbstractState {\n\n  /// Bitwidth of the associated value.\n  uint32_t BitWidth;\n\n  /// State representing assumed range, initially set to empty.\n  ConstantRange Assumed;\n\n  /// State representing known range, initially set to [-inf, inf].\n  ConstantRange Known;\n\n  IntegerRangeState(uint32_t BitWidth)\n      : BitWidth(BitWidth), Assumed(ConstantRange::getEmpty(BitWidth)),\n        Known(ConstantRange::getFull(BitWidth)) {}\n\n  IntegerRangeState(const ConstantRange &CR)\n      : BitWidth(CR.getBitWidth()), Assumed(CR),\n        Known(getWorstState(CR.getBitWidth())) {}\n\n  /// Return the worst possible representable state.\n  static ConstantRange getWorstState(uint32_t BitWidth) {\n    return ConstantRange::getFull(BitWidth);\n  }\n\n  /// Return the best possible representable state.\n  static ConstantRange getBestState(uint32_t BitWidth) {\n    return ConstantRange::getEmpty(BitWidth);\n  }\n  static ConstantRange getBestState(const IntegerRangeState &IRS) {\n    return getBestState(IRS.getBitWidth());\n  }\n\n  /// Return associated values' bit width.\n  uint32_t getBitWidth() const { return BitWidth; }\n\n  /// See AbstractState::isValidState()\n  bool isValidState() const override {\n    return BitWidth > 0 && !Assumed.isFullSet();\n  }\n\n  /// See AbstractState::isAtFixpoint()\n  bool isAtFixpoint() const override { return Assumed == Known; }\n\n  /// See AbstractState::indicateOptimisticFixpoint(...)\n  ChangeStatus indicateOptimisticFixpoint() override {\n    Known = Assumed;\n    return ChangeStatus::CHANGED;\n  }\n\n  /// See AbstractState::indicatePessimisticFixpoint(...)\n  ChangeStatus indicatePessimisticFixpoint() override {\n    Assumed = Known;\n    return ChangeStatus::CHANGED;\n  }\n\n  /// Return the known state encoding\n  ConstantRange getKnown() const { return Known; }\n\n  /// Return the assumed state encoding.\n  ConstantRange getAssumed() const { return Assumed; }\n\n  /// Unite assumed range with the passed state.\n  void unionAssumed(const ConstantRange &R) {\n    // Don't loose a known range.\n    Assumed = Assumed.unionWith(R).intersectWith(Known);\n  }\n\n  /// See IntegerRangeState::unionAssumed(..).\n  void unionAssumed(const IntegerRangeState &R) {\n    unionAssumed(R.getAssumed());\n  }\n\n  /// Unite known range with the passed state.\n  void unionKnown(const ConstantRange &R) {\n    // Don't loose a known range.\n    Known = Known.unionWith(R);\n    Assumed = Assumed.unionWith(Known);\n  }\n\n  /// See IntegerRangeState::unionKnown(..).\n  void unionKnown(const IntegerRangeState &R) { unionKnown(R.getKnown()); }\n\n  /// Intersect known range with the passed state.\n  void intersectKnown(const ConstantRange &R) {\n    Assumed = Assumed.intersectWith(R);\n    Known = Known.intersectWith(R);\n  }\n\n  /// See IntegerRangeState::intersectKnown(..).\n  void intersectKnown(const IntegerRangeState &R) {\n    intersectKnown(R.getKnown());\n  }\n\n  /// Equality for IntegerRangeState.\n  bool operator==(const IntegerRangeState &R) const {\n    return getAssumed() == R.getAssumed() && getKnown() == R.getKnown();\n  }\n\n  /// \"Clamp\" this state with \\p R. The result is subtype dependent but it is\n  /// intended that only information assumed in both states will be assumed in\n  /// this one afterwards.\n  IntegerRangeState operator^=(const IntegerRangeState &R) {\n    // NOTE: `^=` operator seems like `intersect` but in this case, we need to\n    // take `union`.\n    unionAssumed(R);\n    return *this;\n  }\n\n  IntegerRangeState operator&=(const IntegerRangeState &R) {\n    // NOTE: `&=` operator seems like `intersect` but in this case, we need to\n    // take `union`.\n    unionKnown(R);\n    unionAssumed(R);\n    return *this;\n  }\n};\n/// Helper struct necessary as the modular build fails if the virtual method\n/// IRAttribute::manifest is defined in the Attributor.cpp.\nstruct IRAttributeManifest {\n  static ChangeStatus manifestAttrs(Attributor &A, const IRPosition &IRP,\n                                    const ArrayRef<Attribute> &DeducedAttrs);\n};\n\n/// Helper to tie a abstract state implementation to an abstract attribute.\ntemplate <typename StateTy, typename BaseType, class... Ts>\nstruct StateWrapper : public BaseType, public StateTy {\n  /// Provide static access to the type of the state.\n  using StateType = StateTy;\n\n  StateWrapper(const IRPosition &IRP, Ts... Args)\n      : BaseType(IRP), StateTy(Args...) {}\n\n  /// See AbstractAttribute::getState(...).\n  StateType &getState() override { return *this; }\n\n  /// See AbstractAttribute::getState(...).\n  const StateType &getState() const override { return *this; }\n};\n\n/// Helper class that provides common functionality to manifest IR attributes.\ntemplate <Attribute::AttrKind AK, typename BaseType>\nstruct IRAttribute : public BaseType {\n  IRAttribute(const IRPosition &IRP) : BaseType(IRP) {}\n\n  /// See AbstractAttribute::initialize(...).\n  virtual void initialize(Attributor &A) override {\n    const IRPosition &IRP = this->getIRPosition();\n    if (isa<UndefValue>(IRP.getAssociatedValue()) ||\n        this->hasAttr(getAttrKind(), /* IgnoreSubsumingPositions */ false,\n                      &A)) {\n      this->getState().indicateOptimisticFixpoint();\n      return;\n    }\n\n    bool IsFnInterface = IRP.isFnInterfaceKind();\n    const Function *FnScope = IRP.getAnchorScope();\n    // TODO: Not all attributes require an exact definition. Find a way to\n    //       enable deduction for some but not all attributes in case the\n    //       definition might be changed at runtime, see also\n    //       http://lists.llvm.org/pipermail/llvm-dev/2018-February/121275.html.\n    // TODO: We could always determine abstract attributes and if sufficient\n    //       information was found we could duplicate the functions that do not\n    //       have an exact definition.\n    if (IsFnInterface && (!FnScope || !A.isFunctionIPOAmendable(*FnScope)))\n      this->getState().indicatePessimisticFixpoint();\n  }\n\n  /// See AbstractAttribute::manifest(...).\n  ChangeStatus manifest(Attributor &A) override {\n    if (isa<UndefValue>(this->getIRPosition().getAssociatedValue()))\n      return ChangeStatus::UNCHANGED;\n    SmallVector<Attribute, 4> DeducedAttrs;\n    getDeducedAttributes(this->getAnchorValue().getContext(), DeducedAttrs);\n    return IRAttributeManifest::manifestAttrs(A, this->getIRPosition(),\n                                              DeducedAttrs);\n  }\n\n  /// Return the kind that identifies the abstract attribute implementation.\n  Attribute::AttrKind getAttrKind() const { return AK; }\n\n  /// Return the deduced attributes in \\p Attrs.\n  virtual void getDeducedAttributes(LLVMContext &Ctx,\n                                    SmallVectorImpl<Attribute> &Attrs) const {\n    Attrs.emplace_back(Attribute::get(Ctx, getAttrKind()));\n  }\n};\n\n/// Base struct for all \"concrete attribute\" deductions.\n///\n/// The abstract attribute is a minimal interface that allows the Attributor to\n/// orchestrate the abstract/fixpoint analysis. The design allows to hide away\n/// implementation choices made for the subclasses but also to structure their\n/// implementation and simplify the use of other abstract attributes in-flight.\n///\n/// To allow easy creation of new attributes, most methods have default\n/// implementations. The ones that do not are generally straight forward, except\n/// `AbstractAttribute::updateImpl` which is the location of most reasoning\n/// associated with the abstract attribute. The update is invoked by the\n/// Attributor in case the situation used to justify the current optimistic\n/// state might have changed. The Attributor determines this automatically\n/// by monitoring the `Attributor::getAAFor` calls made by abstract attributes.\n///\n/// The `updateImpl` method should inspect the IR and other abstract attributes\n/// in-flight to justify the best possible (=optimistic) state. The actual\n/// implementation is, similar to the underlying abstract state encoding, not\n/// exposed. In the most common case, the `updateImpl` will go through a list of\n/// reasons why its optimistic state is valid given the current information. If\n/// any combination of them holds and is sufficient to justify the current\n/// optimistic state, the method shall return UNCHAGED. If not, the optimistic\n/// state is adjusted to the situation and the method shall return CHANGED.\n///\n/// If the manifestation of the \"concrete attribute\" deduced by the subclass\n/// differs from the \"default\" behavior, which is a (set of) LLVM-IR\n/// attribute(s) for an argument, call site argument, function return value, or\n/// function, the `AbstractAttribute::manifest` method should be overloaded.\n///\n/// NOTE: If the state obtained via getState() is INVALID, thus if\n///       AbstractAttribute::getState().isValidState() returns false, no\n///       information provided by the methods of this class should be used.\n/// NOTE: The Attributor currently has certain limitations to what we can do.\n///       As a general rule of thumb, \"concrete\" abstract attributes should *for\n///       now* only perform \"backward\" information propagation. That means\n///       optimistic information obtained through abstract attributes should\n///       only be used at positions that precede the origin of the information\n///       with regards to the program flow. More practically, information can\n///       *now* be propagated from instructions to their enclosing function, but\n///       *not* from call sites to the called function. The mechanisms to allow\n///       both directions will be added in the future.\n/// NOTE: The mechanics of adding a new \"concrete\" abstract attribute are\n///       described in the file comment.\nstruct AbstractAttribute : public IRPosition, public AADepGraphNode {\n  using StateType = AbstractState;\n\n  AbstractAttribute(const IRPosition &IRP) : IRPosition(IRP) {}\n\n  /// Virtual destructor.\n  virtual ~AbstractAttribute() {}\n\n  /// This function is used to identify if an \\p DGN is of type\n  /// AbstractAttribute so that the dyn_cast and cast can use such information\n  /// to cast an AADepGraphNode to an AbstractAttribute.\n  ///\n  /// We eagerly return true here because all AADepGraphNodes except for the\n  /// Synthethis Node are of type AbstractAttribute\n  static bool classof(const AADepGraphNode *DGN) { return true; }\n\n  /// Initialize the state with the information in the Attributor \\p A.\n  ///\n  /// This function is called by the Attributor once all abstract attributes\n  /// have been identified. It can and shall be used for task like:\n  ///  - identify existing knowledge in the IR and use it for the \"known state\"\n  ///  - perform any work that is not going to change over time, e.g., determine\n  ///    a subset of the IR, or attributes in-flight, that have to be looked at\n  ///    in the `updateImpl` method.\n  virtual void initialize(Attributor &A) {}\n\n  /// Return the internal abstract state for inspection.\n  virtual StateType &getState() = 0;\n  virtual const StateType &getState() const = 0;\n\n  /// Return an IR position, see struct IRPosition.\n  const IRPosition &getIRPosition() const { return *this; };\n  IRPosition &getIRPosition() { return *this; };\n\n  /// Helper functions, for debug purposes only.\n  ///{\n  void print(raw_ostream &OS) const override;\n  virtual void printWithDeps(raw_ostream &OS) const;\n  void dump() const { print(dbgs()); }\n\n  /// This function should return the \"summarized\" assumed state as string.\n  virtual const std::string getAsStr() const = 0;\n\n  /// This function should return the name of the AbstractAttribute\n  virtual const std::string getName() const = 0;\n\n  /// This function should return the address of the ID of the AbstractAttribute\n  virtual const char *getIdAddr() const = 0;\n  ///}\n\n  /// Allow the Attributor access to the protected methods.\n  friend struct Attributor;\n\nprotected:\n  /// Hook for the Attributor to trigger an update of the internal state.\n  ///\n  /// If this attribute is already fixed, this method will return UNCHANGED,\n  /// otherwise it delegates to `AbstractAttribute::updateImpl`.\n  ///\n  /// \\Return CHANGED if the internal state changed, otherwise UNCHANGED.\n  ChangeStatus update(Attributor &A);\n\n  /// Hook for the Attributor to trigger the manifestation of the information\n  /// represented by the abstract attribute in the LLVM-IR.\n  ///\n  /// \\Return CHANGED if the IR was altered, otherwise UNCHANGED.\n  virtual ChangeStatus manifest(Attributor &A) {\n    return ChangeStatus::UNCHANGED;\n  }\n\n  /// Hook to enable custom statistic tracking, called after manifest that\n  /// resulted in a change if statistics are enabled.\n  ///\n  /// We require subclasses to provide an implementation so we remember to\n  /// add statistics for them.\n  virtual void trackStatistics() const = 0;\n\n  /// The actual update/transfer function which has to be implemented by the\n  /// derived classes.\n  ///\n  /// If it is called, the environment has changed and we have to determine if\n  /// the current information is still valid or adjust it otherwise.\n  ///\n  /// \\Return CHANGED if the internal state changed, otherwise UNCHANGED.\n  virtual ChangeStatus updateImpl(Attributor &A) = 0;\n};\n\n/// Forward declarations of output streams for debug purposes.\n///\n///{\nraw_ostream &operator<<(raw_ostream &OS, const AbstractAttribute &AA);\nraw_ostream &operator<<(raw_ostream &OS, ChangeStatus S);\nraw_ostream &operator<<(raw_ostream &OS, IRPosition::Kind);\nraw_ostream &operator<<(raw_ostream &OS, const IRPosition &);\nraw_ostream &operator<<(raw_ostream &OS, const AbstractState &State);\ntemplate <typename base_ty, base_ty BestState, base_ty WorstState>\nraw_ostream &\noperator<<(raw_ostream &OS,\n           const IntegerStateBase<base_ty, BestState, WorstState> &S) {\n  return OS << \"(\" << S.getKnown() << \"-\" << S.getAssumed() << \")\"\n            << static_cast<const AbstractState &>(S);\n}\nraw_ostream &operator<<(raw_ostream &OS, const IntegerRangeState &State);\n///}\n\nstruct AttributorPass : public PassInfoMixin<AttributorPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\nstruct AttributorCGSCCPass : public PassInfoMixin<AttributorCGSCCPass> {\n  PreservedAnalyses run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &AM,\n                        LazyCallGraph &CG, CGSCCUpdateResult &UR);\n};\n\nPass *createAttributorLegacyPass();\nPass *createAttributorCGSCCLegacyPass();\n\n/// ----------------------------------------------------------------------------\n///                       Abstract Attribute Classes\n/// ----------------------------------------------------------------------------\n\n/// An abstract attribute for the returned values of a function.\nstruct AAReturnedValues\n    : public IRAttribute<Attribute::Returned, AbstractAttribute> {\n  AAReturnedValues(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return an assumed unique return value if a single candidate is found. If\n  /// there cannot be one, return a nullptr. If it is not clear yet, return the\n  /// Optional::NoneType.\n  Optional<Value *> getAssumedUniqueReturnValue(Attributor &A) const;\n\n  /// Check \\p Pred on all returned values.\n  ///\n  /// This method will evaluate \\p Pred on returned values and return\n  /// true if (1) all returned values are known, and (2) \\p Pred returned true\n  /// for all returned values.\n  ///\n  /// Note: Unlike the Attributor::checkForAllReturnedValuesAndReturnInsts\n  /// method, this one will not filter dead return instructions.\n  virtual bool checkForAllReturnedValuesAndReturnInsts(\n      function_ref<bool(Value &, const SmallSetVector<ReturnInst *, 4> &)> Pred)\n      const = 0;\n\n  using iterator =\n      MapVector<Value *, SmallSetVector<ReturnInst *, 4>>::iterator;\n  using const_iterator =\n      MapVector<Value *, SmallSetVector<ReturnInst *, 4>>::const_iterator;\n  virtual llvm::iterator_range<iterator> returned_values() = 0;\n  virtual llvm::iterator_range<const_iterator> returned_values() const = 0;\n\n  virtual size_t getNumReturnValues() const = 0;\n  virtual const SmallSetVector<CallBase *, 4> &getUnresolvedCalls() const = 0;\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAReturnedValues &createForPosition(const IRPosition &IRP,\n                                             Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAReturnedValues\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAReturnedValues\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\nstruct AANoUnwind\n    : public IRAttribute<Attribute::NoUnwind,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoUnwind(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Returns true if nounwind is assumed.\n  bool isAssumedNoUnwind() const { return getAssumed(); }\n\n  /// Returns true if nounwind is known.\n  bool isKnownNoUnwind() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoUnwind &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoUnwind\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoUnwind\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\nstruct AANoSync\n    : public IRAttribute<Attribute::NoSync,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoSync(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Returns true if \"nosync\" is assumed.\n  bool isAssumedNoSync() const { return getAssumed(); }\n\n  /// Returns true if \"nosync\" is known.\n  bool isKnownNoSync() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoSync &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoSync\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoSync\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for all nonnull attributes.\nstruct AANonNull\n    : public IRAttribute<Attribute::NonNull,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANonNull(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if we assume that the underlying value is nonnull.\n  bool isAssumedNonNull() const { return getAssumed(); }\n\n  /// Return true if we know that underlying value is nonnull.\n  bool isKnownNonNull() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANonNull &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANonNull\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANonNull\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract attribute for norecurse.\nstruct AANoRecurse\n    : public IRAttribute<Attribute::NoRecurse,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoRecurse(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if \"norecurse\" is assumed.\n  bool isAssumedNoRecurse() const { return getAssumed(); }\n\n  /// Return true if \"norecurse\" is known.\n  bool isKnownNoRecurse() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoRecurse &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoRecurse\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoRecurse\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract attribute for willreturn.\nstruct AAWillReturn\n    : public IRAttribute<Attribute::WillReturn,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AAWillReturn(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if \"willreturn\" is assumed.\n  bool isAssumedWillReturn() const { return getAssumed(); }\n\n  /// Return true if \"willreturn\" is known.\n  bool isKnownWillReturn() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAWillReturn &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAWillReturn\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AAWillReturn\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract attribute for undefined behavior.\nstruct AAUndefinedBehavior\n    : public StateWrapper<BooleanState, AbstractAttribute> {\n  using Base = StateWrapper<BooleanState, AbstractAttribute>;\n  AAUndefinedBehavior(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\n  /// Return true if \"undefined behavior\" is assumed.\n  bool isAssumedToCauseUB() const { return getAssumed(); }\n\n  /// Return true if \"undefined behavior\" is assumed for a specific instruction.\n  virtual bool isAssumedToCauseUB(Instruction *I) const = 0;\n\n  /// Return true if \"undefined behavior\" is known.\n  bool isKnownToCauseUB() const { return getKnown(); }\n\n  /// Return true if \"undefined behavior\" is known for a specific instruction.\n  virtual bool isKnownToCauseUB(Instruction *I) const = 0;\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAUndefinedBehavior &createForPosition(const IRPosition &IRP,\n                                                Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAUndefinedBehavior\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAUndefineBehavior\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface to determine reachability of point A to B.\nstruct AAReachability : public StateWrapper<BooleanState, AbstractAttribute> {\n  using Base = StateWrapper<BooleanState, AbstractAttribute>;\n  AAReachability(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\n  /// Returns true if 'From' instruction is assumed to reach, 'To' instruction.\n  /// Users should provide two positions they are interested in, and the class\n  /// determines (and caches) reachability.\n  bool isAssumedReachable(Attributor &A, const Instruction &From,\n                          const Instruction &To) const {\n    return A.getInfoCache().getPotentiallyReachable(From, To);\n  }\n\n  /// Returns true if 'From' instruction is known to reach, 'To' instruction.\n  /// Users should provide two positions they are interested in, and the class\n  /// determines (and caches) reachability.\n  bool isKnownReachable(Attributor &A, const Instruction &From,\n                        const Instruction &To) const {\n    return A.getInfoCache().getPotentiallyReachable(From, To);\n  }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAReachability &createForPosition(const IRPosition &IRP,\n                                           Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAReachability\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAReachability\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for all noalias attributes.\nstruct AANoAlias\n    : public IRAttribute<Attribute::NoAlias,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoAlias(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if we assume that the underlying value is alias.\n  bool isAssumedNoAlias() const { return getAssumed(); }\n\n  /// Return true if we know that underlying value is noalias.\n  bool isKnownNoAlias() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoAlias &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoAlias\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoAlias\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An AbstractAttribute for nofree.\nstruct AANoFree\n    : public IRAttribute<Attribute::NoFree,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoFree(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if \"nofree\" is assumed.\n  bool isAssumedNoFree() const { return getAssumed(); }\n\n  /// Return true if \"nofree\" is known.\n  bool isKnownNoFree() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoFree &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoFree\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoFree\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An AbstractAttribute for noreturn.\nstruct AANoReturn\n    : public IRAttribute<Attribute::NoReturn,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoReturn(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if the underlying object is assumed to never return.\n  bool isAssumedNoReturn() const { return getAssumed(); }\n\n  /// Return true if the underlying object is known to never return.\n  bool isKnownNoReturn() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoReturn &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoReturn\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoReturn\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for liveness abstract attribute.\nstruct AAIsDead : public StateWrapper<BooleanState, AbstractAttribute> {\n  using Base = StateWrapper<BooleanState, AbstractAttribute>;\n  AAIsDead(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\nprotected:\n  /// The query functions are protected such that other attributes need to go\n  /// through the Attributor interfaces: `Attributor::isAssumedDead(...)`\n\n  /// Returns true if the underlying value is assumed dead.\n  virtual bool isAssumedDead() const = 0;\n\n  /// Returns true if the underlying value is known dead.\n  virtual bool isKnownDead() const = 0;\n\n  /// Returns true if \\p BB is assumed dead.\n  virtual bool isAssumedDead(const BasicBlock *BB) const = 0;\n\n  /// Returns true if \\p BB is known dead.\n  virtual bool isKnownDead(const BasicBlock *BB) const = 0;\n\n  /// Returns true if \\p I is assumed dead.\n  virtual bool isAssumedDead(const Instruction *I) const = 0;\n\n  /// Returns true if \\p I is known dead.\n  virtual bool isKnownDead(const Instruction *I) const = 0;\n\n  /// This method is used to check if at least one instruction in a collection\n  /// of instructions is live.\n  template <typename T> bool isLiveInstSet(T begin, T end) const {\n    for (const auto &I : llvm::make_range(begin, end)) {\n      assert(I->getFunction() == getIRPosition().getAssociatedFunction() &&\n             \"Instruction must be in the same anchor scope function.\");\n\n      if (!isAssumedDead(I))\n        return true;\n    }\n\n    return false;\n  }\n\npublic:\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAIsDead &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// Determine if \\p F might catch asynchronous exceptions.\n  static bool mayCatchAsynchronousExceptions(const Function &F) {\n    return F.hasPersonalityFn() && !canSimplifyInvokeNoUnwind(&F);\n  }\n\n  /// Return if the edge from \\p From BB to \\p To BB is assumed dead.\n  /// This is specifically useful in AAReachability.\n  virtual bool isEdgeDead(const BasicBlock *From, const BasicBlock *To) const {\n    return false;\n  }\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAIsDead\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AAIsDead\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n\n  friend struct Attributor;\n};\n\n/// State for dereferenceable attribute\nstruct DerefState : AbstractState {\n\n  static DerefState getBestState() { return DerefState(); }\n  static DerefState getBestState(const DerefState &) { return getBestState(); }\n\n  /// Return the worst possible representable state.\n  static DerefState getWorstState() {\n    DerefState DS;\n    DS.indicatePessimisticFixpoint();\n    return DS;\n  }\n  static DerefState getWorstState(const DerefState &) {\n    return getWorstState();\n  }\n\n  /// State representing for dereferenceable bytes.\n  IncIntegerState<> DerefBytesState;\n\n  /// Map representing for accessed memory offsets and sizes.\n  /// A key is Offset and a value is size.\n  /// If there is a load/store instruction something like,\n  ///   p[offset] = v;\n  /// (offset, sizeof(v)) will be inserted to this map.\n  /// std::map is used because we want to iterate keys in ascending order.\n  std::map<int64_t, uint64_t> AccessedBytesMap;\n\n  /// Helper function to calculate dereferenceable bytes from current known\n  /// bytes and accessed bytes.\n  ///\n  /// int f(int *A){\n  ///    *A = 0;\n  ///    *(A+2) = 2;\n  ///    *(A+1) = 1;\n  ///    *(A+10) = 10;\n  /// }\n  /// ```\n  /// In that case, AccessedBytesMap is `{0:4, 4:4, 8:4, 40:4}`.\n  /// AccessedBytesMap is std::map so it is iterated in accending order on\n  /// key(Offset). So KnownBytes will be updated like this:\n  ///\n  /// |Access | KnownBytes\n  /// |(0, 4)| 0 -> 4\n  /// |(4, 4)| 4 -> 8\n  /// |(8, 4)| 8 -> 12\n  /// |(40, 4) | 12 (break)\n  void computeKnownDerefBytesFromAccessedMap() {\n    int64_t KnownBytes = DerefBytesState.getKnown();\n    for (auto &Access : AccessedBytesMap) {\n      if (KnownBytes < Access.first)\n        break;\n      KnownBytes = std::max(KnownBytes, Access.first + (int64_t)Access.second);\n    }\n\n    DerefBytesState.takeKnownMaximum(KnownBytes);\n  }\n\n  /// State representing that whether the value is globaly dereferenceable.\n  BooleanState GlobalState;\n\n  /// See AbstractState::isValidState()\n  bool isValidState() const override { return DerefBytesState.isValidState(); }\n\n  /// See AbstractState::isAtFixpoint()\n  bool isAtFixpoint() const override {\n    return !isValidState() ||\n           (DerefBytesState.isAtFixpoint() && GlobalState.isAtFixpoint());\n  }\n\n  /// See AbstractState::indicateOptimisticFixpoint(...)\n  ChangeStatus indicateOptimisticFixpoint() override {\n    DerefBytesState.indicateOptimisticFixpoint();\n    GlobalState.indicateOptimisticFixpoint();\n    return ChangeStatus::UNCHANGED;\n  }\n\n  /// See AbstractState::indicatePessimisticFixpoint(...)\n  ChangeStatus indicatePessimisticFixpoint() override {\n    DerefBytesState.indicatePessimisticFixpoint();\n    GlobalState.indicatePessimisticFixpoint();\n    return ChangeStatus::CHANGED;\n  }\n\n  /// Update known dereferenceable bytes.\n  void takeKnownDerefBytesMaximum(uint64_t Bytes) {\n    DerefBytesState.takeKnownMaximum(Bytes);\n\n    // Known bytes might increase.\n    computeKnownDerefBytesFromAccessedMap();\n  }\n\n  /// Update assumed dereferenceable bytes.\n  void takeAssumedDerefBytesMinimum(uint64_t Bytes) {\n    DerefBytesState.takeAssumedMinimum(Bytes);\n  }\n\n  /// Add accessed bytes to the map.\n  void addAccessedBytes(int64_t Offset, uint64_t Size) {\n    uint64_t &AccessedBytes = AccessedBytesMap[Offset];\n    AccessedBytes = std::max(AccessedBytes, Size);\n\n    // Known bytes might increase.\n    computeKnownDerefBytesFromAccessedMap();\n  }\n\n  /// Equality for DerefState.\n  bool operator==(const DerefState &R) const {\n    return this->DerefBytesState == R.DerefBytesState &&\n           this->GlobalState == R.GlobalState;\n  }\n\n  /// Inequality for DerefState.\n  bool operator!=(const DerefState &R) const { return !(*this == R); }\n\n  /// See IntegerStateBase::operator^=\n  DerefState operator^=(const DerefState &R) {\n    DerefBytesState ^= R.DerefBytesState;\n    GlobalState ^= R.GlobalState;\n    return *this;\n  }\n\n  /// See IntegerStateBase::operator+=\n  DerefState operator+=(const DerefState &R) {\n    DerefBytesState += R.DerefBytesState;\n    GlobalState += R.GlobalState;\n    return *this;\n  }\n\n  /// See IntegerStateBase::operator&=\n  DerefState operator&=(const DerefState &R) {\n    DerefBytesState &= R.DerefBytesState;\n    GlobalState &= R.GlobalState;\n    return *this;\n  }\n\n  /// See IntegerStateBase::operator|=\n  DerefState operator|=(const DerefState &R) {\n    DerefBytesState |= R.DerefBytesState;\n    GlobalState |= R.GlobalState;\n    return *this;\n  }\n\nprotected:\n  const AANonNull *NonNullAA = nullptr;\n};\n\n/// An abstract interface for all dereferenceable attribute.\nstruct AADereferenceable\n    : public IRAttribute<Attribute::Dereferenceable,\n                         StateWrapper<DerefState, AbstractAttribute>> {\n  AADereferenceable(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if we assume that the underlying value is nonnull.\n  bool isAssumedNonNull() const {\n    return NonNullAA && NonNullAA->isAssumedNonNull();\n  }\n\n  /// Return true if we know that the underlying value is nonnull.\n  bool isKnownNonNull() const {\n    return NonNullAA && NonNullAA->isKnownNonNull();\n  }\n\n  /// Return true if we assume that underlying value is\n  /// dereferenceable(_or_null) globally.\n  bool isAssumedGlobal() const { return GlobalState.getAssumed(); }\n\n  /// Return true if we know that underlying value is\n  /// dereferenceable(_or_null) globally.\n  bool isKnownGlobal() const { return GlobalState.getKnown(); }\n\n  /// Return assumed dereferenceable bytes.\n  uint32_t getAssumedDereferenceableBytes() const {\n    return DerefBytesState.getAssumed();\n  }\n\n  /// Return known dereferenceable bytes.\n  uint32_t getKnownDereferenceableBytes() const {\n    return DerefBytesState.getKnown();\n  }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AADereferenceable &createForPosition(const IRPosition &IRP,\n                                              Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AADereferenceable\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AADereferenceable\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\nusing AAAlignmentStateType =\n    IncIntegerState<uint32_t, Value::MaximumAlignment, 1>;\n/// An abstract interface for all align attributes.\nstruct AAAlign : public IRAttribute<\n                     Attribute::Alignment,\n                     StateWrapper<AAAlignmentStateType, AbstractAttribute>> {\n  AAAlign(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return assumed alignment.\n  unsigned getAssumedAlign() const { return getAssumed(); }\n\n  /// Return known alignment.\n  unsigned getKnownAlign() const { return getKnown(); }\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAAlign\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AAAlign\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAAlign &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for all nocapture attributes.\nstruct AANoCapture\n    : public IRAttribute<\n          Attribute::NoCapture,\n          StateWrapper<BitIntegerState<uint16_t, 7, 0>, AbstractAttribute>> {\n  AANoCapture(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// State encoding bits. A set bit in the state means the property holds.\n  /// NO_CAPTURE is the best possible state, 0 the worst possible state.\n  enum {\n    NOT_CAPTURED_IN_MEM = 1 << 0,\n    NOT_CAPTURED_IN_INT = 1 << 1,\n    NOT_CAPTURED_IN_RET = 1 << 2,\n\n    /// If we do not capture the value in memory or through integers we can only\n    /// communicate it back as a derived pointer.\n    NO_CAPTURE_MAYBE_RETURNED = NOT_CAPTURED_IN_MEM | NOT_CAPTURED_IN_INT,\n\n    /// If we do not capture the value in memory, through integers, or as a\n    /// derived pointer we know it is not captured.\n    NO_CAPTURE =\n        NOT_CAPTURED_IN_MEM | NOT_CAPTURED_IN_INT | NOT_CAPTURED_IN_RET,\n  };\n\n  /// Return true if we know that the underlying value is not captured in its\n  /// respective scope.\n  bool isKnownNoCapture() const { return isKnown(NO_CAPTURE); }\n\n  /// Return true if we assume that the underlying value is not captured in its\n  /// respective scope.\n  bool isAssumedNoCapture() const { return isAssumed(NO_CAPTURE); }\n\n  /// Return true if we know that the underlying value is not captured in its\n  /// respective scope but we allow it to escape through a \"return\".\n  bool isKnownNoCaptureMaybeReturned() const {\n    return isKnown(NO_CAPTURE_MAYBE_RETURNED);\n  }\n\n  /// Return true if we assume that the underlying value is not captured in its\n  /// respective scope but we allow it to escape through a \"return\".\n  bool isAssumedNoCaptureMaybeReturned() const {\n    return isAssumed(NO_CAPTURE_MAYBE_RETURNED);\n  }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoCapture &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoCapture\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoCapture\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for value simplify abstract attribute.\nstruct AAValueSimplify : public StateWrapper<BooleanState, AbstractAttribute> {\n  using Base = StateWrapper<BooleanState, AbstractAttribute>;\n  AAValueSimplify(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\n  /// Return an assumed simplified value if a single candidate is found. If\n  /// there cannot be one, return original value. If it is not clear yet, return\n  /// the Optional::NoneType.\n  virtual Optional<Value *> getAssumedSimplifiedValue(Attributor &A) const = 0;\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAValueSimplify &createForPosition(const IRPosition &IRP,\n                                            Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAValueSimplify\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAValueSimplify\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\nstruct AAHeapToStack : public StateWrapper<BooleanState, AbstractAttribute> {\n  using Base = StateWrapper<BooleanState, AbstractAttribute>;\n  AAHeapToStack(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\n  /// Returns true if HeapToStack conversion is assumed to be possible.\n  bool isAssumedHeapToStack() const { return getAssumed(); }\n\n  /// Returns true if HeapToStack conversion is known to be possible.\n  bool isKnownHeapToStack() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAHeapToStack &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAHeapToStack\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AAHeapToStack\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for privatizability.\n///\n/// A pointer is privatizable if it can be replaced by a new, private one.\n/// Privatizing pointer reduces the use count, interaction between unrelated\n/// code parts.\n///\n/// In order for a pointer to be privatizable its value cannot be observed\n/// (=nocapture), it is (for now) not written (=readonly & noalias), we know\n/// what values are necessary to make the private copy look like the original\n/// one, and the values we need can be loaded (=dereferenceable).\nstruct AAPrivatizablePtr\n    : public StateWrapper<BooleanState, AbstractAttribute> {\n  using Base = StateWrapper<BooleanState, AbstractAttribute>;\n  AAPrivatizablePtr(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\n  /// Returns true if pointer privatization is assumed to be possible.\n  bool isAssumedPrivatizablePtr() const { return getAssumed(); }\n\n  /// Returns true if pointer privatization is known to be possible.\n  bool isKnownPrivatizablePtr() const { return getKnown(); }\n\n  /// Return the type we can choose for a private copy of the underlying\n  /// value. None means it is not clear yet, nullptr means there is none.\n  virtual Optional<Type *> getPrivatizableType() const = 0;\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAPrivatizablePtr &createForPosition(const IRPosition &IRP,\n                                              Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAPrivatizablePtr\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAPricatizablePtr\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for memory access kind related attributes\n/// (readnone/readonly/writeonly).\nstruct AAMemoryBehavior\n    : public IRAttribute<\n          Attribute::ReadNone,\n          StateWrapper<BitIntegerState<uint8_t, 3>, AbstractAttribute>> {\n  AAMemoryBehavior(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// State encoding bits. A set bit in the state means the property holds.\n  /// BEST_STATE is the best possible state, 0 the worst possible state.\n  enum {\n    NO_READS = 1 << 0,\n    NO_WRITES = 1 << 1,\n    NO_ACCESSES = NO_READS | NO_WRITES,\n\n    BEST_STATE = NO_ACCESSES,\n  };\n  static_assert(BEST_STATE == getBestState(), \"Unexpected BEST_STATE value\");\n\n  /// Return true if we know that the underlying value is not read or accessed\n  /// in its respective scope.\n  bool isKnownReadNone() const { return isKnown(NO_ACCESSES); }\n\n  /// Return true if we assume that the underlying value is not read or accessed\n  /// in its respective scope.\n  bool isAssumedReadNone() const { return isAssumed(NO_ACCESSES); }\n\n  /// Return true if we know that the underlying value is not accessed\n  /// (=written) in its respective scope.\n  bool isKnownReadOnly() const { return isKnown(NO_WRITES); }\n\n  /// Return true if we assume that the underlying value is not accessed\n  /// (=written) in its respective scope.\n  bool isAssumedReadOnly() const { return isAssumed(NO_WRITES); }\n\n  /// Return true if we know that the underlying value is not read in its\n  /// respective scope.\n  bool isKnownWriteOnly() const { return isKnown(NO_READS); }\n\n  /// Return true if we assume that the underlying value is not read in its\n  /// respective scope.\n  bool isAssumedWriteOnly() const { return isAssumed(NO_READS); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAMemoryBehavior &createForPosition(const IRPosition &IRP,\n                                             Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAMemoryBehavior\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAMemoryBehavior\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for all memory location attributes\n/// (readnone/argmemonly/inaccessiblememonly/inaccessibleorargmemonly).\nstruct AAMemoryLocation\n    : public IRAttribute<\n          Attribute::ReadNone,\n          StateWrapper<BitIntegerState<uint32_t, 511>, AbstractAttribute>> {\n  using MemoryLocationsKind = StateType::base_t;\n\n  AAMemoryLocation(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Encoding of different locations that could be accessed by a memory\n  /// access.\n  enum {\n    ALL_LOCATIONS = 0,\n    NO_LOCAL_MEM = 1 << 0,\n    NO_CONST_MEM = 1 << 1,\n    NO_GLOBAL_INTERNAL_MEM = 1 << 2,\n    NO_GLOBAL_EXTERNAL_MEM = 1 << 3,\n    NO_GLOBAL_MEM = NO_GLOBAL_INTERNAL_MEM | NO_GLOBAL_EXTERNAL_MEM,\n    NO_ARGUMENT_MEM = 1 << 4,\n    NO_INACCESSIBLE_MEM = 1 << 5,\n    NO_MALLOCED_MEM = 1 << 6,\n    NO_UNKOWN_MEM = 1 << 7,\n    NO_LOCATIONS = NO_LOCAL_MEM | NO_CONST_MEM | NO_GLOBAL_INTERNAL_MEM |\n                   NO_GLOBAL_EXTERNAL_MEM | NO_ARGUMENT_MEM |\n                   NO_INACCESSIBLE_MEM | NO_MALLOCED_MEM | NO_UNKOWN_MEM,\n\n    // Helper bit to track if we gave up or not.\n    VALID_STATE = NO_LOCATIONS + 1,\n\n    BEST_STATE = NO_LOCATIONS | VALID_STATE,\n  };\n  static_assert(BEST_STATE == getBestState(), \"Unexpected BEST_STATE value\");\n\n  /// Return true if we know that the associated functions has no observable\n  /// accesses.\n  bool isKnownReadNone() const { return isKnown(NO_LOCATIONS); }\n\n  /// Return true if we assume that the associated functions has no observable\n  /// accesses.\n  bool isAssumedReadNone() const {\n    return isAssumed(NO_LOCATIONS) | isAssumedStackOnly();\n  }\n\n  /// Return true if we know that the associated functions has at most\n  /// local/stack accesses.\n  bool isKnowStackOnly() const {\n    return isKnown(inverseLocation(NO_LOCAL_MEM, true, true));\n  }\n\n  /// Return true if we assume that the associated functions has at most\n  /// local/stack accesses.\n  bool isAssumedStackOnly() const {\n    return isAssumed(inverseLocation(NO_LOCAL_MEM, true, true));\n  }\n\n  /// Return true if we know that the underlying value will only access\n  /// inaccesible memory only (see Attribute::InaccessibleMemOnly).\n  bool isKnownInaccessibleMemOnly() const {\n    return isKnown(inverseLocation(NO_INACCESSIBLE_MEM, true, true));\n  }\n\n  /// Return true if we assume that the underlying value will only access\n  /// inaccesible memory only (see Attribute::InaccessibleMemOnly).\n  bool isAssumedInaccessibleMemOnly() const {\n    return isAssumed(inverseLocation(NO_INACCESSIBLE_MEM, true, true));\n  }\n\n  /// Return true if we know that the underlying value will only access\n  /// argument pointees (see Attribute::ArgMemOnly).\n  bool isKnownArgMemOnly() const {\n    return isKnown(inverseLocation(NO_ARGUMENT_MEM, true, true));\n  }\n\n  /// Return true if we assume that the underlying value will only access\n  /// argument pointees (see Attribute::ArgMemOnly).\n  bool isAssumedArgMemOnly() const {\n    return isAssumed(inverseLocation(NO_ARGUMENT_MEM, true, true));\n  }\n\n  /// Return true if we know that the underlying value will only access\n  /// inaccesible memory or argument pointees (see\n  /// Attribute::InaccessibleOrArgMemOnly).\n  bool isKnownInaccessibleOrArgMemOnly() const {\n    return isKnown(\n        inverseLocation(NO_INACCESSIBLE_MEM | NO_ARGUMENT_MEM, true, true));\n  }\n\n  /// Return true if we assume that the underlying value will only access\n  /// inaccesible memory or argument pointees (see\n  /// Attribute::InaccessibleOrArgMemOnly).\n  bool isAssumedInaccessibleOrArgMemOnly() const {\n    return isAssumed(\n        inverseLocation(NO_INACCESSIBLE_MEM | NO_ARGUMENT_MEM, true, true));\n  }\n\n  /// Return true if the underlying value may access memory through arguement\n  /// pointers of the associated function, if any.\n  bool mayAccessArgMem() const { return !isAssumed(NO_ARGUMENT_MEM); }\n\n  /// Return true if only the memory locations specififed by \\p MLK are assumed\n  /// to be accessed by the associated function.\n  bool isAssumedSpecifiedMemOnly(MemoryLocationsKind MLK) const {\n    return isAssumed(MLK);\n  }\n\n  /// Return the locations that are assumed to be not accessed by the associated\n  /// function, if any.\n  MemoryLocationsKind getAssumedNotAccessedLocation() const {\n    return getAssumed();\n  }\n\n  /// Return the inverse of location \\p Loc, thus for NO_XXX the return\n  /// describes ONLY_XXX. The flags \\p AndLocalMem and \\p AndConstMem determine\n  /// if local (=stack) and constant memory are allowed as well. Most of the\n  /// time we do want them to be included, e.g., argmemonly allows accesses via\n  /// argument pointers or local or constant memory accesses.\n  static MemoryLocationsKind\n  inverseLocation(MemoryLocationsKind Loc, bool AndLocalMem, bool AndConstMem) {\n    return NO_LOCATIONS & ~(Loc | (AndLocalMem ? NO_LOCAL_MEM : 0) |\n                            (AndConstMem ? NO_CONST_MEM : 0));\n  };\n\n  /// Return the locations encoded by \\p MLK as a readable string.\n  static std::string getMemoryLocationsAsStr(MemoryLocationsKind MLK);\n\n  /// Simple enum to distinguish read/write/read-write accesses.\n  enum AccessKind {\n    NONE = 0,\n    READ = 1 << 0,\n    WRITE = 1 << 1,\n    READ_WRITE = READ | WRITE,\n  };\n\n  /// Check \\p Pred on all accesses to the memory kinds specified by \\p MLK.\n  ///\n  /// This method will evaluate \\p Pred on all accesses (access instruction +\n  /// underlying accessed memory pointer) and it will return true if \\p Pred\n  /// holds every time.\n  virtual bool checkForAllAccessesToMemoryKind(\n      function_ref<bool(const Instruction *, const Value *, AccessKind,\n                        MemoryLocationsKind)>\n          Pred,\n      MemoryLocationsKind MLK) const = 0;\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAMemoryLocation &createForPosition(const IRPosition &IRP,\n                                             Attributor &A);\n\n  /// See AbstractState::getAsStr().\n  const std::string getAsStr() const override {\n    return getMemoryLocationsAsStr(getAssumedNotAccessedLocation());\n  }\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAMemoryLocation\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAMemoryLocation\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for range value analysis.\nstruct AAValueConstantRange\n    : public StateWrapper<IntegerRangeState, AbstractAttribute, uint32_t> {\n  using Base = StateWrapper<IntegerRangeState, AbstractAttribute, uint32_t>;\n  AAValueConstantRange(const IRPosition &IRP, Attributor &A)\n      : Base(IRP, IRP.getAssociatedType()->getIntegerBitWidth()) {}\n\n  /// See AbstractAttribute::getState(...).\n  IntegerRangeState &getState() override { return *this; }\n  const IntegerRangeState &getState() const override { return *this; }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAValueConstantRange &createForPosition(const IRPosition &IRP,\n                                                 Attributor &A);\n\n  /// Return an assumed range for the assocaited value a program point \\p CtxI.\n  /// If \\p I is nullptr, simply return an assumed range.\n  virtual ConstantRange\n  getAssumedConstantRange(Attributor &A,\n                          const Instruction *CtxI = nullptr) const = 0;\n\n  /// Return a known range for the assocaited value at a program point \\p CtxI.\n  /// If \\p I is nullptr, simply return a known range.\n  virtual ConstantRange\n  getKnownConstantRange(Attributor &A,\n                        const Instruction *CtxI = nullptr) const = 0;\n\n  /// Return an assumed constant for the assocaited value a program point \\p\n  /// CtxI.\n  Optional<ConstantInt *>\n  getAssumedConstantInt(Attributor &A,\n                        const Instruction *CtxI = nullptr) const {\n    ConstantRange RangeV = getAssumedConstantRange(A, CtxI);\n    if (auto *C = RangeV.getSingleElement())\n      return cast<ConstantInt>(\n          ConstantInt::get(getAssociatedValue().getType(), *C));\n    if (RangeV.isEmptySet())\n      return llvm::None;\n    return nullptr;\n  }\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAValueConstantRange\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAValueConstantRange\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// A class for a set state.\n/// The assumed boolean state indicates whether the corresponding set is full\n/// set or not. If the assumed state is false, this is the worst state. The\n/// worst state (invalid state) of set of potential values is when the set\n/// contains every possible value (i.e. we cannot in any way limit the value\n/// that the target position can take). That never happens naturally, we only\n/// force it. As for the conditions under which we force it, see\n/// AAPotentialValues.\ntemplate <typename MemberTy, typename KeyInfo = DenseMapInfo<MemberTy>>\nstruct PotentialValuesState : AbstractState {\n  using SetTy = DenseSet<MemberTy, KeyInfo>;\n\n  PotentialValuesState() : IsValidState(true), UndefIsContained(false) {}\n\n  PotentialValuesState(bool IsValid)\n      : IsValidState(IsValid), UndefIsContained(false) {}\n\n  /// See AbstractState::isValidState(...)\n  bool isValidState() const override { return IsValidState.isValidState(); }\n\n  /// See AbstractState::isAtFixpoint(...)\n  bool isAtFixpoint() const override { return IsValidState.isAtFixpoint(); }\n\n  /// See AbstractState::indicatePessimisticFixpoint(...)\n  ChangeStatus indicatePessimisticFixpoint() override {\n    return IsValidState.indicatePessimisticFixpoint();\n  }\n\n  /// See AbstractState::indicateOptimisticFixpoint(...)\n  ChangeStatus indicateOptimisticFixpoint() override {\n    return IsValidState.indicateOptimisticFixpoint();\n  }\n\n  /// Return the assumed state\n  PotentialValuesState &getAssumed() { return *this; }\n  const PotentialValuesState &getAssumed() const { return *this; }\n\n  /// Return this set. We should check whether this set is valid or not by\n  /// isValidState() before calling this function.\n  const SetTy &getAssumedSet() const {\n    assert(isValidState() && \"This set shoud not be used when it is invalid!\");\n    return Set;\n  }\n\n  /// Returns whether this state contains an undef value or not.\n  bool undefIsContained() const {\n    assert(isValidState() && \"This flag shoud not be used when it is invalid!\");\n    return UndefIsContained;\n  }\n\n  bool operator==(const PotentialValuesState &RHS) const {\n    if (isValidState() != RHS.isValidState())\n      return false;\n    if (!isValidState() && !RHS.isValidState())\n      return true;\n    if (undefIsContained() != RHS.undefIsContained())\n      return false;\n    return Set == RHS.getAssumedSet();\n  }\n\n  /// Maximum number of potential values to be tracked.\n  /// This is set by -attributor-max-potential-values command line option\n  static unsigned MaxPotentialValues;\n\n  /// Return empty set as the best state of potential values.\n  static PotentialValuesState getBestState() {\n    return PotentialValuesState(true);\n  }\n\n  static PotentialValuesState getBestState(PotentialValuesState &PVS) {\n    return getBestState();\n  }\n\n  /// Return full set as the worst state of potential values.\n  static PotentialValuesState getWorstState() {\n    return PotentialValuesState(false);\n  }\n\n  /// Union assumed set with the passed value.\n  void unionAssumed(const MemberTy &C) { insert(C); }\n\n  /// Union assumed set with assumed set of the passed state \\p PVS.\n  void unionAssumed(const PotentialValuesState &PVS) { unionWith(PVS); }\n\n  /// Union assumed set with an undef value.\n  void unionAssumedWithUndef() { unionWithUndef(); }\n\n  /// \"Clamp\" this state with \\p PVS.\n  PotentialValuesState operator^=(const PotentialValuesState &PVS) {\n    IsValidState ^= PVS.IsValidState;\n    unionAssumed(PVS);\n    return *this;\n  }\n\n  PotentialValuesState operator&=(const PotentialValuesState &PVS) {\n    IsValidState &= PVS.IsValidState;\n    unionAssumed(PVS);\n    return *this;\n  }\n\nprivate:\n  /// Check the size of this set, and invalidate when the size is no\n  /// less than \\p MaxPotentialValues threshold.\n  void checkAndInvalidate() {\n    if (Set.size() >= MaxPotentialValues)\n      indicatePessimisticFixpoint();\n  }\n\n  /// If this state contains both undef and not undef, we can reduce\n  /// undef to the not undef value.\n  void reduceUndefValue() { UndefIsContained = UndefIsContained & Set.empty(); }\n\n  /// Insert an element into this set.\n  void insert(const MemberTy &C) {\n    if (!isValidState())\n      return;\n    Set.insert(C);\n    checkAndInvalidate();\n  }\n\n  /// Take union with R.\n  void unionWith(const PotentialValuesState &R) {\n    /// If this is a full set, do nothing.;\n    if (!isValidState())\n      return;\n    /// If R is full set, change L to a full set.\n    if (!R.isValidState()) {\n      indicatePessimisticFixpoint();\n      return;\n    }\n    for (const MemberTy &C : R.Set)\n      Set.insert(C);\n    UndefIsContained |= R.undefIsContained();\n    reduceUndefValue();\n    checkAndInvalidate();\n  }\n\n  /// Take union with an undef value.\n  void unionWithUndef() {\n    UndefIsContained = true;\n    reduceUndefValue();\n  }\n\n  /// Take intersection with R.\n  void intersectWith(const PotentialValuesState &R) {\n    /// If R is a full set, do nothing.\n    if (!R.isValidState())\n      return;\n    /// If this is a full set, change this to R.\n    if (!isValidState()) {\n      *this = R;\n      return;\n    }\n    SetTy IntersectSet;\n    for (const MemberTy &C : Set) {\n      if (R.Set.count(C))\n        IntersectSet.insert(C);\n    }\n    Set = IntersectSet;\n    UndefIsContained &= R.undefIsContained();\n    reduceUndefValue();\n  }\n\n  /// A helper state which indicate whether this state is valid or not.\n  BooleanState IsValidState;\n\n  /// Container for potential values\n  SetTy Set;\n\n  /// Flag for undef value\n  bool UndefIsContained;\n};\n\nusing PotentialConstantIntValuesState = PotentialValuesState<APInt>;\n\nraw_ostream &operator<<(raw_ostream &OS,\n                        const PotentialConstantIntValuesState &R);\n\n/// An abstract interface for potential values analysis.\n///\n/// This AA collects potential values for each IR position.\n/// An assumed set of potential values is initialized with the empty set (the\n/// best state) and it will grow monotonically as we find more potential values\n/// for this position.\n/// The set might be forced to the worst state, that is, to contain every\n/// possible value for this position in 2 cases.\n///   1. We surpassed the \\p MaxPotentialValues threshold. This includes the\n///      case that this position is affected (e.g. because of an operation) by a\n///      Value that is in the worst state.\n///   2. We tried to initialize on a Value that we cannot handle (e.g. an\n///      operator we do not currently handle).\n///\n/// TODO: Support values other than constant integers.\nstruct AAPotentialValues\n    : public StateWrapper<PotentialConstantIntValuesState, AbstractAttribute> {\n  using Base = StateWrapper<PotentialConstantIntValuesState, AbstractAttribute>;\n  AAPotentialValues(const IRPosition &IRP, Attributor &A) : Base(IRP) {}\n\n  /// See AbstractAttribute::getState(...).\n  PotentialConstantIntValuesState &getState() override { return *this; }\n  const PotentialConstantIntValuesState &getState() const override {\n    return *this;\n  }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AAPotentialValues &createForPosition(const IRPosition &IRP,\n                                              Attributor &A);\n\n  /// Return assumed constant for the associated value\n  Optional<ConstantInt *>\n  getAssumedConstantInt(Attributor &A,\n                        const Instruction *CtxI = nullptr) const {\n    if (!isValidState())\n      return nullptr;\n    if (getAssumedSet().size() == 1)\n      return cast<ConstantInt>(ConstantInt::get(getAssociatedValue().getType(),\n                                                *(getAssumedSet().begin())));\n    if (getAssumedSet().size() == 0) {\n      if (undefIsContained())\n        return cast<ConstantInt>(\n            ConstantInt::get(getAssociatedValue().getType(), 0));\n      return llvm::None;\n    }\n\n    return nullptr;\n  }\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AAPotentialValues\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is\n  /// AAPotentialValues\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// An abstract interface for all noundef attributes.\nstruct AANoUndef\n    : public IRAttribute<Attribute::NoUndef,\n                         StateWrapper<BooleanState, AbstractAttribute>> {\n  AANoUndef(const IRPosition &IRP, Attributor &A) : IRAttribute(IRP) {}\n\n  /// Return true if we assume that the underlying value is noundef.\n  bool isAssumedNoUndef() const { return getAssumed(); }\n\n  /// Return true if we know that underlying value is noundef.\n  bool isKnownNoUndef() const { return getKnown(); }\n\n  /// Create an abstract attribute view for the position \\p IRP.\n  static AANoUndef &createForPosition(const IRPosition &IRP, Attributor &A);\n\n  /// See AbstractAttribute::getName()\n  const std::string getName() const override { return \"AANoUndef\"; }\n\n  /// See AbstractAttribute::getIdAddr()\n  const char *getIdAddr() const override { return &ID; }\n\n  /// This function should return true if the type of the \\p AA is AANoUndef\n  static bool classof(const AbstractAttribute *AA) {\n    return (AA->getIdAddr() == &ID);\n  }\n\n  /// Unique ID (due to the unique address)\n  static const char ID;\n};\n\n/// Run options, used by the pass manager.\nenum AttributorRunOption {\n  NONE = 0,\n  MODULE = 1 << 0,\n  CGSCC = 1 << 1,\n  ALL = MODULE | CGSCC\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_ATTRIBUTOR_H\n"}, "117": {"id": 117, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/BlockExtractor.h", "content": "//===- BlockExtractor.h - Extracts blocks into their own functions --------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass extracts the specified basic blocks from the module into their\n// own functions.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_BLOCKEXTRACTOR_H\n#define LLVM_TRANSFORMS_IPO_BLOCKEXTRACTOR_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct BlockExtractorPass : PassInfoMixin<BlockExtractorPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_BLOCKEXTRACTOR_H\n"}, "118": {"id": 118, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/CalledValuePropagation.h", "content": "//===- CalledValuePropagation.h - Propagate called values -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements a transformation that attaches !callees metadata to\n// indirect call sites. For a given call site, the metadata, if present,\n// indicates the set of functions the call site could possibly target at\n// run-time. This metadata is added to indirect call sites when the set of\n// possible targets can be determined by analysis and is known to be small. The\n// analysis driving the transformation is similar to constant propagation and\n// makes uses of the generic sparse propagation solver.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_CALLEDVALUEPROPAGATION_H\n#define LLVM_TRANSFORMS_IPO_CALLEDVALUEPROPAGATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass CalledValuePropagationPass\n    : public PassInfoMixin<CalledValuePropagationPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_CALLEDVALUEPROPAGATION_H\n"}, "119": {"id": 119, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/ConstantMerge.h", "content": "//===- ConstantMerge.h - Merge duplicate global constants -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the interface to a pass that merges duplicate global\n// constants together into a single constant that is shared.  This is useful\n// because some passes (ie TraceValues) insert a lot of string constants into\n// the program, regardless of whether or not an existing string is available.\n//\n// Algorithm: ConstantMerge is designed to build up a map of available constants\n// and eliminate duplicates when it is initialized.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_CONSTANTMERGE_H\n#define LLVM_TRANSFORMS_IPO_CONSTANTMERGE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// A pass that merges duplicate global constants into a single constant.\nclass ConstantMergePass : public PassInfoMixin<ConstantMergePass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_CONSTANTMERGE_H\n"}, "120": {"id": 120, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/CrossDSOCFI.h", "content": "//===-- CrossDSOCFI.cpp - Externalize this module's CFI checks --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass exports all llvm.bitset's found in the module in the form of a\n// __cfi_check function, which can be used to verify cross-DSO call targets.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_CROSSDSOCFI_H\n#define LLVM_TRANSFORMS_IPO_CROSSDSOCFI_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass CrossDSOCFIPass : public PassInfoMixin<CrossDSOCFIPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n}\n#endif // LLVM_TRANSFORMS_IPO_CROSSDSOCFI_H\n\n"}, "121": {"id": 121, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/DeadArgumentElimination.h", "content": "//===- DeadArgumentElimination.h - Eliminate Dead Args ----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass deletes dead arguments from internal functions.  Dead argument\n// elimination removes arguments which are directly dead, as well as arguments\n// only passed into function calls as dead arguments of other functions.  This\n// pass also deletes dead return values in a similar way.\n//\n// This pass is often useful as a cleanup pass to run after aggressive\n// interprocedural passes, which add possibly-dead arguments or return values.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_DEADARGUMENTELIMINATION_H\n#define LLVM_TRANSFORMS_IPO_DEADARGUMENTELIMINATION_H\n\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n#include <map>\n#include <set>\n#include <string>\n#include <tuple>\n\nnamespace llvm {\n\nclass Module;\nclass Use;\nclass Value;\n\n/// Eliminate dead arguments (and return values) from functions.\nclass DeadArgumentEliminationPass\n    : public PassInfoMixin<DeadArgumentEliminationPass> {\npublic:\n  /// Struct that represents (part of) either a return value or a function\n  /// argument.  Used so that arguments and return values can be used\n  /// interchangeably.\n  struct RetOrArg {\n    const Function *F;\n    unsigned Idx;\n    bool IsArg;\n\n    RetOrArg(const Function *F, unsigned Idx, bool IsArg)\n        : F(F), Idx(Idx), IsArg(IsArg) {}\n\n    /// Make RetOrArg comparable, so we can put it into a map.\n    bool operator<(const RetOrArg &O) const {\n      return std::tie(F, Idx, IsArg) < std::tie(O.F, O.Idx, O.IsArg);\n    }\n\n    /// Make RetOrArg comparable, so we can easily iterate the multimap.\n    bool operator==(const RetOrArg &O) const {\n      return F == O.F && Idx == O.Idx && IsArg == O.IsArg;\n    }\n\n    std::string getDescription() const {\n      return (Twine(IsArg ? \"Argument #\" : \"Return value #\") + Twine(Idx) +\n              \" of function \" + F->getName())\n          .str();\n    }\n  };\n\n  /// Liveness enum - During our initial pass over the program, we determine\n  /// that things are either alive or maybe alive. We don't mark anything\n  /// explicitly dead (even if we know they are), since anything not alive\n  /// with no registered uses (in Uses) will never be marked alive and will\n  /// thus become dead in the end.\n  enum Liveness { Live, MaybeLive };\n\n  DeadArgumentEliminationPass(bool ShouldHackArguments_ = false)\n      : ShouldHackArguments(ShouldHackArguments_) {}\n\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n\n  /// Convenience wrapper\n  RetOrArg CreateRet(const Function *F, unsigned Idx) {\n    return RetOrArg(F, Idx, false);\n  }\n\n  /// Convenience wrapper\n  RetOrArg CreateArg(const Function *F, unsigned Idx) {\n    return RetOrArg(F, Idx, true);\n  }\n\n  using UseMap = std::multimap<RetOrArg, RetOrArg>;\n\n  /// This maps a return value or argument to any MaybeLive return values or\n  /// arguments it uses. This allows the MaybeLive values to be marked live\n  /// when any of its users is marked live.\n  /// For example (indices are left out for clarity):\n  ///  - Uses[ret F] = ret G\n  ///    This means that F calls G, and F returns the value returned by G.\n  ///  - Uses[arg F] = ret G\n  ///    This means that some function calls G and passes its result as an\n  ///    argument to F.\n  ///  - Uses[ret F] = arg F\n  ///    This means that F returns one of its own arguments.\n  ///  - Uses[arg F] = arg G\n  ///    This means that G calls F and passes one of its own (G's) arguments\n  ///    directly to F.\n  UseMap Uses;\n\n  using LiveSet = std::set<RetOrArg>;\n  using LiveFuncSet = std::set<const Function *>;\n\n  /// This set contains all values that have been determined to be live.\n  LiveSet LiveValues;\n\n  /// This set contains all values that are cannot be changed in any way.\n  LiveFuncSet LiveFunctions;\n\n  using UseVector = SmallVector<RetOrArg, 5>;\n\n  /// This allows this pass to do double-duty as the dead arg hacking pass\n  /// (used only by bugpoint).\n  bool ShouldHackArguments = false;\n\nprivate:\n  Liveness MarkIfNotLive(RetOrArg Use, UseVector &MaybeLiveUses);\n  Liveness SurveyUse(const Use *U, UseVector &MaybeLiveUses,\n                     unsigned RetValNum = -1U);\n  Liveness SurveyUses(const Value *V, UseVector &MaybeLiveUses);\n\n  void SurveyFunction(const Function &F);\n  bool IsLive(const RetOrArg &RA);\n  void MarkValue(const RetOrArg &RA, Liveness L,\n                 const UseVector &MaybeLiveUses);\n  void MarkLive(const RetOrArg &RA);\n  void MarkLive(const Function &F);\n  void PropagateLiveness(const RetOrArg &RA);\n  bool RemoveDeadStuffFromFunction(Function *F);\n  bool DeleteDeadVarargs(Function &Fn);\n  bool RemoveDeadArgumentsFromCallers(Function &Fn);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_DEADARGUMENTELIMINATION_H\n"}, "122": {"id": 122, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/ElimAvailExtern.h", "content": "//===- ElimAvailExtern.h - Optimize Global Variables ------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This transform is designed to eliminate available external global\n// definitions from the program, turning them into declarations.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_ELIMAVAILEXTERN_H\n#define LLVM_TRANSFORMS_IPO_ELIMAVAILEXTERN_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// A pass that transforms external global definitions into declarations.\nclass EliminateAvailableExternallyPass\n    : public PassInfoMixin<EliminateAvailableExternallyPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_ELIMAVAILEXTERN_H\n"}, "123": {"id": 123, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/ForceFunctionAttrs.h", "content": "//===-- ForceFunctionAttrs.h - Force function attrs for debugging ---------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// Super simple passes to force specific function attrs from the commandline\n/// into the IR for debugging purposes.\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_FORCEFUNCTIONATTRS_H\n#define LLVM_TRANSFORMS_IPO_FORCEFUNCTIONATTRS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// Pass which forces specific function attributes into the IR, primarily as\n/// a debugging tool.\nstruct ForceFunctionAttrsPass : PassInfoMixin<ForceFunctionAttrsPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n};\n\n/// Create a legacy pass manager instance of a pass to force function attrs.\nPass *createForceFunctionAttrsLegacyPass();\n\n}\n\n#endif // LLVM_TRANSFORMS_IPO_FORCEFUNCTIONATTRS_H\n"}, "124": {"id": 124, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/FunctionAttrs.h", "content": "//===- FunctionAttrs.h - Compute function attributes ------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// Provides passes for computing function attributes based on interprocedural\n/// analyses.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_FUNCTIONATTRS_H\n#define LLVM_TRANSFORMS_IPO_FUNCTIONATTRS_H\n\n#include \"llvm/Analysis/CGSCCPassManager.h\"\n#include \"llvm/Analysis/LazyCallGraph.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass AAResults;\nclass Function;\nclass Module;\nclass Pass;\n\n/// The three kinds of memory access relevant to 'readonly' and\n/// 'readnone' attributes.\nenum MemoryAccessKind {\n  MAK_ReadNone = 0,\n  MAK_ReadOnly = 1,\n  MAK_MayWrite = 2,\n  MAK_WriteOnly = 3\n};\n\n/// Returns the memory access properties of this copy of the function.\nMemoryAccessKind computeFunctionBodyMemoryAccess(Function &F, AAResults &AAR);\n\n/// Computes function attributes in post-order over the call graph.\n///\n/// By operating in post-order, this pass computes precise attributes for\n/// called functions prior to processsing their callers. This \"bottom-up\"\n/// approach allows powerful interprocedural inference of function attributes\n/// like memory access patterns, etc. It can discover functions that do not\n/// access memory, or only read memory, and give them the readnone/readonly\n/// attribute. It also discovers function arguments that are not captured by\n/// the function and marks them with the nocapture attribute.\nstruct PostOrderFunctionAttrsPass : PassInfoMixin<PostOrderFunctionAttrsPass> {\n  PreservedAnalyses run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &AM,\n                        LazyCallGraph &CG, CGSCCUpdateResult &UR);\n};\n\n/// Create a legacy pass manager instance of a pass to compute function attrs\n/// in post-order.\nPass *createPostOrderFunctionAttrsLegacyPass();\n\n/// A pass to do RPO deduction and propagation of function attributes.\n///\n/// This pass provides a general RPO or \"top down\" propagation of\n/// function attributes. For a few (rare) cases, we can deduce significantly\n/// more about function attributes by working in RPO, so this pass\n/// provides the complement to the post-order pass above where the majority of\n/// deduction is performed.\n// FIXME: Currently there is no RPO CGSCC pass structure to slide into and so\n// this is a boring module pass, but eventually it should be an RPO CGSCC pass\n// when such infrastructure is available.\nclass ReversePostOrderFunctionAttrsPass\n    : public PassInfoMixin<ReversePostOrderFunctionAttrsPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_FUNCTIONATTRS_H\n"}, "125": {"id": 125, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/FunctionImport.h", "content": "//===- llvm/Transforms/IPO/FunctionImport.h - ThinLTO importing -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_FUNCTIONIMPORT_H\n#define LLVM_TRANSFORMS_IPO_FUNCTIONIMPORT_H\n\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/StringMap.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/IR/GlobalValue.h\"\n#include \"llvm/IR/ModuleSummaryIndex.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/Error.h\"\n#include <functional>\n#include <map>\n#include <memory>\n#include <string>\n#include <system_error>\n#include <unordered_set>\n#include <utility>\n\nnamespace llvm {\n\nclass Module;\n\n/// The function importer is automatically importing function from other modules\n/// based on the provided summary informations.\nclass FunctionImporter {\npublic:\n  /// Set of functions to import from a source module. Each entry is a set\n  /// containing all the GUIDs of all functions to import for a source module.\n  using FunctionsToImportTy = std::unordered_set<GlobalValue::GUID>;\n\n  /// The different reasons selectCallee will chose not to import a\n  /// candidate.\n  enum ImportFailureReason {\n    None,\n    // We can encounter a global variable instead of a function in rare\n    // situations with SamplePGO. See comments where this failure type is\n    // set for more details.\n    GlobalVar,\n    // Found to be globally dead, so we don't bother importing.\n    NotLive,\n    // Instruction count over the current threshold.\n    TooLarge,\n    // Don't import something with interposable linkage as we can't inline it\n    // anyway.\n    InterposableLinkage,\n    // Generally we won't end up failing due to this reason, as we expect\n    // to find at least one summary for the GUID that is global or a local\n    // in the referenced module for direct calls.\n    LocalLinkageNotInModule,\n    // This corresponds to the NotEligibleToImport being set on the summary,\n    // which can happen in a few different cases (e.g. local that can't be\n    // renamed or promoted because it is referenced on a llvm*.used variable).\n    NotEligible,\n    // This corresponds to NoInline being set on the function summary,\n    // which will happen if it is known that the inliner will not be able\n    // to inline the function (e.g. it is marked with a NoInline attribute).\n    NoInline\n  };\n\n  /// Information optionally tracked for candidates the importer decided\n  /// not to import. Used for optional stat printing.\n  struct ImportFailureInfo {\n    // The ValueInfo corresponding to the candidate. We save an index hash\n    // table lookup for each GUID by stashing this here.\n    ValueInfo VI;\n    // The maximum call edge hotness for all failed imports of this candidate.\n    CalleeInfo::HotnessType MaxHotness;\n    // most recent reason for failing to import (doesn't necessarily correspond\n    // to the attempt with the maximum hotness).\n    ImportFailureReason Reason;\n    // The number of times we tried to import candidate but failed.\n    unsigned Attempts;\n    ImportFailureInfo(ValueInfo VI, CalleeInfo::HotnessType MaxHotness,\n                      ImportFailureReason Reason, unsigned Attempts)\n        : VI(VI), MaxHotness(MaxHotness), Reason(Reason), Attempts(Attempts) {}\n  };\n\n  /// Map of callee GUID considered for import into a given module to a pair\n  /// consisting of the largest threshold applied when deciding whether to\n  /// import it and, if we decided to import, a pointer to the summary instance\n  /// imported. If we decided not to import, the summary will be nullptr.\n  using ImportThresholdsTy =\n      DenseMap<GlobalValue::GUID,\n               std::tuple<unsigned, const GlobalValueSummary *,\n                          std::unique_ptr<ImportFailureInfo>>>;\n\n  /// The map contains an entry for every module to import from, the key being\n  /// the module identifier to pass to the ModuleLoader. The value is the set of\n  /// functions to import.\n  using ImportMapTy = StringMap<FunctionsToImportTy>;\n\n  /// The set contains an entry for every global value the module exports.\n  using ExportSetTy = DenseSet<ValueInfo>;\n\n  /// A function of this type is used to load modules referenced by the index.\n  using ModuleLoaderTy =\n      std::function<Expected<std::unique_ptr<Module>>(StringRef Identifier)>;\n\n  /// Create a Function Importer.\n  FunctionImporter(const ModuleSummaryIndex &Index, ModuleLoaderTy ModuleLoader,\n                   bool ClearDSOLocalOnDeclarations)\n      : Index(Index), ModuleLoader(std::move(ModuleLoader)),\n        ClearDSOLocalOnDeclarations(ClearDSOLocalOnDeclarations) {}\n\n  /// Import functions in Module \\p M based on the supplied import list.\n  Expected<bool> importFunctions(Module &M, const ImportMapTy &ImportList);\n\nprivate:\n  /// The summaries index used to trigger importing.\n  const ModuleSummaryIndex &Index;\n\n  /// Factory function to load a Module for a given identifier\n  ModuleLoaderTy ModuleLoader;\n\n  /// See the comment of ClearDSOLocalOnDeclarations in\n  /// Utils/FunctionImportUtils.h.\n  bool ClearDSOLocalOnDeclarations;\n};\n\n/// The function importing pass\nclass FunctionImportPass : public PassInfoMixin<FunctionImportPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// Compute all the imports and exports for every module in the Index.\n///\n/// \\p ModuleToDefinedGVSummaries contains for each Module a map\n/// (GUID -> Summary) for every global defined in the module.\n///\n/// \\p ImportLists will be populated with an entry for every Module we are\n/// importing into. This entry is itself a map that can be passed to\n/// FunctionImporter::importFunctions() above (see description there).\n///\n/// \\p ExportLists contains for each Module the set of globals (GUID) that will\n/// be imported by another module, or referenced by such a function. I.e. this\n/// is the set of globals that need to be promoted/renamed appropriately.\nvoid ComputeCrossModuleImport(\n    const ModuleSummaryIndex &Index,\n    const StringMap<GVSummaryMapTy> &ModuleToDefinedGVSummaries,\n    StringMap<FunctionImporter::ImportMapTy> &ImportLists,\n    StringMap<FunctionImporter::ExportSetTy> &ExportLists);\n\n/// Compute all the imports for the given module using the Index.\n///\n/// \\p ImportList will be populated with a map that can be passed to\n/// FunctionImporter::importFunctions() above (see description there).\nvoid ComputeCrossModuleImportForModule(\n    StringRef ModulePath, const ModuleSummaryIndex &Index,\n    FunctionImporter::ImportMapTy &ImportList);\n\n/// Mark all external summaries in \\p Index for import into the given module.\n/// Used for distributed builds using a distributed index.\n///\n/// \\p ImportList will be populated with a map that can be passed to\n/// FunctionImporter::importFunctions() above (see description there).\nvoid ComputeCrossModuleImportForModuleFromIndex(\n    StringRef ModulePath, const ModuleSummaryIndex &Index,\n    FunctionImporter::ImportMapTy &ImportList);\n\n/// PrevailingType enum used as a return type of callback passed\n/// to computeDeadSymbols. Yes and No values used when status explicitly\n/// set by symbols resolution, otherwise status is Unknown.\nenum class PrevailingType { Yes, No, Unknown };\n\n/// Compute all the symbols that are \"dead\": i.e these that can't be reached\n/// in the graph from any of the given symbols listed in\n/// \\p GUIDPreservedSymbols. Non-prevailing symbols are symbols without a\n/// prevailing copy anywhere in IR and are normally dead, \\p isPrevailing\n/// predicate returns status of symbol.\nvoid computeDeadSymbols(\n    ModuleSummaryIndex &Index,\n    const DenseSet<GlobalValue::GUID> &GUIDPreservedSymbols,\n    function_ref<PrevailingType(GlobalValue::GUID)> isPrevailing);\n\n/// Compute dead symbols and run constant propagation in combined index\n/// after that.\nvoid computeDeadSymbolsWithConstProp(\n    ModuleSummaryIndex &Index,\n    const DenseSet<GlobalValue::GUID> &GUIDPreservedSymbols,\n    function_ref<PrevailingType(GlobalValue::GUID)> isPrevailing,\n    bool ImportEnabled);\n\n/// Converts value \\p GV to declaration, or replaces with a declaration if\n/// it is an alias. Returns true if converted, false if replaced.\nbool convertToDeclaration(GlobalValue &GV);\n\n/// Compute the set of summaries needed for a ThinLTO backend compilation of\n/// \\p ModulePath.\n//\n/// This includes summaries from that module (in case any global summary based\n/// optimizations were recorded) and from any definitions in other modules that\n/// should be imported.\n//\n/// \\p ModuleToSummariesForIndex will be populated with the needed summaries\n/// from each required module path. Use a std::map instead of StringMap to get\n/// stable order for bitcode emission.\nvoid gatherImportedSummariesForModule(\n    StringRef ModulePath,\n    const StringMap<GVSummaryMapTy> &ModuleToDefinedGVSummaries,\n    const FunctionImporter::ImportMapTy &ImportList,\n    std::map<std::string, GVSummaryMapTy> &ModuleToSummariesForIndex);\n\n/// Emit into \\p OutputFilename the files module \\p ModulePath will import from.\nstd::error_code EmitImportsFiles(\n    StringRef ModulePath, StringRef OutputFilename,\n    const std::map<std::string, GVSummaryMapTy> &ModuleToSummariesForIndex);\n\n/// Resolve prevailing symbol linkages and constrain visibility (1. CanAutoHide,\n/// 2. consider visibility from other definitions for ELF) in \\p TheModule based\n/// on the information recorded in the summaries during global summary-based\n/// analysis.\nvoid thinLTOResolvePrevailingInModule(Module &TheModule,\n                                      const GVSummaryMapTy &DefinedGlobals);\n\n/// Internalize \\p TheModule based on the information recorded in the summaries\n/// during global summary-based analysis.\nvoid thinLTOInternalizeModule(Module &TheModule,\n                              const GVSummaryMapTy &DefinedGlobals);\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_FUNCTIONIMPORT_H\n"}, "126": {"id": 126, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/GlobalDCE.h", "content": "//===-- GlobalDCE.h - DCE unreachable internal functions ------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This transform is designed to eliminate unreachable internal globals from the\n// program.  It uses an aggressive algorithm, searching out globals that are\n// known to be alive.  After it finds all of the globals which are needed, it\n// deletes whatever is left over.  This allows it to delete recursive chunks of\n// the program which are unreachable.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_GLOBALDCE_H\n#define LLVM_TRANSFORMS_IPO_GLOBALDCE_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/SmallSet.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n#include <unordered_map>\n\nnamespace llvm {\n\n/// Pass to remove unused function declarations.\nclass GlobalDCEPass : public PassInfoMixin<GlobalDCEPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n\nprivate:\n  SmallPtrSet<GlobalValue*, 32> AliveGlobals;\n\n  /// Global -> Global that uses this global.\n  DenseMap<GlobalValue *, SmallPtrSet<GlobalValue *, 4>> GVDependencies;\n\n  /// Constant -> Globals that use this global cache.\n  std::unordered_map<Constant *, SmallPtrSet<GlobalValue *, 8>>\n      ConstantDependenciesCache;\n\n  /// Comdat -> Globals in that Comdat section.\n  std::unordered_multimap<Comdat *, GlobalValue *> ComdatMembers;\n\n  /// !type metadata -> set of (vtable, offset) pairs\n  DenseMap<Metadata *, SmallSet<std::pair<GlobalVariable *, uint64_t>, 4>>\n      TypeIdMap;\n\n  // Global variables which are vtables, and which we have enough information\n  // about to safely do dead virtual function elimination.\n  SmallPtrSet<GlobalValue *, 32> VFESafeVTables;\n\n  void UpdateGVDependencies(GlobalValue &GV);\n  void MarkLive(GlobalValue &GV,\n                SmallVectorImpl<GlobalValue *> *Updates = nullptr);\n  bool RemoveUnusedGlobalValue(GlobalValue &GV);\n\n  // Dead virtual function elimination.\n  void AddVirtualFunctionDependencies(Module &M);\n  void ScanVTables(Module &M);\n  void ScanTypeCheckedLoadIntrinsics(Module &M);\n  void ScanVTableLoad(Function *Caller, Metadata *TypeId, uint64_t CallOffset);\n\n  void ComputeDependencies(Value *V, SmallPtrSetImpl<GlobalValue *> &U);\n};\n\n}\n\n#endif // LLVM_TRANSFORMS_IPO_GLOBALDCE_H\n"}, "127": {"id": 127, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/GlobalOpt.h", "content": "//===- GlobalOpt.h - Optimize Global Variables ------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass transforms simple global variables that never have their address\n// taken.  If obviously true, it marks read/write globals as constant, deletes\n// variables only stored to, etc.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_GLOBALOPT_H\n#define LLVM_TRANSFORMS_IPO_GLOBALOPT_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// Optimize globals that never have their address taken.\nclass GlobalOptPass : public PassInfoMixin<GlobalOptPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_GLOBALOPT_H\n"}, "128": {"id": 128, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/GlobalSplit.h", "content": "//===- GlobalSplit.h - global variable splitter -----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass uses inrange annotations on GEP indices to split globals where\n// beneficial. Clang currently attaches these annotations to references to\n// virtual table globals under the Itanium ABI for the benefit of the\n// whole-program virtual call optimization and control flow integrity passes.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_GLOBALSPLIT_H\n#define LLVM_TRANSFORMS_IPO_GLOBALSPLIT_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// Pass to perform split of global variables.\nclass GlobalSplitPass : public PassInfoMixin<GlobalSplitPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_GLOBALSPLIT_H\n"}, "129": {"id": 129, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/HotColdSplitting.h", "content": "//===- HotColdSplitting.h ---- Outline Cold Regions -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//===----------------------------------------------------------------------===//\n//\n// This pass outlines cold regions to a separate function.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_HOTCOLDSPLITTING_H\n#define LLVM_TRANSFORMS_IPO_HOTCOLDSPLITTING_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\nclass ProfileSummaryInfo;\nclass BlockFrequencyInfo;\nclass TargetTransformInfo;\nclass OptimizationRemarkEmitter;\nclass AssumptionCache;\nclass DominatorTree;\nclass CodeExtractorAnalysisCache;\n\n/// A sequence of basic blocks.\n///\n/// A 0-sized SmallVector is slightly cheaper to move than a std::vector.\nusing BlockSequence = SmallVector<BasicBlock *, 0>;\n\nclass HotColdSplitting {\npublic:\n  HotColdSplitting(ProfileSummaryInfo *ProfSI,\n                   function_ref<BlockFrequencyInfo *(Function &)> GBFI,\n                   function_ref<TargetTransformInfo &(Function &)> GTTI,\n                   std::function<OptimizationRemarkEmitter &(Function &)> *GORE,\n                   function_ref<AssumptionCache *(Function &)> LAC)\n      : PSI(ProfSI), GetBFI(GBFI), GetTTI(GTTI), GetORE(GORE), LookupAC(LAC) {}\n  bool run(Module &M);\n\nprivate:\n  bool isFunctionCold(const Function &F) const;\n  bool shouldOutlineFrom(const Function &F) const;\n  bool outlineColdRegions(Function &F, bool HasProfileSummary);\n  Function *extractColdRegion(const BlockSequence &Region,\n                              const CodeExtractorAnalysisCache &CEAC,\n                              DominatorTree &DT, BlockFrequencyInfo *BFI,\n                              TargetTransformInfo &TTI,\n                              OptimizationRemarkEmitter &ORE,\n                              AssumptionCache *AC, unsigned Count);\n  ProfileSummaryInfo *PSI;\n  function_ref<BlockFrequencyInfo *(Function &)> GetBFI;\n  function_ref<TargetTransformInfo &(Function &)> GetTTI;\n  std::function<OptimizationRemarkEmitter &(Function &)> *GetORE;\n  function_ref<AssumptionCache *(Function &)> LookupAC;\n};\n\n/// Pass to outline cold regions.\nclass HotColdSplittingPass : public PassInfoMixin<HotColdSplittingPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_HOTCOLDSPLITTING_H\n\n"}, "130": {"id": 130, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/IROutliner.h", "content": "//===- IROutliner.h - Extract similar IR regions into functions ------------==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// The interface file for the IROutliner which is used by the IROutliner Pass.\n//\n// The outliner uses the IRSimilarityIdentifier to identify the similar regions\n// of code.  It evaluates each set of IRSimilarityCandidates with an estimate of\n// whether it will provide code size reduction.  Each region is extracted using\n// the code extractor.  These extracted functions are consolidated into a single\n// function and called from the extracted call site.\n//\n// For example:\n// \\code\n//   %1 = add i32 %a, %b\n//   %2 = add i32 %b, %a\n//   %3 = add i32 %b, %a\n//   %4 = add i32 %a, %b\n// \\endcode\n// would become function\n// \\code\n// define internal void outlined_ir_function(i32 %0, i32 %1) {\n//   %1 = add i32 %0, %1\n//   %2 = add i32 %1, %0\n//   ret void\n// }\n// \\endcode\n// with calls:\n// \\code\n//   call void outlined_ir_function(i32 %a, i32 %b)\n//   call void outlined_ir_function(i32 %b, i32 %a)\n// \\endcode\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_IROUTLINER_H\n#define LLVM_TRANSFORMS_IPO_IROUTLINER_H\n\n#include \"llvm/Analysis/IRSimilarityIdentifier.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueMap.h\"\n#include \"llvm/Support/InstructionCost.h\"\n#include \"llvm/Transforms/Utils/CodeExtractor.h\"\n#include <set>\n\nstruct OutlinableGroup;\n\nnamespace llvm {\nusing namespace IRSimilarity;\n\nclass Module;\nclass TargetTransformInfo;\nclass OptimizationRemarkEmitter;\n\n/// The OutlinableRegion holds all the information for a specific region, or\n/// sequence of instructions. This includes what values need to be hoisted to\n/// arguments from the extracted function, inputs and outputs to the region, and\n/// mapping from the extracted function arguments to overall function arguments.\nstruct OutlinableRegion {\n  /// Describes the region of code.\n  IRSimilarityCandidate *Candidate;\n\n  /// If this region is outlined, the front and back IRInstructionData could\n  /// potentially become invalidated if the only new instruction is a call.\n  /// This ensures that we replace in the instruction in the IRInstructionData.\n  IRInstructionData *NewFront = nullptr;\n  IRInstructionData *NewBack = nullptr;\n\n  /// The number of extracted inputs from the CodeExtractor.\n  unsigned NumExtractedInputs;\n\n  /// The corresponding BasicBlock with the appropriate stores for this\n  /// OutlinableRegion in the overall function.\n  unsigned OutputBlockNum;\n\n  /// Mapping the extracted argument number to the argument number in the\n  /// overall function.  Since there will be inputs, such as elevated constants\n  /// that are not the same in each region in a SimilarityGroup, or values that\n  /// cannot be sunk into the extracted section in every region, we must keep\n  /// track of which extracted argument maps to which overall argument.\n  DenseMap<unsigned, unsigned> ExtractedArgToAgg;\n  DenseMap<unsigned, unsigned> AggArgToExtracted;\n\n  /// Mapping of the argument number in the deduplicated function\n  /// to a given constant, which is used when creating the arguments to the call\n  /// to the newly created deduplicated function.  This is handled separately\n  /// since the CodeExtractor does not recognize constants.\n  DenseMap<unsigned, Constant *> AggArgToConstant;\n\n  /// The global value numbers that are used as outputs for this section. Once\n  /// extracted, each output will be stored to an output register.  This\n  /// documents the global value numbers that are used in this pattern.\n  SmallVector<unsigned, 4> GVNStores;\n\n  /// Used to create an outlined function.\n  CodeExtractor *CE = nullptr;\n\n  /// The call site of the extracted region.\n  CallInst *Call = nullptr;\n\n  /// The function for the extracted region.\n  Function *ExtractedFunction = nullptr;\n\n  /// Flag for whether we have split out the IRSimilarityCanidate. That is,\n  /// make the region contained the IRSimilarityCandidate its own BasicBlock.\n  bool CandidateSplit = false;\n\n  /// Flag for whether we should not consider this region for extraction.\n  bool IgnoreRegion = false;\n\n  /// The BasicBlock that is before the start of the region BasicBlock,\n  /// only defined when the region has been split.\n  BasicBlock *PrevBB = nullptr;\n\n  /// The BasicBlock that contains the starting instruction of the region.\n  BasicBlock *StartBB = nullptr;\n\n  /// The BasicBlock that contains the ending instruction of the region.\n  BasicBlock *EndBB = nullptr;\n\n  /// The BasicBlock that is after the start of the region BasicBlock,\n  /// only defined when the region has been split.\n  BasicBlock *FollowBB = nullptr;\n\n  /// The Outlinable Group that contains this region and structurally similar\n  /// regions to this region.\n  OutlinableGroup *Parent = nullptr;\n\n  OutlinableRegion(IRSimilarityCandidate &C, OutlinableGroup &Group)\n      : Candidate(&C), Parent(&Group) {\n    StartBB = C.getStartBB();\n    EndBB = C.getEndBB();\n  }\n\n  /// For the contained region, split the parent BasicBlock at the starting and\n  /// ending instructions of the contained IRSimilarityCandidate.\n  void splitCandidate();\n\n  /// For the contained region, reattach the BasicBlock at the starting and\n  /// ending instructions of the contained IRSimilarityCandidate, or if the\n  /// function has been extracted, the start and end of the BasicBlock\n  /// containing the called function.\n  void reattachCandidate();\n\n  /// Get the size of the code removed from the region.\n  ///\n  /// \\param [in] TTI - The TargetTransformInfo for the parent function.\n  /// \\returns the code size of the region\n  InstructionCost getBenefit(TargetTransformInfo &TTI);\n};\n\n/// This class is a pass that identifies similarity in a Module, extracts\n/// instances of the similarity, and then consolidating the similar regions\n/// in an effort to reduce code size.  It uses the IRSimilarityIdentifier pass\n/// to identify the similar regions of code, and then extracts the similar\n/// sections into a single function.  See the above for an example as to\n/// how code is extracted and consolidated into a single function.\nclass IROutliner {\npublic:\n  IROutliner(function_ref<TargetTransformInfo &(Function &)> GTTI,\n             function_ref<IRSimilarityIdentifier &(Module &)> GIRSI,\n             function_ref<OptimizationRemarkEmitter &(Function &)> GORE)\n      : getTTI(GTTI), getIRSI(GIRSI), getORE(GORE) {}\n  bool run(Module &M);\n\nprivate:\n  /// Find repeated similar code sequences in \\p M and outline them into new\n  /// Functions.\n  ///\n  /// \\param [in] M - The module to outline from.\n  /// \\returns The number of Functions created.\n  unsigned doOutline(Module &M);\n\n  /// Remove all the IRSimilarityCandidates from \\p CandidateVec that have\n  /// instructions contained in a previously outlined region and put the\n  /// remaining regions in \\p CurrentGroup.\n  ///\n  /// \\param [in] CandidateVec - List of similarity candidates for regions with\n  /// the same similarity structure.\n  /// \\param [in,out] CurrentGroup - Contains the potential sections to\n  /// be outlined.\n  void\n  pruneIncompatibleRegions(std::vector<IRSimilarityCandidate> &CandidateVec,\n                           OutlinableGroup &CurrentGroup);\n\n  /// Create the function based on the overall types found in the current\n  /// regions being outlined.\n  ///\n  /// \\param M - The module to outline from.\n  /// \\param [in,out] CG - The OutlinableGroup for the regions to be outlined.\n  /// \\param [in] FunctionNameSuffix - How many functions have we previously\n  /// created.\n  /// \\returns the newly created function.\n  Function *createFunction(Module &M, OutlinableGroup &CG,\n                           unsigned FunctionNameSuffix);\n\n  /// Identify the needed extracted inputs in a section, and add to the overall\n  /// function if needed.\n  ///\n  /// \\param [in] M - The module to outline from.\n  /// \\param [in,out] Region - The region to be extracted.\n  /// \\param [in] NotSame - The global value numbers of the Values in the region\n  /// that do not have the same Constant in each strucutrally similar region.\n  void findAddInputsOutputs(Module &M, OutlinableRegion &Region,\n                            DenseSet<unsigned> &NotSame);\n\n  /// Find the number of instructions that will be removed by extracting the\n  /// OutlinableRegions in \\p CurrentGroup.\n  ///\n  /// \\param [in] CurrentGroup - The collection of OutlinableRegions to be\n  /// analyzed.\n  /// \\returns the number of outlined instructions across all regions.\n  InstructionCost findBenefitFromAllRegions(OutlinableGroup &CurrentGroup);\n\n  /// Find the number of instructions that will be added by reloading arguments.\n  ///\n  /// \\param [in] CurrentGroup - The collection of OutlinableRegions to be\n  /// analyzed.\n  /// \\returns the number of added reload instructions across all regions.\n  InstructionCost findCostOutputReloads(OutlinableGroup &CurrentGroup);\n\n  /// Find the cost and the benefit of \\p CurrentGroup and save it back to\n  /// \\p CurrentGroup.\n  ///\n  /// \\param [in] M - The module being analyzed\n  /// \\param [in,out] CurrentGroup - The overall outlined section\n  void findCostBenefit(Module &M, OutlinableGroup &CurrentGroup);\n\n  /// Update the output mapping based on the load instruction, and the outputs\n  /// of the extracted function.\n  ///\n  /// \\param Region - The region extracted\n  /// \\param Outputs - The outputs from the extracted function.\n  /// \\param LI - The load instruction used to update the mapping.\n  void updateOutputMapping(OutlinableRegion &Region,\n                           ArrayRef<Value *> Outputs, LoadInst *LI);\n\n  /// Extract \\p Region into its own function.\n  ///\n  /// \\param [in] Region - The region to be extracted into its own function.\n  /// \\returns True if it was successfully outlined.\n  bool extractSection(OutlinableRegion &Region);\n\n  /// For the similarities found, and the extracted sections, create a single\n  /// outlined function with appropriate output blocks as necessary.\n  ///\n  /// \\param [in] M - The module to outline from\n  /// \\param [in] CurrentGroup - The set of extracted sections to consolidate.\n  /// \\param [in,out] FuncsToRemove - List of functions to remove from the\n  /// module after outlining is completed.\n  /// \\param [in,out] OutlinedFunctionNum - the number of new outlined\n  /// functions.\n  void deduplicateExtractedSections(Module &M, OutlinableGroup &CurrentGroup,\n                                    std::vector<Function *> &FuncsToRemove,\n                                    unsigned &OutlinedFunctionNum);\n\n  /// If true, enables us to outline from functions that have LinkOnceFromODR\n  /// linkages.\n  bool OutlineFromLinkODRs = false;\n\n  /// If false, we do not worry if the cost is greater than the benefit.  This\n  /// is for debugging and testing, so that we can test small cases to ensure\n  /// that the outlining is being done correctly.\n  bool CostModel = true;\n\n  /// The set of outlined Instructions, identified by their location in the\n  /// sequential ordering of instructions in a Module.\n  DenseSet<unsigned> Outlined;\n\n  /// TargetTransformInfo lambda for target specific information.\n  function_ref<TargetTransformInfo &(Function &)> getTTI;\n\n  /// A mapping from newly created reloaded output values to the original value.\n  /// If an value is replace by an output from an outlined region, this maps\n  /// that Value, back to its original Value.\n  DenseMap<Value *, Value *> OutputMappings;\n\n  /// IRSimilarityIdentifier lambda to retrieve IRSimilarityIdentifier.\n  function_ref<IRSimilarityIdentifier &(Module &)> getIRSI;\n\n  /// The optimization remark emitter for the pass.\n  function_ref<OptimizationRemarkEmitter &(Function &)> getORE;\n\n  /// The memory allocator used to allocate the CodeExtractors.\n  SpecificBumpPtrAllocator<CodeExtractor> ExtractorAllocator;\n\n  /// The memory allocator used to allocate the OutlinableRegions.\n  SpecificBumpPtrAllocator<OutlinableRegion> RegionAllocator;\n\n  /// The memory allocator used to allocate new IRInstructionData.\n  SpecificBumpPtrAllocator<IRInstructionData> InstDataAllocator;\n\n  /// Custom InstVisitor to classify different instructions for whether it can\n  /// be analyzed for similarity.  This is needed as there may be instruction we\n  /// can identify as having similarity, but are more complicated to outline.\n  struct InstructionAllowed : public InstVisitor<InstructionAllowed, bool> {\n    InstructionAllowed() {}\n\n    // TODO: Determine a scheme to resolve when the label is similar enough.\n    bool visitBranchInst(BranchInst &BI) { return false; }\n    // TODO: Determine a scheme to resolve when the labels are similar enough.\n    bool visitPHINode(PHINode &PN) { return false; }\n    // TODO: Handle allocas.\n    bool visitAllocaInst(AllocaInst &AI) { return false; }\n    // VAArg instructions are not allowed since this could cause difficulty when\n    // differentiating between different sets of variable instructions in\n    // the deduplicated outlined regions.\n    bool visitVAArgInst(VAArgInst &VI) { return false; }\n    // We exclude all exception handling cases since they are so context\n    // dependent.\n    bool visitLandingPadInst(LandingPadInst &LPI) { return false; }\n    bool visitFuncletPadInst(FuncletPadInst &FPI) { return false; }\n    // DebugInfo should be included in the regions, but should not be\n    // analyzed for similarity as it has no bearing on the outcome of the\n    // program.\n    bool visitDbgInfoIntrinsic(DbgInfoIntrinsic &DII) { return true; }\n    // TODO: Handle specific intrinsics individually from those that can be\n    // handled.\n    bool IntrinsicInst(IntrinsicInst &II) { return false; }\n    // We only handle CallInsts that are not indirect, since we cannot guarantee\n    // that they have a name in these cases.\n    bool visitCallInst(CallInst &CI) {\n      Function *F = CI.getCalledFunction();\n      if (!F || CI.isIndirectCall() || !F->hasName())\n        return false;\n      return true;\n    }\n    // TODO: Handle FreezeInsts.  Since a frozen value could be frozen inside\n    // the outlined region, and then returned as an output, this will have to be\n    // handled differently.\n    bool visitFreezeInst(FreezeInst &CI) { return false; }\n    // TODO: We do not current handle similarity that changes the control flow.\n    bool visitInvokeInst(InvokeInst &II) { return false; }\n    // TODO: We do not current handle similarity that changes the control flow.\n    bool visitCallBrInst(CallBrInst &CBI) { return false; }\n    // TODO: Handle interblock similarity.\n    bool visitTerminator(Instruction &I) { return false; }\n    bool visitInstruction(Instruction &I) { return true; }\n  };\n\n  /// A InstVisitor used to exclude certain instructions from being outlined.\n  InstructionAllowed InstructionClassifier;\n};\n\n/// Pass to outline similar regions.\nclass IROutlinerPass : public PassInfoMixin<IROutlinerPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_IROUTLINER_H\n"}, "131": {"id": 131, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/InferFunctionAttrs.h", "content": "//===-- InferFunctionAttrs.h - Infer implicit function attributes ---------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// Interfaces for passes which infer implicit function attributes from the\n/// name and signature of function declarations.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_INFERFUNCTIONATTRS_H\n#define LLVM_TRANSFORMS_IPO_INFERFUNCTIONATTRS_H\n\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// A pass which infers function attributes from the names and signatures of\n/// function declarations in a module.\nstruct InferFunctionAttrsPass : PassInfoMixin<InferFunctionAttrsPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n/// Create a legacy pass manager instance of a pass to infer function\n/// attributes.\nPass *createInferFunctionAttrsLegacyPass();\n\n}\n\n#endif // LLVM_TRANSFORMS_IPO_INFERFUNCTIONATTRS_H\n"}, "132": {"id": 132, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/MergeFunctions.h", "content": "//===- MergeFunctions.h - Merge Identical Functions -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass transforms simple global variables that never have their address\n// taken.  If obviously true, it marks read/write globals as constant, deletes\n// variables only stored to, etc.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_MERGEFUNCTIONS_H\n#define LLVM_TRANSFORMS_IPO_MERGEFUNCTIONS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// Merge identical functions.\nclass MergeFunctionsPass : public PassInfoMixin<MergeFunctionsPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_MERGEFUNCTIONS_H\n"}, "133": {"id": 133, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/OpenMPOpt.h", "content": "//===- IPO/OpenMPOpt.h - Collection of OpenMP optimizations -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_OPENMPOPT_H\n#define LLVM_TRANSFORMS_IPO_OPENMPOPT_H\n\n#include \"llvm/Analysis/CGSCCPassManager.h\"\n#include \"llvm/Analysis/LazyCallGraph.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nnamespace omp {\n\n/// Summary of a kernel (=entry point for target offloading).\nusing Kernel = Function *;\n\n/// Helper to remember if the module contains OpenMP (runtime calls), to be used\n/// foremost with containsOpenMP.\nstruct OpenMPInModule {\n  OpenMPInModule &operator=(bool Found) {\n    if (Found)\n      Value = OpenMPInModule::OpenMP::FOUND;\n    else\n      Value = OpenMPInModule::OpenMP::NOT_FOUND;\n    return *this;\n  }\n  bool isKnown() { return Value != OpenMP::UNKNOWN; }\n  operator bool() { return Value != OpenMP::NOT_FOUND; }\n\n  /// Does this function \\p F contain any OpenMP runtime calls?\n  bool containsOMPRuntimeCalls(Function *F) const {\n    return FuncsWithOMPRuntimeCalls.contains(F);\n  }\n\n  /// Return the known kernels (=GPU entry points) in the module.\n  SmallPtrSetImpl<Kernel> &getKernels() { return Kernels; }\n\n  /// Identify kernels in the module and populate the Kernels set.\n  void identifyKernels(Module &M);\n\nprivate:\n  enum class OpenMP { FOUND, NOT_FOUND, UNKNOWN } Value = OpenMP::UNKNOWN;\n\n  friend bool containsOpenMP(Module &M, OpenMPInModule &OMPInModule);\n\n  /// In which functions are OpenMP runtime calls present?\n  SmallPtrSet<Function *, 32> FuncsWithOMPRuntimeCalls;\n\n  /// Collection of known kernels (=GPU entry points) in the module.\n  SmallPtrSet<Kernel, 8> Kernels;\n};\n\n/// Helper to determine if \\p M contains OpenMP (runtime calls).\nbool containsOpenMP(Module &M, OpenMPInModule &OMPInModule);\n\n} // namespace omp\n\n/// OpenMP optimizations pass.\nclass OpenMPOptPass : public PassInfoMixin<OpenMPOptPass> {\n  /// Helper to remember if the module contains OpenMP (runtime calls).\n  omp::OpenMPInModule OMPInModule;\n\npublic:\n  PreservedAnalyses run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &AM,\n                        LazyCallGraph &CG, CGSCCUpdateResult &UR);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_OPENMPOPT_H\n"}, "134": {"id": 134, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/PartialInlining.h", "content": "//===- PartialInlining.h - Inline parts of functions ------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass performs partial inlining, typically by inlining an if statement\n// that surrounds the body of the function.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_PARTIALINLINING_H\n#define LLVM_TRANSFORMS_IPO_PARTIALINLINING_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// Pass to remove unused function declarations.\nclass PartialInlinerPass : public PassInfoMixin<PartialInlinerPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_PARTIALINLINING_H\n"}, "135": {"id": 135, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/SCCP.h", "content": "//===- SCCP.h - Sparse Conditional Constant Propagation ---------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass implements  interprocedural sparse conditional constant\n// propagation and merging.\n//\n// Specifically, this:\n//   * Assumes values are constant unless proven otherwise\n//   * Assumes BasicBlocks are dead unless proven otherwise\n//   * Proves values to be constant, and replaces them with constants\n//   * Proves conditional branches to be unconditional\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_SCCP_H\n#define LLVM_TRANSFORMS_IPO_SCCP_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\n/// Pass to perform interprocedural constant propagation.\nclass IPSCCPPass : public PassInfoMixin<IPSCCPPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_SCCP_H\n"}, "136": {"id": 136, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripDeadPrototypes.h", "content": "//===-- StripDeadPrototypes.h - Remove unused function declarations -------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass loops over all of the functions in the input module, looking for\n// dead declarations and removes them. Dead declarations are declarations of\n// functions for which no implementation is available (i.e., declarations for\n// unused library functions).\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_STRIPDEADPROTOTYPES_H\n#define LLVM_TRANSFORMS_IPO_STRIPDEADPROTOTYPES_H\n\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// Pass to remove unused function declarations.\nstruct StripDeadPrototypesPass : PassInfoMixin<StripDeadPrototypesPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &);\n};\n\n}\n\n#endif // LLVM_TRANSFORMS_IPO_STRIPDEADPROTOTYPES_H\n"}, "137": {"id": 137, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripSymbols.h", "content": "//===- StripSymbols.h - Strip symbols and debug info from a module --------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// The StripSymbols transformation implements code stripping. Specifically, it\n// can delete:\n//\n//   * names for virtual registers\n//   * symbols for internal globals and functions\n//   * debug information\n//\n// Note that this transformation makes code much less readable, so it should\n// only be used in situations where the 'strip' utility would be used, such as\n// reducing code size or making it harder to reverse engineer code.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_STRIPSYMBOLS_H\n#define LLVM_TRANSFORMS_IPO_STRIPSYMBOLS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct StripSymbolsPass : PassInfoMixin<StripSymbolsPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\nstruct StripNonDebugSymbolsPass : PassInfoMixin<StripNonDebugSymbolsPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\nstruct StripDebugDeclarePass : PassInfoMixin<StripDebugDeclarePass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\nstruct StripDeadDebugInfoPass : PassInfoMixin<StripDeadDebugInfoPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_IPO_STRIPSYMBOLS_H\n"}, "138": {"id": 138, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/SyntheticCountsPropagation.h", "content": "//=- SyntheticCountsPropagation.h - Propagate function counts -----*- C++ -*-=//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_IPO_SYNTHETICCOUNTSPROPAGATION_H\n#define LLVM_TRANSFORMS_IPO_SYNTHETICCOUNTSPROPAGATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass Module;\n\nclass SyntheticCountsPropagation\n    : public PassInfoMixin<SyntheticCountsPropagation> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &MAM);\n};\n} // namespace llvm\n#endif\n"}, "139": {"id": 139, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation.h", "content": "//===- Transforms/Instrumentation.h - Instrumentation passes ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines constructor functions for instrumentation passes.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_H\n\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include <cassert>\n#include <cstdint>\n#include <limits>\n#include <string>\n#include <vector>\n\nnamespace llvm {\n\nclass Triple;\nclass FunctionPass;\nclass ModulePass;\nclass OptimizationRemarkEmitter;\nclass Comdat;\nclass CallBase;\n\n/// Instrumentation passes often insert conditional checks into entry blocks.\n/// Call this function before splitting the entry block to move instructions\n/// that must remain in the entry block up before the split point. Static\n/// allocas and llvm.localescape calls, for example, must remain in the entry\n/// block.\nBasicBlock::iterator PrepareToSplitEntryBlock(BasicBlock &BB,\n                                              BasicBlock::iterator IP);\n\n// Create a constant for Str so that we can pass it to the run-time lib.\nGlobalVariable *createPrivateGlobalForString(Module &M, StringRef Str,\n                                             bool AllowMerging,\n                                             const char *NamePrefix = \"\");\n\n// Returns F.getComdat() if it exists.\n// Otherwise creates a new comdat, sets F's comdat, and returns it.\n// Returns nullptr on failure.\nComdat *getOrCreateFunctionComdat(Function &F, Triple &T);\n\n// Insert GCOV profiling instrumentation\nstruct GCOVOptions {\n  static GCOVOptions getDefault();\n\n  // Specify whether to emit .gcno files.\n  bool EmitNotes;\n\n  // Specify whether to modify the program to emit .gcda files when run.\n  bool EmitData;\n\n  // A four-byte version string. The meaning of a version string is described in\n  // gcc's gcov-io.h\n  char Version[4];\n\n  // Add the 'noredzone' attribute to added runtime library calls.\n  bool NoRedZone;\n\n  // Use atomic profile counter increments.\n  bool Atomic = false;\n\n  // Regexes separated by a semi-colon to filter the files to instrument.\n  std::string Filter;\n\n  // Regexes separated by a semi-colon to filter the files to not instrument.\n  std::string Exclude;\n};\n\nModulePass *createGCOVProfilerPass(const GCOVOptions &Options =\n                                   GCOVOptions::getDefault());\n\n// PGO Instrumention. Parameter IsCS indicates if this is the context senstive\n// instrumentation.\nModulePass *createPGOInstrumentationGenLegacyPass(bool IsCS = false);\nModulePass *\ncreatePGOInstrumentationUseLegacyPass(StringRef Filename = StringRef(\"\"),\n                                      bool IsCS = false);\nModulePass *createPGOInstrumentationGenCreateVarLegacyPass(\n    StringRef CSInstrName = StringRef(\"\"));\nModulePass *createPGOIndirectCallPromotionLegacyPass(bool InLTO = false,\n                                                     bool SamplePGO = false);\nFunctionPass *createPGOMemOPSizeOptLegacyPass();\n\nModulePass *createCGProfileLegacyPass();\n\n// The pgo-specific indirect call promotion function declared below is used by\n// the pgo-driven indirect call promotion and sample profile passes. It's a\n// wrapper around llvm::promoteCall, et al. that additionally computes !prof\n// metadata. We place it in a pgo namespace so it's not confused with the\n// generic utilities.\nnamespace pgo {\n\n// Helper function that transforms CB (either an indirect-call instruction, or\n// an invoke instruction , to a conditional call to F. This is like:\n//     if (Inst.CalledValue == F)\n//        F(...);\n//     else\n//        Inst(...);\n//     end\n// TotalCount is the profile count value that the instruction executes.\n// Count is the profile count value that F is the target function.\n// These two values are used to update the branch weight.\n// If \\p AttachProfToDirectCall is true, a prof metadata is attached to the\n// new direct call to contain \\p Count.\n// Returns the promoted direct call instruction.\nCallBase &promoteIndirectCall(CallBase &CB, Function *F, uint64_t Count,\n                              uint64_t TotalCount, bool AttachProfToDirectCall,\n                              OptimizationRemarkEmitter *ORE);\n} // namespace pgo\n\n/// Options for the frontend instrumentation based profiling pass.\nstruct InstrProfOptions {\n  // Add the 'noredzone' attribute to added runtime library calls.\n  bool NoRedZone = false;\n\n  // Do counter register promotion\n  bool DoCounterPromotion = false;\n\n  // Use atomic profile counter increments.\n  bool Atomic = false;\n\n  // Use BFI to guide register promotion\n  bool UseBFIInPromotion = false;\n\n  // Name of the profile file to use as output\n  std::string InstrProfileOutput;\n\n  InstrProfOptions() = default;\n};\n\n/// Insert frontend instrumentation based profiling. Parameter IsCS indicates if\n// this is the context senstive instrumentation.\nModulePass *createInstrProfilingLegacyPass(\n    const InstrProfOptions &Options = InstrProfOptions(), bool IsCS = false);\n\nModulePass *createInstrOrderFilePass();\n\n// Insert DataFlowSanitizer (dynamic data flow analysis) instrumentation\nModulePass *createDataFlowSanitizerLegacyPassPass(\n    const std::vector<std::string> &ABIListFiles = std::vector<std::string>());\n\n// Options for sanitizer coverage instrumentation.\nstruct SanitizerCoverageOptions {\n  enum Type {\n    SCK_None = 0,\n    SCK_Function,\n    SCK_BB,\n    SCK_Edge\n  } CoverageType = SCK_None;\n  bool IndirectCalls = false;\n  bool TraceBB = false;\n  bool TraceCmp = false;\n  bool TraceDiv = false;\n  bool TraceGep = false;\n  bool Use8bitCounters = false;\n  bool TracePC = false;\n  bool TracePCGuard = false;\n  bool Inline8bitCounters = false;\n  bool InlineBoolFlag = false;\n  bool PCTable = false;\n  bool NoPrune = false;\n  bool StackDepth = false;\n\n  SanitizerCoverageOptions() = default;\n};\n\n/// Calculate what to divide by to scale counts.\n///\n/// Given the maximum count, calculate a divisor that will scale all the\n/// weights to strictly less than std::numeric_limits<uint32_t>::max().\nstatic inline uint64_t calculateCountScale(uint64_t MaxCount) {\n  return MaxCount < std::numeric_limits<uint32_t>::max()\n             ? 1\n             : MaxCount / std::numeric_limits<uint32_t>::max() + 1;\n}\n\n/// Scale an individual branch count.\n///\n/// Scale a 64-bit weight down to 32-bits using \\c Scale.\n///\nstatic inline uint32_t scaleBranchCount(uint64_t Count, uint64_t Scale) {\n  uint64_t Scaled = Count / Scale;\n  assert(Scaled <= std::numeric_limits<uint32_t>::max() && \"overflow 32-bits\");\n  return Scaled;\n}\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_INSTRUMENTATION_H\n"}, "140": {"id": 140, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizer.h", "content": "//===--------- Definition of the AddressSanitizer class ---------*- C++ -*-===//\n//\n//                     The LLVM Compiler Infrastructure\n//\n// This file is distributed under the University of Illinois Open Source\n// License. See LICENSE.TXT for details.\n//\n//===----------------------------------------------------------------------===//\n//\n// This file declares the AddressSanitizer class which is a port of the legacy\n// AddressSanitizer pass to use the new PassManager infrastructure.\n//\n//===----------------------------------------------------------------------===//\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_ADDRESSSANITIZER_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_ADDRESSSANITIZER_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Instrumentation/AddressSanitizerOptions.h\"\n\nnamespace llvm {\n\n/// Frontend-provided metadata for source location.\nstruct LocationMetadata {\n  StringRef Filename;\n  int LineNo = 0;\n  int ColumnNo = 0;\n\n  LocationMetadata() = default;\n\n  bool empty() const { return Filename.empty(); }\n  void parse(MDNode *MDN);\n};\n\n/// Frontend-provided metadata for global variables.\nclass GlobalsMetadata {\npublic:\n  struct Entry {\n    LocationMetadata SourceLoc;\n    StringRef Name;\n    bool IsDynInit = false;\n    bool IsExcluded = false;\n\n    Entry() = default;\n  };\n\n  /// Create a default uninitialized GlobalsMetadata instance.\n  GlobalsMetadata() = default;\n\n  /// Create an initialized GlobalsMetadata instance.\n  GlobalsMetadata(Module &M);\n\n  /// Returns metadata entry for a given global.\n  Entry get(GlobalVariable *G) const {\n    auto Pos = Entries.find(G);\n    return (Pos != Entries.end()) ? Pos->second : Entry();\n  }\n\n  /// Handle invalidation from the pass manager.\n  /// These results are never invalidated.\n  bool invalidate(Module &, const PreservedAnalyses &,\n                  ModuleAnalysisManager::Invalidator &) {\n    return false;\n  }\n  bool invalidate(Function &, const PreservedAnalyses &,\n                  FunctionAnalysisManager::Invalidator &) {\n    return false;\n  }\n\nprivate:\n  DenseMap<GlobalVariable *, Entry> Entries;\n};\n\n/// The ASanGlobalsMetadataAnalysis initializes and returns a GlobalsMetadata\n/// object. More specifically, ASan requires looking at all globals registered\n/// in 'llvm.asan.globals' before running, which only depends on reading module\n/// level metadata. This analysis is required to run before running the\n/// AddressSanitizerPass since it collects that metadata.\n/// The legacy pass manager equivalent of this is ASanGlobalsMetadataLegacyPass.\nclass ASanGlobalsMetadataAnalysis\n    : public AnalysisInfoMixin<ASanGlobalsMetadataAnalysis> {\npublic:\n  using Result = GlobalsMetadata;\n\n  Result run(Module &, ModuleAnalysisManager &);\n\nprivate:\n  friend AnalysisInfoMixin<ASanGlobalsMetadataAnalysis>;\n  static AnalysisKey Key;\n};\n\n/// Public interface to the address sanitizer pass for instrumenting code to\n/// check for various memory errors at runtime.\n///\n/// The sanitizer itself is a function pass that works by inserting various\n/// calls to the ASan runtime library functions. The runtime library essentially\n/// replaces malloc() and free() with custom implementations that allow regions\n/// surrounding requested memory to be checked for invalid accesses.\nclass AddressSanitizerPass : public PassInfoMixin<AddressSanitizerPass> {\npublic:\n  explicit AddressSanitizerPass(bool CompileKernel = false,\n                                bool Recover = false,\n                                bool UseAfterScope = false);\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  static bool isRequired() { return true; }\n\nprivate:\n  bool CompileKernel;\n  bool Recover;\n  bool UseAfterScope;\n};\n\n/// Public interface to the address sanitizer module pass for instrumenting code\n/// to check for various memory errors.\n///\n/// This adds 'asan.module_ctor' to 'llvm.global_ctors'. This pass may also\n/// run intependently of the function address sanitizer.\nclass ModuleAddressSanitizerPass\n    : public PassInfoMixin<ModuleAddressSanitizerPass> {\npublic:\n  explicit ModuleAddressSanitizerPass(\n      bool CompileKernel = false, bool Recover = false, bool UseGlobalGC = true,\n      bool UseOdrIndicator = false,\n      AsanDtorKind DestructorKind = AsanDtorKind::Global);\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  static bool isRequired() { return true; }\n\nprivate:\n  bool CompileKernel;\n  bool Recover;\n  bool UseGlobalGC;\n  bool UseOdrIndicator;\n  AsanDtorKind DestructorKind;\n};\n\n// Insert AddressSanitizer (address sanity checking) instrumentation\nFunctionPass *createAddressSanitizerFunctionPass(bool CompileKernel = false,\n                                                 bool Recover = false,\n                                                 bool UseAfterScope = false);\nModulePass *createModuleAddressSanitizerLegacyPassPass(\n    bool CompileKernel = false, bool Recover = false, bool UseGlobalsGC = true,\n    bool UseOdrIndicator = true,\n    AsanDtorKind DestructorKind = AsanDtorKind::Global);\n\n} // namespace llvm\n\n#endif\n"}, "141": {"id": 141, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/BoundsChecking.h", "content": "//===- BoundsChecking.h - Bounds checking instrumentation -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_BOUNDSCHECKING_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_BOUNDSCHECKING_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// A pass to instrument code and perform run-time bounds checking on loads,\n/// stores, and other memory intrinsics.\nstruct BoundsCheckingPass : PassInfoMixin<BoundsCheckingPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n\n\n/// Legacy pass creation function for the above pass.\nFunctionPass *createBoundsCheckingLegacyPass();\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_INSTRUMENTATION_BOUNDSCHECKING_H\n"}, "142": {"id": 142, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/CGProfile.h", "content": "//===- Transforms/Instrumentation/CGProfile.h -------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This file provides the interface for LLVM's Call Graph Profile pass.\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_CGPROFILE_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_CGPROFILE_H\n\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass CGProfilePass : public PassInfoMixin<CGProfilePass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_INSTRUMENTATION_CGPROFILE_H\n"}, "143": {"id": 143, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/DataFlowSanitizer.h", "content": "//===- DataFlowSanitizer.h - dynamic data flow analysis -------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_DATAFLOWSANITIZER_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_DATAFLOWSANITIZER_H\n\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n#include <string>\n#include <vector>\n\nnamespace llvm {\n\nclass DataFlowSanitizerPass : public PassInfoMixin<DataFlowSanitizerPass> {\nprivate:\n  std::vector<std::string> ABIListFiles;\n\npublic:\n  DataFlowSanitizerPass(\n      const std::vector<std::string> &ABIListFiles = std::vector<std::string>())\n      : ABIListFiles(ABIListFiles) {}\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n\n} // namespace llvm\n\n#endif\n"}, "144": {"id": 144, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/InstrOrderFile.h", "content": "//===- InstrOrderFile.h ---- Late IR instrumentation for order file ----===//\n//\n//                     The LLVM Compiler Infrastructure\n//\n// This file is distributed under the University of Illinois Open Source\n// License. See LICENSE.TXT for details.\n//\n//===----------------------------------------------------------------------===//\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_INSTRORDERFILE_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_INSTRORDERFILE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass Module;\n\n/// The instrumentation pass for recording function order.\nclass InstrOrderFilePass : public PassInfoMixin<InstrOrderFilePass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_INSTRUMENTATION_INSTRORDERFILE_H\n"}, "145": {"id": 145, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/MemorySanitizer.h", "content": "//===- Transforms/Instrumentation/MemorySanitizer.h - MSan Pass -----------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the memoy sanitizer pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_MEMORYSANITIZER_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_MEMORYSANITIZER_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nstruct MemorySanitizerOptions {\n  MemorySanitizerOptions() : MemorySanitizerOptions(0, false, false){};\n  MemorySanitizerOptions(int TrackOrigins, bool Recover, bool Kernel);\n  bool Kernel;\n  int TrackOrigins;\n  bool Recover;\n};\n\n// Insert MemorySanitizer instrumentation (detection of uninitialized reads)\nFunctionPass *\ncreateMemorySanitizerLegacyPassPass(MemorySanitizerOptions Options = {});\n\n/// A function pass for msan instrumentation.\n///\n/// Instruments functions to detect unitialized reads. This function pass\n/// inserts calls to runtime library functions. If the functions aren't declared\n/// yet, the pass inserts the declarations. Otherwise the existing globals are\n/// used.\nstruct MemorySanitizerPass : public PassInfoMixin<MemorySanitizerPass> {\n  MemorySanitizerPass(MemorySanitizerOptions Options) : Options(Options) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  static bool isRequired() { return true; }\n\nprivate:\n  MemorySanitizerOptions Options;\n};\n}\n\n#endif /* LLVM_TRANSFORMS_INSTRUMENTATION_MEMORYSANITIZER_H */\n"}, "146": {"id": 146, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/PoisonChecking.h", "content": "//===- PoisonChecking.h - ---------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_POISONCHECKING_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_POISONCHECKING_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct PoisonCheckingPass : public PassInfoMixin<PoisonCheckingPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n}\n\n#endif // LLVM_TRANSFORMS_INSTRUMENTATION_POISONCHECKING_H\n"}, "147": {"id": 147, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/SanitizerCoverage.h", "content": "//===--------- Definition of the SanitizerCoverage class --------*- C++ -*-===//\n//\n//                     The LLVM Compiler Infrastructure\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file declares the SanitizerCoverage class which is a port of the legacy\n// SanitizerCoverage pass to use the new PassManager infrastructure.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_SANITIZERCOVERAGE_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_SANITIZERCOVERAGE_H\n\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/SpecialCaseList.h\"\n#include \"llvm/Support/VirtualFileSystem.h\"\n#include \"llvm/Transforms/Instrumentation.h\"\n\nnamespace llvm {\n\n/// This is the ModuleSanitizerCoverage pass used in the new pass manager. The\n/// pass instruments functions for coverage, adds initialization calls to the\n/// module for trace PC guards and 8bit counters if they are requested, and\n/// appends globals to llvm.compiler.used.\nclass ModuleSanitizerCoveragePass\n    : public PassInfoMixin<ModuleSanitizerCoveragePass> {\npublic:\n  explicit ModuleSanitizerCoveragePass(\n      SanitizerCoverageOptions Options = SanitizerCoverageOptions(),\n      const std::vector<std::string> &AllowlistFiles =\n          std::vector<std::string>(),\n      const std::vector<std::string> &BlocklistFiles =\n          std::vector<std::string>())\n      : Options(Options) {\n    if (AllowlistFiles.size() > 0)\n      Allowlist = SpecialCaseList::createOrDie(AllowlistFiles,\n                                               *vfs::getRealFileSystem());\n    if (BlocklistFiles.size() > 0)\n      Blocklist = SpecialCaseList::createOrDie(BlocklistFiles,\n                                               *vfs::getRealFileSystem());\n  }\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  static bool isRequired() { return true; }\n\nprivate:\n  SanitizerCoverageOptions Options;\n\n  std::unique_ptr<SpecialCaseList> Allowlist;\n  std::unique_ptr<SpecialCaseList> Blocklist;\n};\n\n// Insert SanitizerCoverage instrumentation.\nModulePass *createModuleSanitizerCoverageLegacyPassPass(\n    const SanitizerCoverageOptions &Options = SanitizerCoverageOptions(),\n    const std::vector<std::string> &AllowlistFiles = std::vector<std::string>(),\n    const std::vector<std::string> &BlocklistFiles =\n        std::vector<std::string>());\n\n} // namespace llvm\n\n#endif\n"}, "148": {"id": 148, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/ThreadSanitizer.h", "content": "//===- Transforms/Instrumentation/ThreadSanitizer.h - TSan Pass -----------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the thread sanitizer pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_INSTRUMENTATION_THREADSANITIZER_H\n#define LLVM_TRANSFORMS_INSTRUMENTATION_THREADSANITIZER_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n// Insert ThreadSanitizer (race detection) instrumentation\nFunctionPass *createThreadSanitizerLegacyPassPass();\n\n/// A function pass for tsan instrumentation.\n///\n/// Instruments functions to detect race conditions reads. This function pass\n/// inserts calls to runtime library functions. If the functions aren't declared\n/// yet, the pass inserts the declarations. Otherwise the existing globals are\nstruct ThreadSanitizerPass : public PassInfoMixin<ThreadSanitizerPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n  static bool isRequired() { return true; }\n};\n\n} // namespace llvm\n#endif /* LLVM_TRANSFORMS_INSTRUMENTATION_THREADSANITIZER_H */\n"}, "149": {"id": 149, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/ObjCARC.h", "content": "//===-- ObjCARC.h - ObjCARC Scalar Transformations --------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This header file defines prototypes for accessor functions that expose passes\n// in the ObjCARC Scalar Transformations library.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_OBJCARC_H\n#define LLVM_TRANSFORMS_OBJCARC_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Pass;\n\n//===----------------------------------------------------------------------===//\n//\n// ObjCARCAPElim - ObjC ARC autorelease pool elimination.\n//\nPass *createObjCARCAPElimPass();\n\n//===----------------------------------------------------------------------===//\n//\n// ObjCARCExpand - ObjC ARC preliminary simplifications.\n//\nPass *createObjCARCExpandPass();\n\n//===----------------------------------------------------------------------===//\n//\n// ObjCARCContract - Late ObjC ARC cleanups.\n//\nPass *createObjCARCContractPass();\n\n//===----------------------------------------------------------------------===//\n//\n// ObjCARCOpt - ObjC ARC optimization.\n//\nPass *createObjCARCOptPass();\n\nstruct ObjCARCOptPass : public PassInfoMixin<ObjCARCOptPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nstruct ObjCARCContractPass : public PassInfoMixin<ObjCARCContractPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nstruct ObjCARCAPElimPass : public PassInfoMixin<ObjCARCAPElimPass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\nstruct ObjCARCExpandPass : public PassInfoMixin<ObjCARCExpandPass> {\n  PreservedAnalyses run(Function &M, FunctionAnalysisManager &AM);\n};\n\n} // End llvm namespace\n\n#endif\n"}, "150": {"id": 150, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/ADCE.h", "content": "//===- ADCE.h - Aggressive dead code elimination ----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides the interface for the Aggressive Dead Code Elimination\n// pass. This pass optimistically assumes that all instructions are dead until\n// proven otherwise, allowing it to eliminate dead computations that other DCE\n// passes do not catch, particularly involving loop computations.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_ADCE_H\n#define LLVM_TRANSFORMS_SCALAR_ADCE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\n/// A DCE pass that assumes instructions are dead until proven otherwise.\n///\n/// This pass eliminates dead code by optimistically assuming that all\n/// instructions are dead until proven otherwise. This allows it to eliminate\n/// dead computations that other DCE passes do not catch, particularly involving\n/// loop computations.\nstruct ADCEPass : PassInfoMixin<ADCEPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_ADCE_H\n"}, "151": {"id": 151, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/AlignmentFromAssumptions.h", "content": "//===---- AlignmentFromAssumptions.h ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements a ScalarEvolution-based transformation to set\n// the alignments of load, stores and memory intrinsics based on the truth\n// expressions of assume intrinsics. The primary motivation is to handle\n// complex alignment assumptions that apply to vector loads and stores that\n// appear after vectorization and unrolling.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_ALIGNMENTFROMASSUMPTIONS_H\n#define LLVM_TRANSFORMS_SCALAR_ALIGNMENTFROMASSUMPTIONS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass DominatorTree;\nclass ScalarEvolution;\nclass SCEV;\n\nstruct AlignmentFromAssumptionsPass\n    : public PassInfoMixin<AlignmentFromAssumptionsPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n\n  // Glue for old PM.\n  bool runImpl(Function &F, AssumptionCache &AC, ScalarEvolution *SE_,\n               DominatorTree *DT_);\n\n  ScalarEvolution *SE = nullptr;\n  DominatorTree *DT = nullptr;\n\n  bool extractAlignmentInfo(CallInst *I, unsigned Idx, Value *&AAPtr,\n                            const SCEV *&AlignSCEV, const SCEV *&OffSCEV);\n  bool processAssumption(CallInst *I, unsigned Idx);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_ALIGNMENTFROMASSUMPTIONS_H\n"}, "152": {"id": 152, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/AnnotationRemarks.h", "content": "//===- AnnotationRemarks.cpp - Emit remarks for !annotation MD --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// This file defines AnnotationRemarksPass for the new pass manager.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_ANNOTATIONREMARKS_H\n#define LLVM_TRANSFORMS_SCALAR_ANNOTATIONREMARKS_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct AnnotationRemarksPass : public PassInfoMixin<AnnotationRemarksPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_ANNOTATIONREMARKS_H\n"}, "153": {"id": 153, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/BDCE.h", "content": "//===---- BDCE.cpp - Bit-tracking dead code elimination ---------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements the Bit-Tracking Dead Code Elimination pass. Some\n// instructions (shifts, some ands, ors, etc.) kill some of their input bits.\n// We track these dead bits and remove instructions that compute only these\n// dead bits.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_BDCE_H\n#define LLVM_TRANSFORMS_SCALAR_BDCE_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n// The Bit-Tracking Dead Code Elimination pass.\nstruct BDCEPass : PassInfoMixin<BDCEPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_BDCE_H\n"}, "154": {"id": 154, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/CallSiteSplitting.h", "content": "//===- CallSiteSplitting..h - Callsite Splitting ------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_CALLSITESPLITTING_H\n#define LLVM_TRANSFORMS_SCALAR_CALLSITESPLITTING_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct CallSiteSplittingPass : PassInfoMixin<CallSiteSplittingPass> {\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_CALLSITESPLITTING_H\n"}, "156": {"id": 156, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/ConstraintElimination.h", "content": "//===- ConstraintElimination.h - Constraint elimination pass ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_CONSTRAINTELIMINATION_H\n#define LLVM_TRANSFORMS_SCALAR_CONSTRAINTELIMINATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass ConstraintEliminationPass\n    : public PassInfoMixin<ConstraintEliminationPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_CONSTRAINTELIMINATION_H\n"}, "157": {"id": 157, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/CorrelatedValuePropagation.h", "content": "//===- CorrelatedValuePropagation.h -----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_CORRELATEDVALUEPROPAGATION_H\n#define LLVM_TRANSFORMS_SCALAR_CORRELATEDVALUEPROPAGATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nstruct CorrelatedValuePropagationPass\n    : PassInfoMixin<CorrelatedValuePropagationPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_CORRELATEDVALUEPROPAGATION_H\n"}, "158": {"id": 158, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DCE.h", "content": "//===- DCE.h - Dead code elimination ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides the interface for the Dead Code Elimination pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_DCE_H\n#define LLVM_TRANSFORMS_SCALAR_DCE_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// Basic Dead Code Elimination pass.\nclass DCEPass : public PassInfoMixin<DCEPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nclass RedundantDbgInstEliminationPass\n    : public PassInfoMixin<RedundantDbgInstEliminationPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_DCE_H\n"}, "159": {"id": 159, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DeadStoreElimination.h", "content": "//===- DeadStoreElimination.h - Fast Dead Store Elimination -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements a trivial dead store elimination that only considers\n// basic-block local redundant stores.\n//\n// FIXME: This should eventually be extended to be a post-dominator tree\n// traversal.  Doing so would be pretty trivial.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_DEADSTOREELIMINATION_H\n#define LLVM_TRANSFORMS_SCALAR_DEADSTOREELIMINATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\n/// This class implements a trivial dead store elimination. We consider\n/// only the redundant stores that are local to a single Basic Block.\nclass DSEPass : public PassInfoMixin<DSEPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_DEADSTOREELIMINATION_H\n"}, "160": {"id": 160, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DivRemPairs.h", "content": "//===- DivRemPairs.h - Hoist/decompose integer division and remainder -----===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass hoists and/or decomposes integer division and remainder\n// instructions to enable CFG improvements and better codegen.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_DIVREMPAIRS_H\n#define LLVM_TRANSFORMS_SCALAR_DIVREMPAIRS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// Hoist/decompose integer division and remainder instructions to enable CFG\n/// improvements and better codegen.\nstruct DivRemPairsPass : public PassInfoMixin<DivRemPairsPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n};\n\n}\n#endif // LLVM_TRANSFORMS_SCALAR_DIVREMPAIRS_H\n\n"}, "161": {"id": 161, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Float2Int.h", "content": "//===-- Float2Int.h - Demote floating point ops to work on integers -------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides the Float2Int pass, which aims to demote floating\n// point operations to work on integers, where that is losslessly possible.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_FLOAT2INT_H\n#define LLVM_TRANSFORMS_SCALAR_FLOAT2INT_H\n\n#include \"llvm/ADT/EquivalenceClasses.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/IR/ConstantRange.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass Float2IntPass : public PassInfoMixin<Float2IntPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n\n  // Glue for old PM.\n  bool runImpl(Function &F, const DominatorTree &DT);\n\nprivate:\n  void findRoots(Function &F, const DominatorTree &DT);\n  void seen(Instruction *I, ConstantRange R);\n  ConstantRange badRange();\n  ConstantRange unknownRange();\n  ConstantRange validateRange(ConstantRange R);\n  void walkBackwards();\n  void walkForwards();\n  bool validateAndTransform();\n  Value *convert(Instruction *I, Type *ToTy);\n  void cleanup();\n\n  MapVector<Instruction *, ConstantRange> SeenInsts;\n  SmallSetVector<Instruction *, 8> Roots;\n  EquivalenceClasses<Instruction *> ECs;\n  MapVector<Instruction *, Value *> ConvertedInsts;\n  LLVMContext *Ctx;\n};\n}\n#endif // LLVM_TRANSFORMS_SCALAR_FLOAT2INT_H\n"}, "162": {"id": 162, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h", "content": "//===- GVN.h - Eliminate redundant values and loads -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This file provides the interface for LLVM's Global Value Numbering pass\n/// which eliminates fully redundant instructions. It also does somewhat Ad-Hoc\n/// PRE and dead load elimination.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_GVN_H\n#define LLVM_TRANSFORMS_SCALAR_GVN_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/PostOrderIterator.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Analysis/InstructionPrecedenceTracking.h\"\n#include \"llvm/Analysis/MemoryDependenceAnalysis.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Allocator.h\"\n#include \"llvm/Support/Compiler.h\"\n#include <cstdint>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\nclass AAResults;\nclass AssumptionCache;\nclass BasicBlock;\nclass BranchInst;\nclass CallInst;\nclass Constant;\nclass ExtractValueInst;\nclass Function;\nclass FunctionPass;\nclass IntrinsicInst;\nclass LoadInst;\nclass LoopInfo;\nclass MemorySSA;\nclass MemorySSAUpdater;\nclass OptimizationRemarkEmitter;\nclass PHINode;\nclass TargetLibraryInfo;\nclass Value;\n/// A private \"module\" namespace for types and utilities used by GVN. These\n/// are implementation details and should not be used by clients.\nnamespace gvn LLVM_LIBRARY_VISIBILITY {\n\nstruct AvailableValue;\nstruct AvailableValueInBlock;\nclass GVNLegacyPass;\n\n} // end namespace gvn\n\n/// A set of parameters to control various transforms performed by GVN pass.\n//  Each of the optional boolean parameters can be set to:\n///      true - enabling the transformation.\n///      false - disabling the transformation.\n///      None - relying on a global default.\n/// Intended use is to create a default object, modify parameters with\n/// additional setters and then pass it to GVN.\nstruct GVNOptions {\n  Optional<bool> AllowPRE = None;\n  Optional<bool> AllowLoadPRE = None;\n  Optional<bool> AllowLoadInLoopPRE = None;\n  Optional<bool> AllowLoadPRESplitBackedge = None;\n  Optional<bool> AllowMemDep = None;\n\n  GVNOptions() = default;\n\n  /// Enables or disables PRE in GVN.\n  GVNOptions &setPRE(bool PRE) {\n    AllowPRE = PRE;\n    return *this;\n  }\n\n  /// Enables or disables PRE of loads in GVN.\n  GVNOptions &setLoadPRE(bool LoadPRE) {\n    AllowLoadPRE = LoadPRE;\n    return *this;\n  }\n\n  GVNOptions &setLoadInLoopPRE(bool LoadInLoopPRE) {\n    AllowLoadInLoopPRE = LoadInLoopPRE;\n    return *this;\n  }\n\n  /// Enables or disables PRE of loads in GVN.\n  GVNOptions &setLoadPRESplitBackedge(bool LoadPRESplitBackedge) {\n    AllowLoadPRESplitBackedge = LoadPRESplitBackedge;\n    return *this;\n  }\n\n  /// Enables or disables use of MemDepAnalysis.\n  GVNOptions &setMemDep(bool MemDep) {\n    AllowMemDep = MemDep;\n    return *this;\n  }\n};\n\n/// The core GVN pass object.\n///\n/// FIXME: We should have a good summary of the GVN algorithm implemented by\n/// this particular pass here.\nclass GVN : public PassInfoMixin<GVN> {\n  GVNOptions Options;\n\npublic:\n  struct Expression;\n\n  GVN(GVNOptions Options = {}) : Options(Options) {}\n\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n\n  /// This removes the specified instruction from\n  /// our various maps and marks it for deletion.\n  void markInstructionForDeletion(Instruction *I) {\n    VN.erase(I);\n    InstrsToErase.push_back(I);\n  }\n\n  DominatorTree &getDominatorTree() const { return *DT; }\n  AAResults *getAliasAnalysis() const { return VN.getAliasAnalysis(); }\n  MemoryDependenceResults &getMemDep() const { return *MD; }\n\n  bool isPREEnabled() const;\n  bool isLoadPREEnabled() const;\n  bool isLoadInLoopPREEnabled() const;\n  bool isLoadPRESplitBackedgeEnabled() const;\n  bool isMemDepEnabled() const;\n\n  /// This class holds the mapping between values and value numbers.  It is used\n  /// as an efficient mechanism to determine the expression-wise equivalence of\n  /// two values.\n  class ValueTable {\n    DenseMap<Value *, uint32_t> valueNumbering;\n    DenseMap<Expression, uint32_t> expressionNumbering;\n\n    // Expressions is the vector of Expression. ExprIdx is the mapping from\n    // value number to the index of Expression in Expressions. We use it\n    // instead of a DenseMap because filling such mapping is faster than\n    // filling a DenseMap and the compile time is a little better.\n    uint32_t nextExprNumber = 0;\n\n    std::vector<Expression> Expressions;\n    std::vector<uint32_t> ExprIdx;\n\n    // Value number to PHINode mapping. Used for phi-translate in scalarpre.\n    DenseMap<uint32_t, PHINode *> NumberingPhi;\n\n    // Cache for phi-translate in scalarpre.\n    using PhiTranslateMap =\n        DenseMap<std::pair<uint32_t, const BasicBlock *>, uint32_t>;\n    PhiTranslateMap PhiTranslateTable;\n\n    AAResults *AA = nullptr;\n    MemoryDependenceResults *MD = nullptr;\n    DominatorTree *DT = nullptr;\n\n    uint32_t nextValueNumber = 1;\n\n    Expression createExpr(Instruction *I);\n    Expression createCmpExpr(unsigned Opcode, CmpInst::Predicate Predicate,\n                             Value *LHS, Value *RHS);\n    Expression createExtractvalueExpr(ExtractValueInst *EI);\n    uint32_t lookupOrAddCall(CallInst *C);\n    uint32_t phiTranslateImpl(const BasicBlock *BB, const BasicBlock *PhiBlock,\n                              uint32_t Num, GVN &Gvn);\n    bool areCallValsEqual(uint32_t Num, uint32_t NewNum, const BasicBlock *Pred,\n                          const BasicBlock *PhiBlock, GVN &Gvn);\n    std::pair<uint32_t, bool> assignExpNewValueNum(Expression &exp);\n    bool areAllValsInBB(uint32_t num, const BasicBlock *BB, GVN &Gvn);\n\n  public:\n    ValueTable();\n    ValueTable(const ValueTable &Arg);\n    ValueTable(ValueTable &&Arg);\n    ~ValueTable();\n    ValueTable &operator=(const ValueTable &Arg);\n\n    uint32_t lookupOrAdd(Value *V);\n    uint32_t lookup(Value *V, bool Verify = true) const;\n    uint32_t lookupOrAddCmp(unsigned Opcode, CmpInst::Predicate Pred,\n                            Value *LHS, Value *RHS);\n    uint32_t phiTranslate(const BasicBlock *BB, const BasicBlock *PhiBlock,\n                          uint32_t Num, GVN &Gvn);\n    void eraseTranslateCacheEntry(uint32_t Num, const BasicBlock &CurrBlock);\n    bool exists(Value *V) const;\n    void add(Value *V, uint32_t num);\n    void clear();\n    void erase(Value *v);\n    void setAliasAnalysis(AAResults *A) { AA = A; }\n    AAResults *getAliasAnalysis() const { return AA; }\n    void setMemDep(MemoryDependenceResults *M) { MD = M; }\n    void setDomTree(DominatorTree *D) { DT = D; }\n    uint32_t getNextUnusedValueNumber() { return nextValueNumber; }\n    void verifyRemoved(const Value *) const;\n  };\n\nprivate:\n  friend class gvn::GVNLegacyPass;\n  friend struct DenseMapInfo<Expression>;\n\n  MemoryDependenceResults *MD = nullptr;\n  DominatorTree *DT = nullptr;\n  const TargetLibraryInfo *TLI = nullptr;\n  AssumptionCache *AC = nullptr;\n  SetVector<BasicBlock *> DeadBlocks;\n  OptimizationRemarkEmitter *ORE = nullptr;\n  ImplicitControlFlowTracking *ICF = nullptr;\n  LoopInfo *LI = nullptr;\n  MemorySSAUpdater *MSSAU = nullptr;\n\n  ValueTable VN;\n\n  /// A mapping from value numbers to lists of Value*'s that\n  /// have that value number.  Use findLeader to query it.\n  struct LeaderTableEntry {\n    Value *Val;\n    const BasicBlock *BB;\n    LeaderTableEntry *Next;\n  };\n  DenseMap<uint32_t, LeaderTableEntry> LeaderTable;\n  BumpPtrAllocator TableAllocator;\n\n  // Block-local map of equivalent values to their leader, does not\n  // propagate to any successors. Entries added mid-block are applied\n  // to the remaining instructions in the block.\n  SmallMapVector<Value *, Value *, 4> ReplaceOperandsWithMap;\n  SmallVector<Instruction *, 8> InstrsToErase;\n\n  // Map the block to reversed postorder traversal number. It is used to\n  // find back edge easily.\n  DenseMap<AssertingVH<BasicBlock>, uint32_t> BlockRPONumber;\n\n  // This is set 'true' initially and also when new blocks have been added to\n  // the function being analyzed. This boolean is used to control the updating\n  // of BlockRPONumber prior to accessing the contents of BlockRPONumber.\n  bool InvalidBlockRPONumbers = true;\n\n  using LoadDepVect = SmallVector<NonLocalDepResult, 64>;\n  using AvailValInBlkVect = SmallVector<gvn::AvailableValueInBlock, 64>;\n  using UnavailBlkVect = SmallVector<BasicBlock *, 64>;\n\n  bool runImpl(Function &F, AssumptionCache &RunAC, DominatorTree &RunDT,\n               const TargetLibraryInfo &RunTLI, AAResults &RunAA,\n               MemoryDependenceResults *RunMD, LoopInfo *LI,\n               OptimizationRemarkEmitter *ORE, MemorySSA *MSSA = nullptr);\n\n  /// Push a new Value to the LeaderTable onto the list for its value number.\n  void addToLeaderTable(uint32_t N, Value *V, const BasicBlock *BB) {\n    LeaderTableEntry &Curr = LeaderTable[N];\n    if (!Curr.Val) {\n      Curr.Val = V;\n      Curr.BB = BB;\n      return;\n    }\n\n    LeaderTableEntry *Node = TableAllocator.Allocate<LeaderTableEntry>();\n    Node->Val = V;\n    Node->BB = BB;\n    Node->Next = Curr.Next;\n    Curr.Next = Node;\n  }\n\n  /// Scan the list of values corresponding to a given\n  /// value number, and remove the given instruction if encountered.\n  void removeFromLeaderTable(uint32_t N, Instruction *I, BasicBlock *BB) {\n    LeaderTableEntry *Prev = nullptr;\n    LeaderTableEntry *Curr = &LeaderTable[N];\n\n    while (Curr && (Curr->Val != I || Curr->BB != BB)) {\n      Prev = Curr;\n      Curr = Curr->Next;\n    }\n\n    if (!Curr)\n      return;\n\n    if (Prev) {\n      Prev->Next = Curr->Next;\n    } else {\n      if (!Curr->Next) {\n        Curr->Val = nullptr;\n        Curr->BB = nullptr;\n      } else {\n        LeaderTableEntry *Next = Curr->Next;\n        Curr->Val = Next->Val;\n        Curr->BB = Next->BB;\n        Curr->Next = Next->Next;\n      }\n    }\n  }\n\n  // List of critical edges to be split between iterations.\n  SmallVector<std::pair<Instruction *, unsigned>, 4> toSplit;\n\n  // Helper functions of redundant load elimination\n  bool processLoad(LoadInst *L);\n  bool processNonLocalLoad(LoadInst *L);\n  bool processAssumeIntrinsic(IntrinsicInst *II);\n\n  /// Given a local dependency (Def or Clobber) determine if a value is\n  /// available for the load.  Returns true if an value is known to be\n  /// available and populates Res.  Returns false otherwise.\n  bool AnalyzeLoadAvailability(LoadInst *LI, MemDepResult DepInfo,\n                               Value *Address, gvn::AvailableValue &Res);\n\n  /// Given a list of non-local dependencies, determine if a value is\n  /// available for the load in each specified block.  If it is, add it to\n  /// ValuesPerBlock.  If not, add it to UnavailableBlocks.\n  void AnalyzeLoadAvailability(LoadInst *LI, LoadDepVect &Deps,\n                               AvailValInBlkVect &ValuesPerBlock,\n                               UnavailBlkVect &UnavailableBlocks);\n\n  bool PerformLoadPRE(LoadInst *LI, AvailValInBlkVect &ValuesPerBlock,\n                      UnavailBlkVect &UnavailableBlocks);\n\n  // Other helper routines\n  bool processInstruction(Instruction *I);\n  bool processBlock(BasicBlock *BB);\n  void dump(DenseMap<uint32_t, Value *> &d) const;\n  bool iterateOnFunction(Function &F);\n  bool performPRE(Function &F);\n  bool performScalarPRE(Instruction *I);\n  bool performScalarPREInsertion(Instruction *Instr, BasicBlock *Pred,\n                                 BasicBlock *Curr, unsigned int ValNo);\n  Value *findLeader(const BasicBlock *BB, uint32_t num);\n  void cleanupGlobalSets();\n  void verifyRemoved(const Instruction *I) const;\n  bool splitCriticalEdges();\n  BasicBlock *splitCriticalEdges(BasicBlock *Pred, BasicBlock *Succ);\n  bool replaceOperandsForInBlockEquality(Instruction *I) const;\n  bool propagateEquality(Value *LHS, Value *RHS, const BasicBlockEdge &Root,\n                         bool DominatesByEdge);\n  bool processFoldableCondBr(BranchInst *BI);\n  void addDeadBlock(BasicBlock *BB);\n  void assignValNumForDeadCode();\n  void assignBlockRPONumber(Function &F);\n};\n\n/// Create a legacy GVN pass. This also allows parameterizing whether or not\n/// MemDep is enabled.\nFunctionPass *createGVNPass(bool NoMemDepAnalysis = false);\n\n/// A simple and fast domtree-based GVN pass to hoist common expressions\n/// from sibling branches.\nstruct GVNHoistPass : PassInfoMixin<GVNHoistPass> {\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Uses an \"inverted\" value numbering to decide the similarity of\n/// expressions and sinks similar expressions into successors.\nstruct GVNSinkPass : PassInfoMixin<GVNSinkPass> {\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_GVN_H\n"}, "163": {"id": 163, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/GuardWidening.h", "content": "//===- GuardWidening.h - ----------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Guard widening is an optimization over the @llvm.experimental.guard intrinsic\n// that (optimistically) combines multiple guards into one to have fewer checks\n// at runtime.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_GUARDWIDENING_H\n#define LLVM_TRANSFORMS_SCALAR_GUARDWIDENING_H\n\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nstruct GuardWideningPass : public PassInfoMixin<GuardWideningPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_GUARDWIDENING_H\n"}, "164": {"id": 164, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/InductiveRangeCheckElimination.h", "content": "//===- InductiveRangeCheckElimination.h - IRCE ------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides the interface for the Inductive Range Check Elimination\n// loop pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_INDUCTIVERANGECHECKELIMINATION_H\n#define LLVM_TRANSFORMS_SCALAR_INDUCTIVERANGECHECKELIMINATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass IRCEPass : public PassInfoMixin<IRCEPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_INDUCTIVERANGECHECKELIMINATION_H\n"}, "165": {"id": 165, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/InstSimplifyPass.h", "content": "//===- InstSimplifyPass.h ---------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// Defines passes for running instruction simplification across chunks of IR.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_INSTSIMPLIFYPASS_H\n#define LLVM_TRANSFORMS_SCALAR_INSTSIMPLIFYPASS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass FunctionPass;\n\n/// Run instruction simplification across each instruction in the function.\n///\n/// Instruction simplification has useful constraints in some contexts:\n/// - It will never introduce *new* instructions.\n/// - There is no need to iterate to a fixed point.\n///\n/// Many passes use instruction simplification as a library facility, but it may\n/// also be useful (in tests and other contexts) to have access to this very\n/// restricted transform at a pass granularity. However, for a much more\n/// powerful and comprehensive peephole optimization engine, see the\n/// `instcombine` pass instead.\nclass InstSimplifyPass : public PassInfoMixin<InstSimplifyPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_INSTSIMPLIFYPASS_H\n"}, "166": {"id": 166, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopDistribute.h", "content": "//===- LoopDistribute.cpp - Loop Distribution Pass --------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements the Loop Distribution Pass.  Its main focus is to\n// distribute loops that cannot be vectorized due to dependence cycles.  It\n// tries to isolate the offending dependences into a new loop allowing\n// vectorization of the remaining parts.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPDISTRIBUTE_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPDISTRIBUTE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass LoopDistributePass : public PassInfoMixin<LoopDistributePass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPDISTRIBUTE_H\n"}, "167": {"id": 167, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopFuse.h", "content": "//===- LoopFuse.h - Loop Fusion Pass ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// This file implements the Loop Fusion pass.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPFUSE_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPFUSE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass LoopFusePass : public PassInfoMixin<LoopFusePass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPFUSE_H\n"}, "168": {"id": 168, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopIdiomRecognize.h", "content": "//===- LoopIdiomRecognize.h - Loop Idiom Recognize Pass ---------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass implements an idiom recognizer that transforms simple loops into a\n// non-loop form.  In cases that this kicks in, it can be a significant\n// performance win.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPIDIOMRECOGNIZE_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPIDIOMRECOGNIZE_H\n\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Loop;\nclass LPMUpdater;\n\n/// Options to disable Loop Idiom Recognize, which can be shared with other\n/// passes.\nstruct DisableLIRP {\n  /// When true, the entire pass is disabled.\n  static bool All;\n\n  /// When true, Memset is disabled.\n  static bool Memset;\n\n  /// When true, Memcpy is disabled.\n  static bool Memcpy;\n};\n\n/// Performs Loop Idiom Recognize Pass.\nclass LoopIdiomRecognizePass : public PassInfoMixin<LoopIdiomRecognizePass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPIDIOMRECOGNIZE_H\n"}, "169": {"id": 169, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopInstSimplify.h", "content": "//===- LoopInstSimplify.h - Loop Inst Simplify Pass -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass performs lightweight instruction simplification on loop bodies.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPINSTSIMPLIFY_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPINSTSIMPLIFY_H\n\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Loop;\nclass LPMUpdater;\n\n/// Performs Loop Inst Simplify Pass.\nclass LoopInstSimplifyPass : public PassInfoMixin<LoopInstSimplifyPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPINSTSIMPLIFY_H\n"}, "170": {"id": 170, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopInterchange.h", "content": "//===- LoopInterchange.h - Loop interchange pass --------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPINTERCHANGE_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPINTERCHANGE_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\nstruct LoopInterchangePass : public PassInfoMixin<LoopInterchangePass> {\n  PreservedAnalyses run(LoopNest &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPINTERCHANGE_H\n"}, "171": {"id": 171, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopLoadElimination.h", "content": "//===- LoopLoadElimination.h ------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This header defines the LoopLoadEliminationPass object. This pass forwards\n/// loaded values around loop backedges to allow their use in subsequent\n/// iterations.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPLOADELIMINATION_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPLOADELIMINATION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\n/// Pass to forward loads in a loop around the backedge to subsequent\n/// iterations.\nstruct LoopLoadEliminationPass : public PassInfoMixin<LoopLoadEliminationPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPLOADELIMINATION_H\n"}, "173": {"id": 173, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopPredication.h", "content": "//===- LoopPredication.h - Guard based loop predication pass ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass tries to convert loop variant range checks to loop invariant by\n// widening checks across loop iterations.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPPREDICATION_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPPREDICATION_H\n\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\n/// Performs Loop Predication Pass.\nclass LoopPredicationPass : public PassInfoMixin<LoopPredicationPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPPREDICATION_H\n"}, "174": {"id": 174, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopReroll.h", "content": "//===- LoopReroll.h - Loop rerolling pass ---------------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPREROLL_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPREROLL_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass LoopRerollPass : public PassInfoMixin<LoopRerollPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPREROLL_H\n"}, "175": {"id": 175, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopSimplifyCFG.h", "content": "//===- LoopSimplifyCFG.cpp - Loop CFG Simplification Pass -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file implements the Loop SimplifyCFG Pass. This pass is responsible for\n// basic loop CFG cleanup, primarily to assist other loop passes. If you\n// encounter a noncanonical CFG construct that causes another loop pass to\n// perform suboptimally, this is the place to fix it up.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPSIMPLIFYCFG_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPSIMPLIFYCFG_H\n\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\n/// Performs basic CFG simplifications to assist other loop passes.\nclass LoopSimplifyCFGPass : public PassInfoMixin<LoopSimplifyCFGPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPSIMPLIFYCFG_H\n"}, "176": {"id": 176, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopSink.h", "content": "//===- LoopSink.h - Loop Sink Pass ------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides the interface for the Loop Sink pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPSINK_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPSINK_H\n\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\n/// A pass that does profile-guided sinking of instructions into loops.\n///\n/// This is a function pass as it shouldn't be composed into any kind of\n/// unified loop pass pipeline. The goal of it is to sink code into loops that\n/// is loop invariant but only required within the loop body when doing so\n/// reduces the global expected dynamic frequency with which it executes.\n/// A classic example is an extremely cold branch within a loop body.\n///\n/// We do this as a separate pass so that during normal optimization all\n/// invariant operations can be held outside the loop body to simplify\n/// fundamental analyses and transforms of the loop.\nclass LoopSinkPass : public PassInfoMixin<LoopSinkPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPSINK_H\n"}, "178": {"id": 178, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopUnrollPass.h", "content": "//===- LoopUnrollPass.h -----------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPUNROLLPASS_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPUNROLLPASS_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/CommandLine.h\"\n\nnamespace llvm {\n\nextern cl::opt<bool> ForgetSCEVInLoopUnroll;\n\nclass Function;\nclass Loop;\nclass LPMUpdater;\n\n/// Loop unroll pass that only does full loop unrolling and peeling.\nclass LoopFullUnrollPass : public PassInfoMixin<LoopFullUnrollPass> {\n  const int OptLevel;\n\n  /// If false, use a cost model to determine whether unrolling of a loop is\n  /// profitable. If true, only loops that explicitly request unrolling via\n  /// metadata are considered. All other loops are skipped.\n  const bool OnlyWhenForced;\n\n  /// If true, forget all loops when unrolling. If false, forget top-most loop\n  /// of the currently processed loops, which removes one entry at a time from\n  /// the internal SCEV records. For large loops, the former is faster.\n  const bool ForgetSCEV;\n\npublic:\n  explicit LoopFullUnrollPass(int OptLevel = 2, bool OnlyWhenForced = false,\n                              bool ForgetSCEV = false)\n      : OptLevel(OptLevel), OnlyWhenForced(OnlyWhenForced),\n        ForgetSCEV(ForgetSCEV) {}\n\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n/// A set of parameters used to control various transforms performed by the\n/// LoopUnroll pass. Each of the boolean parameters can be set to:\n///      true - enabling the transformation.\n///      false - disabling the transformation.\n///      None - relying on a global default.\n///\n/// There is also OptLevel parameter, which is used for additional loop unroll\n/// tuning.\n///\n/// Intended use is to create a default object, modify parameters with\n/// additional setters and then pass it to LoopUnrollPass.\n///\nstruct LoopUnrollOptions {\n  Optional<bool> AllowPartial;\n  Optional<bool> AllowPeeling;\n  Optional<bool> AllowRuntime;\n  Optional<bool> AllowUpperBound;\n  Optional<bool> AllowProfileBasedPeeling;\n  Optional<unsigned> FullUnrollMaxCount;\n  int OptLevel;\n\n  /// If false, use a cost model to determine whether unrolling of a loop is\n  /// profitable. If true, only loops that explicitly request unrolling via\n  /// metadata are considered. All other loops are skipped.\n  bool OnlyWhenForced;\n\n  /// If true, forget all loops when unrolling. If false, forget top-most loop\n  /// of the currently processed loops, which removes one entry at a time from\n  /// the internal SCEV records. For large loops, the former is faster.\n  const bool ForgetSCEV;\n\n  LoopUnrollOptions(int OptLevel = 2, bool OnlyWhenForced = false,\n                    bool ForgetSCEV = false)\n      : OptLevel(OptLevel), OnlyWhenForced(OnlyWhenForced),\n        ForgetSCEV(ForgetSCEV) {}\n\n  /// Enables or disables partial unrolling. When disabled only full unrolling\n  /// is allowed.\n  LoopUnrollOptions &setPartial(bool Partial) {\n    AllowPartial = Partial;\n    return *this;\n  }\n\n  /// Enables or disables unrolling of loops with runtime trip count.\n  LoopUnrollOptions &setRuntime(bool Runtime) {\n    AllowRuntime = Runtime;\n    return *this;\n  }\n\n  /// Enables or disables loop peeling.\n  LoopUnrollOptions &setPeeling(bool Peeling) {\n    AllowPeeling = Peeling;\n    return *this;\n  }\n\n  /// Enables or disables the use of trip count upper bound\n  /// in loop unrolling.\n  LoopUnrollOptions &setUpperBound(bool UpperBound) {\n    AllowUpperBound = UpperBound;\n    return *this;\n  }\n\n  // Sets \"optimization level\" tuning parameter for loop unrolling.\n  LoopUnrollOptions &setOptLevel(int O) {\n    OptLevel = O;\n    return *this;\n  }\n\n  // Enables or disables loop peeling basing on profile.\n  LoopUnrollOptions &setProfileBasedPeeling(int O) {\n    AllowProfileBasedPeeling = O;\n    return *this;\n  }\n\n  // Sets the max full unroll count.\n  LoopUnrollOptions &setFullUnrollMaxCount(unsigned O) {\n    FullUnrollMaxCount = O;\n    return *this;\n  }\n};\n\n/// Loop unroll pass that will support both full and partial unrolling.\n/// It is a function pass to have access to function and module analyses.\n/// It will also put loops into canonical form (simplified and LCSSA).\nclass LoopUnrollPass : public PassInfoMixin<LoopUnrollPass> {\n  LoopUnrollOptions UnrollOpts;\n\npublic:\n  /// This uses the target information (or flags) to control the thresholds for\n  /// different unrolling stategies but supports all of them.\n  explicit LoopUnrollPass(LoopUnrollOptions UnrollOpts = {})\n      : UnrollOpts(UnrollOpts) {}\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPUNROLLPASS_H\n"}, "179": {"id": 179, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopVersioningLICM.h", "content": "//===- LoopVersioningLICM.h - LICM Loop Versioning ------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOOPVERSIONINGLICM_H\n#define LLVM_TRANSFORMS_SCALAR_LOOPVERSIONINGLICM_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\nclass LoopVersioningLICMPass : public PassInfoMixin<LoopVersioningLICMPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &LAR, LPMUpdater &U);\n};\n\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOOPVERSIONINGLICM_H\n"}, "180": {"id": 180, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerAtomic.h", "content": "//===- LowerAtomic.cpp - Lower atomic intrinsics ----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n// This pass lowers atomic intrinsics to non-atomic form for use in a known\n// non-preemptible environment.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOWERATOMIC_H\n#define LLVM_TRANSFORMS_SCALAR_LOWERATOMIC_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// A pass that lowers atomic intrinsic into non-atomic intrinsics.\nclass LowerAtomicPass : public PassInfoMixin<LowerAtomicPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n  static bool isRequired() { return true; }\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOWERATOMIC_H\n"}, "181": {"id": 181, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerExpectIntrinsic.h", "content": "//===- LowerExpectIntrinsic.h - LowerExpectIntrinsic pass -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// The header file for the LowerExpectIntrinsic pass as used by the new pass\n/// manager.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_LOWEREXPECTINTRINSIC_H\n#define LLVM_TRANSFORMS_SCALAR_LOWEREXPECTINTRINSIC_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/CommandLine.h\"\n\nnamespace llvm {\n\nstruct LowerExpectIntrinsicPass : PassInfoMixin<LowerExpectIntrinsicPass> {\n  /// Run the pass over the function.\n  ///\n  /// This will lower all of the expect intrinsic calls in this function into\n  /// branch weight metadata. That metadata will subsequently feed the analysis\n  /// of the probabilities and frequencies of the CFG. After running this pass,\n  /// no more expect intrinsics remain, allowing the rest of the optimizer to\n  /// ignore them.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n};\n\nextern cl::opt<uint32_t> LikelyBranchWeight;\nextern cl::opt<uint32_t> UnlikelyBranchWeight;\n}\n\n#endif\n"}, "182": {"id": 182, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerGuardIntrinsic.h", "content": "//===--- LowerGuardIntrinsic.h - Lower the guard intrinsic ---------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass lowers the llvm.experimental.guard intrinsic to a conditional call\n// to @llvm.experimental.deoptimize.  Once this happens, the guard can no longer\n// be widened.\n//\n//===----------------------------------------------------------------------===//\n#ifndef LLVM_TRANSFORMS_SCALAR_LOWERGUARDINTRINSIC_H\n#define LLVM_TRANSFORMS_SCALAR_LOWERGUARDINTRINSIC_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct LowerGuardIntrinsicPass : PassInfoMixin<LowerGuardIntrinsicPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOWERGUARDINTRINSIC_H\n"}, "183": {"id": 183, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerWidenableCondition.h", "content": "//===--- LowerWidenableCondition.h - Lower the guard intrinsic ---------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass lowers the llvm.widenable.condition intrinsic to default value\n// which is i1 true.\n//\n//===----------------------------------------------------------------------===//\n#ifndef LLVM_TRANSFORMS_SCALAR_LOWERWIDENABLECONDITION_H\n#define LLVM_TRANSFORMS_SCALAR_LOWERWIDENABLECONDITION_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct LowerWidenableConditionPass : PassInfoMixin<LowerWidenableConditionPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_LOWERWIDENABLECONDITION_H\n"}, "184": {"id": 184, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MakeGuardsExplicit.h", "content": "//===-- MakeGuardsExplicit.h - Turn guard intrinsics into guard branches --===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass lowers the @llvm.experimental.guard intrinsic to the new form of\n// guard represented as widenable explicit branch to the deopt block. The\n// difference between this pass and LowerGuardIntrinsic is that after this pass\n// the guard represented as intrinsic:\n//\n//   call void(i1, ...) @llvm.experimental.guard(i1 %old_cond) [ \"deopt\"() ]\n//\n// transforms to a guard represented as widenable explicit branch:\n//\n//   %widenable_cond = call i1 @llvm.experimental.widenable.condition()\n//   br i1 (%old_cond & %widenable_cond), label %guarded, label %deopt\n//\n// Here:\n//   - The semantics of @llvm.experimental.widenable.condition allows to replace\n//     %widenable_cond with the construction (%widenable_cond & %any_other_cond)\n//     without loss of correctness;\n//   - %guarded is the lower part of old guard intrinsic's parent block split by\n//     the intrinsic call;\n//   - %deopt is a block containing a sole call to @llvm.experimental.deoptimize\n//     intrinsic.\n//\n// Therefore, this branch preserves the property of widenability.\n//\n//===----------------------------------------------------------------------===//\n#ifndef LLVM_TRANSFORMS_SCALAR_MAKEGUARDSEXPLICIT_H\n#define LLVM_TRANSFORMS_SCALAR_MAKEGUARDSEXPLICIT_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct MakeGuardsExplicitPass : public PassInfoMixin<MakeGuardsExplicitPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_MAKEGUARDSEXPLICIT_H\n"}, "186": {"id": 186, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MergedLoadStoreMotion.h", "content": "//===- MergedLoadStoreMotion.h - merge and hoist/sink load/stores ---------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n//! \\file\n//! This pass performs merges of loads and stores on both sides of a\n//  diamond (hammock). It hoists the loads and sinks the stores.\n//\n// The algorithm iteratively hoists two loads to the same address out of a\n// diamond (hammock) and merges them into a single load in the header. Similar\n// it sinks and merges two stores to the tail block (footer). The algorithm\n// iterates over the instructions of one side of the diamond and attempts to\n// find a matching load/store on the other side. It hoists / sinks when it\n// thinks it safe to do so.  This optimization helps with eg. hiding load\n// latencies, triggering if-conversion, and reducing static code size.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_MERGEDLOADSTOREMOTION_H\n#define LLVM_TRANSFORMS_SCALAR_MERGEDLOADSTOREMOTION_H\n\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct MergedLoadStoreMotionOptions {\n  bool SplitFooterBB;\n  MergedLoadStoreMotionOptions(bool SplitFooterBB = false)\n      : SplitFooterBB(SplitFooterBB) {}\n\n  MergedLoadStoreMotionOptions &splitFooterBB(bool SFBB) {\n    SplitFooterBB = SFBB;\n    return *this;\n  }\n};\n\nclass MergedLoadStoreMotionPass\n    : public PassInfoMixin<MergedLoadStoreMotionPass> {\n  MergedLoadStoreMotionOptions Options;\n\npublic:\n  MergedLoadStoreMotionPass()\n      : MergedLoadStoreMotionPass(MergedLoadStoreMotionOptions()) {}\n  MergedLoadStoreMotionPass(const MergedLoadStoreMotionOptions &PassOptions)\n      : Options(PassOptions) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_MERGEDLOADSTOREMOTION_H\n"}, "187": {"id": 187, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/NaryReassociate.h", "content": "//===- NaryReassociate.h - Reassociate n-ary expressions --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass reassociates n-ary add expressions and eliminates the redundancy\n// exposed by the reassociation.\n//\n// A motivating example:\n//\n//   void foo(int a, int b) {\n//     bar(a + b);\n//     bar((a + 2) + b);\n//   }\n//\n// An ideal compiler should reassociate (a + 2) + b to (a + b) + 2 and simplify\n// the above code to\n//\n//   int t = a + b;\n//   bar(t);\n//   bar(t + 2);\n//\n// However, the Reassociate pass is unable to do that because it processes each\n// instruction individually and believes (a + 2) + b is the best form according\n// to its rank system.\n//\n// To address this limitation, NaryReassociate reassociates an expression in a\n// form that reuses existing instructions. As a result, NaryReassociate can\n// reassociate (a + 2) + b in the example to (a + b) + 2 because it detects that\n// (a + b) is computed before.\n//\n// NaryReassociate works as follows. For every instruction in the form of (a +\n// b) + c, it checks whether a + c or b + c is already computed by a dominating\n// instruction. If so, it then reassociates (a + b) + c into (a + c) + b or (b +\n// c) + a and removes the redundancy accordingly. To efficiently look up whether\n// an expression is computed before, we store each instruction seen and its SCEV\n// into an SCEV-to-instruction map.\n//\n// Although the algorithm pattern-matches only ternary additions, it\n// automatically handles many >3-ary expressions by walking through the function\n// in the depth-first order. For example, given\n//\n//   (a + c) + d\n//   ((a + b) + c) + d\n//\n// NaryReassociate first rewrites (a + b) + c to (a + c) + b, and then rewrites\n// ((a + c) + b) + d into ((a + c) + d) + b.\n//\n// Finally, the above dominator-based algorithm may need to be run multiple\n// iterations before emitting optimal code. One source of this need is that we\n// only split an operand when it is used only once. The above algorithm can\n// eliminate an instruction and decrease the usage count of its operands. As a\n// result, an instruction that previously had multiple uses may become a\n// single-use instruction and thus eligible for split consideration. For\n// example,\n//\n//   ac = a + c\n//   ab = a + b\n//   abc = ab + c\n//   ab2 = ab + b\n//   ab2c = ab2 + c\n//\n// In the first iteration, we cannot reassociate abc to ac+b because ab is used\n// twice. However, we can reassociate ab2c to abc+b in the first iteration. As a\n// result, ab2 becomes dead and ab will be used only once in the second\n// iteration.\n//\n// Limitations and TODO items:\n//\n// 1) We only considers n-ary adds and muls for now. This should be extended\n// and generalized.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_NARYREASSOCIATE_H\n#define LLVM_TRANSFORMS_SCALAR_NARYREASSOCIATE_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass BinaryOperator;\nclass DataLayout;\nclass DominatorTree;\nclass Function;\nclass GetElementPtrInst;\nclass Instruction;\nclass ScalarEvolution;\nclass SCEV;\nclass TargetLibraryInfo;\nclass TargetTransformInfo;\nclass Type;\nclass Value;\n\nclass NaryReassociatePass : public PassInfoMixin<NaryReassociatePass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n\n  // Glue for old PM.\n  bool runImpl(Function &F, AssumptionCache *AC_, DominatorTree *DT_,\n               ScalarEvolution *SE_, TargetLibraryInfo *TLI_,\n               TargetTransformInfo *TTI_);\n\nprivate:\n  // Runs only one iteration of the dominator-based algorithm. See the header\n  // comments for why we need multiple iterations.\n  bool doOneIteration(Function &F);\n\n  // Reassociates I for better CSE.\n  Instruction *tryReassociate(Instruction *I, const SCEV *&OrigSCEV);\n\n  // Reassociate GEP for better CSE.\n  Instruction *tryReassociateGEP(GetElementPtrInst *GEP);\n\n  // Try splitting GEP at the I-th index and see whether either part can be\n  // CSE'ed. This is a helper function for tryReassociateGEP.\n  //\n  // \\p IndexedType The element type indexed by GEP's I-th index. This is\n  //                equivalent to\n  //                  GEP->getIndexedType(GEP->getPointerOperand(), 0-th index,\n  //                                      ..., i-th index).\n  GetElementPtrInst *tryReassociateGEPAtIndex(GetElementPtrInst *GEP,\n                                              unsigned I, Type *IndexedType);\n\n  // Given GEP's I-th index = LHS + RHS, see whether &Base[..][LHS][..] or\n  // &Base[..][RHS][..] can be CSE'ed and rewrite GEP accordingly.\n  GetElementPtrInst *tryReassociateGEPAtIndex(GetElementPtrInst *GEP,\n                                              unsigned I, Value *LHS,\n                                              Value *RHS, Type *IndexedType);\n\n  // Reassociate binary operators for better CSE.\n  Instruction *tryReassociateBinaryOp(BinaryOperator *I);\n\n  // A helper function for tryReassociateBinaryOp. LHS and RHS are explicitly\n  // passed.\n  Instruction *tryReassociateBinaryOp(Value *LHS, Value *RHS,\n                                      BinaryOperator *I);\n  // Rewrites I to (LHS op RHS) if LHS is computed already.\n  Instruction *tryReassociatedBinaryOp(const SCEV *LHS, Value *RHS,\n                                       BinaryOperator *I);\n\n  // Tries to match Op1 and Op2 by using V.\n  bool matchTernaryOp(BinaryOperator *I, Value *V, Value *&Op1, Value *&Op2);\n\n  // Gets SCEV for (LHS op RHS).\n  const SCEV *getBinarySCEV(BinaryOperator *I, const SCEV *LHS,\n                            const SCEV *RHS);\n\n  // Returns the closest dominator of \\c Dominatee that computes\n  // \\c CandidateExpr. Returns null if not found.\n  Instruction *findClosestMatchingDominator(const SCEV *CandidateExpr,\n                                            Instruction *Dominatee);\n\n  // GetElementPtrInst implicitly sign-extends an index if the index is shorter\n  // than the pointer size. This function returns whether Index is shorter than\n  // GEP's pointer size, i.e., whether Index needs to be sign-extended in order\n  // to be an index of GEP.\n  bool requiresSignExtension(Value *Index, GetElementPtrInst *GEP);\n\n  AssumptionCache *AC;\n  const DataLayout *DL;\n  DominatorTree *DT;\n  ScalarEvolution *SE;\n  TargetLibraryInfo *TLI;\n  TargetTransformInfo *TTI;\n\n  // A lookup table quickly telling which instructions compute the given SCEV.\n  // Note that there can be multiple instructions at different locations\n  // computing to the same SCEV, so we map a SCEV to an instruction list.  For\n  // example,\n  //\n  //   if (p1)\n  //     foo(a + b);\n  //   if (p2)\n  //     bar(a + b);\n  DenseMap<const SCEV *, SmallVector<WeakTrackingVH, 2>> SeenExprs;\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_NARYREASSOCIATE_H\n"}, "188": {"id": 188, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/NewGVN.h", "content": "//===- NewGVN.h - Global Value Numbering Pass -------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This file provides the interface for LLVM's Global Value Numbering pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_NEWGVN_H\n#define LLVM_TRANSFORMS_SCALAR_NEWGVN_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass NewGVNPass : public PassInfoMixin<NewGVNPass> {\npublic:\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, AnalysisManager<Function> &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_NEWGVN_H\n\n"}, "190": {"id": 190, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Reassociate.h", "content": "//===- Reassociate.h - Reassociate binary expressions -----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass reassociates commutative expressions in an order that is designed\n// to promote better constant propagation, GCSE, LICM, PRE, etc.\n//\n// For example: 4 + (x + 5) -> x + (4 + 5)\n//\n// In the implementation of this algorithm, constants are assigned rank = 0,\n// function arguments are rank = 1, and other values are assigned ranks\n// corresponding to the reverse post order traversal of current function\n// (starting at 2), which effectively gives values in deep loops higher rank\n// than values not in loops.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_REASSOCIATE_H\n#define LLVM_TRANSFORMS_SCALAR_REASSOCIATE_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/PostOrderIterator.h\"\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include <deque>\n\nnamespace llvm {\n\nclass APInt;\nclass BasicBlock;\nclass BinaryOperator;\nclass Function;\nclass Instruction;\nclass IRBuilderBase;\nclass Value;\n\n/// A private \"module\" namespace for types and utilities used by Reassociate.\n/// These are implementation details and should not be used by clients.\nnamespace reassociate {\n\nstruct ValueEntry {\n  unsigned Rank;\n  Value *Op;\n\n  ValueEntry(unsigned R, Value *O) : Rank(R), Op(O) {}\n};\n\ninline bool operator<(const ValueEntry &LHS, const ValueEntry &RHS) {\n  return LHS.Rank > RHS.Rank; // Sort so that highest rank goes to start.\n}\n\n/// Utility class representing a base and exponent pair which form one\n/// factor of some product.\nstruct Factor {\n  Value *Base;\n  unsigned Power;\n\n  Factor(Value *Base, unsigned Power) : Base(Base), Power(Power) {}\n};\n\nclass XorOpnd;\n\n} // end namespace reassociate\n\n/// Reassociate commutative expressions.\nclass ReassociatePass : public PassInfoMixin<ReassociatePass> {\npublic:\n  using OrderedSet =\n      SetVector<AssertingVH<Instruction>, std::deque<AssertingVH<Instruction>>>;\n\nprotected:\n  DenseMap<BasicBlock *, unsigned> RankMap;\n  DenseMap<AssertingVH<Value>, unsigned> ValueRankMap;\n  OrderedSet RedoInsts;\n\n  // Arbitrary, but prevents quadratic behavior.\n  static const unsigned GlobalReassociateLimit = 10;\n  static const unsigned NumBinaryOps =\n      Instruction::BinaryOpsEnd - Instruction::BinaryOpsBegin;\n\n  struct PairMapValue {\n    WeakVH Value1;\n    WeakVH Value2;\n    unsigned Score;\n    bool isValid() const { return Value1 && Value2; }\n  };\n  DenseMap<std::pair<Value *, Value *>, PairMapValue> PairMap[NumBinaryOps];\n\n  bool MadeChange;\n\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n\nprivate:\n  void BuildRankMap(Function &F, ReversePostOrderTraversal<Function *> &RPOT);\n  unsigned getRank(Value *V);\n  void canonicalizeOperands(Instruction *I);\n  void ReassociateExpression(BinaryOperator *I);\n  void RewriteExprTree(BinaryOperator *I,\n                       SmallVectorImpl<reassociate::ValueEntry> &Ops);\n  Value *OptimizeExpression(BinaryOperator *I,\n                            SmallVectorImpl<reassociate::ValueEntry> &Ops);\n  Value *OptimizeAdd(Instruction *I,\n                     SmallVectorImpl<reassociate::ValueEntry> &Ops);\n  Value *OptimizeXor(Instruction *I,\n                     SmallVectorImpl<reassociate::ValueEntry> &Ops);\n  bool CombineXorOpnd(Instruction *I, reassociate::XorOpnd *Opnd1,\n                      APInt &ConstOpnd, Value *&Res);\n  bool CombineXorOpnd(Instruction *I, reassociate::XorOpnd *Opnd1,\n                      reassociate::XorOpnd *Opnd2, APInt &ConstOpnd,\n                      Value *&Res);\n  Value *buildMinimalMultiplyDAG(IRBuilderBase &Builder,\n                                 SmallVectorImpl<reassociate::Factor> &Factors);\n  Value *OptimizeMul(BinaryOperator *I,\n                     SmallVectorImpl<reassociate::ValueEntry> &Ops);\n  Value *RemoveFactorFromExpression(Value *V, Value *Factor);\n  void EraseInst(Instruction *I);\n  void RecursivelyEraseDeadInsts(Instruction *I, OrderedSet &Insts);\n  void OptimizeInst(Instruction *I);\n  Instruction *canonicalizeNegFPConstantsForOp(Instruction *I, Instruction *Op,\n                                               Value *OtherOp);\n  Instruction *canonicalizeNegFPConstants(Instruction *I);\n  void BuildPairMap(ReversePostOrderTraversal<Function *> &RPOT);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_REASSOCIATE_H\n"}, "191": {"id": 191, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Reg2Mem.h", "content": "//===- Reg2Mem.h - Convert registers to allocas -----------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides the interface for the RegToMem Pass.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_REG2MEM_H\n#define LLVM_TRANSFORMS_SCALAR_REG2MEM_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass RegToMemPass : public PassInfoMixin<RegToMemPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_REG2MEM_H\n"}, "192": {"id": 192, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/RewriteStatepointsForGC.h", "content": "//===- RewriteStatepointsForGC.h - ------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file provides interface to \"Rewrite Statepoints for GC\" pass.\n//\n// This passe rewrites call/invoke instructions so as to make potential\n// relocations performed by the garbage collector explicit in the IR.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_REWRITESTATEPOINTSFORGC_H\n#define LLVM_TRANSFORMS_SCALAR_REWRITESTATEPOINTSFORGC_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass DominatorTree;\nclass Function;\nclass Module;\nclass TargetTransformInfo;\nclass TargetLibraryInfo;\n\nstruct RewriteStatepointsForGC : public PassInfoMixin<RewriteStatepointsForGC> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n\n  bool runOnFunction(Function &F, DominatorTree &, TargetTransformInfo &,\n                     const TargetLibraryInfo &);\n};\n\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_REWRITESTATEPOINTSFORGC_H\n"}, "193": {"id": 193, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SCCP.h", "content": "//===- SCCP.cpp - Sparse Conditional Constant Propagation -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// \\file\n// This file implements sparse conditional constant propagation and merging:\n//\n// Specifically, this:\n//   * Assumes values are constant unless proven otherwise\n//   * Assumes BasicBlocks are dead unless proven otherwise\n//   * Proves values to be constant, and replaces them with constants\n//   * Proves conditional branches to be unconditional\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_SCCP_H\n#define LLVM_TRANSFORMS_SCALAR_SCCP_H\n\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/Analysis/TargetLibraryInfo.h\"\n#include \"llvm/IR/DataLayout.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Utils/PredicateInfo.h\"\n\nnamespace llvm {\n\nclass PostDominatorTree;\n\n/// This pass performs function-level constant propagation and merging.\nclass SCCPPass : public PassInfoMixin<SCCPPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Helper struct for bundling up the analysis results per function for IPSCCP.\nstruct AnalysisResultsForFn {\n  std::unique_ptr<PredicateInfo> PredInfo;\n  DominatorTree *DT;\n  PostDominatorTree *PDT;\n};\n\nbool runIPSCCP(Module &M, const DataLayout &DL,\n               std::function<const TargetLibraryInfo &(Function &)> GetTLI,\n               function_ref<AnalysisResultsForFn(Function &)> getAnalysis);\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_SCCP_H\n"}, "195": {"id": 195, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Scalarizer.h", "content": "//===- Scalarizer.h --- Scalarize vector operations -----------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// This pass converts vector operations into scalar operations, in order\n/// to expose optimization opportunities on the individual scalar operations.\n/// It is mainly intended for targets that do not have vector units, but it\n/// may also be useful for revectorizing code to different vector widths.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_SCALARIZER_H\n#define LLVM_TRANSFORMS_SCALAR_SCALARIZER_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass ScalarizerPass : public PassInfoMixin<ScalarizerPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Create a legacy pass manager instance of the Scalarizer pass\nFunctionPass *createScalarizerPass();\n\n}\n\n#endif /* LLVM_TRANSFORMS_SCALAR_SCALARIZER_H */\n"}, "196": {"id": 196, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SimpleLoopUnswitch.h", "content": "//===- SimpleLoopUnswitch.h - Hoist loop-invariant control flow -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_SIMPLELOOPUNSWITCH_H\n#define LLVM_TRANSFORMS_SCALAR_SIMPLELOOPUNSWITCH_H\n\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n\nnamespace llvm {\n\n/// This pass transforms loops that contain branches or switches on loop-\n/// invariant conditions to have multiple loops. For example, it turns the left\n/// into the right code:\n///\n///  for (...)                  if (lic)\n///    A                          for (...)\n///    if (lic)                     A; B; C\n///      B                      else\n///    C                          for (...)\n///                                 A; C\n///\n/// This can increase the size of the code exponentially (doubling it every time\n/// a loop is unswitched) so we only unswitch if the resultant code will be\n/// smaller than a threshold.\n///\n/// This pass expects LICM to be run before it to hoist invariant conditions out\n/// of the loop, to make the unswitching opportunity obvious.\n///\n/// There is a taxonomy of unswitching that we use to classify different forms\n/// of this transformaiton:\n///\n/// - Trival unswitching: this is when the condition can be unswitched without\n///   cloning any code from inside the loop. A non-trivial unswitch requires\n///   code duplication.\n///\n/// - Full unswitching: this is when the branch or switch is completely moved\n///   from inside the loop to outside the loop. Partial unswitching removes the\n///   branch from the clone of the loop but must leave a (somewhat simplified)\n///   branch in the original loop. While theoretically partial unswitching can\n///   be done for switches, the requirements are extreme - we need the loop\n///   invariant input to the switch to be sufficient to collapse to a single\n///   successor in each clone.\n///\n/// This pass always does trivial, full unswitching for both branches and\n/// switches. For branches, it also always does trivial, partial unswitching.\n///\n/// If enabled (via the constructor's `NonTrivial` parameter), this pass will\n/// additionally do non-trivial, full unswitching for branches and switches, and\n/// will do non-trivial, partial unswitching for branches.\n///\n/// Because partial unswitching of switches is extremely unlikely to be possible\n/// in practice and significantly complicates the implementation, this pass does\n/// not currently implement that in any mode.\nclass SimpleLoopUnswitchPass : public PassInfoMixin<SimpleLoopUnswitchPass> {\n  bool NonTrivial;\n\npublic:\n  SimpleLoopUnswitchPass(bool NonTrivial = false) : NonTrivial(NonTrivial) {}\n\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n/// Create the legacy pass object for the simple loop unswitcher.\n///\n/// See the documentaion for `SimpleLoopUnswitchPass` for details.\nPass *createSimpleLoopUnswitchLegacyPass(bool NonTrivial = false);\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_SIMPLELOOPUNSWITCH_H\n"}, "197": {"id": 197, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SimplifyCFG.h", "content": "//===- SimplifyCFG.h - Simplify and canonicalize the CFG --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n/// This file provides the interface for the pass responsible for both\n/// simplifying and canonicalizing the CFG.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_SIMPLIFYCFG_H\n#define LLVM_TRANSFORMS_SCALAR_SIMPLIFYCFG_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Utils/SimplifyCFGOptions.h\"\n\nnamespace llvm {\n\n/// A pass to simplify and canonicalize the CFG of a function.\n///\n/// This pass iteratively simplifies the entire CFG of a function. It may change\n/// or remove control flow to put the CFG into a canonical form expected by\n/// other passes of the mid-level optimizer. Depending on the specified options,\n/// it may further optimize control-flow to create non-canonical forms.\nclass SimplifyCFGPass : public PassInfoMixin<SimplifyCFGPass> {\n  SimplifyCFGOptions Options;\n\npublic:\n  /// The default constructor sets the pass options to create canonical IR,\n  /// rather than optimal IR. That is, by default we bypass transformations that\n  /// are likely to improve performance but make analysis for other passes more\n  /// difficult.\n  SimplifyCFGPass();\n\n  /// Construct a pass with optional optimizations.\n  SimplifyCFGPass(const SimplifyCFGOptions &PassOptions);\n\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n}\n\n#endif\n"}, "198": {"id": 198, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Sink.h", "content": "//===-- Sink.h - Code Sinking -----------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass moves instructions into successor blocks, when possible, so that\n// they aren't executed on paths where their results aren't needed.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_SINK_H\n#define LLVM_TRANSFORMS_SCALAR_SINK_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// Move instructions into successor blocks when possible.\nclass SinkingPass : public PassInfoMixin<SinkingPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_SINK_H\n"}, "199": {"id": 199, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SpeculateAroundPHIs.h", "content": "//===- SpeculateAroundPHIs.h - Speculate around PHIs ------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_SPECULATEAROUNDPHIS_H\n#define LLVM_TRANSFORMS_SCALAR_SPECULATEAROUNDPHIS_H\n\n#include \"llvm/ADT/SetVector.h\"\n#include \"llvm/Analysis/AssumptionCache.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/Compiler.h\"\n#include <vector>\n\nnamespace llvm {\n\n/// This pass handles simple speculating of  instructions around PHIs when\n/// doing so is profitable for a particular target despite duplicated\n/// instructions.\n///\n/// The motivating example are PHIs of constants which will require\n/// materializing the constants along each edge. If the PHI is used by an\n/// instruction where the target can materialize the constant as part of the\n/// instruction, it is profitable to speculate those instructions around the\n/// PHI node. This can reduce dynamic instruction count as well as decrease\n/// register pressure.\n///\n/// Consider this IR for example:\n///   ```\n///   entry:\n///     br i1 %flag, label %a, label %b\n///\n///   a:\n///     br label %exit\n///\n///   b:\n///     br label %exit\n///\n///   exit:\n///     %p = phi i32 [ 7, %a ], [ 11, %b ]\n///     %sum = add i32 %arg, %p\n///     ret i32 %sum\n///   ```\n/// To materialize the inputs to this PHI node may require an explicit\n/// instruction. For example, on x86 this would turn into something like\n///   ```\n///     testq %eax, %eax\n///     movl $7, %rNN\n///     jne .L\n///     movl $11, %rNN\n///   .L:\n///     addl %edi, %rNN\n///     movl %rNN, %eax\n///     retq\n///   ```\n/// When these constants can be folded directly into another instruction, it\n/// would be preferable to avoid the potential for register pressure (above we\n/// can easily avoid it, but that isn't always true) and simply duplicate the\n/// instruction using the PHI:\n///   ```\n///   entry:\n///     br i1 %flag, label %a, label %b\n///\n///   a:\n///     %sum.1 = add i32 %arg, 7\n///     br label %exit\n///\n///   b:\n///     %sum.2 = add i32 %arg, 11\n///     br label %exit\n///\n///   exit:\n///     %p = phi i32 [ %sum.1, %a ], [ %sum.2, %b ]\n///     ret i32 %p\n///   ```\n/// Which will generate something like the following on x86:\n///   ```\n///     testq %eax, %eax\n///     addl $7, %edi\n///     jne .L\n///     addl $11, %edi\n///   .L:\n///     movl %edi, %eax\n///     retq\n///   ```\n///\n/// It is important to note that this pass is never intended to handle more\n/// complex cases where speculating around PHIs allows simplifications of the\n/// IR itself or other subsequent optimizations. Those can and should already\n/// be handled before this pass is ever run by a more powerful analysis that\n/// can reason about equivalences and common subexpressions. Classically, those\n/// cases would be handled by a GVN-powered PRE or similar transform. This\n/// pass, in contrast, is *only* interested in cases where despite no\n/// simplifications to the IR itself, speculation is *faster* to execute. The\n/// result of this is that the cost models which are appropriate to consider\n/// here are relatively simple ones around execution and codesize cost, without\n/// any need to consider simplifications or other transformations.\nstruct SpeculateAroundPHIsPass : PassInfoMixin<SpeculateAroundPHIsPass> {\n  /// Run the pass over the function.\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_SPECULATEAROUNDPHIS_H\n"}, "200": {"id": 200, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/StraightLineStrengthReduce.h", "content": "//===- StraightLineStrengthReduce.h - -----------------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_STRAIGHTLINESTRENGTHREDUCE_H\n#define LLVM_TRANSFORMS_SCALAR_STRAIGHTLINESTRENGTHREDUCE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass StraightLineStrengthReducePass\n    : public PassInfoMixin<StraightLineStrengthReducePass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_STRAIGHTLINESTRENGTHREDUCE_H\n"}, "201": {"id": 201, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/StructurizeCFG.h", "content": "//===- StructurizeCFG.h ---------------------------------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_STRUCTURIZECFG_H\n#define LLVM_TRANSFORMS_SCALAR_STRUCTURIZECFG_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct StructurizeCFGPass : PassInfoMixin<StructurizeCFGPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_SCALAR_STRUCTURIZECFG_H\n"}, "202": {"id": 202, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/TailRecursionElimination.h", "content": "//===---- TailRecursionElimination.h ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file transforms calls of the current function (self recursion) followed\n// by a return instruction with a branch to the entry of the function, creating\n// a loop.  This pass also implements the following extensions to the basic\n// algorithm:\n//\n//  1. Trivial instructions between the call and return do not prevent the\n//     transformation from taking place, though currently the analysis cannot\n//     support moving any really useful instructions (only dead ones).\n//  2. This pass transforms functions that are prevented from being tail\n//     recursive by an associative and commutative expression to use an\n//     accumulator variable, thus compiling the typical naive factorial or\n//     'fib' implementation into efficient code.\n//  3. TRE is performed if the function returns void, if the return\n//     returns the result returned by the call, or if the function returns a\n//     run-time constant on all exits from the function.  It is possible, though\n//     unlikely, that the return returns something else (like constant 0), and\n//     can still be TRE'd.  It can be TRE'd if ALL OTHER return instructions in\n//     the function return the exact same value.\n//  4. If it can prove that callees do not access their caller stack frame,\n//     they are marked as eligible for tail call elimination (by the code\n//     generator).\n//\n// There are several improvements that could be made:\n//\n//  1. If the function has any alloca instructions, these instructions will be\n//     moved out of the entry block of the function, causing them to be\n//     evaluated each time through the tail recursion.  Safely keeping allocas\n//     in the entry block requires analysis to proves that the tail-called\n//     function does not read or write the stack object.\n//  2. Tail recursion is only performed if the call immediately precedes the\n//     return instruction.  It's possible that there could be a jump between\n//     the call and the return.\n//  3. There can be intervening operations between the call and the return that\n//     prevent the TRE from occurring.  For example, there could be GEP's and\n//     stores to memory that will not be read or written by the call.  This\n//     requires some substantial analysis (such as with DSA) to prove safe to\n//     move ahead of the call, but doing so could allow many more TREs to be\n//     performed, for example in TreeAdd/TreeAlloc from the treeadd benchmark.\n//  4. The algorithm we use to detect if callees access their caller stack\n//     frames is very primitive.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_SCALAR_TAILRECURSIONELIMINATION_H\n#define LLVM_TRANSFORMS_SCALAR_TAILRECURSIONELIMINATION_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nstruct TailCallElimPass : PassInfoMixin<TailCallElimPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n}\n\n#endif // LLVM_TRANSFORMS_SCALAR_TAILRECURSIONELIMINATION_H\n"}, "203": {"id": 203, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/AddDiscriminators.h", "content": "//===- AddDiscriminators.h --------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass adds DWARF discriminators to the IR. Path discriminators are used\n// to decide what CFG path was taken inside sub-graphs whose instructions share\n// the same line and column number information.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_ADDDISCRIMINATORS_H\n#define LLVM_TRANSFORMS_UTILS_ADDDISCRIMINATORS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass AddDiscriminatorsPass : public PassInfoMixin<AddDiscriminatorsPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_ADDDISCRIMINATORS_H\n"}, "204": {"id": 204, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/AssumeBundleBuilder.h", "content": "//===- AssumeBundleBuilder.h - utils to build assume bundles ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file contain tools to preserve informations. They should be used before\n// performing a transformation that may move and delete instructions as those\n// transformation may destroy or worsen information that can be derived from the\n// IR.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_ASSUMEBUNDLEBUILDER_H\n#define LLVM_TRANSFORMS_UTILS_ASSUMEBUNDLEBUILDER_H\n\n#include \"llvm/Analysis/AssumeBundleQueries.h\"\n#include \"llvm/IR/Attributes.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass IntrinsicInst;\nclass AssumptionCache;\nclass DominatorTree;\n\n/// Build a call to llvm.assume to preserve informations that can be derived\n/// from the given instruction.\n/// If no information derived from \\p I, this call returns null.\n/// The returned instruction is not inserted anywhere.\nIntrinsicInst *buildAssumeFromInst(Instruction *I);\n\n/// Calls BuildAssumeFromInst and if the resulting llvm.assume is valid insert\n/// if before I. This is usually what need to be done to salvage the knowledge\n/// contained in the instruction I.\n/// The AssumptionCache must be provided if it is available or the cache may\n/// become silently be invalid.\n/// The DominatorTree can optionally be provided to enable cross-block\n/// reasoning.\nvoid salvageKnowledge(Instruction *I, AssumptionCache *AC = nullptr,\n                      DominatorTree *DT = nullptr);\n\n/// Build and return a new assume created from the provided knowledge\n/// if the knowledge in the assume is fully redundant this will return nullptr\nIntrinsicInst *buildAssumeFromKnowledge(ArrayRef<RetainedKnowledge> Knowledge,\n                                        Instruction *CtxI,\n                                        AssumptionCache *AC = nullptr,\n                                        DominatorTree *DT = nullptr);\n\n/// This pass attempts to minimize the number of assume without loosing any\n/// information.\nstruct AssumeSimplifyPass : public PassInfoMixin<AssumeSimplifyPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\nFunctionPass *createAssumeSimplifyPass();\n\n/// This pass will try to build an llvm.assume for every instruction in the\n/// function. Its main purpose is testing.\nstruct AssumeBuilderPass : public PassInfoMixin<AssumeBuilderPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// canonicalize the RetainedKnowledge RK. it is assumed that RK is part of\n/// Assume. This will return an empty RetainedKnowledge if the knowledge is\n/// useless.\nRetainedKnowledge simplifyRetainedKnowledge(CallBase *Assume,\n                                            RetainedKnowledge RK,\n                                            AssumptionCache *AC,\n                                            DominatorTree *DT);\n\n} // namespace llvm\n\n#endif\n"}, "205": {"id": 205, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/BreakCriticalEdges.h", "content": "//===- BreakCriticalEdges.h - Critical Edge Elimination Pass --------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// BreakCriticalEdges pass - Break all of the critical edges in the CFG by\n// inserting a dummy basic block.  This pass may be \"required\" by passes that\n// cannot deal with critical edges.  For this usage, the structure type is\n// forward declared.  This pass obviously invalidates the CFG, but can update\n// dominator trees.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_BREAKCRITICALEDGES_H\n#define LLVM_TRANSFORMS_UTILS_BREAKCRITICALEDGES_H\n\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct BreakCriticalEdgesPass : public PassInfoMixin<BreakCriticalEdgesPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // namespace llvm\n#endif // LLVM_TRANSFORMS_UTILS_BREAKCRITICALEDGES_H\n"}, "206": {"id": 206, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/CanonicalizeFreezeInLoops.h", "content": "//==- CanonicalizeFreezeInLoop.h - Canonicalize freezes in a loop-*- C++ -*-==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file canonicalizes freeze instructions in a loop.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_CANONICALIZEFREEZEINLOOPS_H\n#define LLVM_TRANSFORMS_UTILS_CANONICALIZEFREEZEINLOOPS_H\n\n#include \"llvm/Analysis/LoopAnalysisManager.h\"\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nclass LPMUpdater;\n\n/// A pass that canonicalizes freeze instructions in a loop.\nclass CanonicalizeFreezeInLoopsPass\n    : public PassInfoMixin<CanonicalizeFreezeInLoopsPass> {\npublic:\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &AM,\n                        LoopStandardAnalysisResults &AR, LPMUpdater &U);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_CANONICALIZEFREEZEINLOOPS_H\n"}, "207": {"id": 207, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/FixIrreducible.h", "content": "//===- FixIrreducible.h - Convert irreducible control-flow into loops -----===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_FIXIRREDUCIBLE_H\n#define LLVM_TRANSFORMS_UTILS_FIXIRREDUCIBLE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct FixIrreduciblePass : PassInfoMixin<FixIrreduciblePass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_FIXIRREDUCIBLE_H\n"}, "208": {"id": 208, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/HelloWorld.h", "content": "//===-- HelloWorld.h - Example Transformations ------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_HELLOWORLD_H\n#define LLVM_TRANSFORMS_UTILS_HELLOWORLD_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass HelloWorldPass : public PassInfoMixin<HelloWorldPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_HELLOWORLD_H\n"}, "209": {"id": 209, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/InjectTLIMappings.h", "content": "//===- InjectTLIMAppings.h - TLI to VFABI attribute injection  ------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Populates the VFABI attribute with the scalar-to-vector mappings\n// from the TargetLibraryInfo.\n//\n//===----------------------------------------------------------------------===//\n#ifndef LLVM_TRANSFORMS_UTILS_INJECTTLIMAPPINGS_H\n#define LLVM_TRANSFORMS_UTILS_INJECTTLIMAPPINGS_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/InitializePasses.h\"\n\nnamespace llvm {\nclass InjectTLIMappings : public PassInfoMixin<InjectTLIMappings> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n// Legacy pass\nclass InjectTLIMappingsLegacy : public FunctionPass {\npublic:\n  static char ID;\n  InjectTLIMappingsLegacy() : FunctionPass(ID) {\n    initializeInjectTLIMappingsLegacyPass(*PassRegistry::getPassRegistry());\n  }\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n  bool runOnFunction(Function &F) override;\n};\n\n} // End namespace llvm\n#endif // LLVM_TRANSFORMS_UTILS_INJECTTLIMAPPINGS_H\n"}, "210": {"id": 210, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/InstructionNamer.h", "content": "//===- InstructionNamer.h - Give anonymous instructions names -------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_INSTRUCTIONNAMER_H\n#define LLVM_TRANSFORMS_UTILS_INSTRUCTIONNAMER_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct InstructionNamerPass : PassInfoMixin<InstructionNamerPass> {\n  PreservedAnalyses run(Function &, FunctionAnalysisManager &);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_INSTRUCTIONNAMER_H\n"}, "212": {"id": 212, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/LibCallsShrinkWrap.h", "content": "//===- LibCallsShrinkWrap.h - Shrink Wrap Library Calls -------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_LIBCALLSSHRINKWRAP_H\n#define LLVM_TRANSFORMS_UTILS_LIBCALLSSHRINKWRAP_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass LibCallsShrinkWrapPass : public PassInfoMixin<LibCallsShrinkWrapPass> {\npublic:\n  static StringRef name() { return \"LibCallsShrinkWrapPass\"; }\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n};\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_LIBCALLSSHRINKWRAP_H\n"}, "214": {"id": 214, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/LoopVersioning.h", "content": "//===- LoopVersioning.h - Utility to version a loop -------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines a utility class to perform loop versioning.  The versioned\n// loop speculates that otherwise may-aliasing memory accesses don't overlap and\n// emits checks to prove this.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_LOOPVERSIONING_H\n#define LLVM_TRANSFORMS_UTILS_LOOPVERSIONING_H\n\n#include \"llvm/Analysis/ScalarEvolution.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Transforms/Utils/LoopUtils.h\"\n#include \"llvm/Transforms/Utils/ValueMapper.h\"\n\nnamespace llvm {\n\nclass Loop;\nclass LoopAccessInfo;\nclass LoopInfo;\nstruct RuntimeCheckingPtrGroup;\ntypedef std::pair<const RuntimeCheckingPtrGroup *,\n                  const RuntimeCheckingPtrGroup *>\n    RuntimePointerCheck;\n\ntemplate <typename T> class ArrayRef;\n\n/// This class emits a version of the loop where run-time checks ensure\n/// that may-alias pointers can't overlap.\n///\n/// It currently only supports single-exit loops and assumes that the loop\n/// already has a preheader.\nclass LoopVersioning {\npublic:\n  /// Expects LoopAccessInfo, Loop, LoopInfo, DominatorTree as input.\n  /// It uses runtime check provided by the user. If \\p UseLAIChecks is true,\n  /// we will retain the default checks made by LAI. Otherwise, construct an\n  /// object having no checks and we expect the user to add them.\n  LoopVersioning(const LoopAccessInfo &LAI,\n                 ArrayRef<RuntimePointerCheck> Checks, Loop *L, LoopInfo *LI,\n                 DominatorTree *DT, ScalarEvolution *SE);\n\n  /// Performs the CFG manipulation part of versioning the loop including\n  /// the DominatorTree and LoopInfo updates.\n  ///\n  /// The loop that was used to construct the class will be the \"versioned\" loop\n  /// i.e. the loop that will receive control if all the memchecks pass.\n  ///\n  /// This allows the loop transform pass to operate on the same loop regardless\n  /// of whether versioning was necessary or not:\n  ///\n  ///    for each loop L:\n  ///        analyze L\n  ///        if versioning is necessary version L\n  ///        transform L\n  void versionLoop() { versionLoop(findDefsUsedOutsideOfLoop(VersionedLoop)); }\n\n  /// Same but if the client has already precomputed the set of values\n  /// used outside the loop, this API will allows passing that.\n  void versionLoop(const SmallVectorImpl<Instruction *> &DefsUsedOutside);\n\n  /// Returns the versioned loop.  Control flows here if pointers in the\n  /// loop don't alias (i.e. all memchecks passed).  (This loop is actually the\n  /// same as the original loop that we got constructed with.)\n  Loop *getVersionedLoop() { return VersionedLoop; }\n\n  /// Returns the fall-back loop.  Control flows here if pointers in the\n  /// loop may alias (i.e. one of the memchecks failed).\n  Loop *getNonVersionedLoop() { return NonVersionedLoop; }\n\n  /// Annotate memory instructions in the versioned loop with no-alias\n  /// metadata based on the memchecks issued.\n  ///\n  /// This is just wrapper that calls prepareNoAliasMetadata and\n  /// annotateInstWithNoAlias on the instructions of the versioned loop.\n  void annotateLoopWithNoAlias();\n\n  /// Set up the aliasing scopes based on the memchecks.  This needs to\n  /// be called before the first call to annotateInstWithNoAlias.\n  void prepareNoAliasMetadata();\n\n  /// Add the noalias annotations to \\p VersionedInst.\n  ///\n  /// \\p OrigInst is the instruction corresponding to \\p VersionedInst in the\n  /// original loop.  Initialize the aliasing scopes with\n  /// prepareNoAliasMetadata once before this can be called.\n  void annotateInstWithNoAlias(Instruction *VersionedInst,\n                               const Instruction *OrigInst);\n\nprivate:\n  /// Adds the necessary PHI nodes for the versioned loops based on the\n  /// loop-defined values used outside of the loop.\n  ///\n  /// This needs to be called after versionLoop if there are defs in the loop\n  /// that are used outside the loop.\n  void addPHINodes(const SmallVectorImpl<Instruction *> &DefsUsedOutside);\n\n  /// Add the noalias annotations to \\p I.  Initialize the aliasing\n  /// scopes with prepareNoAliasMetadata once before this can be called.\n  void annotateInstWithNoAlias(Instruction *I) {\n    annotateInstWithNoAlias(I, I);\n  }\n\n  /// The original loop.  This becomes the \"versioned\" one.  I.e.,\n  /// control flows here if pointers in the loop don't alias.\n  Loop *VersionedLoop;\n  /// The fall-back loop.  I.e. control flows here if pointers in the\n  /// loop may alias (memchecks failed).\n  Loop *NonVersionedLoop;\n\n  /// This maps the instructions from VersionedLoop to their counterpart\n  /// in NonVersionedLoop.\n  ValueToValueMapTy VMap;\n\n  /// The set of alias checks that we are versioning for.\n  SmallVector<RuntimePointerCheck, 4> AliasChecks;\n\n  /// The set of SCEV checks that we are versioning for.\n  const SCEVUnionPredicate &Preds;\n\n  /// Maps a pointer to the pointer checking group that the pointer\n  /// belongs to.\n  DenseMap<const Value *, const RuntimeCheckingPtrGroup *> PtrToGroup;\n\n  /// The alias scope corresponding to a pointer checking group.\n  DenseMap<const RuntimeCheckingPtrGroup *, MDNode *> GroupToScope;\n\n  /// The list of alias scopes that a pointer checking group can't alias.\n  DenseMap<const RuntimeCheckingPtrGroup *, MDNode *>\n      GroupToNonAliasingScopeList;\n\n  /// Analyses used.\n  const LoopAccessInfo &LAI;\n  LoopInfo *LI;\n  DominatorTree *DT;\n  ScalarEvolution *SE;\n};\n\n/// Expose LoopVersioning as a pass.  Currently this is only used for\n/// unit-testing.  It adds all memchecks necessary to remove all may-aliasing\n/// array accesses from the loop.\nclass LoopVersioningPass : public PassInfoMixin<LoopVersioningPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &FAM);\n};\n}\n\n#endif\n"}, "216": {"id": 216, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/LowerSwitch.h", "content": "//===- LowerSwitch.h - Eliminate Switch instructions ----------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// The LowerSwitch transformation rewrites switch instructions with a sequence\n// of branches, which allows targets to get away with not implementing the\n// switch instruction until it is convenient.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_LOWERSWITCH_H\n#define LLVM_TRANSFORMS_UTILS_LOWERSWITCH_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct LowerSwitchPass : public PassInfoMixin<LowerSwitchPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_LOWERSWITCH_H\n"}, "217": {"id": 217, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/Mem2Reg.h", "content": "//===- Mem2Reg.h - The -mem2reg pass, a wrapper around the Utils lib ------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass is a simple pass wrapper around the PromoteMemToReg function call\n// exposed by the Utils library.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_MEM2REG_H\n#define LLVM_TRANSFORMS_UTILS_MEM2REG_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass PromotePass : public PassInfoMixin<PromotePass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_MEM2REG_H\n"}, "218": {"id": 218, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/MetaRenamer.h", "content": "//===- MetaRenamer.h - Rename everything with metasyntatic names ----------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass renames everything with metasyntatic names. The intent is to use\n// this pass after bugpoint reduction to conceal the nature of the original\n// program.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_METARENAMER_H\n#define LLVM_TRANSFORMS_UTILS_METARENAMER_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\nstruct MetaRenamerPass : PassInfoMixin<MetaRenamerPass> {\n  PreservedAnalyses run(Module &, ModuleAnalysisManager &);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_METARENAMER_H\n"}, "219": {"id": 219, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/PredicateInfo.h", "content": "//===- PredicateInfo.h - Build PredicateInfo ----------------------*-C++-*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n///  This file implements the PredicateInfo analysis, which creates an Extended\n/// SSA form for operations used in branch comparisons and llvm.assume\n/// comparisons.\n///\n/// Copies of these operations are inserted into the true/false edge (and after\n/// assumes), and information attached to the copies.  All uses of the original\n/// operation in blocks dominated by the true/false edge (and assume), are\n/// replaced with uses of the copies.  This enables passes to easily and sparsely\n/// propagate condition based info into the operations that may be affected.\n///\n/// Example:\n/// %cmp = icmp eq i32 %x, 50\n/// br i1 %cmp, label %true, label %false\n/// true:\n/// ret i32 %x\n/// false:\n/// ret i32 1\n///\n/// will become\n///\n/// %cmp = icmp eq i32, %x, 50\n/// br i1 %cmp, label %true, label %false\n/// true:\n/// %x.0 = call \\@llvm.ssa_copy.i32(i32 %x)\n/// ret i32 %x.0\n/// false:\n/// ret i32 1\n///\n/// Using getPredicateInfoFor on x.0 will give you the comparison it is\n/// dominated by (the icmp), and that you are located in the true edge of that\n/// comparison, which tells you x.0 is 50.\n///\n/// In order to reduce the number of copies inserted, predicateinfo is only\n/// inserted where it would actually be live.  This means if there are no uses of\n/// an operation dominated by the branch edges, or by an assume, the associated\n/// predicate info is never inserted.\n///\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_PREDICATEINFO_H\n#define LLVM_TRANSFORMS_UTILS_PREDICATEINFO_H\n\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/SmallSet.h\"\n#include \"llvm/ADT/ilist.h\"\n#include \"llvm/ADT/ilist_node.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass AssumptionCache;\nclass DominatorTree;\nclass Function;\nclass IntrinsicInst;\nclass raw_ostream;\n\nenum PredicateType { PT_Branch, PT_Assume, PT_Switch };\n\n/// Constraint for a predicate of the form \"cmp Pred Op, OtherOp\", where Op\n/// is the value the constraint applies to (the ssa.copy result).\nstruct PredicateConstraint {\n  CmpInst::Predicate Predicate;\n  Value *OtherOp;\n};\n\n// Base class for all predicate information we provide.\n// All of our predicate information has at least a comparison.\nclass PredicateBase : public ilist_node<PredicateBase> {\npublic:\n  PredicateType Type;\n  // The original operand before we renamed it.\n  // This can be use by passes, when destroying predicateinfo, to know\n  // whether they can just drop the intrinsic, or have to merge metadata.\n  Value *OriginalOp;\n  // The renamed operand in the condition used for this predicate. For nested\n  // predicates, this is different to OriginalOp which refers to the initial\n  // operand.\n  Value *RenamedOp;\n  // The condition associated with this predicate.\n  Value *Condition;\n\n  PredicateBase(const PredicateBase &) = delete;\n  PredicateBase &operator=(const PredicateBase &) = delete;\n  PredicateBase() = delete;\n  virtual ~PredicateBase() = default;\n  static bool classof(const PredicateBase *PB) {\n    return PB->Type == PT_Assume || PB->Type == PT_Branch ||\n           PB->Type == PT_Switch;\n  }\n\n  /// Fetch condition in the form of PredicateConstraint, if possible.\n  Optional<PredicateConstraint> getConstraint() const;\n\nprotected:\n  PredicateBase(PredicateType PT, Value *Op, Value *Condition)\n      : Type(PT), OriginalOp(Op), Condition(Condition) {}\n};\n\n// Provides predicate information for assumes.  Since assumes are always true,\n// we simply provide the assume instruction, so you can tell your relative\n// position to it.\nclass PredicateAssume : public PredicateBase {\npublic:\n  IntrinsicInst *AssumeInst;\n  PredicateAssume(Value *Op, IntrinsicInst *AssumeInst, Value *Condition)\n      : PredicateBase(PT_Assume, Op, Condition), AssumeInst(AssumeInst) {}\n  PredicateAssume() = delete;\n  static bool classof(const PredicateBase *PB) {\n    return PB->Type == PT_Assume;\n  }\n};\n\n// Mixin class for edge predicates.  The FROM block is the block where the\n// predicate originates, and the TO block is the block where the predicate is\n// valid.\nclass PredicateWithEdge : public PredicateBase {\npublic:\n  BasicBlock *From;\n  BasicBlock *To;\n  PredicateWithEdge() = delete;\n  static bool classof(const PredicateBase *PB) {\n    return PB->Type == PT_Branch || PB->Type == PT_Switch;\n  }\n\nprotected:\n  PredicateWithEdge(PredicateType PType, Value *Op, BasicBlock *From,\n                    BasicBlock *To, Value *Cond)\n      : PredicateBase(PType, Op, Cond), From(From), To(To) {}\n};\n\n// Provides predicate information for branches.\nclass PredicateBranch : public PredicateWithEdge {\npublic:\n  // If true, SplitBB is the true successor, otherwise it's the false successor.\n  bool TrueEdge;\n  PredicateBranch(Value *Op, BasicBlock *BranchBB, BasicBlock *SplitBB,\n                  Value *Condition, bool TakenEdge)\n      : PredicateWithEdge(PT_Branch, Op, BranchBB, SplitBB, Condition),\n        TrueEdge(TakenEdge) {}\n  PredicateBranch() = delete;\n  static bool classof(const PredicateBase *PB) {\n    return PB->Type == PT_Branch;\n  }\n};\n\nclass PredicateSwitch : public PredicateWithEdge {\npublic:\n  Value *CaseValue;\n  // This is the switch instruction.\n  SwitchInst *Switch;\n  PredicateSwitch(Value *Op, BasicBlock *SwitchBB, BasicBlock *TargetBB,\n                  Value *CaseValue, SwitchInst *SI)\n      : PredicateWithEdge(PT_Switch, Op, SwitchBB, TargetBB,\n                          SI->getCondition()),\n        CaseValue(CaseValue), Switch(SI) {}\n  PredicateSwitch() = delete;\n  static bool classof(const PredicateBase *PB) {\n    return PB->Type == PT_Switch;\n  }\n};\n\n/// Encapsulates PredicateInfo, including all data associated with memory\n/// accesses.\nclass PredicateInfo {\npublic:\n  PredicateInfo(Function &, DominatorTree &, AssumptionCache &);\n  ~PredicateInfo();\n\n  void verifyPredicateInfo() const;\n\n  void dump() const;\n  void print(raw_ostream &) const;\n\n  const PredicateBase *getPredicateInfoFor(const Value *V) const {\n    return PredicateMap.lookup(V);\n  }\n\nprotected:\n  // Used by PredicateInfo annotater, dumpers, and wrapper pass.\n  friend class PredicateInfoAnnotatedWriter;\n  friend class PredicateInfoPrinterLegacyPass;\n  friend class PredicateInfoBuilder;\n\nprivate:\n  Function &F;\n\n  // This owns the all the predicate infos in the function, placed or not.\n  iplist<PredicateBase> AllInfos;\n\n  // This maps from copy operands to Predicate Info. Note that it does not own\n  // the Predicate Info, they belong to the ValueInfo structs in the ValueInfos\n  // vector.\n  DenseMap<const Value *, const PredicateBase *> PredicateMap;\n  // The set of ssa_copy declarations we created with our custom mangling.\n  SmallSet<AssertingVH<Function>, 20> CreatedDeclarations;\n};\n\n// This pass does eager building and then printing of PredicateInfo. It is used\n// by\n// the tests to be able to build, dump, and verify PredicateInfo.\nclass PredicateInfoPrinterLegacyPass : public FunctionPass {\npublic:\n  PredicateInfoPrinterLegacyPass();\n\n  static char ID;\n  bool runOnFunction(Function &) override;\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n};\n\n/// Printer pass for \\c PredicateInfo.\nclass PredicateInfoPrinterPass\n    : public PassInfoMixin<PredicateInfoPrinterPass> {\n  raw_ostream &OS;\n\npublic:\n  explicit PredicateInfoPrinterPass(raw_ostream &OS) : OS(OS) {}\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Verifier pass for \\c PredicateInfo.\nstruct PredicateInfoVerifierPass : PassInfoMixin<PredicateInfoVerifierPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_PREDICATEINFO_H\n"}, "221": {"id": 221, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/StripGCRelocates.h", "content": "//===- StripGCRelocates.h - -----------------------------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_STRIPGCRELOCATES_H\n#define LLVM_TRANSFORMS_UTILS_STRIPGCRELOCATES_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Function;\n\nclass StripGCRelocates : public PassInfoMixin<StripGCRelocates> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_STRIPGCRELOCATES_H\n"}, "222": {"id": 222, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/StripNonLineTableDebugInfo.h", "content": "//===- StripNonLineTableDebugInfo.h - -------------------------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_STRIPNONLINETABLEDEBUGINFO_H\n#define LLVM_TRANSFORMS_UTILS_STRIPNONLINETABLEDEBUGINFO_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass Module;\n\nclass StripNonLineTableDebugInfoPass\n    : public PassInfoMixin<StripNonLineTableDebugInfoPass> {\npublic:\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_STRIPNONLINETABLEDEBUGINFO_H\n"}, "223": {"id": 223, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/UnifyFunctionExitNodes.h", "content": "//===-- UnifyFunctionExitNodes.h - Ensure fn's have one return --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass is used to ensure that functions have at most one return and one\n// unreachable instruction in them.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_UNIFYFUNCTIONEXITNODES_H\n#define LLVM_TRANSFORMS_UTILS_UNIFYFUNCTIONEXITNODES_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Pass.h\"\n\nnamespace llvm {\n\nclass BasicBlock;\n\nclass UnifyFunctionExitNodesLegacyPass : public FunctionPass {\npublic:\n  static char ID; // Pass identification, replacement for typeid\n  UnifyFunctionExitNodesLegacyPass();\n\n  // We can preserve non-critical-edgeness when we unify function exit nodes\n  void getAnalysisUsage(AnalysisUsage &AU) const override;\n\n  bool runOnFunction(Function &F) override;\n};\n\nPass *createUnifyFunctionExitNodesPass();\n\nclass UnifyFunctionExitNodesPass\n    : public PassInfoMixin<UnifyFunctionExitNodesPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_UNIFYFUNCTIONEXITNODES_H\n"}, "224": {"id": 224, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/UnifyLoopExits.h", "content": "//===- UnifyLoopExits.h - Redirect exiting edges to one block -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_UTILS_UNIFYLOOPEXITS_H\n#define LLVM_TRANSFORMS_UTILS_UNIFYLOOPEXITS_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass UnifyLoopExitsPass : public PassInfoMixin<UnifyLoopExitsPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n} // namespace llvm\n\n#endif // LLVM_TRANSFORMS_UTILS_UNIFYLOOPEXITS_H\n"}, "225": {"id": 225, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/LoadStoreVectorizer.h", "content": "//===- LoadStoreVectorizer.cpp - GPU Load & Store Vectorizer --------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_VECTORIZE_LOADSTOREVECTORIZER_H\n#define LLVM_TRANSFORMS_VECTORIZE_LOADSTOREVECTORIZER_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass LoadStoreVectorizerPass : public PassInfoMixin<LoadStoreVectorizerPass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n};\n\n/// Create a legacy pass manager instance of the LoadStoreVectorizer pass\nPass *createLoadStoreVectorizerPass();\n\n}\n\n#endif /* LLVM_TRANSFORMS_VECTORIZE_LOADSTOREVECTORIZER_H */\n"}, "226": {"id": 226, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/LoopVectorize.h", "content": "//===- LoopVectorize.h ------------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This is the LLVM loop vectorizer. This pass modifies 'vectorizable' loops\n// and generates target-independent LLVM-IR.\n// The vectorizer uses the TargetTransformInfo analysis to estimate the costs\n// of instructions in order to estimate the profitability of vectorization.\n//\n// The loop vectorizer combines consecutive loop iterations into a single\n// 'wide' iteration. After this transformation the index is incremented\n// by the SIMD vector width, and not by one.\n//\n// This pass has three parts:\n// 1. The main loop pass that drives the different parts.\n// 2. LoopVectorizationLegality - A unit that checks for the legality\n//    of the vectorization.\n// 3. InnerLoopVectorizer - A unit that performs the actual\n//    widening of instructions.\n// 4. LoopVectorizationCostModel - A unit that checks for the profitability\n//    of vectorization. It decides on the optimal vector width, which\n//    can be one, if vectorization is not profitable.\n//\n// There is a development effort going on to migrate loop vectorizer to the\n// VPlan infrastructure and to introduce outer loop vectorization support (see\n// docs/Proposal/VectorizationPlan.rst and\n// http://lists.llvm.org/pipermail/llvm-dev/2017-December/119523.html). For this\n// purpose, we temporarily introduced the VPlan-native vectorization path: an\n// alternative vectorization path that is natively implemented on top of the\n// VPlan infrastructure. See EnableVPlanNativePath for enabling.\n//\n//===----------------------------------------------------------------------===//\n//\n// The reduction-variable vectorization is based on the paper:\n//  D. Nuzman and R. Henderson. Multi-platform Auto-vectorization.\n//\n// Variable uniformity checks are inspired by:\n//  Karrenberg, R. and Hack, S. Whole Function Vectorization.\n//\n// The interleaved access vectorization is based on the paper:\n//  Dorit Nuzman, Ira Rosen and Ayal Zaks.  Auto-Vectorization of Interleaved\n//  Data for SIMD\n//\n// Other ideas/concepts are from:\n//  A. Zaks and D. Nuzman. Autovectorization in GCC-two years later.\n//\n//  S. Maleki, Y. Gao, M. Garzaran, T. Wong and D. Padua.  An Evaluation of\n//  Vectorizing Compilers.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_VECTORIZE_LOOPVECTORIZE_H\n#define LLVM_TRANSFORMS_VECTORIZE_LOOPVECTORIZE_H\n\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Support/CommandLine.h\"\n#include <functional>\n\nnamespace llvm {\n\nclass AAResults;\nclass AssumptionCache;\nclass BlockFrequencyInfo;\nclass DemandedBits;\nclass DominatorTree;\nclass Function;\nclass Loop;\nclass LoopAccessInfo;\nclass LoopInfo;\nclass OptimizationRemarkEmitter;\nclass ProfileSummaryInfo;\nclass ScalarEvolution;\nclass TargetLibraryInfo;\nclass TargetTransformInfo;\n\nextern cl::opt<bool> EnableLoopInterleaving;\nextern cl::opt<bool> EnableLoopVectorization;\n\nstruct LoopVectorizeOptions {\n  /// If false, consider all loops for interleaving.\n  /// If true, only loops that explicitly request interleaving are considered.\n  bool InterleaveOnlyWhenForced;\n\n  /// If false, consider all loops for vectorization.\n  /// If true, only loops that explicitly request vectorization are considered.\n  bool VectorizeOnlyWhenForced;\n\n  /// The current defaults when creating the pass with no arguments are:\n  /// EnableLoopInterleaving = true and EnableLoopVectorization = true. This\n  /// means that interleaving default is consistent with the cl::opt flag, while\n  /// vectorization is not.\n  /// FIXME: The default for EnableLoopVectorization in the cl::opt should be\n  /// set to true, and the corresponding change to account for this be made in\n  /// opt.cpp. The initializations below will become:\n  /// InterleaveOnlyWhenForced(!EnableLoopInterleaving)\n  /// VectorizeOnlyWhenForced(!EnableLoopVectorization).\n  LoopVectorizeOptions()\n      : InterleaveOnlyWhenForced(false), VectorizeOnlyWhenForced(false) {}\n  LoopVectorizeOptions(bool InterleaveOnlyWhenForced,\n                       bool VectorizeOnlyWhenForced)\n      : InterleaveOnlyWhenForced(InterleaveOnlyWhenForced),\n        VectorizeOnlyWhenForced(VectorizeOnlyWhenForced) {}\n\n  LoopVectorizeOptions &setInterleaveOnlyWhenForced(bool Value) {\n    InterleaveOnlyWhenForced = Value;\n    return *this;\n  }\n\n  LoopVectorizeOptions &setVectorizeOnlyWhenForced(bool Value) {\n    VectorizeOnlyWhenForced = Value;\n    return *this;\n  }\n};\n\n/// Storage for information about made changes.\nstruct LoopVectorizeResult {\n  bool MadeAnyChange;\n  bool MadeCFGChange;\n\n  LoopVectorizeResult(bool MadeAnyChange, bool MadeCFGChange)\n      : MadeAnyChange(MadeAnyChange), MadeCFGChange(MadeCFGChange) {}\n};\n\n/// The LoopVectorize Pass.\nstruct LoopVectorizePass : public PassInfoMixin<LoopVectorizePass> {\nprivate:\n  /// If false, consider all loops for interleaving.\n  /// If true, only loops that explicitly request interleaving are considered.\n  bool InterleaveOnlyWhenForced;\n\n  /// If false, consider all loops for vectorization.\n  /// If true, only loops that explicitly request vectorization are considered.\n  bool VectorizeOnlyWhenForced;\n\npublic:\n  LoopVectorizePass(LoopVectorizeOptions Opts = {});\n\n  ScalarEvolution *SE;\n  LoopInfo *LI;\n  TargetTransformInfo *TTI;\n  DominatorTree *DT;\n  BlockFrequencyInfo *BFI;\n  TargetLibraryInfo *TLI;\n  DemandedBits *DB;\n  AAResults *AA;\n  AssumptionCache *AC;\n  std::function<const LoopAccessInfo &(Loop &)> *GetLAA;\n  OptimizationRemarkEmitter *ORE;\n  ProfileSummaryInfo *PSI;\n\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n\n  // Shim for old PM.\n  LoopVectorizeResult\n  runImpl(Function &F, ScalarEvolution &SE_, LoopInfo &LI_,\n          TargetTransformInfo &TTI_, DominatorTree &DT_,\n          BlockFrequencyInfo &BFI_, TargetLibraryInfo *TLI_, DemandedBits &DB_,\n          AAResults &AA_, AssumptionCache &AC_,\n          std::function<const LoopAccessInfo &(Loop &)> &GetLAA_,\n          OptimizationRemarkEmitter &ORE_, ProfileSummaryInfo *PSI_);\n\n  bool processLoop(Loop *L);\n};\n\n/// Reports a vectorization failure: print \\p DebugMsg for debugging\n/// purposes along with the corresponding optimization remark \\p RemarkName.\n/// If \\p I is passed, it is an instruction that prevents vectorization.\n/// Otherwise, the loop \\p TheLoop is used for the location of the remark.\nvoid reportVectorizationFailure(const StringRef DebugMsg,\n    const StringRef OREMsg, const StringRef ORETag,\n    OptimizationRemarkEmitter *ORE, Loop *TheLoop, Instruction *I = nullptr);\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_VECTORIZE_LOOPVECTORIZE_H\n"}, "227": {"id": 227, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/SLPVectorizer.h", "content": "//===- SLPVectorizer.h ------------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n// This pass implements the Bottom Up SLP vectorizer. It detects consecutive\n// stores that can be put together into vector-stores. Next, it attempts to\n// construct vectorizable tree using the use-def chains. If a profitable tree\n// was found, the SLP vectorizer performs vectorization on the tree.\n//\n// The pass is inspired by the work described in the paper:\n//  \"Loop-Aware SLP in GCC\" by Ira Rosen, Dorit Nuzman, Ayal Zaks.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_VECTORIZE_SLPVECTORIZER_H\n#define LLVM_TRANSFORMS_VECTORIZE_SLPVECTORIZER_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\nclass AAResults;\nclass AssumptionCache;\nclass BasicBlock;\nclass CmpInst;\nclass DataLayout;\nclass DemandedBits;\nclass DominatorTree;\nclass Function;\nclass GetElementPtrInst;\nclass InsertElementInst;\nclass InsertValueInst;\nclass Instruction;\nclass LoopInfo;\nclass OptimizationRemarkEmitter;\nclass PHINode;\nclass ScalarEvolution;\nclass StoreInst;\nclass TargetLibraryInfo;\nclass TargetTransformInfo;\nclass Value;\n\n/// A private \"module\" namespace for types and utilities used by this pass.\n/// These are implementation details and should not be used by clients.\nnamespace slpvectorizer {\n\nclass BoUpSLP;\n\n} // end namespace slpvectorizer\n\nstruct SLPVectorizerPass : public PassInfoMixin<SLPVectorizerPass> {\n  using StoreList = SmallVector<StoreInst *, 8>;\n  using StoreListMap = MapVector<Value *, StoreList>;\n  using GEPList = SmallVector<GetElementPtrInst *, 8>;\n  using GEPListMap = MapVector<Value *, GEPList>;\n\n  ScalarEvolution *SE = nullptr;\n  TargetTransformInfo *TTI = nullptr;\n  TargetLibraryInfo *TLI = nullptr;\n  AAResults *AA = nullptr;\n  LoopInfo *LI = nullptr;\n  DominatorTree *DT = nullptr;\n  AssumptionCache *AC = nullptr;\n  DemandedBits *DB = nullptr;\n  const DataLayout *DL = nullptr;\n\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);\n\n  // Glue for old PM.\n  bool runImpl(Function &F, ScalarEvolution *SE_, TargetTransformInfo *TTI_,\n               TargetLibraryInfo *TLI_, AAResults *AA_, LoopInfo *LI_,\n               DominatorTree *DT_, AssumptionCache *AC_, DemandedBits *DB_,\n               OptimizationRemarkEmitter *ORE_);\n\nprivate:\n  /// Collect store and getelementptr instructions and organize them\n  /// according to the underlying object of their pointer operands. We sort the\n  /// instructions by their underlying objects to reduce the cost of\n  /// consecutive access queries.\n  ///\n  /// TODO: We can further reduce this cost if we flush the chain creation\n  ///       every time we run into a memory barrier.\n  void collectSeedInstructions(BasicBlock *BB);\n\n  /// Try to vectorize a chain that starts at two arithmetic instrs.\n  bool tryToVectorizePair(Value *A, Value *B, slpvectorizer::BoUpSLP &R);\n\n  /// Try to vectorize a list of operands.\n  /// When \\p InsertUses is provided and its entries are non-zero\n  /// then users of \\p VL are known to be InsertElement instructions\n  /// each associated with same VL entry index. Their cost is then\n  /// used to adjust cost of the vectorization assuming instcombine pass\n  /// then optimizes ExtractElement-InsertElement sequence.\n  /// \\returns true if a value was vectorized.\n  bool tryToVectorizeList(ArrayRef<Value *> VL, slpvectorizer::BoUpSLP &R,\n                          bool AllowReorder = false,\n                          ArrayRef<Value *> InsertUses = None);\n\n  /// Try to vectorize a chain that may start at the operands of \\p I.\n  bool tryToVectorize(Instruction *I, slpvectorizer::BoUpSLP &R);\n\n  /// Vectorize the store instructions collected in Stores.\n  bool vectorizeStoreChains(slpvectorizer::BoUpSLP &R);\n\n  /// Vectorize the index computations of the getelementptr instructions\n  /// collected in GEPs.\n  bool vectorizeGEPIndices(BasicBlock *BB, slpvectorizer::BoUpSLP &R);\n\n  /// Try to find horizontal reduction or otherwise vectorize a chain of binary\n  /// operators.\n  bool vectorizeRootInstruction(PHINode *P, Value *V, BasicBlock *BB,\n                                slpvectorizer::BoUpSLP &R,\n                                TargetTransformInfo *TTI);\n\n  /// Try to vectorize trees that start at insertvalue instructions.\n  bool vectorizeInsertValueInst(InsertValueInst *IVI, BasicBlock *BB,\n                                slpvectorizer::BoUpSLP &R);\n\n  /// Try to vectorize trees that start at insertelement instructions.\n  bool vectorizeInsertElementInst(InsertElementInst *IEI, BasicBlock *BB,\n                                  slpvectorizer::BoUpSLP &R);\n\n  /// Try to vectorize trees that start at compare instructions.\n  bool vectorizeCmpInst(CmpInst *CI, BasicBlock *BB, slpvectorizer::BoUpSLP &R);\n\n  /// Tries to vectorize constructs started from CmpInst, InsertValueInst or\n  /// InsertElementInst instructions.\n  bool vectorizeSimpleInstructions(SmallVectorImpl<Instruction *> &Instructions,\n                                   BasicBlock *BB, slpvectorizer::BoUpSLP &R);\n\n  /// Scan the basic block and look for patterns that are likely to start\n  /// a vectorization chain.\n  bool vectorizeChainsInBlock(BasicBlock *BB, slpvectorizer::BoUpSLP &R);\n\n  bool vectorizeStoreChain(ArrayRef<Value *> Chain, slpvectorizer::BoUpSLP &R,\n                           unsigned Idx);\n\n  bool vectorizeStores(ArrayRef<StoreInst *> Stores, slpvectorizer::BoUpSLP &R);\n\n  /// The store instructions in a basic block organized by base pointer.\n  StoreListMap Stores;\n\n  /// The getelementptr instructions in a basic block organized by base pointer.\n  GEPListMap GEPs;\n};\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_VECTORIZE_SLPVECTORIZER_H\n"}, "228": {"id": 228, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/VectorCombine.h", "content": "//===-------- VectorCombine.h - Optimize partial vector operations --------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This pass optimizes scalar/vector interactions using target cost models. The\n// transforms implemented here may not fit in traditional loop-based or SLP\n// vectorization passes.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_TRANSFORMS_VECTORIZE_VECTORCOMBINE_H\n#define LLVM_TRANSFORMS_VECTORIZE_VECTORCOMBINE_H\n\n#include \"llvm/IR/PassManager.h\"\n\nnamespace llvm {\n\n/// Optimize scalar/vector interactions in IR using target cost models.\nstruct VectorCombinePass : public PassInfoMixin<VectorCombinePass> {\npublic:\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &);\n};\n\n}\n#endif // LLVM_TRANSFORMS_VECTORIZE_VECTORCOMBINE_H\n"}, "229": {"id": 229, "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "content": "//===- Parsing, selection, and construction of pass pipelines -------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n/// \\file\n///\n/// This file provides the implementation of the PassBuilder based on our\n/// static pass registry as well as related functionality. It also provides\n/// helpers to aid in analyzing, debugging, and testing passes and pass\n/// pipelines.\n///\n//===----------------------------------------------------------------------===//\n\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/ADT/StringSwitch.h\"\n#include \"llvm/Analysis/AliasAnalysisEvaluator.h\"\n#include \"llvm/Analysis/AliasSetTracker.h\"\n#include \"llvm/Analysis/AssumptionCache.h\"\n#include \"llvm/Analysis/BasicAliasAnalysis.h\"\n#include \"llvm/Analysis/BlockFrequencyInfo.h\"\n#include \"llvm/Analysis/BranchProbabilityInfo.h\"\n#include \"llvm/Analysis/CFGPrinter.h\"\n#include \"llvm/Analysis/CFLAndersAliasAnalysis.h\"\n#include \"llvm/Analysis/CFLSteensAliasAnalysis.h\"\n#include \"llvm/Analysis/CGSCCPassManager.h\"\n#include \"llvm/Analysis/CallGraph.h\"\n#include \"llvm/Analysis/DDG.h\"\n#include \"llvm/Analysis/DDGPrinter.h\"\n#include \"llvm/Analysis/Delinearization.h\"\n#include \"llvm/Analysis/DemandedBits.h\"\n#include \"llvm/Analysis/DependenceAnalysis.h\"\n#include \"llvm/Analysis/DivergenceAnalysis.h\"\n#include \"llvm/Analysis/DominanceFrontier.h\"\n#include \"llvm/Analysis/FunctionPropertiesAnalysis.h\"\n#include \"llvm/Analysis/GlobalsModRef.h\"\n#include \"llvm/Analysis/IRSimilarityIdentifier.h\"\n#include \"llvm/Analysis/IVUsers.h\"\n#include \"llvm/Analysis/InlineAdvisor.h\"\n#include \"llvm/Analysis/InlineSizeEstimatorAnalysis.h\"\n#include \"llvm/Analysis/InstCount.h\"\n#include \"llvm/Analysis/LazyCallGraph.h\"\n#include \"llvm/Analysis/LazyValueInfo.h\"\n#include \"llvm/Analysis/Lint.h\"\n#include \"llvm/Analysis/LoopAccessAnalysis.h\"\n#include \"llvm/Analysis/LoopCacheAnalysis.h\"\n#include \"llvm/Analysis/LoopInfo.h\"\n#include \"llvm/Analysis/LoopNestAnalysis.h\"\n#include \"llvm/Analysis/MemDerefPrinter.h\"\n#include \"llvm/Analysis/MemoryDependenceAnalysis.h\"\n#include \"llvm/Analysis/MemorySSA.h\"\n#include \"llvm/Analysis/ModuleDebugInfoPrinter.h\"\n#include \"llvm/Analysis/ModuleSummaryAnalysis.h\"\n#include \"llvm/Analysis/MustExecute.h\"\n#include \"llvm/Analysis/ObjCARCAliasAnalysis.h\"\n#include \"llvm/Analysis/OptimizationRemarkEmitter.h\"\n#include \"llvm/Analysis/PhiValues.h\"\n#include \"llvm/Analysis/PostDominators.h\"\n#include \"llvm/Analysis/ProfileSummaryInfo.h\"\n#include \"llvm/Analysis/RegionInfo.h\"\n#include \"llvm/Analysis/ScalarEvolution.h\"\n#include \"llvm/Analysis/ScalarEvolutionAliasAnalysis.h\"\n#include \"llvm/Analysis/ScopedNoAliasAA.h\"\n#include \"llvm/Analysis/StackLifetime.h\"\n#include \"llvm/Analysis/StackSafetyAnalysis.h\"\n#include \"llvm/Analysis/TargetLibraryInfo.h\"\n#include \"llvm/Analysis/TargetTransformInfo.h\"\n#include \"llvm/Analysis/TypeBasedAliasAnalysis.h\"\n#include \"llvm/IR/Dominators.h\"\n#include \"llvm/IR/IRPrintingPasses.h\"\n#include \"llvm/IR/PassManager.h\"\n#include \"llvm/IR/PrintPasses.h\"\n#include \"llvm/IR/SafepointIRVerifier.h\"\n#include \"llvm/IR/Verifier.h\"\n#include \"llvm/Support/CommandLine.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"llvm/Support/FormatVariadic.h\"\n#include \"llvm/Support/Regex.h\"\n#include \"llvm/Target/TargetMachine.h\"\n#include \"llvm/Transforms/AggressiveInstCombine/AggressiveInstCombine.h\"\n#include \"llvm/Transforms/Coroutines/CoroCleanup.h\"\n#include \"llvm/Transforms/Coroutines/CoroEarly.h\"\n#include \"llvm/Transforms/Coroutines/CoroElide.h\"\n#include \"llvm/Transforms/Coroutines/CoroSplit.h\"\n#include \"llvm/Transforms/IPO/AlwaysInliner.h\"\n#include \"llvm/Transforms/IPO/Annotation2Metadata.h\"\n#include \"llvm/Transforms/IPO/ArgumentPromotion.h\"\n#include \"llvm/Transforms/IPO/Attributor.h\"\n#include \"llvm/Transforms/IPO/BlockExtractor.h\"\n#include \"llvm/Transforms/IPO/CalledValuePropagation.h\"\n#include \"llvm/Transforms/IPO/ConstantMerge.h\"\n#include \"llvm/Transforms/IPO/CrossDSOCFI.h\"\n#include \"llvm/Transforms/IPO/DeadArgumentElimination.h\"\n#include \"llvm/Transforms/IPO/ElimAvailExtern.h\"\n#include \"llvm/Transforms/IPO/ForceFunctionAttrs.h\"\n#include \"llvm/Transforms/IPO/FunctionAttrs.h\"\n#include \"llvm/Transforms/IPO/FunctionImport.h\"\n#include \"llvm/Transforms/IPO/GlobalDCE.h\"\n#include \"llvm/Transforms/IPO/GlobalOpt.h\"\n#include \"llvm/Transforms/IPO/GlobalSplit.h\"\n#include \"llvm/Transforms/IPO/HotColdSplitting.h\"\n#include \"llvm/Transforms/IPO/IROutliner.h\"\n#include \"llvm/Transforms/IPO/InferFunctionAttrs.h\"\n#include \"llvm/Transforms/IPO/Inliner.h\"\n#include \"llvm/Transforms/IPO/Internalize.h\"\n#include \"llvm/Transforms/IPO/LoopExtractor.h\"\n#include \"llvm/Transforms/IPO/LowerTypeTests.h\"\n#include \"llvm/Transforms/IPO/MergeFunctions.h\"\n#include \"llvm/Transforms/IPO/OpenMPOpt.h\"\n#include \"llvm/Transforms/IPO/PartialInlining.h\"\n#include \"llvm/Transforms/IPO/SCCP.h\"\n#include \"llvm/Transforms/IPO/SampleProfile.h\"\n#include \"llvm/Transforms/IPO/SampleProfileProbe.h\"\n#include \"llvm/Transforms/IPO/StripDeadPrototypes.h\"\n#include \"llvm/Transforms/IPO/StripSymbols.h\"\n#include \"llvm/Transforms/IPO/SyntheticCountsPropagation.h\"\n#include \"llvm/Transforms/IPO/WholeProgramDevirt.h\"\n#include \"llvm/Transforms/InstCombine/InstCombine.h\"\n#include \"llvm/Transforms/Instrumentation.h\"\n#include \"llvm/Transforms/Instrumentation/AddressSanitizer.h\"\n#include \"llvm/Transforms/Instrumentation/BoundsChecking.h\"\n#include \"llvm/Transforms/Instrumentation/CGProfile.h\"\n#include \"llvm/Transforms/Instrumentation/ControlHeightReduction.h\"\n#include \"llvm/Transforms/Instrumentation/DataFlowSanitizer.h\"\n#include \"llvm/Transforms/Instrumentation/GCOVProfiler.h\"\n#include \"llvm/Transforms/Instrumentation/HWAddressSanitizer.h\"\n#include \"llvm/Transforms/Instrumentation/InstrOrderFile.h\"\n#include \"llvm/Transforms/Instrumentation/InstrProfiling.h\"\n#include \"llvm/Transforms/Instrumentation/MemProfiler.h\"\n#include \"llvm/Transforms/Instrumentation/MemorySanitizer.h\"\n#include \"llvm/Transforms/Instrumentation/PGOInstrumentation.h\"\n#include \"llvm/Transforms/Instrumentation/PoisonChecking.h\"\n#include \"llvm/Transforms/Instrumentation/SanitizerCoverage.h\"\n#include \"llvm/Transforms/Instrumentation/ThreadSanitizer.h\"\n#include \"llvm/Transforms/ObjCARC.h\"\n#include \"llvm/Transforms/Scalar/ADCE.h\"\n#include \"llvm/Transforms/Scalar/AlignmentFromAssumptions.h\"\n#include \"llvm/Transforms/Scalar/AnnotationRemarks.h\"\n#include \"llvm/Transforms/Scalar/BDCE.h\"\n#include \"llvm/Transforms/Scalar/CallSiteSplitting.h\"\n#include \"llvm/Transforms/Scalar/ConstantHoisting.h\"\n#include \"llvm/Transforms/Scalar/ConstraintElimination.h\"\n#include \"llvm/Transforms/Scalar/CorrelatedValuePropagation.h\"\n#include \"llvm/Transforms/Scalar/DCE.h\"\n#include \"llvm/Transforms/Scalar/DeadStoreElimination.h\"\n#include \"llvm/Transforms/Scalar/DivRemPairs.h\"\n#include \"llvm/Transforms/Scalar/EarlyCSE.h\"\n#include \"llvm/Transforms/Scalar/Float2Int.h\"\n#include \"llvm/Transforms/Scalar/GVN.h\"\n#include \"llvm/Transforms/Scalar/GuardWidening.h\"\n#include \"llvm/Transforms/Scalar/IVUsersPrinter.h\"\n#include \"llvm/Transforms/Scalar/IndVarSimplify.h\"\n#include \"llvm/Transforms/Scalar/InductiveRangeCheckElimination.h\"\n#include \"llvm/Transforms/Scalar/InferAddressSpaces.h\"\n#include \"llvm/Transforms/Scalar/InstSimplifyPass.h\"\n#include \"llvm/Transforms/Scalar/JumpThreading.h\"\n#include \"llvm/Transforms/Scalar/LICM.h\"\n#include \"llvm/Transforms/Scalar/LoopAccessAnalysisPrinter.h\"\n#include \"llvm/Transforms/Scalar/LoopDataPrefetch.h\"\n#include \"llvm/Transforms/Scalar/LoopDeletion.h\"\n#include \"llvm/Transforms/Scalar/LoopDistribute.h\"\n#include \"llvm/Transforms/Scalar/LoopFlatten.h\"\n#include \"llvm/Transforms/Scalar/LoopFuse.h\"\n#include \"llvm/Transforms/Scalar/LoopIdiomRecognize.h\"\n#include \"llvm/Transforms/Scalar/LoopInstSimplify.h\"\n#include \"llvm/Transforms/Scalar/LoopInterchange.h\"\n#include \"llvm/Transforms/Scalar/LoopLoadElimination.h\"\n#include \"llvm/Transforms/Scalar/LoopPassManager.h\"\n#include \"llvm/Transforms/Scalar/LoopPredication.h\"\n#include \"llvm/Transforms/Scalar/LoopReroll.h\"\n#include \"llvm/Transforms/Scalar/LoopRotation.h\"\n#include \"llvm/Transforms/Scalar/LoopSimplifyCFG.h\"\n#include \"llvm/Transforms/Scalar/LoopSink.h\"\n#include \"llvm/Transforms/Scalar/LoopStrengthReduce.h\"\n#include \"llvm/Transforms/Scalar/LoopUnrollAndJamPass.h\"\n#include \"llvm/Transforms/Scalar/LoopUnrollPass.h\"\n#include \"llvm/Transforms/Scalar/LoopVersioningLICM.h\"\n#include \"llvm/Transforms/Scalar/LowerAtomic.h\"\n#include \"llvm/Transforms/Scalar/LowerConstantIntrinsics.h\"\n#include \"llvm/Transforms/Scalar/LowerExpectIntrinsic.h\"\n#include \"llvm/Transforms/Scalar/LowerGuardIntrinsic.h\"\n#include \"llvm/Transforms/Scalar/LowerMatrixIntrinsics.h\"\n#include \"llvm/Transforms/Scalar/LowerWidenableCondition.h\"\n#include \"llvm/Transforms/Scalar/MakeGuardsExplicit.h\"\n#include \"llvm/Transforms/Scalar/MemCpyOptimizer.h\"\n#include \"llvm/Transforms/Scalar/MergeICmps.h\"\n#include \"llvm/Transforms/Scalar/MergedLoadStoreMotion.h\"\n#include \"llvm/Transforms/Scalar/NaryReassociate.h\"\n#include \"llvm/Transforms/Scalar/NewGVN.h\"\n#include \"llvm/Transforms/Scalar/PartiallyInlineLibCalls.h\"\n#include \"llvm/Transforms/Scalar/Reassociate.h\"\n#include \"llvm/Transforms/Scalar/Reg2Mem.h\"\n#include \"llvm/Transforms/Scalar/RewriteStatepointsForGC.h\"\n#include \"llvm/Transforms/Scalar/SCCP.h\"\n#include \"llvm/Transforms/Scalar/SROA.h\"\n#include \"llvm/Transforms/Scalar/ScalarizeMaskedMemIntrin.h\"\n#include \"llvm/Transforms/Scalar/Scalarizer.h\"\n#include \"llvm/Transforms/Scalar/SeparateConstOffsetFromGEP.h\"\n#include \"llvm/Transforms/Scalar/SimpleLoopUnswitch.h\"\n#include \"llvm/Transforms/Scalar/SimplifyCFG.h\"\n#include \"llvm/Transforms/Scalar/Sink.h\"\n#include \"llvm/Transforms/Scalar/SpeculateAroundPHIs.h\"\n#include \"llvm/Transforms/Scalar/SpeculativeExecution.h\"\n#include \"llvm/Transforms/Scalar/StraightLineStrengthReduce.h\"\n#include \"llvm/Transforms/Scalar/StructurizeCFG.h\"\n#include \"llvm/Transforms/Scalar/TailRecursionElimination.h\"\n#include \"llvm/Transforms/Scalar/WarnMissedTransforms.h\"\n#include \"llvm/Transforms/Utils/AddDiscriminators.h\"\n#include \"llvm/Transforms/Utils/AssumeBundleBuilder.h\"\n#include \"llvm/Transforms/Utils/BreakCriticalEdges.h\"\n#include \"llvm/Transforms/Utils/CanonicalizeAliases.h\"\n#include \"llvm/Transforms/Utils/CanonicalizeFreezeInLoops.h\"\n#include \"llvm/Transforms/Utils/EntryExitInstrumenter.h\"\n#include \"llvm/Transforms/Utils/FixIrreducible.h\"\n#include \"llvm/Transforms/Utils/HelloWorld.h\"\n#include \"llvm/Transforms/Utils/InjectTLIMappings.h\"\n#include \"llvm/Transforms/Utils/InstructionNamer.h\"\n#include \"llvm/Transforms/Utils/LCSSA.h\"\n#include \"llvm/Transforms/Utils/LibCallsShrinkWrap.h\"\n#include \"llvm/Transforms/Utils/LoopSimplify.h\"\n#include \"llvm/Transforms/Utils/LoopVersioning.h\"\n#include \"llvm/Transforms/Utils/LowerInvoke.h\"\n#include \"llvm/Transforms/Utils/LowerSwitch.h\"\n#include \"llvm/Transforms/Utils/Mem2Reg.h\"\n#include \"llvm/Transforms/Utils/MetaRenamer.h\"\n#include \"llvm/Transforms/Utils/NameAnonGlobals.h\"\n#include \"llvm/Transforms/Utils/StripGCRelocates.h\"\n#include \"llvm/Transforms/Utils/StripNonLineTableDebugInfo.h\"\n#include \"llvm/Transforms/Utils/SymbolRewriter.h\"\n#include \"llvm/Transforms/Utils/UnifyFunctionExitNodes.h\"\n#include \"llvm/Transforms/Utils/UnifyLoopExits.h\"\n#include \"llvm/Transforms/Vectorize/LoadStoreVectorizer.h\"\n#include \"llvm/Transforms/Vectorize/LoopVectorize.h\"\n#include \"llvm/Transforms/Vectorize/SLPVectorizer.h\"\n#include \"llvm/Transforms/Vectorize/VectorCombine.h\"\n\nusing namespace llvm;\n\nextern cl::opt<unsigned> MaxDevirtIterations;\n\nstatic cl::opt<InliningAdvisorMode> UseInlineAdvisor(\n    \"enable-ml-inliner\", cl::init(InliningAdvisorMode::Default), cl::Hidden,\n    cl::desc(\"Enable ML policy for inliner. Currently trained for -Oz only\"),\n    cl::values(clEnumValN(InliningAdvisorMode::Default, \"default\",\n                          \"Heuristics-based inliner version.\"),\n               clEnumValN(InliningAdvisorMode::Development, \"development\",\n                          \"Use development mode (runtime-loadable model).\"),\n               clEnumValN(InliningAdvisorMode::Release, \"release\",\n                          \"Use release mode (AOT-compiled model).\")));\n\nstatic cl::opt<bool> EnableSyntheticCounts(\n    \"enable-npm-synthetic-counts\", cl::init(false), cl::Hidden, cl::ZeroOrMore,\n    cl::desc(\"Run synthetic function entry count generation \"\n             \"pass\"));\n\nstatic const Regex DefaultAliasRegex(\n    \"^(default|thinlto-pre-link|thinlto|lto-pre-link|lto)<(O[0123sz])>$\");\n\n/// Flag to enable inline deferral during PGO.\nstatic cl::opt<bool>\n    EnablePGOInlineDeferral(\"enable-npm-pgo-inline-deferral\", cl::init(true),\n                            cl::Hidden,\n                            cl::desc(\"Enable inline deferral during PGO\"));\n\nstatic cl::opt<bool> EnableMemProfiler(\"enable-mem-prof\", cl::init(false),\n                                       cl::Hidden, cl::ZeroOrMore,\n                                       cl::desc(\"Enable memory profiler\"));\n\nstatic cl::opt<bool> PerformMandatoryInliningsFirst(\n    \"mandatory-inlining-first\", cl::init(true), cl::Hidden, cl::ZeroOrMore,\n    cl::desc(\"Perform mandatory inlinings module-wide, before performing \"\n             \"inlining.\"));\n\nstatic cl::opt<bool> EnableO3NonTrivialUnswitching(\n    \"enable-npm-O3-nontrivial-unswitch\", cl::init(true), cl::Hidden,\n    cl::ZeroOrMore, cl::desc(\"Enable non-trivial loop unswitching for -O3\"));\n\nPipelineTuningOptions::PipelineTuningOptions() {\n  LoopInterleaving = true;\n  LoopVectorization = true;\n  SLPVectorization = false;\n  LoopUnrolling = true;\n  ForgetAllSCEVInLoopUnroll = ForgetSCEVInLoopUnroll;\n  Coroutines = false;\n  LicmMssaOptCap = SetLicmMssaOptCap;\n  LicmMssaNoAccForPromotionCap = SetLicmMssaNoAccForPromotionCap;\n  CallGraphProfile = true;\n  MergeFunctions = false;\n}\nextern cl::opt<bool> ExtraVectorizerPasses;\n\nextern cl::opt<bool> EnableConstraintElimination;\nextern cl::opt<bool> EnableGVNHoist;\nextern cl::opt<bool> EnableGVNSink;\nextern cl::opt<bool> EnableHotColdSplit;\nextern cl::opt<bool> EnableIROutliner;\nextern cl::opt<bool> EnableOrderFileInstrumentation;\nextern cl::opt<bool> EnableCHR;\nextern cl::opt<bool> EnableLoopInterchange;\nextern cl::opt<bool> EnableUnrollAndJam;\nextern cl::opt<bool> EnableLoopFlatten;\nextern cl::opt<bool> RunNewGVN;\nextern cl::opt<bool> RunPartialInlining;\n\nextern cl::opt<bool> FlattenedProfileUsed;\n\nextern cl::opt<AttributorRunOption> AttributorRun;\nextern cl::opt<bool> EnableKnowledgeRetention;\n\nextern cl::opt<bool> EnableMatrix;\n\nextern cl::opt<bool> DisablePreInliner;\nextern cl::opt<int> PreInlineThreshold;\n\nconst PassBuilder::OptimizationLevel PassBuilder::OptimizationLevel::O0 = {\n    /*SpeedLevel*/ 0,\n    /*SizeLevel*/ 0};\nconst PassBuilder::OptimizationLevel PassBuilder::OptimizationLevel::O1 = {\n    /*SpeedLevel*/ 1,\n    /*SizeLevel*/ 0};\nconst PassBuilder::OptimizationLevel PassBuilder::OptimizationLevel::O2 = {\n    /*SpeedLevel*/ 2,\n    /*SizeLevel*/ 0};\nconst PassBuilder::OptimizationLevel PassBuilder::OptimizationLevel::O3 = {\n    /*SpeedLevel*/ 3,\n    /*SizeLevel*/ 0};\nconst PassBuilder::OptimizationLevel PassBuilder::OptimizationLevel::Os = {\n    /*SpeedLevel*/ 2,\n    /*SizeLevel*/ 1};\nconst PassBuilder::OptimizationLevel PassBuilder::OptimizationLevel::Oz = {\n    /*SpeedLevel*/ 2,\n    /*SizeLevel*/ 2};\n\nnamespace {\n\n// The following passes/analyses have custom names, otherwise their name will\n// include `(anonymous namespace)`. These are special since they are only for\n// testing purposes and don't live in a header file.\n\n/// No-op module pass which does nothing.\nstruct NoOpModulePass : PassInfoMixin<NoOpModulePass> {\n  PreservedAnalyses run(Module &M, ModuleAnalysisManager &) {\n    return PreservedAnalyses::all();\n  }\n\n  static StringRef name() { return \"NoOpModulePass\"; }\n};\n\n/// No-op module analysis.\nclass NoOpModuleAnalysis : public AnalysisInfoMixin<NoOpModuleAnalysis> {\n  friend AnalysisInfoMixin<NoOpModuleAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  struct Result {};\n  Result run(Module &, ModuleAnalysisManager &) { return Result(); }\n  static StringRef name() { return \"NoOpModuleAnalysis\"; }\n};\n\n/// No-op CGSCC pass which does nothing.\nstruct NoOpCGSCCPass : PassInfoMixin<NoOpCGSCCPass> {\n  PreservedAnalyses run(LazyCallGraph::SCC &C, CGSCCAnalysisManager &,\n                        LazyCallGraph &, CGSCCUpdateResult &UR) {\n    return PreservedAnalyses::all();\n  }\n  static StringRef name() { return \"NoOpCGSCCPass\"; }\n};\n\n/// No-op CGSCC analysis.\nclass NoOpCGSCCAnalysis : public AnalysisInfoMixin<NoOpCGSCCAnalysis> {\n  friend AnalysisInfoMixin<NoOpCGSCCAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  struct Result {};\n  Result run(LazyCallGraph::SCC &, CGSCCAnalysisManager &, LazyCallGraph &G) {\n    return Result();\n  }\n  static StringRef name() { return \"NoOpCGSCCAnalysis\"; }\n};\n\n/// No-op function pass which does nothing.\nstruct NoOpFunctionPass : PassInfoMixin<NoOpFunctionPass> {\n  PreservedAnalyses run(Function &F, FunctionAnalysisManager &) {\n    return PreservedAnalyses::all();\n  }\n  static StringRef name() { return \"NoOpFunctionPass\"; }\n};\n\n/// No-op function analysis.\nclass NoOpFunctionAnalysis : public AnalysisInfoMixin<NoOpFunctionAnalysis> {\n  friend AnalysisInfoMixin<NoOpFunctionAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  struct Result {};\n  Result run(Function &, FunctionAnalysisManager &) { return Result(); }\n  static StringRef name() { return \"NoOpFunctionAnalysis\"; }\n};\n\n/// No-op loop pass which does nothing.\nstruct NoOpLoopPass : PassInfoMixin<NoOpLoopPass> {\n  PreservedAnalyses run(Loop &L, LoopAnalysisManager &,\n                        LoopStandardAnalysisResults &, LPMUpdater &) {\n    return PreservedAnalyses::all();\n  }\n  static StringRef name() { return \"NoOpLoopPass\"; }\n};\n\n/// No-op loop analysis.\nclass NoOpLoopAnalysis : public AnalysisInfoMixin<NoOpLoopAnalysis> {\n  friend AnalysisInfoMixin<NoOpLoopAnalysis>;\n  static AnalysisKey Key;\n\npublic:\n  struct Result {};\n  Result run(Loop &, LoopAnalysisManager &, LoopStandardAnalysisResults &) {\n    return Result();\n  }\n  static StringRef name() { return \"NoOpLoopAnalysis\"; }\n};\n\nAnalysisKey NoOpModuleAnalysis::Key;\nAnalysisKey NoOpCGSCCAnalysis::Key;\nAnalysisKey NoOpFunctionAnalysis::Key;\nAnalysisKey NoOpLoopAnalysis::Key;\n\n/// Whether or not we should populate a PassInstrumentationCallbacks's class to\n/// pass name map.\n///\n/// This is for optimization purposes so we don't populate it if we never use\n/// it. This should be updated if new pass instrumentation wants to use the map.\n/// We currently only use this for --print-before/after.\nbool shouldPopulateClassToPassNames() {\n  return !printBeforePasses().empty() || !printAfterPasses().empty();\n}\n\n} // namespace\n\nPassBuilder::PassBuilder(bool DebugLogging, TargetMachine *TM,\n                         PipelineTuningOptions PTO, Optional<PGOOptions> PGOOpt,\n                         PassInstrumentationCallbacks *PIC)\n    : DebugLogging(DebugLogging), TM(TM), PTO(PTO), PGOOpt(PGOOpt), PIC(PIC) {\n  if (TM)\n    TM->registerPassBuilderCallbacks(*this, DebugLogging);\n  if (PIC && shouldPopulateClassToPassNames()) {\n#define MODULE_PASS(NAME, CREATE_PASS)                                         \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS)                                   \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define LOOP_ANALYSIS(NAME, CREATE_PASS)                                       \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define CGSCC_PASS(NAME, CREATE_PASS)                                          \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#define CGSCC_ANALYSIS(NAME, CREATE_PASS)                                      \\\n  PIC->addClassToPassName(decltype(CREATE_PASS)::name(), NAME);\n#include \"PassRegistry.def\"\n  }\n}\n\nvoid PassBuilder::invokePeepholeEPCallbacks(\n    FunctionPassManager &FPM, PassBuilder::OptimizationLevel Level) {\n  for (auto &C : PeepholeEPCallbacks)\n    C(FPM, Level);\n}\n\nvoid PassBuilder::registerModuleAnalyses(ModuleAnalysisManager &MAM) {\n#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\\n  MAM.registerPass([&] { return CREATE_PASS; });\n#include \"PassRegistry.def\"\n\n  for (auto &C : ModuleAnalysisRegistrationCallbacks)\n    C(MAM);\n}\n\nvoid PassBuilder::registerCGSCCAnalyses(CGSCCAnalysisManager &CGAM) {\n#define CGSCC_ANALYSIS(NAME, CREATE_PASS)                                      \\\n  CGAM.registerPass([&] { return CREATE_PASS; });\n#include \"PassRegistry.def\"\n\n  for (auto &C : CGSCCAnalysisRegistrationCallbacks)\n    C(CGAM);\n}\n\nvoid PassBuilder::registerFunctionAnalyses(FunctionAnalysisManager &FAM) {\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS)                                   \\\n  FAM.registerPass([&] { return CREATE_PASS; });\n#include \"PassRegistry.def\"\n\n  for (auto &C : FunctionAnalysisRegistrationCallbacks)\n    C(FAM);\n}\n\nvoid PassBuilder::registerLoopAnalyses(LoopAnalysisManager &LAM) {\n#define LOOP_ANALYSIS(NAME, CREATE_PASS)                                       \\\n  LAM.registerPass([&] { return CREATE_PASS; });\n#include \"PassRegistry.def\"\n\n  for (auto &C : LoopAnalysisRegistrationCallbacks)\n    C(LAM);\n}\n\n// Helper to add AnnotationRemarksPass.\nstatic void addAnnotationRemarksPass(ModulePassManager &MPM) {\n  FunctionPassManager FPM;\n  FPM.addPass(AnnotationRemarksPass());\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));\n}\n\n// Helper to check if the current compilation phase is preparing for LTO\nstatic bool isLTOPreLink(ThinOrFullLTOPhase Phase) {\n  return Phase == ThinOrFullLTOPhase::ThinLTOPreLink ||\n         Phase == ThinOrFullLTOPhase::ThinLTOPreLink;\n}\n\n// TODO: Investigate the cost/benefit of tail call elimination on debugging.\nFunctionPassManager\nPassBuilder::buildO1FunctionSimplificationPipeline(OptimizationLevel Level,\n                                                   ThinOrFullLTOPhase Phase) {\n\n  FunctionPassManager FPM(DebugLogging);\n\n  // Form SSA out of local memory accesses after breaking apart aggregates into\n  // scalars.\n  FPM.addPass(SROA());\n\n  // Catch trivial redundancies\n  FPM.addPass(EarlyCSEPass(true /* Enable mem-ssa. */));\n\n  // Hoisting of scalars and load expressions.\n  FPM.addPass(SimplifyCFGPass());\n  FPM.addPass(InstCombinePass());\n\n  FPM.addPass(LibCallsShrinkWrapPass());\n\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  FPM.addPass(SimplifyCFGPass());\n\n  // Form canonically associated expression trees, and simplify the trees using\n  // basic mathematical properties. For example, this will form (nearly)\n  // minimal multiplication trees.\n  FPM.addPass(ReassociatePass());\n\n  // Add the primary loop simplification pipeline.\n  // FIXME: Currently this is split into two loop pass pipelines because we run\n  // some function passes in between them. These can and should be removed\n  // and/or replaced by scheduling the loop pass equivalents in the correct\n  // positions. But those equivalent passes aren't powerful enough yet.\n  // Specifically, `SimplifyCFGPass` and `InstCombinePass` are currently still\n  // used. We have `LoopSimplifyCFGPass` which isn't yet powerful enough yet to\n  // fully replace `SimplifyCFGPass`, and the closest to the other we have is\n  // `LoopInstSimplify`.\n  LoopPassManager LPM1(DebugLogging), LPM2(DebugLogging);\n\n  // Simplify the loop body. We do this initially to clean up after other loop\n  // passes run, either when iterating on a loop or on inner loops with\n  // implications on the outer loop.\n  LPM1.addPass(LoopInstSimplifyPass());\n  LPM1.addPass(LoopSimplifyCFGPass());\n\n  LPM1.addPass(LoopRotatePass(/* Disable header duplication */ true,\n                              isLTOPreLink(Phase)));\n  // TODO: Investigate promotion cap for O1.\n  LPM1.addPass(LICMPass(PTO.LicmMssaOptCap, PTO.LicmMssaNoAccForPromotionCap));\n  LPM1.addPass(SimpleLoopUnswitchPass());\n\n  LPM2.addPass(LoopIdiomRecognizePass());\n  LPM2.addPass(IndVarSimplifyPass());\n\n  for (auto &C : LateLoopOptimizationsEPCallbacks)\n    C(LPM2, Level);\n\n  LPM2.addPass(LoopDeletionPass());\n\n  if (EnableLoopInterchange)\n    LPM2.addPass(LoopInterchangePass());\n\n  // Do not enable unrolling in PreLinkThinLTO phase during sample PGO\n  // because it changes IR to makes profile annotation in back compile\n  // inaccurate. The normal unroller doesn't pay attention to forced full unroll\n  // attributes so we need to make sure and allow the full unroll pass to pay\n  // attention to it.\n  if (Phase != ThinOrFullLTOPhase::ThinLTOPreLink || !PGOOpt ||\n      PGOOpt->Action != PGOOptions::SampleUse)\n    LPM2.addPass(LoopFullUnrollPass(Level.getSpeedupLevel(),\n                                    /* OnlyWhenForced= */ !PTO.LoopUnrolling,\n                                    PTO.ForgetAllSCEVInLoopUnroll));\n\n  for (auto &C : LoopOptimizerEndEPCallbacks)\n    C(LPM2, Level);\n\n  // We provide the opt remark emitter pass for LICM to use. We only need to do\n  // this once as it is immutable.\n  FPM.addPass(\n      RequireAnalysisPass<OptimizationRemarkEmitterAnalysis, Function>());\n  FPM.addPass(createFunctionToLoopPassAdaptor(\n      std::move(LPM1), EnableMSSALoopDependency, /*UseBlockFrequencyInfo=*/true,\n      DebugLogging));\n  FPM.addPass(SimplifyCFGPass());\n  FPM.addPass(InstCombinePass());\n  if (EnableLoopFlatten)\n    FPM.addPass(LoopFlattenPass());\n  // The loop passes in LPM2 (LoopFullUnrollPass) do not preserve MemorySSA.\n  // *All* loop passes must preserve it, in order to be able to use it.\n  FPM.addPass(createFunctionToLoopPassAdaptor(\n      std::move(LPM2), /*UseMemorySSA=*/false, /*UseBlockFrequencyInfo=*/false,\n      DebugLogging));\n\n  // Delete small array after loop unroll.\n  FPM.addPass(SROA());\n\n  // Specially optimize memory movement as it doesn't look like dataflow in SSA.\n  FPM.addPass(MemCpyOptPass());\n\n  // Sparse conditional constant propagation.\n  // FIXME: It isn't clear why we do this *after* loop passes rather than\n  // before...\n  FPM.addPass(SCCPPass());\n\n  // Delete dead bit computations (instcombine runs after to fold away the dead\n  // computations, and then ADCE will run later to exploit any new DCE\n  // opportunities that creates).\n  FPM.addPass(BDCEPass());\n\n  // Run instcombine after redundancy and dead bit elimination to exploit\n  // opportunities opened up by them.\n  FPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  if (PTO.Coroutines)\n    FPM.addPass(CoroElidePass());\n\n  for (auto &C : ScalarOptimizerLateEPCallbacks)\n    C(FPM, Level);\n\n  // Finally, do an expensive DCE pass to catch all the dead code exposed by\n  // the simplifications and basic cleanup after all the simplifications.\n  // TODO: Investigate if this is too expensive.\n  FPM.addPass(ADCEPass());\n  FPM.addPass(SimplifyCFGPass());\n  FPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  return FPM;\n}\n\nFunctionPassManager\nPassBuilder::buildFunctionSimplificationPipeline(OptimizationLevel Level,\n                                                 ThinOrFullLTOPhase Phase) {\n  assert(Level != OptimizationLevel::O0 && \"Must request optimizations!\");\n\n  // The O1 pipeline has a separate pipeline creation function to simplify\n  // construction readability.\n  if (Level.getSpeedupLevel() == 1)\n    return buildO1FunctionSimplificationPipeline(Level, Phase);\n\n  FunctionPassManager FPM(DebugLogging);\n\n  // Form SSA out of local memory accesses after breaking apart aggregates into\n  // scalars.\n  FPM.addPass(SROA());\n\n  // Catch trivial redundancies\n  FPM.addPass(EarlyCSEPass(true /* Enable mem-ssa. */));\n  if (EnableKnowledgeRetention)\n    FPM.addPass(AssumeSimplifyPass());\n\n  // Hoisting of scalars and load expressions.\n  if (EnableGVNHoist)\n    FPM.addPass(GVNHoistPass());\n\n  // Global value numbering based sinking.\n  if (EnableGVNSink) {\n    FPM.addPass(GVNSinkPass());\n    FPM.addPass(SimplifyCFGPass());\n  }\n\n  if (EnableConstraintElimination)\n    FPM.addPass(ConstraintEliminationPass());\n\n  // Speculative execution if the target has divergent branches; otherwise nop.\n  FPM.addPass(SpeculativeExecutionPass(/* OnlyIfDivergentTarget =*/true));\n\n  // Optimize based on known information about branches, and cleanup afterward.\n  FPM.addPass(JumpThreadingPass());\n  FPM.addPass(CorrelatedValuePropagationPass());\n\n  FPM.addPass(SimplifyCFGPass());\n  if (Level == OptimizationLevel::O3)\n    FPM.addPass(AggressiveInstCombinePass());\n  FPM.addPass(InstCombinePass());\n\n  if (!Level.isOptimizingForSize())\n    FPM.addPass(LibCallsShrinkWrapPass());\n\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  // For PGO use pipeline, try to optimize memory intrinsics such as memcpy\n  // using the size value profile. Don't perform this when optimizing for size.\n  if (PGOOpt && PGOOpt->Action == PGOOptions::IRUse &&\n      !Level.isOptimizingForSize())\n    FPM.addPass(PGOMemOPSizeOpt());\n\n  FPM.addPass(TailCallElimPass());\n  FPM.addPass(SimplifyCFGPass());\n\n  // Form canonically associated expression trees, and simplify the trees using\n  // basic mathematical properties. For example, this will form (nearly)\n  // minimal multiplication trees.\n  FPM.addPass(ReassociatePass());\n\n  // Add the primary loop simplification pipeline.\n  // FIXME: Currently this is split into two loop pass pipelines because we run\n  // some function passes in between them. These can and should be removed\n  // and/or replaced by scheduling the loop pass equivalents in the correct\n  // positions. But those equivalent passes aren't powerful enough yet.\n  // Specifically, `SimplifyCFGPass` and `InstCombinePass` are currently still\n  // used. We have `LoopSimplifyCFGPass` which isn't yet powerful enough yet to\n  // fully replace `SimplifyCFGPass`, and the closest to the other we have is\n  // `LoopInstSimplify`.\n  LoopPassManager LPM1(DebugLogging), LPM2(DebugLogging);\n\n  // Simplify the loop body. We do this initially to clean up after other loop\n  // passes run, either when iterating on a loop or on inner loops with\n  // implications on the outer loop.\n  LPM1.addPass(LoopInstSimplifyPass());\n  LPM1.addPass(LoopSimplifyCFGPass());\n\n  // Disable header duplication in loop rotation at -Oz.\n  LPM1.addPass(\n      LoopRotatePass(Level != OptimizationLevel::Oz, isLTOPreLink(Phase)));\n  // TODO: Investigate promotion cap for O1.\n  LPM1.addPass(LICMPass(PTO.LicmMssaOptCap, PTO.LicmMssaNoAccForPromotionCap));\n  LPM1.addPass(\n      SimpleLoopUnswitchPass(/* NonTrivial */ Level == OptimizationLevel::O3 &&\n                             EnableO3NonTrivialUnswitching));\n  LPM2.addPass(LoopIdiomRecognizePass());\n  LPM2.addPass(IndVarSimplifyPass());\n\n  for (auto &C : LateLoopOptimizationsEPCallbacks)\n    C(LPM2, Level);\n\n  LPM2.addPass(LoopDeletionPass());\n\n  if (EnableLoopInterchange)\n    LPM2.addPass(LoopInterchangePass());\n\n  // Do not enable unrolling in PreLinkThinLTO phase during sample PGO\n  // because it changes IR to makes profile annotation in back compile\n  // inaccurate. The normal unroller doesn't pay attention to forced full unroll\n  // attributes so we need to make sure and allow the full unroll pass to pay\n  // attention to it.\n  if (Phase != ThinOrFullLTOPhase::ThinLTOPreLink || !PGOOpt ||\n      PGOOpt->Action != PGOOptions::SampleUse)\n    LPM2.addPass(LoopFullUnrollPass(Level.getSpeedupLevel(),\n                                    /* OnlyWhenForced= */ !PTO.LoopUnrolling,\n                                    PTO.ForgetAllSCEVInLoopUnroll));\n\n  for (auto &C : LoopOptimizerEndEPCallbacks)\n    C(LPM2, Level);\n\n  // We provide the opt remark emitter pass for LICM to use. We only need to do\n  // this once as it is immutable.\n  FPM.addPass(\n      RequireAnalysisPass<OptimizationRemarkEmitterAnalysis, Function>());\n  FPM.addPass(createFunctionToLoopPassAdaptor(\n      std::move(LPM1), EnableMSSALoopDependency, /*UseBlockFrequencyInfo=*/true,\n      DebugLogging));\n  FPM.addPass(SimplifyCFGPass());\n  FPM.addPass(InstCombinePass());\n  if (EnableLoopFlatten)\n    FPM.addPass(LoopFlattenPass());\n  // The loop passes in LPM2 (LoopIdiomRecognizePass, IndVarSimplifyPass,\n  // LoopDeletionPass and LoopFullUnrollPass) do not preserve MemorySSA.\n  // *All* loop passes must preserve it, in order to be able to use it.\n  FPM.addPass(createFunctionToLoopPassAdaptor(\n      std::move(LPM2), /*UseMemorySSA=*/false, /*UseBlockFrequencyInfo=*/false,\n      DebugLogging));\n\n  // Delete small array after loop unroll.\n  FPM.addPass(SROA());\n\n  // Eliminate redundancies.\n  FPM.addPass(MergedLoadStoreMotionPass());\n  if (RunNewGVN)\n    FPM.addPass(NewGVNPass());\n  else\n    FPM.addPass(GVN());\n\n  // Sparse conditional constant propagation.\n  // FIXME: It isn't clear why we do this *after* loop passes rather than\n  // before...\n  FPM.addPass(SCCPPass());\n\n  // Delete dead bit computations (instcombine runs after to fold away the dead\n  // computations, and then ADCE will run later to exploit any new DCE\n  // opportunities that creates).\n  FPM.addPass(BDCEPass());\n\n  // Run instcombine after redundancy and dead bit elimination to exploit\n  // opportunities opened up by them.\n  FPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  // Re-consider control flow based optimizations after redundancy elimination,\n  // redo DCE, etc.\n  FPM.addPass(JumpThreadingPass());\n  FPM.addPass(CorrelatedValuePropagationPass());\n\n  // Finally, do an expensive DCE pass to catch all the dead code exposed by\n  // the simplifications and basic cleanup after all the simplifications.\n  // TODO: Investigate if this is too expensive.\n  FPM.addPass(ADCEPass());\n\n  // Specially optimize memory movement as it doesn't look like dataflow in SSA.\n  FPM.addPass(MemCpyOptPass());\n\n  FPM.addPass(DSEPass());\n  FPM.addPass(createFunctionToLoopPassAdaptor(\n      LICMPass(PTO.LicmMssaOptCap, PTO.LicmMssaNoAccForPromotionCap),\n      EnableMSSALoopDependency, /*UseBlockFrequencyInfo=*/true, DebugLogging));\n\n  if (PTO.Coroutines)\n    FPM.addPass(CoroElidePass());\n\n  for (auto &C : ScalarOptimizerLateEPCallbacks)\n    C(FPM, Level);\n\n  FPM.addPass(SimplifyCFGPass());\n  FPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  if (EnableCHR && Level == OptimizationLevel::O3 && PGOOpt &&\n      (PGOOpt->Action == PGOOptions::IRUse ||\n       PGOOpt->Action == PGOOptions::SampleUse))\n    FPM.addPass(ControlHeightReductionPass());\n\n  return FPM;\n}\n\nvoid PassBuilder::addRequiredLTOPreLinkPasses(ModulePassManager &MPM) {\n  MPM.addPass(CanonicalizeAliasesPass());\n  MPM.addPass(NameAnonGlobalPass());\n}\n\nvoid PassBuilder::addPGOInstrPasses(ModulePassManager &MPM,\n                                    PassBuilder::OptimizationLevel Level,\n                                    bool RunProfileGen, bool IsCS,\n                                    std::string ProfileFile,\n                                    std::string ProfileRemappingFile) {\n  assert(Level != OptimizationLevel::O0 && \"Not expecting O0 here!\");\n  if (!IsCS && !DisablePreInliner) {\n    InlineParams IP;\n\n    IP.DefaultThreshold = PreInlineThreshold;\n\n    // FIXME: The hint threshold has the same value used by the regular inliner\n    // when not optimzing for size. This should probably be lowered after\n    // performance testing.\n    // FIXME: this comment is cargo culted from the old pass manager, revisit).\n    IP.HintThreshold = Level.isOptimizingForSize() ? PreInlineThreshold : 325;\n    ModuleInlinerWrapperPass MIWP(IP, DebugLogging);\n    CGSCCPassManager &CGPipeline = MIWP.getPM();\n\n    FunctionPassManager FPM;\n    FPM.addPass(SROA());\n    FPM.addPass(EarlyCSEPass());    // Catch trivial redundancies.\n    FPM.addPass(SimplifyCFGPass()); // Merge & remove basic blocks.\n    FPM.addPass(InstCombinePass()); // Combine silly sequences.\n    invokePeepholeEPCallbacks(FPM, Level);\n\n    CGPipeline.addPass(createCGSCCToFunctionPassAdaptor(std::move(FPM)));\n\n    MPM.addPass(std::move(MIWP));\n\n    // Delete anything that is now dead to make sure that we don't instrument\n    // dead code. Instrumentation can end up keeping dead code around and\n    // dramatically increase code size.\n    MPM.addPass(GlobalDCEPass());\n  }\n\n  if (!RunProfileGen) {\n    assert(!ProfileFile.empty() && \"Profile use expecting a profile file!\");\n    MPM.addPass(PGOInstrumentationUse(ProfileFile, ProfileRemappingFile, IsCS));\n    // Cache ProfileSummaryAnalysis once to avoid the potential need to insert\n    // RequireAnalysisPass for PSI before subsequent non-module passes.\n    MPM.addPass(RequireAnalysisPass<ProfileSummaryAnalysis, Module>());\n    return;\n  }\n\n  // Perform PGO instrumentation.\n  MPM.addPass(PGOInstrumentationGen(IsCS));\n\n  FunctionPassManager FPM;\n  // Disable header duplication in loop rotation at -Oz.\n  FPM.addPass(createFunctionToLoopPassAdaptor(\n      LoopRotatePass(Level != OptimizationLevel::Oz), EnableMSSALoopDependency,\n      /*UseBlockFrequencyInfo=*/false, DebugLogging));\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));\n\n  // Add the profile lowering pass.\n  InstrProfOptions Options;\n  if (!ProfileFile.empty())\n    Options.InstrProfileOutput = ProfileFile;\n  // Do counter promotion at Level greater than O0.\n  Options.DoCounterPromotion = true;\n  Options.UseBFIInPromotion = IsCS;\n  MPM.addPass(InstrProfiling(Options, IsCS));\n}\n\nvoid PassBuilder::addPGOInstrPassesForO0(ModulePassManager &MPM,\n                                         bool RunProfileGen, bool IsCS,\n                                         std::string ProfileFile,\n                                         std::string ProfileRemappingFile) {\n  if (!RunProfileGen) {\n    assert(!ProfileFile.empty() && \"Profile use expecting a profile file!\");\n    MPM.addPass(PGOInstrumentationUse(ProfileFile, ProfileRemappingFile, IsCS));\n    // Cache ProfileSummaryAnalysis once to avoid the potential need to insert\n    // RequireAnalysisPass for PSI before subsequent non-module passes.\n    MPM.addPass(RequireAnalysisPass<ProfileSummaryAnalysis, Module>());\n    return;\n  }\n\n  // Perform PGO instrumentation.\n  MPM.addPass(PGOInstrumentationGen(IsCS));\n  // Add the profile lowering pass.\n  InstrProfOptions Options;\n  if (!ProfileFile.empty())\n    Options.InstrProfileOutput = ProfileFile;\n  // Do not do counter promotion at O0.\n  Options.DoCounterPromotion = false;\n  Options.UseBFIInPromotion = IsCS;\n  MPM.addPass(InstrProfiling(Options, IsCS));\n}\n\nstatic InlineParams\ngetInlineParamsFromOptLevel(PassBuilder::OptimizationLevel Level) {\n  return getInlineParams(Level.getSpeedupLevel(), Level.getSizeLevel());\n}\n\nModuleInlinerWrapperPass\nPassBuilder::buildInlinerPipeline(OptimizationLevel Level,\n                                  ThinOrFullLTOPhase Phase) {\n  InlineParams IP = getInlineParamsFromOptLevel(Level);\n  if (Phase == ThinOrFullLTOPhase::ThinLTOPreLink && PGOOpt &&\n      PGOOpt->Action == PGOOptions::SampleUse)\n    IP.HotCallSiteThreshold = 0;\n\n  if (PGOOpt)\n    IP.EnableDeferral = EnablePGOInlineDeferral;\n\n  ModuleInlinerWrapperPass MIWP(IP, DebugLogging,\n                                PerformMandatoryInliningsFirst,\n                                UseInlineAdvisor, MaxDevirtIterations);\n\n  // Require the GlobalsAA analysis for the module so we can query it within\n  // the CGSCC pipeline.\n  MIWP.addRequiredModuleAnalysis<GlobalsAA>();\n\n  // Require the ProfileSummaryAnalysis for the module so we can query it within\n  // the inliner pass.\n  MIWP.addRequiredModuleAnalysis<ProfileSummaryAnalysis>();\n\n  // Now begin the main postorder CGSCC pipeline.\n  // FIXME: The current CGSCC pipeline has its origins in the legacy pass\n  // manager and trying to emulate its precise behavior. Much of this doesn't\n  // make a lot of sense and we should revisit the core CGSCC structure.\n  CGSCCPassManager &MainCGPipeline = MIWP.getPM();\n\n  // Note: historically, the PruneEH pass was run first to deduce nounwind and\n  // generally clean up exception handling overhead. It isn't clear this is\n  // valuable as the inliner doesn't currently care whether it is inlining an\n  // invoke or a call.\n\n  if (AttributorRun & AttributorRunOption::CGSCC)\n    MainCGPipeline.addPass(AttributorCGSCCPass());\n\n  if (PTO.Coroutines)\n    MainCGPipeline.addPass(CoroSplitPass(Level != OptimizationLevel::O0));\n\n  // Now deduce any function attributes based in the current code.\n  MainCGPipeline.addPass(PostOrderFunctionAttrsPass());\n\n  // When at O3 add argument promotion to the pass pipeline.\n  // FIXME: It isn't at all clear why this should be limited to O3.\n  if (Level == OptimizationLevel::O3)\n    MainCGPipeline.addPass(ArgumentPromotionPass());\n\n  // Try to perform OpenMP specific optimizations. This is a (quick!) no-op if\n  // there are no OpenMP runtime calls present in the module.\n  if (Level == OptimizationLevel::O2 || Level == OptimizationLevel::O3)\n    MainCGPipeline.addPass(OpenMPOptPass());\n\n  for (auto &C : CGSCCOptimizerLateEPCallbacks)\n    C(MainCGPipeline, Level);\n\n  // Lastly, add the core function simplification pipeline nested inside the\n  // CGSCC walk.\n  MainCGPipeline.addPass(createCGSCCToFunctionPassAdaptor(\n      buildFunctionSimplificationPipeline(Level, Phase)));\n\n  return MIWP;\n}\n\nModulePassManager\nPassBuilder::buildModuleSimplificationPipeline(OptimizationLevel Level,\n                                               ThinOrFullLTOPhase Phase) {\n  ModulePassManager MPM(DebugLogging);\n\n  // Place pseudo probe instrumentation as the first pass of the pipeline to\n  // minimize the impact of optimization changes.\n  if (PGOOpt && PGOOpt->PseudoProbeForProfiling &&\n      Phase != ThinOrFullLTOPhase::ThinLTOPostLink)\n    MPM.addPass(SampleProfileProbePass(TM));\n\n  bool HasSampleProfile = PGOOpt && (PGOOpt->Action == PGOOptions::SampleUse);\n\n  // In ThinLTO mode, when flattened profile is used, all the available\n  // profile information will be annotated in PreLink phase so there is\n  // no need to load the profile again in PostLink.\n  bool LoadSampleProfile =\n      HasSampleProfile &&\n      !(FlattenedProfileUsed && Phase == ThinOrFullLTOPhase::ThinLTOPostLink);\n\n  // During the ThinLTO backend phase we perform early indirect call promotion\n  // here, before globalopt. Otherwise imported available_externally functions\n  // look unreferenced and are removed. If we are going to load the sample\n  // profile then defer until later.\n  // TODO: See if we can move later and consolidate with the location where\n  // we perform ICP when we are loading a sample profile.\n  // TODO: We pass HasSampleProfile (whether there was a sample profile file\n  // passed to the compile) to the SamplePGO flag of ICP. This is used to\n  // determine whether the new direct calls are annotated with prof metadata.\n  // Ideally this should be determined from whether the IR is annotated with\n  // sample profile, and not whether the a sample profile was provided on the\n  // command line. E.g. for flattened profiles where we will not be reloading\n  // the sample profile in the ThinLTO backend, we ideally shouldn't have to\n  // provide the sample profile file.\n  if (Phase == ThinOrFullLTOPhase::ThinLTOPostLink && !LoadSampleProfile)\n    MPM.addPass(PGOIndirectCallPromotion(true /* InLTO */, HasSampleProfile));\n\n  // Do basic inference of function attributes from known properties of system\n  // libraries and other oracles.\n  MPM.addPass(InferFunctionAttrsPass());\n\n  // Create an early function pass manager to cleanup the output of the\n  // frontend.\n  FunctionPassManager EarlyFPM(DebugLogging);\n  EarlyFPM.addPass(SimplifyCFGPass());\n  EarlyFPM.addPass(SROA());\n  EarlyFPM.addPass(EarlyCSEPass());\n  EarlyFPM.addPass(LowerExpectIntrinsicPass());\n  if (PTO.Coroutines)\n    EarlyFPM.addPass(CoroEarlyPass());\n  if (Level == OptimizationLevel::O3)\n    EarlyFPM.addPass(CallSiteSplittingPass());\n\n  // In SamplePGO ThinLTO backend, we need instcombine before profile annotation\n  // to convert bitcast to direct calls so that they can be inlined during the\n  // profile annotation prepration step.\n  // More details about SamplePGO design can be found in:\n  // https://research.google.com/pubs/pub45290.html\n  // FIXME: revisit how SampleProfileLoad/Inliner/ICP is structured.\n  if (LoadSampleProfile)\n    EarlyFPM.addPass(InstCombinePass());\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(EarlyFPM)));\n\n  if (LoadSampleProfile) {\n    // Annotate sample profile right after early FPM to ensure freshness of\n    // the debug info.\n    MPM.addPass(SampleProfileLoaderPass(PGOOpt->ProfileFile,\n                                        PGOOpt->ProfileRemappingFile, Phase));\n    // Cache ProfileSummaryAnalysis once to avoid the potential need to insert\n    // RequireAnalysisPass for PSI before subsequent non-module passes.\n    MPM.addPass(RequireAnalysisPass<ProfileSummaryAnalysis, Module>());\n    // Do not invoke ICP in the LTOPrelink phase as it makes it hard\n    // for the profile annotation to be accurate in the LTO backend.\n    if (Phase != ThinOrFullLTOPhase::ThinLTOPreLink &&\n        Phase != ThinOrFullLTOPhase::FullLTOPreLink)\n      // We perform early indirect call promotion here, before globalopt.\n      // This is important for the ThinLTO backend phase because otherwise\n      // imported available_externally functions look unreferenced and are\n      // removed.\n      MPM.addPass(\n          PGOIndirectCallPromotion(true /* IsInLTO */, true /* SamplePGO */));\n  }\n\n  if (AttributorRun & AttributorRunOption::MODULE)\n    MPM.addPass(AttributorPass());\n\n  // Lower type metadata and the type.test intrinsic in the ThinLTO\n  // post link pipeline after ICP. This is to enable usage of the type\n  // tests in ICP sequences.\n  if (Phase == ThinOrFullLTOPhase::ThinLTOPostLink)\n    MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));\n\n  for (auto &C : PipelineEarlySimplificationEPCallbacks)\n    C(MPM, Level);\n\n  // Interprocedural constant propagation now that basic cleanup has occurred\n  // and prior to optimizing globals.\n  // FIXME: This position in the pipeline hasn't been carefully considered in\n  // years, it should be re-analyzed.\n  MPM.addPass(IPSCCPPass());\n\n  // Attach metadata to indirect call sites indicating the set of functions\n  // they may target at run-time. This should follow IPSCCP.\n  MPM.addPass(CalledValuePropagationPass());\n\n  // Optimize globals to try and fold them into constants.\n  MPM.addPass(GlobalOptPass());\n\n  // Promote any localized globals to SSA registers.\n  // FIXME: Should this instead by a run of SROA?\n  // FIXME: We should probably run instcombine and simplify-cfg afterward to\n  // delete control flows that are dead once globals have been folded to\n  // constants.\n  MPM.addPass(createModuleToFunctionPassAdaptor(PromotePass()));\n\n  // Remove any dead arguments exposed by cleanups and constant folding\n  // globals.\n  MPM.addPass(DeadArgumentEliminationPass());\n\n  // Create a small function pass pipeline to cleanup after all the global\n  // optimizations.\n  FunctionPassManager GlobalCleanupPM(DebugLogging);\n  GlobalCleanupPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(GlobalCleanupPM, Level);\n\n  GlobalCleanupPM.addPass(SimplifyCFGPass());\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(GlobalCleanupPM)));\n\n  // Add all the requested passes for instrumentation PGO, if requested.\n  if (PGOOpt && Phase != ThinOrFullLTOPhase::ThinLTOPostLink &&\n      (PGOOpt->Action == PGOOptions::IRInstr ||\n       PGOOpt->Action == PGOOptions::IRUse)) {\n    addPGOInstrPasses(MPM, Level,\n                      /* RunProfileGen */ PGOOpt->Action == PGOOptions::IRInstr,\n                      /* IsCS */ false, PGOOpt->ProfileFile,\n                      PGOOpt->ProfileRemappingFile);\n    MPM.addPass(PGOIndirectCallPromotion(false, false));\n  }\n  if (PGOOpt && Phase != ThinOrFullLTOPhase::ThinLTOPostLink &&\n      PGOOpt->CSAction == PGOOptions::CSIRInstr)\n    MPM.addPass(PGOInstrumentationGenCreateVar(PGOOpt->CSProfileGenFile));\n\n  // Synthesize function entry counts for non-PGO compilation.\n  if (EnableSyntheticCounts && !PGOOpt)\n    MPM.addPass(SyntheticCountsPropagation());\n\n  MPM.addPass(buildInlinerPipeline(Level, Phase));\n\n  if (EnableMemProfiler && Phase != ThinOrFullLTOPhase::ThinLTOPreLink) {\n    MPM.addPass(createModuleToFunctionPassAdaptor(MemProfilerPass()));\n    MPM.addPass(ModuleMemProfilerPass());\n  }\n\n  return MPM;\n}\n\nModulePassManager\nPassBuilder::buildModuleOptimizationPipeline(OptimizationLevel Level,\n                                             bool LTOPreLink) {\n  ModulePassManager MPM(DebugLogging);\n\n  // Optimize globals now that the module is fully simplified.\n  MPM.addPass(GlobalOptPass());\n  MPM.addPass(GlobalDCEPass());\n\n  // Run partial inlining pass to partially inline functions that have\n  // large bodies.\n  if (RunPartialInlining)\n    MPM.addPass(PartialInlinerPass());\n\n  // Remove avail extern fns and globals definitions since we aren't compiling\n  // an object file for later LTO. For LTO we want to preserve these so they\n  // are eligible for inlining at link-time. Note if they are unreferenced they\n  // will be removed by GlobalDCE later, so this only impacts referenced\n  // available externally globals. Eventually they will be suppressed during\n  // codegen, but eliminating here enables more opportunity for GlobalDCE as it\n  // may make globals referenced by available external functions dead and saves\n  // running remaining passes on the eliminated functions. These should be\n  // preserved during prelinking for link-time inlining decisions.\n  if (!LTOPreLink)\n    MPM.addPass(EliminateAvailableExternallyPass());\n\n  if (EnableOrderFileInstrumentation)\n    MPM.addPass(InstrOrderFilePass());\n\n  // Do RPO function attribute inference across the module to forward-propagate\n  // attributes where applicable.\n  // FIXME: Is this really an optimization rather than a canonicalization?\n  MPM.addPass(ReversePostOrderFunctionAttrsPass());\n\n  // Do a post inline PGO instrumentation and use pass. This is a context\n  // sensitive PGO pass. We don't want to do this in LTOPreLink phrase as\n  // cross-module inline has not been done yet. The context sensitive\n  // instrumentation is after all the inlines are done.\n  if (!LTOPreLink && PGOOpt) {\n    if (PGOOpt->CSAction == PGOOptions::CSIRInstr)\n      addPGOInstrPasses(MPM, Level, /* RunProfileGen */ true,\n                        /* IsCS */ true, PGOOpt->CSProfileGenFile,\n                        PGOOpt->ProfileRemappingFile);\n    else if (PGOOpt->CSAction == PGOOptions::CSIRUse)\n      addPGOInstrPasses(MPM, Level, /* RunProfileGen */ false,\n                        /* IsCS */ true, PGOOpt->ProfileFile,\n                        PGOOpt->ProfileRemappingFile);\n  }\n\n  // Re-require GloblasAA here prior to function passes. This is particularly\n  // useful as the above will have inlined, DCE'ed, and function-attr\n  // propagated everything. We should at this point have a reasonably minimal\n  // and richly annotated call graph. By computing aliasing and mod/ref\n  // information for all local globals here, the late loop passes and notably\n  // the vectorizer will be able to use them to help recognize vectorizable\n  // memory operations.\n  MPM.addPass(RequireAnalysisPass<GlobalsAA, Module>());\n\n  FunctionPassManager OptimizePM(DebugLogging);\n  OptimizePM.addPass(Float2IntPass());\n  OptimizePM.addPass(LowerConstantIntrinsicsPass());\n\n  if (EnableMatrix) {\n    OptimizePM.addPass(LowerMatrixIntrinsicsPass());\n    OptimizePM.addPass(EarlyCSEPass());\n  }\n\n  // FIXME: We need to run some loop optimizations to re-rotate loops after\n  // simplify-cfg and others undo their rotation.\n\n  // Optimize the loop execution. These passes operate on entire loop nests\n  // rather than on each loop in an inside-out manner, and so they are actually\n  // function passes.\n\n  for (auto &C : VectorizerStartEPCallbacks)\n    C(OptimizePM, Level);\n\n  // First rotate loops that may have been un-rotated by prior passes.\n  // Disable header duplication at -Oz.\n  OptimizePM.addPass(createFunctionToLoopPassAdaptor(\n      LoopRotatePass(Level != OptimizationLevel::Oz, LTOPreLink),\n      EnableMSSALoopDependency,\n      /*UseBlockFrequencyInfo=*/false, DebugLogging));\n\n  // Distribute loops to allow partial vectorization.  I.e. isolate dependences\n  // into separate loop that would otherwise inhibit vectorization.  This is\n  // currently only performed for loops marked with the metadata\n  // llvm.loop.distribute=true or when -enable-loop-distribute is specified.\n  OptimizePM.addPass(LoopDistributePass());\n\n  // Populates the VFABI attribute with the scalar-to-vector mappings\n  // from the TargetLibraryInfo.\n  OptimizePM.addPass(InjectTLIMappings());\n\n  // Now run the core loop vectorizer.\n  OptimizePM.addPass(LoopVectorizePass(\n      LoopVectorizeOptions(!PTO.LoopInterleaving, !PTO.LoopVectorization)));\n\n  // Eliminate loads by forwarding stores from the previous iteration to loads\n  // of the current iteration.\n  OptimizePM.addPass(LoopLoadEliminationPass());\n\n  // Cleanup after the loop optimization passes.\n  OptimizePM.addPass(InstCombinePass());\n\n  if (Level.getSpeedupLevel() > 1 && ExtraVectorizerPasses) {\n    // At higher optimization levels, try to clean up any runtime overlap and\n    // alignment checks inserted by the vectorizer. We want to track correlated\n    // runtime checks for two inner loops in the same outer loop, fold any\n    // common computations, hoist loop-invariant aspects out of any outer loop,\n    // and unswitch the runtime checks if possible. Once hoisted, we may have\n    // dead (or speculatable) control flows or more combining opportunities.\n    OptimizePM.addPass(EarlyCSEPass());\n    OptimizePM.addPass(CorrelatedValuePropagationPass());\n    OptimizePM.addPass(InstCombinePass());\n    LoopPassManager LPM(DebugLogging);\n    LPM.addPass(LICMPass(PTO.LicmMssaOptCap, PTO.LicmMssaNoAccForPromotionCap));\n    LPM.addPass(\n        SimpleLoopUnswitchPass(/* NonTrivial */ Level == OptimizationLevel::O3));\n    OptimizePM.addPass(RequireAnalysisPass<OptimizationRemarkEmitterAnalysis, Function>());\n    OptimizePM.addPass(createFunctionToLoopPassAdaptor(\n        std::move(LPM), EnableMSSALoopDependency, /*UseBlockFrequencyInfo=*/true,\n        DebugLogging));\n    OptimizePM.addPass(SimplifyCFGPass());\n    OptimizePM.addPass(InstCombinePass());\n  }\n\n  // Now that we've formed fast to execute loop structures, we do further\n  // optimizations. These are run afterward as they might block doing complex\n  // analyses and transforms such as what are needed for loop vectorization.\n\n  // Cleanup after loop vectorization, etc. Simplification passes like CVP and\n  // GVN, loop transforms, and others have already run, so it's now better to\n  // convert to more optimized IR using more aggressive simplify CFG options.\n  // The extra sinking transform can create larger basic blocks, so do this\n  // before SLP vectorization.\n  // FIXME: study whether hoisting and/or sinking of common instructions should\n  //        be delayed until after SLP vectorizer.\n  OptimizePM.addPass(SimplifyCFGPass(SimplifyCFGOptions()\n                                         .forwardSwitchCondToPhi(true)\n                                         .convertSwitchToLookupTable(true)\n                                         .needCanonicalLoops(false)\n                                         .hoistCommonInsts(true)\n                                         .sinkCommonInsts(true)));\n\n  // Optimize parallel scalar instruction chains into SIMD instructions.\n  if (PTO.SLPVectorization) {\n    OptimizePM.addPass(SLPVectorizerPass());\n    if (Level.getSpeedupLevel() > 1 && ExtraVectorizerPasses) {\n      OptimizePM.addPass(EarlyCSEPass());\n    }\n  }\n\n  // Enhance/cleanup vector code.\n  OptimizePM.addPass(VectorCombinePass());\n  OptimizePM.addPass(InstCombinePass());\n\n  // Unroll small loops to hide loop backedge latency and saturate any parallel\n  // execution resources of an out-of-order processor. We also then need to\n  // clean up redundancies and loop invariant code.\n  // FIXME: It would be really good to use a loop-integrated instruction\n  // combiner for cleanup here so that the unrolling and LICM can be pipelined\n  // across the loop nests.\n  // We do UnrollAndJam in a separate LPM to ensure it happens before unroll\n  if (EnableUnrollAndJam && PTO.LoopUnrolling) {\n    OptimizePM.addPass(LoopUnrollAndJamPass(Level.getSpeedupLevel()));\n  }\n  OptimizePM.addPass(LoopUnrollPass(LoopUnrollOptions(\n      Level.getSpeedupLevel(), /*OnlyWhenForced=*/!PTO.LoopUnrolling,\n      PTO.ForgetAllSCEVInLoopUnroll)));\n  OptimizePM.addPass(WarnMissedTransformationsPass());\n  OptimizePM.addPass(InstCombinePass());\n  OptimizePM.addPass(RequireAnalysisPass<OptimizationRemarkEmitterAnalysis, Function>());\n  OptimizePM.addPass(createFunctionToLoopPassAdaptor(\n      LICMPass(PTO.LicmMssaOptCap, PTO.LicmMssaNoAccForPromotionCap),\n      EnableMSSALoopDependency, /*UseBlockFrequencyInfo=*/true, DebugLogging));\n\n  // Now that we've vectorized and unrolled loops, we may have more refined\n  // alignment information, try to re-derive it here.\n  OptimizePM.addPass(AlignmentFromAssumptionsPass());\n\n  // Split out cold code. Splitting is done late to avoid hiding context from\n  // other optimizations and inadvertently regressing performance. The tradeoff\n  // is that this has a higher code size cost than splitting early.\n  if (EnableHotColdSplit && !LTOPreLink)\n    MPM.addPass(HotColdSplittingPass());\n\n  // Search the code for similar regions of code. If enough similar regions can\n  // be found where extracting the regions into their own function will decrease\n  // the size of the program, we extract the regions, a deduplicate the\n  // structurally similar regions.\n  if (EnableIROutliner)\n    MPM.addPass(IROutlinerPass());\n\n  // Merge functions if requested.\n  if (PTO.MergeFunctions)\n    MPM.addPass(MergeFunctionsPass());\n\n  // LoopSink pass sinks instructions hoisted by LICM, which serves as a\n  // canonicalization pass that enables other optimizations. As a result,\n  // LoopSink pass needs to be a very late IR pass to avoid undoing LICM\n  // result too early.\n  OptimizePM.addPass(LoopSinkPass());\n\n  // And finally clean up LCSSA form before generating code.\n  OptimizePM.addPass(InstSimplifyPass());\n\n  // This hoists/decomposes div/rem ops. It should run after other sink/hoist\n  // passes to avoid re-sinking, but before SimplifyCFG because it can allow\n  // flattening of blocks.\n  OptimizePM.addPass(DivRemPairsPass());\n\n  // LoopSink (and other loop passes since the last simplifyCFG) might have\n  // resulted in single-entry-single-exit or empty blocks. Clean up the CFG.\n  OptimizePM.addPass(SimplifyCFGPass());\n\n  // Optimize PHIs by speculating around them when profitable. Note that this\n  // pass needs to be run after any PRE or similar pass as it is essentially\n  // inserting redundancies into the program. This even includes SimplifyCFG.\n  OptimizePM.addPass(SpeculateAroundPHIsPass());\n\n  if (PTO.Coroutines)\n    OptimizePM.addPass(CoroCleanupPass());\n\n  // Add the core optimizing pipeline.\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(OptimizePM)));\n\n  for (auto &C : OptimizerLastEPCallbacks)\n    C(MPM, Level);\n\n  if (PTO.CallGraphProfile)\n    MPM.addPass(CGProfilePass());\n\n  // Now we need to do some global optimization transforms.\n  // FIXME: It would seem like these should come first in the optimization\n  // pipeline and maybe be the bottom of the canonicalization pipeline? Weird\n  // ordering here.\n  MPM.addPass(GlobalDCEPass());\n  MPM.addPass(ConstantMergePass());\n\n  return MPM;\n}\n\nModulePassManager\nPassBuilder::buildPerModuleDefaultPipeline(OptimizationLevel Level,\n                                           bool LTOPreLink) {\n  assert(Level != OptimizationLevel::O0 &&\n         \"Must request optimizations for the default pipeline!\");\n\n  ModulePassManager MPM(DebugLogging);\n\n  // Convert @llvm.global.annotations to !annotation metadata.\n  MPM.addPass(Annotation2MetadataPass());\n\n  // Force any function attributes we want the rest of the pipeline to observe.\n  MPM.addPass(ForceFunctionAttrsPass());\n\n  // Apply module pipeline start EP callback.\n  for (auto &C : PipelineStartEPCallbacks)\n    C(MPM, Level);\n\n  if (PGOOpt && PGOOpt->DebugInfoForProfiling)\n    MPM.addPass(createModuleToFunctionPassAdaptor(AddDiscriminatorsPass()));\n\n  // Add the core simplification pipeline.\n  MPM.addPass(buildModuleSimplificationPipeline(\n      Level, LTOPreLink ? ThinOrFullLTOPhase::FullLTOPreLink\n                        : ThinOrFullLTOPhase::None));\n\n  // Now add the optimization pipeline.\n  MPM.addPass(buildModuleOptimizationPipeline(Level, LTOPreLink));\n\n  if (PGOOpt && PGOOpt->PseudoProbeForProfiling)\n    MPM.addPass(PseudoProbeUpdatePass());\n\n  // Emit annotation remarks.\n  addAnnotationRemarksPass(MPM);\n\n  if (LTOPreLink)\n    addRequiredLTOPreLinkPasses(MPM);\n\n  return MPM;\n}\n\nModulePassManager\nPassBuilder::buildThinLTOPreLinkDefaultPipeline(OptimizationLevel Level) {\n  assert(Level != OptimizationLevel::O0 &&\n         \"Must request optimizations for the default pipeline!\");\n\n  ModulePassManager MPM(DebugLogging);\n\n  // Convert @llvm.global.annotations to !annotation metadata.\n  MPM.addPass(Annotation2MetadataPass());\n\n  // Force any function attributes we want the rest of the pipeline to observe.\n  MPM.addPass(ForceFunctionAttrsPass());\n\n  if (PGOOpt && PGOOpt->DebugInfoForProfiling)\n    MPM.addPass(createModuleToFunctionPassAdaptor(AddDiscriminatorsPass()));\n\n  // Apply module pipeline start EP callback.\n  for (auto &C : PipelineStartEPCallbacks)\n    C(MPM, Level);\n\n  // If we are planning to perform ThinLTO later, we don't bloat the code with\n  // unrolling/vectorization/... now. Just simplify the module as much as we\n  // can.\n  MPM.addPass(buildModuleSimplificationPipeline(\n      Level, ThinOrFullLTOPhase::ThinLTOPreLink));\n\n  // Run partial inlining pass to partially inline functions that have\n  // large bodies.\n  // FIXME: It isn't clear whether this is really the right place to run this\n  // in ThinLTO. Because there is another canonicalization and simplification\n  // phase that will run after the thin link, running this here ends up with\n  // less information than will be available later and it may grow functions in\n  // ways that aren't beneficial.\n  if (RunPartialInlining)\n    MPM.addPass(PartialInlinerPass());\n\n  // Reduce the size of the IR as much as possible.\n  MPM.addPass(GlobalOptPass());\n\n  // Module simplification splits coroutines, but does not fully clean up\n  // coroutine intrinsics. To ensure ThinLTO optimization passes don't trip up\n  // on these, we schedule the cleanup here.\n  if (PTO.Coroutines)\n    MPM.addPass(createModuleToFunctionPassAdaptor(CoroCleanupPass()));\n\n  if (PGOOpt && PGOOpt->PseudoProbeForProfiling)\n    MPM.addPass(PseudoProbeUpdatePass());\n\n  // Handle OptimizerLastEPCallbacks added by clang on PreLink. Actual\n  // optimization is going to be done in PostLink stage, but clang can't\n  // add callbacks there in case of in-process ThinLTO called by linker.\n  for (auto &C : OptimizerLastEPCallbacks)\n    C(MPM, Level);\n\n  // Emit annotation remarks.\n  addAnnotationRemarksPass(MPM);\n\n  addRequiredLTOPreLinkPasses(MPM);\n\n  return MPM;\n}\n\nModulePassManager PassBuilder::buildThinLTODefaultPipeline(\n    OptimizationLevel Level, const ModuleSummaryIndex *ImportSummary) {\n  ModulePassManager MPM(DebugLogging);\n\n  // Convert @llvm.global.annotations to !annotation metadata.\n  MPM.addPass(Annotation2MetadataPass());\n\n  if (ImportSummary) {\n    // These passes import type identifier resolutions for whole-program\n    // devirtualization and CFI. They must run early because other passes may\n    // disturb the specific instruction patterns that these passes look for,\n    // creating dependencies on resolutions that may not appear in the summary.\n    //\n    // For example, GVN may transform the pattern assume(type.test) appearing in\n    // two basic blocks into assume(phi(type.test, type.test)), which would\n    // transform a dependency on a WPD resolution into a dependency on a type\n    // identifier resolution for CFI.\n    //\n    // Also, WPD has access to more precise information than ICP and can\n    // devirtualize more effectively, so it should operate on the IR first.\n    //\n    // The WPD and LowerTypeTest passes need to run at -O0 to lower type\n    // metadata and intrinsics.\n    MPM.addPass(WholeProgramDevirtPass(nullptr, ImportSummary));\n    MPM.addPass(LowerTypeTestsPass(nullptr, ImportSummary));\n  }\n\n  if (Level == OptimizationLevel::O0) {\n    // Run a second time to clean up any type tests left behind by WPD for use\n    // in ICP.\n    MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));\n    // Drop available_externally and unreferenced globals. This is necessary\n    // with ThinLTO in order to avoid leaving undefined references to dead\n    // globals in the object file.\n    MPM.addPass(EliminateAvailableExternallyPass());\n    MPM.addPass(GlobalDCEPass());\n    return MPM;\n  }\n\n  // Force any function attributes we want the rest of the pipeline to observe.\n  MPM.addPass(ForceFunctionAttrsPass());\n\n  // Add the core simplification pipeline.\n  MPM.addPass(buildModuleSimplificationPipeline(\n      Level, ThinOrFullLTOPhase::ThinLTOPostLink));\n\n  // Now add the optimization pipeline.\n  MPM.addPass(buildModuleOptimizationPipeline(Level));\n\n  // Emit annotation remarks.\n  addAnnotationRemarksPass(MPM);\n\n  return MPM;\n}\n\nModulePassManager\nPassBuilder::buildLTOPreLinkDefaultPipeline(OptimizationLevel Level) {\n  assert(Level != OptimizationLevel::O0 &&\n         \"Must request optimizations for the default pipeline!\");\n  // FIXME: We should use a customized pre-link pipeline!\n  return buildPerModuleDefaultPipeline(Level,\n                                       /* LTOPreLink */ true);\n}\n\nModulePassManager\nPassBuilder::buildLTODefaultPipeline(OptimizationLevel Level,\n                                     ModuleSummaryIndex *ExportSummary) {\n  ModulePassManager MPM(DebugLogging);\n\n  // Convert @llvm.global.annotations to !annotation metadata.\n  MPM.addPass(Annotation2MetadataPass());\n\n  if (Level == OptimizationLevel::O0) {\n    // The WPD and LowerTypeTest passes need to run at -O0 to lower type\n    // metadata and intrinsics.\n    MPM.addPass(WholeProgramDevirtPass(ExportSummary, nullptr));\n    MPM.addPass(LowerTypeTestsPass(ExportSummary, nullptr));\n    // Run a second time to clean up any type tests left behind by WPD for use\n    // in ICP.\n    MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));\n\n    // Emit annotation remarks.\n    addAnnotationRemarksPass(MPM);\n\n    return MPM;\n  }\n\n  if (PGOOpt && PGOOpt->Action == PGOOptions::SampleUse) {\n    // Load sample profile before running the LTO optimization pipeline.\n    MPM.addPass(SampleProfileLoaderPass(PGOOpt->ProfileFile,\n                                        PGOOpt->ProfileRemappingFile,\n                                        ThinOrFullLTOPhase::FullLTOPostLink));\n    // Cache ProfileSummaryAnalysis once to avoid the potential need to insert\n    // RequireAnalysisPass for PSI before subsequent non-module passes.\n    MPM.addPass(RequireAnalysisPass<ProfileSummaryAnalysis, Module>());\n  }\n\n  // Remove unused virtual tables to improve the quality of code generated by\n  // whole-program devirtualization and bitset lowering.\n  MPM.addPass(GlobalDCEPass());\n\n  // Force any function attributes we want the rest of the pipeline to observe.\n  MPM.addPass(ForceFunctionAttrsPass());\n\n  // Do basic inference of function attributes from known properties of system\n  // libraries and other oracles.\n  MPM.addPass(InferFunctionAttrsPass());\n\n  if (Level.getSpeedupLevel() > 1) {\n    FunctionPassManager EarlyFPM(DebugLogging);\n    EarlyFPM.addPass(CallSiteSplittingPass());\n    MPM.addPass(createModuleToFunctionPassAdaptor(std::move(EarlyFPM)));\n\n    // Indirect call promotion. This should promote all the targets that are\n    // left by the earlier promotion pass that promotes intra-module targets.\n    // This two-step promotion is to save the compile time. For LTO, it should\n    // produce the same result as if we only do promotion here.\n    MPM.addPass(PGOIndirectCallPromotion(\n        true /* InLTO */, PGOOpt && PGOOpt->Action == PGOOptions::SampleUse));\n    // Propagate constants at call sites into the functions they call.  This\n    // opens opportunities for globalopt (and inlining) by substituting function\n    // pointers passed as arguments to direct uses of functions.\n    MPM.addPass(IPSCCPPass());\n\n    // Attach metadata to indirect call sites indicating the set of functions\n    // they may target at run-time. This should follow IPSCCP.\n    MPM.addPass(CalledValuePropagationPass());\n  }\n\n  // Now deduce any function attributes based in the current code.\n  MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(\n              PostOrderFunctionAttrsPass()));\n\n  // Do RPO function attribute inference across the module to forward-propagate\n  // attributes where applicable.\n  // FIXME: Is this really an optimization rather than a canonicalization?\n  MPM.addPass(ReversePostOrderFunctionAttrsPass());\n\n  // Use in-range annotations on GEP indices to split globals where beneficial.\n  MPM.addPass(GlobalSplitPass());\n\n  // Run whole program optimization of virtual call when the list of callees\n  // is fixed.\n  MPM.addPass(WholeProgramDevirtPass(ExportSummary, nullptr));\n\n  // Stop here at -O1.\n  if (Level == OptimizationLevel::O1) {\n    // The LowerTypeTestsPass needs to run to lower type metadata and the\n    // type.test intrinsics. The pass does nothing if CFI is disabled.\n    MPM.addPass(LowerTypeTestsPass(ExportSummary, nullptr));\n    // Run a second time to clean up any type tests left behind by WPD for use\n    // in ICP (which is performed earlier than this in the regular LTO\n    // pipeline).\n    MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));\n\n    // Emit annotation remarks.\n    addAnnotationRemarksPass(MPM);\n\n    return MPM;\n  }\n\n  // Optimize globals to try and fold them into constants.\n  MPM.addPass(GlobalOptPass());\n\n  // Promote any localized globals to SSA registers.\n  MPM.addPass(createModuleToFunctionPassAdaptor(PromotePass()));\n\n  // Linking modules together can lead to duplicate global constant, only\n  // keep one copy of each constant.\n  MPM.addPass(ConstantMergePass());\n\n  // Remove unused arguments from functions.\n  MPM.addPass(DeadArgumentEliminationPass());\n\n  // Reduce the code after globalopt and ipsccp.  Both can open up significant\n  // simplification opportunities, and both can propagate functions through\n  // function pointers.  When this happens, we often have to resolve varargs\n  // calls, etc, so let instcombine do this.\n  FunctionPassManager PeepholeFPM(DebugLogging);\n  if (Level == OptimizationLevel::O3)\n    PeepholeFPM.addPass(AggressiveInstCombinePass());\n  PeepholeFPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(PeepholeFPM, Level);\n\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(PeepholeFPM)));\n\n  // Note: historically, the PruneEH pass was run first to deduce nounwind and\n  // generally clean up exception handling overhead. It isn't clear this is\n  // valuable as the inliner doesn't currently care whether it is inlining an\n  // invoke or a call.\n  // Run the inliner now.\n  MPM.addPass(ModuleInlinerWrapperPass(getInlineParamsFromOptLevel(Level),\n                                       DebugLogging));\n\n  // Optimize globals again after we ran the inliner.\n  MPM.addPass(GlobalOptPass());\n\n  // Garbage collect dead functions.\n  // FIXME: Add ArgumentPromotion pass after once it's ported.\n  MPM.addPass(GlobalDCEPass());\n\n  FunctionPassManager FPM(DebugLogging);\n  // The IPO Passes may leave cruft around. Clean up after them.\n  FPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(FPM, Level);\n\n  FPM.addPass(JumpThreadingPass(/*InsertFreezeWhenUnfoldingSelect*/ true));\n\n  // Do a post inline PGO instrumentation and use pass. This is a context\n  // sensitive PGO pass.\n  if (PGOOpt) {\n    if (PGOOpt->CSAction == PGOOptions::CSIRInstr)\n      addPGOInstrPasses(MPM, Level, /* RunProfileGen */ true,\n                        /* IsCS */ true, PGOOpt->CSProfileGenFile,\n                        PGOOpt->ProfileRemappingFile);\n    else if (PGOOpt->CSAction == PGOOptions::CSIRUse)\n      addPGOInstrPasses(MPM, Level, /* RunProfileGen */ false,\n                        /* IsCS */ true, PGOOpt->ProfileFile,\n                        PGOOpt->ProfileRemappingFile);\n  }\n\n  // Break up allocas\n  FPM.addPass(SROA());\n\n  // LTO provides additional opportunities for tailcall elimination due to\n  // link-time inlining, and visibility of nocapture attribute.\n  FPM.addPass(TailCallElimPass());\n\n  // Run a few AA driver optimizations here and now to cleanup the code.\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));\n\n  MPM.addPass(\n      createModuleToPostOrderCGSCCPassAdaptor(PostOrderFunctionAttrsPass()));\n  // FIXME: here we run IP alias analysis in the legacy PM.\n\n  FunctionPassManager MainFPM;\n\n  MainFPM.addPass(createFunctionToLoopPassAdaptor(\n      LICMPass(PTO.LicmMssaOptCap, PTO.LicmMssaNoAccForPromotionCap)));\n\n  if (RunNewGVN)\n    MainFPM.addPass(NewGVNPass());\n  else\n    MainFPM.addPass(GVN());\n\n  // Remove dead memcpy()'s.\n  MainFPM.addPass(MemCpyOptPass());\n\n  // Nuke dead stores.\n  MainFPM.addPass(DSEPass());\n  MainFPM.addPass(MergedLoadStoreMotionPass());\n\n  // More loops are countable; try to optimize them.\n  if (EnableLoopFlatten && Level.getSpeedupLevel() > 1)\n    MainFPM.addPass(LoopFlattenPass());\n\n  if (EnableConstraintElimination)\n    MainFPM.addPass(ConstraintEliminationPass());\n\n  LoopPassManager LPM(DebugLogging);\n  LPM.addPass(IndVarSimplifyPass());\n  LPM.addPass(LoopDeletionPass());\n  // FIXME: Add loop interchange.\n\n  // Unroll small loops and perform peeling.\n  LPM.addPass(LoopFullUnrollPass(Level.getSpeedupLevel(),\n                                 /* OnlyWhenForced= */ !PTO.LoopUnrolling,\n                                 PTO.ForgetAllSCEVInLoopUnroll));\n  // The loop passes in LPM (LoopFullUnrollPass) do not preserve MemorySSA.\n  // *All* loop passes must preserve it, in order to be able to use it.\n  MainFPM.addPass(createFunctionToLoopPassAdaptor(\n      std::move(LPM), /*UseMemorySSA=*/false, /*UseBlockFrequencyInfo=*/true,\n      DebugLogging));\n\n  MainFPM.addPass(LoopDistributePass());\n  MainFPM.addPass(LoopVectorizePass(\n      LoopVectorizeOptions(!PTO.LoopInterleaving, !PTO.LoopVectorization)));\n  // The vectorizer may have significantly shortened a loop body; unroll again.\n  MainFPM.addPass(LoopUnrollPass(LoopUnrollOptions(\n      Level.getSpeedupLevel(), /*OnlyWhenForced=*/!PTO.LoopUnrolling,\n      PTO.ForgetAllSCEVInLoopUnroll)));\n\n  MainFPM.addPass(WarnMissedTransformationsPass());\n\n  MainFPM.addPass(InstCombinePass());\n  MainFPM.addPass(SimplifyCFGPass(SimplifyCFGOptions().hoistCommonInsts(true)));\n  MainFPM.addPass(SCCPPass());\n  MainFPM.addPass(InstCombinePass());\n  MainFPM.addPass(BDCEPass());\n\n  // More scalar chains could be vectorized due to more alias information\n  if (PTO.SLPVectorization) {\n    MainFPM.addPass(SLPVectorizerPass());\n    if (Level.getSpeedupLevel() > 1 && ExtraVectorizerPasses) {\n      MainFPM.addPass(EarlyCSEPass());\n    }\n  }\n\n  MainFPM.addPass(VectorCombinePass()); // Clean up partial vectorization.\n\n  // After vectorization, assume intrinsics may tell us more about pointer\n  // alignments.\n  MainFPM.addPass(AlignmentFromAssumptionsPass());\n\n  // FIXME: Conditionally run LoadCombine here, after it's ported\n  // (in case we still have this pass, given its questionable usefulness).\n\n  MainFPM.addPass(InstCombinePass());\n  invokePeepholeEPCallbacks(MainFPM, Level);\n  MainFPM.addPass(JumpThreadingPass(/*InsertFreezeWhenUnfoldingSelect*/ true));\n  MPM.addPass(createModuleToFunctionPassAdaptor(std::move(MainFPM)));\n\n  // Create a function that performs CFI checks for cross-DSO calls with\n  // targets in the current module.\n  MPM.addPass(CrossDSOCFIPass());\n\n  // Lower type metadata and the type.test intrinsic. This pass supports\n  // clang's control flow integrity mechanisms (-fsanitize=cfi*) and needs\n  // to be run at link time if CFI is enabled. This pass does nothing if\n  // CFI is disabled.\n  MPM.addPass(LowerTypeTestsPass(ExportSummary, nullptr));\n  // Run a second time to clean up any type tests left behind by WPD for use\n  // in ICP (which is performed earlier than this in the regular LTO pipeline).\n  MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));\n\n  // Enable splitting late in the FullLTO post-link pipeline. This is done in\n  // the same stage in the old pass manager (\\ref addLateLTOOptimizationPasses).\n  if (EnableHotColdSplit)\n    MPM.addPass(HotColdSplittingPass());\n\n  // Add late LTO optimization passes.\n  // Delete basic blocks, which optimization passes may have killed.\n  MPM.addPass(createModuleToFunctionPassAdaptor(\n      SimplifyCFGPass(SimplifyCFGOptions().hoistCommonInsts(true))));\n\n  // Drop bodies of available eternally objects to improve GlobalDCE.\n  MPM.addPass(EliminateAvailableExternallyPass());\n\n  // Now that we have optimized the program, discard unreachable functions.\n  MPM.addPass(GlobalDCEPass());\n\n  if (PTO.MergeFunctions)\n    MPM.addPass(MergeFunctionsPass());\n\n  // Emit annotation remarks.\n  addAnnotationRemarksPass(MPM);\n\n  return MPM;\n}\n\nModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,\n                                                      bool LTOPreLink) {\n  assert(Level == OptimizationLevel::O0 &&\n         \"buildO0DefaultPipeline should only be used with O0\");\n\n  ModulePassManager MPM(DebugLogging);\n\n  if (PGOOpt && (PGOOpt->Action == PGOOptions::IRInstr ||\n                 PGOOpt->Action == PGOOptions::IRUse))\n    addPGOInstrPassesForO0(\n        MPM,\n        /* RunProfileGen */ (PGOOpt->Action == PGOOptions::IRInstr),\n        /* IsCS */ false, PGOOpt->ProfileFile, PGOOpt->ProfileRemappingFile);\n\n  for (auto &C : PipelineStartEPCallbacks)\n    C(MPM, Level);\n  for (auto &C : PipelineEarlySimplificationEPCallbacks)\n    C(MPM, Level);\n\n  // Build a minimal pipeline based on the semantics required by LLVM,\n  // which is just that always inlining occurs. Further, disable generating\n  // lifetime intrinsics to avoid enabling further optimizations during\n  // code generation.\n  // However, we need to insert lifetime intrinsics to avoid invalid access\n  // caused by multithreaded coroutines.\n  MPM.addPass(AlwaysInlinerPass(\n      /*InsertLifetimeIntrinsics=*/PTO.Coroutines));\n\n  if (PTO.MergeFunctions)\n    MPM.addPass(MergeFunctionsPass());\n\n  if (EnableMatrix)\n    MPM.addPass(\n        createModuleToFunctionPassAdaptor(LowerMatrixIntrinsicsPass(true)));\n\n  if (!CGSCCOptimizerLateEPCallbacks.empty()) {\n    CGSCCPassManager CGPM(DebugLogging);\n    for (auto &C : CGSCCOptimizerLateEPCallbacks)\n      C(CGPM, Level);\n    if (!CGPM.isEmpty())\n      MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(std::move(CGPM)));\n  }\n  if (!LateLoopOptimizationsEPCallbacks.empty()) {\n    LoopPassManager LPM(DebugLogging);\n    for (auto &C : LateLoopOptimizationsEPCallbacks)\n      C(LPM, Level);\n    if (!LPM.isEmpty()) {\n      MPM.addPass(createModuleToFunctionPassAdaptor(\n          createFunctionToLoopPassAdaptor(std::move(LPM))));\n    }\n  }\n  if (!LoopOptimizerEndEPCallbacks.empty()) {\n    LoopPassManager LPM(DebugLogging);\n    for (auto &C : LoopOptimizerEndEPCallbacks)\n      C(LPM, Level);\n    if (!LPM.isEmpty()) {\n      MPM.addPass(createModuleToFunctionPassAdaptor(\n          createFunctionToLoopPassAdaptor(std::move(LPM))));\n    }\n  }\n  if (!ScalarOptimizerLateEPCallbacks.empty()) {\n    FunctionPassManager FPM(DebugLogging);\n    for (auto &C : ScalarOptimizerLateEPCallbacks)\n      C(FPM, Level);\n    if (!FPM.isEmpty())\n      MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));\n  }\n  if (!VectorizerStartEPCallbacks.empty()) {\n    FunctionPassManager FPM(DebugLogging);\n    for (auto &C : VectorizerStartEPCallbacks)\n      C(FPM, Level);\n    if (!FPM.isEmpty())\n      MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));\n  }\n\n  if (PTO.Coroutines) {\n    MPM.addPass(createModuleToFunctionPassAdaptor(CoroEarlyPass()));\n\n    CGSCCPassManager CGPM(DebugLogging);\n    CGPM.addPass(CoroSplitPass());\n    CGPM.addPass(createCGSCCToFunctionPassAdaptor(CoroElidePass()));\n    MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(std::move(CGPM)));\n\n    MPM.addPass(createModuleToFunctionPassAdaptor(CoroCleanupPass()));\n  }\n\n  for (auto &C : OptimizerLastEPCallbacks)\n    C(MPM, Level);\n\n  if (LTOPreLink)\n    addRequiredLTOPreLinkPasses(MPM);\n\n  return MPM;\n}\n\nAAManager PassBuilder::buildDefaultAAPipeline() {\n  AAManager AA;\n\n  // The order in which these are registered determines their priority when\n  // being queried.\n\n  // First we register the basic alias analysis that provides the majority of\n  // per-function local AA logic. This is a stateless, on-demand local set of\n  // AA techniques.\n  AA.registerFunctionAnalysis<BasicAA>();\n\n  // Next we query fast, specialized alias analyses that wrap IR-embedded\n  // information about aliasing.\n  AA.registerFunctionAnalysis<ScopedNoAliasAA>();\n  AA.registerFunctionAnalysis<TypeBasedAA>();\n\n  // Add support for querying global aliasing information when available.\n  // Because the `AAManager` is a function analysis and `GlobalsAA` is a module\n  // analysis, all that the `AAManager` can do is query for any *cached*\n  // results from `GlobalsAA` through a readonly proxy.\n  AA.registerModuleAnalysis<GlobalsAA>();\n\n  // Add target-specific alias analyses.\n  if (TM)\n    TM->registerDefaultAliasAnalyses(AA);\n\n  return AA;\n}\n\nstatic Optional<int> parseRepeatPassName(StringRef Name) {\n  if (!Name.consume_front(\"repeat<\") || !Name.consume_back(\">\"))\n    return None;\n  int Count;\n  if (Name.getAsInteger(0, Count) || Count <= 0)\n    return None;\n  return Count;\n}\n\nstatic Optional<int> parseDevirtPassName(StringRef Name) {\n  if (!Name.consume_front(\"devirt<\") || !Name.consume_back(\">\"))\n    return None;\n  int Count;\n  if (Name.getAsInteger(0, Count) || Count < 0)\n    return None;\n  return Count;\n}\n\nstatic bool checkParametrizedPassName(StringRef Name, StringRef PassName) {\n  if (!Name.consume_front(PassName))\n    return false;\n  // normal pass name w/o parameters == default parameters\n  if (Name.empty())\n    return true;\n  return Name.startswith(\"<\") && Name.endswith(\">\");\n}\n\nnamespace {\n\n/// This performs customized parsing of pass name with parameters.\n///\n/// We do not need parametrization of passes in textual pipeline very often,\n/// yet on a rare occasion ability to specify parameters right there can be\n/// useful.\n///\n/// \\p Name - parameterized specification of a pass from a textual pipeline\n/// is a string in a form of :\n///      PassName '<' parameter-list '>'\n///\n/// Parameter list is being parsed by the parser callable argument, \\p Parser,\n/// It takes a string-ref of parameters and returns either StringError or a\n/// parameter list in a form of a custom parameters type, all wrapped into\n/// Expected<> template class.\n///\ntemplate <typename ParametersParseCallableT>\nauto parsePassParameters(ParametersParseCallableT &&Parser, StringRef Name,\n                         StringRef PassName) -> decltype(Parser(StringRef{})) {\n  using ParametersT = typename decltype(Parser(StringRef{}))::value_type;\n\n  StringRef Params = Name;\n  if (!Params.consume_front(PassName)) {\n    assert(false &&\n           \"unable to strip pass name from parametrized pass specification\");\n  }\n  if (Params.empty())\n    return ParametersT{};\n  if (!Params.consume_front(\"<\") || !Params.consume_back(\">\")) {\n    assert(false && \"invalid format for parametrized pass name\");\n  }\n\n  Expected<ParametersT> Result = Parser(Params);\n  assert((Result || Result.template errorIsA<StringError>()) &&\n         \"Pass parameter parser can only return StringErrors.\");\n  return Result;\n}\n\n/// Parser of parameters for LoopUnroll pass.\nExpected<LoopUnrollOptions> parseLoopUnrollOptions(StringRef Params) {\n  LoopUnrollOptions UnrollOpts;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n    int OptLevel = StringSwitch<int>(ParamName)\n                       .Case(\"O0\", 0)\n                       .Case(\"O1\", 1)\n                       .Case(\"O2\", 2)\n                       .Case(\"O3\", 3)\n                       .Default(-1);\n    if (OptLevel >= 0) {\n      UnrollOpts.setOptLevel(OptLevel);\n      continue;\n    }\n    if (ParamName.consume_front(\"full-unroll-max=\")) {\n      int Count;\n      if (ParamName.getAsInteger(0, Count))\n        return make_error<StringError>(\n            formatv(\"invalid LoopUnrollPass parameter '{0}' \", ParamName).str(),\n            inconvertibleErrorCode());\n      UnrollOpts.setFullUnrollMaxCount(Count);\n      continue;\n    }\n\n    bool Enable = !ParamName.consume_front(\"no-\");\n    if (ParamName == \"partial\") {\n      UnrollOpts.setPartial(Enable);\n    } else if (ParamName == \"peeling\") {\n      UnrollOpts.setPeeling(Enable);\n    } else if (ParamName == \"profile-peeling\") {\n      UnrollOpts.setProfileBasedPeeling(Enable);\n    } else if (ParamName == \"runtime\") {\n      UnrollOpts.setRuntime(Enable);\n    } else if (ParamName == \"upperbound\") {\n      UnrollOpts.setUpperBound(Enable);\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid LoopUnrollPass parameter '{0}' \", ParamName).str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return UnrollOpts;\n}\n\nExpected<MemorySanitizerOptions> parseMSanPassOptions(StringRef Params) {\n  MemorySanitizerOptions Result;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    if (ParamName == \"recover\") {\n      Result.Recover = true;\n    } else if (ParamName == \"kernel\") {\n      Result.Kernel = true;\n    } else if (ParamName.consume_front(\"track-origins=\")) {\n      if (ParamName.getAsInteger(0, Result.TrackOrigins))\n        return make_error<StringError>(\n            formatv(\"invalid argument to MemorySanitizer pass track-origins \"\n                    \"parameter: '{0}' \",\n                    ParamName)\n                .str(),\n            inconvertibleErrorCode());\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid MemorySanitizer pass parameter '{0}' \", ParamName)\n              .str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Result;\n}\n\n/// Parser of parameters for SimplifyCFG pass.\nExpected<SimplifyCFGOptions> parseSimplifyCFGOptions(StringRef Params) {\n  SimplifyCFGOptions Result;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    bool Enable = !ParamName.consume_front(\"no-\");\n    if (ParamName == \"forward-switch-cond\") {\n      Result.forwardSwitchCondToPhi(Enable);\n    } else if (ParamName == \"switch-to-lookup\") {\n      Result.convertSwitchToLookupTable(Enable);\n    } else if (ParamName == \"keep-loops\") {\n      Result.needCanonicalLoops(Enable);\n    } else if (ParamName == \"hoist-common-insts\") {\n      Result.hoistCommonInsts(Enable);\n    } else if (ParamName == \"sink-common-insts\") {\n      Result.sinkCommonInsts(Enable);\n    } else if (Enable && ParamName.consume_front(\"bonus-inst-threshold=\")) {\n      APInt BonusInstThreshold;\n      if (ParamName.getAsInteger(0, BonusInstThreshold))\n        return make_error<StringError>(\n            formatv(\"invalid argument to SimplifyCFG pass bonus-threshold \"\n                    \"parameter: '{0}' \",\n                    ParamName).str(),\n            inconvertibleErrorCode());\n      Result.bonusInstThreshold(BonusInstThreshold.getSExtValue());\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid SimplifyCFG pass parameter '{0}' \", ParamName).str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Result;\n}\n\n/// Parser of parameters for LoopVectorize pass.\nExpected<LoopVectorizeOptions> parseLoopVectorizeOptions(StringRef Params) {\n  LoopVectorizeOptions Opts;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    bool Enable = !ParamName.consume_front(\"no-\");\n    if (ParamName == \"interleave-forced-only\") {\n      Opts.setInterleaveOnlyWhenForced(Enable);\n    } else if (ParamName == \"vectorize-forced-only\") {\n      Opts.setVectorizeOnlyWhenForced(Enable);\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid LoopVectorize parameter '{0}' \", ParamName).str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Opts;\n}\n\nExpected<bool> parseLoopUnswitchOptions(StringRef Params) {\n  bool Result = false;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    bool Enable = !ParamName.consume_front(\"no-\");\n    if (ParamName == \"nontrivial\") {\n      Result = Enable;\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid LoopUnswitch pass parameter '{0}' \", ParamName)\n              .str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Result;\n}\n\nExpected<bool> parseMergedLoadStoreMotionOptions(StringRef Params) {\n  bool Result = false;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    bool Enable = !ParamName.consume_front(\"no-\");\n    if (ParamName == \"split-footer-bb\") {\n      Result = Enable;\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid MergedLoadStoreMotion pass parameter '{0}' \",\n                  ParamName)\n              .str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Result;\n}\n\nExpected<GVNOptions> parseGVNOptions(StringRef Params) {\n  GVNOptions Result;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    bool Enable = !ParamName.consume_front(\"no-\");\n    if (ParamName == \"pre\") {\n      Result.setPRE(Enable);\n    } else if (ParamName == \"load-pre\") {\n      Result.setLoadPRE(Enable);\n    } else if (ParamName == \"split-backedge-load-pre\") {\n      Result.setLoadPRESplitBackedge(Enable);\n    } else if (ParamName == \"memdep\") {\n      Result.setMemDep(Enable);\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid GVN pass parameter '{0}' \", ParamName).str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Result;\n}\n\nExpected<StackLifetime::LivenessType>\nparseStackLifetimeOptions(StringRef Params) {\n  StackLifetime::LivenessType Result = StackLifetime::LivenessType::May;\n  while (!Params.empty()) {\n    StringRef ParamName;\n    std::tie(ParamName, Params) = Params.split(';');\n\n    if (ParamName == \"may\") {\n      Result = StackLifetime::LivenessType::May;\n    } else if (ParamName == \"must\") {\n      Result = StackLifetime::LivenessType::Must;\n    } else {\n      return make_error<StringError>(\n          formatv(\"invalid StackLifetime parameter '{0}' \", ParamName).str(),\n          inconvertibleErrorCode());\n    }\n  }\n  return Result;\n}\n\n} // namespace\n\n/// Tests whether a pass name starts with a valid prefix for a default pipeline\n/// alias.\nstatic bool startsWithDefaultPipelineAliasPrefix(StringRef Name) {\n  return Name.startswith(\"default\") || Name.startswith(\"thinlto\") ||\n         Name.startswith(\"lto\");\n}\n\n/// Tests whether registered callbacks will accept a given pass name.\n///\n/// When parsing a pipeline text, the type of the outermost pipeline may be\n/// omitted, in which case the type is automatically determined from the first\n/// pass name in the text. This may be a name that is handled through one of the\n/// callbacks. We check this through the oridinary parsing callbacks by setting\n/// up a dummy PassManager in order to not force the client to also handle this\n/// type of query.\ntemplate <typename PassManagerT, typename CallbacksT>\nstatic bool callbacksAcceptPassName(StringRef Name, CallbacksT &Callbacks) {\n  if (!Callbacks.empty()) {\n    PassManagerT DummyPM;\n    for (auto &CB : Callbacks)\n      if (CB(Name, DummyPM, {}))\n        return true;\n  }\n  return false;\n}\n\ntemplate <typename CallbacksT>\nstatic bool isModulePassName(StringRef Name, CallbacksT &Callbacks) {\n  // Manually handle aliases for pre-configured pipeline fragments.\n  if (startsWithDefaultPipelineAliasPrefix(Name))\n    return DefaultAliasRegex.match(Name);\n\n  // Explicitly handle pass manager names.\n  if (Name == \"module\")\n    return true;\n  if (Name == \"cgscc\")\n    return true;\n  if (Name == \"function\")\n    return true;\n\n  // Explicitly handle custom-parsed pass names.\n  if (parseRepeatPassName(Name))\n    return true;\n\n#define MODULE_PASS(NAME, CREATE_PASS)                                         \\\n  if (Name == NAME)                                                            \\\n    return true;\n#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\\n  if (Name == \"require<\" NAME \">\" || Name == \"invalidate<\" NAME \">\")           \\\n    return true;\n#include \"PassRegistry.def\"\n\n  return callbacksAcceptPassName<ModulePassManager>(Name, Callbacks);\n}\n\ntemplate <typename CallbacksT>\nstatic bool isCGSCCPassName(StringRef Name, CallbacksT &Callbacks) {\n  // Explicitly handle pass manager names.\n  if (Name == \"cgscc\")\n    return true;\n  if (Name == \"function\")\n    return true;\n\n  // Explicitly handle custom-parsed pass names.\n  if (parseRepeatPassName(Name))\n    return true;\n  if (parseDevirtPassName(Name))\n    return true;\n\n#define CGSCC_PASS(NAME, CREATE_PASS)                                          \\\n  if (Name == NAME)                                                            \\\n    return true;\n#define CGSCC_ANALYSIS(NAME, CREATE_PASS)                                      \\\n  if (Name == \"require<\" NAME \">\" || Name == \"invalidate<\" NAME \">\")           \\\n    return true;\n#include \"PassRegistry.def\"\n\n  return callbacksAcceptPassName<CGSCCPassManager>(Name, Callbacks);\n}\n\ntemplate <typename CallbacksT>\nstatic bool isFunctionPassName(StringRef Name, CallbacksT &Callbacks) {\n  // Explicitly handle pass manager names.\n  if (Name == \"function\")\n    return true;\n  if (Name == \"loop\" || Name == \"loop-mssa\")\n    return true;\n\n  // Explicitly handle custom-parsed pass names.\n  if (parseRepeatPassName(Name))\n    return true;\n\n#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\\n  if (Name == NAME)                                                            \\\n    return true;\n#define FUNCTION_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                   \\\n  if (checkParametrizedPassName(Name, NAME))                                   \\\n    return true;\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS)                                   \\\n  if (Name == \"require<\" NAME \">\" || Name == \"invalidate<\" NAME \">\")           \\\n    return true;\n#include \"PassRegistry.def\"\n\n  return callbacksAcceptPassName<FunctionPassManager>(Name, Callbacks);\n}\n\ntemplate <typename CallbacksT>\nstatic bool isLoopPassName(StringRef Name, CallbacksT &Callbacks) {\n  // Explicitly handle pass manager names.\n  if (Name == \"loop\" || Name == \"loop-mssa\")\n    return true;\n\n  // Explicitly handle custom-parsed pass names.\n  if (parseRepeatPassName(Name))\n    return true;\n\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\\n  if (Name == NAME)                                                            \\\n    return true;\n#define LOOP_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                       \\\n  if (checkParametrizedPassName(Name, NAME))                                   \\\n    return true;\n#define LOOP_ANALYSIS(NAME, CREATE_PASS)                                       \\\n  if (Name == \"require<\" NAME \">\" || Name == \"invalidate<\" NAME \">\")           \\\n    return true;\n#include \"PassRegistry.def\"\n\n  return callbacksAcceptPassName<LoopPassManager>(Name, Callbacks);\n}\n\nOptional<std::vector<PassBuilder::PipelineElement>>\nPassBuilder::parsePipelineText(StringRef Text) {\n  std::vector<PipelineElement> ResultPipeline;\n\n  SmallVector<std::vector<PipelineElement> *, 4> PipelineStack = {\n      &ResultPipeline};\n  for (;;) {\n    std::vector<PipelineElement> &Pipeline = *PipelineStack.back();\n    size_t Pos = Text.find_first_of(\",()\");\n    Pipeline.push_back({Text.substr(0, Pos), {}});\n\n    // If we have a single terminating name, we're done.\n    if (Pos == Text.npos)\n      break;\n\n    char Sep = Text[Pos];\n    Text = Text.substr(Pos + 1);\n    if (Sep == ',')\n      // Just a name ending in a comma, continue.\n      continue;\n\n    if (Sep == '(') {\n      // Push the inner pipeline onto the stack to continue processing.\n      PipelineStack.push_back(&Pipeline.back().InnerPipeline);\n      continue;\n    }\n\n    assert(Sep == ')' && \"Bogus separator!\");\n    // When handling the close parenthesis, we greedily consume them to avoid\n    // empty strings in the pipeline.\n    do {\n      // If we try to pop the outer pipeline we have unbalanced parentheses.\n      if (PipelineStack.size() == 1)\n        return None;\n\n      PipelineStack.pop_back();\n    } while (Text.consume_front(\")\"));\n\n    // Check if we've finished parsing.\n    if (Text.empty())\n      break;\n\n    // Otherwise, the end of an inner pipeline always has to be followed by\n    // a comma, and then we can continue.\n    if (!Text.consume_front(\",\"))\n      return None;\n  }\n\n  if (PipelineStack.size() > 1)\n    // Unbalanced paretheses.\n    return None;\n\n  assert(PipelineStack.back() == &ResultPipeline &&\n         \"Wrong pipeline at the bottom of the stack!\");\n  return {std::move(ResultPipeline)};\n}\n\nError PassBuilder::parseModulePass(ModulePassManager &MPM,\n                                   const PipelineElement &E) {\n  auto &Name = E.Name;\n  auto &InnerPipeline = E.InnerPipeline;\n\n  // First handle complex passes like the pass managers which carry pipelines.\n  if (!InnerPipeline.empty()) {\n    if (Name == \"module\") {\n      ModulePassManager NestedMPM(DebugLogging);\n      if (auto Err = parseModulePassPipeline(NestedMPM, InnerPipeline))\n        return Err;\n      MPM.addPass(std::move(NestedMPM));\n      return Error::success();\n    }\n    if (Name == \"cgscc\") {\n      CGSCCPassManager CGPM(DebugLogging);\n      if (auto Err = parseCGSCCPassPipeline(CGPM, InnerPipeline))\n        return Err;\n      MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(std::move(CGPM)));\n      return Error::success();\n    }\n    if (Name == \"function\") {\n      FunctionPassManager FPM(DebugLogging);\n      if (auto Err = parseFunctionPassPipeline(FPM, InnerPipeline))\n        return Err;\n      MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));\n      return Error::success();\n    }\n    if (auto Count = parseRepeatPassName(Name)) {\n      ModulePassManager NestedMPM(DebugLogging);\n      if (auto Err = parseModulePassPipeline(NestedMPM, InnerPipeline))\n        return Err;\n      MPM.addPass(createRepeatedPass(*Count, std::move(NestedMPM)));\n      return Error::success();\n    }\n\n    for (auto &C : ModulePipelineParsingCallbacks)\n      if (C(Name, MPM, InnerPipeline))\n        return Error::success();\n\n    // Normal passes can't have pipelines.\n    return make_error<StringError>(\n        formatv(\"invalid use of '{0}' pass as module pipeline\", Name).str(),\n        inconvertibleErrorCode());\n    ;\n  }\n\n  // Manually handle aliases for pre-configured pipeline fragments.\n  if (startsWithDefaultPipelineAliasPrefix(Name)) {\n    SmallVector<StringRef, 3> Matches;\n    if (!DefaultAliasRegex.match(Name, &Matches))\n      return make_error<StringError>(\n          formatv(\"unknown default pipeline alias '{0}'\", Name).str(),\n          inconvertibleErrorCode());\n\n    assert(Matches.size() == 3 && \"Must capture two matched strings!\");\n\n    OptimizationLevel L = StringSwitch<OptimizationLevel>(Matches[2])\n                              .Case(\"O0\", OptimizationLevel::O0)\n                              .Case(\"O1\", OptimizationLevel::O1)\n                              .Case(\"O2\", OptimizationLevel::O2)\n                              .Case(\"O3\", OptimizationLevel::O3)\n                              .Case(\"Os\", OptimizationLevel::Os)\n                              .Case(\"Oz\", OptimizationLevel::Oz);\n    if (L == OptimizationLevel::O0 && Matches[1] != \"thinlto\" &&\n        Matches[1] != \"lto\") {\n      MPM.addPass(buildO0DefaultPipeline(L, Matches[1] == \"thinlto-pre-link\" ||\n                                                Matches[1] == \"lto-pre-link\"));\n      return Error::success();\n    }\n\n    // This is consistent with old pass manager invoked via opt, but\n    // inconsistent with clang. Clang doesn't enable loop vectorization\n    // but does enable slp vectorization at Oz.\n    PTO.LoopVectorization =\n        L.getSpeedupLevel() > 1 && L != OptimizationLevel::Oz;\n    PTO.SLPVectorization =\n        L.getSpeedupLevel() > 1 && L != OptimizationLevel::Oz;\n\n    if (Matches[1] == \"default\") {\n      MPM.addPass(buildPerModuleDefaultPipeline(L));\n    } else if (Matches[1] == \"thinlto-pre-link\") {\n      MPM.addPass(buildThinLTOPreLinkDefaultPipeline(L));\n    } else if (Matches[1] == \"thinlto\") {\n      MPM.addPass(buildThinLTODefaultPipeline(L, nullptr));\n    } else if (Matches[1] == \"lto-pre-link\") {\n      MPM.addPass(buildLTOPreLinkDefaultPipeline(L));\n    } else {\n      assert(Matches[1] == \"lto\" && \"Not one of the matched options!\");\n      MPM.addPass(buildLTODefaultPipeline(L, nullptr));\n    }\n    return Error::success();\n  }\n\n  // Finally expand the basic registered passes from the .inc file.\n#define MODULE_PASS(NAME, CREATE_PASS)                                         \\\n  if (Name == NAME) {                                                          \\\n    MPM.addPass(CREATE_PASS);                                                  \\\n    return Error::success();                                                   \\\n  }\n#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\\n  if (Name == \"require<\" NAME \">\") {                                           \\\n    MPM.addPass(                                                               \\\n        RequireAnalysisPass<                                                   \\\n            std::remove_reference<decltype(CREATE_PASS)>::type, Module>());    \\\n    return Error::success();                                                   \\\n  }                                                                            \\\n  if (Name == \"invalidate<\" NAME \">\") {                                        \\\n    MPM.addPass(InvalidateAnalysisPass<                                        \\\n                std::remove_reference<decltype(CREATE_PASS)>::type>());        \\\n    return Error::success();                                                   \\\n  }\n#define CGSCC_PASS(NAME, CREATE_PASS)                                          \\\n  if (Name == NAME) {                                                          \\\n    MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(CREATE_PASS));         \\\n    return Error::success();                                                   \\\n  }\n#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\\n  if (Name == NAME) {                                                          \\\n    MPM.addPass(createModuleToFunctionPassAdaptor(CREATE_PASS));               \\\n    return Error::success();                                                   \\\n  }\n#define FUNCTION_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                   \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    MPM.addPass(createModuleToFunctionPassAdaptor(CREATE_PASS(Params.get()))); \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\\n  if (Name == NAME) {                                                          \\\n    MPM.addPass(                                                               \\\n        createModuleToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(     \\\n            CREATE_PASS, false, false, DebugLogging)));                        \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                       \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    MPM.addPass(                                                               \\\n        createModuleToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(     \\\n            CREATE_PASS(Params.get()), false, false, DebugLogging)));          \\\n    return Error::success();                                                   \\\n  }\n#include \"PassRegistry.def\"\n\n  for (auto &C : ModulePipelineParsingCallbacks)\n    if (C(Name, MPM, InnerPipeline))\n      return Error::success();\n  return make_error<StringError>(\n      formatv(\"unknown module pass '{0}'\", Name).str(),\n      inconvertibleErrorCode());\n}\n\nError PassBuilder::parseCGSCCPass(CGSCCPassManager &CGPM,\n                                  const PipelineElement &E) {\n  auto &Name = E.Name;\n  auto &InnerPipeline = E.InnerPipeline;\n\n  // First handle complex passes like the pass managers which carry pipelines.\n  if (!InnerPipeline.empty()) {\n    if (Name == \"cgscc\") {\n      CGSCCPassManager NestedCGPM(DebugLogging);\n      if (auto Err = parseCGSCCPassPipeline(NestedCGPM, InnerPipeline))\n        return Err;\n      // Add the nested pass manager with the appropriate adaptor.\n      CGPM.addPass(std::move(NestedCGPM));\n      return Error::success();\n    }\n    if (Name == \"function\") {\n      FunctionPassManager FPM(DebugLogging);\n      if (auto Err = parseFunctionPassPipeline(FPM, InnerPipeline))\n        return Err;\n      // Add the nested pass manager with the appropriate adaptor.\n      CGPM.addPass(createCGSCCToFunctionPassAdaptor(std::move(FPM)));\n      return Error::success();\n    }\n    if (auto Count = parseRepeatPassName(Name)) {\n      CGSCCPassManager NestedCGPM(DebugLogging);\n      if (auto Err = parseCGSCCPassPipeline(NestedCGPM, InnerPipeline))\n        return Err;\n      CGPM.addPass(createRepeatedPass(*Count, std::move(NestedCGPM)));\n      return Error::success();\n    }\n    if (auto MaxRepetitions = parseDevirtPassName(Name)) {\n      CGSCCPassManager NestedCGPM(DebugLogging);\n      if (auto Err = parseCGSCCPassPipeline(NestedCGPM, InnerPipeline))\n        return Err;\n      CGPM.addPass(\n          createDevirtSCCRepeatedPass(std::move(NestedCGPM), *MaxRepetitions));\n      return Error::success();\n    }\n\n    for (auto &C : CGSCCPipelineParsingCallbacks)\n      if (C(Name, CGPM, InnerPipeline))\n        return Error::success();\n\n    // Normal passes can't have pipelines.\n    return make_error<StringError>(\n        formatv(\"invalid use of '{0}' pass as cgscc pipeline\", Name).str(),\n        inconvertibleErrorCode());\n  }\n\n// Now expand the basic registered passes from the .inc file.\n#define CGSCC_PASS(NAME, CREATE_PASS)                                          \\\n  if (Name == NAME) {                                                          \\\n    CGPM.addPass(CREATE_PASS);                                                 \\\n    return Error::success();                                                   \\\n  }\n#define CGSCC_ANALYSIS(NAME, CREATE_PASS)                                      \\\n  if (Name == \"require<\" NAME \">\") {                                           \\\n    CGPM.addPass(RequireAnalysisPass<                                          \\\n                 std::remove_reference<decltype(CREATE_PASS)>::type,           \\\n                 LazyCallGraph::SCC, CGSCCAnalysisManager, LazyCallGraph &,    \\\n                 CGSCCUpdateResult &>());                                      \\\n    return Error::success();                                                   \\\n  }                                                                            \\\n  if (Name == \"invalidate<\" NAME \">\") {                                        \\\n    CGPM.addPass(InvalidateAnalysisPass<                                       \\\n                 std::remove_reference<decltype(CREATE_PASS)>::type>());       \\\n    return Error::success();                                                   \\\n  }\n#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\\n  if (Name == NAME) {                                                          \\\n    CGPM.addPass(createCGSCCToFunctionPassAdaptor(CREATE_PASS));               \\\n    return Error::success();                                                   \\\n  }\n#define FUNCTION_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                   \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    CGPM.addPass(createCGSCCToFunctionPassAdaptor(CREATE_PASS(Params.get()))); \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\\n  if (Name == NAME) {                                                          \\\n    CGPM.addPass(                                                              \\\n        createCGSCCToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(      \\\n            CREATE_PASS, false, false, DebugLogging)));                        \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                       \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    CGPM.addPass(                                                              \\\n        createCGSCCToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(      \\\n            CREATE_PASS(Params.get()), false, false, DebugLogging)));          \\\n    return Error::success();                                                   \\\n  }\n#include \"PassRegistry.def\"\n\n  for (auto &C : CGSCCPipelineParsingCallbacks)\n    if (C(Name, CGPM, InnerPipeline))\n      return Error::success();\n  return make_error<StringError>(\n      formatv(\"unknown cgscc pass '{0}'\", Name).str(),\n      inconvertibleErrorCode());\n}\n\nError PassBuilder::parseFunctionPass(FunctionPassManager &FPM,\n                                     const PipelineElement &E) {\n  auto &Name = E.Name;\n  auto &InnerPipeline = E.InnerPipeline;\n\n  // First handle complex passes like the pass managers which carry pipelines.\n  if (!InnerPipeline.empty()) {\n    if (Name == \"function\") {\n      FunctionPassManager NestedFPM(DebugLogging);\n      if (auto Err = parseFunctionPassPipeline(NestedFPM, InnerPipeline))\n        return Err;\n      // Add the nested pass manager with the appropriate adaptor.\n      FPM.addPass(std::move(NestedFPM));\n      return Error::success();\n    }\n    if (Name == \"loop\" || Name == \"loop-mssa\") {\n      LoopPassManager LPM(DebugLogging);\n      if (auto Err = parseLoopPassPipeline(LPM, InnerPipeline))\n        return Err;\n      // Add the nested pass manager with the appropriate adaptor.\n      bool UseMemorySSA = (Name == \"loop-mssa\");\n      bool UseBFI = llvm::any_of(\n          InnerPipeline, [](auto Pipeline) { return Pipeline.Name == \"licm\"; });\n      FPM.addPass(createFunctionToLoopPassAdaptor(std::move(LPM), UseMemorySSA,\n                                                  UseBFI, DebugLogging));\n      return Error::success();\n    }\n    if (auto Count = parseRepeatPassName(Name)) {\n      FunctionPassManager NestedFPM(DebugLogging);\n      if (auto Err = parseFunctionPassPipeline(NestedFPM, InnerPipeline))\n        return Err;\n      FPM.addPass(createRepeatedPass(*Count, std::move(NestedFPM)));\n      return Error::success();\n    }\n\n    for (auto &C : FunctionPipelineParsingCallbacks)\n      if (C(Name, FPM, InnerPipeline))\n        return Error::success();\n\n    // Normal passes can't have pipelines.\n    return make_error<StringError>(\n        formatv(\"invalid use of '{0}' pass as function pipeline\", Name).str(),\n        inconvertibleErrorCode());\n  }\n\n// Now expand the basic registered passes from the .inc file.\n#define FUNCTION_PASS(NAME, CREATE_PASS)                                       \\\n  if (Name == NAME) {                                                          \\\n    FPM.addPass(CREATE_PASS);                                                  \\\n    return Error::success();                                                   \\\n  }\n#define FUNCTION_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                   \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    FPM.addPass(CREATE_PASS(Params.get()));                                    \\\n    return Error::success();                                                   \\\n  }\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS)                                   \\\n  if (Name == \"require<\" NAME \">\") {                                           \\\n    FPM.addPass(                                                               \\\n        RequireAnalysisPass<                                                   \\\n            std::remove_reference<decltype(CREATE_PASS)>::type, Function>());  \\\n    return Error::success();                                                   \\\n  }                                                                            \\\n  if (Name == \"invalidate<\" NAME \">\") {                                        \\\n    FPM.addPass(InvalidateAnalysisPass<                                        \\\n                std::remove_reference<decltype(CREATE_PASS)>::type>());        \\\n    return Error::success();                                                   \\\n  }\n// FIXME: UseMemorySSA is set to false. Maybe we could do things like:\n//        bool UseMemorySSA = !(\"canon-freeze\" || \"loop-predication\" ||\n//                              \"guard-widening\");\n//        The risk is that it may become obsolete if we're not careful.\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\\n  if (Name == NAME) {                                                          \\\n    FPM.addPass(createFunctionToLoopPassAdaptor(CREATE_PASS, false, false,     \\\n                                                DebugLogging));                \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                       \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    FPM.addPass(createFunctionToLoopPassAdaptor(CREATE_PASS(Params.get()),     \\\n                                                false, false, DebugLogging));  \\\n    return Error::success();                                                   \\\n  }\n#include \"PassRegistry.def\"\n\n  for (auto &C : FunctionPipelineParsingCallbacks)\n    if (C(Name, FPM, InnerPipeline))\n      return Error::success();\n  return make_error<StringError>(\n      formatv(\"unknown function pass '{0}'\", Name).str(),\n      inconvertibleErrorCode());\n}\n\nError PassBuilder::parseLoopPass(LoopPassManager &LPM,\n                                 const PipelineElement &E) {\n  StringRef Name = E.Name;\n  auto &InnerPipeline = E.InnerPipeline;\n\n  // First handle complex passes like the pass managers which carry pipelines.\n  if (!InnerPipeline.empty()) {\n    if (Name == \"loop\") {\n      LoopPassManager NestedLPM(DebugLogging);\n      if (auto Err = parseLoopPassPipeline(NestedLPM, InnerPipeline))\n        return Err;\n      // Add the nested pass manager with the appropriate adaptor.\n      LPM.addPass(std::move(NestedLPM));\n      return Error::success();\n    }\n    if (auto Count = parseRepeatPassName(Name)) {\n      LoopPassManager NestedLPM(DebugLogging);\n      if (auto Err = parseLoopPassPipeline(NestedLPM, InnerPipeline))\n        return Err;\n      LPM.addPass(createRepeatedPass(*Count, std::move(NestedLPM)));\n      return Error::success();\n    }\n\n    for (auto &C : LoopPipelineParsingCallbacks)\n      if (C(Name, LPM, InnerPipeline))\n        return Error::success();\n\n    // Normal passes can't have pipelines.\n    return make_error<StringError>(\n        formatv(\"invalid use of '{0}' pass as loop pipeline\", Name).str(),\n        inconvertibleErrorCode());\n  }\n\n// Now expand the basic registered passes from the .inc file.\n#define LOOP_PASS(NAME, CREATE_PASS)                                           \\\n  if (Name == NAME) {                                                          \\\n    LPM.addPass(CREATE_PASS);                                                  \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_PASS_WITH_PARAMS(NAME, CREATE_PASS, PARSER)                       \\\n  if (checkParametrizedPassName(Name, NAME)) {                                 \\\n    auto Params = parsePassParameters(PARSER, Name, NAME);                     \\\n    if (!Params)                                                               \\\n      return Params.takeError();                                               \\\n    LPM.addPass(CREATE_PASS(Params.get()));                                    \\\n    return Error::success();                                                   \\\n  }\n#define LOOP_ANALYSIS(NAME, CREATE_PASS)                                       \\\n  if (Name == \"require<\" NAME \">\") {                                           \\\n    LPM.addPass(RequireAnalysisPass<                                           \\\n                std::remove_reference<decltype(CREATE_PASS)>::type, Loop,      \\\n                LoopAnalysisManager, LoopStandardAnalysisResults &,            \\\n                LPMUpdater &>());                                              \\\n    return Error::success();                                                   \\\n  }                                                                            \\\n  if (Name == \"invalidate<\" NAME \">\") {                                        \\\n    LPM.addPass(InvalidateAnalysisPass<                                        \\\n                std::remove_reference<decltype(CREATE_PASS)>::type>());        \\\n    return Error::success();                                                   \\\n  }\n#include \"PassRegistry.def\"\n\n  for (auto &C : LoopPipelineParsingCallbacks)\n    if (C(Name, LPM, InnerPipeline))\n      return Error::success();\n  return make_error<StringError>(formatv(\"unknown loop pass '{0}'\", Name).str(),\n                                 inconvertibleErrorCode());\n}\n\nbool PassBuilder::parseAAPassName(AAManager &AA, StringRef Name) {\n#define MODULE_ALIAS_ANALYSIS(NAME, CREATE_PASS)                               \\\n  if (Name == NAME) {                                                          \\\n    AA.registerModuleAnalysis<                                                 \\\n        std::remove_reference<decltype(CREATE_PASS)>::type>();                 \\\n    return true;                                                               \\\n  }\n#define FUNCTION_ALIAS_ANALYSIS(NAME, CREATE_PASS)                             \\\n  if (Name == NAME) {                                                          \\\n    AA.registerFunctionAnalysis<                                               \\\n        std::remove_reference<decltype(CREATE_PASS)>::type>();                 \\\n    return true;                                                               \\\n  }\n#include \"PassRegistry.def\"\n\n  for (auto &C : AAParsingCallbacks)\n    if (C(Name, AA))\n      return true;\n  return false;\n}\n\nError PassBuilder::parseLoopPassPipeline(LoopPassManager &LPM,\n                                         ArrayRef<PipelineElement> Pipeline) {\n  for (const auto &Element : Pipeline) {\n    if (auto Err = parseLoopPass(LPM, Element))\n      return Err;\n  }\n  return Error::success();\n}\n\nError PassBuilder::parseFunctionPassPipeline(\n    FunctionPassManager &FPM, ArrayRef<PipelineElement> Pipeline) {\n  for (const auto &Element : Pipeline) {\n    if (auto Err = parseFunctionPass(FPM, Element))\n      return Err;\n  }\n  return Error::success();\n}\n\nError PassBuilder::parseCGSCCPassPipeline(CGSCCPassManager &CGPM,\n                                          ArrayRef<PipelineElement> Pipeline) {\n  for (const auto &Element : Pipeline) {\n    if (auto Err = parseCGSCCPass(CGPM, Element))\n      return Err;\n  }\n  return Error::success();\n}\n\nvoid PassBuilder::crossRegisterProxies(LoopAnalysisManager &LAM,\n                                       FunctionAnalysisManager &FAM,\n                                       CGSCCAnalysisManager &CGAM,\n                                       ModuleAnalysisManager &MAM) {\n  MAM.registerPass([&] { return FunctionAnalysisManagerModuleProxy(FAM); });\n  MAM.registerPass([&] { return CGSCCAnalysisManagerModuleProxy(CGAM); });\n  CGAM.registerPass([&] { return ModuleAnalysisManagerCGSCCProxy(MAM); });\n  FAM.registerPass([&] { return CGSCCAnalysisManagerFunctionProxy(CGAM); });\n  FAM.registerPass([&] { return ModuleAnalysisManagerFunctionProxy(MAM); });\n  FAM.registerPass([&] { return LoopAnalysisManagerFunctionProxy(LAM); });\n  LAM.registerPass([&] { return FunctionAnalysisManagerLoopProxy(FAM); });\n}\n\nError PassBuilder::parseModulePassPipeline(ModulePassManager &MPM,\n                                           ArrayRef<PipelineElement> Pipeline) {\n  for (const auto &Element : Pipeline) {\n    if (auto Err = parseModulePass(MPM, Element))\n      return Err;\n  }\n  return Error::success();\n}\n\n// Primary pass pipeline description parsing routine for a \\c ModulePassManager\n// FIXME: Should this routine accept a TargetMachine or require the caller to\n// pre-populate the analysis managers with target-specific stuff?\nError PassBuilder::parsePassPipeline(ModulePassManager &MPM,\n                                     StringRef PipelineText) {\n  auto Pipeline = parsePipelineText(PipelineText);\n  if (!Pipeline || Pipeline->empty())\n    return make_error<StringError>(\n        formatv(\"invalid pipeline '{0}'\", PipelineText).str(),\n        inconvertibleErrorCode());\n\n  // If the first name isn't at the module layer, wrap the pipeline up\n  // automatically.\n  StringRef FirstName = Pipeline->front().Name;\n\n  if (!isModulePassName(FirstName, ModulePipelineParsingCallbacks)) {\n    if (isCGSCCPassName(FirstName, CGSCCPipelineParsingCallbacks)) {\n      Pipeline = {{\"cgscc\", std::move(*Pipeline)}};\n    } else if (isFunctionPassName(FirstName,\n                                  FunctionPipelineParsingCallbacks)) {\n      Pipeline = {{\"function\", std::move(*Pipeline)}};\n    } else if (isLoopPassName(FirstName, LoopPipelineParsingCallbacks)) {\n      Pipeline = {{\"function\", {{\"loop\", std::move(*Pipeline)}}}};\n    } else {\n      for (auto &C : TopLevelPipelineParsingCallbacks)\n        if (C(MPM, *Pipeline, DebugLogging))\n          return Error::success();\n\n      // Unknown pass or pipeline name!\n      auto &InnerPipeline = Pipeline->front().InnerPipeline;\n      return make_error<StringError>(\n          formatv(\"unknown {0} name '{1}'\",\n                  (InnerPipeline.empty() ? \"pass\" : \"pipeline\"), FirstName)\n              .str(),\n          inconvertibleErrorCode());\n    }\n  }\n\n  if (auto Err = parseModulePassPipeline(MPM, *Pipeline))\n    return Err;\n  return Error::success();\n}\n\n// Primary pass pipeline description parsing routine for a \\c CGSCCPassManager\nError PassBuilder::parsePassPipeline(CGSCCPassManager &CGPM,\n                                     StringRef PipelineText) {\n  auto Pipeline = parsePipelineText(PipelineText);\n  if (!Pipeline || Pipeline->empty())\n    return make_error<StringError>(\n        formatv(\"invalid pipeline '{0}'\", PipelineText).str(),\n        inconvertibleErrorCode());\n\n  StringRef FirstName = Pipeline->front().Name;\n  if (!isCGSCCPassName(FirstName, CGSCCPipelineParsingCallbacks))\n    return make_error<StringError>(\n        formatv(\"unknown cgscc pass '{0}' in pipeline '{1}'\", FirstName,\n                PipelineText)\n            .str(),\n        inconvertibleErrorCode());\n\n  if (auto Err = parseCGSCCPassPipeline(CGPM, *Pipeline))\n    return Err;\n  return Error::success();\n}\n\n// Primary pass pipeline description parsing routine for a \\c\n// FunctionPassManager\nError PassBuilder::parsePassPipeline(FunctionPassManager &FPM,\n                                     StringRef PipelineText) {\n  auto Pipeline = parsePipelineText(PipelineText);\n  if (!Pipeline || Pipeline->empty())\n    return make_error<StringError>(\n        formatv(\"invalid pipeline '{0}'\", PipelineText).str(),\n        inconvertibleErrorCode());\n\n  StringRef FirstName = Pipeline->front().Name;\n  if (!isFunctionPassName(FirstName, FunctionPipelineParsingCallbacks))\n    return make_error<StringError>(\n        formatv(\"unknown function pass '{0}' in pipeline '{1}'\", FirstName,\n                PipelineText)\n            .str(),\n        inconvertibleErrorCode());\n\n  if (auto Err = parseFunctionPassPipeline(FPM, *Pipeline))\n    return Err;\n  return Error::success();\n}\n\n// Primary pass pipeline description parsing routine for a \\c LoopPassManager\nError PassBuilder::parsePassPipeline(LoopPassManager &CGPM,\n                                     StringRef PipelineText) {\n  auto Pipeline = parsePipelineText(PipelineText);\n  if (!Pipeline || Pipeline->empty())\n    return make_error<StringError>(\n        formatv(\"invalid pipeline '{0}'\", PipelineText).str(),\n        inconvertibleErrorCode());\n\n  if (auto Err = parseLoopPassPipeline(CGPM, *Pipeline))\n    return Err;\n\n  return Error::success();\n}\n\nError PassBuilder::parseAAPipeline(AAManager &AA, StringRef PipelineText) {\n  // If the pipeline just consists of the word 'default' just replace the AA\n  // manager with our default one.\n  if (PipelineText == \"default\") {\n    AA = buildDefaultAAPipeline();\n    return Error::success();\n  }\n\n  while (!PipelineText.empty()) {\n    StringRef Name;\n    std::tie(Name, PipelineText) = PipelineText.split(',');\n    if (!parseAAPassName(AA, Name))\n      return make_error<StringError>(\n          formatv(\"unknown alias analysis name '{0}'\", Name).str(),\n          inconvertibleErrorCode());\n  }\n\n  return Error::success();\n}\n\nbool PassBuilder::isAAPassName(StringRef PassName) {\n#define MODULE_ALIAS_ANALYSIS(NAME, CREATE_PASS)                               \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#define FUNCTION_ALIAS_ANALYSIS(NAME, CREATE_PASS)                             \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#include \"PassRegistry.def\"\n  return false;\n}\n\nbool PassBuilder::isAnalysisPassName(StringRef PassName) {\n#define MODULE_ANALYSIS(NAME, CREATE_PASS)                                     \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS)                                   \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#define LOOP_ANALYSIS(NAME, CREATE_PASS)                                       \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#define CGSCC_ANALYSIS(NAME, CREATE_PASS)                                      \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#define MODULE_ALIAS_ANALYSIS(NAME, CREATE_PASS)                               \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#define FUNCTION_ALIAS_ANALYSIS(NAME, CREATE_PASS)                             \\\n  if (PassName == NAME)                                                        \\\n    return true;\n#include \"PassRegistry.def\"\n  return false;\n}\n\nstatic void printPassName(StringRef PassName, raw_ostream &OS) {\n  OS << \"  \" << PassName << \"\\n\";\n}\n\nvoid PassBuilder::printPassNames(raw_ostream &OS) {\n  // TODO: print pass descriptions when they are available\n\n  OS << \"Module passes:\\n\";\n#define MODULE_PASS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Module analyses:\\n\";\n#define MODULE_ANALYSIS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Module alias analyses:\\n\";\n#define MODULE_ALIAS_ANALYSIS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"CGSCC passes:\\n\";\n#define CGSCC_PASS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"CGSCC analyses:\\n\";\n#define CGSCC_ANALYSIS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Function passes:\\n\";\n#define FUNCTION_PASS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Function analyses:\\n\";\n#define FUNCTION_ANALYSIS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Function alias analyses:\\n\";\n#define FUNCTION_ALIAS_ANALYSIS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Loop passes:\\n\";\n#define LOOP_PASS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n\n  OS << \"Loop analyses:\\n\";\n#define LOOP_ANALYSIS(NAME, CREATE_PASS) printPassName(NAME, OS);\n#include \"PassRegistry.def\"\n}\n\nvoid PassBuilder::registerParseTopLevelPipelineCallback(\n    const std::function<bool(ModulePassManager &, ArrayRef<PipelineElement>,\n                             bool DebugLogging)> &C) {\n  TopLevelPipelineParsingCallbacks.push_back(C);\n}\n"}}, "reports": [{"events": [{"location": {"col": 7, "file": 18, "line": 1194}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AliasAnalysis.h", "reportHash": "a1b6e8fd7ed3a50bb4c041c2d9f991aa", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 21, "line": 169}, "message": "default constructor 'AssumptionAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/AssumptionCache.h", "reportHash": "09222cfea9075211ba9df635169eeed7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 22, "line": 249}, "message": "default constructor 'BasicAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/BasicAliasAnalysis.h", "reportHash": "93702acd097595ae055769b9a3bb9466", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 23, "line": 112}, "message": "default constructor 'BlockFrequencyAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/BlockFrequencyInfo.h", "reportHash": "c7f66f746b3d0748f3cd6a046f0b92ce", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 24, "line": 420}, "message": "default constructor 'BranchProbabilityAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/BranchProbabilityInfo.h", "reportHash": "d4bed4aa774e21eb61c9496e0278109b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 25, "line": 34}, "message": "default constructor 'CFGViewerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFGPrinter.h", "reportHash": "502f5880a3fd806168160e5df3a2f74b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 25, "line": 39}, "message": "default constructor 'CFGOnlyViewerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFGPrinter.h", "reportHash": "10b5393ccfcfd2da6687a0e1ffb5e879", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 25, "line": 49}, "message": "default constructor 'CFGOnlyPrinterPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFGPrinter.h", "reportHash": "66906c2c9aa0982c267cd3d6d6947f4e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 26, "line": 94}, "message": "default constructor 'CFLAndersAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFLAndersAliasAnalysis.h", "reportHash": "c68177d9525bc6a151a07c3e286bf8d1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 27, "line": 111}, "message": "default constructor 'CFLSteensAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CFLSteensAliasAnalysis.h", "reportHash": "c9848f4f92b88a1c3bd5f70a4abbe079", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 28, "line": 392}, "message": "default constructor 'FunctionAnalysisManagerCGSCCProxy' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CGSCCPassManager.h", "reportHash": "51b857cce55cd6033e87699030e0cf77", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 29, "line": 305}, "message": "default constructor 'CallGraphAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/CallGraph.h", "reportHash": "8ce9ff2dddf35c1801417e369c1c78b6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 31, "line": 425}, "message": "default constructor 'DDGAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DDG.h", "reportHash": "164b60dfbbe67c3f2d08a4390d2a1a92", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 32, "line": 27}, "message": "default constructor 'DDGDotPrinterPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DDGPrinter.h", "reportHash": "273b54ebb255359c7b539ef1b5362681", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 33, "line": 120}, "message": "default constructor 'DemandedBitsAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DemandedBits.h", "reportHash": "b9c81594568986e40c2838d90d9c22c6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 34, "line": 957}, "message": "default constructor 'DependenceAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DependenceAnalysis.h", "reportHash": "d17f685821536c799fde337b83bb0709", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 196}, "message": "default constructor 'DivergenceAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DivergenceAnalysis.h", "reportHash": "8f0187ec9c6ad166898301bc78a83ecc", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 36, "line": 182}, "message": "default constructor 'DominanceFrontierAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/DominanceFrontier.h", "reportHash": "7bd061163f705c0a17e8c1d0c761874a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 37, "line": 63}, "message": "default constructor 'FunctionPropertiesAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/FunctionPropertiesAnalysis.h", "reportHash": "1364667c5b39f27b7401a30016e5516b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 38, "line": 132}, "message": "default constructor 'GlobalsAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/GlobalsModRef.h", "reportHash": "615939f47739c500989bc084eeaa6ff1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 39, "line": 766}, "message": "default constructor 'IRSimilarityAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/IRSimilarityIdentifier.h", "reportHash": "eb54d92fd6036cca1d0e0b69a27a37e9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 40, "line": 188}, "message": "default constructor 'IVUsersAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/IVUsers.h", "reportHash": "c492a74940b04dbdcc674506881e723f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 42, "line": 160}, "message": "default constructor 'InlineParams' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/InlineCost.h", "reportHash": "f73add69bfbc66ca6e174a40f85fcec0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 43, "line": 22}, "message": "default constructor 'InstCountPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/InstCount.h", "reportHash": "a04a75f0d1eade62c9debe5bd726d358", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 44, "line": 1275}, "message": "default constructor 'LazyCallGraphAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LazyCallGraph.h", "reportHash": "584111a640df1e3a0d467f506639b243", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 45, "line": 123}, "message": "default constructor 'LazyValueAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LazyValueInfo.h", "reportHash": "1754fd52f5795f961b8a400e36163f1f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 46, "line": 41}, "message": "default constructor 'LintPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/Lint.h", "reportHash": "64dc0e7d98b716d3894e797b353d39c7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 47, "line": 750}, "message": "default constructor 'LoopAccessAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopAccessAnalysis.h", "reportHash": "d569caefddde6948470701adef7a424c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 48, "line": 1224}, "message": "default constructor 'LoopAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "reportHash": "427f95f0acf90062e31d23008e938828", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 48, "line": 1244}, "message": "default constructor 'LoopVerifierPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/LoopInfo.h", "reportHash": "657e2e4d3e32c0caad0ebd8724b2049f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 51, "line": 921}, "message": "default constructor 'MemorySSAAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h", "reportHash": "d6bee7f9980d6c7ebb114e3a182e4288", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 51, "line": 955}, "message": "default constructor 'MemorySSAVerifierPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/MemorySSA.h", "reportHash": "36d9a85236294bec42baa12c57892b87", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 52, "line": 44}, "message": "default constructor 'ModuleSummaryIndexAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ModuleSummaryAnalysis.h", "reportHash": "fa6332b6a9db9b273c9844734ef0113e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 69}, "message": "default constructor 'ObjCARCAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ObjCARCAliasAnalysis.h", "reportHash": "4f5f7cbcd666cb4a96d21169365e3675", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 54, "line": 156}, "message": "default constructor 'OptimizationRemarkEmitterAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/OptimizationRemarkEmitter.h", "reportHash": "cb458472fd601da0477637150f400806", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 55, "line": 116}, "message": "default constructor 'PhiValuesAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/PhiValues.h", "reportHash": "47d172c53f74212ee28d55fa2e7f144a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 56, "line": 47}, "message": "default constructor 'PostDominatorTreeAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/PostDominators.h", "reportHash": "74cfda8e8da9438febd9cd2cc42d5747", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 57, "line": 204}, "message": "default constructor 'ProfileSummaryAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ProfileSummaryInfo.h", "reportHash": "f2c390c86e64e94eb6ed38a410a5c1d4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 58, "line": 967}, "message": "default constructor 'RegionInfoAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "reportHash": "c0e1cefb9a45669e7b008fd65f17c082", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 58, "line": 989}, "message": "default constructor 'RegionInfoVerifierPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "reportHash": "d98a5dd164e59533c7bbbbbf5574954d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 59, "line": 2058}, "message": "default constructor 'ScalarEvolutionAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "39000aa46c60bf358f827e7cc03fb66c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 59, "line": 2071}, "message": "default constructor 'ScalarEvolutionVerifierPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolution.h", "reportHash": "33f5365dbf257c0998b46120ac438d14", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 60, "line": 41}, "message": "default constructor 'SCEVAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScalarEvolutionAliasAnalysis.h", "reportHash": "5decd2e1879a0dbaeefa82e4e7f0272f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 61, "line": 53}, "message": "default constructor 'ScopedNoAliasAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/ScopedNoAliasAA.h", "reportHash": "4bad5a6d7ed98fc6718b98729556d53a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 62, "line": 185}, "message": "move constructor 'StackLifetimePrinterPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/StackLifetime.h", "reportHash": "00c29e13e52ddf8f3ccadaf30c8c0501", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 63, "line": 84}, "message": "default constructor 'StackSafetyAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/StackSafetyAnalysis.h", "reportHash": "a27be1134b9615c80d2198c9ebabd698", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 63, "line": 120}, "message": "default constructor 'StackSafetyGlobalAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/StackSafetyAnalysis.h", "reportHash": "f096c3b8e833384c68951bc9d6feef25", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 64, "line": 59}, "message": "default constructor 'TypeBasedAA' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Analysis/TypeBasedAliasAnalysis.h", "reportHash": "c53ed31a2b6ccdf5e3fd86ba8caa51f9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 73, "line": 252}, "message": "default constructor 'DominatorTreeAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Dominators.h", "reportHash": "9f0c5f1e261a8b85cdc6248d1091060b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 73, "line": 276}, "message": "default constructor 'DominatorTreeVerifierPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Dominators.h", "reportHash": "bbd1ae61e2a122abad26aaa10c316aff", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 85, "line": 1315}, "message": "default constructor 'InvalidateAllAnalysesPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/PassManager.h", "reportHash": "2d006fd19b87dcb2e706a6ff5d31e8ba", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 87, "line": 107}, "message": "default constructor 'VerifierAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/Verifier.h", "reportHash": "dbdb8872054463bbd71e1393e3948df5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 89, "line": 164}, "message": "destructor '~OptimizationLevel' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Passes/PassBuilder.h", "reportHash": "7892b584fac501f89f257fe4d08d2525", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 111, "line": 24}, "message": "default constructor 'AggressiveInstCombinePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/AggressiveInstCombine/AggressiveInstCombine.h", "reportHash": "8575693435a8301b0135231b6897018b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 112, "line": 23}, "message": "default constructor 'CoroCleanupPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroCleanup.h", "reportHash": "29b2b69354844ac783864343f35459a8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 113, "line": 26}, "message": "default constructor 'CoroEarlyPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroEarly.h", "reportHash": "b4066747f0d5466a9ce2847746d6eb81", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 114, "line": 25}, "message": "default constructor 'CoroElidePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Coroutines/CoroElide.h", "reportHash": "82c7361ce4b5f6964afc5efe8c69588c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 115, "line": 24}, "message": "default constructor 'Annotation2MetadataPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/Annotation2Metadata.h", "reportHash": "25223bd66694f30fbce7fac8a6257638", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 116, "line": 2436}, "message": "default constructor 'AttributorPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/Attributor.h", "reportHash": "6e7384dad19635c50de767b0fcafb6e8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 116, "line": 2439}, "message": "default constructor 'AttributorCGSCCPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/Attributor.h", "reportHash": "72f2b5f0639071d0cbbac96588224f4c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 117, "line": 20}, "message": "default constructor 'BlockExtractorPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/BlockExtractor.h", "reportHash": "5d201179539896d7887b9fcf4221f945", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 118, "line": 26}, "message": "default constructor 'CalledValuePropagationPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/CalledValuePropagation.h", "reportHash": "bd5fd60006395c7d974782fea29588d1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 119, "line": 29}, "message": "default constructor 'ConstantMergePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/ConstantMerge.h", "reportHash": "71d43ff304f5276b1beb36e75c5684ed", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 120, "line": 20}, "message": "default constructor 'CrossDSOCFIPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/CrossDSOCFI.h", "reportHash": "28fc983f85ecb12490a347e904ce0f28", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 121, "line": 44}, "message": "destructor '~RetOrArg' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/DeadArgumentElimination.h", "reportHash": "712e31fa7b0aacfc831aa641f6efcf5a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 121, "line": 44}, "message": "move constructor 'RetOrArg' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/DeadArgumentElimination.h", "reportHash": "aaefc28c04f4758f37f10be1275ccff6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 122, "line": 24}, "message": "default constructor 'EliminateAvailableExternallyPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/ElimAvailExtern.h", "reportHash": "a89153a754b1bb9e07d31f0e59769e58", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 123, "line": 22}, "message": "default constructor 'ForceFunctionAttrsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/ForceFunctionAttrs.h", "reportHash": "bd744a7077ab9736c3e3467b4ead2df3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 124, "line": 50}, "message": "default constructor 'PostOrderFunctionAttrsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/FunctionAttrs.h", "reportHash": "85ce336d9a97c8824895225d3f36de40", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 124, "line": 69}, "message": "default constructor 'ReversePostOrderFunctionAttrsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/FunctionAttrs.h", "reportHash": "739ea8e8ff7e234f7661a2a00ae31e50", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 125, "line": 129}, "message": "default constructor 'FunctionImportPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/FunctionImport.h", "reportHash": "686c24d957a370dda644d362558f5af2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 126, "line": 29}, "message": "default constructor 'GlobalDCEPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/GlobalDCE.h", "reportHash": "37511c839da2e3f6778e2da9ed27b26d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 127, "line": 25}, "message": "default constructor 'GlobalOptPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/GlobalOpt.h", "reportHash": "1e881ee1a5df1d70aae71ec7cfb2ef7a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 128, "line": 26}, "message": "default constructor 'GlobalSplitPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/GlobalSplit.h", "reportHash": "b29237420f11b1078ddf3cb330fd19f2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 129, "line": 61}, "message": "default constructor 'HotColdSplittingPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/HotColdSplitting.h", "reportHash": "0120830ed25e58459f5fcff023018800", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 130, "line": 351}, "message": "default constructor 'IROutlinerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/IROutliner.h", "reportHash": "c02f7972438d7034a48bae0b54046459", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 131, "line": 25}, "message": "default constructor 'InferFunctionAttrsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/InferFunctionAttrs.h", "reportHash": "a59cba13caef7ac9dacfcbb7114595c5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 132, "line": 25}, "message": "default constructor 'MergeFunctionsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/MergeFunctions.h", "reportHash": "d82c64a7cdd43b8ff4c9d87317130b55", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 133, "line": 65}, "message": "default constructor 'OpenMPOptPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/OpenMPOpt.h", "reportHash": "1c1cbb4fff594c2ab06983a272235b08", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 134, "line": 24}, "message": "default constructor 'PartialInlinerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/PartialInlining.h", "reportHash": "4913a9b0f9c8e81602310afe9ef9f776", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 135, "line": 30}, "message": "default constructor 'IPSCCPPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/SCCP.h", "reportHash": "9de6711f4b88624d3e0ef6a3c3ddc702", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 136, "line": 25}, "message": "default constructor 'StripDeadPrototypesPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripDeadPrototypes.h", "reportHash": "90e19520d7d68ccbb4ba9da8b083a8c0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 137, "line": 29}, "message": "default constructor 'StripSymbolsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripSymbols.h", "reportHash": "250939e19ccc48ffa0a93c35d5a5c2f0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 137, "line": 33}, "message": "default constructor 'StripNonDebugSymbolsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripSymbols.h", "reportHash": "4455844d3a994a115dd30a028f439182", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 137, "line": 37}, "message": "default constructor 'StripDebugDeclarePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripSymbols.h", "reportHash": "3733e5463cd6cb04ca724459c2ef58ff", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 137, "line": 41}, "message": "default constructor 'StripDeadDebugInfoPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/StripSymbols.h", "reportHash": "50e4a9610d28592d3615bfc9fc1d15d4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 138, "line": 17}, "message": "default constructor 'SyntheticCountsPropagation' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/IPO/SyntheticCountsPropagation.h", "reportHash": "191c950f48b6db3ba331b78848c8207c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 139, "line": 152}, "message": "destructor '~SanitizerCoverageOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation.h", "reportHash": "dad12a1295cb9e86a2f36b6fc3d9596d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 139, "line": 152}, "message": "move constructor 'SanitizerCoverageOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation.h", "reportHash": "b26e63e2bdc807dfdc1902acb116acfb", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 140, "line": 25}, "message": "destructor '~LocationMetadata' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizer.h", "reportHash": "7acdf020877d8aa024bfe625178f6efd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 140, "line": 39}, "message": "destructor '~Entry' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizer.h", "reportHash": "8a71749037598f4669f452ff2ceaa2c9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 140, "line": 81}, "message": "default constructor 'ASanGlobalsMetadataAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/AddressSanitizer.h", "reportHash": "4180b9d0bd979e462dc0dbd2ac5d5291", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 141, "line": 18}, "message": "default constructor 'BoundsCheckingPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/BoundsChecking.h", "reportHash": "073e570a18c24ca28006ecb34f79bc14", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 142, "line": 19}, "message": "default constructor 'CGProfilePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/CGProfile.h", "reportHash": "74439c35f9cc628fdbffb785c959f3ba", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 143, "line": 18}, "message": "default constructor 'DataFlowSanitizerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/DataFlowSanitizer.h", "reportHash": "c6a4d0e33ba727e65e577668ea4385dd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 144, "line": 21}, "message": "default constructor 'InstrOrderFilePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/InstrOrderFile.h", "reportHash": "2ffd7733f7e71a88ec952642b71a0a8c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 145, "line": 21}, "message": "destructor '~MemorySanitizerOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/MemorySanitizer.h", "reportHash": "fe25c02fa55cd0cbb647ee7c537be1a0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 145, "line": 21}, "message": "move constructor 'MemorySanitizerOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/MemorySanitizer.h", "reportHash": "2a766cf60f04797be503c2d6e67c09ea", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 145, "line": 39}, "message": "move constructor 'MemorySanitizerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/MemorySanitizer.h", "reportHash": "1999a17fe7d85ef3969cb4328cdc806f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 146, "line": 16}, "message": "default constructor 'PoisonCheckingPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/PoisonChecking.h", "reportHash": "a089cea1867c1f69c4bfc84759b62392", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 147, "line": 31}, "message": "default constructor 'ModuleSanitizerCoveragePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/SanitizerCoverage.h", "reportHash": "113b81fd478e730aae593608fe589fef", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 148, "line": 28}, "message": "default constructor 'ThreadSanitizerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Instrumentation/ThreadSanitizer.h", "reportHash": "15f6e2fbf90b5c6db88ed0df4c82361a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 149, "line": 47}, "message": "default constructor 'ObjCARCOptPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/ObjCARC.h", "reportHash": "397fd2016b19f3e215fad53f1ba6df60", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 149, "line": 51}, "message": "default constructor 'ObjCARCContractPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/ObjCARC.h", "reportHash": "145d1967f06ab2b1481a7eec38304859", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 149, "line": 55}, "message": "default constructor 'ObjCARCAPElimPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/ObjCARC.h", "reportHash": "362af4996a0767b42b0b408dc2c8b2b6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 149, "line": 59}, "message": "default constructor 'ObjCARCExpandPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/ObjCARC.h", "reportHash": "93b6eedb1e231b7b0631f879602e3462", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 150, "line": 31}, "message": "default constructor 'ADCEPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/ADCE.h", "reportHash": "5bc2ac99ad2b315c4a5c9f94b275e291", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 151, "line": 29}, "message": "default constructor 'AlignmentFromAssumptionsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/AlignmentFromAssumptions.h", "reportHash": "1bdca7f3be2b44f000150278a45e9408", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 152, "line": 21}, "message": "default constructor 'AnnotationRemarksPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/AnnotationRemarks.h", "reportHash": "81d81cb8c2c59ab211df681f300c0353", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 153, "line": 25}, "message": "default constructor 'BDCEPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/BDCE.h", "reportHash": "614cf691e3744de0ac0a4f305bb72d96", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 154, "line": 17}, "message": "default constructor 'CallSiteSplittingPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/CallSiteSplitting.h", "reportHash": "69e76c1cf4ec8e9c6aeb0ef546058649", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 156, "line": 16}, "message": "default constructor 'ConstraintEliminationPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/ConstraintElimination.h", "reportHash": "457e504a7656c3fa2f55cd396921a4a1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 157, "line": 18}, "message": "default constructor 'CorrelatedValuePropagationPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/CorrelatedValuePropagation.h", "reportHash": "15e64642a2e73b551a8e6cf582535e8c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 158, "line": 22}, "message": "default constructor 'DCEPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DCE.h", "reportHash": "e0e2861ff9348d663cb597015829dd67", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 158, "line": 27}, "message": "default constructor 'RedundantDbgInstEliminationPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DCE.h", "reportHash": "c8fe5c9568cf559789388f2e150f1ff8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 159, "line": 28}, "message": "default constructor 'DSEPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DeadStoreElimination.h", "reportHash": "d423fd8bc065742cdac6b2d672b32950", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 160, "line": 23}, "message": "default constructor 'DivRemPairsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/DivRemPairs.h", "reportHash": "1c8daf27534491c86e1a04f4d63e63e3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 161, "line": 26}, "message": "default constructor 'Float2IntPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Float2Int.h", "reportHash": "4c515bc017644e09da87c20b7ac5d502", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 162, "line": 115}, "message": "move constructor 'GVN' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h", "reportHash": "b0d2920babfdba7a9f38aaf7427b1ec6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 162, "line": 359}, "message": "default constructor 'GVNHoistPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h", "reportHash": "cac497ac87bfe051403230876b8a08e8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 162, "line": 366}, "message": "default constructor 'GVNSinkPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/GVN.h", "reportHash": "ef7b833b36f26444e3fd99c4489d401b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 163, "line": 26}, "message": "default constructor 'GuardWideningPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/GuardWidening.h", "reportHash": "abc84bed1ead26f3756752fff4cf2ac5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 164, "line": 21}, "message": "default constructor 'IRCEPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/InductiveRangeCheckElimination.h", "reportHash": "5612c587b069ec7ea2790f484cf7712b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 165, "line": 34}, "message": "default constructor 'InstSimplifyPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/InstSimplifyPass.h", "reportHash": "29b1b2603a3fd674f5a73e63e2fc6b42", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 166, "line": 25}, "message": "default constructor 'LoopDistributePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopDistribute.h", "reportHash": "7dd1c25526d0db4ee3a573aad1a539cc", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 167, "line": 23}, "message": "default constructor 'LoopFusePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopFuse.h", "reportHash": "8694c97ff64ebc361c9a3fd3bf3b3053", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 168, "line": 40}, "message": "default constructor 'LoopIdiomRecognizePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopIdiomRecognize.h", "reportHash": "7a6418c4ef3d3c7f5664a9016f067904", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 169, "line": 25}, "message": "default constructor 'LoopInstSimplifyPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopInstSimplify.h", "reportHash": "70cf86836ccb24b9dfbf75c1f66e7ac6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 170, "line": 17}, "message": "default constructor 'LoopInterchangePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopInterchange.h", "reportHash": "53174597457b4af335685d589c15a45a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 171, "line": 27}, "message": "default constructor 'LoopLoadEliminationPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopLoadElimination.h", "reportHash": "296e55e5e0f1940fd371071f60336af1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 173, "line": 24}, "message": "default constructor 'LoopPredicationPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopPredication.h", "reportHash": "1aa062d62e47c123edd2ad1105594e3a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 174, "line": 19}, "message": "default constructor 'LoopRerollPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopReroll.h", "reportHash": "570b547aa30ea75385fe05ee6515041f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 175, "line": 26}, "message": "default constructor 'LoopSimplifyCFGPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopSimplifyCFG.h", "reportHash": "2dd2d2192dca9708414fdda588b5daf2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 176, "line": 33}, "message": "default constructor 'LoopSinkPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopSink.h", "reportHash": "e3057db1712a5d434c4642bb5a56e483", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 178, "line": 61}, "message": "move constructor 'LoopUnrollOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopUnrollPass.h", "reportHash": "52c91e722fea463bee9d1aa790d1412a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 178, "line": 133}, "message": "move constructor 'LoopUnrollPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopUnrollPass.h", "reportHash": "57d124dd6381344e615b97a165c4c439", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 179, "line": 17}, "message": "default constructor 'LoopVersioningLICMPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LoopVersioningLICM.h", "reportHash": "6ac560d63c31e37e969ca2b0e7d1a461", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 180, "line": 22}, "message": "default constructor 'LowerAtomicPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerAtomic.h", "reportHash": "41eb7f4237a2e571cfbb957b5d617712", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 181, "line": 24}, "message": "default constructor 'LowerExpectIntrinsicPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerExpectIntrinsic.h", "reportHash": "285a9da0a059a302e828cbed3a5287c9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 182, "line": 21}, "message": "default constructor 'LowerGuardIntrinsicPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerGuardIntrinsic.h", "reportHash": "a763d13799b833c7c2894949c24a613a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 183, "line": 20}, "message": "default constructor 'LowerWidenableConditionPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/LowerWidenableCondition.h", "reportHash": "6a03c3f38659a3b83aa65767ee59e0bf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 184, "line": 40}, "message": "default constructor 'MakeGuardsExplicitPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MakeGuardsExplicit.h", "reportHash": "200504b97d1ad907bd320cdf4e0a9cdd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 186, "line": 30}, "message": "destructor '~MergedLoadStoreMotionOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MergedLoadStoreMotion.h", "reportHash": "6cd1757d5cffb696f82626e1ecbf080e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 186, "line": 30}, "message": "move constructor 'MergedLoadStoreMotionOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MergedLoadStoreMotion.h", "reportHash": "2354283957c8c38158acdfc9246e13d3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 186, "line": 41}, "message": "destructor '~MergedLoadStoreMotionPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MergedLoadStoreMotion.h", "reportHash": "ae91ce3feaf13161eff362cee41ce6d3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 186, "line": 41}, "message": "move constructor 'MergedLoadStoreMotionPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/MergedLoadStoreMotion.h", "reportHash": "db5a9250e05c00df3f93feb72476ee95", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 187, "line": 102}, "message": "default constructor 'NaryReassociatePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/NaryReassociate.h", "reportHash": "c61a10adfc415f374a012c885ccdedb3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 188, "line": 23}, "message": "default constructor 'NewGVNPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/NewGVN.h", "reportHash": "1f9689d38fd899e028c9e8f61ee45e05", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 190, "line": 71}, "message": "default constructor 'ReassociatePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Reassociate.h", "reportHash": "03c0761b7027bc7915384731114c5da6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 191, "line": 20}, "message": "default constructor 'RegToMemPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Reg2Mem.h", "reportHash": "e09998d63d693c8b2dfbc15a333fd5d2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 192, "line": 29}, "message": "default constructor 'RewriteStatepointsForGC' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/RewriteStatepointsForGC.h", "reportHash": "501a0a79f20fc605e3e46d8cba6f6acb", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 193, "line": 36}, "message": "default constructor 'SCCPPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SCCP.h", "reportHash": "a4341ffedbae9b27f38d813ec8f697e1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 195, "line": 24}, "message": "default constructor 'ScalarizerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Scalarizer.h", "reportHash": "808f57aef17a902ff38bf4a5cfd25de3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 196, "line": 62}, "message": "move constructor 'SimpleLoopUnswitchPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SimpleLoopUnswitch.h", "reportHash": "d827cf79340e303052a71b2c20f0d332", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 197, "line": 29}, "message": "move constructor 'SimplifyCFGPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SimplifyCFG.h", "reportHash": "8c67005a91d3834400a246dec2252490", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 198, "line": 23}, "message": "default constructor 'SinkingPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/Sink.h", "reportHash": "6787c8a17ed4243def9dd446b528a769", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 199, "line": 103}, "message": "default constructor 'SpeculateAroundPHIsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/SpeculateAroundPHIs.h", "reportHash": "d9d770d3efd59d827cd70048314db7f1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 200, "line": 16}, "message": "default constructor 'StraightLineStrengthReducePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/StraightLineStrengthReduce.h", "reportHash": "db76c31f2433be83c85655cef2f19c9e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 201, "line": 15}, "message": "default constructor 'StructurizeCFGPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/StructurizeCFG.h", "reportHash": "ddc6e5a057f237d9b237412458885fda", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 202, "line": 60}, "message": "default constructor 'TailCallElimPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Scalar/TailRecursionElimination.h", "reportHash": "5e9095a79b629b1c6dee2083b597aef3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 203, "line": 24}, "message": "default constructor 'AddDiscriminatorsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/AddDiscriminators.h", "reportHash": "5023c921e8cd212d417c9a6c29164bbb", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 204, "line": 54}, "message": "default constructor 'AssumeSimplifyPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/AssumeBundleBuilder.h", "reportHash": "1d4bbbc1d2535a3dbdc0fdf883580cec", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 204, "line": 62}, "message": "default constructor 'AssumeBuilderPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/AssumeBundleBuilder.h", "reportHash": "2b8c7dee6e4b033a5941539d8ad2da3e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 205, "line": 24}, "message": "default constructor 'BreakCriticalEdgesPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/BreakCriticalEdges.h", "reportHash": "565fc3951ed19b13b9381f9676b7b6c6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 206, "line": 24}, "message": "default constructor 'CanonicalizeFreezeInLoopsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/CanonicalizeFreezeInLoops.h", "reportHash": "32bb4c59f8d878d2050f88e3683d5f29", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 207, "line": 15}, "message": "default constructor 'FixIrreduciblePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/FixIrreducible.h", "reportHash": "3920489d349ea669f54fc6de80ee77f5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 208, "line": 16}, "message": "default constructor 'HelloWorldPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/HelloWorld.h", "reportHash": "0f58cffbf6441f252c36f2779789848b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 209, "line": 20}, "message": "default constructor 'InjectTLIMappings' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/InjectTLIMappings.h", "reportHash": "519e259bcef759feee0618d6d69a7e43", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 210, "line": 15}, "message": "default constructor 'InstructionNamerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/InstructionNamer.h", "reportHash": "83bf0d58cd5155d186ca8b5631cb52b8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 212, "line": 18}, "message": "default constructor 'LibCallsShrinkWrapPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/LibCallsShrinkWrap.h", "reportHash": "82a27cdab7a4fd7a790e713d9ceaf06c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 214, "line": 149}, "message": "default constructor 'LoopVersioningPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/LoopVersioning.h", "reportHash": "3da540fa3a937d2b556f917d563ade62", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 216, "line": 21}, "message": "default constructor 'LowerSwitchPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/LowerSwitch.h", "reportHash": "67e6145e10bc12385ae1416314803ba5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 217, "line": 23}, "message": "default constructor 'PromotePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/Mem2Reg.h", "reportHash": "58ff1efdf36b62d7b3bfb244c8e6668c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 218, "line": 21}, "message": "default constructor 'MetaRenamerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/MetaRenamer.h", "reportHash": "2db9be0cd09f95a24ff6f76fb33af2db", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 219, "line": 116}, "message": "destructor '~PredicateAssume' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/PredicateInfo.h", "reportHash": "5f558e62f9581b99830e409a904d3875", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 219, "line": 130}, "message": "destructor '~PredicateWithEdge' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/PredicateInfo.h", "reportHash": "3c46fbf582613041c0e2eec3bc95bf1e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 219, "line": 146}, "message": "destructor '~PredicateBranch' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/PredicateInfo.h", "reportHash": "bc37c23f2d823a8d030f2dc973de11d0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 219, "line": 160}, "message": "destructor '~PredicateSwitch' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/PredicateInfo.h", "reportHash": "7f917004d7b2e78a17091e2fbe532e52", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 221, "line": 18}, "message": "default constructor 'StripGCRelocates' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/StripGCRelocates.h", "reportHash": "ce7f297fdb8b0d8d247c6451e1530fc6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 222, "line": 18}, "message": "default constructor 'StripNonLineTableDebugInfoPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/StripNonLineTableDebugInfo.h", "reportHash": "345f62da5068da396e6dba216d8992db", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 223, "line": 37}, "message": "default constructor 'UnifyFunctionExitNodesPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/UnifyFunctionExitNodes.h", "reportHash": "de873a19b0a1a45cf951402b8b4e9581", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 224, "line": 16}, "message": "default constructor 'UnifyLoopExitsPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Utils/UnifyLoopExits.h", "reportHash": "6df14693b65cdd7b52b880ed67cd31c2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 225, "line": 16}, "message": "default constructor 'LoadStoreVectorizerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/LoadStoreVectorizer.h", "reportHash": "98cbd3c7451cf80c918e6c1c896d7549", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 226, "line": 83}, "message": "destructor '~LoopVectorizeOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/LoopVectorize.h", "reportHash": "8daee87f88c8479e3592e99a6d5d6114", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 226, "line": 83}, "message": "move constructor 'LoopVectorizeOptions' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/LoopVectorize.h", "reportHash": "db1d8a35ac6444f269af218737b69ccc", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 226, "line": 129}, "message": "move constructor 'LoopVectorizePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/LoopVectorize.h", "reportHash": "346c35ed23d0c16c375062ae9dd8c42e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 227, "line": 58}, "message": "default constructor 'SLPVectorizerPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/SLPVectorizer.h", "reportHash": "11cab230b5483ca257e98a2198e47034", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 228, "line": 23}, "message": "default constructor 'VectorCombinePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Transforms/Vectorize/VectorCombine.h", "reportHash": "59c43d597bb9a17d1b5fb71e2e98534d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 229, "line": 344}, "message": "default constructor 'NoOpModulePass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "9968935b58a1cc1d674a1bc1eb482000", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 229, "line": 353}, "message": "default constructor 'NoOpModuleAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "06c497f9486430bbe53286046eb90b45", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 358}, "message": "default constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "fea30c4384b634e32bec42adf08a85a2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 358}, "message": "destructor '~Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "932c23a68cec73c07dc9034ef386ec75", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 358}, "message": "move constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "69f952d17e0d60c313f316fd1e5582cf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 229, "line": 364}, "message": "default constructor 'NoOpCGSCCPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "195928eeb88ec1c24020f621b9282e5b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 229, "line": 373}, "message": "default constructor 'NoOpCGSCCAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "55328c23670a1273a15ab335603be744", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 378}, "message": "default constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "fea30c4384b634e32bec42adf08a85a2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 378}, "message": "destructor '~Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "932c23a68cec73c07dc9034ef386ec75", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 378}, "message": "move constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "69f952d17e0d60c313f316fd1e5582cf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 229, "line": 386}, "message": "default constructor 'NoOpFunctionPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "ef494a3b971f37563615b9cb0a5fa512", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 229, "line": 394}, "message": "default constructor 'NoOpFunctionAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "f54b145b5446b654e7380c7a3958d1a2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 399}, "message": "default constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "fea30c4384b634e32bec42adf08a85a2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 399}, "message": "destructor '~Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "932c23a68cec73c07dc9034ef386ec75", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 399}, "message": "move constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "69f952d17e0d60c313f316fd1e5582cf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 229, "line": 405}, "message": "default constructor 'NoOpLoopPass' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "0ad80dc9e54e9f5f199f6fe4efd3617a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 229, "line": 414}, "message": "default constructor 'NoOpLoopAnalysis' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "a38f59be7da45dbaea4094a5a0115a58", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 419}, "message": "default constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "fea30c4384b634e32bec42adf08a85a2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 419}, "message": "destructor '~Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "932c23a68cec73c07dc9034ef386ec75", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 229, "line": 419}, "message": "move constructor 'Result' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/lib/Passes/PassBuilder.cpp", "reportHash": "69f952d17e0d60c313f316fd1e5582cf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
