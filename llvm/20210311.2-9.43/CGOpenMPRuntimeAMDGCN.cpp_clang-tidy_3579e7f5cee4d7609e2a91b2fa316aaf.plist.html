<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"2": {"id": 2, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/ASTFwd.h", "content": "//===--- ASTFwd.h ----------------------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===--------------------------------------------------------------===//\n///\n/// \\file\n/// Forward declaration of all AST node types.\n///\n//===-------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_ASTFWD_H\n#define LLVM_CLANG_AST_ASTFWD_H\n\nnamespace clang {\n\nclass Decl;\n#define DECL(DERIVED, BASE) class DERIVED##Decl;\n#include \"clang/AST/DeclNodes.inc\"\nclass Stmt;\n#define STMT(DERIVED, BASE) class DERIVED;\n#include \"clang/AST/StmtNodes.inc\"\nclass Type;\n#define TYPE(DERIVED, BASE) class DERIVED##Type;\n#include \"clang/AST/TypeNodes.inc\"\nclass CXXCtorInitializer;\nclass OMPClause;\n#define GEN_CLANG_CLAUSE_CLASS\n#define CLAUSE_CLASS(Enum, Str, Class) class Class;\n#include \"llvm/Frontend/OpenMP/OMP.inc\"\n\n} // end namespace clang\n\n#endif\n"}, "3": {"id": 3, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/CharUnits.h", "content": "//===--- CharUnits.h - Character units for sizes and offsets ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n//  This file defines the CharUnits class\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_CHARUNITS_H\n#define LLVM_CLANG_AST_CHARUNITS_H\n\n#include \"llvm/ADT/DenseMapInfo.h\"\n#include \"llvm/Support/Alignment.h\"\n#include \"llvm/Support/DataTypes.h\"\n#include \"llvm/Support/MathExtras.h\"\n\nnamespace clang {\n\n  /// CharUnits - This is an opaque type for sizes expressed in character units.\n  /// Instances of this type represent a quantity as a multiple of the size\n  /// of the standard C type, char, on the target architecture. As an opaque\n  /// type, CharUnits protects you from accidentally combining operations on\n  /// quantities in bit units and character units.\n  ///\n  /// In both C and C++, an object of type 'char', 'signed char', or 'unsigned\n  /// char' occupies exactly one byte, so 'character unit' and 'byte' refer to\n  /// the same quantity of storage. However, we use the term 'character unit'\n  /// rather than 'byte' to avoid an implication that a character unit is\n  /// exactly 8 bits.\n  ///\n  /// For portability, never assume that a target character is 8 bits wide. Use\n  /// CharUnit values wherever you calculate sizes, offsets, or alignments\n  /// in character units.\n  class CharUnits {\n    public:\n      typedef int64_t QuantityType;\n\n    private:\n      QuantityType Quantity = 0;\n\n      explicit CharUnits(QuantityType C) : Quantity(C) {}\n\n    public:\n\n      /// CharUnits - A default constructor.\n      CharUnits() = default;\n\n      /// Zero - Construct a CharUnits quantity of zero.\n      static CharUnits Zero() {\n        return CharUnits(0);\n      }\n\n      /// One - Construct a CharUnits quantity of one.\n      static CharUnits One() {\n        return CharUnits(1);\n      }\n\n      /// fromQuantity - Construct a CharUnits quantity from a raw integer type.\n      static CharUnits fromQuantity(QuantityType Quantity) {\n        return CharUnits(Quantity);\n      }\n\n      // Compound assignment.\n      CharUnits& operator+= (const CharUnits &Other) {\n        Quantity += Other.Quantity;\n        return *this;\n      }\n      CharUnits& operator++ () {\n        ++Quantity;\n        return *this;\n      }\n      CharUnits operator++ (int) {\n        return CharUnits(Quantity++);\n      }\n      CharUnits& operator-= (const CharUnits &Other) {\n        Quantity -= Other.Quantity;\n        return *this;\n      }\n      CharUnits& operator-- () {\n        --Quantity;\n        return *this;\n      }\n      CharUnits operator-- (int) {\n        return CharUnits(Quantity--);\n      }\n\n      // Comparison operators.\n      bool operator== (const CharUnits &Other) const {\n        return Quantity == Other.Quantity;\n      }\n      bool operator!= (const CharUnits &Other) const {\n        return Quantity != Other.Quantity;\n      }\n\n      // Relational operators.\n      bool operator<  (const CharUnits &Other) const {\n        return Quantity <  Other.Quantity;\n      }\n      bool operator<= (const CharUnits &Other) const {\n        return Quantity <= Other.Quantity;\n      }\n      bool operator>  (const CharUnits &Other) const {\n        return Quantity >  Other.Quantity;\n      }\n      bool operator>= (const CharUnits &Other) const {\n        return Quantity >= Other.Quantity;\n      }\n\n      // Other predicates.\n\n      /// isZero - Test whether the quantity equals zero.\n      bool isZero() const     { return Quantity == 0; }\n\n      /// isOne - Test whether the quantity equals one.\n      bool isOne() const      { return Quantity == 1; }\n\n      /// isPositive - Test whether the quantity is greater than zero.\n      bool isPositive() const { return Quantity  > 0; }\n\n      /// isNegative - Test whether the quantity is less than zero.\n      bool isNegative() const { return Quantity  < 0; }\n\n      /// isPowerOfTwo - Test whether the quantity is a power of two.\n      /// Zero is not a power of two.\n      bool isPowerOfTwo() const {\n        return (Quantity & -Quantity) == Quantity;\n      }\n\n      /// Test whether this is a multiple of the other value.\n      ///\n      /// Among other things, this promises that\n      /// self.alignTo(N) will just return self.\n      bool isMultipleOf(CharUnits N) const {\n        return (*this % N) == 0;\n      }\n\n      // Arithmetic operators.\n      CharUnits operator* (QuantityType N) const {\n        return CharUnits(Quantity * N);\n      }\n      CharUnits &operator*= (QuantityType N) {\n        Quantity *= N;\n        return *this;\n      }\n      CharUnits operator/ (QuantityType N) const {\n        return CharUnits(Quantity / N);\n      }\n      CharUnits &operator/= (QuantityType N) {\n        Quantity /= N;\n        return *this;\n      }\n      QuantityType operator/ (const CharUnits &Other) const {\n        return Quantity / Other.Quantity;\n      }\n      CharUnits operator% (QuantityType N) const {\n        return CharUnits(Quantity % N);\n      }\n      QuantityType operator% (const CharUnits &Other) const {\n        return Quantity % Other.Quantity;\n      }\n      CharUnits operator+ (const CharUnits &Other) const {\n        return CharUnits(Quantity + Other.Quantity);\n      }\n      CharUnits operator- (const CharUnits &Other) const {\n        return CharUnits(Quantity - Other.Quantity);\n      }\n      CharUnits operator- () const {\n        return CharUnits(-Quantity);\n      }\n\n\n      // Conversions.\n\n      /// getQuantity - Get the raw integer representation of this quantity.\n      QuantityType getQuantity() const { return Quantity; }\n\n      /// getAsAlign - Returns Quantity as a valid llvm::Align,\n      /// Beware llvm::Align assumes power of two 8-bit bytes.\n      llvm::Align getAsAlign() const { return llvm::Align(Quantity); }\n\n      /// alignTo - Returns the next integer (mod 2**64) that is\n      /// greater than or equal to this quantity and is a multiple of \\p Align.\n      /// Align must be non-zero.\n      CharUnits alignTo(const CharUnits &Align) const {\n        return CharUnits(llvm::alignTo(Quantity, Align.Quantity));\n      }\n\n      /// Given that this is a non-zero alignment value, what is the\n      /// alignment at the given offset?\n      CharUnits alignmentAtOffset(CharUnits offset) const {\n        assert(Quantity != 0 && \"offsetting from unknown alignment?\");\n        return CharUnits(llvm::MinAlign(Quantity, offset.Quantity));\n      }\n\n      /// Given that this is the alignment of the first element of an\n      /// array, return the minimum alignment of any element in the array.\n      CharUnits alignmentOfArrayElement(CharUnits elementSize) const {\n        // Since we don't track offsetted alignments, the alignment of\n        // the second element (or any odd element) will be minimally\n        // aligned.\n        return alignmentAtOffset(elementSize);\n      }\n\n\n  }; // class CharUnit\n} // namespace clang\n\ninline clang::CharUnits operator* (clang::CharUnits::QuantityType Scale,\n                                   const clang::CharUnits &CU) {\n  return CU * Scale;\n}\n\nnamespace llvm {\n\ntemplate<> struct DenseMapInfo<clang::CharUnits> {\n  static clang::CharUnits getEmptyKey() {\n    clang::CharUnits::QuantityType Quantity =\n      DenseMapInfo<clang::CharUnits::QuantityType>::getEmptyKey();\n\n    return clang::CharUnits::fromQuantity(Quantity);\n  }\n\n  static clang::CharUnits getTombstoneKey() {\n    clang::CharUnits::QuantityType Quantity =\n      DenseMapInfo<clang::CharUnits::QuantityType>::getTombstoneKey();\n\n    return clang::CharUnits::fromQuantity(Quantity);\n  }\n\n  static unsigned getHashValue(const clang::CharUnits &CU) {\n    clang::CharUnits::QuantityType Quantity = CU.getQuantity();\n    return DenseMapInfo<clang::CharUnits::QuantityType>::getHashValue(Quantity);\n  }\n\n  static bool isEqual(const clang::CharUnits &LHS,\n                      const clang::CharUnits &RHS) {\n    return LHS == RHS;\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_CLANG_AST_CHARUNITS_H\n"}, "4": {"id": 4, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/CurrentSourceLocExprScope.h", "content": "//===--- CurrentSourceLocExprScope.h ----------------------------*- C++ -*-===//\n//\n//                     The LLVM Compiler Infrastructure\n//\n// This file is distributed under the University of Illinois Open Source\n// License. See LICENSE.TXT for details.\n//\n//===----------------------------------------------------------------------===//\n//\n//  This file defines types used to track the current context needed to evaluate\n//  a SourceLocExpr.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_CURRENT_SOURCE_LOC_EXPR_SCOPE_H\n#define LLVM_CLANG_AST_CURRENT_SOURCE_LOC_EXPR_SCOPE_H\n\n#include <cassert>\n\nnamespace clang {\nclass Expr;\n\n/// Represents the current source location and context used to determine the\n/// value of the source location builtins (ex. __builtin_LINE), including the\n/// context of default argument and default initializer expressions.\nclass CurrentSourceLocExprScope {\n  /// The CXXDefaultArgExpr or CXXDefaultInitExpr we're currently evaluating.\n  const Expr *DefaultExpr = nullptr;\n\npublic:\n  /// A RAII style scope guard used for tracking the current source\n  /// location and context as used by the source location builtins\n  /// (ex. __builtin_LINE).\n  class SourceLocExprScopeGuard;\n\n  const Expr *getDefaultExpr() const { return DefaultExpr; }\n\n  explicit CurrentSourceLocExprScope() = default;\n\nprivate:\n  explicit CurrentSourceLocExprScope(const Expr *DefaultExpr)\n      : DefaultExpr(DefaultExpr) {}\n\n  CurrentSourceLocExprScope(CurrentSourceLocExprScope const &) = default;\n  CurrentSourceLocExprScope &\n  operator=(CurrentSourceLocExprScope const &) = default;\n};\n\nclass CurrentSourceLocExprScope::SourceLocExprScopeGuard {\npublic:\n  SourceLocExprScopeGuard(const Expr *DefaultExpr,\n                          CurrentSourceLocExprScope &Current)\n      : Current(Current), OldVal(Current), Enable(false) {\n    assert(DefaultExpr && \"the new scope should not be empty\");\n    if ((Enable = (Current.getDefaultExpr() == nullptr)))\n      Current = CurrentSourceLocExprScope(DefaultExpr);\n  }\n\n  ~SourceLocExprScopeGuard() {\n    if (Enable)\n      Current = OldVal;\n  }\n\nprivate:\n  SourceLocExprScopeGuard(SourceLocExprScopeGuard const &) = delete;\n  SourceLocExprScopeGuard &operator=(SourceLocExprScopeGuard const &) = delete;\n\n  CurrentSourceLocExprScope &Current;\n  CurrentSourceLocExprScope OldVal;\n  bool Enable;\n};\n\n} // end namespace clang\n\n#endif // LLVM_CLANG_AST_CURRENT_SOURCE_LOC_EXPR_SCOPE_H\n"}, "15": {"id": 15, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Mangle.h", "content": "//===--- Mangle.h - Mangle C++ Names ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Defines the C++ name mangling interface.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_MANGLE_H\n#define LLVM_CLANG_AST_MANGLE_H\n\n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/GlobalDecl.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/ABI.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/Support/Casting.h\"\n\nnamespace llvm {\n  class raw_ostream;\n}\n\nnamespace clang {\n  class ASTContext;\n  class BlockDecl;\n  class CXXConstructorDecl;\n  class CXXDestructorDecl;\n  class CXXMethodDecl;\n  class FunctionDecl;\n  struct MethodVFTableLocation;\n  class NamedDecl;\n  class ObjCMethodDecl;\n  class StringLiteral;\n  struct ThisAdjustment;\n  struct ThunkInfo;\n  class VarDecl;\n\n/// MangleContext - Context for tracking state which persists across multiple\n/// calls to the C++ name mangler.\nclass MangleContext {\npublic:\n  enum ManglerKind {\n    MK_Itanium,\n    MK_Microsoft\n  };\n\nprivate:\n  virtual void anchor();\n\n  ASTContext &Context;\n  DiagnosticsEngine &Diags;\n  const ManglerKind Kind;\n\n  llvm::DenseMap<const BlockDecl*, unsigned> GlobalBlockIds;\n  llvm::DenseMap<const BlockDecl*, unsigned> LocalBlockIds;\n  llvm::DenseMap<const NamedDecl*, uint64_t> AnonStructIds;\n\npublic:\n  ManglerKind getKind() const { return Kind; }\n\n  explicit MangleContext(ASTContext &Context,\n                         DiagnosticsEngine &Diags,\n                         ManglerKind Kind)\n      : Context(Context), Diags(Diags), Kind(Kind) {}\n\n  virtual ~MangleContext() { }\n\n  ASTContext &getASTContext() const { return Context; }\n\n  DiagnosticsEngine &getDiags() const { return Diags; }\n\n  virtual void startNewFunction() { LocalBlockIds.clear(); }\n\n  unsigned getBlockId(const BlockDecl *BD, bool Local) {\n    llvm::DenseMap<const BlockDecl *, unsigned> &BlockIds\n      = Local? LocalBlockIds : GlobalBlockIds;\n    std::pair<llvm::DenseMap<const BlockDecl *, unsigned>::iterator, bool>\n      Result = BlockIds.insert(std::make_pair(BD, BlockIds.size()));\n    return Result.first->second;\n  }\n\n  uint64_t getAnonymousStructId(const NamedDecl *D) {\n    std::pair<llvm::DenseMap<const NamedDecl *, uint64_t>::iterator, bool>\n        Result = AnonStructIds.insert(std::make_pair(D, AnonStructIds.size()));\n    return Result.first->second;\n  }\n\n  uint64_t getAnonymousStructIdForDebugInfo(const NamedDecl *D) {\n    llvm::DenseMap<const NamedDecl *, uint64_t>::iterator Result =\n        AnonStructIds.find(D);\n    // The decl should already be inserted, but return 0 in case it is not.\n    if (Result == AnonStructIds.end())\n      return 0;\n    return Result->second;\n  }\n\n  virtual std::string getLambdaString(const CXXRecordDecl *Lambda) = 0;\n\n  /// @name Mangler Entry Points\n  /// @{\n\n  bool shouldMangleDeclName(const NamedDecl *D);\n  virtual bool shouldMangleCXXName(const NamedDecl *D) = 0;\n  virtual bool shouldMangleStringLiteral(const StringLiteral *SL) = 0;\n\n  virtual bool isDeviceMangleContext() const { return false; }\n  virtual void setDeviceMangleContext(bool) {}\n\n  virtual bool isUniqueInternalLinkageDecl(const NamedDecl *ND) {\n    return false;\n  }\n\n  virtual void needsUniqueInternalLinkageNames() { }\n\n  // FIXME: consider replacing raw_ostream & with something like SmallString &.\n  void mangleName(GlobalDecl GD, raw_ostream &);\n  virtual void mangleCXXName(GlobalDecl GD, raw_ostream &) = 0;\n  virtual void mangleThunk(const CXXMethodDecl *MD,\n                          const ThunkInfo &Thunk,\n                          raw_ostream &) = 0;\n  virtual void mangleCXXDtorThunk(const CXXDestructorDecl *DD, CXXDtorType Type,\n                                  const ThisAdjustment &ThisAdjustment,\n                                  raw_ostream &) = 0;\n  virtual void mangleReferenceTemporary(const VarDecl *D,\n                                        unsigned ManglingNumber,\n                                        raw_ostream &) = 0;\n  virtual void mangleCXXRTTI(QualType T, raw_ostream &) = 0;\n  virtual void mangleCXXRTTIName(QualType T, raw_ostream &) = 0;\n  virtual void mangleStringLiteral(const StringLiteral *SL, raw_ostream &) = 0;\n  virtual void mangleMSGuidDecl(const MSGuidDecl *GD, raw_ostream&);\n\n  void mangleGlobalBlock(const BlockDecl *BD,\n                         const NamedDecl *ID,\n                         raw_ostream &Out);\n  void mangleCtorBlock(const CXXConstructorDecl *CD, CXXCtorType CT,\n                       const BlockDecl *BD, raw_ostream &Out);\n  void mangleDtorBlock(const CXXDestructorDecl *CD, CXXDtorType DT,\n                       const BlockDecl *BD, raw_ostream &Out);\n  void mangleBlock(const DeclContext *DC, const BlockDecl *BD,\n                   raw_ostream &Out);\n\n  void mangleObjCMethodName(const ObjCMethodDecl *MD, raw_ostream &OS,\n                            bool includePrefixByte = true,\n                            bool includeCategoryNamespace = true);\n  void mangleObjCMethodNameAsSourceName(const ObjCMethodDecl *MD,\n                                        raw_ostream &);\n\n  virtual void mangleStaticGuardVariable(const VarDecl *D, raw_ostream &) = 0;\n\n  virtual void mangleDynamicInitializer(const VarDecl *D, raw_ostream &) = 0;\n\n  virtual void mangleDynamicAtExitDestructor(const VarDecl *D,\n                                             raw_ostream &) = 0;\n\n  virtual void mangleSEHFilterExpression(const NamedDecl *EnclosingDecl,\n                                         raw_ostream &Out) = 0;\n\n  virtual void mangleSEHFinallyBlock(const NamedDecl *EnclosingDecl,\n                                     raw_ostream &Out) = 0;\n\n  /// Generates a unique string for an externally visible type for use with TBAA\n  /// or type uniquing.\n  /// TODO: Extend this to internal types by generating names that are unique\n  /// across translation units so it can be used with LTO.\n  virtual void mangleTypeName(QualType T, raw_ostream &) = 0;\n\n  /// @}\n};\n\nclass ItaniumMangleContext : public MangleContext {\npublic:\n  explicit ItaniumMangleContext(ASTContext &C, DiagnosticsEngine &D)\n      : MangleContext(C, D, MK_Itanium) {}\n\n  virtual void mangleCXXVTable(const CXXRecordDecl *RD, raw_ostream &) = 0;\n  virtual void mangleCXXVTT(const CXXRecordDecl *RD, raw_ostream &) = 0;\n  virtual void mangleCXXCtorVTable(const CXXRecordDecl *RD, int64_t Offset,\n                                   const CXXRecordDecl *Type,\n                                   raw_ostream &) = 0;\n  virtual void mangleItaniumThreadLocalInit(const VarDecl *D,\n                                            raw_ostream &) = 0;\n  virtual void mangleItaniumThreadLocalWrapper(const VarDecl *D,\n                                               raw_ostream &) = 0;\n\n  virtual void mangleCXXCtorComdat(const CXXConstructorDecl *D,\n                                   raw_ostream &) = 0;\n  virtual void mangleCXXDtorComdat(const CXXDestructorDecl *D,\n                                   raw_ostream &) = 0;\n\n  virtual void mangleLambdaSig(const CXXRecordDecl *Lambda, raw_ostream &) = 0;\n\n  virtual void mangleDynamicStermFinalizer(const VarDecl *D, raw_ostream &) = 0;\n\n  static bool classof(const MangleContext *C) {\n    return C->getKind() == MK_Itanium;\n  }\n\n  static ItaniumMangleContext *create(ASTContext &Context,\n                                      DiagnosticsEngine &Diags);\n};\n\nclass MicrosoftMangleContext : public MangleContext {\npublic:\n  explicit MicrosoftMangleContext(ASTContext &C, DiagnosticsEngine &D)\n      : MangleContext(C, D, MK_Microsoft) {}\n\n  /// Mangle vftable symbols.  Only a subset of the bases along the path\n  /// to the vftable are included in the name.  It's up to the caller to pick\n  /// them correctly.\n  virtual void mangleCXXVFTable(const CXXRecordDecl *Derived,\n                                ArrayRef<const CXXRecordDecl *> BasePath,\n                                raw_ostream &Out) = 0;\n\n  /// Mangle vbtable symbols.  Only a subset of the bases along the path\n  /// to the vbtable are included in the name.  It's up to the caller to pick\n  /// them correctly.\n  virtual void mangleCXXVBTable(const CXXRecordDecl *Derived,\n                                ArrayRef<const CXXRecordDecl *> BasePath,\n                                raw_ostream &Out) = 0;\n\n  virtual void mangleThreadSafeStaticGuardVariable(const VarDecl *VD,\n                                                   unsigned GuardNum,\n                                                   raw_ostream &Out) = 0;\n\n  virtual void mangleVirtualMemPtrThunk(const CXXMethodDecl *MD,\n                                        const MethodVFTableLocation &ML,\n                                        raw_ostream &Out) = 0;\n\n  virtual void mangleCXXVirtualDisplacementMap(const CXXRecordDecl *SrcRD,\n                                               const CXXRecordDecl *DstRD,\n                                               raw_ostream &Out) = 0;\n\n  virtual void mangleCXXThrowInfo(QualType T, bool IsConst, bool IsVolatile,\n                                  bool IsUnaligned, uint32_t NumEntries,\n                                  raw_ostream &Out) = 0;\n\n  virtual void mangleCXXCatchableTypeArray(QualType T, uint32_t NumEntries,\n                                           raw_ostream &Out) = 0;\n\n  virtual void mangleCXXCatchableType(QualType T, const CXXConstructorDecl *CD,\n                                      CXXCtorType CT, uint32_t Size,\n                                      uint32_t NVOffset, int32_t VBPtrOffset,\n                                      uint32_t VBIndex, raw_ostream &Out) = 0;\n\n  virtual void mangleCXXRTTIBaseClassDescriptor(\n      const CXXRecordDecl *Derived, uint32_t NVOffset, int32_t VBPtrOffset,\n      uint32_t VBTableOffset, uint32_t Flags, raw_ostream &Out) = 0;\n\n  virtual void mangleCXXRTTIBaseClassArray(const CXXRecordDecl *Derived,\n                                           raw_ostream &Out) = 0;\n  virtual void\n  mangleCXXRTTIClassHierarchyDescriptor(const CXXRecordDecl *Derived,\n                                        raw_ostream &Out) = 0;\n\n  virtual void\n  mangleCXXRTTICompleteObjectLocator(const CXXRecordDecl *Derived,\n                                     ArrayRef<const CXXRecordDecl *> BasePath,\n                                     raw_ostream &Out) = 0;\n\n  static bool classof(const MangleContext *C) {\n    return C->getKind() == MK_Microsoft;\n  }\n\n  static MicrosoftMangleContext *create(ASTContext &Context,\n                                        DiagnosticsEngine &Diags);\n};\n\nclass ASTNameGenerator {\npublic:\n  explicit ASTNameGenerator(ASTContext &Ctx);\n  ~ASTNameGenerator();\n\n  /// Writes name for \\p D to \\p OS.\n  /// \\returns true on failure, false on success.\n  bool writeName(const Decl *D, raw_ostream &OS);\n\n  /// \\returns name for \\p D\n  std::string getName(const Decl *D);\n\n  /// \\returns all applicable mangled names.\n  /// For example C++ constructors/destructors can have multiple.\n  std::vector<std::string> getAllManglings(const Decl *D);\n\nprivate:\n  class Implementation;\n  std::unique_ptr<Implementation> Impl;\n};\n}\n\n#endif\n"}, "17": {"id": 17, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/PrettyPrinter.h", "content": "//===--- PrettyPrinter.h - Classes for aiding with AST printing -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n//  This file defines helper types for AST pretty-printing.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_PRETTYPRINTER_H\n#define LLVM_CLANG_AST_PRETTYPRINTER_H\n\n#include \"clang/Basic/LLVM.h\"\n#include \"clang/Basic/LangOptions.h\"\n\nnamespace clang {\n\nclass DeclContext;\nclass LangOptions;\nclass SourceManager;\nclass Stmt;\nclass TagDecl;\n\nclass PrinterHelper {\npublic:\n  virtual ~PrinterHelper();\n  virtual bool handledStmt(Stmt* E, raw_ostream& OS) = 0;\n};\n\n/// Callbacks to use to customize the behavior of the pretty-printer.\nclass PrintingCallbacks {\nprotected:\n  ~PrintingCallbacks() = default;\n\npublic:\n  /// Remap a path to a form suitable for printing.\n  virtual std::string remapPath(StringRef Path) const {\n    return std::string(Path);\n  }\n\n  /// When printing type to be inserted into code in specific context, this\n  /// callback can be used to avoid printing the redundant part of the\n  /// qualifier. For example, when inserting code inside namespace foo, we\n  /// should print bar::SomeType instead of foo::bar::SomeType.\n  /// To do this, shouldPrintScope should return true on \"foo\" NamespaceDecl.\n  /// The printing stops at the first isScopeVisible() == true, so there will\n  /// be no calls with outer scopes.\n  virtual bool isScopeVisible(const DeclContext *DC) const { return false; }\n};\n\n/// Describes how types, statements, expressions, and declarations should be\n/// printed.\n///\n/// This type is intended to be small and suitable for passing by value.\n/// It is very frequently copied.\nstruct PrintingPolicy {\n  /// Create a default printing policy for the specified language.\n  PrintingPolicy(const LangOptions &LO)\n      : Indentation(2), SuppressSpecifiers(false),\n        SuppressTagKeyword(LO.CPlusPlus), IncludeTagDefinition(false),\n        SuppressScope(false), SuppressUnwrittenScope(false),\n        SuppressInlineNamespace(true), SuppressInitializers(false),\n        ConstantArraySizeAsWritten(false), AnonymousTagLocations(true),\n        SuppressStrongLifetime(false), SuppressLifetimeQualifiers(false),\n        SuppressTemplateArgsInCXXConstructors(false),\n        SuppressDefaultTemplateArgs(true), Bool(LO.Bool),\n        Nullptr(LO.CPlusPlus11), Restrict(LO.C99), Alignof(LO.CPlusPlus11),\n        UnderscoreAlignof(LO.C11), UseVoidForZeroParams(!LO.CPlusPlus),\n        SplitTemplateClosers(!LO.CPlusPlus11), TerseOutput(false),\n        PolishForDeclaration(false), Half(LO.Half),\n        MSWChar(LO.MicrosoftExt && !LO.WChar), IncludeNewlines(true),\n        MSVCFormatting(false), ConstantsAsWritten(false),\n        SuppressImplicitBase(false), FullyQualifiedName(false),\n        PrintCanonicalTypes(false), PrintInjectedClassNameWithArguments(true) {}\n\n  /// Adjust this printing policy for cases where it's known that we're\n  /// printing C++ code (for instance, if AST dumping reaches a C++-only\n  /// construct). This should not be used if a real LangOptions object is\n  /// available.\n  void adjustForCPlusPlus() {\n    SuppressTagKeyword = true;\n    Bool = true;\n    UseVoidForZeroParams = false;\n  }\n\n  /// The number of spaces to use to indent each line.\n  unsigned Indentation : 8;\n\n  /// Whether we should suppress printing of the actual specifiers for\n  /// the given type or declaration.\n  ///\n  /// This flag is only used when we are printing declarators beyond\n  /// the first declarator within a declaration group. For example, given:\n  ///\n  /// \\code\n  /// const int *x, *y;\n  /// \\endcode\n  ///\n  /// SuppressSpecifiers will be false when printing the\n  /// declaration for \"x\", so that we will print \"int *x\"; it will be\n  /// \\c true when we print \"y\", so that we suppress printing the\n  /// \"const int\" type specifier and instead only print the \"*y\".\n  unsigned SuppressSpecifiers : 1;\n\n  /// Whether type printing should skip printing the tag keyword.\n  ///\n  /// This is used when printing the inner type of elaborated types,\n  /// (as the tag keyword is part of the elaborated type):\n  ///\n  /// \\code\n  /// struct Geometry::Point;\n  /// \\endcode\n  unsigned SuppressTagKeyword : 1;\n\n  /// When true, include the body of a tag definition.\n  ///\n  /// This is used to place the definition of a struct\n  /// in the middle of another declaration as with:\n  ///\n  /// \\code\n  /// typedef struct { int x, y; } Point;\n  /// \\endcode\n  unsigned IncludeTagDefinition : 1;\n\n  /// Suppresses printing of scope specifiers.\n  unsigned SuppressScope : 1;\n\n  /// Suppress printing parts of scope specifiers that are never\n  /// written, e.g., for anonymous namespaces.\n  unsigned SuppressUnwrittenScope : 1;\n\n  /// Suppress printing parts of scope specifiers that correspond\n  /// to inline namespaces, where the name is unambiguous with the specifier\n  /// removed.\n  unsigned SuppressInlineNamespace : 1;\n\n  /// Suppress printing of variable initializers.\n  ///\n  /// This flag is used when printing the loop variable in a for-range\n  /// statement. For example, given:\n  ///\n  /// \\code\n  /// for (auto x : coll)\n  /// \\endcode\n  ///\n  /// SuppressInitializers will be true when printing \"auto x\", so that the\n  /// internal initializer constructed for x will not be printed.\n  unsigned SuppressInitializers : 1;\n\n  /// Whether we should print the sizes of constant array expressions as written\n  /// in the sources.\n  ///\n  /// This flag determines whether array types declared as\n  ///\n  /// \\code\n  /// int a[4+10*10];\n  /// char a[] = \"A string\";\n  /// \\endcode\n  ///\n  /// will be printed as written or as follows:\n  ///\n  /// \\code\n  /// int a[104];\n  /// char a[9] = \"A string\";\n  /// \\endcode\n  unsigned ConstantArraySizeAsWritten : 1;\n\n  /// When printing an anonymous tag name, also print the location of that\n  /// entity (e.g., \"enum <anonymous at t.h:10:5>\"). Otherwise, just prints\n  /// \"(anonymous)\" for the name.\n  unsigned AnonymousTagLocations : 1;\n\n  /// When true, suppress printing of the __strong lifetime qualifier in ARC.\n  unsigned SuppressStrongLifetime : 1;\n\n  /// When true, suppress printing of lifetime qualifier in ARC.\n  unsigned SuppressLifetimeQualifiers : 1;\n\n  /// When true, suppresses printing template arguments in names of C++\n  /// constructors.\n  unsigned SuppressTemplateArgsInCXXConstructors : 1;\n\n  /// When true, attempt to suppress template arguments that match the default\n  /// argument for the parameter.\n  unsigned SuppressDefaultTemplateArgs : 1;\n\n  /// Whether we can use 'bool' rather than '_Bool' (even if the language\n  /// doesn't actually have 'bool', because, e.g., it is defined as a macro).\n  unsigned Bool : 1;\n\n  /// Whether we should use 'nullptr' rather than '0' as a null pointer\n  /// constant.\n  unsigned Nullptr : 1;\n\n  /// Whether we can use 'restrict' rather than '__restrict'.\n  unsigned Restrict : 1;\n\n  /// Whether we can use 'alignof' rather than '__alignof'.\n  unsigned Alignof : 1;\n\n  /// Whether we can use '_Alignof' rather than '__alignof'.\n  unsigned UnderscoreAlignof : 1;\n\n  /// Whether we should use '(void)' rather than '()' for a function prototype\n  /// with zero parameters.\n  unsigned UseVoidForZeroParams : 1;\n\n  /// Whether nested templates must be closed like 'a\\<b\\<c\\> \\>' rather than\n  /// 'a\\<b\\<c\\>\\>'.\n  unsigned SplitTemplateClosers : 1;\n\n  /// Provide a 'terse' output.\n  ///\n  /// For example, in this mode we don't print function bodies, class members,\n  /// declarations inside namespaces etc.  Effectively, this should print\n  /// only the requested declaration.\n  unsigned TerseOutput : 1;\n\n  /// When true, do certain refinement needed for producing proper declaration\n  /// tag; such as, do not print attributes attached to the declaration.\n  ///\n  unsigned PolishForDeclaration : 1;\n\n  /// When true, print the half-precision floating-point type as 'half'\n  /// instead of '__fp16'\n  unsigned Half : 1;\n\n  /// When true, print the built-in wchar_t type as __wchar_t. For use in\n  /// Microsoft mode when wchar_t is not available.\n  unsigned MSWChar : 1;\n\n  /// When true, include newlines after statements like \"break\", etc.\n  unsigned IncludeNewlines : 1;\n\n  /// Use whitespace and punctuation like MSVC does. In particular, this prints\n  /// anonymous namespaces as `anonymous namespace' and does not insert spaces\n  /// after template arguments.\n  unsigned MSVCFormatting : 1;\n\n  /// Whether we should print the constant expressions as written in the\n  /// sources.\n  ///\n  /// This flag determines whether constants expressions like\n  ///\n  /// \\code\n  /// 0x10\n  /// 2.5e3\n  /// \\endcode\n  ///\n  /// will be printed as written or as follows:\n  ///\n  /// \\code\n  /// 0x10\n  /// 2.5e3\n  /// \\endcode\n  unsigned ConstantsAsWritten : 1;\n\n  /// When true, don't print the implicit 'self' or 'this' expressions.\n  unsigned SuppressImplicitBase : 1;\n\n  /// When true, print the fully qualified name of function declarations.\n  /// This is the opposite of SuppressScope and thus overrules it.\n  unsigned FullyQualifiedName : 1;\n\n  /// Whether to print types as written or canonically.\n  unsigned PrintCanonicalTypes : 1;\n\n  /// Whether to print an InjectedClassNameType with template arguments or as\n  /// written. When a template argument is unnamed, printing it results in\n  /// invalid C++ code.\n  unsigned PrintInjectedClassNameWithArguments : 1;\n\n  /// Callbacks to use to allow the behavior of printing to be customized.\n  const PrintingCallbacks *Callbacks = nullptr;\n};\n\n} // end namespace clang\n\n#endif\n"}, "22": {"id": 22, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/VTableBuilder.h", "content": "//===--- VTableBuilder.h - C++ vtable layout builder --------------*- C++ -*-=//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This contains code dealing with generation of the layout of virtual tables.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_VTABLEBUILDER_H\n#define LLVM_CLANG_AST_VTABLEBUILDER_H\n\n#include \"clang/AST/BaseSubobject.h\"\n#include \"clang/AST/CXXInheritance.h\"\n#include \"clang/AST/GlobalDecl.h\"\n#include \"clang/AST/RecordLayout.h\"\n#include \"clang/Basic/ABI.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include <memory>\n#include <utility>\n\nnamespace clang {\n  class CXXRecordDecl;\n\n/// Represents a single component in a vtable.\nclass VTableComponent {\npublic:\n  enum Kind {\n    CK_VCallOffset,\n    CK_VBaseOffset,\n    CK_OffsetToTop,\n    CK_RTTI,\n    CK_FunctionPointer,\n\n    /// A pointer to the complete destructor.\n    CK_CompleteDtorPointer,\n\n    /// A pointer to the deleting destructor.\n    CK_DeletingDtorPointer,\n\n    /// An entry that is never used.\n    ///\n    /// In some cases, a vtable function pointer will end up never being\n    /// called. Such vtable function pointers are represented as a\n    /// CK_UnusedFunctionPointer.\n    CK_UnusedFunctionPointer\n  };\n\n  VTableComponent() = default;\n\n  static VTableComponent MakeVCallOffset(CharUnits Offset) {\n    return VTableComponent(CK_VCallOffset, Offset);\n  }\n\n  static VTableComponent MakeVBaseOffset(CharUnits Offset) {\n    return VTableComponent(CK_VBaseOffset, Offset);\n  }\n\n  static VTableComponent MakeOffsetToTop(CharUnits Offset) {\n    return VTableComponent(CK_OffsetToTop, Offset);\n  }\n\n  static VTableComponent MakeRTTI(const CXXRecordDecl *RD) {\n    return VTableComponent(CK_RTTI, reinterpret_cast<uintptr_t>(RD));\n  }\n\n  static VTableComponent MakeFunction(const CXXMethodDecl *MD) {\n    assert(!isa<CXXDestructorDecl>(MD) &&\n           \"Don't use MakeFunction with destructors!\");\n\n    return VTableComponent(CK_FunctionPointer,\n                           reinterpret_cast<uintptr_t>(MD));\n  }\n\n  static VTableComponent MakeCompleteDtor(const CXXDestructorDecl *DD) {\n    return VTableComponent(CK_CompleteDtorPointer,\n                           reinterpret_cast<uintptr_t>(DD));\n  }\n\n  static VTableComponent MakeDeletingDtor(const CXXDestructorDecl *DD) {\n    return VTableComponent(CK_DeletingDtorPointer,\n                           reinterpret_cast<uintptr_t>(DD));\n  }\n\n  static VTableComponent MakeUnusedFunction(const CXXMethodDecl *MD) {\n    assert(!isa<CXXDestructorDecl>(MD) &&\n           \"Don't use MakeUnusedFunction with destructors!\");\n    return VTableComponent(CK_UnusedFunctionPointer,\n                           reinterpret_cast<uintptr_t>(MD));\n  }\n\n  /// Get the kind of this vtable component.\n  Kind getKind() const {\n    return (Kind)(Value & 0x7);\n  }\n\n  CharUnits getVCallOffset() const {\n    assert(getKind() == CK_VCallOffset && \"Invalid component kind!\");\n\n    return getOffset();\n  }\n\n  CharUnits getVBaseOffset() const {\n    assert(getKind() == CK_VBaseOffset && \"Invalid component kind!\");\n\n    return getOffset();\n  }\n\n  CharUnits getOffsetToTop() const {\n    assert(getKind() == CK_OffsetToTop && \"Invalid component kind!\");\n\n    return getOffset();\n  }\n\n  const CXXRecordDecl *getRTTIDecl() const {\n    assert(isRTTIKind() && \"Invalid component kind!\");\n    return reinterpret_cast<CXXRecordDecl *>(getPointer());\n  }\n\n  const CXXMethodDecl *getFunctionDecl() const {\n    assert(isFunctionPointerKind() && \"Invalid component kind!\");\n    if (isDestructorKind())\n      return getDestructorDecl();\n    return reinterpret_cast<CXXMethodDecl *>(getPointer());\n  }\n\n  const CXXDestructorDecl *getDestructorDecl() const {\n    assert(isDestructorKind() && \"Invalid component kind!\");\n    return reinterpret_cast<CXXDestructorDecl *>(getPointer());\n  }\n\n  const CXXMethodDecl *getUnusedFunctionDecl() const {\n    assert(getKind() == CK_UnusedFunctionPointer && \"Invalid component kind!\");\n    return reinterpret_cast<CXXMethodDecl *>(getPointer());\n  }\n\n  bool isDestructorKind() const { return isDestructorKind(getKind()); }\n\n  bool isUsedFunctionPointerKind() const {\n    return isUsedFunctionPointerKind(getKind());\n  }\n\n  bool isFunctionPointerKind() const {\n    return isFunctionPointerKind(getKind());\n  }\n\n  bool isRTTIKind() const { return isRTTIKind(getKind()); }\n\n  GlobalDecl getGlobalDecl() const {\n    assert(isUsedFunctionPointerKind() &&\n           \"GlobalDecl can be created only from virtual function\");\n\n    auto *DtorDecl = dyn_cast<CXXDestructorDecl>(getFunctionDecl());\n    switch (getKind()) {\n    case CK_FunctionPointer:\n      return GlobalDecl(getFunctionDecl());\n    case CK_CompleteDtorPointer:\n      return GlobalDecl(DtorDecl, CXXDtorType::Dtor_Complete);\n    case CK_DeletingDtorPointer:\n      return GlobalDecl(DtorDecl, CXXDtorType::Dtor_Deleting);\n    case CK_VCallOffset:\n    case CK_VBaseOffset:\n    case CK_OffsetToTop:\n    case CK_RTTI:\n    case CK_UnusedFunctionPointer:\n      llvm_unreachable(\"Only function pointers kinds\");\n    }\n    llvm_unreachable(\"Should already return\");\n  }\n\nprivate:\n  static bool isFunctionPointerKind(Kind ComponentKind) {\n    return isUsedFunctionPointerKind(ComponentKind) ||\n           ComponentKind == CK_UnusedFunctionPointer;\n  }\n  static bool isUsedFunctionPointerKind(Kind ComponentKind) {\n    return ComponentKind == CK_FunctionPointer ||\n           isDestructorKind(ComponentKind);\n  }\n  static bool isDestructorKind(Kind ComponentKind) {\n    return ComponentKind == CK_CompleteDtorPointer ||\n           ComponentKind == CK_DeletingDtorPointer;\n  }\n  static bool isRTTIKind(Kind ComponentKind) {\n    return ComponentKind == CK_RTTI;\n  }\n\n  VTableComponent(Kind ComponentKind, CharUnits Offset) {\n    assert((ComponentKind == CK_VCallOffset ||\n            ComponentKind == CK_VBaseOffset ||\n            ComponentKind == CK_OffsetToTop) && \"Invalid component kind!\");\n    assert(Offset.getQuantity() < (1LL << 56) && \"Offset is too big!\");\n    assert(Offset.getQuantity() >= -(1LL << 56) && \"Offset is too small!\");\n\n    Value = (uint64_t(Offset.getQuantity()) << 3) | ComponentKind;\n  }\n\n  VTableComponent(Kind ComponentKind, uintptr_t Ptr) {\n    assert((isRTTIKind(ComponentKind) || isFunctionPointerKind(ComponentKind)) &&\n           \"Invalid component kind!\");\n\n    assert((Ptr & 7) == 0 && \"Pointer not sufficiently aligned!\");\n\n    Value = Ptr | ComponentKind;\n  }\n\n  CharUnits getOffset() const {\n    assert((getKind() == CK_VCallOffset || getKind() == CK_VBaseOffset ||\n            getKind() == CK_OffsetToTop) && \"Invalid component kind!\");\n\n    return CharUnits::fromQuantity(Value >> 3);\n  }\n\n  uintptr_t getPointer() const {\n    assert((getKind() == CK_RTTI || isFunctionPointerKind()) &&\n           \"Invalid component kind!\");\n\n    return static_cast<uintptr_t>(Value & ~7ULL);\n  }\n\n  /// The kind is stored in the lower 3 bits of the value. For offsets, we\n  /// make use of the facts that classes can't be larger than 2^55 bytes,\n  /// so we store the offset in the lower part of the 61 bits that remain.\n  /// (The reason that we're not simply using a PointerIntPair here is that we\n  /// need the offsets to be 64-bit, even when on a 32-bit machine).\n  int64_t Value;\n};\n\nclass VTableLayout {\npublic:\n  typedef std::pair<uint64_t, ThunkInfo> VTableThunkTy;\n  struct AddressPointLocation {\n    unsigned VTableIndex, AddressPointIndex;\n  };\n  typedef llvm::DenseMap<BaseSubobject, AddressPointLocation>\n      AddressPointsMapTy;\n\n  // Mapping between the VTable index and address point index. This is useful\n  // when you don't care about the base subobjects and only want the address\n  // point for a given vtable index.\n  typedef llvm::SmallVector<unsigned, 4> AddressPointsIndexMapTy;\n\nprivate:\n  // Stores the component indices of the first component of each virtual table in\n  // the virtual table group. To save a little memory in the common case where\n  // the vtable group contains a single vtable, an empty vector here represents\n  // the vector {0}.\n  OwningArrayRef<size_t> VTableIndices;\n\n  OwningArrayRef<VTableComponent> VTableComponents;\n\n  /// Contains thunks needed by vtables, sorted by indices.\n  OwningArrayRef<VTableThunkTy> VTableThunks;\n\n  /// Address points for all vtables.\n  AddressPointsMapTy AddressPoints;\n\n  /// Address points for all vtable indices.\n  AddressPointsIndexMapTy AddressPointIndices;\n\npublic:\n  VTableLayout(ArrayRef<size_t> VTableIndices,\n               ArrayRef<VTableComponent> VTableComponents,\n               ArrayRef<VTableThunkTy> VTableThunks,\n               const AddressPointsMapTy &AddressPoints);\n  ~VTableLayout();\n\n  ArrayRef<VTableComponent> vtable_components() const {\n    return VTableComponents;\n  }\n\n  ArrayRef<VTableThunkTy> vtable_thunks() const {\n    return VTableThunks;\n  }\n\n  AddressPointLocation getAddressPoint(BaseSubobject Base) const {\n    assert(AddressPoints.count(Base) && \"Did not find address point!\");\n    return AddressPoints.find(Base)->second;\n  }\n\n  const AddressPointsMapTy &getAddressPoints() const {\n    return AddressPoints;\n  }\n\n  const AddressPointsIndexMapTy &getAddressPointIndices() const {\n    return AddressPointIndices;\n  }\n\n  size_t getNumVTables() const {\n    if (VTableIndices.empty())\n      return 1;\n    return VTableIndices.size();\n  }\n\n  size_t getVTableOffset(size_t i) const {\n    if (VTableIndices.empty()) {\n      assert(i == 0);\n      return 0;\n    }\n    return VTableIndices[i];\n  }\n\n  size_t getVTableSize(size_t i) const {\n    if (VTableIndices.empty()) {\n      assert(i == 0);\n      return vtable_components().size();\n    }\n\n    size_t thisIndex = VTableIndices[i];\n    size_t nextIndex = (i + 1 == VTableIndices.size())\n                           ? vtable_components().size()\n                           : VTableIndices[i + 1];\n    return nextIndex - thisIndex;\n  }\n};\n\nclass VTableContextBase {\npublic:\n  typedef SmallVector<ThunkInfo, 1> ThunkInfoVectorTy;\n\n  bool isMicrosoft() const { return IsMicrosoftABI; }\n\n  virtual ~VTableContextBase() {}\n\nprotected:\n  typedef llvm::DenseMap<const CXXMethodDecl *, ThunkInfoVectorTy> ThunksMapTy;\n\n  /// Contains all thunks that a given method decl will need.\n  ThunksMapTy Thunks;\n\n  /// Compute and store all vtable related information (vtable layout, vbase\n  /// offset offsets, thunks etc) for the given record decl.\n  virtual void computeVTableRelatedInformation(const CXXRecordDecl *RD) = 0;\n\n  VTableContextBase(bool MS) : IsMicrosoftABI(MS) {}\n\npublic:\n  virtual const ThunkInfoVectorTy *getThunkInfo(GlobalDecl GD) {\n    const CXXMethodDecl *MD = cast<CXXMethodDecl>(GD.getDecl()->getCanonicalDecl());\n    computeVTableRelatedInformation(MD->getParent());\n\n    // This assumes that all the destructors present in the vtable\n    // use exactly the same set of thunks.\n    ThunksMapTy::const_iterator I = Thunks.find(MD);\n    if (I == Thunks.end()) {\n      // We did not find a thunk for this method.\n      return nullptr;\n    }\n\n    return &I->second;\n  }\n\n  bool IsMicrosoftABI;\n\n  /// Determine whether this function should be assigned a vtable slot.\n  static bool hasVtableSlot(const CXXMethodDecl *MD);\n};\n\nclass ItaniumVTableContext : public VTableContextBase {\nprivate:\n\n  /// Contains the index (relative to the vtable address point)\n  /// where the function pointer for a virtual function is stored.\n  typedef llvm::DenseMap<GlobalDecl, int64_t> MethodVTableIndicesTy;\n  MethodVTableIndicesTy MethodVTableIndices;\n\n  typedef llvm::DenseMap<const CXXRecordDecl *,\n                         std::unique_ptr<const VTableLayout>>\n      VTableLayoutMapTy;\n  VTableLayoutMapTy VTableLayouts;\n\n  typedef std::pair<const CXXRecordDecl *,\n                    const CXXRecordDecl *> ClassPairTy;\n\n  /// vtable offsets for offsets of virtual bases of a class.\n  ///\n  /// Contains the vtable offset (relative to the address point) in chars\n  /// where the offsets for virtual bases of a class are stored.\n  typedef llvm::DenseMap<ClassPairTy, CharUnits>\n    VirtualBaseClassOffsetOffsetsMapTy;\n  VirtualBaseClassOffsetOffsetsMapTy VirtualBaseClassOffsetOffsets;\n\n  void computeVTableRelatedInformation(const CXXRecordDecl *RD) override;\n\npublic:\n  enum VTableComponentLayout {\n    /// Components in the vtable are pointers to other structs/functions.\n    Pointer,\n\n    /// Components in the vtable are relative offsets between the vtable and the\n    /// other structs/functions.\n    Relative,\n  };\n\n  ItaniumVTableContext(ASTContext &Context,\n                       VTableComponentLayout ComponentLayout = Pointer);\n  ~ItaniumVTableContext() override;\n\n  const VTableLayout &getVTableLayout(const CXXRecordDecl *RD) {\n    computeVTableRelatedInformation(RD);\n    assert(VTableLayouts.count(RD) && \"No layout for this record decl!\");\n\n    return *VTableLayouts[RD];\n  }\n\n  std::unique_ptr<VTableLayout> createConstructionVTableLayout(\n      const CXXRecordDecl *MostDerivedClass, CharUnits MostDerivedClassOffset,\n      bool MostDerivedClassIsVirtual, const CXXRecordDecl *LayoutClass);\n\n  /// Locate a virtual function in the vtable.\n  ///\n  /// Return the index (relative to the vtable address point) where the\n  /// function pointer for the given virtual function is stored.\n  uint64_t getMethodVTableIndex(GlobalDecl GD);\n\n  /// Return the offset in chars (relative to the vtable address point) where\n  /// the offset of the virtual base that contains the given base is stored,\n  /// otherwise, if no virtual base contains the given class, return 0.\n  ///\n  /// Base must be a virtual base class or an unambiguous base.\n  CharUnits getVirtualBaseOffsetOffset(const CXXRecordDecl *RD,\n                                       const CXXRecordDecl *VBase);\n\n  static bool classof(const VTableContextBase *VT) {\n    return !VT->isMicrosoft();\n  }\n\n  VTableComponentLayout getVTableComponentLayout() const {\n    return ComponentLayout;\n  }\n\n  bool isPointerLayout() const { return ComponentLayout == Pointer; }\n  bool isRelativeLayout() const { return ComponentLayout == Relative; }\n\nprivate:\n  VTableComponentLayout ComponentLayout;\n};\n\n/// Holds information about the inheritance path to a virtual base or function\n/// table pointer.  A record may contain as many vfptrs or vbptrs as there are\n/// base subobjects.\nstruct VPtrInfo {\n  typedef SmallVector<const CXXRecordDecl *, 1> BasePath;\n\n  VPtrInfo(const CXXRecordDecl *RD)\n      : ObjectWithVPtr(RD), IntroducingObject(RD), NextBaseToMangle(RD) {}\n\n  /// This is the most derived class that has this vptr at offset zero. When\n  /// single inheritance is used, this is always the most derived class. If\n  /// multiple inheritance is used, it may be any direct or indirect base.\n  const CXXRecordDecl *ObjectWithVPtr;\n\n  /// This is the class that introduced the vptr by declaring new virtual\n  /// methods or virtual bases.\n  const CXXRecordDecl *IntroducingObject;\n\n  /// IntroducingObject is at this offset from its containing complete object or\n  /// virtual base.\n  CharUnits NonVirtualOffset;\n\n  /// The bases from the inheritance path that got used to mangle the vbtable\n  /// name.  This is not really a full path like a CXXBasePath.  It holds the\n  /// subset of records that need to be mangled into the vbtable symbol name in\n  /// order to get a unique name.\n  BasePath MangledPath;\n\n  /// The next base to push onto the mangled path if this path is ambiguous in a\n  /// derived class.  If it's null, then it's already been pushed onto the path.\n  const CXXRecordDecl *NextBaseToMangle;\n\n  /// The set of possibly indirect vbases that contain this vbtable.  When a\n  /// derived class indirectly inherits from the same vbase twice, we only keep\n  /// vtables and their paths from the first instance.\n  BasePath ContainingVBases;\n\n  /// This holds the base classes path from the complete type to the first base\n  /// with the given vfptr offset, in the base-to-derived order.  Only used for\n  /// vftables.\n  BasePath PathToIntroducingObject;\n\n  /// Static offset from the top of the most derived class to this vfptr,\n  /// including any virtual base offset.  Only used for vftables.\n  CharUnits FullOffsetInMDC;\n\n  /// The vptr is stored inside the non-virtual component of this virtual base.\n  const CXXRecordDecl *getVBaseWithVPtr() const {\n    return ContainingVBases.empty() ? nullptr : ContainingVBases.front();\n  }\n};\n\ntypedef SmallVector<std::unique_ptr<VPtrInfo>, 2> VPtrInfoVector;\n\n/// All virtual base related information about a given record decl.  Includes\n/// information on all virtual base tables and the path components that are used\n/// to mangle them.\nstruct VirtualBaseInfo {\n  /// A map from virtual base to vbtable index for doing a conversion from the\n  /// the derived class to the a base.\n  llvm::DenseMap<const CXXRecordDecl *, unsigned> VBTableIndices;\n\n  /// Information on all virtual base tables used when this record is the most\n  /// derived class.\n  VPtrInfoVector VBPtrPaths;\n};\n\nstruct MethodVFTableLocation {\n  /// If nonzero, holds the vbtable index of the virtual base with the vfptr.\n  uint64_t VBTableIndex;\n\n  /// If nonnull, holds the last vbase which contains the vfptr that the\n  /// method definition is adjusted to.\n  const CXXRecordDecl *VBase;\n\n  /// This is the offset of the vfptr from the start of the last vbase, or the\n  /// complete type if there are no virtual bases.\n  CharUnits VFPtrOffset;\n\n  /// Method's index in the vftable.\n  uint64_t Index;\n\n  MethodVFTableLocation()\n      : VBTableIndex(0), VBase(nullptr), VFPtrOffset(CharUnits::Zero()),\n        Index(0) {}\n\n  MethodVFTableLocation(uint64_t VBTableIndex, const CXXRecordDecl *VBase,\n                        CharUnits VFPtrOffset, uint64_t Index)\n      : VBTableIndex(VBTableIndex), VBase(VBase), VFPtrOffset(VFPtrOffset),\n        Index(Index) {}\n\n  bool operator<(const MethodVFTableLocation &other) const {\n    if (VBTableIndex != other.VBTableIndex) {\n      assert(VBase != other.VBase);\n      return VBTableIndex < other.VBTableIndex;\n    }\n    return std::tie(VFPtrOffset, Index) <\n           std::tie(other.VFPtrOffset, other.Index);\n  }\n};\n\nclass MicrosoftVTableContext : public VTableContextBase {\npublic:\n\nprivate:\n  ASTContext &Context;\n\n  typedef llvm::DenseMap<GlobalDecl, MethodVFTableLocation>\n    MethodVFTableLocationsTy;\n  MethodVFTableLocationsTy MethodVFTableLocations;\n\n  typedef llvm::DenseMap<const CXXRecordDecl *, std::unique_ptr<VPtrInfoVector>>\n      VFPtrLocationsMapTy;\n  VFPtrLocationsMapTy VFPtrLocations;\n\n  typedef std::pair<const CXXRecordDecl *, CharUnits> VFTableIdTy;\n  typedef llvm::DenseMap<VFTableIdTy, std::unique_ptr<const VTableLayout>>\n      VFTableLayoutMapTy;\n  VFTableLayoutMapTy VFTableLayouts;\n\n  llvm::DenseMap<const CXXRecordDecl *, std::unique_ptr<VirtualBaseInfo>>\n      VBaseInfo;\n\n  void enumerateVFPtrs(const CXXRecordDecl *ForClass, VPtrInfoVector &Result);\n\n  void computeVTableRelatedInformation(const CXXRecordDecl *RD) override;\n\n  void dumpMethodLocations(const CXXRecordDecl *RD,\n                           const MethodVFTableLocationsTy &NewMethods,\n                           raw_ostream &);\n\n  const VirtualBaseInfo &\n  computeVBTableRelatedInformation(const CXXRecordDecl *RD);\n\n  void computeVTablePaths(bool ForVBTables, const CXXRecordDecl *RD,\n                          VPtrInfoVector &Paths);\n\npublic:\n  MicrosoftVTableContext(ASTContext &Context)\n      : VTableContextBase(/*MS=*/true), Context(Context) {}\n\n  ~MicrosoftVTableContext() override;\n\n  const VPtrInfoVector &getVFPtrOffsets(const CXXRecordDecl *RD);\n\n  const VTableLayout &getVFTableLayout(const CXXRecordDecl *RD,\n                                       CharUnits VFPtrOffset);\n\n  MethodVFTableLocation getMethodVFTableLocation(GlobalDecl GD);\n\n  const ThunkInfoVectorTy *getThunkInfo(GlobalDecl GD) override {\n    // Complete destructors don't have a slot in a vftable, so no thunks needed.\n    if (isa<CXXDestructorDecl>(GD.getDecl()) &&\n        GD.getDtorType() == Dtor_Complete)\n      return nullptr;\n    return VTableContextBase::getThunkInfo(GD);\n  }\n\n  /// Returns the index of VBase in the vbtable of Derived.\n  /// VBase must be a morally virtual base of Derived.\n  /// The vbtable is an array of i32 offsets.  The first entry is a self entry,\n  /// and the rest are offsets from the vbptr to virtual bases.\n  unsigned getVBTableIndex(const CXXRecordDecl *Derived,\n                           const CXXRecordDecl *VBase);\n\n  const VPtrInfoVector &enumerateVBTables(const CXXRecordDecl *RD);\n\n  static bool classof(const VTableContextBase *VT) { return VT->isMicrosoft(); }\n};\n\n} // namespace clang\n\n#endif\n"}, "30": {"id": 30, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/Basic/Sanitizers.h", "content": "//===- Sanitizers.h - C Language Family Language Options --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// Defines the clang::SanitizerKind enum.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_BASIC_SANITIZERS_H\n#define LLVM_CLANG_BASIC_SANITIZERS_H\n\n#include \"clang/Basic/LLVM.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/Support/MathExtras.h\"\n#include \"llvm/Transforms/Instrumentation/AddressSanitizerOptions.h\"\n#include <cassert>\n#include <cstdint>\n\nnamespace llvm {\nclass hash_code;\n}\n\nnamespace clang {\n\nclass SanitizerMask {\n  // NOTE: this class assumes kNumElem == 2 in most of the constexpr functions,\n  // in order to work within the C++11 constexpr function constraints. If you\n  // change kNumElem, you'll need to update those member functions as well.\n\n  /// Number of array elements.\n  static constexpr unsigned kNumElem = 2;\n  /// Mask value initialized to 0.\n  uint64_t maskLoToHigh[kNumElem]{};\n  /// Number of bits in a mask.\n  static constexpr unsigned kNumBits = sizeof(decltype(maskLoToHigh)) * 8;\n  /// Number of bits in a mask element.\n  static constexpr unsigned kNumBitElem = sizeof(decltype(maskLoToHigh[0])) * 8;\n\n  constexpr SanitizerMask(uint64_t mask1, uint64_t mask2)\n      : maskLoToHigh{mask1, mask2} {}\n\npublic:\n  SanitizerMask() = default;\n\n  static constexpr bool checkBitPos(const unsigned Pos) {\n    return Pos < kNumBits;\n  }\n\n  /// Create a mask with a bit enabled at position Pos.\n  static constexpr SanitizerMask bitPosToMask(const unsigned Pos) {\n    uint64_t mask1 = (Pos < kNumBitElem) ? 1ULL << (Pos % kNumBitElem) : 0;\n    uint64_t mask2 = (Pos >= kNumBitElem && Pos < (kNumBitElem * 2))\n                         ? 1ULL << (Pos % kNumBitElem)\n                         : 0;\n    return SanitizerMask(mask1, mask2);\n  }\n\n  unsigned countPopulation() const {\n    unsigned total = 0;\n    for (const auto &Val : maskLoToHigh)\n      total += llvm::countPopulation(Val);\n    return total;\n  }\n\n  void flipAllBits() {\n    for (auto &Val : maskLoToHigh)\n      Val = ~Val;\n  }\n\n  bool isPowerOf2() const {\n    return countPopulation() == 1;\n  }\n\n  llvm::hash_code hash_value() const;\n\n  constexpr explicit operator bool() const {\n    return maskLoToHigh[0] || maskLoToHigh[1];\n  }\n\n  constexpr bool operator==(const SanitizerMask &V) const {\n    return maskLoToHigh[0] == V.maskLoToHigh[0] &&\n           maskLoToHigh[1] == V.maskLoToHigh[1];\n  }\n\n  SanitizerMask &operator&=(const SanitizerMask &RHS) {\n    for (unsigned k = 0; k < kNumElem; k++)\n      maskLoToHigh[k] &= RHS.maskLoToHigh[k];\n    return *this;\n  }\n\n  SanitizerMask &operator|=(const SanitizerMask &RHS) {\n    for (unsigned k = 0; k < kNumElem; k++)\n      maskLoToHigh[k] |= RHS.maskLoToHigh[k];\n    return *this;\n  }\n\n  constexpr bool operator!() const { return !bool(*this); }\n\n  constexpr bool operator!=(const SanitizerMask &RHS) const {\n    return !((*this) == RHS);\n  }\n\n  friend constexpr inline SanitizerMask operator~(SanitizerMask v) {\n    return SanitizerMask(~v.maskLoToHigh[0], ~v.maskLoToHigh[1]);\n  }\n\n  friend constexpr inline SanitizerMask operator&(SanitizerMask a,\n                                                  const SanitizerMask &b) {\n    return SanitizerMask(a.maskLoToHigh[0] & b.maskLoToHigh[0],\n                         a.maskLoToHigh[1] & b.maskLoToHigh[1]);\n  }\n\n  friend constexpr inline SanitizerMask operator|(SanitizerMask a,\n                                                  const SanitizerMask &b) {\n    return SanitizerMask(a.maskLoToHigh[0] | b.maskLoToHigh[0],\n                         a.maskLoToHigh[1] | b.maskLoToHigh[1]);\n  }\n};\n\n// Declaring in clang namespace so that it can be found by ADL.\nllvm::hash_code hash_value(const clang::SanitizerMask &Arg);\n\n// Define the set of sanitizer kinds, as well as the set of sanitizers each\n// sanitizer group expands into.\nstruct SanitizerKind {\n  // Assign ordinals to possible values of -fsanitize= flag, which we will use\n  // as bit positions.\n  enum SanitizerOrdinal : uint64_t {\n#define SANITIZER(NAME, ID) SO_##ID,\n#define SANITIZER_GROUP(NAME, ID, ALIAS) SO_##ID##Group,\n#include \"clang/Basic/Sanitizers.def\"\n    SO_Count\n  };\n\n#define SANITIZER(NAME, ID)                                                    \\\n  static constexpr SanitizerMask ID = SanitizerMask::bitPosToMask(SO_##ID);    \\\n  static_assert(SanitizerMask::checkBitPos(SO_##ID), \"Bit position too big.\");\n#define SANITIZER_GROUP(NAME, ID, ALIAS)                                       \\\n  static constexpr SanitizerMask ID = SanitizerMask(ALIAS);                    \\\n  static constexpr SanitizerMask ID##Group =                                   \\\n      SanitizerMask::bitPosToMask(SO_##ID##Group);                             \\\n  static_assert(SanitizerMask::checkBitPos(SO_##ID##Group),                    \\\n                \"Bit position too big.\");\n#include \"clang/Basic/Sanitizers.def\"\n}; // SanitizerKind\n\nstruct SanitizerSet {\n  /// Check if a certain (single) sanitizer is enabled.\n  bool has(SanitizerMask K) const {\n    assert(K.isPowerOf2() && \"Has to be a single sanitizer.\");\n    return static_cast<bool>(Mask & K);\n  }\n\n  /// Check if one or more sanitizers are enabled.\n  bool hasOneOf(SanitizerMask K) const { return static_cast<bool>(Mask & K); }\n\n  /// Enable or disable a certain (single) sanitizer.\n  void set(SanitizerMask K, bool Value) {\n    assert(K.isPowerOf2() && \"Has to be a single sanitizer.\");\n    Mask = Value ? (Mask | K) : (Mask & ~K);\n  }\n\n  /// Disable the sanitizers specified in \\p K.\n  void clear(SanitizerMask K = SanitizerKind::All) { Mask &= ~K; }\n\n  /// Returns true if no sanitizers are enabled.\n  bool empty() const { return !Mask; }\n\n  /// Bitmask of enabled sanitizers.\n  SanitizerMask Mask;\n};\n\n/// Parse a single value from a -fsanitize= or -fno-sanitize= value list.\n/// Returns a non-zero SanitizerMask, or \\c 0 if \\p Value is not known.\nSanitizerMask parseSanitizerValue(StringRef Value, bool AllowGroups);\n\n/// Serialize a SanitizerSet into values for -fsanitize= or -fno-sanitize=.\nvoid serializeSanitizerSet(SanitizerSet Set,\n                           SmallVectorImpl<StringRef> &Values);\n\n/// For each sanitizer group bit set in \\p Kinds, set the bits for sanitizers\n/// this group enables.\nSanitizerMask expandSanitizerGroups(SanitizerMask Kinds);\n\n/// Return the sanitizers which do not affect preprocessing.\ninline SanitizerMask getPPTransparentSanitizers() {\n  return SanitizerKind::CFI | SanitizerKind::Integer |\n         SanitizerKind::ImplicitConversion | SanitizerKind::Nullability |\n         SanitizerKind::Undefined | SanitizerKind::FloatDivideByZero;\n}\n\nStringRef AsanDtorKindToString(llvm::AsanDtorKind kind);\n\nllvm::AsanDtorKind AsanDtorKindFromString(StringRef kind);\n\n} // namespace clang\n\n#endif // LLVM_CLANG_BASIC_SANITIZERS_H\n"}, "32": {"id": 32, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/Basic/TargetInfo.h", "content": "//===--- TargetInfo.h - Expose information about the target -----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n///\n/// \\file\n/// Defines the clang::TargetInfo interface.\n///\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_BASIC_TARGETINFO_H\n#define LLVM_CLANG_BASIC_TARGETINFO_H\n\n#include \"clang/Basic/AddressSpaces.h\"\n#include \"clang/Basic/CodeGenOptions.h\"\n#include \"clang/Basic/LLVM.h\"\n#include \"clang/Basic/LangOptions.h\"\n#include \"clang/Basic/Specifiers.h\"\n#include \"clang/Basic/TargetCXXABI.h\"\n#include \"clang/Basic/TargetOptions.h\"\n#include \"llvm/ADT/APFloat.h\"\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/IntrusiveRefCntPtr.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/SmallSet.h\"\n#include \"llvm/ADT/StringMap.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Triple.h\"\n#include \"llvm/Frontend/OpenMP/OMPGridValues.h\"\n#include \"llvm/Support/DataTypes.h\"\n#include \"llvm/Support/Error.h\"\n#include \"llvm/Support/VersionTuple.h\"\n#include <cassert>\n#include <string>\n#include <vector>\n\nnamespace llvm {\nstruct fltSemantics;\nclass DataLayout;\n}\n\nnamespace clang {\nclass DiagnosticsEngine;\nclass LangOptions;\nclass CodeGenOptions;\nclass MacroBuilder;\nclass QualType;\nclass SourceLocation;\nclass SourceManager;\n\nnamespace Builtin { struct Info; }\n\n/// Fields controlling how types are laid out in memory; these may need to\n/// be copied for targets like AMDGPU that base their ABIs on an auxiliary\n/// CPU target.\nstruct TransferrableTargetInfo {\n  unsigned char PointerWidth, PointerAlign;\n  unsigned char BoolWidth, BoolAlign;\n  unsigned char IntWidth, IntAlign;\n  unsigned char HalfWidth, HalfAlign;\n  unsigned char BFloat16Width, BFloat16Align;\n  unsigned char FloatWidth, FloatAlign;\n  unsigned char DoubleWidth, DoubleAlign;\n  unsigned char LongDoubleWidth, LongDoubleAlign, Float128Align;\n  unsigned char LargeArrayMinWidth, LargeArrayAlign;\n  unsigned char LongWidth, LongAlign;\n  unsigned char LongLongWidth, LongLongAlign;\n\n  // Fixed point bit widths\n  unsigned char ShortAccumWidth, ShortAccumAlign;\n  unsigned char AccumWidth, AccumAlign;\n  unsigned char LongAccumWidth, LongAccumAlign;\n  unsigned char ShortFractWidth, ShortFractAlign;\n  unsigned char FractWidth, FractAlign;\n  unsigned char LongFractWidth, LongFractAlign;\n\n  // If true, unsigned fixed point types have the same number of fractional bits\n  // as their signed counterparts, forcing the unsigned types to have one extra\n  // bit of padding. Otherwise, unsigned fixed point types have\n  // one more fractional bit than its corresponding signed type. This is false\n  // by default.\n  bool PaddingOnUnsignedFixedPoint;\n\n  // Fixed point integral and fractional bit sizes\n  // Saturated types share the same integral/fractional bits as their\n  // corresponding unsaturated types.\n  // For simplicity, the fractional bits in a _Fract type will be one less the\n  // width of that _Fract type. This leaves all signed _Fract types having no\n  // padding and unsigned _Fract types will only have 1 bit of padding after the\n  // sign if PaddingOnUnsignedFixedPoint is set.\n  unsigned char ShortAccumScale;\n  unsigned char AccumScale;\n  unsigned char LongAccumScale;\n\n  unsigned char SuitableAlign;\n  unsigned char DefaultAlignForAttributeAligned;\n  unsigned char MinGlobalAlign;\n\n  unsigned short NewAlign;\n  unsigned MaxVectorAlign;\n  unsigned MaxTLSAlign;\n\n  const llvm::fltSemantics *HalfFormat, *BFloat16Format, *FloatFormat,\n    *DoubleFormat, *LongDoubleFormat, *Float128Format;\n\n  ///===---- Target Data Type Query Methods -------------------------------===//\n  enum IntType {\n    NoInt = 0,\n    SignedChar,\n    UnsignedChar,\n    SignedShort,\n    UnsignedShort,\n    SignedInt,\n    UnsignedInt,\n    SignedLong,\n    UnsignedLong,\n    SignedLongLong,\n    UnsignedLongLong\n  };\n\n  enum RealType {\n    NoFloat = 255,\n    Float = 0,\n    Double,\n    LongDouble,\n    Float128\n  };\nprotected:\n  IntType SizeType, IntMaxType, PtrDiffType, IntPtrType, WCharType,\n          WIntType, Char16Type, Char32Type, Int64Type, SigAtomicType,\n          ProcessIDType;\n\n  /// Whether Objective-C's built-in boolean type should be signed char.\n  ///\n  /// Otherwise, when this flag is not set, the normal built-in boolean type is\n  /// used.\n  unsigned UseSignedCharForObjCBool : 1;\n\n  /// Control whether the alignment of bit-field types is respected when laying\n  /// out structures. If true, then the alignment of the bit-field type will be\n  /// used to (a) impact the alignment of the containing structure, and (b)\n  /// ensure that the individual bit-field will not straddle an alignment\n  /// boundary.\n  unsigned UseBitFieldTypeAlignment : 1;\n\n  /// Whether zero length bitfields (e.g., int : 0;) force alignment of\n  /// the next bitfield.\n  ///\n  /// If the alignment of the zero length bitfield is greater than the member\n  /// that follows it, `bar', `bar' will be aligned as the type of the\n  /// zero-length bitfield.\n  unsigned UseZeroLengthBitfieldAlignment : 1;\n\n  ///  Whether explicit bit field alignment attributes are honored.\n  unsigned UseExplicitBitFieldAlignment : 1;\n\n  /// If non-zero, specifies a fixed alignment value for bitfields that follow\n  /// zero length bitfield, regardless of the zero length bitfield type.\n  unsigned ZeroLengthBitfieldBoundary;\n};\n\n/// OpenCL type kinds.\nenum OpenCLTypeKind : uint8_t {\n  OCLTK_Default,\n  OCLTK_ClkEvent,\n  OCLTK_Event,\n  OCLTK_Image,\n  OCLTK_Pipe,\n  OCLTK_Queue,\n  OCLTK_ReserveID,\n  OCLTK_Sampler,\n};\n\n/// Exposes information about the current target.\n///\nclass TargetInfo : public virtual TransferrableTargetInfo,\n                   public RefCountedBase<TargetInfo> {\n  std::shared_ptr<TargetOptions> TargetOpts;\n  llvm::Triple Triple;\nprotected:\n  // Target values set by the ctor of the actual target implementation.  Default\n  // values are specified by the TargetInfo constructor.\n  bool BigEndian;\n  bool TLSSupported;\n  bool VLASupported;\n  bool NoAsmVariants;  // True if {|} are normal characters.\n  bool HasLegalHalfType; // True if the backend supports operations on the half\n                         // LLVM IR type.\n  bool HasFloat128;\n  bool HasFloat16;\n  bool HasBFloat16;\n  bool HasStrictFP;\n\n  unsigned char MaxAtomicPromoteWidth, MaxAtomicInlineWidth;\n  unsigned short SimdDefaultAlign;\n  std::unique_ptr<llvm::DataLayout> DataLayout;\n  const char *MCountName;\n  unsigned char RegParmMax, SSERegParmMax;\n  TargetCXXABI TheCXXABI;\n  const LangASMap *AddrSpaceMap;\n  const unsigned *GridValues =\n      nullptr; // Array of target-specific GPU grid values that must be\n               // consistent between host RTL (plugin), device RTL, and clang.\n\n  mutable StringRef PlatformName;\n  mutable VersionTuple PlatformMinVersion;\n\n  unsigned HasAlignMac68kSupport : 1;\n  unsigned RealTypeUsesObjCFPRet : 3;\n  unsigned ComplexLongDoubleUsesFP2Ret : 1;\n\n  unsigned HasBuiltinMSVaList : 1;\n\n  unsigned IsRenderScriptTarget : 1;\n\n  unsigned HasAArch64SVETypes : 1;\n\n  unsigned HasRISCVVTypes : 1;\n\n  unsigned AllowAMDGPUUnsafeFPAtomics : 1;\n\n  unsigned ARMCDECoprocMask : 8;\n\n  unsigned MaxOpenCLWorkGroupSize;\n\n  // TargetInfo Constructor.  Default initializes all fields.\n  TargetInfo(const llvm::Triple &T);\n\n  void resetDataLayout(StringRef DL);\n\npublic:\n  /// Construct a target for the given options.\n  ///\n  /// \\param Opts - The options to use to initialize the target. The target may\n  /// modify the options to canonicalize the target feature information to match\n  /// what the backend expects.\n  static TargetInfo *\n  CreateTargetInfo(DiagnosticsEngine &Diags,\n                   const std::shared_ptr<TargetOptions> &Opts);\n\n  virtual ~TargetInfo();\n\n  /// Retrieve the target options.\n  TargetOptions &getTargetOpts() const {\n    assert(TargetOpts && \"Missing target options\");\n    return *TargetOpts;\n  }\n\n  /// The different kinds of __builtin_va_list types defined by\n  /// the target implementation.\n  enum BuiltinVaListKind {\n    /// typedef char* __builtin_va_list;\n    CharPtrBuiltinVaList = 0,\n\n    /// typedef void* __builtin_va_list;\n    VoidPtrBuiltinVaList,\n\n    /// __builtin_va_list as defined by the AArch64 ABI\n    /// http://infocenter.arm.com/help/topic/com.arm.doc.ihi0055a/IHI0055A_aapcs64.pdf\n    AArch64ABIBuiltinVaList,\n\n    /// __builtin_va_list as defined by the PNaCl ABI:\n    /// http://www.chromium.org/nativeclient/pnacl/bitcode-abi#TOC-Machine-Types\n    PNaClABIBuiltinVaList,\n\n    /// __builtin_va_list as defined by the Power ABI:\n    /// https://www.power.org\n    ///        /resources/downloads/Power-Arch-32-bit-ABI-supp-1.0-Embedded.pdf\n    PowerABIBuiltinVaList,\n\n    /// __builtin_va_list as defined by the x86-64 ABI:\n    /// http://refspecs.linuxbase.org/elf/x86_64-abi-0.21.pdf\n    X86_64ABIBuiltinVaList,\n\n    /// __builtin_va_list as defined by ARM AAPCS ABI\n    /// http://infocenter.arm.com\n    //        /help/topic/com.arm.doc.ihi0042d/IHI0042D_aapcs.pdf\n    AAPCSABIBuiltinVaList,\n\n    // typedef struct __va_list_tag\n    //   {\n    //     long __gpr;\n    //     long __fpr;\n    //     void *__overflow_arg_area;\n    //     void *__reg_save_area;\n    //   } va_list[1];\n    SystemZBuiltinVaList,\n\n    // typedef struct __va_list_tag {\n    //    void *__current_saved_reg_area_pointer;\n    //    void *__saved_reg_area_end_pointer;\n    //    void *__overflow_area_pointer;\n    //} va_list;\n    HexagonBuiltinVaList\n  };\n\nprotected:\n  /// Specify if mangling based on address space map should be used or\n  /// not for language specific address spaces\n  bool UseAddrSpaceMapMangling;\n\npublic:\n  IntType getSizeType() const { return SizeType; }\n  IntType getSignedSizeType() const {\n    switch (SizeType) {\n    case UnsignedShort:\n      return SignedShort;\n    case UnsignedInt:\n      return SignedInt;\n    case UnsignedLong:\n      return SignedLong;\n    case UnsignedLongLong:\n      return SignedLongLong;\n    default:\n      llvm_unreachable(\"Invalid SizeType\");\n    }\n  }\n  IntType getIntMaxType() const { return IntMaxType; }\n  IntType getUIntMaxType() const {\n    return getCorrespondingUnsignedType(IntMaxType);\n  }\n  IntType getPtrDiffType(unsigned AddrSpace) const {\n    return AddrSpace == 0 ? PtrDiffType : getPtrDiffTypeV(AddrSpace);\n  }\n  IntType getUnsignedPtrDiffType(unsigned AddrSpace) const {\n    return getCorrespondingUnsignedType(getPtrDiffType(AddrSpace));\n  }\n  IntType getIntPtrType() const { return IntPtrType; }\n  IntType getUIntPtrType() const {\n    return getCorrespondingUnsignedType(IntPtrType);\n  }\n  IntType getWCharType() const { return WCharType; }\n  IntType getWIntType() const { return WIntType; }\n  IntType getChar16Type() const { return Char16Type; }\n  IntType getChar32Type() const { return Char32Type; }\n  IntType getInt64Type() const { return Int64Type; }\n  IntType getUInt64Type() const {\n    return getCorrespondingUnsignedType(Int64Type);\n  }\n  IntType getSigAtomicType() const { return SigAtomicType; }\n  IntType getProcessIDType() const { return ProcessIDType; }\n\n  static IntType getCorrespondingUnsignedType(IntType T) {\n    switch (T) {\n    case SignedChar:\n      return UnsignedChar;\n    case SignedShort:\n      return UnsignedShort;\n    case SignedInt:\n      return UnsignedInt;\n    case SignedLong:\n      return UnsignedLong;\n    case SignedLongLong:\n      return UnsignedLongLong;\n    default:\n      llvm_unreachable(\"Unexpected signed integer type\");\n    }\n  }\n\n  /// In the event this target uses the same number of fractional bits for its\n  /// unsigned types as it does with its signed counterparts, there will be\n  /// exactly one bit of padding.\n  /// Return true if unsigned fixed point types have padding for this target.\n  bool doUnsignedFixedPointTypesHavePadding() const {\n    return PaddingOnUnsignedFixedPoint;\n  }\n\n  /// Return the width (in bits) of the specified integer type enum.\n  ///\n  /// For example, SignedInt -> getIntWidth().\n  unsigned getTypeWidth(IntType T) const;\n\n  /// Return integer type with specified width.\n  virtual IntType getIntTypeByWidth(unsigned BitWidth, bool IsSigned) const;\n\n  /// Return the smallest integer type with at least the specified width.\n  virtual IntType getLeastIntTypeByWidth(unsigned BitWidth,\n                                         bool IsSigned) const;\n\n  /// Return floating point type with specified width. On PPC, there are\n  /// three possible types for 128-bit floating point: \"PPC double-double\",\n  /// IEEE 754R quad precision, and \"long double\" (which under the covers\n  /// is represented as one of those two). At this time, there is no support\n  /// for an explicit \"PPC double-double\" type (i.e. __ibm128) so we only\n  /// need to differentiate between \"long double\" and IEEE quad precision.\n  RealType getRealTypeByWidth(unsigned BitWidth, bool ExplicitIEEE) const;\n\n  /// Return the alignment (in bits) of the specified integer type enum.\n  ///\n  /// For example, SignedInt -> getIntAlign().\n  unsigned getTypeAlign(IntType T) const;\n\n  /// Returns true if the type is signed; false otherwise.\n  static bool isTypeSigned(IntType T);\n\n  /// Return the width of pointers on this target, for the\n  /// specified address space.\n  uint64_t getPointerWidth(unsigned AddrSpace) const {\n    return AddrSpace == 0 ? PointerWidth : getPointerWidthV(AddrSpace);\n  }\n  uint64_t getPointerAlign(unsigned AddrSpace) const {\n    return AddrSpace == 0 ? PointerAlign : getPointerAlignV(AddrSpace);\n  }\n\n  /// Return the maximum width of pointers on this target.\n  virtual uint64_t getMaxPointerWidth() const {\n    return PointerWidth;\n  }\n\n  /// Get integer value for null pointer.\n  /// \\param AddrSpace address space of pointee in source language.\n  virtual uint64_t getNullPointerValue(LangAS AddrSpace) const { return 0; }\n\n  /// Return the size of '_Bool' and C++ 'bool' for this target, in bits.\n  unsigned getBoolWidth() const { return BoolWidth; }\n\n  /// Return the alignment of '_Bool' and C++ 'bool' for this target.\n  unsigned getBoolAlign() const { return BoolAlign; }\n\n  unsigned getCharWidth() const { return 8; } // FIXME\n  unsigned getCharAlign() const { return 8; } // FIXME\n\n  /// Return the size of 'signed short' and 'unsigned short' for this\n  /// target, in bits.\n  unsigned getShortWidth() const { return 16; } // FIXME\n\n  /// Return the alignment of 'signed short' and 'unsigned short' for\n  /// this target.\n  unsigned getShortAlign() const { return 16; } // FIXME\n\n  /// getIntWidth/Align - Return the size of 'signed int' and 'unsigned int' for\n  /// this target, in bits.\n  unsigned getIntWidth() const { return IntWidth; }\n  unsigned getIntAlign() const { return IntAlign; }\n\n  /// getLongWidth/Align - Return the size of 'signed long' and 'unsigned long'\n  /// for this target, in bits.\n  unsigned getLongWidth() const { return LongWidth; }\n  unsigned getLongAlign() const { return LongAlign; }\n\n  /// getLongLongWidth/Align - Return the size of 'signed long long' and\n  /// 'unsigned long long' for this target, in bits.\n  unsigned getLongLongWidth() const { return LongLongWidth; }\n  unsigned getLongLongAlign() const { return LongLongAlign; }\n\n  /// getShortAccumWidth/Align - Return the size of 'signed short _Accum' and\n  /// 'unsigned short _Accum' for this target, in bits.\n  unsigned getShortAccumWidth() const { return ShortAccumWidth; }\n  unsigned getShortAccumAlign() const { return ShortAccumAlign; }\n\n  /// getAccumWidth/Align - Return the size of 'signed _Accum' and\n  /// 'unsigned _Accum' for this target, in bits.\n  unsigned getAccumWidth() const { return AccumWidth; }\n  unsigned getAccumAlign() const { return AccumAlign; }\n\n  /// getLongAccumWidth/Align - Return the size of 'signed long _Accum' and\n  /// 'unsigned long _Accum' for this target, in bits.\n  unsigned getLongAccumWidth() const { return LongAccumWidth; }\n  unsigned getLongAccumAlign() const { return LongAccumAlign; }\n\n  /// getShortFractWidth/Align - Return the size of 'signed short _Fract' and\n  /// 'unsigned short _Fract' for this target, in bits.\n  unsigned getShortFractWidth() const { return ShortFractWidth; }\n  unsigned getShortFractAlign() const { return ShortFractAlign; }\n\n  /// getFractWidth/Align - Return the size of 'signed _Fract' and\n  /// 'unsigned _Fract' for this target, in bits.\n  unsigned getFractWidth() const { return FractWidth; }\n  unsigned getFractAlign() const { return FractAlign; }\n\n  /// getLongFractWidth/Align - Return the size of 'signed long _Fract' and\n  /// 'unsigned long _Fract' for this target, in bits.\n  unsigned getLongFractWidth() const { return LongFractWidth; }\n  unsigned getLongFractAlign() const { return LongFractAlign; }\n\n  /// getShortAccumScale/IBits - Return the number of fractional/integral bits\n  /// in a 'signed short _Accum' type.\n  unsigned getShortAccumScale() const { return ShortAccumScale; }\n  unsigned getShortAccumIBits() const {\n    return ShortAccumWidth - ShortAccumScale - 1;\n  }\n\n  /// getAccumScale/IBits - Return the number of fractional/integral bits\n  /// in a 'signed _Accum' type.\n  unsigned getAccumScale() const { return AccumScale; }\n  unsigned getAccumIBits() const { return AccumWidth - AccumScale - 1; }\n\n  /// getLongAccumScale/IBits - Return the number of fractional/integral bits\n  /// in a 'signed long _Accum' type.\n  unsigned getLongAccumScale() const { return LongAccumScale; }\n  unsigned getLongAccumIBits() const {\n    return LongAccumWidth - LongAccumScale - 1;\n  }\n\n  /// getUnsignedShortAccumScale/IBits - Return the number of\n  /// fractional/integral bits in a 'unsigned short _Accum' type.\n  unsigned getUnsignedShortAccumScale() const {\n    return PaddingOnUnsignedFixedPoint ? ShortAccumScale : ShortAccumScale + 1;\n  }\n  unsigned getUnsignedShortAccumIBits() const {\n    return PaddingOnUnsignedFixedPoint\n               ? getShortAccumIBits()\n               : ShortAccumWidth - getUnsignedShortAccumScale();\n  }\n\n  /// getUnsignedAccumScale/IBits - Return the number of fractional/integral\n  /// bits in a 'unsigned _Accum' type.\n  unsigned getUnsignedAccumScale() const {\n    return PaddingOnUnsignedFixedPoint ? AccumScale : AccumScale + 1;\n  }\n  unsigned getUnsignedAccumIBits() const {\n    return PaddingOnUnsignedFixedPoint ? getAccumIBits()\n                                       : AccumWidth - getUnsignedAccumScale();\n  }\n\n  /// getUnsignedLongAccumScale/IBits - Return the number of fractional/integral\n  /// bits in a 'unsigned long _Accum' type.\n  unsigned getUnsignedLongAccumScale() const {\n    return PaddingOnUnsignedFixedPoint ? LongAccumScale : LongAccumScale + 1;\n  }\n  unsigned getUnsignedLongAccumIBits() const {\n    return PaddingOnUnsignedFixedPoint\n               ? getLongAccumIBits()\n               : LongAccumWidth - getUnsignedLongAccumScale();\n  }\n\n  /// getShortFractScale - Return the number of fractional bits\n  /// in a 'signed short _Fract' type.\n  unsigned getShortFractScale() const { return ShortFractWidth - 1; }\n\n  /// getFractScale - Return the number of fractional bits\n  /// in a 'signed _Fract' type.\n  unsigned getFractScale() const { return FractWidth - 1; }\n\n  /// getLongFractScale - Return the number of fractional bits\n  /// in a 'signed long _Fract' type.\n  unsigned getLongFractScale() const { return LongFractWidth - 1; }\n\n  /// getUnsignedShortFractScale - Return the number of fractional bits\n  /// in a 'unsigned short _Fract' type.\n  unsigned getUnsignedShortFractScale() const {\n    return PaddingOnUnsignedFixedPoint ? getShortFractScale()\n                                       : getShortFractScale() + 1;\n  }\n\n  /// getUnsignedFractScale - Return the number of fractional bits\n  /// in a 'unsigned _Fract' type.\n  unsigned getUnsignedFractScale() const {\n    return PaddingOnUnsignedFixedPoint ? getFractScale() : getFractScale() + 1;\n  }\n\n  /// getUnsignedLongFractScale - Return the number of fractional bits\n  /// in a 'unsigned long _Fract' type.\n  unsigned getUnsignedLongFractScale() const {\n    return PaddingOnUnsignedFixedPoint ? getLongFractScale()\n                                       : getLongFractScale() + 1;\n  }\n\n  /// Determine whether the __int128 type is supported on this target.\n  virtual bool hasInt128Type() const {\n    return (getPointerWidth(0) >= 64) || getTargetOpts().ForceEnableInt128;\n  } // FIXME\n\n  /// Determine whether the _ExtInt type is supported on this target. This\n  /// limitation is put into place for ABI reasons.\n  virtual bool hasExtIntType() const {\n    return false;\n  }\n\n  /// Determine whether _Float16 is supported on this target.\n  virtual bool hasLegalHalfType() const { return HasLegalHalfType; }\n\n  /// Determine whether the __float128 type is supported on this target.\n  virtual bool hasFloat128Type() const { return HasFloat128; }\n\n  /// Determine whether the _Float16 type is supported on this target.\n  virtual bool hasFloat16Type() const { return HasFloat16; }\n\n  /// Determine whether the _BFloat16 type is supported on this target.\n  virtual bool hasBFloat16Type() const { return HasBFloat16; }\n\n  /// Determine whether constrained floating point is supported on this target.\n  virtual bool hasStrictFP() const { return HasStrictFP; }\n\n  /// Return the alignment that is the largest alignment ever used for any\n  /// scalar/SIMD data type on the target machine you are compiling for\n  /// (including types with an extended alignment requirement).\n  unsigned getSuitableAlign() const { return SuitableAlign; }\n\n  /// Return the default alignment for __attribute__((aligned)) on\n  /// this target, to be used if no alignment value is specified.\n  unsigned getDefaultAlignForAttributeAligned() const {\n    return DefaultAlignForAttributeAligned;\n  }\n\n  /// getMinGlobalAlign - Return the minimum alignment of a global variable,\n  /// unless its alignment is explicitly reduced via attributes.\n  virtual unsigned getMinGlobalAlign (uint64_t) const {\n    return MinGlobalAlign;\n  }\n\n  /// Return the largest alignment for which a suitably-sized allocation with\n  /// '::operator new(size_t)' is guaranteed to produce a correctly-aligned\n  /// pointer.\n  unsigned getNewAlign() const {\n    return NewAlign ? NewAlign : std::max(LongDoubleAlign, LongLongAlign);\n  }\n\n  /// getWCharWidth/Align - Return the size of 'wchar_t' for this target, in\n  /// bits.\n  unsigned getWCharWidth() const { return getTypeWidth(WCharType); }\n  unsigned getWCharAlign() const { return getTypeAlign(WCharType); }\n\n  /// getChar16Width/Align - Return the size of 'char16_t' for this target, in\n  /// bits.\n  unsigned getChar16Width() const { return getTypeWidth(Char16Type); }\n  unsigned getChar16Align() const { return getTypeAlign(Char16Type); }\n\n  /// getChar32Width/Align - Return the size of 'char32_t' for this target, in\n  /// bits.\n  unsigned getChar32Width() const { return getTypeWidth(Char32Type); }\n  unsigned getChar32Align() const { return getTypeAlign(Char32Type); }\n\n  /// getHalfWidth/Align/Format - Return the size/align/format of 'half'.\n  unsigned getHalfWidth() const { return HalfWidth; }\n  unsigned getHalfAlign() const { return HalfAlign; }\n  const llvm::fltSemantics &getHalfFormat() const { return *HalfFormat; }\n\n  /// getFloatWidth/Align/Format - Return the size/align/format of 'float'.\n  unsigned getFloatWidth() const { return FloatWidth; }\n  unsigned getFloatAlign() const { return FloatAlign; }\n  const llvm::fltSemantics &getFloatFormat() const { return *FloatFormat; }\n\n  /// getBFloat16Width/Align/Format - Return the size/align/format of '__bf16'.\n  unsigned getBFloat16Width() const { return BFloat16Width; }\n  unsigned getBFloat16Align() const { return BFloat16Align; }\n  const llvm::fltSemantics &getBFloat16Format() const { return *BFloat16Format; }\n\n  /// getDoubleWidth/Align/Format - Return the size/align/format of 'double'.\n  unsigned getDoubleWidth() const { return DoubleWidth; }\n  unsigned getDoubleAlign() const { return DoubleAlign; }\n  const llvm::fltSemantics &getDoubleFormat() const { return *DoubleFormat; }\n\n  /// getLongDoubleWidth/Align/Format - Return the size/align/format of 'long\n  /// double'.\n  unsigned getLongDoubleWidth() const { return LongDoubleWidth; }\n  unsigned getLongDoubleAlign() const { return LongDoubleAlign; }\n  const llvm::fltSemantics &getLongDoubleFormat() const {\n    return *LongDoubleFormat;\n  }\n\n  /// getFloat128Width/Align/Format - Return the size/align/format of\n  /// '__float128'.\n  unsigned getFloat128Width() const { return 128; }\n  unsigned getFloat128Align() const { return Float128Align; }\n  const llvm::fltSemantics &getFloat128Format() const {\n    return *Float128Format;\n  }\n\n  /// Return the mangled code of long double.\n  virtual const char *getLongDoubleMangling() const { return \"e\"; }\n\n  /// Return the mangled code of __float128.\n  virtual const char *getFloat128Mangling() const { return \"g\"; }\n\n  /// Return the mangled code of bfloat.\n  virtual const char *getBFloat16Mangling() const {\n    llvm_unreachable(\"bfloat not implemented on this target\");\n  }\n\n  /// Return the value for the C99 FLT_EVAL_METHOD macro.\n  virtual unsigned getFloatEvalMethod() const { return 0; }\n\n  // getLargeArrayMinWidth/Align - Return the minimum array size that is\n  // 'large' and its alignment.\n  unsigned getLargeArrayMinWidth() const { return LargeArrayMinWidth; }\n  unsigned getLargeArrayAlign() const { return LargeArrayAlign; }\n\n  /// Return the maximum width lock-free atomic operation which will\n  /// ever be supported for the given target\n  unsigned getMaxAtomicPromoteWidth() const { return MaxAtomicPromoteWidth; }\n  /// Return the maximum width lock-free atomic operation which can be\n  /// inlined given the supported features of the given target.\n  unsigned getMaxAtomicInlineWidth() const { return MaxAtomicInlineWidth; }\n  /// Set the maximum inline or promote width lock-free atomic operation\n  /// for the given target.\n  virtual void setMaxAtomicWidth() {}\n  /// Returns true if the given target supports lock-free atomic\n  /// operations at the specified width and alignment.\n  virtual bool hasBuiltinAtomic(uint64_t AtomicSizeInBits,\n                                uint64_t AlignmentInBits) const {\n    return AtomicSizeInBits <= AlignmentInBits &&\n           AtomicSizeInBits <= getMaxAtomicInlineWidth() &&\n           (AtomicSizeInBits <= getCharWidth() ||\n            llvm::isPowerOf2_64(AtomicSizeInBits / getCharWidth()));\n  }\n\n  /// Return the maximum vector alignment supported for the given target.\n  unsigned getMaxVectorAlign() const { return MaxVectorAlign; }\n  /// Return default simd alignment for the given target. Generally, this\n  /// value is type-specific, but this alignment can be used for most of the\n  /// types for the given target.\n  unsigned getSimdDefaultAlign() const { return SimdDefaultAlign; }\n\n  unsigned getMaxOpenCLWorkGroupSize() const { return MaxOpenCLWorkGroupSize; }\n\n  /// Return the alignment (in bits) of the thrown exception object. This is\n  /// only meaningful for targets that allocate C++ exceptions in a system\n  /// runtime, such as those using the Itanium C++ ABI.\n  virtual unsigned getExnObjectAlignment() const {\n    // Itanium says that an _Unwind_Exception has to be \"double-word\"\n    // aligned (and thus the end of it is also so-aligned), meaning 16\n    // bytes.  Of course, that was written for the actual Itanium,\n    // which is a 64-bit platform.  Classically, the ABI doesn't really\n    // specify the alignment on other platforms, but in practice\n    // libUnwind declares the struct with __attribute__((aligned)), so\n    // we assume that alignment here.  (It's generally 16 bytes, but\n    // some targets overwrite it.)\n    return getDefaultAlignForAttributeAligned();\n  }\n\n  /// Return the size of intmax_t and uintmax_t for this target, in bits.\n  unsigned getIntMaxTWidth() const {\n    return getTypeWidth(IntMaxType);\n  }\n\n  // Return the size of unwind_word for this target.\n  virtual unsigned getUnwindWordWidth() const { return getPointerWidth(0); }\n\n  /// Return the \"preferred\" register width on this target.\n  virtual unsigned getRegisterWidth() const {\n    // Currently we assume the register width on the target matches the pointer\n    // width, we can introduce a new variable for this if/when some target wants\n    // it.\n    return PointerWidth;\n  }\n\n  /// Returns the name of the mcount instrumentation function.\n  const char *getMCountName() const {\n    return MCountName;\n  }\n\n  /// Check if the Objective-C built-in boolean type should be signed\n  /// char.\n  ///\n  /// Otherwise, if this returns false, the normal built-in boolean type\n  /// should also be used for Objective-C.\n  bool useSignedCharForObjCBool() const {\n    return UseSignedCharForObjCBool;\n  }\n  void noSignedCharForObjCBool() {\n    UseSignedCharForObjCBool = false;\n  }\n\n  /// Check whether the alignment of bit-field types is respected\n  /// when laying out structures.\n  bool useBitFieldTypeAlignment() const {\n    return UseBitFieldTypeAlignment;\n  }\n\n  /// Check whether zero length bitfields should force alignment of\n  /// the next member.\n  bool useZeroLengthBitfieldAlignment() const {\n    return UseZeroLengthBitfieldAlignment;\n  }\n\n  /// Get the fixed alignment value in bits for a member that follows\n  /// a zero length bitfield.\n  unsigned getZeroLengthBitfieldBoundary() const {\n    return ZeroLengthBitfieldBoundary;\n  }\n\n  /// Check whether explicit bitfield alignment attributes should be\n  //  honored, as in \"__attribute__((aligned(2))) int b : 1;\".\n  bool useExplicitBitFieldAlignment() const {\n    return UseExplicitBitFieldAlignment;\n  }\n\n  /// Check whether this target support '\\#pragma options align=mac68k'.\n  bool hasAlignMac68kSupport() const {\n    return HasAlignMac68kSupport;\n  }\n\n  /// Return the user string for the specified integer type enum.\n  ///\n  /// For example, SignedShort -> \"short\".\n  static const char *getTypeName(IntType T);\n\n  /// Return the constant suffix for the specified integer type enum.\n  ///\n  /// For example, SignedLong -> \"L\".\n  const char *getTypeConstantSuffix(IntType T) const;\n\n  /// Return the printf format modifier for the specified\n  /// integer type enum.\n  ///\n  /// For example, SignedLong -> \"l\".\n  static const char *getTypeFormatModifier(IntType T);\n\n  /// Check whether the given real type should use the \"fpret\" flavor of\n  /// Objective-C message passing on this target.\n  bool useObjCFPRetForRealType(RealType T) const {\n    return RealTypeUsesObjCFPRet & (1 << T);\n  }\n\n  /// Check whether _Complex long double should use the \"fp2ret\" flavor\n  /// of Objective-C message passing on this target.\n  bool useObjCFP2RetForComplexLongDouble() const {\n    return ComplexLongDoubleUsesFP2Ret;\n  }\n\n  /// Check whether llvm intrinsics such as llvm.convert.to.fp16 should be used\n  /// to convert to and from __fp16.\n  /// FIXME: This function should be removed once all targets stop using the\n  /// conversion intrinsics.\n  virtual bool useFP16ConversionIntrinsics() const {\n    return true;\n  }\n\n  /// Specify if mangling based on address space map should be used or\n  /// not for language specific address spaces\n  bool useAddressSpaceMapMangling() const {\n    return UseAddrSpaceMapMangling;\n  }\n\n  ///===---- Other target property query methods --------------------------===//\n\n  /// Appends the target-specific \\#define values for this\n  /// target set to the specified buffer.\n  virtual void getTargetDefines(const LangOptions &Opts,\n                                MacroBuilder &Builder) const = 0;\n\n\n  /// Return information about target-specific builtins for\n  /// the current primary target, and info about which builtins are non-portable\n  /// across the current set of primary and secondary targets.\n  virtual ArrayRef<Builtin::Info> getTargetBuiltins() const = 0;\n\n  /// The __builtin_clz* and __builtin_ctz* built-in\n  /// functions are specified to have undefined results for zero inputs, but\n  /// on targets that support these operations in a way that provides\n  /// well-defined results for zero without loss of performance, it is a good\n  /// idea to avoid optimizing based on that undef behavior.\n  virtual bool isCLZForZeroUndef() const { return true; }\n\n  /// Returns the kind of __builtin_va_list type that should be used\n  /// with this target.\n  virtual BuiltinVaListKind getBuiltinVaListKind() const = 0;\n\n  /// Returns whether or not type \\c __builtin_ms_va_list type is\n  /// available on this target.\n  bool hasBuiltinMSVaList() const { return HasBuiltinMSVaList; }\n\n  /// Returns true for RenderScript.\n  bool isRenderScriptTarget() const { return IsRenderScriptTarget; }\n\n  /// Returns whether or not the AArch64 SVE built-in types are\n  /// available on this target.\n  bool hasAArch64SVETypes() const { return HasAArch64SVETypes; }\n\n  /// Returns whether or not the RISC-V V built-in types are\n  /// available on this target.\n  bool hasRISCVVTypes() const { return HasRISCVVTypes; }\n\n  /// Returns whether or not the AMDGPU unsafe floating point atomics are\n  /// allowed.\n  bool allowAMDGPUUnsafeFPAtomics() const { return AllowAMDGPUUnsafeFPAtomics; }\n\n  /// For ARM targets returns a mask defining which coprocessors are configured\n  /// as Custom Datapath.\n  uint32_t getARMCDECoprocMask() const { return ARMCDECoprocMask; }\n\n  /// Returns whether the passed in string is a valid clobber in an\n  /// inline asm statement.\n  ///\n  /// This is used by Sema.\n  bool isValidClobber(StringRef Name) const;\n\n  /// Returns whether the passed in string is a valid register name\n  /// according to GCC.\n  ///\n  /// This is used by Sema for inline asm statements.\n  virtual bool isValidGCCRegisterName(StringRef Name) const;\n\n  /// Returns the \"normalized\" GCC register name.\n  ///\n  /// ReturnCannonical true will return the register name without any additions\n  /// such as \"{}\" or \"%\" in it's canonical form, for example:\n  /// ReturnCanonical = true and Name = \"rax\", will return \"ax\".\n  StringRef getNormalizedGCCRegisterName(StringRef Name,\n                                         bool ReturnCanonical = false) const;\n\n  virtual bool isSPRegName(StringRef) const { return false; }\n\n  /// Extracts a register from the passed constraint (if it is a\n  /// single-register constraint) and the asm label expression related to a\n  /// variable in the input or output list of an inline asm statement.\n  ///\n  /// This function is used by Sema in order to diagnose conflicts between\n  /// the clobber list and the input/output lists.\n  virtual StringRef getConstraintRegister(StringRef Constraint,\n                                          StringRef Expression) const {\n    return \"\";\n  }\n\n  struct ConstraintInfo {\n    enum {\n      CI_None = 0x00,\n      CI_AllowsMemory = 0x01,\n      CI_AllowsRegister = 0x02,\n      CI_ReadWrite = 0x04,         // \"+r\" output constraint (read and write).\n      CI_HasMatchingInput = 0x08,  // This output operand has a matching input.\n      CI_ImmediateConstant = 0x10, // This operand must be an immediate constant\n      CI_EarlyClobber = 0x20,      // \"&\" output constraint (early clobber).\n    };\n    unsigned Flags;\n    int TiedOperand;\n    struct {\n      int Min;\n      int Max;\n      bool isConstrained;\n    } ImmRange;\n    llvm::SmallSet<int, 4> ImmSet;\n\n    std::string ConstraintStr;  // constraint: \"=rm\"\n    std::string Name;           // Operand name: [foo] with no []'s.\n  public:\n    ConstraintInfo(StringRef ConstraintStr, StringRef Name)\n        : Flags(0), TiedOperand(-1), ConstraintStr(ConstraintStr.str()),\n          Name(Name.str()) {\n      ImmRange.Min = ImmRange.Max = 0;\n      ImmRange.isConstrained = false;\n    }\n\n    const std::string &getConstraintStr() const { return ConstraintStr; }\n    const std::string &getName() const { return Name; }\n    bool isReadWrite() const { return (Flags & CI_ReadWrite) != 0; }\n    bool earlyClobber() { return (Flags & CI_EarlyClobber) != 0; }\n    bool allowsRegister() const { return (Flags & CI_AllowsRegister) != 0; }\n    bool allowsMemory() const { return (Flags & CI_AllowsMemory) != 0; }\n\n    /// Return true if this output operand has a matching\n    /// (tied) input operand.\n    bool hasMatchingInput() const { return (Flags & CI_HasMatchingInput) != 0; }\n\n    /// Return true if this input operand is a matching\n    /// constraint that ties it to an output operand.\n    ///\n    /// If this returns true then getTiedOperand will indicate which output\n    /// operand this is tied to.\n    bool hasTiedOperand() const { return TiedOperand != -1; }\n    unsigned getTiedOperand() const {\n      assert(hasTiedOperand() && \"Has no tied operand!\");\n      return (unsigned)TiedOperand;\n    }\n\n    bool requiresImmediateConstant() const {\n      return (Flags & CI_ImmediateConstant) != 0;\n    }\n    bool isValidAsmImmediate(const llvm::APInt &Value) const {\n      if (!ImmSet.empty())\n        return Value.isSignedIntN(32) &&\n               ImmSet.count(Value.getZExtValue()) != 0;\n      return !ImmRange.isConstrained ||\n             (Value.sge(ImmRange.Min) && Value.sle(ImmRange.Max));\n    }\n\n    void setIsReadWrite() { Flags |= CI_ReadWrite; }\n    void setEarlyClobber() { Flags |= CI_EarlyClobber; }\n    void setAllowsMemory() { Flags |= CI_AllowsMemory; }\n    void setAllowsRegister() { Flags |= CI_AllowsRegister; }\n    void setHasMatchingInput() { Flags |= CI_HasMatchingInput; }\n    void setRequiresImmediate(int Min, int Max) {\n      Flags |= CI_ImmediateConstant;\n      ImmRange.Min = Min;\n      ImmRange.Max = Max;\n      ImmRange.isConstrained = true;\n    }\n    void setRequiresImmediate(llvm::ArrayRef<int> Exacts) {\n      Flags |= CI_ImmediateConstant;\n      for (int Exact : Exacts)\n        ImmSet.insert(Exact);\n    }\n    void setRequiresImmediate(int Exact) {\n      Flags |= CI_ImmediateConstant;\n      ImmSet.insert(Exact);\n    }\n    void setRequiresImmediate() {\n      Flags |= CI_ImmediateConstant;\n    }\n\n    /// Indicate that this is an input operand that is tied to\n    /// the specified output operand.\n    ///\n    /// Copy over the various constraint information from the output.\n    void setTiedOperand(unsigned N, ConstraintInfo &Output) {\n      Output.setHasMatchingInput();\n      Flags = Output.Flags;\n      TiedOperand = N;\n      // Don't copy Name or constraint string.\n    }\n  };\n\n  /// Validate register name used for global register variables.\n  ///\n  /// This function returns true if the register passed in RegName can be used\n  /// for global register variables on this target. In addition, it returns\n  /// true in HasSizeMismatch if the size of the register doesn't match the\n  /// variable size passed in RegSize.\n  virtual bool validateGlobalRegisterVariable(StringRef RegName,\n                                              unsigned RegSize,\n                                              bool &HasSizeMismatch) const {\n    HasSizeMismatch = false;\n    return true;\n  }\n\n  // validateOutputConstraint, validateInputConstraint - Checks that\n  // a constraint is valid and provides information about it.\n  // FIXME: These should return a real error instead of just true/false.\n  bool validateOutputConstraint(ConstraintInfo &Info) const;\n  bool validateInputConstraint(MutableArrayRef<ConstraintInfo> OutputConstraints,\n                               ConstraintInfo &info) const;\n\n  virtual bool validateOutputSize(const llvm::StringMap<bool> &FeatureMap,\n                                  StringRef /*Constraint*/,\n                                  unsigned /*Size*/) const {\n    return true;\n  }\n\n  virtual bool validateInputSize(const llvm::StringMap<bool> &FeatureMap,\n                                 StringRef /*Constraint*/,\n                                 unsigned /*Size*/) const {\n    return true;\n  }\n  virtual bool\n  validateConstraintModifier(StringRef /*Constraint*/,\n                             char /*Modifier*/,\n                             unsigned /*Size*/,\n                             std::string &/*SuggestedModifier*/) const {\n    return true;\n  }\n  virtual bool\n  validateAsmConstraint(const char *&Name,\n                        TargetInfo::ConstraintInfo &info) const = 0;\n\n  bool resolveSymbolicName(const char *&Name,\n                           ArrayRef<ConstraintInfo> OutputConstraints,\n                           unsigned &Index) const;\n\n  // Constraint parm will be left pointing at the last character of\n  // the constraint.  In practice, it won't be changed unless the\n  // constraint is longer than one character.\n  virtual std::string convertConstraint(const char *&Constraint) const {\n    // 'p' defaults to 'r', but can be overridden by targets.\n    if (*Constraint == 'p')\n      return std::string(\"r\");\n    return std::string(1, *Constraint);\n  }\n\n  /// Returns a string of target-specific clobbers, in LLVM format.\n  virtual const char *getClobbers() const = 0;\n\n  /// Returns true if NaN encoding is IEEE 754-2008.\n  /// Only MIPS allows a different encoding.\n  virtual bool isNan2008() const {\n    return true;\n  }\n\n  /// Returns the target triple of the primary target.\n  const llvm::Triple &getTriple() const {\n    return Triple;\n  }\n\n  /// Returns the target ID if supported.\n  virtual llvm::Optional<std::string> getTargetID() const { return llvm::None; }\n\n  const llvm::DataLayout &getDataLayout() const {\n    assert(DataLayout && \"Uninitialized DataLayout!\");\n    return *DataLayout;\n  }\n\n  struct GCCRegAlias {\n    const char * const Aliases[5];\n    const char * const Register;\n  };\n\n  struct AddlRegName {\n    const char * const Names[5];\n    const unsigned RegNum;\n  };\n\n  /// Does this target support \"protected\" visibility?\n  ///\n  /// Any target which dynamic libraries will naturally support\n  /// something like \"default\" (meaning that the symbol is visible\n  /// outside this shared object) and \"hidden\" (meaning that it isn't)\n  /// visibilities, but \"protected\" is really an ELF-specific concept\n  /// with weird semantics designed around the convenience of dynamic\n  /// linker implementations.  Which is not to suggest that there's\n  /// consistent target-independent semantics for \"default\" visibility\n  /// either; the entire thing is pretty badly mangled.\n  virtual bool hasProtectedVisibility() const { return true; }\n\n  /// Does this target aim for semantic compatibility with\n  /// Microsoft C++ code using dllimport/export attributes?\n  virtual bool shouldDLLImportComdatSymbols() const {\n    return getTriple().isWindowsMSVCEnvironment() ||\n           getTriple().isWindowsItaniumEnvironment() || getTriple().isPS4CPU();\n  }\n\n  /// An optional hook that targets can implement to perform semantic\n  /// checking on attribute((section(\"foo\"))) specifiers.\n  ///\n  /// In this case, \"foo\" is passed in to be checked.  If the section\n  /// specifier is invalid, the backend should return an Error that indicates\n  /// the problem.\n  ///\n  /// This hook is a simple quality of implementation feature to catch errors\n  /// and give good diagnostics in cases when the assembler or code generator\n  /// would otherwise reject the section specifier.\n  ///\n  virtual llvm::Error isValidSectionSpecifier(StringRef SR) const {\n    return llvm::Error::success();\n  }\n\n  /// Set forced language options.\n  ///\n  /// Apply changes to the target information with respect to certain\n  /// language options which change the target configuration and adjust\n  /// the language based on the target options where applicable.\n  virtual void adjust(LangOptions &Opts);\n\n  /// Adjust target options based on codegen options.\n  virtual void adjustTargetOptions(const CodeGenOptions &CGOpts,\n                                   TargetOptions &TargetOpts) const {}\n\n  /// Initialize the map with the default set of target features for the\n  /// CPU this should include all legal feature strings on the target.\n  ///\n  /// \\return False on error (invalid features).\n  virtual bool initFeatureMap(llvm::StringMap<bool> &Features,\n                              DiagnosticsEngine &Diags, StringRef CPU,\n                              const std::vector<std::string> &FeatureVec) const;\n\n  /// Get the ABI currently in use.\n  virtual StringRef getABI() const { return StringRef(); }\n\n  /// Get the C++ ABI currently in use.\n  TargetCXXABI getCXXABI() const {\n    return TheCXXABI;\n  }\n\n  /// Target the specified CPU.\n  ///\n  /// \\return  False on error (invalid CPU name).\n  virtual bool setCPU(const std::string &Name) {\n    return false;\n  }\n\n  /// Fill a SmallVectorImpl with the valid values to setCPU.\n  virtual void fillValidCPUList(SmallVectorImpl<StringRef> &Values) const {}\n\n  /// Fill a SmallVectorImpl with the valid values for tuning CPU.\n  virtual void fillValidTuneCPUList(SmallVectorImpl<StringRef> &Values) const {\n    fillValidCPUList(Values);\n  }\n\n  /// brief Determine whether this TargetInfo supports the given CPU name.\n  virtual bool isValidCPUName(StringRef Name) const {\n    return true;\n  }\n\n  /// brief Determine whether this TargetInfo supports the given CPU name for\n  // tuning.\n  virtual bool isValidTuneCPUName(StringRef Name) const {\n    return isValidCPUName(Name);\n  }\n\n  /// brief Determine whether this TargetInfo supports tune in target attribute.\n  virtual bool supportsTargetAttributeTune() const {\n    return false;\n  }\n\n  /// Use the specified ABI.\n  ///\n  /// \\return False on error (invalid ABI name).\n  virtual bool setABI(const std::string &Name) {\n    return false;\n  }\n\n  /// Use the specified unit for FP math.\n  ///\n  /// \\return False on error (invalid unit name).\n  virtual bool setFPMath(StringRef Name) {\n    return false;\n  }\n\n  /// Enable or disable a specific target feature;\n  /// the feature name must be valid.\n  virtual void setFeatureEnabled(llvm::StringMap<bool> &Features,\n                                 StringRef Name,\n                                 bool Enabled) const {\n    Features[Name] = Enabled;\n  }\n\n  /// Determine whether this TargetInfo supports the given feature.\n  virtual bool isValidFeatureName(StringRef Feature) const {\n    return true;\n  }\n\n  struct BranchProtectionInfo {\n    LangOptions::SignReturnAddressScopeKind SignReturnAddr =\n        LangOptions::SignReturnAddressScopeKind::None;\n    LangOptions::SignReturnAddressKeyKind SignKey =\n        LangOptions::SignReturnAddressKeyKind::AKey;\n    bool BranchTargetEnforcement = false;\n  };\n\n  /// Determine if this TargetInfo supports the given branch protection\n  /// specification\n  virtual bool validateBranchProtection(StringRef Spec,\n                                        BranchProtectionInfo &BPI,\n                                        StringRef &Err) const {\n    Err = \"\";\n    return false;\n  }\n\n  /// Perform initialization based on the user configured\n  /// set of features (e.g., +sse4).\n  ///\n  /// The list is guaranteed to have at most one entry per feature.\n  ///\n  /// The target may modify the features list, to change which options are\n  /// passed onwards to the backend.\n  /// FIXME: This part should be fixed so that we can change handleTargetFeatures\n  /// to merely a TargetInfo initialization routine.\n  ///\n  /// \\return  False on error.\n  virtual bool handleTargetFeatures(std::vector<std::string> &Features,\n                                    DiagnosticsEngine &Diags) {\n    return true;\n  }\n\n  /// Determine whether the given target has the given feature.\n  virtual bool hasFeature(StringRef Feature) const {\n    return false;\n  }\n\n  /// Identify whether this target supports multiversioning of functions,\n  /// which requires support for cpu_supports and cpu_is functionality.\n  bool supportsMultiVersioning() const { return getTriple().isX86(); }\n\n  /// Identify whether this target supports IFuncs.\n  bool supportsIFunc() const { return getTriple().isOSBinFormatELF(); }\n\n  // Validate the contents of the __builtin_cpu_supports(const char*)\n  // argument.\n  virtual bool validateCpuSupports(StringRef Name) const { return false; }\n\n  // Return the target-specific priority for features/cpus/vendors so\n  // that they can be properly sorted for checking.\n  virtual unsigned multiVersionSortPriority(StringRef Name) const {\n    return 0;\n  }\n\n  // Validate the contents of the __builtin_cpu_is(const char*)\n  // argument.\n  virtual bool validateCpuIs(StringRef Name) const { return false; }\n\n  // Validate a cpu_dispatch/cpu_specific CPU option, which is a different list\n  // from cpu_is, since it checks via features rather than CPUs directly.\n  virtual bool validateCPUSpecificCPUDispatch(StringRef Name) const {\n    return false;\n  }\n\n  // Get the character to be added for mangling purposes for cpu_specific.\n  virtual char CPUSpecificManglingCharacter(StringRef Name) const {\n    llvm_unreachable(\n        \"cpu_specific Multiversioning not implemented on this target\");\n  }\n\n  // Get a list of the features that make up the CPU option for\n  // cpu_specific/cpu_dispatch so that it can be passed to llvm as optimization\n  // options.\n  virtual void getCPUSpecificCPUDispatchFeatures(\n      StringRef Name, llvm::SmallVectorImpl<StringRef> &Features) const {\n    llvm_unreachable(\n        \"cpu_specific Multiversioning not implemented on this target\");\n  }\n\n  // Get the cache line size of a given cpu. This method switches over\n  // the given cpu and returns \"None\" if the CPU is not found.\n  virtual Optional<unsigned> getCPUCacheLineSize() const { return None; }\n\n  // Returns maximal number of args passed in registers.\n  unsigned getRegParmMax() const {\n    assert(RegParmMax < 7 && \"RegParmMax value is larger than AST can handle\");\n    return RegParmMax;\n  }\n\n  /// Whether the target supports thread-local storage.\n  bool isTLSSupported() const {\n    return TLSSupported;\n  }\n\n  /// Return the maximum alignment (in bits) of a TLS variable\n  ///\n  /// Gets the maximum alignment (in bits) of a TLS variable on this target.\n  /// Returns zero if there is no such constraint.\n  unsigned getMaxTLSAlign() const { return MaxTLSAlign; }\n\n  /// Whether target supports variable-length arrays.\n  bool isVLASupported() const { return VLASupported; }\n\n  /// Whether the target supports SEH __try.\n  bool isSEHTrySupported() const {\n    return getTriple().isOSWindows() &&\n           (getTriple().isX86() ||\n            getTriple().getArch() == llvm::Triple::aarch64);\n  }\n\n  /// Return true if {|} are normal characters in the asm string.\n  ///\n  /// If this returns false (the default), then {abc|xyz} is syntax\n  /// that says that when compiling for asm variant #0, \"abc\" should be\n  /// generated, but when compiling for asm variant #1, \"xyz\" should be\n  /// generated.\n  bool hasNoAsmVariants() const {\n    return NoAsmVariants;\n  }\n\n  /// Return the register number that __builtin_eh_return_regno would\n  /// return with the specified argument.\n  /// This corresponds with TargetLowering's getExceptionPointerRegister\n  /// and getExceptionSelectorRegister in the backend.\n  virtual int getEHDataRegisterNumber(unsigned RegNo) const {\n    return -1;\n  }\n\n  /// Return the section to use for C++ static initialization functions.\n  virtual const char *getStaticInitSectionSpecifier() const {\n    return nullptr;\n  }\n\n  const LangASMap &getAddressSpaceMap() const { return *AddrSpaceMap; }\n\n  /// Map from the address space field in builtin description strings to the\n  /// language address space.\n  virtual LangAS getOpenCLBuiltinAddressSpace(unsigned AS) const {\n    return getLangASFromTargetAS(AS);\n  }\n\n  /// Map from the address space field in builtin description strings to the\n  /// language address space.\n  virtual LangAS getCUDABuiltinAddressSpace(unsigned AS) const {\n    return getLangASFromTargetAS(AS);\n  }\n\n  /// Return an AST address space which can be used opportunistically\n  /// for constant global memory. It must be possible to convert pointers into\n  /// this address space to LangAS::Default. If no such address space exists,\n  /// this may return None, and such optimizations will be disabled.\n  virtual llvm::Optional<LangAS> getConstantAddressSpace() const {\n    return LangAS::Default;\n  }\n\n  /// Return a target-specific GPU grid value based on the GVIDX enum \\p gv\n  unsigned getGridValue(llvm::omp::GVIDX gv) const {\n    assert(GridValues != nullptr && \"GridValues not initialized\");\n    return GridValues[gv];\n  }\n\n  /// Retrieve the name of the platform as it is used in the\n  /// availability attribute.\n  StringRef getPlatformName() const { return PlatformName; }\n\n  /// Retrieve the minimum desired version of the platform, to\n  /// which the program should be compiled.\n  VersionTuple getPlatformMinVersion() const { return PlatformMinVersion; }\n\n  bool isBigEndian() const { return BigEndian; }\n  bool isLittleEndian() const { return !BigEndian; }\n\n  /// Gets the default calling convention for the given target and\n  /// declaration context.\n  virtual CallingConv getDefaultCallingConv() const {\n    // Not all targets will specify an explicit calling convention that we can\n    // express.  This will always do the right thing, even though it's not\n    // an explicit calling convention.\n    return CC_C;\n  }\n\n  enum CallingConvCheckResult {\n    CCCR_OK,\n    CCCR_Warning,\n    CCCR_Ignore,\n    CCCR_Error,\n  };\n\n  /// Determines whether a given calling convention is valid for the\n  /// target. A calling convention can either be accepted, produce a warning\n  /// and be substituted with the default calling convention, or (someday)\n  /// produce an error (such as using thiscall on a non-instance function).\n  virtual CallingConvCheckResult checkCallingConvention(CallingConv CC) const {\n    switch (CC) {\n      default:\n        return CCCR_Warning;\n      case CC_C:\n        return CCCR_OK;\n    }\n  }\n\n  enum CallingConvKind {\n    CCK_Default,\n    CCK_ClangABI4OrPS4,\n    CCK_MicrosoftWin64\n  };\n\n  virtual CallingConvKind getCallingConvKind(bool ClangABICompat4) const;\n\n  /// Controls if __builtin_longjmp / __builtin_setjmp can be lowered to\n  /// llvm.eh.sjlj.longjmp / llvm.eh.sjlj.setjmp.\n  virtual bool hasSjLjLowering() const {\n    return false;\n  }\n\n  /// Check if the target supports CFProtection branch.\n  virtual bool\n  checkCFProtectionBranchSupported(DiagnosticsEngine &Diags) const;\n\n  /// Check if the target supports CFProtection branch.\n  virtual bool\n  checkCFProtectionReturnSupported(DiagnosticsEngine &Diags) const;\n\n  /// Whether target allows to overalign ABI-specified preferred alignment\n  virtual bool allowsLargerPreferedTypeAlignment() const { return true; }\n\n  /// Whether target defaults to the `power` alignment rules of AIX.\n  virtual bool defaultsToAIXPowerAlignment() const { return false; }\n\n  /// Set supported OpenCL extensions and optional core features.\n  virtual void setSupportedOpenCLOpts() {}\n\n  virtual void supportAllOpenCLOpts(bool V = true) {\n#define OPENCLEXTNAME(Ext) getTargetOpts().OpenCLFeaturesMap[#Ext] = V;\n#include \"clang/Basic/OpenCLExtensions.def\"\n  }\n\n  /// Set supported OpenCL extensions as written on command line\n  virtual void setCommandLineOpenCLOpts() {\n    for (const auto &Ext : getTargetOpts().OpenCLExtensionsAsWritten) {\n      bool IsPrefixed = (Ext[0] == '+' || Ext[0] == '-');\n      std::string Name = IsPrefixed ? Ext.substr(1) : Ext;\n      bool V = IsPrefixed ? Ext[0] == '+' : true;\n\n      if (Name == \"all\") {\n        supportAllOpenCLOpts(V);\n        continue;\n      }\n\n      getTargetOpts().OpenCLFeaturesMap[Name] = V;\n    }\n  }\n\n  /// Define OpenCL macros based on target settings and language version\n  void getOpenCLFeatureDefines(const LangOptions &Opts,\n                               MacroBuilder &Builder) const;\n\n  /// Get supported OpenCL extensions and optional core features.\n  llvm::StringMap<bool> &getSupportedOpenCLOpts() {\n    return getTargetOpts().OpenCLFeaturesMap;\n  }\n\n  /// Get const supported OpenCL extensions and optional core features.\n  const llvm::StringMap<bool> &getSupportedOpenCLOpts() const {\n    return getTargetOpts().OpenCLFeaturesMap;\n  }\n\n  /// Get address space for OpenCL type.\n  virtual LangAS getOpenCLTypeAddrSpace(OpenCLTypeKind TK) const;\n\n  /// \\returns Target specific vtbl ptr address space.\n  virtual unsigned getVtblPtrAddressSpace() const {\n    return 0;\n  }\n\n  /// \\returns If a target requires an address within a target specific address\n  /// space \\p AddressSpace to be converted in order to be used, then return the\n  /// corresponding target specific DWARF address space.\n  ///\n  /// \\returns Otherwise return None and no conversion will be emitted in the\n  /// DWARF.\n  virtual Optional<unsigned> getDWARFAddressSpace(unsigned AddressSpace) const {\n    return None;\n  }\n\n  /// \\returns The version of the SDK which was used during the compilation if\n  /// one was specified, or an empty version otherwise.\n  const llvm::VersionTuple &getSDKVersion() const {\n    return getTargetOpts().SDKVersion;\n  }\n\n  /// Check the target is valid after it is fully initialized.\n  virtual bool validateTarget(DiagnosticsEngine &Diags) const {\n    return true;\n  }\n\n  virtual void setAuxTarget(const TargetInfo *Aux) {}\n\n  /// Whether target allows debuginfo types for decl only variables.\n  virtual bool allowDebugInfoForExternalVar() const { return false; }\n\nprotected:\n  /// Copy type and layout related info.\n  void copyAuxTarget(const TargetInfo *Aux);\n  virtual uint64_t getPointerWidthV(unsigned AddrSpace) const {\n    return PointerWidth;\n  }\n  virtual uint64_t getPointerAlignV(unsigned AddrSpace) const {\n    return PointerAlign;\n  }\n  virtual enum IntType getPtrDiffTypeV(unsigned AddrSpace) const {\n    return PtrDiffType;\n  }\n  virtual ArrayRef<const char *> getGCCRegNames() const = 0;\n  virtual ArrayRef<GCCRegAlias> getGCCRegAliases() const = 0;\n  virtual ArrayRef<AddlRegName> getGCCAddlRegNames() const {\n    return None;\n  }\n\n private:\n  // Assert the values for the fractional and integral bits for each fixed point\n  // type follow the restrictions given in clause 6.2.6.3 of N1169.\n  void CheckFixedPointBits() const;\n};\n\n}  // end namespace clang\n\n#endif\n"}, "34": {"id": 34, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "content": "//==-- CGFunctionInfo.h - Representation of function argument/return types -==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Defines CGFunctionInfo and associated types used in representing the\n// LLVM source types and ABI-coerced types for function arguments and\n// return values.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_CODEGEN_CGFUNCTIONINFO_H\n#define LLVM_CLANG_CODEGEN_CGFUNCTIONINFO_H\n\n#include \"clang/AST/CanonicalType.h\"\n#include \"clang/AST/CharUnits.h\"\n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/Type.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/Support/TrailingObjects.h\"\n#include <cassert>\n\nnamespace clang {\nnamespace CodeGen {\n\n/// ABIArgInfo - Helper class to encapsulate information about how a\n/// specific C type should be passed to or returned from a function.\nclass ABIArgInfo {\npublic:\n  enum Kind : uint8_t {\n    /// Direct - Pass the argument directly using the normal converted LLVM\n    /// type, or by coercing to another specified type stored in\n    /// 'CoerceToType').  If an offset is specified (in UIntData), then the\n    /// argument passed is offset by some number of bytes in the memory\n    /// representation. A dummy argument is emitted before the real argument\n    /// if the specified type stored in \"PaddingType\" is not zero.\n    Direct,\n\n    /// Extend - Valid only for integer argument types. Same as 'direct'\n    /// but also emit a zero/sign extension attribute.\n    Extend,\n\n    /// Indirect - Pass the argument indirectly via a hidden pointer with the\n    /// specified alignment (0 indicates default alignment) and address space.\n    Indirect,\n\n    /// IndirectAliased - Similar to Indirect, but the pointer may be to an\n    /// object that is otherwise referenced.  The object is known to not be\n    /// modified through any other references for the duration of the call, and\n    /// the callee must not itself modify the object.  Because C allows\n    /// parameter variables to be modified and guarantees that they have unique\n    /// addresses, the callee must defensively copy the object into a local\n    /// variable if it might be modified or its address might be compared.\n    /// Since those are uncommon, in principle this convention allows programs\n    /// to avoid copies in more situations.  However, it may introduce *extra*\n    /// copies if the callee fails to prove that a copy is unnecessary and the\n    /// caller naturally produces an unaliased object for the argument.\n    IndirectAliased,\n\n    /// Ignore - Ignore the argument (treat as void). Useful for void and\n    /// empty structs.\n    Ignore,\n\n    /// Expand - Only valid for aggregate argument types. The structure should\n    /// be expanded into consecutive arguments for its constituent fields.\n    /// Currently expand is only allowed on structures whose fields\n    /// are all scalar types or are themselves expandable types.\n    Expand,\n\n    /// CoerceAndExpand - Only valid for aggregate argument types. The\n    /// structure should be expanded into consecutive arguments corresponding\n    /// to the non-array elements of the type stored in CoerceToType.\n    /// Array elements in the type are assumed to be padding and skipped.\n    CoerceAndExpand,\n\n    /// InAlloca - Pass the argument directly using the LLVM inalloca attribute.\n    /// This is similar to indirect with byval, except it only applies to\n    /// arguments stored in memory and forbids any implicit copies.  When\n    /// applied to a return type, it means the value is returned indirectly via\n    /// an implicit sret parameter stored in the argument struct.\n    InAlloca,\n    KindFirst = Direct,\n    KindLast = InAlloca\n  };\n\nprivate:\n  llvm::Type *TypeData; // canHaveCoerceToType()\n  union {\n    llvm::Type *PaddingType; // canHavePaddingType()\n    llvm::Type *UnpaddedCoerceAndExpandType; // isCoerceAndExpand()\n  };\n  union {\n    unsigned DirectOffset;     // isDirect() || isExtend()\n    unsigned IndirectAlign;    // isIndirect()\n    unsigned AllocaFieldIndex; // isInAlloca()\n  };\n  Kind TheKind;\n  unsigned IndirectAddrSpace : 24; // isIndirect()\n  bool PaddingInReg : 1;\n  bool InAllocaSRet : 1;    // isInAlloca()\n  bool InAllocaIndirect : 1;// isInAlloca()\n  bool IndirectByVal : 1;   // isIndirect()\n  bool IndirectRealign : 1; // isIndirect()\n  bool SRetAfterThis : 1;   // isIndirect()\n  bool InReg : 1;           // isDirect() || isExtend() || isIndirect()\n  bool CanBeFlattened: 1;   // isDirect()\n  bool SignExt : 1;         // isExtend()\n\n  bool canHavePaddingType() const {\n    return isDirect() || isExtend() || isIndirect() || isIndirectAliased() ||\n           isExpand();\n  }\n  void setPaddingType(llvm::Type *T) {\n    assert(canHavePaddingType());\n    PaddingType = T;\n  }\n\n  void setUnpaddedCoerceToType(llvm::Type *T) {\n    assert(isCoerceAndExpand());\n    UnpaddedCoerceAndExpandType = T;\n  }\n\npublic:\n  ABIArgInfo(Kind K = Direct)\n      : TypeData(nullptr), PaddingType(nullptr), DirectOffset(0), TheKind(K),\n        IndirectAddrSpace(0), PaddingInReg(false), InAllocaSRet(false),\n        InAllocaIndirect(false), IndirectByVal(false), IndirectRealign(false),\n        SRetAfterThis(false), InReg(false), CanBeFlattened(false),\n        SignExt(false) {}\n\n  static ABIArgInfo getDirect(llvm::Type *T = nullptr, unsigned Offset = 0,\n                              llvm::Type *Padding = nullptr,\n                              bool CanBeFlattened = true) {\n    auto AI = ABIArgInfo(Direct);\n    AI.setCoerceToType(T);\n    AI.setPaddingType(Padding);\n    AI.setDirectOffset(Offset);\n    AI.setCanBeFlattened(CanBeFlattened);\n    return AI;\n  }\n  static ABIArgInfo getDirectInReg(llvm::Type *T = nullptr) {\n    auto AI = getDirect(T);\n    AI.setInReg(true);\n    return AI;\n  }\n\n  static ABIArgInfo getSignExtend(QualType Ty, llvm::Type *T = nullptr) {\n    assert(Ty->isIntegralOrEnumerationType() && \"Unexpected QualType\");\n    auto AI = ABIArgInfo(Extend);\n    AI.setCoerceToType(T);\n    AI.setPaddingType(nullptr);\n    AI.setDirectOffset(0);\n    AI.setSignExt(true);\n    return AI;\n  }\n\n  static ABIArgInfo getZeroExtend(QualType Ty, llvm::Type *T = nullptr) {\n    assert(Ty->isIntegralOrEnumerationType() && \"Unexpected QualType\");\n    auto AI = ABIArgInfo(Extend);\n    AI.setCoerceToType(T);\n    AI.setPaddingType(nullptr);\n    AI.setDirectOffset(0);\n    AI.setSignExt(false);\n    return AI;\n  }\n\n  // ABIArgInfo will record the argument as being extended based on the sign\n  // of its type.\n  static ABIArgInfo getExtend(QualType Ty, llvm::Type *T = nullptr) {\n    assert(Ty->isIntegralOrEnumerationType() && \"Unexpected QualType\");\n    if (Ty->hasSignedIntegerRepresentation())\n      return getSignExtend(Ty, T);\n    return getZeroExtend(Ty, T);\n  }\n\n  static ABIArgInfo getExtendInReg(QualType Ty, llvm::Type *T = nullptr) {\n    auto AI = getExtend(Ty, T);\n    AI.setInReg(true);\n    return AI;\n  }\n  static ABIArgInfo getIgnore() {\n    return ABIArgInfo(Ignore);\n  }\n  static ABIArgInfo getIndirect(CharUnits Alignment, bool ByVal = true,\n                                bool Realign = false,\n                                llvm::Type *Padding = nullptr) {\n    auto AI = ABIArgInfo(Indirect);\n    AI.setIndirectAlign(Alignment);\n    AI.setIndirectByVal(ByVal);\n    AI.setIndirectRealign(Realign);\n    AI.setSRetAfterThis(false);\n    AI.setPaddingType(Padding);\n    return AI;\n  }\n\n  /// Pass this in memory using the IR byref attribute.\n  static ABIArgInfo getIndirectAliased(CharUnits Alignment, unsigned AddrSpace,\n                                       bool Realign = false,\n                                       llvm::Type *Padding = nullptr) {\n    auto AI = ABIArgInfo(IndirectAliased);\n    AI.setIndirectAlign(Alignment);\n    AI.setIndirectRealign(Realign);\n    AI.setPaddingType(Padding);\n    AI.setIndirectAddrSpace(AddrSpace);\n    return AI;\n  }\n\n  static ABIArgInfo getIndirectInReg(CharUnits Alignment, bool ByVal = true,\n                                     bool Realign = false) {\n    auto AI = getIndirect(Alignment, ByVal, Realign);\n    AI.setInReg(true);\n    return AI;\n  }\n  static ABIArgInfo getInAlloca(unsigned FieldIndex, bool Indirect = false) {\n    auto AI = ABIArgInfo(InAlloca);\n    AI.setInAllocaFieldIndex(FieldIndex);\n    AI.setInAllocaIndirect(Indirect);\n    return AI;\n  }\n  static ABIArgInfo getExpand() {\n    auto AI = ABIArgInfo(Expand);\n    AI.setPaddingType(nullptr);\n    return AI;\n  }\n  static ABIArgInfo getExpandWithPadding(bool PaddingInReg,\n                                         llvm::Type *Padding) {\n    auto AI = getExpand();\n    AI.setPaddingInReg(PaddingInReg);\n    AI.setPaddingType(Padding);\n    return AI;\n  }\n\n  /// \\param unpaddedCoerceToType The coerce-to type with padding elements\n  ///   removed, canonicalized to a single element if it would otherwise\n  ///   have exactly one element.\n  static ABIArgInfo getCoerceAndExpand(llvm::StructType *coerceToType,\n                                       llvm::Type *unpaddedCoerceToType) {\n#ifndef NDEBUG\n    // Sanity checks on unpaddedCoerceToType.\n\n    // Assert that we only have a struct type if there are multiple elements.\n    auto unpaddedStruct = dyn_cast<llvm::StructType>(unpaddedCoerceToType);\n    assert(!unpaddedStruct || unpaddedStruct->getNumElements() != 1);\n\n    // Assert that all the non-padding elements have a corresponding element\n    // in the unpadded type.\n    unsigned unpaddedIndex = 0;\n    for (auto eltType : coerceToType->elements()) {\n      if (isPaddingForCoerceAndExpand(eltType)) continue;\n      if (unpaddedStruct) {\n        assert(unpaddedStruct->getElementType(unpaddedIndex) == eltType);\n      } else {\n        assert(unpaddedIndex == 0 && unpaddedCoerceToType == eltType);\n      }\n      unpaddedIndex++;\n    }\n\n    // Assert that there aren't extra elements in the unpadded type.\n    if (unpaddedStruct) {\n      assert(unpaddedStruct->getNumElements() == unpaddedIndex);\n    } else {\n      assert(unpaddedIndex == 1);\n    }\n#endif\n\n    auto AI = ABIArgInfo(CoerceAndExpand);\n    AI.setCoerceToType(coerceToType);\n    AI.setUnpaddedCoerceToType(unpaddedCoerceToType);\n    return AI;\n  }\n\n  static bool isPaddingForCoerceAndExpand(llvm::Type *eltType) {\n    if (eltType->isArrayTy()) {\n      assert(eltType->getArrayElementType()->isIntegerTy(8));\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  Kind getKind() const { return TheKind; }\n  bool isDirect() const { return TheKind == Direct; }\n  bool isInAlloca() const { return TheKind == InAlloca; }\n  bool isExtend() const { return TheKind == Extend; }\n  bool isIgnore() const { return TheKind == Ignore; }\n  bool isIndirect() const { return TheKind == Indirect; }\n  bool isIndirectAliased() const { return TheKind == IndirectAliased; }\n  bool isExpand() const { return TheKind == Expand; }\n  bool isCoerceAndExpand() const { return TheKind == CoerceAndExpand; }\n\n  bool canHaveCoerceToType() const {\n    return isDirect() || isExtend() || isCoerceAndExpand();\n  }\n\n  // Direct/Extend accessors\n  unsigned getDirectOffset() const {\n    assert((isDirect() || isExtend()) && \"Not a direct or extend kind\");\n    return DirectOffset;\n  }\n  void setDirectOffset(unsigned Offset) {\n    assert((isDirect() || isExtend()) && \"Not a direct or extend kind\");\n    DirectOffset = Offset;\n  }\n\n  bool isSignExt() const {\n    assert(isExtend() && \"Invalid kind!\");\n    return SignExt;\n  }\n  void setSignExt(bool SExt) {\n    assert(isExtend() && \"Invalid kind!\");\n    SignExt = SExt;\n  }\n\n  llvm::Type *getPaddingType() const {\n    return (canHavePaddingType() ? PaddingType : nullptr);\n  }\n\n  bool getPaddingInReg() const {\n    return PaddingInReg;\n  }\n  void setPaddingInReg(bool PIR) {\n    PaddingInReg = PIR;\n  }\n\n  llvm::Type *getCoerceToType() const {\n    assert(canHaveCoerceToType() && \"Invalid kind!\");\n    return TypeData;\n  }\n\n  void setCoerceToType(llvm::Type *T) {\n    assert(canHaveCoerceToType() && \"Invalid kind!\");\n    TypeData = T;\n  }\n\n  llvm::StructType *getCoerceAndExpandType() const {\n    assert(isCoerceAndExpand());\n    return cast<llvm::StructType>(TypeData);\n  }\n\n  llvm::Type *getUnpaddedCoerceAndExpandType() const {\n    assert(isCoerceAndExpand());\n    return UnpaddedCoerceAndExpandType;\n  }\n\n  ArrayRef<llvm::Type *>getCoerceAndExpandTypeSequence() const {\n    assert(isCoerceAndExpand());\n    if (auto structTy =\n          dyn_cast<llvm::StructType>(UnpaddedCoerceAndExpandType)) {\n      return structTy->elements();\n    } else {\n      return llvm::makeArrayRef(&UnpaddedCoerceAndExpandType, 1);\n    }\n  }\n\n  bool getInReg() const {\n    assert((isDirect() || isExtend() || isIndirect()) && \"Invalid kind!\");\n    return InReg;\n  }\n\n  void setInReg(bool IR) {\n    assert((isDirect() || isExtend() || isIndirect()) && \"Invalid kind!\");\n    InReg = IR;\n  }\n\n  // Indirect accessors\n  CharUnits getIndirectAlign() const {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    return CharUnits::fromQuantity(IndirectAlign);\n  }\n  void setIndirectAlign(CharUnits IA) {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    IndirectAlign = IA.getQuantity();\n  }\n\n  bool getIndirectByVal() const {\n    assert(isIndirect() && \"Invalid kind!\");\n    return IndirectByVal;\n  }\n  void setIndirectByVal(bool IBV) {\n    assert(isIndirect() && \"Invalid kind!\");\n    IndirectByVal = IBV;\n  }\n\n  unsigned getIndirectAddrSpace() const {\n    assert(isIndirectAliased() && \"Invalid kind!\");\n    return IndirectAddrSpace;\n  }\n\n  void setIndirectAddrSpace(unsigned AddrSpace) {\n    assert(isIndirectAliased() && \"Invalid kind!\");\n    IndirectAddrSpace = AddrSpace;\n  }\n\n  bool getIndirectRealign() const {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    return IndirectRealign;\n  }\n  void setIndirectRealign(bool IR) {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    IndirectRealign = IR;\n  }\n\n  bool isSRetAfterThis() const {\n    assert(isIndirect() && \"Invalid kind!\");\n    return SRetAfterThis;\n  }\n  void setSRetAfterThis(bool AfterThis) {\n    assert(isIndirect() && \"Invalid kind!\");\n    SRetAfterThis = AfterThis;\n  }\n\n  unsigned getInAllocaFieldIndex() const {\n    assert(isInAlloca() && \"Invalid kind!\");\n    return AllocaFieldIndex;\n  }\n  void setInAllocaFieldIndex(unsigned FieldIndex) {\n    assert(isInAlloca() && \"Invalid kind!\");\n    AllocaFieldIndex = FieldIndex;\n  }\n\n  unsigned getInAllocaIndirect() const {\n    assert(isInAlloca() && \"Invalid kind!\");\n    return InAllocaIndirect;\n  }\n  void setInAllocaIndirect(bool Indirect) {\n    assert(isInAlloca() && \"Invalid kind!\");\n    InAllocaIndirect = Indirect;\n  }\n\n  /// Return true if this field of an inalloca struct should be returned\n  /// to implement a struct return calling convention.\n  bool getInAllocaSRet() const {\n    assert(isInAlloca() && \"Invalid kind!\");\n    return InAllocaSRet;\n  }\n\n  void setInAllocaSRet(bool SRet) {\n    assert(isInAlloca() && \"Invalid kind!\");\n    InAllocaSRet = SRet;\n  }\n\n  bool getCanBeFlattened() const {\n    assert(isDirect() && \"Invalid kind!\");\n    return CanBeFlattened;\n  }\n\n  void setCanBeFlattened(bool Flatten) {\n    assert(isDirect() && \"Invalid kind!\");\n    CanBeFlattened = Flatten;\n  }\n\n  void dump() const;\n};\n\n/// A class for recording the number of arguments that a function\n/// signature requires.\nclass RequiredArgs {\n  /// The number of required arguments, or ~0 if the signature does\n  /// not permit optional arguments.\n  unsigned NumRequired;\npublic:\n  enum All_t { All };\n\n  RequiredArgs(All_t _) : NumRequired(~0U) {}\n  explicit RequiredArgs(unsigned n) : NumRequired(n) {\n    assert(n != ~0U);\n  }\n\n  /// Compute the arguments required by the given formal prototype,\n  /// given that there may be some additional, non-formal arguments\n  /// in play.\n  ///\n  /// If FD is not null, this will consider pass_object_size params in FD.\n  static RequiredArgs forPrototypePlus(const FunctionProtoType *prototype,\n                                       unsigned additional) {\n    if (!prototype->isVariadic()) return All;\n\n    if (prototype->hasExtParameterInfos())\n      additional += llvm::count_if(\n          prototype->getExtParameterInfos(),\n          [](const FunctionProtoType::ExtParameterInfo &ExtInfo) {\n            return ExtInfo.hasPassObjectSize();\n          });\n\n    return RequiredArgs(prototype->getNumParams() + additional);\n  }\n\n  static RequiredArgs forPrototypePlus(CanQual<FunctionProtoType> prototype,\n                                       unsigned additional) {\n    return forPrototypePlus(prototype.getTypePtr(), additional);\n  }\n\n  static RequiredArgs forPrototype(const FunctionProtoType *prototype) {\n    return forPrototypePlus(prototype, 0);\n  }\n\n  static RequiredArgs forPrototype(CanQual<FunctionProtoType> prototype) {\n    return forPrototypePlus(prototype.getTypePtr(), 0);\n  }\n\n  bool allowsOptionalArgs() const { return NumRequired != ~0U; }\n  unsigned getNumRequiredArgs() const {\n    assert(allowsOptionalArgs());\n    return NumRequired;\n  }\n\n  unsigned getOpaqueData() const { return NumRequired; }\n  static RequiredArgs getFromOpaqueData(unsigned value) {\n    if (value == ~0U) return All;\n    return RequiredArgs(value);\n  }\n};\n\n// Implementation detail of CGFunctionInfo, factored out so it can be named\n// in the TrailingObjects base class of CGFunctionInfo.\nstruct CGFunctionInfoArgInfo {\n  CanQualType type;\n  ABIArgInfo info;\n};\n\n/// CGFunctionInfo - Class to encapsulate the information about a\n/// function definition.\nclass CGFunctionInfo final\n    : public llvm::FoldingSetNode,\n      private llvm::TrailingObjects<CGFunctionInfo, CGFunctionInfoArgInfo,\n                                    FunctionProtoType::ExtParameterInfo> {\n  typedef CGFunctionInfoArgInfo ArgInfo;\n  typedef FunctionProtoType::ExtParameterInfo ExtParameterInfo;\n\n  /// The LLVM::CallingConv to use for this function (as specified by the\n  /// user).\n  unsigned CallingConvention : 8;\n\n  /// The LLVM::CallingConv to actually use for this function, which may\n  /// depend on the ABI.\n  unsigned EffectiveCallingConvention : 8;\n\n  /// The clang::CallingConv that this was originally created with.\n  unsigned ASTCallingConvention : 6;\n\n  /// Whether this is an instance method.\n  unsigned InstanceMethod : 1;\n\n  /// Whether this is a chain call.\n  unsigned ChainCall : 1;\n\n  /// Whether this function is a CMSE nonsecure call\n  unsigned CmseNSCall : 1;\n\n  /// Whether this function is noreturn.\n  unsigned NoReturn : 1;\n\n  /// Whether this function is returns-retained.\n  unsigned ReturnsRetained : 1;\n\n  /// Whether this function saved caller registers.\n  unsigned NoCallerSavedRegs : 1;\n\n  /// How many arguments to pass inreg.\n  unsigned HasRegParm : 1;\n  unsigned RegParm : 3;\n\n  /// Whether this function has nocf_check attribute.\n  unsigned NoCfCheck : 1;\n\n  RequiredArgs Required;\n\n  /// The struct representing all arguments passed in memory.  Only used when\n  /// passing non-trivial types with inalloca.  Not part of the profile.\n  llvm::StructType *ArgStruct;\n  unsigned ArgStructAlign : 31;\n  unsigned HasExtParameterInfos : 1;\n\n  unsigned NumArgs;\n\n  ArgInfo *getArgsBuffer() {\n    return getTrailingObjects<ArgInfo>();\n  }\n  const ArgInfo *getArgsBuffer() const {\n    return getTrailingObjects<ArgInfo>();\n  }\n\n  ExtParameterInfo *getExtParameterInfosBuffer() {\n    return getTrailingObjects<ExtParameterInfo>();\n  }\n  const ExtParameterInfo *getExtParameterInfosBuffer() const{\n    return getTrailingObjects<ExtParameterInfo>();\n  }\n\n  CGFunctionInfo() : Required(RequiredArgs::All) {}\n\npublic:\n  static CGFunctionInfo *create(unsigned llvmCC,\n                                bool instanceMethod,\n                                bool chainCall,\n                                const FunctionType::ExtInfo &extInfo,\n                                ArrayRef<ExtParameterInfo> paramInfos,\n                                CanQualType resultType,\n                                ArrayRef<CanQualType> argTypes,\n                                RequiredArgs required);\n  void operator delete(void *p) { ::operator delete(p); }\n\n  // Friending class TrailingObjects is apparently not good enough for MSVC,\n  // so these have to be public.\n  friend class TrailingObjects;\n  size_t numTrailingObjects(OverloadToken<ArgInfo>) const {\n    return NumArgs + 1;\n  }\n  size_t numTrailingObjects(OverloadToken<ExtParameterInfo>) const {\n    return (HasExtParameterInfos ? NumArgs : 0);\n  }\n\n  typedef const ArgInfo *const_arg_iterator;\n  typedef ArgInfo *arg_iterator;\n\n  MutableArrayRef<ArgInfo> arguments() {\n    return MutableArrayRef<ArgInfo>(arg_begin(), NumArgs);\n  }\n  ArrayRef<ArgInfo> arguments() const {\n    return ArrayRef<ArgInfo>(arg_begin(), NumArgs);\n  }\n\n  const_arg_iterator arg_begin() const { return getArgsBuffer() + 1; }\n  const_arg_iterator arg_end() const { return getArgsBuffer() + 1 + NumArgs; }\n  arg_iterator arg_begin() { return getArgsBuffer() + 1; }\n  arg_iterator arg_end() { return getArgsBuffer() + 1 + NumArgs; }\n\n  unsigned  arg_size() const { return NumArgs; }\n\n  bool isVariadic() const { return Required.allowsOptionalArgs(); }\n  RequiredArgs getRequiredArgs() const { return Required; }\n  unsigned getNumRequiredArgs() const {\n    return isVariadic() ? getRequiredArgs().getNumRequiredArgs() : arg_size();\n  }\n\n  bool isInstanceMethod() const { return InstanceMethod; }\n\n  bool isChainCall() const { return ChainCall; }\n\n  bool isCmseNSCall() const { return CmseNSCall; }\n\n  bool isNoReturn() const { return NoReturn; }\n\n  /// In ARC, whether this function retains its return value.  This\n  /// is not always reliable for call sites.\n  bool isReturnsRetained() const { return ReturnsRetained; }\n\n  /// Whether this function no longer saves caller registers.\n  bool isNoCallerSavedRegs() const { return NoCallerSavedRegs; }\n\n  /// Whether this function has nocf_check attribute.\n  bool isNoCfCheck() const { return NoCfCheck; }\n\n  /// getASTCallingConvention() - Return the AST-specified calling\n  /// convention.\n  CallingConv getASTCallingConvention() const {\n    return CallingConv(ASTCallingConvention);\n  }\n\n  /// getCallingConvention - Return the user specified calling\n  /// convention, which has been translated into an LLVM CC.\n  unsigned getCallingConvention() const { return CallingConvention; }\n\n  /// getEffectiveCallingConvention - Return the actual calling convention to\n  /// use, which may depend on the ABI.\n  unsigned getEffectiveCallingConvention() const {\n    return EffectiveCallingConvention;\n  }\n  void setEffectiveCallingConvention(unsigned Value) {\n    EffectiveCallingConvention = Value;\n  }\n\n  bool getHasRegParm() const { return HasRegParm; }\n  unsigned getRegParm() const { return RegParm; }\n\n  FunctionType::ExtInfo getExtInfo() const {\n    return FunctionType::ExtInfo(isNoReturn(), getHasRegParm(), getRegParm(),\n                                 getASTCallingConvention(), isReturnsRetained(),\n                                 isNoCallerSavedRegs(), isNoCfCheck(),\n                                 isCmseNSCall());\n  }\n\n  CanQualType getReturnType() const { return getArgsBuffer()[0].type; }\n\n  ABIArgInfo &getReturnInfo() { return getArgsBuffer()[0].info; }\n  const ABIArgInfo &getReturnInfo() const { return getArgsBuffer()[0].info; }\n\n  ArrayRef<ExtParameterInfo> getExtParameterInfos() const {\n    if (!HasExtParameterInfos) return {};\n    return llvm::makeArrayRef(getExtParameterInfosBuffer(), NumArgs);\n  }\n  ExtParameterInfo getExtParameterInfo(unsigned argIndex) const {\n    assert(argIndex <= NumArgs);\n    if (!HasExtParameterInfos) return ExtParameterInfo();\n    return getExtParameterInfos()[argIndex];\n  }\n\n  /// Return true if this function uses inalloca arguments.\n  bool usesInAlloca() const { return ArgStruct; }\n\n  /// Get the struct type used to represent all the arguments in memory.\n  llvm::StructType *getArgStruct() const { return ArgStruct; }\n  CharUnits getArgStructAlignment() const {\n    return CharUnits::fromQuantity(ArgStructAlign);\n  }\n  void setArgStruct(llvm::StructType *Ty, CharUnits Align) {\n    ArgStruct = Ty;\n    ArgStructAlign = Align.getQuantity();\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    ID.AddInteger(getASTCallingConvention());\n    ID.AddBoolean(InstanceMethod);\n    ID.AddBoolean(ChainCall);\n    ID.AddBoolean(NoReturn);\n    ID.AddBoolean(ReturnsRetained);\n    ID.AddBoolean(NoCallerSavedRegs);\n    ID.AddBoolean(HasRegParm);\n    ID.AddInteger(RegParm);\n    ID.AddBoolean(NoCfCheck);\n    ID.AddBoolean(CmseNSCall);\n    ID.AddInteger(Required.getOpaqueData());\n    ID.AddBoolean(HasExtParameterInfos);\n    if (HasExtParameterInfos) {\n      for (auto paramInfo : getExtParameterInfos())\n        ID.AddInteger(paramInfo.getOpaqueValue());\n    }\n    getReturnType().Profile(ID);\n    for (const auto &I : arguments())\n      I.type.Profile(ID);\n  }\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      bool InstanceMethod,\n                      bool ChainCall,\n                      const FunctionType::ExtInfo &info,\n                      ArrayRef<ExtParameterInfo> paramInfos,\n                      RequiredArgs required,\n                      CanQualType resultType,\n                      ArrayRef<CanQualType> argTypes) {\n    ID.AddInteger(info.getCC());\n    ID.AddBoolean(InstanceMethod);\n    ID.AddBoolean(ChainCall);\n    ID.AddBoolean(info.getNoReturn());\n    ID.AddBoolean(info.getProducesResult());\n    ID.AddBoolean(info.getNoCallerSavedRegs());\n    ID.AddBoolean(info.getHasRegParm());\n    ID.AddInteger(info.getRegParm());\n    ID.AddBoolean(info.getNoCfCheck());\n    ID.AddBoolean(info.getCmseNSCall());\n    ID.AddInteger(required.getOpaqueData());\n    ID.AddBoolean(!paramInfos.empty());\n    if (!paramInfos.empty()) {\n      for (auto paramInfo : paramInfos)\n        ID.AddInteger(paramInfo.getOpaqueValue());\n    }\n    resultType.Profile(ID);\n    for (ArrayRef<CanQualType>::iterator\n           i = argTypes.begin(), e = argTypes.end(); i != e; ++i) {\n      i->Profile(ID);\n    }\n  }\n};\n\n}  // end namespace CodeGen\n}  // end namespace clang\n\n#endif\n"}, "35": {"id": 35, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/ABIInfo.h", "content": "//===----- ABIInfo.h - ABI information access & encapsulation ---*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_ABIINFO_H\n#define LLVM_CLANG_LIB_CODEGEN_ABIINFO_H\n\n#include \"clang/AST/CharUnits.h\"\n#include \"clang/AST/Type.h\"\n#include \"llvm/IR/CallingConv.h\"\n#include \"llvm/IR/Type.h\"\n\nnamespace llvm {\n  class Value;\n  class LLVMContext;\n  class DataLayout;\n  class Type;\n}\n\nnamespace clang {\n  class ASTContext;\n  class CodeGenOptions;\n  class TargetInfo;\n\nnamespace CodeGen {\n  class ABIArgInfo;\n  class Address;\n  class CGCXXABI;\n  class CGFunctionInfo;\n  class CodeGenFunction;\n  class CodeGenTypes;\n  class SwiftABIInfo;\n\nnamespace swiftcall {\n  class SwiftAggLowering;\n}\n\n  // FIXME: All of this stuff should be part of the target interface\n  // somehow. It is currently here because it is not clear how to factor\n  // the targets to support this, since the Targets currently live in a\n  // layer below types n'stuff.\n\n\n  /// ABIInfo - Target specific hooks for defining how a type should be\n  /// passed or returned from functions.\n  class ABIInfo {\n  public:\n    CodeGen::CodeGenTypes &CGT;\n  protected:\n    llvm::CallingConv::ID RuntimeCC;\n  public:\n    ABIInfo(CodeGen::CodeGenTypes &cgt)\n        : CGT(cgt), RuntimeCC(llvm::CallingConv::C) {}\n\n    virtual ~ABIInfo();\n\n    virtual bool supportsSwift() const { return false; }\n\n    virtual bool allowBFloatArgsAndRet() const { return false; }\n\n    CodeGen::CGCXXABI &getCXXABI() const;\n    ASTContext &getContext() const;\n    llvm::LLVMContext &getVMContext() const;\n    const llvm::DataLayout &getDataLayout() const;\n    const TargetInfo &getTarget() const;\n    const CodeGenOptions &getCodeGenOpts() const;\n\n    /// Return the calling convention to use for system runtime\n    /// functions.\n    llvm::CallingConv::ID getRuntimeCC() const {\n      return RuntimeCC;\n    }\n\n    virtual void computeInfo(CodeGen::CGFunctionInfo &FI) const = 0;\n\n    /// EmitVAArg - Emit the target dependent code to load a value of\n    /// \\arg Ty from the va_list pointed to by \\arg VAListAddr.\n\n    // FIXME: This is a gaping layering violation if we wanted to drop\n    // the ABI information any lower than CodeGen. Of course, for\n    // VAArg handling it has to be at this level; there is no way to\n    // abstract this out.\n    virtual CodeGen::Address EmitVAArg(CodeGen::CodeGenFunction &CGF,\n                                       CodeGen::Address VAListAddr,\n                                       QualType Ty) const = 0;\n\n    bool isAndroid() const;\n\n    /// Emit the target dependent code to load a value of\n    /// \\arg Ty from the \\c __builtin_ms_va_list pointed to by \\arg VAListAddr.\n    virtual CodeGen::Address EmitMSVAArg(CodeGen::CodeGenFunction &CGF,\n                                         CodeGen::Address VAListAddr,\n                                         QualType Ty) const;\n\n    virtual bool isHomogeneousAggregateBaseType(QualType Ty) const;\n\n    virtual bool isHomogeneousAggregateSmallEnough(const Type *Base,\n                                                   uint64_t Members) const;\n\n    bool isHomogeneousAggregate(QualType Ty, const Type *&Base,\n                                uint64_t &Members) const;\n\n    // Implement the Type::IsPromotableIntegerType for ABI specific needs. The\n    // only difference is that this considers _ExtInt as well.\n    bool isPromotableIntegerTypeForABI(QualType Ty) const;\n\n    /// A convenience method to return an indirect ABIArgInfo with an\n    /// expected alignment equal to the ABI alignment of the given type.\n    CodeGen::ABIArgInfo\n    getNaturalAlignIndirect(QualType Ty, bool ByVal = true,\n                            bool Realign = false,\n                            llvm::Type *Padding = nullptr) const;\n\n    CodeGen::ABIArgInfo\n    getNaturalAlignIndirectInReg(QualType Ty, bool Realign = false) const;\n\n\n  };\n\n  /// A refining implementation of ABIInfo for targets that support swiftcall.\n  ///\n  /// If we find ourselves wanting multiple such refinements, they'll probably\n  /// be independent refinements, and we should probably find another way\n  /// to do it than simple inheritance.\n  class SwiftABIInfo : public ABIInfo {\n  public:\n    SwiftABIInfo(CodeGen::CodeGenTypes &cgt) : ABIInfo(cgt) {}\n\n    bool supportsSwift() const final override { return true; }\n\n    virtual bool shouldPassIndirectlyForSwift(ArrayRef<llvm::Type*> types,\n                                              bool asReturnValue) const = 0;\n\n    virtual bool isLegalVectorTypeForSwift(CharUnits totalSize,\n                                           llvm::Type *eltTy,\n                                           unsigned elts) const;\n\n    virtual bool isSwiftErrorInRegister() const = 0;\n\n    static bool classof(const ABIInfo *info) {\n      return info->supportsSwift();\n    }\n  };\n}  // end namespace CodeGen\n}  // end namespace clang\n\n#endif\n"}, "36": {"id": 36, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGBuilder.h", "content": "//===-- CGBuilder.h - Choose IRBuilder implementation  ----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGBUILDER_H\n#define LLVM_CLANG_LIB_CODEGEN_CGBUILDER_H\n\n#include \"llvm/IR/DataLayout.h\"\n#include \"llvm/IR/IRBuilder.h\"\n#include \"Address.h\"\n#include \"CodeGenTypeCache.h\"\n\nnamespace clang {\nnamespace CodeGen {\n\nclass CodeGenFunction;\n\n/// This is an IRBuilder insertion helper that forwards to\n/// CodeGenFunction::InsertHelper, which adds necessary metadata to\n/// instructions.\nclass CGBuilderInserter final : public llvm::IRBuilderDefaultInserter {\npublic:\n  CGBuilderInserter() = default;\n  explicit CGBuilderInserter(CodeGenFunction *CGF) : CGF(CGF) {}\n\n  /// This forwards to CodeGenFunction::InsertHelper.\n  void InsertHelper(llvm::Instruction *I, const llvm::Twine &Name,\n                    llvm::BasicBlock *BB,\n                    llvm::BasicBlock::iterator InsertPt) const override;\nprivate:\n  CodeGenFunction *CGF = nullptr;\n};\n\ntypedef CGBuilderInserter CGBuilderInserterTy;\n\ntypedef llvm::IRBuilder<llvm::ConstantFolder, CGBuilderInserterTy>\n    CGBuilderBaseTy;\n\nclass CGBuilderTy : public CGBuilderBaseTy {\n  /// Storing a reference to the type cache here makes it a lot easier\n  /// to build natural-feeling, target-specific IR.\n  const CodeGenTypeCache &TypeCache;\npublic:\n  CGBuilderTy(const CodeGenTypeCache &TypeCache, llvm::LLVMContext &C)\n    : CGBuilderBaseTy(C), TypeCache(TypeCache) {}\n  CGBuilderTy(const CodeGenTypeCache &TypeCache,\n              llvm::LLVMContext &C, const llvm::ConstantFolder &F,\n              const CGBuilderInserterTy &Inserter)\n    : CGBuilderBaseTy(C, F, Inserter), TypeCache(TypeCache) {}\n  CGBuilderTy(const CodeGenTypeCache &TypeCache, llvm::Instruction *I)\n    : CGBuilderBaseTy(I), TypeCache(TypeCache) {}\n  CGBuilderTy(const CodeGenTypeCache &TypeCache, llvm::BasicBlock *BB)\n    : CGBuilderBaseTy(BB), TypeCache(TypeCache) {}\n\n  llvm::ConstantInt *getSize(CharUnits N) {\n    return llvm::ConstantInt::get(TypeCache.SizeTy, N.getQuantity());\n  }\n  llvm::ConstantInt *getSize(uint64_t N) {\n    return llvm::ConstantInt::get(TypeCache.SizeTy, N);\n  }\n\n  // Note that we intentionally hide the CreateLoad APIs that don't\n  // take an alignment.\n  llvm::LoadInst *CreateLoad(Address Addr, const llvm::Twine &Name = \"\") {\n    return CreateAlignedLoad(Addr.getPointer(),\n                             Addr.getAlignment().getAsAlign(), Name);\n  }\n  llvm::LoadInst *CreateLoad(Address Addr, const char *Name) {\n    // This overload is required to prevent string literals from\n    // ending up in the IsVolatile overload.\n    return CreateAlignedLoad(Addr.getPointer(),\n                             Addr.getAlignment().getAsAlign(), Name);\n  }\n  llvm::LoadInst *CreateLoad(Address Addr, bool IsVolatile,\n                             const llvm::Twine &Name = \"\") {\n    return CreateAlignedLoad(\n        Addr.getPointer(), Addr.getAlignment().getAsAlign(), IsVolatile, Name);\n  }\n\n  using CGBuilderBaseTy::CreateAlignedLoad;\n  llvm::LoadInst *CreateAlignedLoad(llvm::Type *Ty, llvm::Value *Addr,\n                                    CharUnits Align,\n                                    const llvm::Twine &Name = \"\") {\n    assert(Addr->getType()->getPointerElementType() == Ty);\n    return CreateAlignedLoad(Ty, Addr, Align.getAsAlign(), Name);\n  }\n\n  // Note that we intentionally hide the CreateStore APIs that don't\n  // take an alignment.\n  llvm::StoreInst *CreateStore(llvm::Value *Val, Address Addr,\n                               bool IsVolatile = false) {\n    return CreateAlignedStore(Val, Addr.getPointer(),\n                              Addr.getAlignment().getAsAlign(), IsVolatile);\n  }\n\n  using CGBuilderBaseTy::CreateAlignedStore;\n  llvm::StoreInst *CreateAlignedStore(llvm::Value *Val, llvm::Value *Addr,\n                                      CharUnits Align, bool IsVolatile = false) {\n    return CreateAlignedStore(Val, Addr, Align.getAsAlign(), IsVolatile);\n  }\n\n  // FIXME: these \"default-aligned\" APIs should be removed,\n  // but I don't feel like fixing all the builtin code right now.\n  llvm::StoreInst *CreateDefaultAlignedStore(llvm::Value *Val,\n                                             llvm::Value *Addr,\n                                             bool IsVolatile = false) {\n    return CGBuilderBaseTy::CreateStore(Val, Addr, IsVolatile);\n  }\n\n  /// Emit a load from an i1 flag variable.\n  llvm::LoadInst *CreateFlagLoad(llvm::Value *Addr,\n                                 const llvm::Twine &Name = \"\") {\n    assert(Addr->getType()->getPointerElementType() == getInt1Ty());\n    return CreateAlignedLoad(getInt1Ty(), Addr, CharUnits::One(), Name);\n  }\n\n  /// Emit a store to an i1 flag variable.\n  llvm::StoreInst *CreateFlagStore(bool Value, llvm::Value *Addr) {\n    assert(Addr->getType()->getPointerElementType() == getInt1Ty());\n    return CreateAlignedStore(getInt1(Value), Addr, CharUnits::One());\n  }\n\n  // Temporarily use old signature; clang will be updated to an Address overload\n  // in a subsequent patch.\n  llvm::AtomicCmpXchgInst *\n  CreateAtomicCmpXchg(llvm::Value *Ptr, llvm::Value *Cmp, llvm::Value *New,\n                      llvm::AtomicOrdering SuccessOrdering,\n                      llvm::AtomicOrdering FailureOrdering,\n                      llvm::SyncScope::ID SSID = llvm::SyncScope::System) {\n    return CGBuilderBaseTy::CreateAtomicCmpXchg(\n        Ptr, Cmp, New, llvm::MaybeAlign(), SuccessOrdering, FailureOrdering,\n        SSID);\n  }\n\n  // Temporarily use old signature; clang will be updated to an Address overload\n  // in a subsequent patch.\n  llvm::AtomicRMWInst *\n  CreateAtomicRMW(llvm::AtomicRMWInst::BinOp Op, llvm::Value *Ptr,\n                  llvm::Value *Val, llvm::AtomicOrdering Ordering,\n                  llvm::SyncScope::ID SSID = llvm::SyncScope::System) {\n    return CGBuilderBaseTy::CreateAtomicRMW(Op, Ptr, Val, llvm::MaybeAlign(),\n                                            Ordering, SSID);\n  }\n\n  using CGBuilderBaseTy::CreateBitCast;\n  Address CreateBitCast(Address Addr, llvm::Type *Ty,\n                        const llvm::Twine &Name = \"\") {\n    return Address(CreateBitCast(Addr.getPointer(), Ty, Name),\n                   Addr.getAlignment());\n  }\n\n  using CGBuilderBaseTy::CreateAddrSpaceCast;\n  Address CreateAddrSpaceCast(Address Addr, llvm::Type *Ty,\n                              const llvm::Twine &Name = \"\") {\n    return Address(CreateAddrSpaceCast(Addr.getPointer(), Ty, Name),\n                   Addr.getAlignment());\n  }\n\n  /// Cast the element type of the given address to a different type,\n  /// preserving information like the alignment and address space.\n  Address CreateElementBitCast(Address Addr, llvm::Type *Ty,\n                               const llvm::Twine &Name = \"\") {\n    auto PtrTy = Ty->getPointerTo(Addr.getAddressSpace());\n    return CreateBitCast(Addr, PtrTy, Name);\n  }\n\n  using CGBuilderBaseTy::CreatePointerBitCastOrAddrSpaceCast;\n  Address CreatePointerBitCastOrAddrSpaceCast(Address Addr, llvm::Type *Ty,\n                                              const llvm::Twine &Name = \"\") {\n    llvm::Value *Ptr =\n      CreatePointerBitCastOrAddrSpaceCast(Addr.getPointer(), Ty, Name);\n    return Address(Ptr, Addr.getAlignment());\n  }\n\n  /// Given\n  ///   %addr = {T1, T2...}* ...\n  /// produce\n  ///   %name = getelementptr inbounds %addr, i32 0, i32 index\n  ///\n  /// This API assumes that drilling into a struct like this is always an\n  /// inbounds operation.\n  using CGBuilderBaseTy::CreateStructGEP;\n  Address CreateStructGEP(Address Addr, unsigned Index,\n                          const llvm::Twine &Name = \"\") {\n    llvm::StructType *ElTy = cast<llvm::StructType>(Addr.getElementType());\n    const llvm::DataLayout &DL = BB->getParent()->getParent()->getDataLayout();\n    const llvm::StructLayout *Layout = DL.getStructLayout(ElTy);\n    auto Offset = CharUnits::fromQuantity(Layout->getElementOffset(Index));\n\n    return Address(CreateStructGEP(Addr.getElementType(),\n                                   Addr.getPointer(), Index, Name),\n                   Addr.getAlignment().alignmentAtOffset(Offset));\n  }\n\n  /// Given\n  ///   %addr = [n x T]* ...\n  /// produce\n  ///   %name = getelementptr inbounds %addr, i64 0, i64 index\n  /// where i64 is actually the target word size.\n  ///\n  /// This API assumes that drilling into an array like this is always\n  /// an inbounds operation.\n  Address CreateConstArrayGEP(Address Addr, uint64_t Index,\n                              const llvm::Twine &Name = \"\") {\n    llvm::ArrayType *ElTy = cast<llvm::ArrayType>(Addr.getElementType());\n    const llvm::DataLayout &DL = BB->getParent()->getParent()->getDataLayout();\n    CharUnits EltSize =\n        CharUnits::fromQuantity(DL.getTypeAllocSize(ElTy->getElementType()));\n\n    return Address(\n        CreateInBoundsGEP(Addr.getPointer(),\n                          {getSize(CharUnits::Zero()), getSize(Index)}, Name),\n        Addr.getAlignment().alignmentAtOffset(Index * EltSize));\n  }\n\n  /// Given\n  ///   %addr = T* ...\n  /// produce\n  ///   %name = getelementptr inbounds %addr, i64 index\n  /// where i64 is actually the target word size.\n  Address CreateConstInBoundsGEP(Address Addr, uint64_t Index,\n                                 const llvm::Twine &Name = \"\") {\n    llvm::Type *ElTy = Addr.getElementType();\n    const llvm::DataLayout &DL = BB->getParent()->getParent()->getDataLayout();\n    CharUnits EltSize = CharUnits::fromQuantity(DL.getTypeAllocSize(ElTy));\n\n    return Address(CreateInBoundsGEP(Addr.getElementType(), Addr.getPointer(),\n                                     getSize(Index), Name),\n                   Addr.getAlignment().alignmentAtOffset(Index * EltSize));\n  }\n\n  /// Given\n  ///   %addr = T* ...\n  /// produce\n  ///   %name = getelementptr inbounds %addr, i64 index\n  /// where i64 is actually the target word size.\n  Address CreateConstGEP(Address Addr, uint64_t Index,\n                         const llvm::Twine &Name = \"\") {\n    const llvm::DataLayout &DL = BB->getParent()->getParent()->getDataLayout();\n    CharUnits EltSize =\n        CharUnits::fromQuantity(DL.getTypeAllocSize(Addr.getElementType()));\n\n    return Address(CreateGEP(Addr.getElementType(), Addr.getPointer(),\n                             getSize(Index), Name),\n                   Addr.getAlignment().alignmentAtOffset(Index * EltSize));\n  }\n\n  /// Given a pointer to i8, adjust it by a given constant offset.\n  Address CreateConstInBoundsByteGEP(Address Addr, CharUnits Offset,\n                                     const llvm::Twine &Name = \"\") {\n    assert(Addr.getElementType() == TypeCache.Int8Ty);\n    return Address(CreateInBoundsGEP(Addr.getPointer(), getSize(Offset), Name),\n                   Addr.getAlignment().alignmentAtOffset(Offset));\n  }\n  Address CreateConstByteGEP(Address Addr, CharUnits Offset,\n                             const llvm::Twine &Name = \"\") {\n    assert(Addr.getElementType() == TypeCache.Int8Ty);\n    return Address(CreateGEP(Addr.getPointer(), getSize(Offset), Name),\n                   Addr.getAlignment().alignmentAtOffset(Offset));\n  }\n\n  using CGBuilderBaseTy::CreateConstInBoundsGEP2_32;\n  Address CreateConstInBoundsGEP2_32(Address Addr, unsigned Idx0, unsigned Idx1,\n                                     const llvm::Twine &Name = \"\") {\n    const llvm::DataLayout &DL = BB->getParent()->getParent()->getDataLayout();\n\n    auto *GEP = cast<llvm::GetElementPtrInst>(CreateConstInBoundsGEP2_32(\n        Addr.getElementType(), Addr.getPointer(), Idx0, Idx1, Name));\n    llvm::APInt Offset(\n        DL.getIndexSizeInBits(Addr.getType()->getPointerAddressSpace()), 0,\n        /*isSigned=*/true);\n    if (!GEP->accumulateConstantOffset(DL, Offset))\n      llvm_unreachable(\"offset of GEP with constants is always computable\");\n    return Address(GEP, Addr.getAlignment().alignmentAtOffset(\n                            CharUnits::fromQuantity(Offset.getSExtValue())));\n  }\n\n  using CGBuilderBaseTy::CreateMemCpy;\n  llvm::CallInst *CreateMemCpy(Address Dest, Address Src, llvm::Value *Size,\n                               bool IsVolatile = false) {\n    return CreateMemCpy(Dest.getPointer(), Dest.getAlignment().getAsAlign(),\n                        Src.getPointer(), Src.getAlignment().getAsAlign(), Size,\n                        IsVolatile);\n  }\n  llvm::CallInst *CreateMemCpy(Address Dest, Address Src, uint64_t Size,\n                               bool IsVolatile = false) {\n    return CreateMemCpy(Dest.getPointer(), Dest.getAlignment().getAsAlign(),\n                        Src.getPointer(), Src.getAlignment().getAsAlign(), Size,\n                        IsVolatile);\n  }\n\n  using CGBuilderBaseTy::CreateMemCpyInline;\n  llvm::CallInst *CreateMemCpyInline(Address Dest, Address Src, uint64_t Size) {\n    return CreateMemCpyInline(\n        Dest.getPointer(), Dest.getAlignment().getAsAlign(), Src.getPointer(),\n        Src.getAlignment().getAsAlign(), getInt64(Size));\n  }\n\n  using CGBuilderBaseTy::CreateMemMove;\n  llvm::CallInst *CreateMemMove(Address Dest, Address Src, llvm::Value *Size,\n                                bool IsVolatile = false) {\n    return CreateMemMove(Dest.getPointer(), Dest.getAlignment().getAsAlign(),\n                         Src.getPointer(), Src.getAlignment().getAsAlign(),\n                         Size, IsVolatile);\n  }\n\n  using CGBuilderBaseTy::CreateMemSet;\n  llvm::CallInst *CreateMemSet(Address Dest, llvm::Value *Value,\n                               llvm::Value *Size, bool IsVolatile = false) {\n    return CreateMemSet(Dest.getPointer(), Value, Size,\n                        Dest.getAlignment().getAsAlign(), IsVolatile);\n  }\n\n  using CGBuilderBaseTy::CreatePreserveStructAccessIndex;\n  Address CreatePreserveStructAccessIndex(Address Addr,\n                                          unsigned Index,\n                                          unsigned FieldIndex,\n                                          llvm::MDNode *DbgInfo) {\n    llvm::StructType *ElTy = cast<llvm::StructType>(Addr.getElementType());\n    const llvm::DataLayout &DL = BB->getParent()->getParent()->getDataLayout();\n    const llvm::StructLayout *Layout = DL.getStructLayout(ElTy);\n    auto Offset = CharUnits::fromQuantity(Layout->getElementOffset(Index));\n\n    return Address(CreatePreserveStructAccessIndex(ElTy, Addr.getPointer(),\n                                                   Index, FieldIndex, DbgInfo),\n                   Addr.getAlignment().alignmentAtOffset(Offset));\n  }\n};\n\n}  // end namespace CodeGen\n}  // end namespace clang\n\n#endif\n"}, "37": {"id": 37, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "content": "//===----- CGCall.h - Encapsulate calling convention details ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// These classes wrap the information about a call or function\n// definition used to handle ABI compliancy.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGCALL_H\n#define LLVM_CLANG_LIB_CODEGEN_CGCALL_H\n\n#include \"CGValue.h\"\n#include \"EHScopeStack.h\"\n#include \"clang/AST/ASTFwd.h\"\n#include \"clang/AST/CanonicalType.h\"\n#include \"clang/AST/GlobalDecl.h\"\n#include \"clang/AST/Type.h\"\n#include \"llvm/IR/Value.h\"\n\n// FIXME: Restructure so we don't have to expose so much stuff.\n#include \"ABIInfo.h\"\n\nnamespace llvm {\nclass AttributeList;\nclass Function;\nclass Type;\nclass Value;\n} // namespace llvm\n\nnamespace clang {\nclass ASTContext;\nclass Decl;\nclass FunctionDecl;\nclass ObjCMethodDecl;\nclass VarDecl;\n\nnamespace CodeGen {\n\n/// Abstract information about a function or function prototype.\nclass CGCalleeInfo {\n  /// The function prototype of the callee.\n  const FunctionProtoType *CalleeProtoTy;\n  /// The function declaration of the callee.\n  GlobalDecl CalleeDecl;\n\npublic:\n  explicit CGCalleeInfo() : CalleeProtoTy(nullptr), CalleeDecl() {}\n  CGCalleeInfo(const FunctionProtoType *calleeProtoTy, GlobalDecl calleeDecl)\n      : CalleeProtoTy(calleeProtoTy), CalleeDecl(calleeDecl) {}\n  CGCalleeInfo(const FunctionProtoType *calleeProtoTy)\n      : CalleeProtoTy(calleeProtoTy), CalleeDecl() {}\n  CGCalleeInfo(GlobalDecl calleeDecl)\n      : CalleeProtoTy(nullptr), CalleeDecl(calleeDecl) {}\n\n  const FunctionProtoType *getCalleeFunctionProtoType() const {\n    return CalleeProtoTy;\n  }\n  const GlobalDecl getCalleeDecl() const { return CalleeDecl; }\n};\n\n/// All available information about a concrete callee.\nclass CGCallee {\n  enum class SpecialKind : uintptr_t {\n    Invalid,\n    Builtin,\n    PseudoDestructor,\n    Virtual,\n\n    Last = Virtual\n  };\n\n  struct BuiltinInfoStorage {\n    const FunctionDecl *Decl;\n    unsigned ID;\n  };\n  struct PseudoDestructorInfoStorage {\n    const CXXPseudoDestructorExpr *Expr;\n  };\n  struct VirtualInfoStorage {\n    const CallExpr *CE;\n    GlobalDecl MD;\n    Address Addr;\n    llvm::FunctionType *FTy;\n  };\n\n  SpecialKind KindOrFunctionPointer;\n  union {\n    CGCalleeInfo AbstractInfo;\n    BuiltinInfoStorage BuiltinInfo;\n    PseudoDestructorInfoStorage PseudoDestructorInfo;\n    VirtualInfoStorage VirtualInfo;\n  };\n\n  explicit CGCallee(SpecialKind kind) : KindOrFunctionPointer(kind) {}\n\n  CGCallee(const FunctionDecl *builtinDecl, unsigned builtinID)\n      : KindOrFunctionPointer(SpecialKind::Builtin) {\n    BuiltinInfo.Decl = builtinDecl;\n    BuiltinInfo.ID = builtinID;\n  }\n\npublic:\n  CGCallee() : KindOrFunctionPointer(SpecialKind::Invalid) {}\n\n  /// Construct a callee.  Call this constructor directly when this\n  /// isn't a direct call.\n  CGCallee(const CGCalleeInfo &abstractInfo, llvm::Value *functionPtr)\n      : KindOrFunctionPointer(\n            SpecialKind(reinterpret_cast<uintptr_t>(functionPtr))) {\n    AbstractInfo = abstractInfo;\n    assert(functionPtr && \"configuring callee without function pointer\");\n    assert(functionPtr->getType()->isPointerTy());\n    assert(functionPtr->getType()->getPointerElementType()->isFunctionTy());\n  }\n\n  static CGCallee forBuiltin(unsigned builtinID,\n                             const FunctionDecl *builtinDecl) {\n    CGCallee result(SpecialKind::Builtin);\n    result.BuiltinInfo.Decl = builtinDecl;\n    result.BuiltinInfo.ID = builtinID;\n    return result;\n  }\n\n  static CGCallee forPseudoDestructor(const CXXPseudoDestructorExpr *E) {\n    CGCallee result(SpecialKind::PseudoDestructor);\n    result.PseudoDestructorInfo.Expr = E;\n    return result;\n  }\n\n  static CGCallee forDirect(llvm::Constant *functionPtr,\n                            const CGCalleeInfo &abstractInfo = CGCalleeInfo()) {\n    return CGCallee(abstractInfo, functionPtr);\n  }\n\n  static CGCallee forDirect(llvm::FunctionCallee functionPtr,\n                            const CGCalleeInfo &abstractInfo = CGCalleeInfo()) {\n    return CGCallee(abstractInfo, functionPtr.getCallee());\n  }\n\n  static CGCallee forVirtual(const CallExpr *CE, GlobalDecl MD, Address Addr,\n                             llvm::FunctionType *FTy) {\n    CGCallee result(SpecialKind::Virtual);\n    result.VirtualInfo.CE = CE;\n    result.VirtualInfo.MD = MD;\n    result.VirtualInfo.Addr = Addr;\n    result.VirtualInfo.FTy = FTy;\n    return result;\n  }\n\n  bool isBuiltin() const {\n    return KindOrFunctionPointer == SpecialKind::Builtin;\n  }\n  const FunctionDecl *getBuiltinDecl() const {\n    assert(isBuiltin());\n    return BuiltinInfo.Decl;\n  }\n  unsigned getBuiltinID() const {\n    assert(isBuiltin());\n    return BuiltinInfo.ID;\n  }\n\n  bool isPseudoDestructor() const {\n    return KindOrFunctionPointer == SpecialKind::PseudoDestructor;\n  }\n  const CXXPseudoDestructorExpr *getPseudoDestructorExpr() const {\n    assert(isPseudoDestructor());\n    return PseudoDestructorInfo.Expr;\n  }\n\n  bool isOrdinary() const {\n    return uintptr_t(KindOrFunctionPointer) > uintptr_t(SpecialKind::Last);\n  }\n  CGCalleeInfo getAbstractInfo() const {\n    if (isVirtual())\n      return VirtualInfo.MD;\n    assert(isOrdinary());\n    return AbstractInfo;\n  }\n  llvm::Value *getFunctionPointer() const {\n    assert(isOrdinary());\n    return reinterpret_cast<llvm::Value *>(uintptr_t(KindOrFunctionPointer));\n  }\n  void setFunctionPointer(llvm::Value *functionPtr) {\n    assert(isOrdinary());\n    KindOrFunctionPointer =\n        SpecialKind(reinterpret_cast<uintptr_t>(functionPtr));\n  }\n\n  bool isVirtual() const {\n    return KindOrFunctionPointer == SpecialKind::Virtual;\n  }\n  const CallExpr *getVirtualCallExpr() const {\n    assert(isVirtual());\n    return VirtualInfo.CE;\n  }\n  GlobalDecl getVirtualMethodDecl() const {\n    assert(isVirtual());\n    return VirtualInfo.MD;\n  }\n  Address getThisAddress() const {\n    assert(isVirtual());\n    return VirtualInfo.Addr;\n  }\n  llvm::FunctionType *getVirtualFunctionType() const {\n    assert(isVirtual());\n    return VirtualInfo.FTy;\n  }\n\n  /// If this is a delayed callee computation of some sort, prepare\n  /// a concrete callee.\n  CGCallee prepareConcreteCallee(CodeGenFunction &CGF) const;\n};\n\nstruct CallArg {\nprivate:\n  union {\n    RValue RV;\n    LValue LV; /// The argument is semantically a load from this l-value.\n  };\n  bool HasLV;\n\n  /// A data-flow flag to make sure getRValue and/or copyInto are not\n  /// called twice for duplicated IR emission.\n  mutable bool IsUsed;\n\npublic:\n  QualType Ty;\n  CallArg(RValue rv, QualType ty)\n      : RV(rv), HasLV(false), IsUsed(false), Ty(ty) {}\n  CallArg(LValue lv, QualType ty)\n      : LV(lv), HasLV(true), IsUsed(false), Ty(ty) {}\n  bool hasLValue() const { return HasLV; }\n  QualType getType() const { return Ty; }\n\n  /// \\returns an independent RValue. If the CallArg contains an LValue,\n  /// a temporary copy is returned.\n  RValue getRValue(CodeGenFunction &CGF) const;\n\n  LValue getKnownLValue() const {\n    assert(HasLV && !IsUsed);\n    return LV;\n  }\n  RValue getKnownRValue() const {\n    assert(!HasLV && !IsUsed);\n    return RV;\n  }\n  void setRValue(RValue _RV) {\n    assert(!HasLV);\n    RV = _RV;\n  }\n\n  bool isAggregate() const { return HasLV || RV.isAggregate(); }\n\n  void copyInto(CodeGenFunction &CGF, Address A) const;\n};\n\n/// CallArgList - Type for representing both the value and type of\n/// arguments in a call.\nclass CallArgList : public SmallVector<CallArg, 8> {\npublic:\n  CallArgList() : StackBase(nullptr) {}\n\n  struct Writeback {\n    /// The original argument.  Note that the argument l-value\n    /// is potentially null.\n    LValue Source;\n\n    /// The temporary alloca.\n    Address Temporary;\n\n    /// A value to \"use\" after the writeback, or null.\n    llvm::Value *ToUse;\n  };\n\n  struct CallArgCleanup {\n    EHScopeStack::stable_iterator Cleanup;\n\n    /// The \"is active\" insertion point.  This instruction is temporary and\n    /// will be removed after insertion.\n    llvm::Instruction *IsActiveIP;\n  };\n\n  void add(RValue rvalue, QualType type) { push_back(CallArg(rvalue, type)); }\n\n  void addUncopiedAggregate(LValue LV, QualType type) {\n    push_back(CallArg(LV, type));\n  }\n\n  /// Add all the arguments from another CallArgList to this one. After doing\n  /// this, the old CallArgList retains its list of arguments, but must not\n  /// be used to emit a call.\n  void addFrom(const CallArgList &other) {\n    insert(end(), other.begin(), other.end());\n    Writebacks.insert(Writebacks.end(), other.Writebacks.begin(),\n                      other.Writebacks.end());\n    CleanupsToDeactivate.insert(CleanupsToDeactivate.end(),\n                                other.CleanupsToDeactivate.begin(),\n                                other.CleanupsToDeactivate.end());\n    assert(!(StackBase && other.StackBase) && \"can't merge stackbases\");\n    if (!StackBase)\n      StackBase = other.StackBase;\n  }\n\n  void addWriteback(LValue srcLV, Address temporary, llvm::Value *toUse) {\n    Writeback writeback = {srcLV, temporary, toUse};\n    Writebacks.push_back(writeback);\n  }\n\n  bool hasWritebacks() const { return !Writebacks.empty(); }\n\n  typedef llvm::iterator_range<SmallVectorImpl<Writeback>::const_iterator>\n      writeback_const_range;\n\n  writeback_const_range writebacks() const {\n    return writeback_const_range(Writebacks.begin(), Writebacks.end());\n  }\n\n  void addArgCleanupDeactivation(EHScopeStack::stable_iterator Cleanup,\n                                 llvm::Instruction *IsActiveIP) {\n    CallArgCleanup ArgCleanup;\n    ArgCleanup.Cleanup = Cleanup;\n    ArgCleanup.IsActiveIP = IsActiveIP;\n    CleanupsToDeactivate.push_back(ArgCleanup);\n  }\n\n  ArrayRef<CallArgCleanup> getCleanupsToDeactivate() const {\n    return CleanupsToDeactivate;\n  }\n\n  void allocateArgumentMemory(CodeGenFunction &CGF);\n  llvm::Instruction *getStackBase() const { return StackBase; }\n  void freeArgumentMemory(CodeGenFunction &CGF) const;\n\n  /// Returns if we're using an inalloca struct to pass arguments in\n  /// memory.\n  bool isUsingInAlloca() const { return StackBase; }\n\nprivate:\n  SmallVector<Writeback, 1> Writebacks;\n\n  /// Deactivate these cleanups immediately before making the call.  This\n  /// is used to cleanup objects that are owned by the callee once the call\n  /// occurs.\n  SmallVector<CallArgCleanup, 1> CleanupsToDeactivate;\n\n  /// The stacksave call.  It dominates all of the argument evaluation.\n  llvm::CallInst *StackBase;\n};\n\n/// FunctionArgList - Type for representing both the decl and type\n/// of parameters to a function. The decl must be either a\n/// ParmVarDecl or ImplicitParamDecl.\nclass FunctionArgList : public SmallVector<const VarDecl *, 16> {};\n\n/// ReturnValueSlot - Contains the address where the return value of a\n/// function can be stored, and whether the address is volatile or not.\nclass ReturnValueSlot {\n  Address Addr = Address::invalid();\n\n  // Return value slot flags\n  unsigned IsVolatile : 1;\n  unsigned IsUnused : 1;\n  unsigned IsExternallyDestructed : 1;\n\npublic:\n  ReturnValueSlot()\n      : IsVolatile(false), IsUnused(false), IsExternallyDestructed(false) {}\n  ReturnValueSlot(Address Addr, bool IsVolatile, bool IsUnused = false,\n                  bool IsExternallyDestructed = false)\n      : Addr(Addr), IsVolatile(IsVolatile), IsUnused(IsUnused),\n        IsExternallyDestructed(IsExternallyDestructed) {}\n\n  bool isNull() const { return !Addr.isValid(); }\n  bool isVolatile() const { return IsVolatile; }\n  Address getValue() const { return Addr; }\n  bool isUnused() const { return IsUnused; }\n  bool isExternallyDestructed() const { return IsExternallyDestructed; }\n};\n\n} // end namespace CodeGen\n} // end namespace clang\n\n#endif\n"}, "38": {"id": 38, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeAMDGCN.h", "content": "//===--- CGOpenMPRuntimeAMDGCN.h - Interface to OpenMP AMDGCN Runtimes ---===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This provides a class for OpenMP runtime code generation specialized to\n// AMDGCN targets from generalized CGOpenMPRuntimeGPU class.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGOPENMPRUNTIMEAMDGCN_H\n#define LLVM_CLANG_LIB_CODEGEN_CGOPENMPRUNTIMEAMDGCN_H\n\n#include \"CGOpenMPRuntime.h\"\n#include \"CGOpenMPRuntimeGPU.h\"\n#include \"CodeGenFunction.h\"\n#include \"clang/AST/StmtOpenMP.h\"\n\nnamespace clang {\nnamespace CodeGen {\n\nclass CGOpenMPRuntimeAMDGCN final : public CGOpenMPRuntimeGPU {\n\npublic:\n  explicit CGOpenMPRuntimeAMDGCN(CodeGenModule &CGM);\n\n  /// Get the GPU warp size.\n  llvm::Value *getGPUWarpSize(CodeGenFunction &CGF) override;\n\n  /// Get the id of the current thread on the GPU.\n  llvm::Value *getGPUThreadID(CodeGenFunction &CGF) override;\n\n  /// Get the maximum number of threads in a block of the GPU.\n  llvm::Value *getGPUNumThreads(CodeGenFunction &CGF) override;\n};\n\n} // namespace CodeGen\n} // namespace clang\n\n#endif // LLVM_CLANG_LIB_CODEGEN_CGOPENMPRUNTIMEAMDGCN_H\n"}, "39": {"id": 39, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "content": "//===-- CodeGenFunction.h - Per-Function state for LLVM CodeGen -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This is the internal per-function state used for llvm translation.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CODEGENFUNCTION_H\n#define LLVM_CLANG_LIB_CODEGEN_CODEGENFUNCTION_H\n\n#include \"CGBuilder.h\"\n#include \"CGDebugInfo.h\"\n#include \"CGLoopInfo.h\"\n#include \"CGValue.h\"\n#include \"CodeGenModule.h\"\n#include \"CodeGenPGO.h\"\n#include \"EHScopeStack.h\"\n#include \"VarBypassDetector.h\"\n#include \"clang/AST/CharUnits.h\"\n#include \"clang/AST/CurrentSourceLocExprScope.h\"\n#include \"clang/AST/ExprCXX.h\"\n#include \"clang/AST/ExprObjC.h\"\n#include \"clang/AST/ExprOpenMP.h\"\n#include \"clang/AST/StmtOpenMP.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/ABI.h\"\n#include \"clang/Basic/CapturedStmt.h\"\n#include \"clang/Basic/CodeGenOptions.h\"\n#include \"clang/Basic/OpenMPKinds.h\"\n#include \"clang/Basic/TargetInfo.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Frontend/OpenMP/OMPIRBuilder.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Transforms/Utils/SanitizerStats.h\"\n\nnamespace llvm {\nclass BasicBlock;\nclass LLVMContext;\nclass MDNode;\nclass Module;\nclass SwitchInst;\nclass Twine;\nclass Value;\nclass CanonicalLoopInfo;\n}\n\nnamespace clang {\nclass ASTContext;\nclass BlockDecl;\nclass CXXDestructorDecl;\nclass CXXForRangeStmt;\nclass CXXTryStmt;\nclass Decl;\nclass LabelDecl;\nclass EnumConstantDecl;\nclass FunctionDecl;\nclass FunctionProtoType;\nclass LabelStmt;\nclass ObjCContainerDecl;\nclass ObjCInterfaceDecl;\nclass ObjCIvarDecl;\nclass ObjCMethodDecl;\nclass ObjCImplementationDecl;\nclass ObjCPropertyImplDecl;\nclass TargetInfo;\nclass VarDecl;\nclass ObjCForCollectionStmt;\nclass ObjCAtTryStmt;\nclass ObjCAtThrowStmt;\nclass ObjCAtSynchronizedStmt;\nclass ObjCAutoreleasePoolStmt;\nclass OMPUseDevicePtrClause;\nclass OMPUseDeviceAddrClause;\nclass ReturnsNonNullAttr;\nclass SVETypeFlags;\nclass OMPExecutableDirective;\n\nnamespace analyze_os_log {\nclass OSLogBufferLayout;\n}\n\nnamespace CodeGen {\nclass CodeGenTypes;\nclass CGCallee;\nclass CGFunctionInfo;\nclass CGRecordLayout;\nclass CGBlockInfo;\nclass CGCXXABI;\nclass BlockByrefHelpers;\nclass BlockByrefInfo;\nclass BlockFlags;\nclass BlockFieldFlags;\nclass RegionCodeGenTy;\nclass TargetCodeGenInfo;\nstruct OMPTaskDataTy;\nstruct CGCoroData;\n\n/// The kind of evaluation to perform on values of a particular\n/// type.  Basically, is the code in CGExprScalar, CGExprComplex, or\n/// CGExprAgg?\n///\n/// TODO: should vectors maybe be split out into their own thing?\nenum TypeEvaluationKind {\n  TEK_Scalar,\n  TEK_Complex,\n  TEK_Aggregate\n};\n\n#define LIST_SANITIZER_CHECKS                                                  \\\n  SANITIZER_CHECK(AddOverflow, add_overflow, 0)                                \\\n  SANITIZER_CHECK(BuiltinUnreachable, builtin_unreachable, 0)                  \\\n  SANITIZER_CHECK(CFICheckFail, cfi_check_fail, 0)                             \\\n  SANITIZER_CHECK(DivremOverflow, divrem_overflow, 0)                          \\\n  SANITIZER_CHECK(DynamicTypeCacheMiss, dynamic_type_cache_miss, 0)            \\\n  SANITIZER_CHECK(FloatCastOverflow, float_cast_overflow, 0)                   \\\n  SANITIZER_CHECK(FunctionTypeMismatch, function_type_mismatch, 1)             \\\n  SANITIZER_CHECK(ImplicitConversion, implicit_conversion, 0)                  \\\n  SANITIZER_CHECK(InvalidBuiltin, invalid_builtin, 0)                          \\\n  SANITIZER_CHECK(InvalidObjCCast, invalid_objc_cast, 0)                       \\\n  SANITIZER_CHECK(LoadInvalidValue, load_invalid_value, 0)                     \\\n  SANITIZER_CHECK(MissingReturn, missing_return, 0)                            \\\n  SANITIZER_CHECK(MulOverflow, mul_overflow, 0)                                \\\n  SANITIZER_CHECK(NegateOverflow, negate_overflow, 0)                          \\\n  SANITIZER_CHECK(NullabilityArg, nullability_arg, 0)                          \\\n  SANITIZER_CHECK(NullabilityReturn, nullability_return, 1)                    \\\n  SANITIZER_CHECK(NonnullArg, nonnull_arg, 0)                                  \\\n  SANITIZER_CHECK(NonnullReturn, nonnull_return, 1)                            \\\n  SANITIZER_CHECK(OutOfBounds, out_of_bounds, 0)                               \\\n  SANITIZER_CHECK(PointerOverflow, pointer_overflow, 0)                        \\\n  SANITIZER_CHECK(ShiftOutOfBounds, shift_out_of_bounds, 0)                    \\\n  SANITIZER_CHECK(SubOverflow, sub_overflow, 0)                                \\\n  SANITIZER_CHECK(TypeMismatch, type_mismatch, 1)                              \\\n  SANITIZER_CHECK(AlignmentAssumption, alignment_assumption, 0)                \\\n  SANITIZER_CHECK(VLABoundNotPositive, vla_bound_not_positive, 0)\n\nenum SanitizerHandler {\n#define SANITIZER_CHECK(Enum, Name, Version) Enum,\n  LIST_SANITIZER_CHECKS\n#undef SANITIZER_CHECK\n};\n\n/// Helper class with most of the code for saving a value for a\n/// conditional expression cleanup.\nstruct DominatingLLVMValue {\n  typedef llvm::PointerIntPair<llvm::Value*, 1, bool> saved_type;\n\n  /// Answer whether the given value needs extra work to be saved.\n  static bool needsSaving(llvm::Value *value) {\n    // If it's not an instruction, we don't need to save.\n    if (!isa<llvm::Instruction>(value)) return false;\n\n    // If it's an instruction in the entry block, we don't need to save.\n    llvm::BasicBlock *block = cast<llvm::Instruction>(value)->getParent();\n    return (block != &block->getParent()->getEntryBlock());\n  }\n\n  static saved_type save(CodeGenFunction &CGF, llvm::Value *value);\n  static llvm::Value *restore(CodeGenFunction &CGF, saved_type value);\n};\n\n/// A partial specialization of DominatingValue for llvm::Values that\n/// might be llvm::Instructions.\ntemplate <class T> struct DominatingPointer<T,true> : DominatingLLVMValue {\n  typedef T *type;\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return static_cast<T*>(DominatingLLVMValue::restore(CGF, value));\n  }\n};\n\n/// A specialization of DominatingValue for Address.\ntemplate <> struct DominatingValue<Address> {\n  typedef Address type;\n\n  struct saved_type {\n    DominatingLLVMValue::saved_type SavedValue;\n    CharUnits Alignment;\n  };\n\n  static bool needsSaving(type value) {\n    return DominatingLLVMValue::needsSaving(value.getPointer());\n  }\n  static saved_type save(CodeGenFunction &CGF, type value) {\n    return { DominatingLLVMValue::save(CGF, value.getPointer()),\n             value.getAlignment() };\n  }\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return Address(DominatingLLVMValue::restore(CGF, value.SavedValue),\n                   value.Alignment);\n  }\n};\n\n/// A specialization of DominatingValue for RValue.\ntemplate <> struct DominatingValue<RValue> {\n  typedef RValue type;\n  class saved_type {\n    enum Kind { ScalarLiteral, ScalarAddress, AggregateLiteral,\n                AggregateAddress, ComplexAddress };\n\n    llvm::Value *Value;\n    unsigned K : 3;\n    unsigned Align : 29;\n    saved_type(llvm::Value *v, Kind k, unsigned a = 0)\n      : Value(v), K(k), Align(a) {}\n\n  public:\n    static bool needsSaving(RValue value);\n    static saved_type save(CodeGenFunction &CGF, RValue value);\n    RValue restore(CodeGenFunction &CGF);\n\n    // implementations in CGCleanup.cpp\n  };\n\n  static bool needsSaving(type value) {\n    return saved_type::needsSaving(value);\n  }\n  static saved_type save(CodeGenFunction &CGF, type value) {\n    return saved_type::save(CGF, value);\n  }\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return value.restore(CGF);\n  }\n};\n\n/// CodeGenFunction - This class organizes the per-function state that is used\n/// while generating LLVM code.\nclass CodeGenFunction : public CodeGenTypeCache {\n  CodeGenFunction(const CodeGenFunction &) = delete;\n  void operator=(const CodeGenFunction &) = delete;\n\n  friend class CGCXXABI;\npublic:\n  /// A jump destination is an abstract label, branching to which may\n  /// require a jump out through normal cleanups.\n  struct JumpDest {\n    JumpDest() : Block(nullptr), ScopeDepth(), Index(0) {}\n    JumpDest(llvm::BasicBlock *Block,\n             EHScopeStack::stable_iterator Depth,\n             unsigned Index)\n      : Block(Block), ScopeDepth(Depth), Index(Index) {}\n\n    bool isValid() const { return Block != nullptr; }\n    llvm::BasicBlock *getBlock() const { return Block; }\n    EHScopeStack::stable_iterator getScopeDepth() const { return ScopeDepth; }\n    unsigned getDestIndex() const { return Index; }\n\n    // This should be used cautiously.\n    void setScopeDepth(EHScopeStack::stable_iterator depth) {\n      ScopeDepth = depth;\n    }\n\n  private:\n    llvm::BasicBlock *Block;\n    EHScopeStack::stable_iterator ScopeDepth;\n    unsigned Index;\n  };\n\n  CodeGenModule &CGM;  // Per-module state.\n  const TargetInfo &Target;\n\n  // For EH/SEH outlined funclets, this field points to parent's CGF\n  CodeGenFunction *ParentCGF = nullptr;\n\n  typedef std::pair<llvm::Value *, llvm::Value *> ComplexPairTy;\n  LoopInfoStack LoopStack;\n  CGBuilderTy Builder;\n\n  // Stores variables for which we can't generate correct lifetime markers\n  // because of jumps.\n  VarBypassDetector Bypasses;\n\n  /// List of recently emitted OMPCanonicalLoops.\n  ///\n  /// Since OMPCanonicalLoops are nested inside other statements (in particular\n  /// CapturedStmt generated by OMPExecutableDirective and non-perfectly nested\n  /// loops), we cannot directly call OMPEmitOMPCanonicalLoop and receive its\n  /// llvm::CanonicalLoopInfo. Instead, we call EmitStmt and any\n  /// OMPEmitOMPCanonicalLoop called by it will add its CanonicalLoopInfo to\n  /// this stack when done. Entering a new loop requires clearing this list; it\n  /// either means we start parsing a new loop nest (in which case the previous\n  /// loop nest goes out of scope) or a second loop in the same level in which\n  /// case it would be ambiguous into which of the two (or more) loops the loop\n  /// nest would extend.\n  SmallVector<llvm::CanonicalLoopInfo *, 4> OMPLoopNestStack;\n\n  // CodeGen lambda for loops and support for ordered clause\n  typedef llvm::function_ref<void(CodeGenFunction &, const OMPLoopDirective &,\n                                  JumpDest)>\n      CodeGenLoopTy;\n  typedef llvm::function_ref<void(CodeGenFunction &, SourceLocation,\n                                  const unsigned, const bool)>\n      CodeGenOrderedTy;\n\n  // Codegen lambda for loop bounds in worksharing loop constructs\n  typedef llvm::function_ref<std::pair<LValue, LValue>(\n      CodeGenFunction &, const OMPExecutableDirective &S)>\n      CodeGenLoopBoundsTy;\n\n  // Codegen lambda for loop bounds in dispatch-based loop implementation\n  typedef llvm::function_ref<std::pair<llvm::Value *, llvm::Value *>(\n      CodeGenFunction &, const OMPExecutableDirective &S, Address LB,\n      Address UB)>\n      CodeGenDispatchBoundsTy;\n\n  /// CGBuilder insert helper. This function is called after an\n  /// instruction is created using Builder.\n  void InsertHelper(llvm::Instruction *I, const llvm::Twine &Name,\n                    llvm::BasicBlock *BB,\n                    llvm::BasicBlock::iterator InsertPt) const;\n\n  /// CurFuncDecl - Holds the Decl for the current outermost\n  /// non-closure context.\n  const Decl *CurFuncDecl;\n  /// CurCodeDecl - This is the inner-most code context, which includes blocks.\n  const Decl *CurCodeDecl;\n  const CGFunctionInfo *CurFnInfo;\n  QualType FnRetTy;\n  llvm::Function *CurFn = nullptr;\n\n  // Holds coroutine data if the current function is a coroutine. We use a\n  // wrapper to manage its lifetime, so that we don't have to define CGCoroData\n  // in this header.\n  struct CGCoroInfo {\n    std::unique_ptr<CGCoroData> Data;\n    CGCoroInfo();\n    ~CGCoroInfo();\n  };\n  CGCoroInfo CurCoro;\n\n  bool isCoroutine() const {\n    return CurCoro.Data != nullptr;\n  }\n\n  /// CurGD - The GlobalDecl for the current function being compiled.\n  GlobalDecl CurGD;\n\n  /// PrologueCleanupDepth - The cleanup depth enclosing all the\n  /// cleanups associated with the parameters.\n  EHScopeStack::stable_iterator PrologueCleanupDepth;\n\n  /// ReturnBlock - Unified return block.\n  JumpDest ReturnBlock;\n\n  /// ReturnValue - The temporary alloca to hold the return\n  /// value. This is invalid iff the function has no return value.\n  Address ReturnValue = Address::invalid();\n\n  /// ReturnValuePointer - The temporary alloca to hold a pointer to sret.\n  /// This is invalid if sret is not in use.\n  Address ReturnValuePointer = Address::invalid();\n\n  /// If a return statement is being visited, this holds the return statment's\n  /// result expression.\n  const Expr *RetExpr = nullptr;\n\n  /// Return true if a label was seen in the current scope.\n  bool hasLabelBeenSeenInCurrentScope() const {\n    if (CurLexicalScope)\n      return CurLexicalScope->hasLabels();\n    return !LabelMap.empty();\n  }\n\n  /// AllocaInsertPoint - This is an instruction in the entry block before which\n  /// we prefer to insert allocas.\n  llvm::AssertingVH<llvm::Instruction> AllocaInsertPt;\n\n  /// API for captured statement code generation.\n  class CGCapturedStmtInfo {\n  public:\n    explicit CGCapturedStmtInfo(CapturedRegionKind K = CR_Default)\n        : Kind(K), ThisValue(nullptr), CXXThisFieldDecl(nullptr) {}\n    explicit CGCapturedStmtInfo(const CapturedStmt &S,\n                                CapturedRegionKind K = CR_Default)\n      : Kind(K), ThisValue(nullptr), CXXThisFieldDecl(nullptr) {\n\n      RecordDecl::field_iterator Field =\n        S.getCapturedRecordDecl()->field_begin();\n      for (CapturedStmt::const_capture_iterator I = S.capture_begin(),\n                                                E = S.capture_end();\n           I != E; ++I, ++Field) {\n        if (I->capturesThis())\n          CXXThisFieldDecl = *Field;\n        else if (I->capturesVariable())\n          CaptureFields[I->getCapturedVar()->getCanonicalDecl()] = *Field;\n        else if (I->capturesVariableByCopy())\n          CaptureFields[I->getCapturedVar()->getCanonicalDecl()] = *Field;\n      }\n    }\n\n    virtual ~CGCapturedStmtInfo();\n\n    CapturedRegionKind getKind() const { return Kind; }\n\n    virtual void setContextValue(llvm::Value *V) { ThisValue = V; }\n    // Retrieve the value of the context parameter.\n    virtual llvm::Value *getContextValue() const { return ThisValue; }\n\n    /// Lookup the captured field decl for a variable.\n    virtual const FieldDecl *lookup(const VarDecl *VD) const {\n      return CaptureFields.lookup(VD->getCanonicalDecl());\n    }\n\n    bool isCXXThisExprCaptured() const { return getThisFieldDecl() != nullptr; }\n    virtual FieldDecl *getThisFieldDecl() const { return CXXThisFieldDecl; }\n\n    static bool classof(const CGCapturedStmtInfo *) {\n      return true;\n    }\n\n    /// Emit the captured statement body.\n    virtual void EmitBody(CodeGenFunction &CGF, const Stmt *S) {\n      CGF.incrementProfileCounter(S);\n      CGF.EmitStmt(S);\n    }\n\n    /// Get the name of the capture helper.\n    virtual StringRef getHelperName() const { return \"__captured_stmt\"; }\n\n  private:\n    /// The kind of captured statement being generated.\n    CapturedRegionKind Kind;\n\n    /// Keep the map between VarDecl and FieldDecl.\n    llvm::SmallDenseMap<const VarDecl *, FieldDecl *> CaptureFields;\n\n    /// The base address of the captured record, passed in as the first\n    /// argument of the parallel region function.\n    llvm::Value *ThisValue;\n\n    /// Captured 'this' type.\n    FieldDecl *CXXThisFieldDecl;\n  };\n  CGCapturedStmtInfo *CapturedStmtInfo = nullptr;\n\n  /// RAII for correct setting/restoring of CapturedStmtInfo.\n  class CGCapturedStmtRAII {\n  private:\n    CodeGenFunction &CGF;\n    CGCapturedStmtInfo *PrevCapturedStmtInfo;\n  public:\n    CGCapturedStmtRAII(CodeGenFunction &CGF,\n                       CGCapturedStmtInfo *NewCapturedStmtInfo)\n        : CGF(CGF), PrevCapturedStmtInfo(CGF.CapturedStmtInfo) {\n      CGF.CapturedStmtInfo = NewCapturedStmtInfo;\n    }\n    ~CGCapturedStmtRAII() { CGF.CapturedStmtInfo = PrevCapturedStmtInfo; }\n  };\n\n  /// An abstract representation of regular/ObjC call/message targets.\n  class AbstractCallee {\n    /// The function declaration of the callee.\n    const Decl *CalleeDecl;\n\n  public:\n    AbstractCallee() : CalleeDecl(nullptr) {}\n    AbstractCallee(const FunctionDecl *FD) : CalleeDecl(FD) {}\n    AbstractCallee(const ObjCMethodDecl *OMD) : CalleeDecl(OMD) {}\n    bool hasFunctionDecl() const {\n      return dyn_cast_or_null<FunctionDecl>(CalleeDecl);\n    }\n    const Decl *getDecl() const { return CalleeDecl; }\n    unsigned getNumParams() const {\n      if (const auto *FD = dyn_cast<FunctionDecl>(CalleeDecl))\n        return FD->getNumParams();\n      return cast<ObjCMethodDecl>(CalleeDecl)->param_size();\n    }\n    const ParmVarDecl *getParamDecl(unsigned I) const {\n      if (const auto *FD = dyn_cast<FunctionDecl>(CalleeDecl))\n        return FD->getParamDecl(I);\n      return *(cast<ObjCMethodDecl>(CalleeDecl)->param_begin() + I);\n    }\n  };\n\n  /// Sanitizers enabled for this function.\n  SanitizerSet SanOpts;\n\n  /// True if CodeGen currently emits code implementing sanitizer checks.\n  bool IsSanitizerScope = false;\n\n  /// RAII object to set/unset CodeGenFunction::IsSanitizerScope.\n  class SanitizerScope {\n    CodeGenFunction *CGF;\n  public:\n    SanitizerScope(CodeGenFunction *CGF);\n    ~SanitizerScope();\n  };\n\n  /// In C++, whether we are code generating a thunk.  This controls whether we\n  /// should emit cleanups.\n  bool CurFuncIsThunk = false;\n\n  /// In ARC, whether we should autorelease the return value.\n  bool AutoreleaseResult = false;\n\n  /// Whether we processed a Microsoft-style asm block during CodeGen. These can\n  /// potentially set the return value.\n  bool SawAsmBlock = false;\n\n  const NamedDecl *CurSEHParent = nullptr;\n\n  /// True if the current function is an outlined SEH helper. This can be a\n  /// finally block or filter expression.\n  bool IsOutlinedSEHHelper = false;\n\n  /// True if CodeGen currently emits code inside presereved access index\n  /// region.\n  bool IsInPreservedAIRegion = false;\n\n  /// True if the current statement has nomerge attribute.\n  bool InNoMergeAttributedStmt = false;\n\n  /// True if the current function should be marked mustprogress.\n  bool FnIsMustProgress = false;\n\n  /// True if the C++ Standard Requires Progress.\n  bool CPlusPlusWithProgress() {\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Never)\n      return false;\n\n    return getLangOpts().CPlusPlus11 || getLangOpts().CPlusPlus14 ||\n           getLangOpts().CPlusPlus17 || getLangOpts().CPlusPlus20;\n  }\n\n  /// True if the C Standard Requires Progress.\n  bool CWithProgress() {\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Always)\n      return true;\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Never)\n      return false;\n\n    return getLangOpts().C11 || getLangOpts().C17 || getLangOpts().C2x;\n  }\n\n  /// True if the language standard requires progress in functions or\n  /// in infinite loops with non-constant conditionals.\n  bool LanguageRequiresProgress() {\n    return CWithProgress() || CPlusPlusWithProgress();\n  }\n\n  const CodeGen::CGBlockInfo *BlockInfo = nullptr;\n  llvm::Value *BlockPointer = nullptr;\n\n  llvm::DenseMap<const VarDecl *, FieldDecl *> LambdaCaptureFields;\n  FieldDecl *LambdaThisCaptureField = nullptr;\n\n  /// A mapping from NRVO variables to the flags used to indicate\n  /// when the NRVO has been applied to this variable.\n  llvm::DenseMap<const VarDecl *, llvm::Value *> NRVOFlags;\n\n  EHScopeStack EHStack;\n  llvm::SmallVector<char, 256> LifetimeExtendedCleanupStack;\n  llvm::SmallVector<const JumpDest *, 2> SEHTryEpilogueStack;\n\n  llvm::Instruction *CurrentFuncletPad = nullptr;\n\n  class CallLifetimeEnd final : public EHScopeStack::Cleanup {\n    llvm::Value *Addr;\n    llvm::Value *Size;\n\n  public:\n    CallLifetimeEnd(Address addr, llvm::Value *size)\n        : Addr(addr.getPointer()), Size(size) {}\n\n    void Emit(CodeGenFunction &CGF, Flags flags) override {\n      CGF.EmitLifetimeEnd(Size, Addr);\n    }\n  };\n\n  /// Header for data within LifetimeExtendedCleanupStack.\n  struct LifetimeExtendedCleanupHeader {\n    /// The size of the following cleanup object.\n    unsigned Size;\n    /// The kind of cleanup to push: a value from the CleanupKind enumeration.\n    unsigned Kind : 31;\n    /// Whether this is a conditional cleanup.\n    unsigned IsConditional : 1;\n\n    size_t getSize() const { return Size; }\n    CleanupKind getKind() const { return (CleanupKind)Kind; }\n    bool isConditional() const { return IsConditional; }\n  };\n\n  /// i32s containing the indexes of the cleanup destinations.\n  Address NormalCleanupDest = Address::invalid();\n\n  unsigned NextCleanupDestIndex = 1;\n\n  /// EHResumeBlock - Unified block containing a call to llvm.eh.resume.\n  llvm::BasicBlock *EHResumeBlock = nullptr;\n\n  /// The exception slot.  All landing pads write the current exception pointer\n  /// into this alloca.\n  llvm::Value *ExceptionSlot = nullptr;\n\n  /// The selector slot.  Under the MandatoryCleanup model, all landing pads\n  /// write the current selector value into this alloca.\n  llvm::AllocaInst *EHSelectorSlot = nullptr;\n\n  /// A stack of exception code slots. Entering an __except block pushes a slot\n  /// on the stack and leaving pops one. The __exception_code() intrinsic loads\n  /// a value from the top of the stack.\n  SmallVector<Address, 1> SEHCodeSlotStack;\n\n  /// Value returned by __exception_info intrinsic.\n  llvm::Value *SEHInfo = nullptr;\n\n  /// Emits a landing pad for the current EH stack.\n  llvm::BasicBlock *EmitLandingPad();\n\n  llvm::BasicBlock *getInvokeDestImpl();\n\n  /// Parent loop-based directive for scan directive.\n  const OMPExecutableDirective *OMPParentLoopDirectiveForScan = nullptr;\n  llvm::BasicBlock *OMPBeforeScanBlock = nullptr;\n  llvm::BasicBlock *OMPAfterScanBlock = nullptr;\n  llvm::BasicBlock *OMPScanExitBlock = nullptr;\n  llvm::BasicBlock *OMPScanDispatch = nullptr;\n  bool OMPFirstScanLoop = false;\n\n  /// Manages parent directive for scan directives.\n  class ParentLoopDirectiveForScanRegion {\n    CodeGenFunction &CGF;\n    const OMPExecutableDirective *ParentLoopDirectiveForScan;\n\n  public:\n    ParentLoopDirectiveForScanRegion(\n        CodeGenFunction &CGF,\n        const OMPExecutableDirective &ParentLoopDirectiveForScan)\n        : CGF(CGF),\n          ParentLoopDirectiveForScan(CGF.OMPParentLoopDirectiveForScan) {\n      CGF.OMPParentLoopDirectiveForScan = &ParentLoopDirectiveForScan;\n    }\n    ~ParentLoopDirectiveForScanRegion() {\n      CGF.OMPParentLoopDirectiveForScan = ParentLoopDirectiveForScan;\n    }\n  };\n\n  template <class T>\n  typename DominatingValue<T>::saved_type saveValueInCond(T value) {\n    return DominatingValue<T>::save(*this, value);\n  }\n\n  class CGFPOptionsRAII {\n  public:\n    CGFPOptionsRAII(CodeGenFunction &CGF, FPOptions FPFeatures);\n    CGFPOptionsRAII(CodeGenFunction &CGF, const Expr *E);\n    ~CGFPOptionsRAII();\n\n  private:\n    void ConstructorHelper(FPOptions FPFeatures);\n    CodeGenFunction &CGF;\n    FPOptions OldFPFeatures;\n    llvm::fp::ExceptionBehavior OldExcept;\n    llvm::RoundingMode OldRounding;\n    Optional<CGBuilderTy::FastMathFlagGuard> FMFGuard;\n  };\n  FPOptions CurFPFeatures;\n\npublic:\n  /// ObjCEHValueStack - Stack of Objective-C exception values, used for\n  /// rethrows.\n  SmallVector<llvm::Value*, 8> ObjCEHValueStack;\n\n  /// A class controlling the emission of a finally block.\n  class FinallyInfo {\n    /// Where the catchall's edge through the cleanup should go.\n    JumpDest RethrowDest;\n\n    /// A function to call to enter the catch.\n    llvm::FunctionCallee BeginCatchFn;\n\n    /// An i1 variable indicating whether or not the @finally is\n    /// running for an exception.\n    llvm::AllocaInst *ForEHVar;\n\n    /// An i8* variable into which the exception pointer to rethrow\n    /// has been saved.\n    llvm::AllocaInst *SavedExnVar;\n\n  public:\n    void enter(CodeGenFunction &CGF, const Stmt *Finally,\n               llvm::FunctionCallee beginCatchFn,\n               llvm::FunctionCallee endCatchFn, llvm::FunctionCallee rethrowFn);\n    void exit(CodeGenFunction &CGF);\n  };\n\n  /// Returns true inside SEH __try blocks.\n  bool isSEHTryScope() const { return !SEHTryEpilogueStack.empty(); }\n\n  /// Returns true while emitting a cleanuppad.\n  bool isCleanupPadScope() const {\n    return CurrentFuncletPad && isa<llvm::CleanupPadInst>(CurrentFuncletPad);\n  }\n\n  /// pushFullExprCleanup - Push a cleanup to be run at the end of the\n  /// current full-expression.  Safe against the possibility that\n  /// we're currently inside a conditionally-evaluated expression.\n  template <class T, class... As>\n  void pushFullExprCleanup(CleanupKind kind, As... A) {\n    // If we're not in a conditional branch, or if none of the\n    // arguments requires saving, then use the unconditional cleanup.\n    if (!isInConditionalBranch())\n      return EHStack.pushCleanup<T>(kind, A...);\n\n    // Stash values in a tuple so we can guarantee the order of saves.\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved{saveValueInCond(A)...};\n\n    typedef EHScopeStack::ConditionalCleanup<T, As...> CleanupType;\n    EHStack.pushCleanupTuple<CleanupType>(kind, Saved);\n    initFullExprCleanup();\n  }\n\n  /// Queue a cleanup to be pushed after finishing the current full-expression,\n  /// potentially with an active flag.\n  template <class T, class... As>\n  void pushCleanupAfterFullExpr(CleanupKind Kind, As... A) {\n    if (!isInConditionalBranch())\n      return pushCleanupAfterFullExprWithActiveFlag<T>(Kind, Address::invalid(),\n                                                       A...);\n\n    Address ActiveFlag = createCleanupActiveFlag();\n    assert(!DominatingValue<Address>::needsSaving(ActiveFlag) &&\n           \"cleanup active flag should never need saving\");\n\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved{saveValueInCond(A)...};\n\n    typedef EHScopeStack::ConditionalCleanup<T, As...> CleanupType;\n    pushCleanupAfterFullExprWithActiveFlag<CleanupType>(Kind, ActiveFlag, Saved);\n  }\n\n  template <class T, class... As>\n  void pushCleanupAfterFullExprWithActiveFlag(CleanupKind Kind,\n                                              Address ActiveFlag, As... A) {\n    LifetimeExtendedCleanupHeader Header = {sizeof(T), Kind,\n                                            ActiveFlag.isValid()};\n\n    size_t OldSize = LifetimeExtendedCleanupStack.size();\n    LifetimeExtendedCleanupStack.resize(\n        LifetimeExtendedCleanupStack.size() + sizeof(Header) + Header.Size +\n        (Header.IsConditional ? sizeof(ActiveFlag) : 0));\n\n    static_assert(sizeof(Header) % alignof(T) == 0,\n                  \"Cleanup will be allocated on misaligned address\");\n    char *Buffer = &LifetimeExtendedCleanupStack[OldSize];\n    new (Buffer) LifetimeExtendedCleanupHeader(Header);\n    new (Buffer + sizeof(Header)) T(A...);\n    if (Header.IsConditional)\n      new (Buffer + sizeof(Header) + sizeof(T)) Address(ActiveFlag);\n  }\n\n  /// Set up the last cleanup that was pushed as a conditional\n  /// full-expression cleanup.\n  void initFullExprCleanup() {\n    initFullExprCleanupWithFlag(createCleanupActiveFlag());\n  }\n\n  void initFullExprCleanupWithFlag(Address ActiveFlag);\n  Address createCleanupActiveFlag();\n\n  /// PushDestructorCleanup - Push a cleanup to call the\n  /// complete-object destructor of an object of the given type at the\n  /// given address.  Does nothing if T is not a C++ class type with a\n  /// non-trivial destructor.\n  void PushDestructorCleanup(QualType T, Address Addr);\n\n  /// PushDestructorCleanup - Push a cleanup to call the\n  /// complete-object variant of the given destructor on the object at\n  /// the given address.\n  void PushDestructorCleanup(const CXXDestructorDecl *Dtor, QualType T,\n                             Address Addr);\n\n  /// PopCleanupBlock - Will pop the cleanup entry on the stack and\n  /// process all branch fixups.\n  void PopCleanupBlock(bool FallThroughIsBranchThrough = false);\n\n  /// DeactivateCleanupBlock - Deactivates the given cleanup block.\n  /// The block cannot be reactivated.  Pops it if it's the top of the\n  /// stack.\n  ///\n  /// \\param DominatingIP - An instruction which is known to\n  ///   dominate the current IP (if set) and which lies along\n  ///   all paths of execution between the current IP and the\n  ///   the point at which the cleanup comes into scope.\n  void DeactivateCleanupBlock(EHScopeStack::stable_iterator Cleanup,\n                              llvm::Instruction *DominatingIP);\n\n  /// ActivateCleanupBlock - Activates an initially-inactive cleanup.\n  /// Cannot be used to resurrect a deactivated cleanup.\n  ///\n  /// \\param DominatingIP - An instruction which is known to\n  ///   dominate the current IP (if set) and which lies along\n  ///   all paths of execution between the current IP and the\n  ///   the point at which the cleanup comes into scope.\n  void ActivateCleanupBlock(EHScopeStack::stable_iterator Cleanup,\n                            llvm::Instruction *DominatingIP);\n\n  /// Enters a new scope for capturing cleanups, all of which\n  /// will be executed once the scope is exited.\n  class RunCleanupsScope {\n    EHScopeStack::stable_iterator CleanupStackDepth, OldCleanupScopeDepth;\n    size_t LifetimeExtendedCleanupStackSize;\n    bool OldDidCallStackSave;\n  protected:\n    bool PerformCleanup;\n  private:\n\n    RunCleanupsScope(const RunCleanupsScope &) = delete;\n    void operator=(const RunCleanupsScope &) = delete;\n\n  protected:\n    CodeGenFunction& CGF;\n\n  public:\n    /// Enter a new cleanup scope.\n    explicit RunCleanupsScope(CodeGenFunction &CGF)\n      : PerformCleanup(true), CGF(CGF)\n    {\n      CleanupStackDepth = CGF.EHStack.stable_begin();\n      LifetimeExtendedCleanupStackSize =\n          CGF.LifetimeExtendedCleanupStack.size();\n      OldDidCallStackSave = CGF.DidCallStackSave;\n      CGF.DidCallStackSave = false;\n      OldCleanupScopeDepth = CGF.CurrentCleanupScopeDepth;\n      CGF.CurrentCleanupScopeDepth = CleanupStackDepth;\n    }\n\n    /// Exit this cleanup scope, emitting any accumulated cleanups.\n    ~RunCleanupsScope() {\n      if (PerformCleanup)\n        ForceCleanup();\n    }\n\n    /// Determine whether this scope requires any cleanups.\n    bool requiresCleanups() const {\n      return CGF.EHStack.stable_begin() != CleanupStackDepth;\n    }\n\n    /// Force the emission of cleanups now, instead of waiting\n    /// until this object is destroyed.\n    /// \\param ValuesToReload - A list of values that need to be available at\n    /// the insertion point after cleanup emission. If cleanup emission created\n    /// a shared cleanup block, these value pointers will be rewritten.\n    /// Otherwise, they not will be modified.\n    void ForceCleanup(std::initializer_list<llvm::Value**> ValuesToReload = {}) {\n      assert(PerformCleanup && \"Already forced cleanup\");\n      CGF.DidCallStackSave = OldDidCallStackSave;\n      CGF.PopCleanupBlocks(CleanupStackDepth, LifetimeExtendedCleanupStackSize,\n                           ValuesToReload);\n      PerformCleanup = false;\n      CGF.CurrentCleanupScopeDepth = OldCleanupScopeDepth;\n    }\n  };\n\n  // Cleanup stack depth of the RunCleanupsScope that was pushed most recently.\n  EHScopeStack::stable_iterator CurrentCleanupScopeDepth =\n      EHScopeStack::stable_end();\n\n  class LexicalScope : public RunCleanupsScope {\n    SourceRange Range;\n    SmallVector<const LabelDecl*, 4> Labels;\n    LexicalScope *ParentScope;\n\n    LexicalScope(const LexicalScope &) = delete;\n    void operator=(const LexicalScope &) = delete;\n\n  public:\n    /// Enter a new cleanup scope.\n    explicit LexicalScope(CodeGenFunction &CGF, SourceRange Range)\n      : RunCleanupsScope(CGF), Range(Range), ParentScope(CGF.CurLexicalScope) {\n      CGF.CurLexicalScope = this;\n      if (CGDebugInfo *DI = CGF.getDebugInfo())\n        DI->EmitLexicalBlockStart(CGF.Builder, Range.getBegin());\n    }\n\n    void addLabel(const LabelDecl *label) {\n      assert(PerformCleanup && \"adding label to dead scope?\");\n      Labels.push_back(label);\n    }\n\n    /// Exit this cleanup scope, emitting any accumulated\n    /// cleanups.\n    ~LexicalScope() {\n      if (CGDebugInfo *DI = CGF.getDebugInfo())\n        DI->EmitLexicalBlockEnd(CGF.Builder, Range.getEnd());\n\n      // If we should perform a cleanup, force them now.  Note that\n      // this ends the cleanup scope before rescoping any labels.\n      if (PerformCleanup) {\n        ApplyDebugLocation DL(CGF, Range.getEnd());\n        ForceCleanup();\n      }\n    }\n\n    /// Force the emission of cleanups now, instead of waiting\n    /// until this object is destroyed.\n    void ForceCleanup() {\n      CGF.CurLexicalScope = ParentScope;\n      RunCleanupsScope::ForceCleanup();\n\n      if (!Labels.empty())\n        rescopeLabels();\n    }\n\n    bool hasLabels() const {\n      return !Labels.empty();\n    }\n\n    void rescopeLabels();\n  };\n\n  typedef llvm::DenseMap<const Decl *, Address> DeclMapTy;\n\n  /// The class used to assign some variables some temporarily addresses.\n  class OMPMapVars {\n    DeclMapTy SavedLocals;\n    DeclMapTy SavedTempAddresses;\n    OMPMapVars(const OMPMapVars &) = delete;\n    void operator=(const OMPMapVars &) = delete;\n\n  public:\n    explicit OMPMapVars() = default;\n    ~OMPMapVars() {\n      assert(SavedLocals.empty() && \"Did not restored original addresses.\");\n    };\n\n    /// Sets the address of the variable \\p LocalVD to be \\p TempAddr in\n    /// function \\p CGF.\n    /// \\return true if at least one variable was set already, false otherwise.\n    bool setVarAddr(CodeGenFunction &CGF, const VarDecl *LocalVD,\n                    Address TempAddr) {\n      LocalVD = LocalVD->getCanonicalDecl();\n      // Only save it once.\n      if (SavedLocals.count(LocalVD)) return false;\n\n      // Copy the existing local entry to SavedLocals.\n      auto it = CGF.LocalDeclMap.find(LocalVD);\n      if (it != CGF.LocalDeclMap.end())\n        SavedLocals.try_emplace(LocalVD, it->second);\n      else\n        SavedLocals.try_emplace(LocalVD, Address::invalid());\n\n      // Generate the private entry.\n      QualType VarTy = LocalVD->getType();\n      if (VarTy->isReferenceType()) {\n        Address Temp = CGF.CreateMemTemp(VarTy);\n        CGF.Builder.CreateStore(TempAddr.getPointer(), Temp);\n        TempAddr = Temp;\n      }\n      SavedTempAddresses.try_emplace(LocalVD, TempAddr);\n\n      return true;\n    }\n\n    /// Applies new addresses to the list of the variables.\n    /// \\return true if at least one variable is using new address, false\n    /// otherwise.\n    bool apply(CodeGenFunction &CGF) {\n      copyInto(SavedTempAddresses, CGF.LocalDeclMap);\n      SavedTempAddresses.clear();\n      return !SavedLocals.empty();\n    }\n\n    /// Restores original addresses of the variables.\n    void restore(CodeGenFunction &CGF) {\n      if (!SavedLocals.empty()) {\n        copyInto(SavedLocals, CGF.LocalDeclMap);\n        SavedLocals.clear();\n      }\n    }\n\n  private:\n    /// Copy all the entries in the source map over the corresponding\n    /// entries in the destination, which must exist.\n    static void copyInto(const DeclMapTy &Src, DeclMapTy &Dest) {\n      for (auto &Pair : Src) {\n        if (!Pair.second.isValid()) {\n          Dest.erase(Pair.first);\n          continue;\n        }\n\n        auto I = Dest.find(Pair.first);\n        if (I != Dest.end())\n          I->second = Pair.second;\n        else\n          Dest.insert(Pair);\n      }\n    }\n  };\n\n  /// The scope used to remap some variables as private in the OpenMP loop body\n  /// (or other captured region emitted without outlining), and to restore old\n  /// vars back on exit.\n  class OMPPrivateScope : public RunCleanupsScope {\n    OMPMapVars MappedVars;\n    OMPPrivateScope(const OMPPrivateScope &) = delete;\n    void operator=(const OMPPrivateScope &) = delete;\n\n  public:\n    /// Enter a new OpenMP private scope.\n    explicit OMPPrivateScope(CodeGenFunction &CGF) : RunCleanupsScope(CGF) {}\n\n    /// Registers \\p LocalVD variable as a private and apply \\p PrivateGen\n    /// function for it to generate corresponding private variable. \\p\n    /// PrivateGen returns an address of the generated private variable.\n    /// \\return true if the variable is registered as private, false if it has\n    /// been privatized already.\n    bool addPrivate(const VarDecl *LocalVD,\n                    const llvm::function_ref<Address()> PrivateGen) {\n      assert(PerformCleanup && \"adding private to dead scope\");\n      return MappedVars.setVarAddr(CGF, LocalVD, PrivateGen());\n    }\n\n    /// Privatizes local variables previously registered as private.\n    /// Registration is separate from the actual privatization to allow\n    /// initializers use values of the original variables, not the private one.\n    /// This is important, for example, if the private variable is a class\n    /// variable initialized by a constructor that references other private\n    /// variables. But at initialization original variables must be used, not\n    /// private copies.\n    /// \\return true if at least one variable was privatized, false otherwise.\n    bool Privatize() { return MappedVars.apply(CGF); }\n\n    void ForceCleanup() {\n      RunCleanupsScope::ForceCleanup();\n      MappedVars.restore(CGF);\n    }\n\n    /// Exit scope - all the mapped variables are restored.\n    ~OMPPrivateScope() {\n      if (PerformCleanup)\n        ForceCleanup();\n    }\n\n    /// Checks if the global variable is captured in current function.\n    bool isGlobalVarCaptured(const VarDecl *VD) const {\n      VD = VD->getCanonicalDecl();\n      return !VD->isLocalVarDeclOrParm() && CGF.LocalDeclMap.count(VD) > 0;\n    }\n  };\n\n  /// Save/restore original map of previously emitted local vars in case when we\n  /// need to duplicate emission of the same code several times in the same\n  /// function for OpenMP code.\n  class OMPLocalDeclMapRAII {\n    CodeGenFunction &CGF;\n    DeclMapTy SavedMap;\n\n  public:\n    OMPLocalDeclMapRAII(CodeGenFunction &CGF)\n        : CGF(CGF), SavedMap(CGF.LocalDeclMap) {}\n    ~OMPLocalDeclMapRAII() { SavedMap.swap(CGF.LocalDeclMap); }\n  };\n\n  /// Takes the old cleanup stack size and emits the cleanup blocks\n  /// that have been added.\n  void\n  PopCleanupBlocks(EHScopeStack::stable_iterator OldCleanupStackSize,\n                   std::initializer_list<llvm::Value **> ValuesToReload = {});\n\n  /// Takes the old cleanup stack size and emits the cleanup blocks\n  /// that have been added, then adds all lifetime-extended cleanups from\n  /// the given position to the stack.\n  void\n  PopCleanupBlocks(EHScopeStack::stable_iterator OldCleanupStackSize,\n                   size_t OldLifetimeExtendedStackSize,\n                   std::initializer_list<llvm::Value **> ValuesToReload = {});\n\n  void ResolveBranchFixups(llvm::BasicBlock *Target);\n\n  /// The given basic block lies in the current EH scope, but may be a\n  /// target of a potentially scope-crossing jump; get a stable handle\n  /// to which we can perform this jump later.\n  JumpDest getJumpDestInCurrentScope(llvm::BasicBlock *Target) {\n    return JumpDest(Target,\n                    EHStack.getInnermostNormalCleanup(),\n                    NextCleanupDestIndex++);\n  }\n\n  /// The given basic block lies in the current EH scope, but may be a\n  /// target of a potentially scope-crossing jump; get a stable handle\n  /// to which we can perform this jump later.\n  JumpDest getJumpDestInCurrentScope(StringRef Name = StringRef()) {\n    return getJumpDestInCurrentScope(createBasicBlock(Name));\n  }\n\n  /// EmitBranchThroughCleanup - Emit a branch from the current insert\n  /// block through the normal cleanup handling code (if any) and then\n  /// on to \\arg Dest.\n  void EmitBranchThroughCleanup(JumpDest Dest);\n\n  /// isObviouslyBranchWithoutCleanups - Return true if a branch to the\n  /// specified destination obviously has no cleanups to run.  'false' is always\n  /// a conservatively correct answer for this method.\n  bool isObviouslyBranchWithoutCleanups(JumpDest Dest) const;\n\n  /// popCatchScope - Pops the catch scope at the top of the EHScope\n  /// stack, emitting any required code (other than the catch handlers\n  /// themselves).\n  void popCatchScope();\n\n  llvm::BasicBlock *getEHResumeBlock(bool isCleanup);\n  llvm::BasicBlock *getEHDispatchBlock(EHScopeStack::stable_iterator scope);\n  llvm::BasicBlock *\n  getFuncletEHDispatchBlock(EHScopeStack::stable_iterator scope);\n\n  /// An object to manage conditionally-evaluated expressions.\n  class ConditionalEvaluation {\n    llvm::BasicBlock *StartBB;\n\n  public:\n    ConditionalEvaluation(CodeGenFunction &CGF)\n      : StartBB(CGF.Builder.GetInsertBlock()) {}\n\n    void begin(CodeGenFunction &CGF) {\n      assert(CGF.OutermostConditional != this);\n      if (!CGF.OutermostConditional)\n        CGF.OutermostConditional = this;\n    }\n\n    void end(CodeGenFunction &CGF) {\n      assert(CGF.OutermostConditional != nullptr);\n      if (CGF.OutermostConditional == this)\n        CGF.OutermostConditional = nullptr;\n    }\n\n    /// Returns a block which will be executed prior to each\n    /// evaluation of the conditional code.\n    llvm::BasicBlock *getStartingBlock() const {\n      return StartBB;\n    }\n  };\n\n  /// isInConditionalBranch - Return true if we're currently emitting\n  /// one branch or the other of a conditional expression.\n  bool isInConditionalBranch() const { return OutermostConditional != nullptr; }\n\n  void setBeforeOutermostConditional(llvm::Value *value, Address addr) {\n    assert(isInConditionalBranch());\n    llvm::BasicBlock *block = OutermostConditional->getStartingBlock();\n    auto store = new llvm::StoreInst(value, addr.getPointer(), &block->back());\n    store->setAlignment(addr.getAlignment().getAsAlign());\n  }\n\n  /// An RAII object to record that we're evaluating a statement\n  /// expression.\n  class StmtExprEvaluation {\n    CodeGenFunction &CGF;\n\n    /// We have to save the outermost conditional: cleanups in a\n    /// statement expression aren't conditional just because the\n    /// StmtExpr is.\n    ConditionalEvaluation *SavedOutermostConditional;\n\n  public:\n    StmtExprEvaluation(CodeGenFunction &CGF)\n      : CGF(CGF), SavedOutermostConditional(CGF.OutermostConditional) {\n      CGF.OutermostConditional = nullptr;\n    }\n\n    ~StmtExprEvaluation() {\n      CGF.OutermostConditional = SavedOutermostConditional;\n      CGF.EnsureInsertPoint();\n    }\n  };\n\n  /// An object which temporarily prevents a value from being\n  /// destroyed by aggressive peephole optimizations that assume that\n  /// all uses of a value have been realized in the IR.\n  class PeepholeProtection {\n    llvm::Instruction *Inst;\n    friend class CodeGenFunction;\n\n  public:\n    PeepholeProtection() : Inst(nullptr) {}\n  };\n\n  /// A non-RAII class containing all the information about a bound\n  /// opaque value.  OpaqueValueMapping, below, is a RAII wrapper for\n  /// this which makes individual mappings very simple; using this\n  /// class directly is useful when you have a variable number of\n  /// opaque values or don't want the RAII functionality for some\n  /// reason.\n  class OpaqueValueMappingData {\n    const OpaqueValueExpr *OpaqueValue;\n    bool BoundLValue;\n    CodeGenFunction::PeepholeProtection Protection;\n\n    OpaqueValueMappingData(const OpaqueValueExpr *ov,\n                           bool boundLValue)\n      : OpaqueValue(ov), BoundLValue(boundLValue) {}\n  public:\n    OpaqueValueMappingData() : OpaqueValue(nullptr) {}\n\n    static bool shouldBindAsLValue(const Expr *expr) {\n      // gl-values should be bound as l-values for obvious reasons.\n      // Records should be bound as l-values because IR generation\n      // always keeps them in memory.  Expressions of function type\n      // act exactly like l-values but are formally required to be\n      // r-values in C.\n      return expr->isGLValue() ||\n             expr->getType()->isFunctionType() ||\n             hasAggregateEvaluationKind(expr->getType());\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const Expr *e) {\n      if (shouldBindAsLValue(ov))\n        return bind(CGF, ov, CGF.EmitLValue(e));\n      return bind(CGF, ov, CGF.EmitAnyExpr(e));\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const LValue &lv) {\n      assert(shouldBindAsLValue(ov));\n      CGF.OpaqueLValues.insert(std::make_pair(ov, lv));\n      return OpaqueValueMappingData(ov, true);\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const RValue &rv) {\n      assert(!shouldBindAsLValue(ov));\n      CGF.OpaqueRValues.insert(std::make_pair(ov, rv));\n\n      OpaqueValueMappingData data(ov, false);\n\n      // Work around an extremely aggressive peephole optimization in\n      // EmitScalarConversion which assumes that all other uses of a\n      // value are extant.\n      data.Protection = CGF.protectFromPeepholes(rv);\n\n      return data;\n    }\n\n    bool isValid() const { return OpaqueValue != nullptr; }\n    void clear() { OpaqueValue = nullptr; }\n\n    void unbind(CodeGenFunction &CGF) {\n      assert(OpaqueValue && \"no data to unbind!\");\n\n      if (BoundLValue) {\n        CGF.OpaqueLValues.erase(OpaqueValue);\n      } else {\n        CGF.OpaqueRValues.erase(OpaqueValue);\n        CGF.unprotectFromPeepholes(Protection);\n      }\n    }\n  };\n\n  /// An RAII object to set (and then clear) a mapping for an OpaqueValueExpr.\n  class OpaqueValueMapping {\n    CodeGenFunction &CGF;\n    OpaqueValueMappingData Data;\n\n  public:\n    static bool shouldBindAsLValue(const Expr *expr) {\n      return OpaqueValueMappingData::shouldBindAsLValue(expr);\n    }\n\n    /// Build the opaque value mapping for the given conditional\n    /// operator if it's the GNU ?: extension.  This is a common\n    /// enough pattern that the convenience operator is really\n    /// helpful.\n    ///\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const AbstractConditionalOperator *op) : CGF(CGF) {\n      if (isa<ConditionalOperator>(op))\n        // Leave Data empty.\n        return;\n\n      const BinaryConditionalOperator *e = cast<BinaryConditionalOperator>(op);\n      Data = OpaqueValueMappingData::bind(CGF, e->getOpaqueValue(),\n                                          e->getCommon());\n    }\n\n    /// Build the opaque value mapping for an OpaqueValueExpr whose source\n    /// expression is set to the expression the OVE represents.\n    OpaqueValueMapping(CodeGenFunction &CGF, const OpaqueValueExpr *OV)\n        : CGF(CGF) {\n      if (OV) {\n        assert(OV->getSourceExpr() && \"wrong form of OpaqueValueMapping used \"\n                                      \"for OVE with no source expression\");\n        Data = OpaqueValueMappingData::bind(CGF, OV, OV->getSourceExpr());\n      }\n    }\n\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const OpaqueValueExpr *opaqueValue,\n                       LValue lvalue)\n      : CGF(CGF), Data(OpaqueValueMappingData::bind(CGF, opaqueValue, lvalue)) {\n    }\n\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const OpaqueValueExpr *opaqueValue,\n                       RValue rvalue)\n      : CGF(CGF), Data(OpaqueValueMappingData::bind(CGF, opaqueValue, rvalue)) {\n    }\n\n    void pop() {\n      Data.unbind(CGF);\n      Data.clear();\n    }\n\n    ~OpaqueValueMapping() {\n      if (Data.isValid()) Data.unbind(CGF);\n    }\n  };\n\nprivate:\n  CGDebugInfo *DebugInfo;\n  /// Used to create unique names for artificial VLA size debug info variables.\n  unsigned VLAExprCounter = 0;\n  bool DisableDebugInfo = false;\n\n  /// DidCallStackSave - Whether llvm.stacksave has been called. Used to avoid\n  /// calling llvm.stacksave for multiple VLAs in the same scope.\n  bool DidCallStackSave = false;\n\n  /// IndirectBranch - The first time an indirect goto is seen we create a block\n  /// with an indirect branch.  Every time we see the address of a label taken,\n  /// we add the label to the indirect goto.  Every subsequent indirect goto is\n  /// codegen'd as a jump to the IndirectBranch's basic block.\n  llvm::IndirectBrInst *IndirectBranch = nullptr;\n\n  /// LocalDeclMap - This keeps track of the LLVM allocas or globals for local C\n  /// decls.\n  DeclMapTy LocalDeclMap;\n\n  // Keep track of the cleanups for callee-destructed parameters pushed to the\n  // cleanup stack so that they can be deactivated later.\n  llvm::DenseMap<const ParmVarDecl *, EHScopeStack::stable_iterator>\n      CalleeDestructedParamCleanups;\n\n  /// SizeArguments - If a ParmVarDecl had the pass_object_size attribute, this\n  /// will contain a mapping from said ParmVarDecl to its implicit \"object_size\"\n  /// parameter.\n  llvm::SmallDenseMap<const ParmVarDecl *, const ImplicitParamDecl *, 2>\n      SizeArguments;\n\n  /// Track escaped local variables with auto storage. Used during SEH\n  /// outlining to produce a call to llvm.localescape.\n  llvm::DenseMap<llvm::AllocaInst *, int> EscapedLocals;\n\n  /// LabelMap - This keeps track of the LLVM basic block for each C label.\n  llvm::DenseMap<const LabelDecl*, JumpDest> LabelMap;\n\n  // BreakContinueStack - This keeps track of where break and continue\n  // statements should jump to.\n  struct BreakContinue {\n    BreakContinue(JumpDest Break, JumpDest Continue)\n      : BreakBlock(Break), ContinueBlock(Continue) {}\n\n    JumpDest BreakBlock;\n    JumpDest ContinueBlock;\n  };\n  SmallVector<BreakContinue, 8> BreakContinueStack;\n\n  /// Handles cancellation exit points in OpenMP-related constructs.\n  class OpenMPCancelExitStack {\n    /// Tracks cancellation exit point and join point for cancel-related exit\n    /// and normal exit.\n    struct CancelExit {\n      CancelExit() = default;\n      CancelExit(OpenMPDirectiveKind Kind, JumpDest ExitBlock,\n                 JumpDest ContBlock)\n          : Kind(Kind), ExitBlock(ExitBlock), ContBlock(ContBlock) {}\n      OpenMPDirectiveKind Kind = llvm::omp::OMPD_unknown;\n      /// true if the exit block has been emitted already by the special\n      /// emitExit() call, false if the default codegen is used.\n      bool HasBeenEmitted = false;\n      JumpDest ExitBlock;\n      JumpDest ContBlock;\n    };\n\n    SmallVector<CancelExit, 8> Stack;\n\n  public:\n    OpenMPCancelExitStack() : Stack(1) {}\n    ~OpenMPCancelExitStack() = default;\n    /// Fetches the exit block for the current OpenMP construct.\n    JumpDest getExitBlock() const { return Stack.back().ExitBlock; }\n    /// Emits exit block with special codegen procedure specific for the related\n    /// OpenMP construct + emits code for normal construct cleanup.\n    void emitExit(CodeGenFunction &CGF, OpenMPDirectiveKind Kind,\n                  const llvm::function_ref<void(CodeGenFunction &)> CodeGen) {\n      if (Stack.back().Kind == Kind && getExitBlock().isValid()) {\n        assert(CGF.getOMPCancelDestination(Kind).isValid());\n        assert(CGF.HaveInsertPoint());\n        assert(!Stack.back().HasBeenEmitted);\n        auto IP = CGF.Builder.saveAndClearIP();\n        CGF.EmitBlock(Stack.back().ExitBlock.getBlock());\n        CodeGen(CGF);\n        CGF.EmitBranch(Stack.back().ContBlock.getBlock());\n        CGF.Builder.restoreIP(IP);\n        Stack.back().HasBeenEmitted = true;\n      }\n      CodeGen(CGF);\n    }\n    /// Enter the cancel supporting \\a Kind construct.\n    /// \\param Kind OpenMP directive that supports cancel constructs.\n    /// \\param HasCancel true, if the construct has inner cancel directive,\n    /// false otherwise.\n    void enter(CodeGenFunction &CGF, OpenMPDirectiveKind Kind, bool HasCancel) {\n      Stack.push_back({Kind,\n                       HasCancel ? CGF.getJumpDestInCurrentScope(\"cancel.exit\")\n                                 : JumpDest(),\n                       HasCancel ? CGF.getJumpDestInCurrentScope(\"cancel.cont\")\n                                 : JumpDest()});\n    }\n    /// Emits default exit point for the cancel construct (if the special one\n    /// has not be used) + join point for cancel/normal exits.\n    void exit(CodeGenFunction &CGF) {\n      if (getExitBlock().isValid()) {\n        assert(CGF.getOMPCancelDestination(Stack.back().Kind).isValid());\n        bool HaveIP = CGF.HaveInsertPoint();\n        if (!Stack.back().HasBeenEmitted) {\n          if (HaveIP)\n            CGF.EmitBranchThroughCleanup(Stack.back().ContBlock);\n          CGF.EmitBlock(Stack.back().ExitBlock.getBlock());\n          CGF.EmitBranchThroughCleanup(Stack.back().ContBlock);\n        }\n        CGF.EmitBlock(Stack.back().ContBlock.getBlock());\n        if (!HaveIP) {\n          CGF.Builder.CreateUnreachable();\n          CGF.Builder.ClearInsertionPoint();\n        }\n      }\n      Stack.pop_back();\n    }\n  };\n  OpenMPCancelExitStack OMPCancelStack;\n\n  /// Calculate branch weights for the likelihood attribute\n  llvm::MDNode *createBranchWeights(Stmt::Likelihood LH) const;\n\n  CodeGenPGO PGO;\n\n  /// Calculate branch weights appropriate for PGO data\n  llvm::MDNode *createProfileWeights(uint64_t TrueCount,\n                                     uint64_t FalseCount) const;\n  llvm::MDNode *createProfileWeights(ArrayRef<uint64_t> Weights) const;\n  llvm::MDNode *createProfileWeightsForLoop(const Stmt *Cond,\n                                            uint64_t LoopCount) const;\n\n  /// Calculate the branch weight for PGO data or the likelihood attribute.\n  /// The function tries to get the weight of \\ref createProfileWeightsForLoop.\n  /// If that fails it gets the weight of \\ref createBranchWeights.\n  llvm::MDNode *createProfileOrBranchWeightsForLoop(const Stmt *Cond,\n                                                    uint64_t LoopCount,\n                                                    const Stmt *Body) const;\n\npublic:\n  /// Increment the profiler's counter for the given statement by \\p StepV.\n  /// If \\p StepV is null, the default increment is 1.\n  void incrementProfileCounter(const Stmt *S, llvm::Value *StepV = nullptr) {\n    if (CGM.getCodeGenOpts().hasProfileClangInstr() &&\n        !CurFn->hasFnAttribute(llvm::Attribute::NoProfile))\n      PGO.emitCounterIncrement(Builder, S, StepV);\n    PGO.setCurrentStmt(S);\n  }\n\n  /// Get the profiler's count for the given statement.\n  uint64_t getProfileCount(const Stmt *S) {\n    Optional<uint64_t> Count = PGO.getStmtCount(S);\n    if (!Count.hasValue())\n      return 0;\n    return *Count;\n  }\n\n  /// Set the profiler's current count.\n  void setCurrentProfileCount(uint64_t Count) {\n    PGO.setCurrentRegionCount(Count);\n  }\n\n  /// Get the profiler's current count. This is generally the count for the most\n  /// recently incremented counter.\n  uint64_t getCurrentProfileCount() {\n    return PGO.getCurrentRegionCount();\n  }\n\nprivate:\n\n  /// SwitchInsn - This is nearest current switch instruction. It is null if\n  /// current context is not in a switch.\n  llvm::SwitchInst *SwitchInsn = nullptr;\n  /// The branch weights of SwitchInsn when doing instrumentation based PGO.\n  SmallVector<uint64_t, 16> *SwitchWeights = nullptr;\n\n  /// The likelihood attributes of the SwitchCase.\n  SmallVector<Stmt::Likelihood, 16> *SwitchLikelihood = nullptr;\n\n  /// CaseRangeBlock - This block holds if condition check for last case\n  /// statement range in current switch instruction.\n  llvm::BasicBlock *CaseRangeBlock = nullptr;\n\n  /// OpaqueLValues - Keeps track of the current set of opaque value\n  /// expressions.\n  llvm::DenseMap<const OpaqueValueExpr *, LValue> OpaqueLValues;\n  llvm::DenseMap<const OpaqueValueExpr *, RValue> OpaqueRValues;\n\n  // VLASizeMap - This keeps track of the associated size for each VLA type.\n  // We track this by the size expression rather than the type itself because\n  // in certain situations, like a const qualifier applied to an VLA typedef,\n  // multiple VLA types can share the same size expression.\n  // FIXME: Maybe this could be a stack of maps that is pushed/popped as we\n  // enter/leave scopes.\n  llvm::DenseMap<const Expr*, llvm::Value*> VLASizeMap;\n\n  /// A block containing a single 'unreachable' instruction.  Created\n  /// lazily by getUnreachableBlock().\n  llvm::BasicBlock *UnreachableBlock = nullptr;\n\n  /// Counts of the number return expressions in the function.\n  unsigned NumReturnExprs = 0;\n\n  /// Count the number of simple (constant) return expressions in the function.\n  unsigned NumSimpleReturnExprs = 0;\n\n  /// The last regular (non-return) debug location (breakpoint) in the function.\n  SourceLocation LastStopPoint;\n\npublic:\n  /// Source location information about the default argument or member\n  /// initializer expression we're evaluating, if any.\n  CurrentSourceLocExprScope CurSourceLocExprScope;\n  using SourceLocExprScopeGuard =\n      CurrentSourceLocExprScope::SourceLocExprScopeGuard;\n\n  /// A scope within which we are constructing the fields of an object which\n  /// might use a CXXDefaultInitExpr. This stashes away a 'this' value to use\n  /// if we need to evaluate a CXXDefaultInitExpr within the evaluation.\n  class FieldConstructionScope {\n  public:\n    FieldConstructionScope(CodeGenFunction &CGF, Address This)\n        : CGF(CGF), OldCXXDefaultInitExprThis(CGF.CXXDefaultInitExprThis) {\n      CGF.CXXDefaultInitExprThis = This;\n    }\n    ~FieldConstructionScope() {\n      CGF.CXXDefaultInitExprThis = OldCXXDefaultInitExprThis;\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    Address OldCXXDefaultInitExprThis;\n  };\n\n  /// The scope of a CXXDefaultInitExpr. Within this scope, the value of 'this'\n  /// is overridden to be the object under construction.\n  class CXXDefaultInitExprScope  {\n  public:\n    CXXDefaultInitExprScope(CodeGenFunction &CGF, const CXXDefaultInitExpr *E)\n        : CGF(CGF), OldCXXThisValue(CGF.CXXThisValue),\n          OldCXXThisAlignment(CGF.CXXThisAlignment),\n          SourceLocScope(E, CGF.CurSourceLocExprScope) {\n      CGF.CXXThisValue = CGF.CXXDefaultInitExprThis.getPointer();\n      CGF.CXXThisAlignment = CGF.CXXDefaultInitExprThis.getAlignment();\n    }\n    ~CXXDefaultInitExprScope() {\n      CGF.CXXThisValue = OldCXXThisValue;\n      CGF.CXXThisAlignment = OldCXXThisAlignment;\n    }\n\n  public:\n    CodeGenFunction &CGF;\n    llvm::Value *OldCXXThisValue;\n    CharUnits OldCXXThisAlignment;\n    SourceLocExprScopeGuard SourceLocScope;\n  };\n\n  struct CXXDefaultArgExprScope : SourceLocExprScopeGuard {\n    CXXDefaultArgExprScope(CodeGenFunction &CGF, const CXXDefaultArgExpr *E)\n        : SourceLocExprScopeGuard(E, CGF.CurSourceLocExprScope) {}\n  };\n\n  /// The scope of an ArrayInitLoopExpr. Within this scope, the value of the\n  /// current loop index is overridden.\n  class ArrayInitLoopExprScope {\n  public:\n    ArrayInitLoopExprScope(CodeGenFunction &CGF, llvm::Value *Index)\n      : CGF(CGF), OldArrayInitIndex(CGF.ArrayInitIndex) {\n      CGF.ArrayInitIndex = Index;\n    }\n    ~ArrayInitLoopExprScope() {\n      CGF.ArrayInitIndex = OldArrayInitIndex;\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    llvm::Value *OldArrayInitIndex;\n  };\n\n  class InlinedInheritingConstructorScope {\n  public:\n    InlinedInheritingConstructorScope(CodeGenFunction &CGF, GlobalDecl GD)\n        : CGF(CGF), OldCurGD(CGF.CurGD), OldCurFuncDecl(CGF.CurFuncDecl),\n          OldCurCodeDecl(CGF.CurCodeDecl),\n          OldCXXABIThisDecl(CGF.CXXABIThisDecl),\n          OldCXXABIThisValue(CGF.CXXABIThisValue),\n          OldCXXThisValue(CGF.CXXThisValue),\n          OldCXXABIThisAlignment(CGF.CXXABIThisAlignment),\n          OldCXXThisAlignment(CGF.CXXThisAlignment),\n          OldReturnValue(CGF.ReturnValue), OldFnRetTy(CGF.FnRetTy),\n          OldCXXInheritedCtorInitExprArgs(\n              std::move(CGF.CXXInheritedCtorInitExprArgs)) {\n      CGF.CurGD = GD;\n      CGF.CurFuncDecl = CGF.CurCodeDecl =\n          cast<CXXConstructorDecl>(GD.getDecl());\n      CGF.CXXABIThisDecl = nullptr;\n      CGF.CXXABIThisValue = nullptr;\n      CGF.CXXThisValue = nullptr;\n      CGF.CXXABIThisAlignment = CharUnits();\n      CGF.CXXThisAlignment = CharUnits();\n      CGF.ReturnValue = Address::invalid();\n      CGF.FnRetTy = QualType();\n      CGF.CXXInheritedCtorInitExprArgs.clear();\n    }\n    ~InlinedInheritingConstructorScope() {\n      CGF.CurGD = OldCurGD;\n      CGF.CurFuncDecl = OldCurFuncDecl;\n      CGF.CurCodeDecl = OldCurCodeDecl;\n      CGF.CXXABIThisDecl = OldCXXABIThisDecl;\n      CGF.CXXABIThisValue = OldCXXABIThisValue;\n      CGF.CXXThisValue = OldCXXThisValue;\n      CGF.CXXABIThisAlignment = OldCXXABIThisAlignment;\n      CGF.CXXThisAlignment = OldCXXThisAlignment;\n      CGF.ReturnValue = OldReturnValue;\n      CGF.FnRetTy = OldFnRetTy;\n      CGF.CXXInheritedCtorInitExprArgs =\n          std::move(OldCXXInheritedCtorInitExprArgs);\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    GlobalDecl OldCurGD;\n    const Decl *OldCurFuncDecl;\n    const Decl *OldCurCodeDecl;\n    ImplicitParamDecl *OldCXXABIThisDecl;\n    llvm::Value *OldCXXABIThisValue;\n    llvm::Value *OldCXXThisValue;\n    CharUnits OldCXXABIThisAlignment;\n    CharUnits OldCXXThisAlignment;\n    Address OldReturnValue;\n    QualType OldFnRetTy;\n    CallArgList OldCXXInheritedCtorInitExprArgs;\n  };\n\n  // Helper class for the OpenMP IR Builder. Allows reusability of code used for\n  // region body, and finalization codegen callbacks. This will class will also\n  // contain privatization functions used by the privatization call backs\n  //\n  // TODO: this is temporary class for things that are being moved out of\n  // CGOpenMPRuntime, new versions of current CodeGenFunction methods, or\n  // utility function for use with the OMPBuilder. Once that move to use the\n  // OMPBuilder is done, everything here will either become part of CodeGenFunc.\n  // directly, or a new helper class that will contain functions used by both\n  // this and the OMPBuilder\n\n  struct OMPBuilderCBHelpers {\n\n    OMPBuilderCBHelpers() = delete;\n    OMPBuilderCBHelpers(const OMPBuilderCBHelpers &) = delete;\n    OMPBuilderCBHelpers &operator=(const OMPBuilderCBHelpers &) = delete;\n\n    using InsertPointTy = llvm::OpenMPIRBuilder::InsertPointTy;\n\n    /// Cleanup action for allocate support.\n    class OMPAllocateCleanupTy final : public EHScopeStack::Cleanup {\n\n    private:\n      llvm::CallInst *RTLFnCI;\n\n    public:\n      OMPAllocateCleanupTy(llvm::CallInst *RLFnCI) : RTLFnCI(RLFnCI) {\n        RLFnCI->removeFromParent();\n      }\n\n      void Emit(CodeGenFunction &CGF, Flags /*flags*/) override {\n        if (!CGF.HaveInsertPoint())\n          return;\n        CGF.Builder.Insert(RTLFnCI);\n      }\n    };\n\n    /// Returns address of the threadprivate variable for the current\n    /// thread. This Also create any necessary OMP runtime calls.\n    ///\n    /// \\param VD VarDecl for Threadprivate variable.\n    /// \\param VDAddr Address of the Vardecl\n    /// \\param Loc  The location where the barrier directive was encountered\n    static Address getAddrOfThreadPrivate(CodeGenFunction &CGF,\n                                          const VarDecl *VD, Address VDAddr,\n                                          SourceLocation Loc);\n\n    /// Gets the OpenMP-specific address of the local variable /p VD.\n    static Address getAddressOfLocalVariable(CodeGenFunction &CGF,\n                                             const VarDecl *VD);\n    /// Get the platform-specific name separator.\n    /// \\param Parts different parts of the final name that needs separation\n    /// \\param FirstSeparator First separator used between the initial two\n    ///        parts of the name.\n    /// \\param Separator separator used between all of the rest consecutinve\n    ///        parts of the name\n    static std::string getNameWithSeparators(ArrayRef<StringRef> Parts,\n                                             StringRef FirstSeparator = \".\",\n                                             StringRef Separator = \".\");\n    /// Emit the Finalization for an OMP region\n    /// \\param CGF\tThe Codegen function this belongs to\n    /// \\param IP\tInsertion point for generating the finalization code.\n    static void FinalizeOMPRegion(CodeGenFunction &CGF, InsertPointTy IP) {\n      CGBuilderTy::InsertPointGuard IPG(CGF.Builder);\n      assert(IP.getBlock()->end() != IP.getPoint() &&\n             \"OpenMP IR Builder should cause terminated block!\");\n\n      llvm::BasicBlock *IPBB = IP.getBlock();\n      llvm::BasicBlock *DestBB = IPBB->getUniqueSuccessor();\n      assert(DestBB && \"Finalization block should have one successor!\");\n\n      // erase and replace with cleanup branch.\n      IPBB->getTerminator()->eraseFromParent();\n      CGF.Builder.SetInsertPoint(IPBB);\n      CodeGenFunction::JumpDest Dest = CGF.getJumpDestInCurrentScope(DestBB);\n      CGF.EmitBranchThroughCleanup(Dest);\n    }\n\n    /// Emit the body of an OMP region\n    /// \\param CGF\tThe Codegen function this belongs to\n    /// \\param RegionBodyStmt\tThe body statement for the OpenMP region being\n    /// \t\t\t generated\n    /// \\param CodeGenIP\tInsertion point for generating the body code.\n    /// \\param FiniBB\tThe finalization basic block\n    static void EmitOMPRegionBody(CodeGenFunction &CGF,\n                                  const Stmt *RegionBodyStmt,\n                                  InsertPointTy CodeGenIP,\n                                  llvm::BasicBlock &FiniBB) {\n      llvm::BasicBlock *CodeGenIPBB = CodeGenIP.getBlock();\n      if (llvm::Instruction *CodeGenIPBBTI = CodeGenIPBB->getTerminator())\n        CodeGenIPBBTI->eraseFromParent();\n\n      CGF.Builder.SetInsertPoint(CodeGenIPBB);\n\n      CGF.EmitStmt(RegionBodyStmt);\n\n      if (CGF.Builder.saveIP().isSet())\n        CGF.Builder.CreateBr(&FiniBB);\n    }\n\n    /// RAII for preserving necessary info during Outlined region body codegen.\n    class OutlinedRegionBodyRAII {\n\n      llvm::AssertingVH<llvm::Instruction> OldAllocaIP;\n      CodeGenFunction::JumpDest OldReturnBlock;\n      CGBuilderTy::InsertPoint IP;\n      CodeGenFunction &CGF;\n\n    public:\n      OutlinedRegionBodyRAII(CodeGenFunction &cgf, InsertPointTy &AllocaIP,\n                             llvm::BasicBlock &RetBB)\n          : CGF(cgf) {\n        assert(AllocaIP.isSet() &&\n               \"Must specify Insertion point for allocas of outlined function\");\n        OldAllocaIP = CGF.AllocaInsertPt;\n        CGF.AllocaInsertPt = &*AllocaIP.getPoint();\n        IP = CGF.Builder.saveIP();\n\n        OldReturnBlock = CGF.ReturnBlock;\n        CGF.ReturnBlock = CGF.getJumpDestInCurrentScope(&RetBB);\n      }\n\n      ~OutlinedRegionBodyRAII() {\n        CGF.AllocaInsertPt = OldAllocaIP;\n        CGF.ReturnBlock = OldReturnBlock;\n        CGF.Builder.restoreIP(IP);\n      }\n    };\n\n    /// RAII for preserving necessary info during inlined region body codegen.\n    class InlinedRegionBodyRAII {\n\n      llvm::AssertingVH<llvm::Instruction> OldAllocaIP;\n      CodeGenFunction &CGF;\n\n    public:\n      InlinedRegionBodyRAII(CodeGenFunction &cgf, InsertPointTy &AllocaIP,\n                            llvm::BasicBlock &FiniBB)\n          : CGF(cgf) {\n        // Alloca insertion block should be in the entry block of the containing\n        // function so it expects an empty AllocaIP in which case will reuse the\n        // old alloca insertion point, or a new AllocaIP in the same block as\n        // the old one\n        assert((!AllocaIP.isSet() ||\n                CGF.AllocaInsertPt->getParent() == AllocaIP.getBlock()) &&\n               \"Insertion point should be in the entry block of containing \"\n               \"function!\");\n        OldAllocaIP = CGF.AllocaInsertPt;\n        if (AllocaIP.isSet())\n          CGF.AllocaInsertPt = &*AllocaIP.getPoint();\n\n        // TODO: Remove the call, after making sure the counter is not used by\n        //       the EHStack.\n        // Since this is an inlined region, it should not modify the\n        // ReturnBlock, and should reuse the one for the enclosing outlined\n        // region. So, the JumpDest being return by the function is discarded\n        (void)CGF.getJumpDestInCurrentScope(&FiniBB);\n      }\n\n      ~InlinedRegionBodyRAII() { CGF.AllocaInsertPt = OldAllocaIP; }\n    };\n  };\n\nprivate:\n  /// CXXThisDecl - When generating code for a C++ member function,\n  /// this will hold the implicit 'this' declaration.\n  ImplicitParamDecl *CXXABIThisDecl = nullptr;\n  llvm::Value *CXXABIThisValue = nullptr;\n  llvm::Value *CXXThisValue = nullptr;\n  CharUnits CXXABIThisAlignment;\n  CharUnits CXXThisAlignment;\n\n  /// The value of 'this' to use when evaluating CXXDefaultInitExprs within\n  /// this expression.\n  Address CXXDefaultInitExprThis = Address::invalid();\n\n  /// The current array initialization index when evaluating an\n  /// ArrayInitIndexExpr within an ArrayInitLoopExpr.\n  llvm::Value *ArrayInitIndex = nullptr;\n\n  /// The values of function arguments to use when evaluating\n  /// CXXInheritedCtorInitExprs within this context.\n  CallArgList CXXInheritedCtorInitExprArgs;\n\n  /// CXXStructorImplicitParamDecl - When generating code for a constructor or\n  /// destructor, this will hold the implicit argument (e.g. VTT).\n  ImplicitParamDecl *CXXStructorImplicitParamDecl = nullptr;\n  llvm::Value *CXXStructorImplicitParamValue = nullptr;\n\n  /// OutermostConditional - Points to the outermost active\n  /// conditional control.  This is used so that we know if a\n  /// temporary should be destroyed conditionally.\n  ConditionalEvaluation *OutermostConditional = nullptr;\n\n  /// The current lexical scope.\n  LexicalScope *CurLexicalScope = nullptr;\n\n  /// The current source location that should be used for exception\n  /// handling code.\n  SourceLocation CurEHLocation;\n\n  /// BlockByrefInfos - For each __block variable, contains\n  /// information about the layout of the variable.\n  llvm::DenseMap<const ValueDecl *, BlockByrefInfo> BlockByrefInfos;\n\n  /// Used by -fsanitize=nullability-return to determine whether the return\n  /// value can be checked.\n  llvm::Value *RetValNullabilityPrecondition = nullptr;\n\n  /// Check if -fsanitize=nullability-return instrumentation is required for\n  /// this function.\n  bool requiresReturnValueNullabilityCheck() const {\n    return RetValNullabilityPrecondition;\n  }\n\n  /// Used to store precise source locations for return statements by the\n  /// runtime return value checks.\n  Address ReturnLocation = Address::invalid();\n\n  /// Check if the return value of this function requires sanitization.\n  bool requiresReturnValueCheck() const;\n\n  llvm::BasicBlock *TerminateLandingPad = nullptr;\n  llvm::BasicBlock *TerminateHandler = nullptr;\n  llvm::SmallVector<llvm::BasicBlock *, 2> TrapBBs;\n\n  /// Terminate funclets keyed by parent funclet pad.\n  llvm::MapVector<llvm::Value *, llvm::BasicBlock *> TerminateFunclets;\n\n  /// Largest vector width used in ths function. Will be used to create a\n  /// function attribute.\n  unsigned LargestVectorWidth = 0;\n\n  /// True if we need emit the life-time markers.\n  const bool ShouldEmitLifetimeMarkers;\n\n  /// Add OpenCL kernel arg metadata and the kernel attribute metadata to\n  /// the function metadata.\n  void EmitOpenCLKernelMetadata(const FunctionDecl *FD,\n                                llvm::Function *Fn);\n\npublic:\n  CodeGenFunction(CodeGenModule &cgm, bool suppressNewContext=false);\n  ~CodeGenFunction();\n\n  CodeGenTypes &getTypes() const { return CGM.getTypes(); }\n  ASTContext &getContext() const { return CGM.getContext(); }\n  CGDebugInfo *getDebugInfo() {\n    if (DisableDebugInfo)\n      return nullptr;\n    return DebugInfo;\n  }\n  void disableDebugInfo() { DisableDebugInfo = true; }\n  void enableDebugInfo() { DisableDebugInfo = false; }\n\n  bool shouldUseFusedARCCalls() {\n    return CGM.getCodeGenOpts().OptimizationLevel == 0;\n  }\n\n  const LangOptions &getLangOpts() const { return CGM.getLangOpts(); }\n\n  /// Returns a pointer to the function's exception object and selector slot,\n  /// which is assigned in every landing pad.\n  Address getExceptionSlot();\n  Address getEHSelectorSlot();\n\n  /// Returns the contents of the function's exception object and selector\n  /// slots.\n  llvm::Value *getExceptionFromSlot();\n  llvm::Value *getSelectorFromSlot();\n\n  Address getNormalCleanupDestSlot();\n\n  llvm::BasicBlock *getUnreachableBlock() {\n    if (!UnreachableBlock) {\n      UnreachableBlock = createBasicBlock(\"unreachable\");\n      new llvm::UnreachableInst(getLLVMContext(), UnreachableBlock);\n    }\n    return UnreachableBlock;\n  }\n\n  llvm::BasicBlock *getInvokeDest() {\n    if (!EHStack.requiresLandingPad()) return nullptr;\n    return getInvokeDestImpl();\n  }\n\n  bool currentFunctionUsesSEHTry() const { return CurSEHParent != nullptr; }\n\n  const TargetInfo &getTarget() const { return Target; }\n  llvm::LLVMContext &getLLVMContext() { return CGM.getLLVMContext(); }\n  const TargetCodeGenInfo &getTargetHooks() const {\n    return CGM.getTargetCodeGenInfo();\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                                  Cleanups\n  //===--------------------------------------------------------------------===//\n\n  typedef void Destroyer(CodeGenFunction &CGF, Address addr, QualType ty);\n\n  void pushIrregularPartialArrayCleanup(llvm::Value *arrayBegin,\n                                        Address arrayEndPointer,\n                                        QualType elementType,\n                                        CharUnits elementAlignment,\n                                        Destroyer *destroyer);\n  void pushRegularPartialArrayCleanup(llvm::Value *arrayBegin,\n                                      llvm::Value *arrayEnd,\n                                      QualType elementType,\n                                      CharUnits elementAlignment,\n                                      Destroyer *destroyer);\n\n  void pushDestroy(QualType::DestructionKind dtorKind,\n                   Address addr, QualType type);\n  void pushEHDestroy(QualType::DestructionKind dtorKind,\n                     Address addr, QualType type);\n  void pushDestroy(CleanupKind kind, Address addr, QualType type,\n                   Destroyer *destroyer, bool useEHCleanupForArray);\n  void pushLifetimeExtendedDestroy(CleanupKind kind, Address addr,\n                                   QualType type, Destroyer *destroyer,\n                                   bool useEHCleanupForArray);\n  void pushCallObjectDeleteCleanup(const FunctionDecl *OperatorDelete,\n                                   llvm::Value *CompletePtr,\n                                   QualType ElementType);\n  void pushStackRestore(CleanupKind kind, Address SPMem);\n  void emitDestroy(Address addr, QualType type, Destroyer *destroyer,\n                   bool useEHCleanupForArray);\n  llvm::Function *generateDestroyHelper(Address addr, QualType type,\n                                        Destroyer *destroyer,\n                                        bool useEHCleanupForArray,\n                                        const VarDecl *VD);\n  void emitArrayDestroy(llvm::Value *begin, llvm::Value *end,\n                        QualType elementType, CharUnits elementAlign,\n                        Destroyer *destroyer,\n                        bool checkZeroLength, bool useEHCleanup);\n\n  Destroyer *getDestroyer(QualType::DestructionKind destructionKind);\n\n  /// Determines whether an EH cleanup is required to destroy a type\n  /// with the given destruction kind.\n  bool needsEHCleanup(QualType::DestructionKind kind) {\n    switch (kind) {\n    case QualType::DK_none:\n      return false;\n    case QualType::DK_cxx_destructor:\n    case QualType::DK_objc_weak_lifetime:\n    case QualType::DK_nontrivial_c_struct:\n      return getLangOpts().Exceptions;\n    case QualType::DK_objc_strong_lifetime:\n      return getLangOpts().Exceptions &&\n             CGM.getCodeGenOpts().ObjCAutoRefCountExceptions;\n    }\n    llvm_unreachable(\"bad destruction kind\");\n  }\n\n  CleanupKind getCleanupKind(QualType::DestructionKind kind) {\n    return (needsEHCleanup(kind) ? NormalAndEHCleanup : NormalCleanup);\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                                  Objective-C\n  //===--------------------------------------------------------------------===//\n\n  void GenerateObjCMethod(const ObjCMethodDecl *OMD);\n\n  void StartObjCMethod(const ObjCMethodDecl *MD, const ObjCContainerDecl *CD);\n\n  /// GenerateObjCGetter - Synthesize an Objective-C property getter function.\n  void GenerateObjCGetter(ObjCImplementationDecl *IMP,\n                          const ObjCPropertyImplDecl *PID);\n  void generateObjCGetterBody(const ObjCImplementationDecl *classImpl,\n                              const ObjCPropertyImplDecl *propImpl,\n                              const ObjCMethodDecl *GetterMothodDecl,\n                              llvm::Constant *AtomicHelperFn);\n\n  void GenerateObjCCtorDtorMethod(ObjCImplementationDecl *IMP,\n                                  ObjCMethodDecl *MD, bool ctor);\n\n  /// GenerateObjCSetter - Synthesize an Objective-C property setter function\n  /// for the given property.\n  void GenerateObjCSetter(ObjCImplementationDecl *IMP,\n                          const ObjCPropertyImplDecl *PID);\n  void generateObjCSetterBody(const ObjCImplementationDecl *classImpl,\n                              const ObjCPropertyImplDecl *propImpl,\n                              llvm::Constant *AtomicHelperFn);\n\n  //===--------------------------------------------------------------------===//\n  //                                  Block Bits\n  //===--------------------------------------------------------------------===//\n\n  /// Emit block literal.\n  /// \\return an LLVM value which is a pointer to a struct which contains\n  /// information about the block, including the block invoke function, the\n  /// captured variables, etc.\n  llvm::Value *EmitBlockLiteral(const BlockExpr *);\n\n  llvm::Function *GenerateBlockFunction(GlobalDecl GD,\n                                        const CGBlockInfo &Info,\n                                        const DeclMapTy &ldm,\n                                        bool IsLambdaConversionToBlock,\n                                        bool BuildGlobalBlock);\n\n  /// Check if \\p T is a C++ class that has a destructor that can throw.\n  static bool cxxDestructorCanThrow(QualType T);\n\n  llvm::Constant *GenerateCopyHelperFunction(const CGBlockInfo &blockInfo);\n  llvm::Constant *GenerateDestroyHelperFunction(const CGBlockInfo &blockInfo);\n  llvm::Constant *GenerateObjCAtomicSetterCopyHelperFunction(\n                                             const ObjCPropertyImplDecl *PID);\n  llvm::Constant *GenerateObjCAtomicGetterCopyHelperFunction(\n                                             const ObjCPropertyImplDecl *PID);\n  llvm::Value *EmitBlockCopyAndAutorelease(llvm::Value *Block, QualType Ty);\n\n  void BuildBlockRelease(llvm::Value *DeclPtr, BlockFieldFlags flags,\n                         bool CanThrow);\n\n  class AutoVarEmission;\n\n  void emitByrefStructureInit(const AutoVarEmission &emission);\n\n  /// Enter a cleanup to destroy a __block variable.  Note that this\n  /// cleanup should be a no-op if the variable hasn't left the stack\n  /// yet; if a cleanup is required for the variable itself, that needs\n  /// to be done externally.\n  ///\n  /// \\param Kind Cleanup kind.\n  ///\n  /// \\param Addr When \\p LoadBlockVarAddr is false, the address of the __block\n  /// structure that will be passed to _Block_object_dispose. When\n  /// \\p LoadBlockVarAddr is true, the address of the field of the block\n  /// structure that holds the address of the __block structure.\n  ///\n  /// \\param Flags The flag that will be passed to _Block_object_dispose.\n  ///\n  /// \\param LoadBlockVarAddr Indicates whether we need to emit a load from\n  /// \\p Addr to get the address of the __block structure.\n  void enterByrefCleanup(CleanupKind Kind, Address Addr, BlockFieldFlags Flags,\n                         bool LoadBlockVarAddr, bool CanThrow);\n\n  void setBlockContextParameter(const ImplicitParamDecl *D, unsigned argNum,\n                                llvm::Value *ptr);\n\n  Address LoadBlockStruct();\n  Address GetAddrOfBlockDecl(const VarDecl *var);\n\n  /// BuildBlockByrefAddress - Computes the location of the\n  /// data in a variable which is declared as __block.\n  Address emitBlockByrefAddress(Address baseAddr, const VarDecl *V,\n                                bool followForward = true);\n  Address emitBlockByrefAddress(Address baseAddr,\n                                const BlockByrefInfo &info,\n                                bool followForward,\n                                const llvm::Twine &name);\n\n  const BlockByrefInfo &getBlockByrefInfo(const VarDecl *var);\n\n  QualType BuildFunctionArgList(GlobalDecl GD, FunctionArgList &Args);\n\n  void GenerateCode(GlobalDecl GD, llvm::Function *Fn,\n                    const CGFunctionInfo &FnInfo);\n\n  /// Annotate the function with an attribute that disables TSan checking at\n  /// runtime.\n  void markAsIgnoreThreadCheckingAtRuntime(llvm::Function *Fn);\n\n  /// Emit code for the start of a function.\n  /// \\param Loc       The location to be associated with the function.\n  /// \\param StartLoc  The location of the function body.\n  void StartFunction(GlobalDecl GD,\n                     QualType RetTy,\n                     llvm::Function *Fn,\n                     const CGFunctionInfo &FnInfo,\n                     const FunctionArgList &Args,\n                     SourceLocation Loc = SourceLocation(),\n                     SourceLocation StartLoc = SourceLocation());\n\n  static bool IsConstructorDelegationValid(const CXXConstructorDecl *Ctor);\n\n  void EmitConstructorBody(FunctionArgList &Args);\n  void EmitDestructorBody(FunctionArgList &Args);\n  void emitImplicitAssignmentOperatorBody(FunctionArgList &Args);\n  void EmitFunctionBody(const Stmt *Body);\n  void EmitBlockWithFallThrough(llvm::BasicBlock *BB, const Stmt *S);\n\n  void EmitForwardingCallToLambda(const CXXMethodDecl *LambdaCallOperator,\n                                  CallArgList &CallArgs);\n  void EmitLambdaBlockInvokeBody();\n  void EmitLambdaDelegatingInvokeBody(const CXXMethodDecl *MD);\n  void EmitLambdaStaticInvokeBody(const CXXMethodDecl *MD);\n  void EmitLambdaVLACapture(const VariableArrayType *VAT, LValue LV) {\n    EmitStoreThroughLValue(RValue::get(VLASizeMap[VAT->getSizeExpr()]), LV);\n  }\n  void EmitAsanPrologueOrEpilogue(bool Prologue);\n\n  /// Emit the unified return block, trying to avoid its emission when\n  /// possible.\n  /// \\return The debug location of the user written return statement if the\n  /// return block is is avoided.\n  llvm::DebugLoc EmitReturnBlock();\n\n  /// FinishFunction - Complete IR generation of the current function. It is\n  /// legal to call this function even if there is no current insertion point.\n  void FinishFunction(SourceLocation EndLoc=SourceLocation());\n\n  void StartThunk(llvm::Function *Fn, GlobalDecl GD,\n                  const CGFunctionInfo &FnInfo, bool IsUnprototyped);\n\n  void EmitCallAndReturnForThunk(llvm::FunctionCallee Callee,\n                                 const ThunkInfo *Thunk, bool IsUnprototyped);\n\n  void FinishThunk();\n\n  /// Emit a musttail call for a thunk with a potentially adjusted this pointer.\n  void EmitMustTailThunk(GlobalDecl GD, llvm::Value *AdjustedThisPtr,\n                         llvm::FunctionCallee Callee);\n\n  /// Generate a thunk for the given method.\n  void generateThunk(llvm::Function *Fn, const CGFunctionInfo &FnInfo,\n                     GlobalDecl GD, const ThunkInfo &Thunk,\n                     bool IsUnprototyped);\n\n  llvm::Function *GenerateVarArgsThunk(llvm::Function *Fn,\n                                       const CGFunctionInfo &FnInfo,\n                                       GlobalDecl GD, const ThunkInfo &Thunk);\n\n  void EmitCtorPrologue(const CXXConstructorDecl *CD, CXXCtorType Type,\n                        FunctionArgList &Args);\n\n  void EmitInitializerForField(FieldDecl *Field, LValue LHS, Expr *Init);\n\n  /// Struct with all information about dynamic [sub]class needed to set vptr.\n  struct VPtr {\n    BaseSubobject Base;\n    const CXXRecordDecl *NearestVBase;\n    CharUnits OffsetFromNearestVBase;\n    const CXXRecordDecl *VTableClass;\n  };\n\n  /// Initialize the vtable pointer of the given subobject.\n  void InitializeVTablePointer(const VPtr &vptr);\n\n  typedef llvm::SmallVector<VPtr, 4> VPtrsVector;\n\n  typedef llvm::SmallPtrSet<const CXXRecordDecl *, 4> VisitedVirtualBasesSetTy;\n  VPtrsVector getVTablePointers(const CXXRecordDecl *VTableClass);\n\n  void getVTablePointers(BaseSubobject Base, const CXXRecordDecl *NearestVBase,\n                         CharUnits OffsetFromNearestVBase,\n                         bool BaseIsNonVirtualPrimaryBase,\n                         const CXXRecordDecl *VTableClass,\n                         VisitedVirtualBasesSetTy &VBases, VPtrsVector &vptrs);\n\n  void InitializeVTablePointers(const CXXRecordDecl *ClassDecl);\n\n  /// GetVTablePtr - Return the Value of the vtable pointer member pointed\n  /// to by This.\n  llvm::Value *GetVTablePtr(Address This, llvm::Type *VTableTy,\n                            const CXXRecordDecl *VTableClass);\n\n  enum CFITypeCheckKind {\n    CFITCK_VCall,\n    CFITCK_NVCall,\n    CFITCK_DerivedCast,\n    CFITCK_UnrelatedCast,\n    CFITCK_ICall,\n    CFITCK_NVMFCall,\n    CFITCK_VMFCall,\n  };\n\n  /// Derived is the presumed address of an object of type T after a\n  /// cast. If T is a polymorphic class type, emit a check that the virtual\n  /// table for Derived belongs to a class derived from T.\n  void EmitVTablePtrCheckForCast(QualType T, llvm::Value *Derived,\n                                 bool MayBeNull, CFITypeCheckKind TCK,\n                                 SourceLocation Loc);\n\n  /// EmitVTablePtrCheckForCall - Virtual method MD is being called via VTable.\n  /// If vptr CFI is enabled, emit a check that VTable is valid.\n  void EmitVTablePtrCheckForCall(const CXXRecordDecl *RD, llvm::Value *VTable,\n                                 CFITypeCheckKind TCK, SourceLocation Loc);\n\n  /// EmitVTablePtrCheck - Emit a check that VTable is a valid virtual table for\n  /// RD using llvm.type.test.\n  void EmitVTablePtrCheck(const CXXRecordDecl *RD, llvm::Value *VTable,\n                          CFITypeCheckKind TCK, SourceLocation Loc);\n\n  /// If whole-program virtual table optimization is enabled, emit an assumption\n  /// that VTable is a member of RD's type identifier. Or, if vptr CFI is\n  /// enabled, emit a check that VTable is a member of RD's type identifier.\n  void EmitTypeMetadataCodeForVCall(const CXXRecordDecl *RD,\n                                    llvm::Value *VTable, SourceLocation Loc);\n\n  /// Returns whether we should perform a type checked load when loading a\n  /// virtual function for virtual calls to members of RD. This is generally\n  /// true when both vcall CFI and whole-program-vtables are enabled.\n  bool ShouldEmitVTableTypeCheckedLoad(const CXXRecordDecl *RD);\n\n  /// Emit a type checked load from the given vtable.\n  llvm::Value *EmitVTableTypeCheckedLoad(const CXXRecordDecl *RD, llvm::Value *VTable,\n                                         uint64_t VTableByteOffset);\n\n  /// EnterDtorCleanups - Enter the cleanups necessary to complete the\n  /// given phase of destruction for a destructor.  The end result\n  /// should call destructors on members and base classes in reverse\n  /// order of their construction.\n  void EnterDtorCleanups(const CXXDestructorDecl *Dtor, CXXDtorType Type);\n\n  /// ShouldInstrumentFunction - Return true if the current function should be\n  /// instrumented with __cyg_profile_func_* calls\n  bool ShouldInstrumentFunction();\n\n  /// ShouldXRayInstrument - Return true if the current function should be\n  /// instrumented with XRay nop sleds.\n  bool ShouldXRayInstrumentFunction() const;\n\n  /// AlwaysEmitXRayCustomEvents - Return true if we must unconditionally emit\n  /// XRay custom event handling calls.\n  bool AlwaysEmitXRayCustomEvents() const;\n\n  /// AlwaysEmitXRayTypedEvents - Return true if clang must unconditionally emit\n  /// XRay typed event handling calls.\n  bool AlwaysEmitXRayTypedEvents() const;\n\n  /// Encode an address into a form suitable for use in a function prologue.\n  llvm::Constant *EncodeAddrForUseInPrologue(llvm::Function *F,\n                                             llvm::Constant *Addr);\n\n  /// Decode an address used in a function prologue, encoded by \\c\n  /// EncodeAddrForUseInPrologue.\n  llvm::Value *DecodeAddrUsedInPrologue(llvm::Value *F,\n                                        llvm::Value *EncodedAddr);\n\n  /// EmitFunctionProlog - Emit the target specific LLVM code to load the\n  /// arguments for the given function. This is also responsible for naming the\n  /// LLVM function arguments.\n  void EmitFunctionProlog(const CGFunctionInfo &FI,\n                          llvm::Function *Fn,\n                          const FunctionArgList &Args);\n\n  /// EmitFunctionEpilog - Emit the target specific LLVM code to return the\n  /// given temporary.\n  void EmitFunctionEpilog(const CGFunctionInfo &FI, bool EmitRetDbgLoc,\n                          SourceLocation EndLoc);\n\n  /// Emit a test that checks if the return value \\p RV is nonnull.\n  void EmitReturnValueCheck(llvm::Value *RV);\n\n  /// EmitStartEHSpec - Emit the start of the exception spec.\n  void EmitStartEHSpec(const Decl *D);\n\n  /// EmitEndEHSpec - Emit the end of the exception spec.\n  void EmitEndEHSpec(const Decl *D);\n\n  /// getTerminateLandingPad - Return a landing pad that just calls terminate.\n  llvm::BasicBlock *getTerminateLandingPad();\n\n  /// getTerminateLandingPad - Return a cleanup funclet that just calls\n  /// terminate.\n  llvm::BasicBlock *getTerminateFunclet();\n\n  /// getTerminateHandler - Return a handler (not a landing pad, just\n  /// a catch handler) that just calls terminate.  This is used when\n  /// a terminate scope encloses a try.\n  llvm::BasicBlock *getTerminateHandler();\n\n  llvm::Type *ConvertTypeForMem(QualType T);\n  llvm::Type *ConvertType(QualType T);\n  llvm::Type *ConvertType(const TypeDecl *T) {\n    return ConvertType(getContext().getTypeDeclType(T));\n  }\n\n  /// LoadObjCSelf - Load the value of self. This function is only valid while\n  /// generating code for an Objective-C method.\n  llvm::Value *LoadObjCSelf();\n\n  /// TypeOfSelfObject - Return type of object that this self represents.\n  QualType TypeOfSelfObject();\n\n  /// getEvaluationKind - Return the TypeEvaluationKind of QualType \\c T.\n  static TypeEvaluationKind getEvaluationKind(QualType T);\n\n  static bool hasScalarEvaluationKind(QualType T) {\n    return getEvaluationKind(T) == TEK_Scalar;\n  }\n\n  static bool hasAggregateEvaluationKind(QualType T) {\n    return getEvaluationKind(T) == TEK_Aggregate;\n  }\n\n  /// createBasicBlock - Create an LLVM basic block.\n  llvm::BasicBlock *createBasicBlock(const Twine &name = \"\",\n                                     llvm::Function *parent = nullptr,\n                                     llvm::BasicBlock *before = nullptr) {\n    return llvm::BasicBlock::Create(getLLVMContext(), name, parent, before);\n  }\n\n  /// getBasicBlockForLabel - Return the LLVM basicblock that the specified\n  /// label maps to.\n  JumpDest getJumpDestForLabel(const LabelDecl *S);\n\n  /// SimplifyForwardingBlocks - If the given basic block is only a branch to\n  /// another basic block, simplify it. This assumes that no other code could\n  /// potentially reference the basic block.\n  void SimplifyForwardingBlocks(llvm::BasicBlock *BB);\n\n  /// EmitBlock - Emit the given block \\arg BB and set it as the insert point,\n  /// adding a fall-through branch from the current insert block if\n  /// necessary. It is legal to call this function even if there is no current\n  /// insertion point.\n  ///\n  /// IsFinished - If true, indicates that the caller has finished emitting\n  /// branches to the given block and does not expect to emit code into it. This\n  /// means the block can be ignored if it is unreachable.\n  void EmitBlock(llvm::BasicBlock *BB, bool IsFinished=false);\n\n  /// EmitBlockAfterUses - Emit the given block somewhere hopefully\n  /// near its uses, and leave the insertion point in it.\n  void EmitBlockAfterUses(llvm::BasicBlock *BB);\n\n  /// EmitBranch - Emit a branch to the specified basic block from the current\n  /// insert block, taking care to avoid creation of branches from dummy\n  /// blocks. It is legal to call this function even if there is no current\n  /// insertion point.\n  ///\n  /// This function clears the current insertion point. The caller should follow\n  /// calls to this function with calls to Emit*Block prior to generation new\n  /// code.\n  void EmitBranch(llvm::BasicBlock *Block);\n\n  /// HaveInsertPoint - True if an insertion point is defined. If not, this\n  /// indicates that the current code being emitted is unreachable.\n  bool HaveInsertPoint() const {\n    return Builder.GetInsertBlock() != nullptr;\n  }\n\n  /// EnsureInsertPoint - Ensure that an insertion point is defined so that\n  /// emitted IR has a place to go. Note that by definition, if this function\n  /// creates a block then that block is unreachable; callers may do better to\n  /// detect when no insertion point is defined and simply skip IR generation.\n  void EnsureInsertPoint() {\n    if (!HaveInsertPoint())\n      EmitBlock(createBasicBlock());\n  }\n\n  /// ErrorUnsupported - Print out an error that codegen doesn't support the\n  /// specified stmt yet.\n  void ErrorUnsupported(const Stmt *S, const char *Type);\n\n  //===--------------------------------------------------------------------===//\n  //                                  Helpers\n  //===--------------------------------------------------------------------===//\n\n  LValue MakeAddrLValue(Address Addr, QualType T,\n                        AlignmentSource Source = AlignmentSource::Type) {\n    return LValue::MakeAddr(Addr, T, getContext(), LValueBaseInfo(Source),\n                            CGM.getTBAAAccessInfo(T));\n  }\n\n  LValue MakeAddrLValue(Address Addr, QualType T, LValueBaseInfo BaseInfo,\n                        TBAAAccessInfo TBAAInfo) {\n    return LValue::MakeAddr(Addr, T, getContext(), BaseInfo, TBAAInfo);\n  }\n\n  LValue MakeAddrLValue(llvm::Value *V, QualType T, CharUnits Alignment,\n                        AlignmentSource Source = AlignmentSource::Type) {\n    return LValue::MakeAddr(Address(V, Alignment), T, getContext(),\n                            LValueBaseInfo(Source), CGM.getTBAAAccessInfo(T));\n  }\n\n  LValue MakeAddrLValue(llvm::Value *V, QualType T, CharUnits Alignment,\n                        LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo) {\n    return LValue::MakeAddr(Address(V, Alignment), T, getContext(),\n                            BaseInfo, TBAAInfo);\n  }\n\n  LValue MakeNaturalAlignPointeeAddrLValue(llvm::Value *V, QualType T);\n  LValue MakeNaturalAlignAddrLValue(llvm::Value *V, QualType T);\n\n  Address EmitLoadOfReference(LValue RefLVal,\n                              LValueBaseInfo *PointeeBaseInfo = nullptr,\n                              TBAAAccessInfo *PointeeTBAAInfo = nullptr);\n  LValue EmitLoadOfReferenceLValue(LValue RefLVal);\n  LValue EmitLoadOfReferenceLValue(Address RefAddr, QualType RefTy,\n                                   AlignmentSource Source =\n                                       AlignmentSource::Type) {\n    LValue RefLVal = MakeAddrLValue(RefAddr, RefTy, LValueBaseInfo(Source),\n                                    CGM.getTBAAAccessInfo(RefTy));\n    return EmitLoadOfReferenceLValue(RefLVal);\n  }\n\n  Address EmitLoadOfPointer(Address Ptr, const PointerType *PtrTy,\n                            LValueBaseInfo *BaseInfo = nullptr,\n                            TBAAAccessInfo *TBAAInfo = nullptr);\n  LValue EmitLoadOfPointerLValue(Address Ptr, const PointerType *PtrTy);\n\n  /// CreateTempAlloca - This creates an alloca and inserts it into the entry\n  /// block if \\p ArraySize is nullptr, otherwise inserts it at the current\n  /// insertion point of the builder. The caller is responsible for setting an\n  /// appropriate alignment on\n  /// the alloca.\n  ///\n  /// \\p ArraySize is the number of array elements to be allocated if it\n  ///    is not nullptr.\n  ///\n  /// LangAS::Default is the address space of pointers to local variables and\n  /// temporaries, as exposed in the source language. In certain\n  /// configurations, this is not the same as the alloca address space, and a\n  /// cast is needed to lift the pointer from the alloca AS into\n  /// LangAS::Default. This can happen when the target uses a restricted\n  /// address space for the stack but the source language requires\n  /// LangAS::Default to be a generic address space. The latter condition is\n  /// common for most programming languages; OpenCL is an exception in that\n  /// LangAS::Default is the private address space, which naturally maps\n  /// to the stack.\n  ///\n  /// Because the address of a temporary is often exposed to the program in\n  /// various ways, this function will perform the cast. The original alloca\n  /// instruction is returned through \\p Alloca if it is not nullptr.\n  ///\n  /// The cast is not performaed in CreateTempAllocaWithoutCast. This is\n  /// more efficient if the caller knows that the address will not be exposed.\n  llvm::AllocaInst *CreateTempAlloca(llvm::Type *Ty, const Twine &Name = \"tmp\",\n                                     llvm::Value *ArraySize = nullptr);\n  Address CreateTempAlloca(llvm::Type *Ty, CharUnits align,\n                           const Twine &Name = \"tmp\",\n                           llvm::Value *ArraySize = nullptr,\n                           Address *Alloca = nullptr);\n  Address CreateTempAllocaWithoutCast(llvm::Type *Ty, CharUnits align,\n                                      const Twine &Name = \"tmp\",\n                                      llvm::Value *ArraySize = nullptr);\n\n  /// CreateDefaultAlignedTempAlloca - This creates an alloca with the\n  /// default ABI alignment of the given LLVM type.\n  ///\n  /// IMPORTANT NOTE: This is *not* generally the right alignment for\n  /// any given AST type that happens to have been lowered to the\n  /// given IR type.  This should only ever be used for function-local,\n  /// IR-driven manipulations like saving and restoring a value.  Do\n  /// not hand this address off to arbitrary IRGen routines, and especially\n  /// do not pass it as an argument to a function that might expect a\n  /// properly ABI-aligned value.\n  Address CreateDefaultAlignTempAlloca(llvm::Type *Ty,\n                                       const Twine &Name = \"tmp\");\n\n  /// InitTempAlloca - Provide an initial value for the given alloca which\n  /// will be observable at all locations in the function.\n  ///\n  /// The address should be something that was returned from one of\n  /// the CreateTempAlloca or CreateMemTemp routines, and the\n  /// initializer must be valid in the entry block (i.e. it must\n  /// either be a constant or an argument value).\n  void InitTempAlloca(Address Alloca, llvm::Value *Value);\n\n  /// CreateIRTemp - Create a temporary IR object of the given type, with\n  /// appropriate alignment. This routine should only be used when an temporary\n  /// value needs to be stored into an alloca (for example, to avoid explicit\n  /// PHI construction), but the type is the IR type, not the type appropriate\n  /// for storing in memory.\n  ///\n  /// That is, this is exactly equivalent to CreateMemTemp, but calling\n  /// ConvertType instead of ConvertTypeForMem.\n  Address CreateIRTemp(QualType T, const Twine &Name = \"tmp\");\n\n  /// CreateMemTemp - Create a temporary memory object of the given type, with\n  /// appropriate alignmen and cast it to the default address space. Returns\n  /// the original alloca instruction by \\p Alloca if it is not nullptr.\n  Address CreateMemTemp(QualType T, const Twine &Name = \"tmp\",\n                        Address *Alloca = nullptr);\n  Address CreateMemTemp(QualType T, CharUnits Align, const Twine &Name = \"tmp\",\n                        Address *Alloca = nullptr);\n\n  /// CreateMemTemp - Create a temporary memory object of the given type, with\n  /// appropriate alignmen without casting it to the default address space.\n  Address CreateMemTempWithoutCast(QualType T, const Twine &Name = \"tmp\");\n  Address CreateMemTempWithoutCast(QualType T, CharUnits Align,\n                                   const Twine &Name = \"tmp\");\n\n  /// CreateAggTemp - Create a temporary memory object for the given\n  /// aggregate type.\n  AggValueSlot CreateAggTemp(QualType T, const Twine &Name = \"tmp\",\n                             Address *Alloca = nullptr) {\n    return AggValueSlot::forAddr(CreateMemTemp(T, Name, Alloca),\n                                 T.getQualifiers(),\n                                 AggValueSlot::IsNotDestructed,\n                                 AggValueSlot::DoesNotNeedGCBarriers,\n                                 AggValueSlot::IsNotAliased,\n                                 AggValueSlot::DoesNotOverlap);\n  }\n\n  /// Emit a cast to void* in the appropriate address space.\n  llvm::Value *EmitCastToVoidPtr(llvm::Value *value);\n\n  /// EvaluateExprAsBool - Perform the usual unary conversions on the specified\n  /// expression and compare the result against zero, returning an Int1Ty value.\n  llvm::Value *EvaluateExprAsBool(const Expr *E);\n\n  /// EmitIgnoredExpr - Emit an expression in a context which ignores the result.\n  void EmitIgnoredExpr(const Expr *E);\n\n  /// EmitAnyExpr - Emit code to compute the specified expression which can have\n  /// any type.  The result is returned as an RValue struct.  If this is an\n  /// aggregate expression, the aggloc/agglocvolatile arguments indicate where\n  /// the result should be returned.\n  ///\n  /// \\param ignoreResult True if the resulting value isn't used.\n  RValue EmitAnyExpr(const Expr *E,\n                     AggValueSlot aggSlot = AggValueSlot::ignored(),\n                     bool ignoreResult = false);\n\n  // EmitVAListRef - Emit a \"reference\" to a va_list; this is either the address\n  // or the value of the expression, depending on how va_list is defined.\n  Address EmitVAListRef(const Expr *E);\n\n  /// Emit a \"reference\" to a __builtin_ms_va_list; this is\n  /// always the value of the expression, because a __builtin_ms_va_list is a\n  /// pointer to a char.\n  Address EmitMSVAListRef(const Expr *E);\n\n  /// EmitAnyExprToTemp - Similarly to EmitAnyExpr(), however, the result will\n  /// always be accessible even if no aggregate location is provided.\n  RValue EmitAnyExprToTemp(const Expr *E);\n\n  /// EmitAnyExprToMem - Emits the code necessary to evaluate an\n  /// arbitrary expression into the given memory location.\n  void EmitAnyExprToMem(const Expr *E, Address Location,\n                        Qualifiers Quals, bool IsInitializer);\n\n  void EmitAnyExprToExn(const Expr *E, Address Addr);\n\n  /// EmitExprAsInit - Emits the code necessary to initialize a\n  /// location in memory with the given initializer.\n  void EmitExprAsInit(const Expr *init, const ValueDecl *D, LValue lvalue,\n                      bool capturedByInit);\n\n  /// hasVolatileMember - returns true if aggregate type has a volatile\n  /// member.\n  bool hasVolatileMember(QualType T) {\n    if (const RecordType *RT = T->getAs<RecordType>()) {\n      const RecordDecl *RD = cast<RecordDecl>(RT->getDecl());\n      return RD->hasVolatileMember();\n    }\n    return false;\n  }\n\n  /// Determine whether a return value slot may overlap some other object.\n  AggValueSlot::Overlap_t getOverlapForReturnValue() {\n    // FIXME: Assuming no overlap here breaks guaranteed copy elision for base\n    // class subobjects. These cases may need to be revisited depending on the\n    // resolution of the relevant core issue.\n    return AggValueSlot::DoesNotOverlap;\n  }\n\n  /// Determine whether a field initialization may overlap some other object.\n  AggValueSlot::Overlap_t getOverlapForFieldInit(const FieldDecl *FD);\n\n  /// Determine whether a base class initialization may overlap some other\n  /// object.\n  AggValueSlot::Overlap_t getOverlapForBaseInit(const CXXRecordDecl *RD,\n                                                const CXXRecordDecl *BaseRD,\n                                                bool IsVirtual);\n\n  /// Emit an aggregate assignment.\n  void EmitAggregateAssign(LValue Dest, LValue Src, QualType EltTy) {\n    bool IsVolatile = hasVolatileMember(EltTy);\n    EmitAggregateCopy(Dest, Src, EltTy, AggValueSlot::MayOverlap, IsVolatile);\n  }\n\n  void EmitAggregateCopyCtor(LValue Dest, LValue Src,\n                             AggValueSlot::Overlap_t MayOverlap) {\n    EmitAggregateCopy(Dest, Src, Src.getType(), MayOverlap);\n  }\n\n  /// EmitAggregateCopy - Emit an aggregate copy.\n  ///\n  /// \\param isVolatile \\c true iff either the source or the destination is\n  ///        volatile.\n  /// \\param MayOverlap Whether the tail padding of the destination might be\n  ///        occupied by some other object. More efficient code can often be\n  ///        generated if not.\n  void EmitAggregateCopy(LValue Dest, LValue Src, QualType EltTy,\n                         AggValueSlot::Overlap_t MayOverlap,\n                         bool isVolatile = false);\n\n  /// GetAddrOfLocalVar - Return the address of a local variable.\n  Address GetAddrOfLocalVar(const VarDecl *VD) {\n    auto it = LocalDeclMap.find(VD);\n    assert(it != LocalDeclMap.end() &&\n           \"Invalid argument to GetAddrOfLocalVar(), no decl!\");\n    return it->second;\n  }\n\n  /// Given an opaque value expression, return its LValue mapping if it exists,\n  /// otherwise create one.\n  LValue getOrCreateOpaqueLValueMapping(const OpaqueValueExpr *e);\n\n  /// Given an opaque value expression, return its RValue mapping if it exists,\n  /// otherwise create one.\n  RValue getOrCreateOpaqueRValueMapping(const OpaqueValueExpr *e);\n\n  /// Get the index of the current ArrayInitLoopExpr, if any.\n  llvm::Value *getArrayInitIndex() { return ArrayInitIndex; }\n\n  /// getAccessedFieldNo - Given an encoded value and a result number, return\n  /// the input field number being accessed.\n  static unsigned getAccessedFieldNo(unsigned Idx, const llvm::Constant *Elts);\n\n  llvm::BlockAddress *GetAddrOfLabel(const LabelDecl *L);\n  llvm::BasicBlock *GetIndirectGotoBlock();\n\n  /// Check if \\p E is a C++ \"this\" pointer wrapped in value-preserving casts.\n  static bool IsWrappedCXXThis(const Expr *E);\n\n  /// EmitNullInitialization - Generate code to set a value of the given type to\n  /// null, If the type contains data member pointers, they will be initialized\n  /// to -1 in accordance with the Itanium C++ ABI.\n  void EmitNullInitialization(Address DestPtr, QualType Ty);\n\n  /// Emits a call to an LLVM variable-argument intrinsic, either\n  /// \\c llvm.va_start or \\c llvm.va_end.\n  /// \\param ArgValue A reference to the \\c va_list as emitted by either\n  /// \\c EmitVAListRef or \\c EmitMSVAListRef.\n  /// \\param IsStart If \\c true, emits a call to \\c llvm.va_start; otherwise,\n  /// calls \\c llvm.va_end.\n  llvm::Value *EmitVAStartEnd(llvm::Value *ArgValue, bool IsStart);\n\n  /// Generate code to get an argument from the passed in pointer\n  /// and update it accordingly.\n  /// \\param VE The \\c VAArgExpr for which to generate code.\n  /// \\param VAListAddr Receives a reference to the \\c va_list as emitted by\n  /// either \\c EmitVAListRef or \\c EmitMSVAListRef.\n  /// \\returns A pointer to the argument.\n  // FIXME: We should be able to get rid of this method and use the va_arg\n  // instruction in LLVM instead once it works well enough.\n  Address EmitVAArg(VAArgExpr *VE, Address &VAListAddr);\n\n  /// emitArrayLength - Compute the length of an array, even if it's a\n  /// VLA, and drill down to the base element type.\n  llvm::Value *emitArrayLength(const ArrayType *arrayType,\n                               QualType &baseType,\n                               Address &addr);\n\n  /// EmitVLASize - Capture all the sizes for the VLA expressions in\n  /// the given variably-modified type and store them in the VLASizeMap.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitVariablyModifiedType(QualType Ty);\n\n  struct VlaSizePair {\n    llvm::Value *NumElts;\n    QualType Type;\n\n    VlaSizePair(llvm::Value *NE, QualType T) : NumElts(NE), Type(T) {}\n  };\n\n  /// Return the number of elements for a single dimension\n  /// for the given array type.\n  VlaSizePair getVLAElements1D(const VariableArrayType *vla);\n  VlaSizePair getVLAElements1D(QualType vla);\n\n  /// Returns an LLVM value that corresponds to the size,\n  /// in non-variably-sized elements, of a variable length array type,\n  /// plus that largest non-variably-sized element type.  Assumes that\n  /// the type has already been emitted with EmitVariablyModifiedType.\n  VlaSizePair getVLASize(const VariableArrayType *vla);\n  VlaSizePair getVLASize(QualType vla);\n\n  /// LoadCXXThis - Load the value of 'this'. This function is only valid while\n  /// generating code for an C++ member function.\n  llvm::Value *LoadCXXThis() {\n    assert(CXXThisValue && \"no 'this' value for this function\");\n    return CXXThisValue;\n  }\n  Address LoadCXXThisAddress();\n\n  /// LoadCXXVTT - Load the VTT parameter to base constructors/destructors have\n  /// virtual bases.\n  // FIXME: Every place that calls LoadCXXVTT is something\n  // that needs to be abstracted properly.\n  llvm::Value *LoadCXXVTT() {\n    assert(CXXStructorImplicitParamValue && \"no VTT value for this function\");\n    return CXXStructorImplicitParamValue;\n  }\n\n  /// GetAddressOfBaseOfCompleteClass - Convert the given pointer to a\n  /// complete class to the given direct base.\n  Address\n  GetAddressOfDirectBaseInCompleteClass(Address Value,\n                                        const CXXRecordDecl *Derived,\n                                        const CXXRecordDecl *Base,\n                                        bool BaseIsVirtual);\n\n  static bool ShouldNullCheckClassCastValue(const CastExpr *Cast);\n\n  /// GetAddressOfBaseClass - This function will add the necessary delta to the\n  /// load of 'this' and returns address of the base class.\n  Address GetAddressOfBaseClass(Address Value,\n                                const CXXRecordDecl *Derived,\n                                CastExpr::path_const_iterator PathBegin,\n                                CastExpr::path_const_iterator PathEnd,\n                                bool NullCheckValue, SourceLocation Loc);\n\n  Address GetAddressOfDerivedClass(Address Value,\n                                   const CXXRecordDecl *Derived,\n                                   CastExpr::path_const_iterator PathBegin,\n                                   CastExpr::path_const_iterator PathEnd,\n                                   bool NullCheckValue);\n\n  /// GetVTTParameter - Return the VTT parameter that should be passed to a\n  /// base constructor/destructor with virtual bases.\n  /// FIXME: VTTs are Itanium ABI-specific, so the definition should move\n  /// to ItaniumCXXABI.cpp together with all the references to VTT.\n  llvm::Value *GetVTTParameter(GlobalDecl GD, bool ForVirtualBase,\n                               bool Delegating);\n\n  void EmitDelegateCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                      CXXCtorType CtorType,\n                                      const FunctionArgList &Args,\n                                      SourceLocation Loc);\n  // It's important not to confuse this and the previous function. Delegating\n  // constructors are the C++0x feature. The constructor delegate optimization\n  // is used to reduce duplication in the base and complete consturctors where\n  // they are substantially the same.\n  void EmitDelegatingCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                        const FunctionArgList &Args);\n\n  /// Emit a call to an inheriting constructor (that is, one that invokes a\n  /// constructor inherited from a base class) by inlining its definition. This\n  /// is necessary if the ABI does not support forwarding the arguments to the\n  /// base class constructor (because they're variadic or similar).\n  void EmitInlinedInheritingCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                               CXXCtorType CtorType,\n                                               bool ForVirtualBase,\n                                               bool Delegating,\n                                               CallArgList &Args);\n\n  /// Emit a call to a constructor inherited from a base class, passing the\n  /// current constructor's arguments along unmodified (without even making\n  /// a copy).\n  void EmitInheritedCXXConstructorCall(const CXXConstructorDecl *D,\n                                       bool ForVirtualBase, Address This,\n                                       bool InheritedFromVBase,\n                                       const CXXInheritedCtorInitExpr *E);\n\n  void EmitCXXConstructorCall(const CXXConstructorDecl *D, CXXCtorType Type,\n                              bool ForVirtualBase, bool Delegating,\n                              AggValueSlot ThisAVS, const CXXConstructExpr *E);\n\n  void EmitCXXConstructorCall(const CXXConstructorDecl *D, CXXCtorType Type,\n                              bool ForVirtualBase, bool Delegating,\n                              Address This, CallArgList &Args,\n                              AggValueSlot::Overlap_t Overlap,\n                              SourceLocation Loc, bool NewPointerIsChecked);\n\n  /// Emit assumption load for all bases. Requires to be be called only on\n  /// most-derived class and not under construction of the object.\n  void EmitVTableAssumptionLoads(const CXXRecordDecl *ClassDecl, Address This);\n\n  /// Emit assumption that vptr load == global vtable.\n  void EmitVTableAssumptionLoad(const VPtr &vptr, Address This);\n\n  void EmitSynthesizedCXXCopyCtorCall(const CXXConstructorDecl *D,\n                                      Address This, Address Src,\n                                      const CXXConstructExpr *E);\n\n  void EmitCXXAggrConstructorCall(const CXXConstructorDecl *D,\n                                  const ArrayType *ArrayTy,\n                                  Address ArrayPtr,\n                                  const CXXConstructExpr *E,\n                                  bool NewPointerIsChecked,\n                                  bool ZeroInitialization = false);\n\n  void EmitCXXAggrConstructorCall(const CXXConstructorDecl *D,\n                                  llvm::Value *NumElements,\n                                  Address ArrayPtr,\n                                  const CXXConstructExpr *E,\n                                  bool NewPointerIsChecked,\n                                  bool ZeroInitialization = false);\n\n  static Destroyer destroyCXXObject;\n\n  void EmitCXXDestructorCall(const CXXDestructorDecl *D, CXXDtorType Type,\n                             bool ForVirtualBase, bool Delegating, Address This,\n                             QualType ThisTy);\n\n  void EmitNewArrayInitializer(const CXXNewExpr *E, QualType elementType,\n                               llvm::Type *ElementTy, Address NewPtr,\n                               llvm::Value *NumElements,\n                               llvm::Value *AllocSizeWithoutCookie);\n\n  void EmitCXXTemporary(const CXXTemporary *Temporary, QualType TempType,\n                        Address Ptr);\n\n  llvm::Value *EmitLifetimeStart(uint64_t Size, llvm::Value *Addr);\n  void EmitLifetimeEnd(llvm::Value *Size, llvm::Value *Addr);\n\n  llvm::Value *EmitCXXNewExpr(const CXXNewExpr *E);\n  void EmitCXXDeleteExpr(const CXXDeleteExpr *E);\n\n  void EmitDeleteCall(const FunctionDecl *DeleteFD, llvm::Value *Ptr,\n                      QualType DeleteTy, llvm::Value *NumElements = nullptr,\n                      CharUnits CookieSize = CharUnits());\n\n  RValue EmitBuiltinNewDeleteCall(const FunctionProtoType *Type,\n                                  const CallExpr *TheCallExpr, bool IsDelete);\n\n  llvm::Value *EmitCXXTypeidExpr(const CXXTypeidExpr *E);\n  llvm::Value *EmitDynamicCast(Address V, const CXXDynamicCastExpr *DCE);\n  Address EmitCXXUuidofExpr(const CXXUuidofExpr *E);\n\n  /// Situations in which we might emit a check for the suitability of a\n  /// pointer or glvalue. Needs to be kept in sync with ubsan_handlers.cpp in\n  /// compiler-rt.\n  enum TypeCheckKind {\n    /// Checking the operand of a load. Must be suitably sized and aligned.\n    TCK_Load,\n    /// Checking the destination of a store. Must be suitably sized and aligned.\n    TCK_Store,\n    /// Checking the bound value in a reference binding. Must be suitably sized\n    /// and aligned, but is not required to refer to an object (until the\n    /// reference is used), per core issue 453.\n    TCK_ReferenceBinding,\n    /// Checking the object expression in a non-static data member access. Must\n    /// be an object within its lifetime.\n    TCK_MemberAccess,\n    /// Checking the 'this' pointer for a call to a non-static member function.\n    /// Must be an object within its lifetime.\n    TCK_MemberCall,\n    /// Checking the 'this' pointer for a constructor call.\n    TCK_ConstructorCall,\n    /// Checking the operand of a static_cast to a derived pointer type. Must be\n    /// null or an object within its lifetime.\n    TCK_DowncastPointer,\n    /// Checking the operand of a static_cast to a derived reference type. Must\n    /// be an object within its lifetime.\n    TCK_DowncastReference,\n    /// Checking the operand of a cast to a base object. Must be suitably sized\n    /// and aligned.\n    TCK_Upcast,\n    /// Checking the operand of a cast to a virtual base object. Must be an\n    /// object within its lifetime.\n    TCK_UpcastToVirtualBase,\n    /// Checking the value assigned to a _Nonnull pointer. Must not be null.\n    TCK_NonnullAssign,\n    /// Checking the operand of a dynamic_cast or a typeid expression.  Must be\n    /// null or an object within its lifetime.\n    TCK_DynamicOperation\n  };\n\n  /// Determine whether the pointer type check \\p TCK permits null pointers.\n  static bool isNullPointerAllowed(TypeCheckKind TCK);\n\n  /// Determine whether the pointer type check \\p TCK requires a vptr check.\n  static bool isVptrCheckRequired(TypeCheckKind TCK, QualType Ty);\n\n  /// Whether any type-checking sanitizers are enabled. If \\c false,\n  /// calls to EmitTypeCheck can be skipped.\n  bool sanitizePerformTypeCheck() const;\n\n  /// Emit a check that \\p V is the address of storage of the\n  /// appropriate size and alignment for an object of type \\p Type\n  /// (or if ArraySize is provided, for an array of that bound).\n  void EmitTypeCheck(TypeCheckKind TCK, SourceLocation Loc, llvm::Value *V,\n                     QualType Type, CharUnits Alignment = CharUnits::Zero(),\n                     SanitizerSet SkippedChecks = SanitizerSet(),\n                     llvm::Value *ArraySize = nullptr);\n\n  /// Emit a check that \\p Base points into an array object, which\n  /// we can access at index \\p Index. \\p Accessed should be \\c false if we\n  /// this expression is used as an lvalue, for instance in \"&Arr[Idx]\".\n  void EmitBoundsCheck(const Expr *E, const Expr *Base, llvm::Value *Index,\n                       QualType IndexType, bool Accessed);\n\n  llvm::Value *EmitScalarPrePostIncDec(const UnaryOperator *E, LValue LV,\n                                       bool isInc, bool isPre);\n  ComplexPairTy EmitComplexPrePostIncDec(const UnaryOperator *E, LValue LV,\n                                         bool isInc, bool isPre);\n\n  /// Converts Location to a DebugLoc, if debug information is enabled.\n  llvm::DebugLoc SourceLocToDebugLoc(SourceLocation Location);\n\n  /// Get the record field index as represented in debug info.\n  unsigned getDebugInfoFIndex(const RecordDecl *Rec, unsigned FieldIndex);\n\n\n  //===--------------------------------------------------------------------===//\n  //                            Declaration Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitDecl - Emit a declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitDecl(const Decl &D);\n\n  /// EmitVarDecl - Emit a local variable declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitVarDecl(const VarDecl &D);\n\n  void EmitScalarInit(const Expr *init, const ValueDecl *D, LValue lvalue,\n                      bool capturedByInit);\n\n  typedef void SpecialInitFn(CodeGenFunction &Init, const VarDecl &D,\n                             llvm::Value *Address);\n\n  /// Determine whether the given initializer is trivial in the sense\n  /// that it requires no code to be generated.\n  bool isTrivialInitializer(const Expr *Init);\n\n  /// EmitAutoVarDecl - Emit an auto variable declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitAutoVarDecl(const VarDecl &D);\n\n  class AutoVarEmission {\n    friend class CodeGenFunction;\n\n    const VarDecl *Variable;\n\n    /// The address of the alloca for languages with explicit address space\n    /// (e.g. OpenCL) or alloca casted to generic pointer for address space\n    /// agnostic languages (e.g. C++). Invalid if the variable was emitted\n    /// as a global constant.\n    Address Addr;\n\n    llvm::Value *NRVOFlag;\n\n    /// True if the variable is a __block variable that is captured by an\n    /// escaping block.\n    bool IsEscapingByRef;\n\n    /// True if the variable is of aggregate type and has a constant\n    /// initializer.\n    bool IsConstantAggregate;\n\n    /// Non-null if we should use lifetime annotations.\n    llvm::Value *SizeForLifetimeMarkers;\n\n    /// Address with original alloca instruction. Invalid if the variable was\n    /// emitted as a global constant.\n    Address AllocaAddr;\n\n    struct Invalid {};\n    AutoVarEmission(Invalid)\n        : Variable(nullptr), Addr(Address::invalid()),\n          AllocaAddr(Address::invalid()) {}\n\n    AutoVarEmission(const VarDecl &variable)\n        : Variable(&variable), Addr(Address::invalid()), NRVOFlag(nullptr),\n          IsEscapingByRef(false), IsConstantAggregate(false),\n          SizeForLifetimeMarkers(nullptr), AllocaAddr(Address::invalid()) {}\n\n    bool wasEmittedAsGlobal() const { return !Addr.isValid(); }\n\n  public:\n    static AutoVarEmission invalid() { return AutoVarEmission(Invalid()); }\n\n    bool useLifetimeMarkers() const {\n      return SizeForLifetimeMarkers != nullptr;\n    }\n    llvm::Value *getSizeForLifetimeMarkers() const {\n      assert(useLifetimeMarkers());\n      return SizeForLifetimeMarkers;\n    }\n\n    /// Returns the raw, allocated address, which is not necessarily\n    /// the address of the object itself. It is casted to default\n    /// address space for address space agnostic languages.\n    Address getAllocatedAddress() const {\n      return Addr;\n    }\n\n    /// Returns the address for the original alloca instruction.\n    Address getOriginalAllocatedAddress() const { return AllocaAddr; }\n\n    /// Returns the address of the object within this declaration.\n    /// Note that this does not chase the forwarding pointer for\n    /// __block decls.\n    Address getObjectAddress(CodeGenFunction &CGF) const {\n      if (!IsEscapingByRef) return Addr;\n\n      return CGF.emitBlockByrefAddress(Addr, Variable, /*forward*/ false);\n    }\n  };\n  AutoVarEmission EmitAutoVarAlloca(const VarDecl &var);\n  void EmitAutoVarInit(const AutoVarEmission &emission);\n  void EmitAutoVarCleanups(const AutoVarEmission &emission);\n  void emitAutoVarTypeCleanup(const AutoVarEmission &emission,\n                              QualType::DestructionKind dtorKind);\n\n  /// Emits the alloca and debug information for the size expressions for each\n  /// dimension of an array. It registers the association of its (1-dimensional)\n  /// QualTypes and size expression's debug node, so that CGDebugInfo can\n  /// reference this node when creating the DISubrange object to describe the\n  /// array types.\n  void EmitAndRegisterVariableArrayDimensions(CGDebugInfo *DI,\n                                              const VarDecl &D,\n                                              bool EmitDebugInfo);\n\n  void EmitStaticVarDecl(const VarDecl &D,\n                         llvm::GlobalValue::LinkageTypes Linkage);\n\n  class ParamValue {\n    llvm::Value *Value;\n    unsigned Alignment;\n    ParamValue(llvm::Value *V, unsigned A) : Value(V), Alignment(A) {}\n  public:\n    static ParamValue forDirect(llvm::Value *value) {\n      return ParamValue(value, 0);\n    }\n    static ParamValue forIndirect(Address addr) {\n      assert(!addr.getAlignment().isZero());\n      return ParamValue(addr.getPointer(), addr.getAlignment().getQuantity());\n    }\n\n    bool isIndirect() const { return Alignment != 0; }\n    llvm::Value *getAnyValue() const { return Value; }\n\n    llvm::Value *getDirectValue() const {\n      assert(!isIndirect());\n      return Value;\n    }\n\n    Address getIndirectAddress() const {\n      assert(isIndirect());\n      return Address(Value, CharUnits::fromQuantity(Alignment));\n    }\n  };\n\n  /// EmitParmDecl - Emit a ParmVarDecl or an ImplicitParamDecl.\n  void EmitParmDecl(const VarDecl &D, ParamValue Arg, unsigned ArgNo);\n\n  /// protectFromPeepholes - Protect a value that we're intending to\n  /// store to the side, but which will probably be used later, from\n  /// aggressive peepholing optimizations that might delete it.\n  ///\n  /// Pass the result to unprotectFromPeepholes to declare that\n  /// protection is no longer required.\n  ///\n  /// There's no particular reason why this shouldn't apply to\n  /// l-values, it's just that no existing peepholes work on pointers.\n  PeepholeProtection protectFromPeepholes(RValue rvalue);\n  void unprotectFromPeepholes(PeepholeProtection protection);\n\n  void emitAlignmentAssumptionCheck(llvm::Value *Ptr, QualType Ty,\n                                    SourceLocation Loc,\n                                    SourceLocation AssumptionLoc,\n                                    llvm::Value *Alignment,\n                                    llvm::Value *OffsetValue,\n                                    llvm::Value *TheCheck,\n                                    llvm::Instruction *Assumption);\n\n  void emitAlignmentAssumption(llvm::Value *PtrValue, QualType Ty,\n                               SourceLocation Loc, SourceLocation AssumptionLoc,\n                               llvm::Value *Alignment,\n                               llvm::Value *OffsetValue = nullptr);\n\n  void emitAlignmentAssumption(llvm::Value *PtrValue, const Expr *E,\n                               SourceLocation AssumptionLoc,\n                               llvm::Value *Alignment,\n                               llvm::Value *OffsetValue = nullptr);\n\n  //===--------------------------------------------------------------------===//\n  //                             Statement Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitStopPoint - Emit a debug stoppoint if we are emitting debug info.\n  void EmitStopPoint(const Stmt *S);\n\n  /// EmitStmt - Emit the code for the statement \\arg S. It is legal to call\n  /// this function even if there is no current insertion point.\n  ///\n  /// This function may clear the current insertion point; callers should use\n  /// EnsureInsertPoint if they wish to subsequently generate code without first\n  /// calling EmitBlock, EmitBranch, or EmitStmt.\n  void EmitStmt(const Stmt *S, ArrayRef<const Attr *> Attrs = None);\n\n  /// EmitSimpleStmt - Try to emit a \"simple\" statement which does not\n  /// necessarily require an insertion point or debug information; typically\n  /// because the statement amounts to a jump or a container of other\n  /// statements.\n  ///\n  /// \\return True if the statement was handled.\n  bool EmitSimpleStmt(const Stmt *S, ArrayRef<const Attr *> Attrs);\n\n  Address EmitCompoundStmt(const CompoundStmt &S, bool GetLast = false,\n                           AggValueSlot AVS = AggValueSlot::ignored());\n  Address EmitCompoundStmtWithoutScope(const CompoundStmt &S,\n                                       bool GetLast = false,\n                                       AggValueSlot AVS =\n                                                AggValueSlot::ignored());\n\n  /// EmitLabel - Emit the block for the given label. It is legal to call this\n  /// function even if there is no current insertion point.\n  void EmitLabel(const LabelDecl *D); // helper for EmitLabelStmt.\n\n  void EmitLabelStmt(const LabelStmt &S);\n  void EmitAttributedStmt(const AttributedStmt &S);\n  void EmitGotoStmt(const GotoStmt &S);\n  void EmitIndirectGotoStmt(const IndirectGotoStmt &S);\n  void EmitIfStmt(const IfStmt &S);\n\n  void EmitWhileStmt(const WhileStmt &S,\n                     ArrayRef<const Attr *> Attrs = None);\n  void EmitDoStmt(const DoStmt &S, ArrayRef<const Attr *> Attrs = None);\n  void EmitForStmt(const ForStmt &S,\n                   ArrayRef<const Attr *> Attrs = None);\n  void EmitReturnStmt(const ReturnStmt &S);\n  void EmitDeclStmt(const DeclStmt &S);\n  void EmitBreakStmt(const BreakStmt &S);\n  void EmitContinueStmt(const ContinueStmt &S);\n  void EmitSwitchStmt(const SwitchStmt &S);\n  void EmitDefaultStmt(const DefaultStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitCaseStmt(const CaseStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitCaseStmtRange(const CaseStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitAsmStmt(const AsmStmt &S);\n\n  void EmitObjCForCollectionStmt(const ObjCForCollectionStmt &S);\n  void EmitObjCAtTryStmt(const ObjCAtTryStmt &S);\n  void EmitObjCAtThrowStmt(const ObjCAtThrowStmt &S);\n  void EmitObjCAtSynchronizedStmt(const ObjCAtSynchronizedStmt &S);\n  void EmitObjCAutoreleasePoolStmt(const ObjCAutoreleasePoolStmt &S);\n\n  void EmitCoroutineBody(const CoroutineBodyStmt &S);\n  void EmitCoreturnStmt(const CoreturnStmt &S);\n  RValue EmitCoawaitExpr(const CoawaitExpr &E,\n                         AggValueSlot aggSlot = AggValueSlot::ignored(),\n                         bool ignoreResult = false);\n  LValue EmitCoawaitLValue(const CoawaitExpr *E);\n  RValue EmitCoyieldExpr(const CoyieldExpr &E,\n                         AggValueSlot aggSlot = AggValueSlot::ignored(),\n                         bool ignoreResult = false);\n  LValue EmitCoyieldLValue(const CoyieldExpr *E);\n  RValue EmitCoroutineIntrinsic(const CallExpr *E, unsigned int IID);\n\n  void EnterCXXTryStmt(const CXXTryStmt &S, bool IsFnTryBlock = false);\n  void ExitCXXTryStmt(const CXXTryStmt &S, bool IsFnTryBlock = false);\n\n  void EmitCXXTryStmt(const CXXTryStmt &S);\n  void EmitSEHTryStmt(const SEHTryStmt &S);\n  void EmitSEHLeaveStmt(const SEHLeaveStmt &S);\n  void EnterSEHTryStmt(const SEHTryStmt &S);\n  void ExitSEHTryStmt(const SEHTryStmt &S);\n\n  void pushSEHCleanup(CleanupKind kind,\n                      llvm::Function *FinallyFunc);\n  void startOutlinedSEHHelper(CodeGenFunction &ParentCGF, bool IsFilter,\n                              const Stmt *OutlinedStmt);\n\n  llvm::Function *GenerateSEHFilterFunction(CodeGenFunction &ParentCGF,\n                                            const SEHExceptStmt &Except);\n\n  llvm::Function *GenerateSEHFinallyFunction(CodeGenFunction &ParentCGF,\n                                             const SEHFinallyStmt &Finally);\n\n  void EmitSEHExceptionCodeSave(CodeGenFunction &ParentCGF,\n                                llvm::Value *ParentFP,\n                                llvm::Value *EntryEBP);\n  llvm::Value *EmitSEHExceptionCode();\n  llvm::Value *EmitSEHExceptionInfo();\n  llvm::Value *EmitSEHAbnormalTermination();\n\n  /// Emit simple code for OpenMP directives in Simd-only mode.\n  void EmitSimpleOMPExecutableDirective(const OMPExecutableDirective &D);\n\n  /// Scan the outlined statement for captures from the parent function. For\n  /// each capture, mark the capture as escaped and emit a call to\n  /// llvm.localrecover. Insert the localrecover result into the LocalDeclMap.\n  void EmitCapturedLocals(CodeGenFunction &ParentCGF, const Stmt *OutlinedStmt,\n                          bool IsFilter);\n\n  /// Recovers the address of a local in a parent function. ParentVar is the\n  /// address of the variable used in the immediate parent function. It can\n  /// either be an alloca or a call to llvm.localrecover if there are nested\n  /// outlined functions. ParentFP is the frame pointer of the outermost parent\n  /// frame.\n  Address recoverAddrOfEscapedLocal(CodeGenFunction &ParentCGF,\n                                    Address ParentVar,\n                                    llvm::Value *ParentFP);\n\n  void EmitCXXForRangeStmt(const CXXForRangeStmt &S,\n                           ArrayRef<const Attr *> Attrs = None);\n\n  /// Controls insertion of cancellation exit blocks in worksharing constructs.\n  class OMPCancelStackRAII {\n    CodeGenFunction &CGF;\n\n  public:\n    OMPCancelStackRAII(CodeGenFunction &CGF, OpenMPDirectiveKind Kind,\n                       bool HasCancel)\n        : CGF(CGF) {\n      CGF.OMPCancelStack.enter(CGF, Kind, HasCancel);\n    }\n    ~OMPCancelStackRAII() { CGF.OMPCancelStack.exit(CGF); }\n  };\n\n  /// Returns calculated size of the specified type.\n  llvm::Value *getTypeSize(QualType Ty);\n  LValue InitCapturedStruct(const CapturedStmt &S);\n  llvm::Function *EmitCapturedStmt(const CapturedStmt &S, CapturedRegionKind K);\n  llvm::Function *GenerateCapturedStmtFunction(const CapturedStmt &S);\n  Address GenerateCapturedStmtArgument(const CapturedStmt &S);\n  llvm::Function *GenerateOpenMPCapturedStmtFunction(const CapturedStmt &S,\n                                                     SourceLocation Loc);\n  void GenerateOpenMPCapturedVars(const CapturedStmt &S,\n                                  SmallVectorImpl<llvm::Value *> &CapturedVars);\n  void emitOMPSimpleStore(LValue LVal, RValue RVal, QualType RValTy,\n                          SourceLocation Loc);\n  /// Perform element by element copying of arrays with type \\a\n  /// OriginalType from \\a SrcAddr to \\a DestAddr using copying procedure\n  /// generated by \\a CopyGen.\n  ///\n  /// \\param DestAddr Address of the destination array.\n  /// \\param SrcAddr Address of the source array.\n  /// \\param OriginalType Type of destination and source arrays.\n  /// \\param CopyGen Copying procedure that copies value of single array element\n  /// to another single array element.\n  void EmitOMPAggregateAssign(\n      Address DestAddr, Address SrcAddr, QualType OriginalType,\n      const llvm::function_ref<void(Address, Address)> CopyGen);\n  /// Emit proper copying of data from one variable to another.\n  ///\n  /// \\param OriginalType Original type of the copied variables.\n  /// \\param DestAddr Destination address.\n  /// \\param SrcAddr Source address.\n  /// \\param DestVD Destination variable used in \\a CopyExpr (for arrays, has\n  /// type of the base array element).\n  /// \\param SrcVD Source variable used in \\a CopyExpr (for arrays, has type of\n  /// the base array element).\n  /// \\param Copy Actual copygin expression for copying data from \\a SrcVD to \\a\n  /// DestVD.\n  void EmitOMPCopy(QualType OriginalType,\n                   Address DestAddr, Address SrcAddr,\n                   const VarDecl *DestVD, const VarDecl *SrcVD,\n                   const Expr *Copy);\n  /// Emit atomic update code for constructs: \\a X = \\a X \\a BO \\a E or\n  /// \\a X = \\a E \\a BO \\a E.\n  ///\n  /// \\param X Value to be updated.\n  /// \\param E Update value.\n  /// \\param BO Binary operation for update operation.\n  /// \\param IsXLHSInRHSPart true if \\a X is LHS in RHS part of the update\n  /// expression, false otherwise.\n  /// \\param AO Atomic ordering of the generated atomic instructions.\n  /// \\param CommonGen Code generator for complex expressions that cannot be\n  /// expressed through atomicrmw instruction.\n  /// \\returns <true, OldAtomicValue> if simple 'atomicrmw' instruction was\n  /// generated, <false, RValue::get(nullptr)> otherwise.\n  std::pair<bool, RValue> EmitOMPAtomicSimpleUpdateExpr(\n      LValue X, RValue E, BinaryOperatorKind BO, bool IsXLHSInRHSPart,\n      llvm::AtomicOrdering AO, SourceLocation Loc,\n      const llvm::function_ref<RValue(RValue)> CommonGen);\n  bool EmitOMPFirstprivateClause(const OMPExecutableDirective &D,\n                                 OMPPrivateScope &PrivateScope);\n  void EmitOMPPrivateClause(const OMPExecutableDirective &D,\n                            OMPPrivateScope &PrivateScope);\n  void EmitOMPUseDevicePtrClause(\n      const OMPUseDevicePtrClause &C, OMPPrivateScope &PrivateScope,\n      const llvm::DenseMap<const ValueDecl *, Address> &CaptureDeviceAddrMap);\n  void EmitOMPUseDeviceAddrClause(\n      const OMPUseDeviceAddrClause &C, OMPPrivateScope &PrivateScope,\n      const llvm::DenseMap<const ValueDecl *, Address> &CaptureDeviceAddrMap);\n  /// Emit code for copyin clause in \\a D directive. The next code is\n  /// generated at the start of outlined functions for directives:\n  /// \\code\n  /// threadprivate_var1 = master_threadprivate_var1;\n  /// operator=(threadprivate_var2, master_threadprivate_var2);\n  /// ...\n  /// __kmpc_barrier(&loc, global_tid);\n  /// \\endcode\n  ///\n  /// \\param D OpenMP directive possibly with 'copyin' clause(s).\n  /// \\returns true if at least one copyin variable is found, false otherwise.\n  bool EmitOMPCopyinClause(const OMPExecutableDirective &D);\n  /// Emit initial code for lastprivate variables. If some variable is\n  /// not also firstprivate, then the default initialization is used. Otherwise\n  /// initialization of this variable is performed by EmitOMPFirstprivateClause\n  /// method.\n  ///\n  /// \\param D Directive that may have 'lastprivate' directives.\n  /// \\param PrivateScope Private scope for capturing lastprivate variables for\n  /// proper codegen in internal captured statement.\n  ///\n  /// \\returns true if there is at least one lastprivate variable, false\n  /// otherwise.\n  bool EmitOMPLastprivateClauseInit(const OMPExecutableDirective &D,\n                                    OMPPrivateScope &PrivateScope);\n  /// Emit final copying of lastprivate values to original variables at\n  /// the end of the worksharing or simd directive.\n  ///\n  /// \\param D Directive that has at least one 'lastprivate' directives.\n  /// \\param IsLastIterCond Boolean condition that must be set to 'i1 true' if\n  /// it is the last iteration of the loop code in associated directive, or to\n  /// 'i1 false' otherwise. If this item is nullptr, no final check is required.\n  void EmitOMPLastprivateClauseFinal(const OMPExecutableDirective &D,\n                                     bool NoFinals,\n                                     llvm::Value *IsLastIterCond = nullptr);\n  /// Emit initial code for linear clauses.\n  void EmitOMPLinearClause(const OMPLoopDirective &D,\n                           CodeGenFunction::OMPPrivateScope &PrivateScope);\n  /// Emit final code for linear clauses.\n  /// \\param CondGen Optional conditional code for final part of codegen for\n  /// linear clause.\n  void EmitOMPLinearClauseFinal(\n      const OMPLoopDirective &D,\n      const llvm::function_ref<llvm::Value *(CodeGenFunction &)> CondGen);\n  /// Emit initial code for reduction variables. Creates reduction copies\n  /// and initializes them with the values according to OpenMP standard.\n  ///\n  /// \\param D Directive (possibly) with the 'reduction' clause.\n  /// \\param PrivateScope Private scope for capturing reduction variables for\n  /// proper codegen in internal captured statement.\n  ///\n  void EmitOMPReductionClauseInit(const OMPExecutableDirective &D,\n                                  OMPPrivateScope &PrivateScope,\n                                  bool ForInscan = false);\n  /// Emit final update of reduction values to original variables at\n  /// the end of the directive.\n  ///\n  /// \\param D Directive that has at least one 'reduction' directives.\n  /// \\param ReductionKind The kind of reduction to perform.\n  void EmitOMPReductionClauseFinal(const OMPExecutableDirective &D,\n                                   const OpenMPDirectiveKind ReductionKind);\n  /// Emit initial code for linear variables. Creates private copies\n  /// and initializes them with the values according to OpenMP standard.\n  ///\n  /// \\param D Directive (possibly) with the 'linear' clause.\n  /// \\return true if at least one linear variable is found that should be\n  /// initialized with the value of the original variable, false otherwise.\n  bool EmitOMPLinearClauseInit(const OMPLoopDirective &D);\n\n  typedef const llvm::function_ref<void(CodeGenFunction & /*CGF*/,\n                                        llvm::Function * /*OutlinedFn*/,\n                                        const OMPTaskDataTy & /*Data*/)>\n      TaskGenTy;\n  void EmitOMPTaskBasedDirective(const OMPExecutableDirective &S,\n                                 const OpenMPDirectiveKind CapturedRegion,\n                                 const RegionCodeGenTy &BodyGen,\n                                 const TaskGenTy &TaskGen, OMPTaskDataTy &Data);\n  struct OMPTargetDataInfo {\n    Address BasePointersArray = Address::invalid();\n    Address PointersArray = Address::invalid();\n    Address SizesArray = Address::invalid();\n    Address MappersArray = Address::invalid();\n    unsigned NumberOfTargetItems = 0;\n    explicit OMPTargetDataInfo() = default;\n    OMPTargetDataInfo(Address BasePointersArray, Address PointersArray,\n                      Address SizesArray, Address MappersArray,\n                      unsigned NumberOfTargetItems)\n        : BasePointersArray(BasePointersArray), PointersArray(PointersArray),\n          SizesArray(SizesArray), MappersArray(MappersArray),\n          NumberOfTargetItems(NumberOfTargetItems) {}\n  };\n  void EmitOMPTargetTaskBasedDirective(const OMPExecutableDirective &S,\n                                       const RegionCodeGenTy &BodyGen,\n                                       OMPTargetDataInfo &InputInfo);\n\n  void EmitOMPParallelDirective(const OMPParallelDirective &S);\n  void EmitOMPSimdDirective(const OMPSimdDirective &S);\n  void EmitOMPTileDirective(const OMPTileDirective &S);\n  void EmitOMPForDirective(const OMPForDirective &S);\n  void EmitOMPForSimdDirective(const OMPForSimdDirective &S);\n  void EmitOMPSectionsDirective(const OMPSectionsDirective &S);\n  void EmitOMPSectionDirective(const OMPSectionDirective &S);\n  void EmitOMPSingleDirective(const OMPSingleDirective &S);\n  void EmitOMPMasterDirective(const OMPMasterDirective &S);\n  void EmitOMPCriticalDirective(const OMPCriticalDirective &S);\n  void EmitOMPParallelForDirective(const OMPParallelForDirective &S);\n  void EmitOMPParallelForSimdDirective(const OMPParallelForSimdDirective &S);\n  void EmitOMPParallelSectionsDirective(const OMPParallelSectionsDirective &S);\n  void EmitOMPParallelMasterDirective(const OMPParallelMasterDirective &S);\n  void EmitOMPTaskDirective(const OMPTaskDirective &S);\n  void EmitOMPTaskyieldDirective(const OMPTaskyieldDirective &S);\n  void EmitOMPBarrierDirective(const OMPBarrierDirective &S);\n  void EmitOMPTaskwaitDirective(const OMPTaskwaitDirective &S);\n  void EmitOMPTaskgroupDirective(const OMPTaskgroupDirective &S);\n  void EmitOMPFlushDirective(const OMPFlushDirective &S);\n  void EmitOMPDepobjDirective(const OMPDepobjDirective &S);\n  void EmitOMPScanDirective(const OMPScanDirective &S);\n  void EmitOMPOrderedDirective(const OMPOrderedDirective &S);\n  void EmitOMPAtomicDirective(const OMPAtomicDirective &S);\n  void EmitOMPTargetDirective(const OMPTargetDirective &S);\n  void EmitOMPTargetDataDirective(const OMPTargetDataDirective &S);\n  void EmitOMPTargetEnterDataDirective(const OMPTargetEnterDataDirective &S);\n  void EmitOMPTargetExitDataDirective(const OMPTargetExitDataDirective &S);\n  void EmitOMPTargetUpdateDirective(const OMPTargetUpdateDirective &S);\n  void EmitOMPTargetParallelDirective(const OMPTargetParallelDirective &S);\n  void\n  EmitOMPTargetParallelForDirective(const OMPTargetParallelForDirective &S);\n  void EmitOMPTeamsDirective(const OMPTeamsDirective &S);\n  void\n  EmitOMPCancellationPointDirective(const OMPCancellationPointDirective &S);\n  void EmitOMPCancelDirective(const OMPCancelDirective &S);\n  void EmitOMPTaskLoopBasedDirective(const OMPLoopDirective &S);\n  void EmitOMPTaskLoopDirective(const OMPTaskLoopDirective &S);\n  void EmitOMPTaskLoopSimdDirective(const OMPTaskLoopSimdDirective &S);\n  void EmitOMPMasterTaskLoopDirective(const OMPMasterTaskLoopDirective &S);\n  void\n  EmitOMPMasterTaskLoopSimdDirective(const OMPMasterTaskLoopSimdDirective &S);\n  void EmitOMPParallelMasterTaskLoopDirective(\n      const OMPParallelMasterTaskLoopDirective &S);\n  void EmitOMPParallelMasterTaskLoopSimdDirective(\n      const OMPParallelMasterTaskLoopSimdDirective &S);\n  void EmitOMPDistributeDirective(const OMPDistributeDirective &S);\n  void EmitOMPDistributeParallelForDirective(\n      const OMPDistributeParallelForDirective &S);\n  void EmitOMPDistributeParallelForSimdDirective(\n      const OMPDistributeParallelForSimdDirective &S);\n  void EmitOMPDistributeSimdDirective(const OMPDistributeSimdDirective &S);\n  void EmitOMPTargetParallelForSimdDirective(\n      const OMPTargetParallelForSimdDirective &S);\n  void EmitOMPTargetSimdDirective(const OMPTargetSimdDirective &S);\n  void EmitOMPTeamsDistributeDirective(const OMPTeamsDistributeDirective &S);\n  void\n  EmitOMPTeamsDistributeSimdDirective(const OMPTeamsDistributeSimdDirective &S);\n  void EmitOMPTeamsDistributeParallelForSimdDirective(\n      const OMPTeamsDistributeParallelForSimdDirective &S);\n  void EmitOMPTeamsDistributeParallelForDirective(\n      const OMPTeamsDistributeParallelForDirective &S);\n  void EmitOMPTargetTeamsDirective(const OMPTargetTeamsDirective &S);\n  void EmitOMPTargetTeamsDistributeDirective(\n      const OMPTargetTeamsDistributeDirective &S);\n  void EmitOMPTargetTeamsDistributeParallelForDirective(\n      const OMPTargetTeamsDistributeParallelForDirective &S);\n  void EmitOMPTargetTeamsDistributeParallelForSimdDirective(\n      const OMPTargetTeamsDistributeParallelForSimdDirective &S);\n  void EmitOMPTargetTeamsDistributeSimdDirective(\n      const OMPTargetTeamsDistributeSimdDirective &S);\n\n  /// Emit device code for the target directive.\n  static void EmitOMPTargetDeviceFunction(CodeGenModule &CGM,\n                                          StringRef ParentName,\n                                          const OMPTargetDirective &S);\n  static void\n  EmitOMPTargetParallelDeviceFunction(CodeGenModule &CGM, StringRef ParentName,\n                                      const OMPTargetParallelDirective &S);\n  /// Emit device code for the target parallel for directive.\n  static void EmitOMPTargetParallelForDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetParallelForDirective &S);\n  /// Emit device code for the target parallel for simd directive.\n  static void EmitOMPTargetParallelForSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetParallelForSimdDirective &S);\n  /// Emit device code for the target teams directive.\n  static void\n  EmitOMPTargetTeamsDeviceFunction(CodeGenModule &CGM, StringRef ParentName,\n                                   const OMPTargetTeamsDirective &S);\n  /// Emit device code for the target teams distribute directive.\n  static void EmitOMPTargetTeamsDistributeDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeDirective &S);\n  /// Emit device code for the target teams distribute simd directive.\n  static void EmitOMPTargetTeamsDistributeSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeSimdDirective &S);\n  /// Emit device code for the target simd directive.\n  static void EmitOMPTargetSimdDeviceFunction(CodeGenModule &CGM,\n                                              StringRef ParentName,\n                                              const OMPTargetSimdDirective &S);\n  /// Emit device code for the target teams distribute parallel for simd\n  /// directive.\n  static void EmitOMPTargetTeamsDistributeParallelForSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeParallelForSimdDirective &S);\n\n  static void EmitOMPTargetTeamsDistributeParallelForDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeParallelForDirective &S);\n\n  /// Emit the Stmt \\p S and return its topmost canonical loop, if any.\n  /// TODO: The \\p Depth paramter is not yet implemented and must be 1. In the\n  /// future it is meant to be the number of loops expected in the loop nests\n  /// (usually specified by the \"collapse\" clause) that are collapsed to a\n  /// single loop by this function.\n  llvm::CanonicalLoopInfo *EmitOMPCollapsedCanonicalLoopNest(const Stmt *S,\n                                                             int Depth);\n\n  /// Emit an OMPCanonicalLoop using the OpenMPIRBuilder.\n  void EmitOMPCanonicalLoop(const OMPCanonicalLoop *S);\n\n  /// Emit inner loop of the worksharing/simd construct.\n  ///\n  /// \\param S Directive, for which the inner loop must be emitted.\n  /// \\param RequiresCleanup true, if directive has some associated private\n  /// variables.\n  /// \\param LoopCond Bollean condition for loop continuation.\n  /// \\param IncExpr Increment expression for loop control variable.\n  /// \\param BodyGen Generator for the inner body of the inner loop.\n  /// \\param PostIncGen Genrator for post-increment code (required for ordered\n  /// loop directvies).\n  void EmitOMPInnerLoop(\n      const OMPExecutableDirective &S, bool RequiresCleanup,\n      const Expr *LoopCond, const Expr *IncExpr,\n      const llvm::function_ref<void(CodeGenFunction &)> BodyGen,\n      const llvm::function_ref<void(CodeGenFunction &)> PostIncGen);\n\n  JumpDest getOMPCancelDestination(OpenMPDirectiveKind Kind);\n  /// Emit initial code for loop counters of loop-based directives.\n  void EmitOMPPrivateLoopCounters(const OMPLoopDirective &S,\n                                  OMPPrivateScope &LoopScope);\n\n  /// Helper for the OpenMP loop directives.\n  void EmitOMPLoopBody(const OMPLoopDirective &D, JumpDest LoopExit);\n\n  /// Emit code for the worksharing loop-based directive.\n  /// \\return true, if this construct has any lastprivate clause, false -\n  /// otherwise.\n  bool EmitOMPWorksharingLoop(const OMPLoopDirective &S, Expr *EUB,\n                              const CodeGenLoopBoundsTy &CodeGenLoopBounds,\n                              const CodeGenDispatchBoundsTy &CGDispatchBounds);\n\n  /// Emit code for the distribute loop-based directive.\n  void EmitOMPDistributeLoop(const OMPLoopDirective &S,\n                             const CodeGenLoopTy &CodeGenLoop, Expr *IncExpr);\n\n  /// Helpers for the OpenMP loop directives.\n  void EmitOMPSimdInit(const OMPLoopDirective &D, bool IsMonotonic = false);\n  void EmitOMPSimdFinal(\n      const OMPLoopDirective &D,\n      const llvm::function_ref<llvm::Value *(CodeGenFunction &)> CondGen);\n\n  /// Emits the lvalue for the expression with possibly captured variable.\n  LValue EmitOMPSharedLValue(const Expr *E);\n\nprivate:\n  /// Helpers for blocks.\n  llvm::Value *EmitBlockLiteral(const CGBlockInfo &Info);\n\n  /// struct with the values to be passed to the OpenMP loop-related functions\n  struct OMPLoopArguments {\n    /// loop lower bound\n    Address LB = Address::invalid();\n    /// loop upper bound\n    Address UB = Address::invalid();\n    /// loop stride\n    Address ST = Address::invalid();\n    /// isLastIteration argument for runtime functions\n    Address IL = Address::invalid();\n    /// Chunk value generated by sema\n    llvm::Value *Chunk = nullptr;\n    /// EnsureUpperBound\n    Expr *EUB = nullptr;\n    /// IncrementExpression\n    Expr *IncExpr = nullptr;\n    /// Loop initialization\n    Expr *Init = nullptr;\n    /// Loop exit condition\n    Expr *Cond = nullptr;\n    /// Update of LB after a whole chunk has been executed\n    Expr *NextLB = nullptr;\n    /// Update of UB after a whole chunk has been executed\n    Expr *NextUB = nullptr;\n    OMPLoopArguments() = default;\n    OMPLoopArguments(Address LB, Address UB, Address ST, Address IL,\n                     llvm::Value *Chunk = nullptr, Expr *EUB = nullptr,\n                     Expr *IncExpr = nullptr, Expr *Init = nullptr,\n                     Expr *Cond = nullptr, Expr *NextLB = nullptr,\n                     Expr *NextUB = nullptr)\n        : LB(LB), UB(UB), ST(ST), IL(IL), Chunk(Chunk), EUB(EUB),\n          IncExpr(IncExpr), Init(Init), Cond(Cond), NextLB(NextLB),\n          NextUB(NextUB) {}\n  };\n  void EmitOMPOuterLoop(bool DynamicOrOrdered, bool IsMonotonic,\n                        const OMPLoopDirective &S, OMPPrivateScope &LoopScope,\n                        const OMPLoopArguments &LoopArgs,\n                        const CodeGenLoopTy &CodeGenLoop,\n                        const CodeGenOrderedTy &CodeGenOrdered);\n  void EmitOMPForOuterLoop(const OpenMPScheduleTy &ScheduleKind,\n                           bool IsMonotonic, const OMPLoopDirective &S,\n                           OMPPrivateScope &LoopScope, bool Ordered,\n                           const OMPLoopArguments &LoopArgs,\n                           const CodeGenDispatchBoundsTy &CGDispatchBounds);\n  void EmitOMPDistributeOuterLoop(OpenMPDistScheduleClauseKind ScheduleKind,\n                                  const OMPLoopDirective &S,\n                                  OMPPrivateScope &LoopScope,\n                                  const OMPLoopArguments &LoopArgs,\n                                  const CodeGenLoopTy &CodeGenLoopContent);\n  /// Emit code for sections directive.\n  void EmitSections(const OMPExecutableDirective &S);\n\npublic:\n\n  //===--------------------------------------------------------------------===//\n  //                         LValue Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  /// Create a check that a scalar RValue is non-null.\n  llvm::Value *EmitNonNullRValueCheck(RValue RV, QualType T);\n\n  /// GetUndefRValue - Get an appropriate 'undef' rvalue for the given type.\n  RValue GetUndefRValue(QualType Ty);\n\n  /// EmitUnsupportedRValue - Emit a dummy r-value using the type of E\n  /// and issue an ErrorUnsupported style diagnostic (using the\n  /// provided Name).\n  RValue EmitUnsupportedRValue(const Expr *E,\n                               const char *Name);\n\n  /// EmitUnsupportedLValue - Emit a dummy l-value using the type of E and issue\n  /// an ErrorUnsupported style diagnostic (using the provided Name).\n  LValue EmitUnsupportedLValue(const Expr *E,\n                               const char *Name);\n\n  /// EmitLValue - Emit code to compute a designator that specifies the location\n  /// of the expression.\n  ///\n  /// This can return one of two things: a simple address or a bitfield\n  /// reference.  In either case, the LLVM Value* in the LValue structure is\n  /// guaranteed to be an LLVM pointer type.\n  ///\n  /// If this returns a bitfield reference, nothing about the pointee type of\n  /// the LLVM value is known: For example, it may not be a pointer to an\n  /// integer.\n  ///\n  /// If this returns a normal address, and if the lvalue's C type is fixed\n  /// size, this method guarantees that the returned pointer type will point to\n  /// an LLVM type of the same size of the lvalue's type.  If the lvalue has a\n  /// variable length type, this is not possible.\n  ///\n  LValue EmitLValue(const Expr *E);\n\n  /// Same as EmitLValue but additionally we generate checking code to\n  /// guard against undefined behavior.  This is only suitable when we know\n  /// that the address will be used to access the object.\n  LValue EmitCheckedLValue(const Expr *E, TypeCheckKind TCK);\n\n  RValue convertTempToRValue(Address addr, QualType type,\n                             SourceLocation Loc);\n\n  void EmitAtomicInit(Expr *E, LValue lvalue);\n\n  bool LValueIsSuitableForInlineAtomic(LValue Src);\n\n  RValue EmitAtomicLoad(LValue LV, SourceLocation SL,\n                        AggValueSlot Slot = AggValueSlot::ignored());\n\n  RValue EmitAtomicLoad(LValue lvalue, SourceLocation loc,\n                        llvm::AtomicOrdering AO, bool IsVolatile = false,\n                        AggValueSlot slot = AggValueSlot::ignored());\n\n  void EmitAtomicStore(RValue rvalue, LValue lvalue, bool isInit);\n\n  void EmitAtomicStore(RValue rvalue, LValue lvalue, llvm::AtomicOrdering AO,\n                       bool IsVolatile, bool isInit);\n\n  std::pair<RValue, llvm::Value *> EmitAtomicCompareExchange(\n      LValue Obj, RValue Expected, RValue Desired, SourceLocation Loc,\n      llvm::AtomicOrdering Success =\n          llvm::AtomicOrdering::SequentiallyConsistent,\n      llvm::AtomicOrdering Failure =\n          llvm::AtomicOrdering::SequentiallyConsistent,\n      bool IsWeak = false, AggValueSlot Slot = AggValueSlot::ignored());\n\n  void EmitAtomicUpdate(LValue LVal, llvm::AtomicOrdering AO,\n                        const llvm::function_ref<RValue(RValue)> &UpdateOp,\n                        bool IsVolatile);\n\n  /// EmitToMemory - Change a scalar value from its value\n  /// representation to its in-memory representation.\n  llvm::Value *EmitToMemory(llvm::Value *Value, QualType Ty);\n\n  /// EmitFromMemory - Change a scalar value from its memory\n  /// representation to its value representation.\n  llvm::Value *EmitFromMemory(llvm::Value *Value, QualType Ty);\n\n  /// Check if the scalar \\p Value is within the valid range for the given\n  /// type \\p Ty.\n  ///\n  /// Returns true if a check is needed (even if the range is unknown).\n  bool EmitScalarRangeCheck(llvm::Value *Value, QualType Ty,\n                            SourceLocation Loc);\n\n  /// EmitLoadOfScalar - Load a scalar value from an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.\n  llvm::Value *EmitLoadOfScalar(Address Addr, bool Volatile, QualType Ty,\n                                SourceLocation Loc,\n                                AlignmentSource Source = AlignmentSource::Type,\n                                bool isNontemporal = false) {\n    return EmitLoadOfScalar(Addr, Volatile, Ty, Loc, LValueBaseInfo(Source),\n                            CGM.getTBAAAccessInfo(Ty), isNontemporal);\n  }\n\n  llvm::Value *EmitLoadOfScalar(Address Addr, bool Volatile, QualType Ty,\n                                SourceLocation Loc, LValueBaseInfo BaseInfo,\n                                TBAAAccessInfo TBAAInfo,\n                                bool isNontemporal = false);\n\n  /// EmitLoadOfScalar - Load a scalar value from an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.  The l-value must be a simple\n  /// l-value.\n  llvm::Value *EmitLoadOfScalar(LValue lvalue, SourceLocation Loc);\n\n  /// EmitStoreOfScalar - Store a scalar value to an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.\n  void EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                         bool Volatile, QualType Ty,\n                         AlignmentSource Source = AlignmentSource::Type,\n                         bool isInit = false, bool isNontemporal = false) {\n    EmitStoreOfScalar(Value, Addr, Volatile, Ty, LValueBaseInfo(Source),\n                      CGM.getTBAAAccessInfo(Ty), isInit, isNontemporal);\n  }\n\n  void EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                         bool Volatile, QualType Ty,\n                         LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo,\n                         bool isInit = false, bool isNontemporal = false);\n\n  /// EmitStoreOfScalar - Store a scalar value to an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.  The l-value must be a simple\n  /// l-value.  The isInit flag indicates whether this is an initialization.\n  /// If so, atomic qualifiers are ignored and the store is always non-atomic.\n  void EmitStoreOfScalar(llvm::Value *value, LValue lvalue, bool isInit=false);\n\n  /// EmitLoadOfLValue - Given an expression that represents a value lvalue,\n  /// this method emits the address of the lvalue, then loads the result as an\n  /// rvalue, returning the rvalue.\n  RValue EmitLoadOfLValue(LValue V, SourceLocation Loc);\n  RValue EmitLoadOfExtVectorElementLValue(LValue V);\n  RValue EmitLoadOfBitfieldLValue(LValue LV, SourceLocation Loc);\n  RValue EmitLoadOfGlobalRegLValue(LValue LV);\n\n  /// EmitStoreThroughLValue - Store the specified rvalue into the specified\n  /// lvalue, where both are guaranteed to the have the same type, and that type\n  /// is 'Ty'.\n  void EmitStoreThroughLValue(RValue Src, LValue Dst, bool isInit = false);\n  void EmitStoreThroughExtVectorComponentLValue(RValue Src, LValue Dst);\n  void EmitStoreThroughGlobalRegLValue(RValue Src, LValue Dst);\n\n  /// EmitStoreThroughBitfieldLValue - Store Src into Dst with same constraints\n  /// as EmitStoreThroughLValue.\n  ///\n  /// \\param Result [out] - If non-null, this will be set to a Value* for the\n  /// bit-field contents after the store, appropriate for use as the result of\n  /// an assignment to the bit-field.\n  void EmitStoreThroughBitfieldLValue(RValue Src, LValue Dst,\n                                      llvm::Value **Result=nullptr);\n\n  /// Emit an l-value for an assignment (simple or compound) of complex type.\n  LValue EmitComplexAssignmentLValue(const BinaryOperator *E);\n  LValue EmitComplexCompoundAssignmentLValue(const CompoundAssignOperator *E);\n  LValue EmitScalarCompoundAssignWithComplex(const CompoundAssignOperator *E,\n                                             llvm::Value *&Result);\n\n  // Note: only available for agg return types\n  LValue EmitBinaryOperatorLValue(const BinaryOperator *E);\n  LValue EmitCompoundAssignmentLValue(const CompoundAssignOperator *E);\n  // Note: only available for agg return types\n  LValue EmitCallExprLValue(const CallExpr *E);\n  // Note: only available for agg return types\n  LValue EmitVAArgExprLValue(const VAArgExpr *E);\n  LValue EmitDeclRefLValue(const DeclRefExpr *E);\n  LValue EmitStringLiteralLValue(const StringLiteral *E);\n  LValue EmitObjCEncodeExprLValue(const ObjCEncodeExpr *E);\n  LValue EmitPredefinedLValue(const PredefinedExpr *E);\n  LValue EmitUnaryOpLValue(const UnaryOperator *E);\n  LValue EmitArraySubscriptExpr(const ArraySubscriptExpr *E,\n                                bool Accessed = false);\n  LValue EmitMatrixSubscriptExpr(const MatrixSubscriptExpr *E);\n  LValue EmitOMPArraySectionExpr(const OMPArraySectionExpr *E,\n                                 bool IsLowerBound = true);\n  LValue EmitExtVectorElementExpr(const ExtVectorElementExpr *E);\n  LValue EmitMemberExpr(const MemberExpr *E);\n  LValue EmitObjCIsaExpr(const ObjCIsaExpr *E);\n  LValue EmitCompoundLiteralLValue(const CompoundLiteralExpr *E);\n  LValue EmitInitListLValue(const InitListExpr *E);\n  LValue EmitConditionalOperatorLValue(const AbstractConditionalOperator *E);\n  LValue EmitCastLValue(const CastExpr *E);\n  LValue EmitMaterializeTemporaryExpr(const MaterializeTemporaryExpr *E);\n  LValue EmitOpaqueValueLValue(const OpaqueValueExpr *e);\n\n  Address EmitExtVectorElementLValue(LValue V);\n\n  RValue EmitRValueForField(LValue LV, const FieldDecl *FD, SourceLocation Loc);\n\n  Address EmitArrayToPointerDecay(const Expr *Array,\n                                  LValueBaseInfo *BaseInfo = nullptr,\n                                  TBAAAccessInfo *TBAAInfo = nullptr);\n\n  class ConstantEmission {\n    llvm::PointerIntPair<llvm::Constant*, 1, bool> ValueAndIsReference;\n    ConstantEmission(llvm::Constant *C, bool isReference)\n      : ValueAndIsReference(C, isReference) {}\n  public:\n    ConstantEmission() {}\n    static ConstantEmission forReference(llvm::Constant *C) {\n      return ConstantEmission(C, true);\n    }\n    static ConstantEmission forValue(llvm::Constant *C) {\n      return ConstantEmission(C, false);\n    }\n\n    explicit operator bool() const {\n      return ValueAndIsReference.getOpaqueValue() != nullptr;\n    }\n\n    bool isReference() const { return ValueAndIsReference.getInt(); }\n    LValue getReferenceLValue(CodeGenFunction &CGF, Expr *refExpr) const {\n      assert(isReference());\n      return CGF.MakeNaturalAlignAddrLValue(ValueAndIsReference.getPointer(),\n                                            refExpr->getType());\n    }\n\n    llvm::Constant *getValue() const {\n      assert(!isReference());\n      return ValueAndIsReference.getPointer();\n    }\n  };\n\n  ConstantEmission tryEmitAsConstant(DeclRefExpr *refExpr);\n  ConstantEmission tryEmitAsConstant(const MemberExpr *ME);\n  llvm::Value *emitScalarConstant(const ConstantEmission &Constant, Expr *E);\n\n  RValue EmitPseudoObjectRValue(const PseudoObjectExpr *e,\n                                AggValueSlot slot = AggValueSlot::ignored());\n  LValue EmitPseudoObjectLValue(const PseudoObjectExpr *e);\n\n  llvm::Value *EmitIvarOffset(const ObjCInterfaceDecl *Interface,\n                              const ObjCIvarDecl *Ivar);\n  LValue EmitLValueForField(LValue Base, const FieldDecl* Field);\n  LValue EmitLValueForLambdaField(const FieldDecl *Field);\n\n  /// EmitLValueForFieldInitialization - Like EmitLValueForField, except that\n  /// if the Field is a reference, this will return the address of the reference\n  /// and not the address of the value stored in the reference.\n  LValue EmitLValueForFieldInitialization(LValue Base,\n                                          const FieldDecl* Field);\n\n  LValue EmitLValueForIvar(QualType ObjectTy,\n                           llvm::Value* Base, const ObjCIvarDecl *Ivar,\n                           unsigned CVRQualifiers);\n\n  LValue EmitCXXConstructLValue(const CXXConstructExpr *E);\n  LValue EmitCXXBindTemporaryLValue(const CXXBindTemporaryExpr *E);\n  LValue EmitCXXTypeidLValue(const CXXTypeidExpr *E);\n  LValue EmitCXXUuidofLValue(const CXXUuidofExpr *E);\n\n  LValue EmitObjCMessageExprLValue(const ObjCMessageExpr *E);\n  LValue EmitObjCIvarRefLValue(const ObjCIvarRefExpr *E);\n  LValue EmitStmtExprLValue(const StmtExpr *E);\n  LValue EmitPointerToDataMemberBinaryExpr(const BinaryOperator *E);\n  LValue EmitObjCSelectorLValue(const ObjCSelectorExpr *E);\n  void   EmitDeclRefExprDbgValue(const DeclRefExpr *E, const APValue &Init);\n\n  //===--------------------------------------------------------------------===//\n  //                         Scalar Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitCall - Generate a call of the given function, expecting the given\n  /// result type, and using the given argument list which specifies both the\n  /// LLVM arguments and the types they were derived from.\n  RValue EmitCall(const CGFunctionInfo &CallInfo, const CGCallee &Callee,\n                  ReturnValueSlot ReturnValue, const CallArgList &Args,\n                  llvm::CallBase **callOrInvoke, SourceLocation Loc);\n  RValue EmitCall(const CGFunctionInfo &CallInfo, const CGCallee &Callee,\n                  ReturnValueSlot ReturnValue, const CallArgList &Args,\n                  llvm::CallBase **callOrInvoke = nullptr) {\n    return EmitCall(CallInfo, Callee, ReturnValue, Args, callOrInvoke,\n                    SourceLocation());\n  }\n  RValue EmitCall(QualType FnType, const CGCallee &Callee, const CallExpr *E,\n                  ReturnValueSlot ReturnValue, llvm::Value *Chain = nullptr);\n  RValue EmitCallExpr(const CallExpr *E,\n                      ReturnValueSlot ReturnValue = ReturnValueSlot());\n  RValue EmitSimpleCallExpr(const CallExpr *E, ReturnValueSlot ReturnValue);\n  CGCallee EmitCallee(const Expr *E);\n\n  void checkTargetFeatures(const CallExpr *E, const FunctionDecl *TargetDecl);\n  void checkTargetFeatures(SourceLocation Loc, const FunctionDecl *TargetDecl);\n\n  llvm::CallInst *EmitRuntimeCall(llvm::FunctionCallee callee,\n                                  const Twine &name = \"\");\n  llvm::CallInst *EmitRuntimeCall(llvm::FunctionCallee callee,\n                                  ArrayRef<llvm::Value *> args,\n                                  const Twine &name = \"\");\n  llvm::CallInst *EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                          const Twine &name = \"\");\n  llvm::CallInst *EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                          ArrayRef<llvm::Value *> args,\n                                          const Twine &name = \"\");\n\n  SmallVector<llvm::OperandBundleDef, 1>\n  getBundlesForFunclet(llvm::Value *Callee);\n\n  llvm::CallBase *EmitCallOrInvoke(llvm::FunctionCallee Callee,\n                                   ArrayRef<llvm::Value *> Args,\n                                   const Twine &Name = \"\");\n  llvm::CallBase *EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                          ArrayRef<llvm::Value *> args,\n                                          const Twine &name = \"\");\n  llvm::CallBase *EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                          const Twine &name = \"\");\n  void EmitNoreturnRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                       ArrayRef<llvm::Value *> args);\n\n  CGCallee BuildAppleKextVirtualCall(const CXXMethodDecl *MD,\n                                     NestedNameSpecifier *Qual,\n                                     llvm::Type *Ty);\n\n  CGCallee BuildAppleKextVirtualDestructorCall(const CXXDestructorDecl *DD,\n                                               CXXDtorType Type,\n                                               const CXXRecordDecl *RD);\n\n  // Return the copy constructor name with the prefix \"__copy_constructor_\"\n  // removed.\n  static std::string getNonTrivialCopyConstructorStr(QualType QT,\n                                                     CharUnits Alignment,\n                                                     bool IsVolatile,\n                                                     ASTContext &Ctx);\n\n  // Return the destructor name with the prefix \"__destructor_\" removed.\n  static std::string getNonTrivialDestructorStr(QualType QT,\n                                                CharUnits Alignment,\n                                                bool IsVolatile,\n                                                ASTContext &Ctx);\n\n  // These functions emit calls to the special functions of non-trivial C\n  // structs.\n  void defaultInitNonTrivialCStructVar(LValue Dst);\n  void callCStructDefaultConstructor(LValue Dst);\n  void callCStructDestructor(LValue Dst);\n  void callCStructCopyConstructor(LValue Dst, LValue Src);\n  void callCStructMoveConstructor(LValue Dst, LValue Src);\n  void callCStructCopyAssignmentOperator(LValue Dst, LValue Src);\n  void callCStructMoveAssignmentOperator(LValue Dst, LValue Src);\n\n  RValue\n  EmitCXXMemberOrOperatorCall(const CXXMethodDecl *Method,\n                              const CGCallee &Callee,\n                              ReturnValueSlot ReturnValue, llvm::Value *This,\n                              llvm::Value *ImplicitParam,\n                              QualType ImplicitParamTy, const CallExpr *E,\n                              CallArgList *RtlArgs);\n  RValue EmitCXXDestructorCall(GlobalDecl Dtor, const CGCallee &Callee,\n                               llvm::Value *This, QualType ThisTy,\n                               llvm::Value *ImplicitParam,\n                               QualType ImplicitParamTy, const CallExpr *E);\n  RValue EmitCXXMemberCallExpr(const CXXMemberCallExpr *E,\n                               ReturnValueSlot ReturnValue);\n  RValue EmitCXXMemberOrOperatorMemberCallExpr(const CallExpr *CE,\n                                               const CXXMethodDecl *MD,\n                                               ReturnValueSlot ReturnValue,\n                                               bool HasQualifier,\n                                               NestedNameSpecifier *Qualifier,\n                                               bool IsArrow, const Expr *Base);\n  // Compute the object pointer.\n  Address EmitCXXMemberDataPointerAddress(const Expr *E, Address base,\n                                          llvm::Value *memberPtr,\n                                          const MemberPointerType *memberPtrType,\n                                          LValueBaseInfo *BaseInfo = nullptr,\n                                          TBAAAccessInfo *TBAAInfo = nullptr);\n  RValue EmitCXXMemberPointerCallExpr(const CXXMemberCallExpr *E,\n                                      ReturnValueSlot ReturnValue);\n\n  RValue EmitCXXOperatorMemberCallExpr(const CXXOperatorCallExpr *E,\n                                       const CXXMethodDecl *MD,\n                                       ReturnValueSlot ReturnValue);\n  RValue EmitCXXPseudoDestructorExpr(const CXXPseudoDestructorExpr *E);\n\n  RValue EmitCUDAKernelCallExpr(const CUDAKernelCallExpr *E,\n                                ReturnValueSlot ReturnValue);\n\n  RValue EmitNVPTXDevicePrintfCallExpr(const CallExpr *E,\n                                       ReturnValueSlot ReturnValue);\n  RValue EmitAMDGPUDevicePrintfCallExpr(const CallExpr *E,\n                                        ReturnValueSlot ReturnValue);\n\n  RValue EmitBuiltinExpr(const GlobalDecl GD, unsigned BuiltinID,\n                         const CallExpr *E, ReturnValueSlot ReturnValue);\n\n  RValue emitRotate(const CallExpr *E, bool IsRotateRight);\n\n  /// Emit IR for __builtin_os_log_format.\n  RValue emitBuiltinOSLogFormat(const CallExpr &E);\n\n  /// Emit IR for __builtin_is_aligned.\n  RValue EmitBuiltinIsAligned(const CallExpr *E);\n  /// Emit IR for __builtin_align_up/__builtin_align_down.\n  RValue EmitBuiltinAlignTo(const CallExpr *E, bool AlignUp);\n\n  llvm::Function *generateBuiltinOSLogHelperFunction(\n      const analyze_os_log::OSLogBufferLayout &Layout,\n      CharUnits BufferAlignment);\n\n  RValue EmitBlockCallExpr(const CallExpr *E, ReturnValueSlot ReturnValue);\n\n  /// EmitTargetBuiltinExpr - Emit the given builtin call. Returns 0 if the call\n  /// is unhandled by the current target.\n  llvm::Value *EmitTargetBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue);\n\n  llvm::Value *EmitAArch64CompareBuiltinExpr(llvm::Value *Op, llvm::Type *Ty,\n                                             const llvm::CmpInst::Predicate Fp,\n                                             const llvm::CmpInst::Predicate Ip,\n                                             const llvm::Twine &Name = \"\");\n  llvm::Value *EmitARMBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                  ReturnValueSlot ReturnValue,\n                                  llvm::Triple::ArchType Arch);\n  llvm::Value *EmitARMMVEBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue,\n                                     llvm::Triple::ArchType Arch);\n  llvm::Value *EmitARMCDEBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue,\n                                     llvm::Triple::ArchType Arch);\n  llvm::Value *EmitCMSEClearRecord(llvm::Value *V, llvm::IntegerType *ITy,\n                                   QualType RTy);\n  llvm::Value *EmitCMSEClearRecord(llvm::Value *V, llvm::ArrayType *ATy,\n                                   QualType RTy);\n\n  llvm::Value *EmitCommonNeonBuiltinExpr(unsigned BuiltinID,\n                                         unsigned LLVMIntrinsic,\n                                         unsigned AltLLVMIntrinsic,\n                                         const char *NameHint,\n                                         unsigned Modifier,\n                                         const CallExpr *E,\n                                         SmallVectorImpl<llvm::Value *> &Ops,\n                                         Address PtrOp0, Address PtrOp1,\n                                         llvm::Triple::ArchType Arch);\n\n  llvm::Function *LookupNeonLLVMIntrinsic(unsigned IntrinsicID,\n                                          unsigned Modifier, llvm::Type *ArgTy,\n                                          const CallExpr *E);\n  llvm::Value *EmitNeonCall(llvm::Function *F,\n                            SmallVectorImpl<llvm::Value*> &O,\n                            const char *name,\n                            unsigned shift = 0, bool rightshift = false);\n  llvm::Value *EmitNeonSplat(llvm::Value *V, llvm::Constant *Idx,\n                             const llvm::ElementCount &Count);\n  llvm::Value *EmitNeonSplat(llvm::Value *V, llvm::Constant *Idx);\n  llvm::Value *EmitNeonShiftVector(llvm::Value *V, llvm::Type *Ty,\n                                   bool negateForRightShift);\n  llvm::Value *EmitNeonRShiftImm(llvm::Value *Vec, llvm::Value *Amt,\n                                 llvm::Type *Ty, bool usgn, const char *name);\n  llvm::Value *vectorWrapScalar16(llvm::Value *Op);\n  /// SVEBuiltinMemEltTy - Returns the memory element type for this memory\n  /// access builtin.  Only required if it can't be inferred from the base\n  /// pointer operand.\n  llvm::Type *SVEBuiltinMemEltTy(SVETypeFlags TypeFlags);\n\n  SmallVector<llvm::Type *, 2> getSVEOverloadTypes(SVETypeFlags TypeFlags,\n                                                   llvm::Type *ReturnType,\n                                                   ArrayRef<llvm::Value *> Ops);\n  llvm::Type *getEltType(SVETypeFlags TypeFlags);\n  llvm::ScalableVectorType *getSVEType(const SVETypeFlags &TypeFlags);\n  llvm::ScalableVectorType *getSVEPredType(SVETypeFlags TypeFlags);\n  llvm::Value *EmitSVEAllTruePred(SVETypeFlags TypeFlags);\n  llvm::Value *EmitSVEDupX(llvm::Value *Scalar);\n  llvm::Value *EmitSVEDupX(llvm::Value *Scalar, llvm::Type *Ty);\n  llvm::Value *EmitSVEReinterpret(llvm::Value *Val, llvm::Type *Ty);\n  llvm::Value *EmitSVEPMull(SVETypeFlags TypeFlags,\n                            llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                            unsigned BuiltinID);\n  llvm::Value *EmitSVEMovl(SVETypeFlags TypeFlags,\n                           llvm::ArrayRef<llvm::Value *> Ops,\n                           unsigned BuiltinID);\n  llvm::Value *EmitSVEPredicateCast(llvm::Value *Pred,\n                                    llvm::ScalableVectorType *VTy);\n  llvm::Value *EmitSVEGatherLoad(SVETypeFlags TypeFlags,\n                                 llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                                 unsigned IntID);\n  llvm::Value *EmitSVEScatterStore(SVETypeFlags TypeFlags,\n                                   llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                                   unsigned IntID);\n  llvm::Value *EmitSVEMaskedLoad(const CallExpr *, llvm::Type *ReturnTy,\n                                 SmallVectorImpl<llvm::Value *> &Ops,\n                                 unsigned BuiltinID, bool IsZExtReturn);\n  llvm::Value *EmitSVEMaskedStore(const CallExpr *,\n                                  SmallVectorImpl<llvm::Value *> &Ops,\n                                  unsigned BuiltinID);\n  llvm::Value *EmitSVEPrefetchLoad(SVETypeFlags TypeFlags,\n                                   SmallVectorImpl<llvm::Value *> &Ops,\n                                   unsigned BuiltinID);\n  llvm::Value *EmitSVEGatherPrefetch(SVETypeFlags TypeFlags,\n                                     SmallVectorImpl<llvm::Value *> &Ops,\n                                     unsigned IntID);\n  llvm::Value *EmitSVEStructLoad(SVETypeFlags TypeFlags,\n                                 SmallVectorImpl<llvm::Value *> &Ops, unsigned IntID);\n  llvm::Value *EmitSVEStructStore(SVETypeFlags TypeFlags,\n                                  SmallVectorImpl<llvm::Value *> &Ops,\n                                  unsigned IntID);\n  llvm::Value *EmitAArch64SVEBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n\n  llvm::Value *EmitAArch64BuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                      llvm::Triple::ArchType Arch);\n  llvm::Value *EmitBPFBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n\n  llvm::Value *BuildVector(ArrayRef<llvm::Value*> Ops);\n  llvm::Value *EmitX86BuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitPPCBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitAMDGPUBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitSystemZBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitNVPTXBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitWebAssemblyBuiltinExpr(unsigned BuiltinID,\n                                          const CallExpr *E);\n  llvm::Value *EmitHexagonBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitRISCVBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                    ReturnValueSlot ReturnValue);\n  bool ProcessOrderScopeAMDGCN(llvm::Value *Order, llvm::Value *Scope,\n                               llvm::AtomicOrdering &AO,\n                               llvm::SyncScope::ID &SSID);\n\n  enum class MSVCIntrin;\n  llvm::Value *EmitMSVCBuiltinExpr(MSVCIntrin BuiltinID, const CallExpr *E);\n\n  llvm::Value *EmitBuiltinAvailable(const VersionTuple &Version);\n\n  llvm::Value *EmitObjCProtocolExpr(const ObjCProtocolExpr *E);\n  llvm::Value *EmitObjCStringLiteral(const ObjCStringLiteral *E);\n  llvm::Value *EmitObjCBoxedExpr(const ObjCBoxedExpr *E);\n  llvm::Value *EmitObjCArrayLiteral(const ObjCArrayLiteral *E);\n  llvm::Value *EmitObjCDictionaryLiteral(const ObjCDictionaryLiteral *E);\n  llvm::Value *EmitObjCCollectionLiteral(const Expr *E,\n                                const ObjCMethodDecl *MethodWithObjects);\n  llvm::Value *EmitObjCSelectorExpr(const ObjCSelectorExpr *E);\n  RValue EmitObjCMessageExpr(const ObjCMessageExpr *E,\n                             ReturnValueSlot Return = ReturnValueSlot());\n\n  /// Retrieves the default cleanup kind for an ARC cleanup.\n  /// Except under -fobjc-arc-eh, ARC cleanups are normal-only.\n  CleanupKind getARCCleanupKind() {\n    return CGM.getCodeGenOpts().ObjCAutoRefCountExceptions\n             ? NormalAndEHCleanup : NormalCleanup;\n  }\n\n  // ARC primitives.\n  void EmitARCInitWeak(Address addr, llvm::Value *value);\n  void EmitARCDestroyWeak(Address addr);\n  llvm::Value *EmitARCLoadWeak(Address addr);\n  llvm::Value *EmitARCLoadWeakRetained(Address addr);\n  llvm::Value *EmitARCStoreWeak(Address addr, llvm::Value *value, bool ignored);\n  void emitARCCopyAssignWeak(QualType Ty, Address DstAddr, Address SrcAddr);\n  void emitARCMoveAssignWeak(QualType Ty, Address DstAddr, Address SrcAddr);\n  void EmitARCCopyWeak(Address dst, Address src);\n  void EmitARCMoveWeak(Address dst, Address src);\n  llvm::Value *EmitARCRetainAutorelease(QualType type, llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleaseNonBlock(llvm::Value *value);\n  llvm::Value *EmitARCStoreStrong(LValue lvalue, llvm::Value *value,\n                                  bool resultIgnored);\n  llvm::Value *EmitARCStoreStrongCall(Address addr, llvm::Value *value,\n                                      bool resultIgnored);\n  llvm::Value *EmitARCRetain(QualType type, llvm::Value *value);\n  llvm::Value *EmitARCRetainNonBlock(llvm::Value *value);\n  llvm::Value *EmitARCRetainBlock(llvm::Value *value, bool mandatory);\n  void EmitARCDestroyStrong(Address addr, ARCPreciseLifetime_t precise);\n  void EmitARCRelease(llvm::Value *value, ARCPreciseLifetime_t precise);\n  llvm::Value *EmitARCAutorelease(llvm::Value *value);\n  llvm::Value *EmitARCAutoreleaseReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleaseReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleasedReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCUnsafeClaimAutoreleasedReturnValue(llvm::Value *value);\n\n  llvm::Value *EmitObjCAutorelease(llvm::Value *value, llvm::Type *returnType);\n  llvm::Value *EmitObjCRetainNonBlock(llvm::Value *value,\n                                      llvm::Type *returnType);\n  void EmitObjCRelease(llvm::Value *value, ARCPreciseLifetime_t precise);\n\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreAutoreleasing(const BinaryOperator *e);\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreStrong(const BinaryOperator *e, bool ignored);\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreUnsafeUnretained(const BinaryOperator *e, bool ignored);\n\n  llvm::Value *EmitObjCAlloc(llvm::Value *value,\n                             llvm::Type *returnType);\n  llvm::Value *EmitObjCAllocWithZone(llvm::Value *value,\n                                     llvm::Type *returnType);\n  llvm::Value *EmitObjCAllocInit(llvm::Value *value, llvm::Type *resultType);\n\n  llvm::Value *EmitObjCThrowOperand(const Expr *expr);\n  llvm::Value *EmitObjCConsumeObject(QualType T, llvm::Value *Ptr);\n  llvm::Value *EmitObjCExtendObjectLifetime(QualType T, llvm::Value *Ptr);\n\n  llvm::Value *EmitARCExtendBlockObject(const Expr *expr);\n  llvm::Value *EmitARCReclaimReturnedObject(const Expr *e,\n                                            bool allowUnsafeClaim);\n  llvm::Value *EmitARCRetainScalarExpr(const Expr *expr);\n  llvm::Value *EmitARCRetainAutoreleaseScalarExpr(const Expr *expr);\n  llvm::Value *EmitARCUnsafeUnretainedScalarExpr(const Expr *expr);\n\n  void EmitARCIntrinsicUse(ArrayRef<llvm::Value*> values);\n\n  void EmitARCNoopIntrinsicUse(ArrayRef<llvm::Value *> values);\n\n  static Destroyer destroyARCStrongImprecise;\n  static Destroyer destroyARCStrongPrecise;\n  static Destroyer destroyARCWeak;\n  static Destroyer emitARCIntrinsicUse;\n  static Destroyer destroyNonTrivialCStruct;\n\n  void EmitObjCAutoreleasePoolPop(llvm::Value *Ptr);\n  llvm::Value *EmitObjCAutoreleasePoolPush();\n  llvm::Value *EmitObjCMRRAutoreleasePoolPush();\n  void EmitObjCAutoreleasePoolCleanup(llvm::Value *Ptr);\n  void EmitObjCMRRAutoreleasePoolPop(llvm::Value *Ptr);\n\n  /// Emits a reference binding to the passed in expression.\n  RValue EmitReferenceBindingToExpr(const Expr *E);\n\n  //===--------------------------------------------------------------------===//\n  //                           Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  // Expressions are broken into three classes: scalar, complex, aggregate.\n\n  /// EmitScalarExpr - Emit the computation of the specified expression of LLVM\n  /// scalar type, returning the result.\n  llvm::Value *EmitScalarExpr(const Expr *E , bool IgnoreResultAssign = false);\n\n  /// Emit a conversion from the specified type to the specified destination\n  /// type, both of which are LLVM scalar types.\n  llvm::Value *EmitScalarConversion(llvm::Value *Src, QualType SrcTy,\n                                    QualType DstTy, SourceLocation Loc);\n\n  /// Emit a conversion from the specified complex type to the specified\n  /// destination type, where the destination type is an LLVM scalar type.\n  llvm::Value *EmitComplexToScalarConversion(ComplexPairTy Src, QualType SrcTy,\n                                             QualType DstTy,\n                                             SourceLocation Loc);\n\n  /// EmitAggExpr - Emit the computation of the specified expression\n  /// of aggregate type.  The result is computed into the given slot,\n  /// which may be null to indicate that the value is not needed.\n  void EmitAggExpr(const Expr *E, AggValueSlot AS);\n\n  /// EmitAggExprToLValue - Emit the computation of the specified expression of\n  /// aggregate type into a temporary LValue.\n  LValue EmitAggExprToLValue(const Expr *E);\n\n  /// Build all the stores needed to initialize an aggregate at Dest with the\n  /// value Val.\n  void EmitAggregateStore(llvm::Value *Val, Address Dest, bool DestIsVolatile);\n\n  /// EmitExtendGCLifetime - Given a pointer to an Objective-C object,\n  /// make sure it survives garbage collection until this point.\n  void EmitExtendGCLifetime(llvm::Value *object);\n\n  /// EmitComplexExpr - Emit the computation of the specified expression of\n  /// complex type, returning the result.\n  ComplexPairTy EmitComplexExpr(const Expr *E,\n                                bool IgnoreReal = false,\n                                bool IgnoreImag = false);\n\n  /// EmitComplexExprIntoLValue - Emit the given expression of complex\n  /// type and place its result into the specified l-value.\n  void EmitComplexExprIntoLValue(const Expr *E, LValue dest, bool isInit);\n\n  /// EmitStoreOfComplex - Store a complex number into the specified l-value.\n  void EmitStoreOfComplex(ComplexPairTy V, LValue dest, bool isInit);\n\n  /// EmitLoadOfComplex - Load a complex number from the specified l-value.\n  ComplexPairTy EmitLoadOfComplex(LValue src, SourceLocation loc);\n\n  Address emitAddrOfRealComponent(Address complex, QualType complexType);\n  Address emitAddrOfImagComponent(Address complex, QualType complexType);\n\n  /// AddInitializerToStaticVarDecl - Add the initializer for 'D' to the\n  /// global variable that has already been created for it.  If the initializer\n  /// has a different type than GV does, this may free GV and return a different\n  /// one.  Otherwise it just returns GV.\n  llvm::GlobalVariable *\n  AddInitializerToStaticVarDecl(const VarDecl &D,\n                                llvm::GlobalVariable *GV);\n\n  // Emit an @llvm.invariant.start call for the given memory region.\n  void EmitInvariantStart(llvm::Constant *Addr, CharUnits Size);\n\n  /// EmitCXXGlobalVarDeclInit - Create the initializer for a C++\n  /// variable with global storage.\n  void EmitCXXGlobalVarDeclInit(const VarDecl &D, llvm::Constant *DeclPtr,\n                                bool PerformInit);\n\n  llvm::Function *createAtExitStub(const VarDecl &VD, llvm::FunctionCallee Dtor,\n                                   llvm::Constant *Addr);\n\n  /// Call atexit() with a function that passes the given argument to\n  /// the given function.\n  void registerGlobalDtorWithAtExit(const VarDecl &D, llvm::FunctionCallee fn,\n                                    llvm::Constant *addr);\n\n  /// Call atexit() with function dtorStub.\n  void registerGlobalDtorWithAtExit(llvm::Constant *dtorStub);\n\n  /// Call unatexit() with function dtorStub.\n  llvm::Value *unregisterGlobalDtorWithUnAtExit(llvm::Constant *dtorStub);\n\n  /// Emit code in this function to perform a guarded variable\n  /// initialization.  Guarded initializations are used when it's not\n  /// possible to prove that an initialization will be done exactly\n  /// once, e.g. with a static local variable or a static data member\n  /// of a class template.\n  void EmitCXXGuardedInit(const VarDecl &D, llvm::GlobalVariable *DeclPtr,\n                          bool PerformInit);\n\n  enum class GuardKind { VariableGuard, TlsGuard };\n\n  /// Emit a branch to select whether or not to perform guarded initialization.\n  void EmitCXXGuardedInitBranch(llvm::Value *NeedsInit,\n                                llvm::BasicBlock *InitBlock,\n                                llvm::BasicBlock *NoInitBlock,\n                                GuardKind Kind, const VarDecl *D);\n\n  /// GenerateCXXGlobalInitFunc - Generates code for initializing global\n  /// variables.\n  void\n  GenerateCXXGlobalInitFunc(llvm::Function *Fn,\n                            ArrayRef<llvm::Function *> CXXThreadLocals,\n                            ConstantAddress Guard = ConstantAddress::invalid());\n\n  /// GenerateCXXGlobalCleanUpFunc - Generates code for cleaning up global\n  /// variables.\n  void GenerateCXXGlobalCleanUpFunc(\n      llvm::Function *Fn,\n      const std::vector<std::tuple<llvm::FunctionType *, llvm::WeakTrackingVH,\n                                   llvm::Constant *>> &DtorsOrStermFinalizers);\n\n  void GenerateCXXGlobalVarDeclInitFunc(llvm::Function *Fn,\n                                        const VarDecl *D,\n                                        llvm::GlobalVariable *Addr,\n                                        bool PerformInit);\n\n  void EmitCXXConstructExpr(const CXXConstructExpr *E, AggValueSlot Dest);\n\n  void EmitSynthesizedCXXCopyCtor(Address Dest, Address Src, const Expr *Exp);\n\n  void EmitCXXThrowExpr(const CXXThrowExpr *E, bool KeepInsertionPoint = true);\n\n  RValue EmitAtomicExpr(AtomicExpr *E);\n\n  //===--------------------------------------------------------------------===//\n  //                         Annotations Emission\n  //===--------------------------------------------------------------------===//\n\n  /// Emit an annotation call (intrinsic).\n  llvm::Value *EmitAnnotationCall(llvm::Function *AnnotationFn,\n                                  llvm::Value *AnnotatedVal,\n                                  StringRef AnnotationStr,\n                                  SourceLocation Location,\n                                  const AnnotateAttr *Attr);\n\n  /// Emit local annotations for the local variable V, declared by D.\n  void EmitVarAnnotations(const VarDecl *D, llvm::Value *V);\n\n  /// Emit field annotations for the given field & value. Returns the\n  /// annotation result.\n  Address EmitFieldAnnotations(const FieldDecl *D, Address V);\n\n  //===--------------------------------------------------------------------===//\n  //                             Internal Helpers\n  //===--------------------------------------------------------------------===//\n\n  /// ContainsLabel - Return true if the statement contains a label in it.  If\n  /// this statement is not executed normally, it not containing a label means\n  /// that we can just remove the code.\n  static bool ContainsLabel(const Stmt *S, bool IgnoreCaseStmts = false);\n\n  /// containsBreak - Return true if the statement contains a break out of it.\n  /// If the statement (recursively) contains a switch or loop with a break\n  /// inside of it, this is fine.\n  static bool containsBreak(const Stmt *S);\n\n  /// Determine if the given statement might introduce a declaration into the\n  /// current scope, by being a (possibly-labelled) DeclStmt.\n  static bool mightAddDeclToScope(const Stmt *S);\n\n  /// ConstantFoldsToSimpleInteger - If the specified expression does not fold\n  /// to a constant, or if it does but contains a label, return false.  If it\n  /// constant folds return true and set the boolean result in Result.\n  bool ConstantFoldsToSimpleInteger(const Expr *Cond, bool &Result,\n                                    bool AllowLabels = false);\n\n  /// ConstantFoldsToSimpleInteger - If the specified expression does not fold\n  /// to a constant, or if it does but contains a label, return false.  If it\n  /// constant folds return true and set the folded value.\n  bool ConstantFoldsToSimpleInteger(const Expr *Cond, llvm::APSInt &Result,\n                                    bool AllowLabels = false);\n\n  /// isInstrumentedCondition - Determine whether the given condition is an\n  /// instrumentable condition (i.e. no \"&&\" or \"||\").\n  static bool isInstrumentedCondition(const Expr *C);\n\n  /// EmitBranchToCounterBlock - Emit a conditional branch to a new block that\n  /// increments a profile counter based on the semantics of the given logical\n  /// operator opcode.  This is used to instrument branch condition coverage\n  /// for logical operators.\n  void EmitBranchToCounterBlock(const Expr *Cond, BinaryOperator::Opcode LOp,\n                                llvm::BasicBlock *TrueBlock,\n                                llvm::BasicBlock *FalseBlock,\n                                uint64_t TrueCount = 0,\n                                Stmt::Likelihood LH = Stmt::LH_None,\n                                const Expr *CntrIdx = nullptr);\n\n  /// EmitBranchOnBoolExpr - Emit a branch on a boolean condition (e.g. for an\n  /// if statement) to the specified blocks.  Based on the condition, this might\n  /// try to simplify the codegen of the conditional based on the branch.\n  /// TrueCount should be the number of times we expect the condition to\n  /// evaluate to true based on PGO data.\n  void EmitBranchOnBoolExpr(const Expr *Cond, llvm::BasicBlock *TrueBlock,\n                            llvm::BasicBlock *FalseBlock, uint64_t TrueCount,\n                            Stmt::Likelihood LH = Stmt::LH_None);\n\n  /// Given an assignment `*LHS = RHS`, emit a test that checks if \\p RHS is\n  /// nonnull, if \\p LHS is marked _Nonnull.\n  void EmitNullabilityCheck(LValue LHS, llvm::Value *RHS, SourceLocation Loc);\n\n  /// An enumeration which makes it easier to specify whether or not an\n  /// operation is a subtraction.\n  enum { NotSubtraction = false, IsSubtraction = true };\n\n  /// Same as IRBuilder::CreateInBoundsGEP, but additionally emits a check to\n  /// detect undefined behavior when the pointer overflow sanitizer is enabled.\n  /// \\p SignedIndices indicates whether any of the GEP indices are signed.\n  /// \\p IsSubtraction indicates whether the expression used to form the GEP\n  /// is a subtraction.\n  llvm::Value *EmitCheckedInBoundsGEP(llvm::Value *Ptr,\n                                      ArrayRef<llvm::Value *> IdxList,\n                                      bool SignedIndices,\n                                      bool IsSubtraction,\n                                      SourceLocation Loc,\n                                      const Twine &Name = \"\");\n\n  /// Specifies which type of sanitizer check to apply when handling a\n  /// particular builtin.\n  enum BuiltinCheckKind {\n    BCK_CTZPassedZero,\n    BCK_CLZPassedZero,\n  };\n\n  /// Emits an argument for a call to a builtin. If the builtin sanitizer is\n  /// enabled, a runtime check specified by \\p Kind is also emitted.\n  llvm::Value *EmitCheckedArgForBuiltin(const Expr *E, BuiltinCheckKind Kind);\n\n  /// Emit a description of a type in a format suitable for passing to\n  /// a runtime sanitizer handler.\n  llvm::Constant *EmitCheckTypeDescriptor(QualType T);\n\n  /// Convert a value into a format suitable for passing to a runtime\n  /// sanitizer handler.\n  llvm::Value *EmitCheckValue(llvm::Value *V);\n\n  /// Emit a description of a source location in a format suitable for\n  /// passing to a runtime sanitizer handler.\n  llvm::Constant *EmitCheckSourceLocation(SourceLocation Loc);\n\n  /// Create a basic block that will either trap or call a handler function in\n  /// the UBSan runtime with the provided arguments, and create a conditional\n  /// branch to it.\n  void EmitCheck(ArrayRef<std::pair<llvm::Value *, SanitizerMask>> Checked,\n                 SanitizerHandler Check, ArrayRef<llvm::Constant *> StaticArgs,\n                 ArrayRef<llvm::Value *> DynamicArgs);\n\n  /// Emit a slow path cross-DSO CFI check which calls __cfi_slowpath\n  /// if Cond if false.\n  void EmitCfiSlowPathCheck(SanitizerMask Kind, llvm::Value *Cond,\n                            llvm::ConstantInt *TypeId, llvm::Value *Ptr,\n                            ArrayRef<llvm::Constant *> StaticArgs);\n\n  /// Emit a reached-unreachable diagnostic if \\p Loc is valid and runtime\n  /// checking is enabled. Otherwise, just emit an unreachable instruction.\n  void EmitUnreachable(SourceLocation Loc);\n\n  /// Create a basic block that will call the trap intrinsic, and emit a\n  /// conditional branch to it, for the -ftrapv checks.\n  void EmitTrapCheck(llvm::Value *Checked, SanitizerHandler CheckHandlerID);\n\n  /// Emit a call to trap or debugtrap and attach function attribute\n  /// \"trap-func-name\" if specified.\n  llvm::CallInst *EmitTrapCall(llvm::Intrinsic::ID IntrID);\n\n  /// Emit a stub for the cross-DSO CFI check function.\n  void EmitCfiCheckStub();\n\n  /// Emit a cross-DSO CFI failure handling function.\n  void EmitCfiCheckFail();\n\n  /// Create a check for a function parameter that may potentially be\n  /// declared as non-null.\n  void EmitNonNullArgCheck(RValue RV, QualType ArgType, SourceLocation ArgLoc,\n                           AbstractCallee AC, unsigned ParmNum);\n\n  /// EmitCallArg - Emit a single call argument.\n  void EmitCallArg(CallArgList &args, const Expr *E, QualType ArgType);\n\n  /// EmitDelegateCallArg - We are performing a delegate call; that\n  /// is, the current function is delegating to another one.  Produce\n  /// a r-value suitable for passing the given parameter.\n  void EmitDelegateCallArg(CallArgList &args, const VarDecl *param,\n                           SourceLocation loc);\n\n  /// SetFPAccuracy - Set the minimum required accuracy of the given floating\n  /// point operation, expressed as the maximum relative error in ulp.\n  void SetFPAccuracy(llvm::Value *Val, float Accuracy);\n\n  /// SetFPModel - Control floating point behavior via fp-model settings.\n  void SetFPModel();\n\n  /// Set the codegen fast-math flags.\n  void SetFastMathFlags(FPOptions FPFeatures);\n\nprivate:\n  llvm::MDNode *getRangeForLoadFromType(QualType Ty);\n  void EmitReturnOfRValue(RValue RV, QualType Ty);\n\n  void deferPlaceholderReplacement(llvm::Instruction *Old, llvm::Value *New);\n\n  llvm::SmallVector<std::pair<llvm::WeakTrackingVH, llvm::Value *>, 4>\n      DeferredReplacements;\n\n  /// Set the address of a local variable.\n  void setAddrOfLocalVar(const VarDecl *VD, Address Addr) {\n    assert(!LocalDeclMap.count(VD) && \"Decl already exists in LocalDeclMap!\");\n    LocalDeclMap.insert({VD, Addr});\n  }\n\n  /// ExpandTypeFromArgs - Reconstruct a structure of type \\arg Ty\n  /// from function arguments into \\arg Dst. See ABIArgInfo::Expand.\n  ///\n  /// \\param AI - The first function argument of the expansion.\n  void ExpandTypeFromArgs(QualType Ty, LValue Dst,\n                          llvm::Function::arg_iterator &AI);\n\n  /// ExpandTypeToArgs - Expand an CallArg \\arg Arg, with the LLVM type for \\arg\n  /// Ty, into individual arguments on the provided vector \\arg IRCallArgs,\n  /// starting at index \\arg IRCallArgPos. See ABIArgInfo::Expand.\n  void ExpandTypeToArgs(QualType Ty, CallArg Arg, llvm::FunctionType *IRFuncTy,\n                        SmallVectorImpl<llvm::Value *> &IRCallArgs,\n                        unsigned &IRCallArgPos);\n\n  llvm::Value* EmitAsmInput(const TargetInfo::ConstraintInfo &Info,\n                            const Expr *InputExpr, std::string &ConstraintStr);\n\n  llvm::Value* EmitAsmInputLValue(const TargetInfo::ConstraintInfo &Info,\n                                  LValue InputValue, QualType InputType,\n                                  std::string &ConstraintStr,\n                                  SourceLocation Loc);\n\n  /// Attempts to statically evaluate the object size of E. If that\n  /// fails, emits code to figure the size of E out for us. This is\n  /// pass_object_size aware.\n  ///\n  /// If EmittedExpr is non-null, this will use that instead of re-emitting E.\n  llvm::Value *evaluateOrEmitBuiltinObjectSize(const Expr *E, unsigned Type,\n                                               llvm::IntegerType *ResType,\n                                               llvm::Value *EmittedE,\n                                               bool IsDynamic);\n\n  /// Emits the size of E, as required by __builtin_object_size. This\n  /// function is aware of pass_object_size parameters, and will act accordingly\n  /// if E is a parameter with the pass_object_size attribute.\n  llvm::Value *emitBuiltinObjectSize(const Expr *E, unsigned Type,\n                                     llvm::IntegerType *ResType,\n                                     llvm::Value *EmittedE,\n                                     bool IsDynamic);\n\n  void emitZeroOrPatternForAutoVarInit(QualType type, const VarDecl &D,\n                                       Address Loc);\n\npublic:\n  enum class EvaluationOrder {\n    ///! No language constraints on evaluation order.\n    Default,\n    ///! Language semantics require left-to-right evaluation.\n    ForceLeftToRight,\n    ///! Language semantics require right-to-left evaluation.\n    ForceRightToLeft\n  };\n\n  // Wrapper for function prototype sources. Wraps either a FunctionProtoType or\n  // an ObjCMethodDecl.\n  struct PrototypeWrapper {\n    llvm::PointerUnion<const FunctionProtoType *, const ObjCMethodDecl *> P;\n\n    PrototypeWrapper(const FunctionProtoType *FT) : P(FT) {}\n    PrototypeWrapper(const ObjCMethodDecl *MD) : P(MD) {}\n  };\n\n  void EmitCallArgs(CallArgList &Args, PrototypeWrapper Prototype,\n                    llvm::iterator_range<CallExpr::const_arg_iterator> ArgRange,\n                    AbstractCallee AC = AbstractCallee(),\n                    unsigned ParamsToSkip = 0,\n                    EvaluationOrder Order = EvaluationOrder::Default);\n\n  /// EmitPointerWithAlignment - Given an expression with a pointer type,\n  /// emit the value and compute our best estimate of the alignment of the\n  /// pointee.\n  ///\n  /// \\param BaseInfo - If non-null, this will be initialized with\n  /// information about the source of the alignment and the may-alias\n  /// attribute.  Note that this function will conservatively fall back on\n  /// the type when it doesn't recognize the expression and may-alias will\n  /// be set to false.\n  ///\n  /// One reasonable way to use this information is when there's a language\n  /// guarantee that the pointer must be aligned to some stricter value, and\n  /// we're simply trying to ensure that sufficiently obvious uses of under-\n  /// aligned objects don't get miscompiled; for example, a placement new\n  /// into the address of a local variable.  In such a case, it's quite\n  /// reasonable to just ignore the returned alignment when it isn't from an\n  /// explicit source.\n  Address EmitPointerWithAlignment(const Expr *Addr,\n                                   LValueBaseInfo *BaseInfo = nullptr,\n                                   TBAAAccessInfo *TBAAInfo = nullptr);\n\n  /// If \\p E references a parameter with pass_object_size info or a constant\n  /// array size modifier, emit the object size divided by the size of \\p EltTy.\n  /// Otherwise return null.\n  llvm::Value *LoadPassedObjectSize(const Expr *E, QualType EltTy);\n\n  void EmitSanitizerStatReport(llvm::SanitizerStatKind SSK);\n\n  struct MultiVersionResolverOption {\n    llvm::Function *Function;\n    FunctionDecl *FD;\n    struct Conds {\n      StringRef Architecture;\n      llvm::SmallVector<StringRef, 8> Features;\n\n      Conds(StringRef Arch, ArrayRef<StringRef> Feats)\n          : Architecture(Arch), Features(Feats.begin(), Feats.end()) {}\n    } Conditions;\n\n    MultiVersionResolverOption(llvm::Function *F, StringRef Arch,\n                               ArrayRef<StringRef> Feats)\n        : Function(F), Conditions(Arch, Feats) {}\n  };\n\n  // Emits the body of a multiversion function's resolver. Assumes that the\n  // options are already sorted in the proper order, with the 'default' option\n  // last (if it exists).\n  void EmitMultiVersionResolver(llvm::Function *Resolver,\n                                ArrayRef<MultiVersionResolverOption> Options);\n\n  static uint64_t GetX86CpuSupportsMask(ArrayRef<StringRef> FeatureStrs);\n\nprivate:\n  QualType getVarArgType(const Expr *Arg);\n\n  void EmitDeclMetadata();\n\n  BlockByrefHelpers *buildByrefHelpers(llvm::StructType &byrefType,\n                                  const AutoVarEmission &emission);\n\n  void AddObjCARCExceptionMetadata(llvm::Instruction *Inst);\n\n  llvm::Value *GetValueForARMHint(unsigned BuiltinID);\n  llvm::Value *EmitX86CpuIs(const CallExpr *E);\n  llvm::Value *EmitX86CpuIs(StringRef CPUStr);\n  llvm::Value *EmitX86CpuSupports(const CallExpr *E);\n  llvm::Value *EmitX86CpuSupports(ArrayRef<StringRef> FeatureStrs);\n  llvm::Value *EmitX86CpuSupports(uint64_t Mask);\n  llvm::Value *EmitX86CpuInit();\n  llvm::Value *FormResolverCondition(const MultiVersionResolverOption &RO);\n};\n\n/// TargetFeatures - This class is used to check whether the builtin function\n/// has the required tagert specific features. It is able to support the\n/// combination of ','(and), '|'(or), and '()'. By default, the priority of\n/// ',' is higher than that of '|' .\n/// E.g:\n/// A,B|C means the builtin function requires both A and B, or C.\n/// If we want the builtin function requires both A and B, or both A and C,\n/// there are two ways: A,B|A,C or A,(B|C).\n/// The FeaturesList should not contain spaces, and brackets must appear in\n/// pairs.\nclass TargetFeatures {\n  struct FeatureListStatus {\n    bool HasFeatures;\n    StringRef CurFeaturesList;\n  };\n\n  const llvm::StringMap<bool> &CallerFeatureMap;\n\n  FeatureListStatus getAndFeatures(StringRef FeatureList) {\n    int InParentheses = 0;\n    bool HasFeatures = true;\n    size_t SubexpressionStart = 0;\n    for (size_t i = 0, e = FeatureList.size(); i < e; ++i) {\n      char CurrentToken = FeatureList[i];\n      switch (CurrentToken) {\n      default:\n        break;\n      case '(':\n        if (InParentheses == 0)\n          SubexpressionStart = i + 1;\n        ++InParentheses;\n        break;\n      case ')':\n        --InParentheses;\n        assert(InParentheses >= 0 && \"Parentheses are not in pair\");\n        LLVM_FALLTHROUGH;\n      case '|':\n      case ',':\n        if (InParentheses == 0) {\n          if (HasFeatures && i != SubexpressionStart) {\n            StringRef F = FeatureList.slice(SubexpressionStart, i);\n            HasFeatures = CurrentToken == ')' ? hasRequiredFeatures(F)\n                                              : CallerFeatureMap.lookup(F);\n          }\n          SubexpressionStart = i + 1;\n          if (CurrentToken == '|') {\n            return {HasFeatures, FeatureList.substr(SubexpressionStart)};\n          }\n        }\n        break;\n      }\n    }\n    assert(InParentheses == 0 && \"Parentheses are not in pair\");\n    if (HasFeatures && SubexpressionStart != FeatureList.size())\n      HasFeatures =\n          CallerFeatureMap.lookup(FeatureList.substr(SubexpressionStart));\n    return {HasFeatures, StringRef()};\n  }\n\npublic:\n  bool hasRequiredFeatures(StringRef FeatureList) {\n    FeatureListStatus FS = {false, FeatureList};\n    while (!FS.HasFeatures && !FS.CurFeaturesList.empty())\n      FS = getAndFeatures(FS.CurFeaturesList);\n    return FS.HasFeatures;\n  }\n\n  TargetFeatures(const llvm::StringMap<bool> &CallerFeatureMap)\n      : CallerFeatureMap(CallerFeatureMap) {}\n};\n\ninline DominatingLLVMValue::saved_type\nDominatingLLVMValue::save(CodeGenFunction &CGF, llvm::Value *value) {\n  if (!needsSaving(value)) return saved_type(value, false);\n\n  // Otherwise, we need an alloca.\n  auto align = CharUnits::fromQuantity(\n            CGF.CGM.getDataLayout().getPrefTypeAlignment(value->getType()));\n  Address alloca =\n    CGF.CreateTempAlloca(value->getType(), align, \"cond-cleanup.save\");\n  CGF.Builder.CreateStore(value, alloca);\n\n  return saved_type(alloca.getPointer(), true);\n}\n\ninline llvm::Value *DominatingLLVMValue::restore(CodeGenFunction &CGF,\n                                                 saved_type value) {\n  // If the value says it wasn't saved, trust that it's still dominating.\n  if (!value.getInt()) return value.getPointer();\n\n  // Otherwise, it should be an alloca instruction, as set up in save().\n  auto alloca = cast<llvm::AllocaInst>(value.getPointer());\n  return CGF.Builder.CreateAlignedLoad(alloca, alloca->getAlign());\n}\n\n}  // end namespace CodeGen\n\n// Map the LangOption for floating point exception behavior into\n// the corresponding enum in the IR.\nllvm::fp::ExceptionBehavior\nToConstrainedExceptMD(LangOptions::FPExceptionModeKind Kind);\n}  // end namespace clang\n\n#endif\n"}, "40": {"id": 40, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/EHScopeStack.h", "content": "//===-- EHScopeStack.h - Stack for cleanup IR generation --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// These classes should be the minimum interface required for other parts of\n// CodeGen to emit cleanups.  The implementation is in CGCleanup.cpp and other\n// implemenentation details that are not widely needed are in CGCleanup.h.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_EHSCOPESTACK_H\n#define LLVM_CLANG_LIB_CODEGEN_EHSCOPESTACK_H\n\n#include \"clang/Basic/LLVM.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/Value.h\"\n\nnamespace clang {\nnamespace CodeGen {\n\nclass CodeGenFunction;\n\n/// A branch fixup.  These are required when emitting a goto to a\n/// label which hasn't been emitted yet.  The goto is optimistically\n/// emitted as a branch to the basic block for the label, and (if it\n/// occurs in a scope with non-trivial cleanups) a fixup is added to\n/// the innermost cleanup.  When a (normal) cleanup is popped, any\n/// unresolved fixups in that scope are threaded through the cleanup.\nstruct BranchFixup {\n  /// The block containing the terminator which needs to be modified\n  /// into a switch if this fixup is resolved into the current scope.\n  /// If null, LatestBranch points directly to the destination.\n  llvm::BasicBlock *OptimisticBranchBlock;\n\n  /// The ultimate destination of the branch.\n  ///\n  /// This can be set to null to indicate that this fixup was\n  /// successfully resolved.\n  llvm::BasicBlock *Destination;\n\n  /// The destination index value.\n  unsigned DestinationIndex;\n\n  /// The initial branch of the fixup.\n  llvm::BranchInst *InitialBranch;\n};\n\ntemplate <class T> struct InvariantValue {\n  typedef T type;\n  typedef T saved_type;\n  static bool needsSaving(type value) { return false; }\n  static saved_type save(CodeGenFunction &CGF, type value) { return value; }\n  static type restore(CodeGenFunction &CGF, saved_type value) { return value; }\n};\n\n/// A metaprogramming class for ensuring that a value will dominate an\n/// arbitrary position in a function.\ntemplate <class T> struct DominatingValue : InvariantValue<T> {};\n\ntemplate <class T, bool mightBeInstruction =\n            std::is_base_of<llvm::Value, T>::value &&\n            !std::is_base_of<llvm::Constant, T>::value &&\n            !std::is_base_of<llvm::BasicBlock, T>::value>\nstruct DominatingPointer;\ntemplate <class T> struct DominatingPointer<T,false> : InvariantValue<T*> {};\n// template <class T> struct DominatingPointer<T,true> at end of file\n\ntemplate <class T> struct DominatingValue<T*> : DominatingPointer<T> {};\n\nenum CleanupKind : unsigned {\n  /// Denotes a cleanup that should run when a scope is exited using exceptional\n  /// control flow (a throw statement leading to stack unwinding, ).\n  EHCleanup = 0x1,\n\n  /// Denotes a cleanup that should run when a scope is exited using normal\n  /// control flow (falling off the end of the scope, return, goto, ...).\n  NormalCleanup = 0x2,\n\n  NormalAndEHCleanup = EHCleanup | NormalCleanup,\n\n  LifetimeMarker = 0x8,\n  NormalEHLifetimeMarker = LifetimeMarker | NormalAndEHCleanup,\n};\n\n/// A stack of scopes which respond to exceptions, including cleanups\n/// and catch blocks.\nclass EHScopeStack {\npublic:\n  /* Should switch to alignof(uint64_t) instead of 8, when EHCleanupScope can */\n  enum { ScopeStackAlignment = 8 };\n\n  /// A saved depth on the scope stack.  This is necessary because\n  /// pushing scopes onto the stack invalidates iterators.\n  class stable_iterator {\n    friend class EHScopeStack;\n\n    /// Offset from StartOfData to EndOfBuffer.\n    ptrdiff_t Size;\n\n    stable_iterator(ptrdiff_t Size) : Size(Size) {}\n\n  public:\n    static stable_iterator invalid() { return stable_iterator(-1); }\n    stable_iterator() : Size(-1) {}\n\n    bool isValid() const { return Size >= 0; }\n\n    /// Returns true if this scope encloses I.\n    /// Returns false if I is invalid.\n    /// This scope must be valid.\n    bool encloses(stable_iterator I) const { return Size <= I.Size; }\n\n    /// Returns true if this scope strictly encloses I: that is,\n    /// if it encloses I and is not I.\n    /// Returns false is I is invalid.\n    /// This scope must be valid.\n    bool strictlyEncloses(stable_iterator I) const { return Size < I.Size; }\n\n    friend bool operator==(stable_iterator A, stable_iterator B) {\n      return A.Size == B.Size;\n    }\n    friend bool operator!=(stable_iterator A, stable_iterator B) {\n      return A.Size != B.Size;\n    }\n  };\n\n  /// Information for lazily generating a cleanup.  Subclasses must be\n  /// POD-like: cleanups will not be destructed, and they will be\n  /// allocated on the cleanup stack and freely copied and moved\n  /// around.\n  ///\n  /// Cleanup implementations should generally be declared in an\n  /// anonymous namespace.\n  class Cleanup {\n    // Anchor the construction vtable.\n    virtual void anchor();\n\n  protected:\n    ~Cleanup() = default;\n\n  public:\n    Cleanup(const Cleanup &) = default;\n    Cleanup(Cleanup &&) {}\n    Cleanup() = default;\n\n    /// Generation flags.\n    class Flags {\n      enum {\n        F_IsForEH = 0x1,\n        F_IsNormalCleanupKind = 0x2,\n        F_IsEHCleanupKind = 0x4,\n        F_HasExitSwitch = 0x8,\n      };\n      unsigned flags;\n\n    public:\n      Flags() : flags(0) {}\n\n      /// isForEH - true if the current emission is for an EH cleanup.\n      bool isForEHCleanup() const { return flags & F_IsForEH; }\n      bool isForNormalCleanup() const { return !isForEHCleanup(); }\n      void setIsForEHCleanup() { flags |= F_IsForEH; }\n\n      bool isNormalCleanupKind() const { return flags & F_IsNormalCleanupKind; }\n      void setIsNormalCleanupKind() { flags |= F_IsNormalCleanupKind; }\n\n      /// isEHCleanupKind - true if the cleanup was pushed as an EH\n      /// cleanup.\n      bool isEHCleanupKind() const { return flags & F_IsEHCleanupKind; }\n      void setIsEHCleanupKind() { flags |= F_IsEHCleanupKind; }\n\n      bool hasExitSwitch() const { return flags & F_HasExitSwitch; }\n      void setHasExitSwitch() { flags |= F_HasExitSwitch; }\n    };\n\n    /// Emit the cleanup.  For normal cleanups, this is run in the\n    /// same EH context as when the cleanup was pushed, i.e. the\n    /// immediately-enclosing context of the cleanup scope.  For\n    /// EH cleanups, this is run in a terminate context.\n    ///\n    // \\param flags cleanup kind.\n    virtual void Emit(CodeGenFunction &CGF, Flags flags) = 0;\n  };\n\n  /// ConditionalCleanup stores the saved form of its parameters,\n  /// then restores them and performs the cleanup.\n  template <class T, class... As>\n  class ConditionalCleanup final : public Cleanup {\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved;\n\n    template <std::size_t... Is>\n    T restore(CodeGenFunction &CGF, std::index_sequence<Is...>) {\n      // It's important that the restores are emitted in order. The braced init\n      // list guarantees that.\n      return T{DominatingValue<As>::restore(CGF, std::get<Is>(Saved))...};\n    }\n\n    void Emit(CodeGenFunction &CGF, Flags flags) override {\n      restore(CGF, std::index_sequence_for<As...>()).Emit(CGF, flags);\n    }\n\n  public:\n    ConditionalCleanup(typename DominatingValue<As>::saved_type... A)\n        : Saved(A...) {}\n\n    ConditionalCleanup(SavedTuple Tuple) : Saved(std::move(Tuple)) {}\n  };\n\nprivate:\n  // The implementation for this class is in CGException.h and\n  // CGException.cpp; the definition is here because it's used as a\n  // member of CodeGenFunction.\n\n  /// The start of the scope-stack buffer, i.e. the allocated pointer\n  /// for the buffer.  All of these pointers are either simultaneously\n  /// null or simultaneously valid.\n  char *StartOfBuffer;\n\n  /// The end of the buffer.\n  char *EndOfBuffer;\n\n  /// The first valid entry in the buffer.\n  char *StartOfData;\n\n  /// The innermost normal cleanup on the stack.\n  stable_iterator InnermostNormalCleanup;\n\n  /// The innermost EH scope on the stack.\n  stable_iterator InnermostEHScope;\n\n  /// The current set of branch fixups.  A branch fixup is a jump to\n  /// an as-yet unemitted label, i.e. a label for which we don't yet\n  /// know the EH stack depth.  Whenever we pop a cleanup, we have\n  /// to thread all the current branch fixups through it.\n  ///\n  /// Fixups are recorded as the Use of the respective branch or\n  /// switch statement.  The use points to the final destination.\n  /// When popping out of a cleanup, these uses are threaded through\n  /// the cleanup and adjusted to point to the new cleanup.\n  ///\n  /// Note that branches are allowed to jump into protected scopes\n  /// in certain situations;  e.g. the following code is legal:\n  ///     struct A { ~A(); }; // trivial ctor, non-trivial dtor\n  ///     goto foo;\n  ///     A a;\n  ///    foo:\n  ///     bar();\n  SmallVector<BranchFixup, 8> BranchFixups;\n\n  char *allocate(size_t Size);\n  void deallocate(size_t Size);\n\n  void *pushCleanup(CleanupKind K, size_t DataSize);\n\npublic:\n  EHScopeStack() : StartOfBuffer(nullptr), EndOfBuffer(nullptr),\n                   StartOfData(nullptr), InnermostNormalCleanup(stable_end()),\n                   InnermostEHScope(stable_end()) {}\n  ~EHScopeStack() { delete[] StartOfBuffer; }\n\n  /// Push a lazily-created cleanup on the stack.\n  template <class T, class... As> void pushCleanup(CleanupKind Kind, As... A) {\n    static_assert(alignof(T) <= ScopeStackAlignment,\n                  \"Cleanup's alignment is too large.\");\n    void *Buffer = pushCleanup(Kind, sizeof(T));\n    Cleanup *Obj = new (Buffer) T(A...);\n    (void) Obj;\n  }\n\n  /// Push a lazily-created cleanup on the stack. Tuple version.\n  template <class T, class... As>\n  void pushCleanupTuple(CleanupKind Kind, std::tuple<As...> A) {\n    static_assert(alignof(T) <= ScopeStackAlignment,\n                  \"Cleanup's alignment is too large.\");\n    void *Buffer = pushCleanup(Kind, sizeof(T));\n    Cleanup *Obj = new (Buffer) T(std::move(A));\n    (void) Obj;\n  }\n\n  // Feel free to add more variants of the following:\n\n  /// Push a cleanup with non-constant storage requirements on the\n  /// stack.  The cleanup type must provide an additional static method:\n  ///   static size_t getExtraSize(size_t);\n  /// The argument to this method will be the value N, which will also\n  /// be passed as the first argument to the constructor.\n  ///\n  /// The data stored in the extra storage must obey the same\n  /// restrictions as normal cleanup member data.\n  ///\n  /// The pointer returned from this method is valid until the cleanup\n  /// stack is modified.\n  template <class T, class... As>\n  T *pushCleanupWithExtra(CleanupKind Kind, size_t N, As... A) {\n    static_assert(alignof(T) <= ScopeStackAlignment,\n                  \"Cleanup's alignment is too large.\");\n    void *Buffer = pushCleanup(Kind, sizeof(T) + T::getExtraSize(N));\n    return new (Buffer) T(N, A...);\n  }\n\n  void pushCopyOfCleanup(CleanupKind Kind, const void *Cleanup, size_t Size) {\n    void *Buffer = pushCleanup(Kind, Size);\n    std::memcpy(Buffer, Cleanup, Size);\n  }\n\n  /// Pops a cleanup scope off the stack.  This is private to CGCleanup.cpp.\n  void popCleanup();\n\n  /// Push a set of catch handlers on the stack.  The catch is\n  /// uninitialized and will need to have the given number of handlers\n  /// set on it.\n  class EHCatchScope *pushCatch(unsigned NumHandlers);\n\n  /// Pops a catch scope off the stack.  This is private to CGException.cpp.\n  void popCatch();\n\n  /// Push an exceptions filter on the stack.\n  class EHFilterScope *pushFilter(unsigned NumFilters);\n\n  /// Pops an exceptions filter off the stack.\n  void popFilter();\n\n  /// Push a terminate handler on the stack.\n  void pushTerminate();\n\n  /// Pops a terminate handler off the stack.\n  void popTerminate();\n\n  // Returns true iff the current scope is either empty or contains only\n  // lifetime markers, i.e. no real cleanup code\n  bool containsOnlyLifetimeMarkers(stable_iterator Old) const;\n\n  /// Determines whether the exception-scopes stack is empty.\n  bool empty() const { return StartOfData == EndOfBuffer; }\n\n  bool requiresLandingPad() const;\n\n  /// Determines whether there are any normal cleanups on the stack.\n  bool hasNormalCleanups() const {\n    return InnermostNormalCleanup != stable_end();\n  }\n\n  /// Returns the innermost normal cleanup on the stack, or\n  /// stable_end() if there are no normal cleanups.\n  stable_iterator getInnermostNormalCleanup() const {\n    return InnermostNormalCleanup;\n  }\n  stable_iterator getInnermostActiveNormalCleanup() const;\n\n  stable_iterator getInnermostEHScope() const {\n    return InnermostEHScope;\n  }\n\n\n  /// An unstable reference to a scope-stack depth.  Invalidated by\n  /// pushes but not pops.\n  class iterator;\n\n  /// Returns an iterator pointing to the innermost EH scope.\n  iterator begin() const;\n\n  /// Returns an iterator pointing to the outermost EH scope.\n  iterator end() const;\n\n  /// Create a stable reference to the top of the EH stack.  The\n  /// returned reference is valid until that scope is popped off the\n  /// stack.\n  stable_iterator stable_begin() const {\n    return stable_iterator(EndOfBuffer - StartOfData);\n  }\n\n  /// Create a stable reference to the bottom of the EH stack.\n  static stable_iterator stable_end() {\n    return stable_iterator(0);\n  }\n\n  /// Translates an iterator into a stable_iterator.\n  stable_iterator stabilize(iterator it) const;\n\n  /// Turn a stable reference to a scope depth into a unstable pointer\n  /// to the EH stack.\n  iterator find(stable_iterator save) const;\n\n  /// Add a branch fixup to the current cleanup scope.\n  BranchFixup &addBranchFixup() {\n    assert(hasNormalCleanups() && \"adding fixup in scope without cleanups\");\n    BranchFixups.push_back(BranchFixup());\n    return BranchFixups.back();\n  }\n\n  unsigned getNumBranchFixups() const { return BranchFixups.size(); }\n  BranchFixup &getBranchFixup(unsigned I) {\n    assert(I < getNumBranchFixups());\n    return BranchFixups[I];\n  }\n\n  /// Pops lazily-removed fixups from the end of the list.  This\n  /// should only be called by procedures which have just popped a\n  /// cleanup or resolved one or more fixups.\n  void popNullFixups();\n\n  /// Clears the branch-fixups list.  This should only be called by\n  /// ResolveAllBranchFixups.\n  void clearFixups() { BranchFixups.clear(); }\n};\n\n} // namespace CodeGen\n} // namespace clang\n\n#endif\n"}, "50": {"id": 50, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ADT/STLExtras.h", "content": "//===- llvm/ADT/STLExtras.h - Useful STL related functions ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file contains some templates that are useful if you are working with the\n// STL at all.\n//\n// No library is required when using these functions.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_ADT_STLEXTRAS_H\n#define LLVM_ADT_STLEXTRAS_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/iterator.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Config/abi-breaking.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <cstdlib>\n#include <functional>\n#include <initializer_list>\n#include <iterator>\n#include <limits>\n#include <memory>\n#include <tuple>\n#include <type_traits>\n#include <utility>\n\n#ifdef EXPENSIVE_CHECKS\n#include <random> // for std::mt19937\n#endif\n\nnamespace llvm {\n\n// Only used by compiler if both template types are the same.  Useful when\n// using SFINAE to test for the existence of member functions.\ntemplate <typename T, T> struct SameType;\n\nnamespace detail {\n\ntemplate <typename RangeT>\nusing IterOfRange = decltype(std::begin(std::declval<RangeT &>()));\n\ntemplate <typename RangeT>\nusing ValueOfRange = typename std::remove_reference<decltype(\n    *std::begin(std::declval<RangeT &>()))>::type;\n\n} // end namespace detail\n\n//===----------------------------------------------------------------------===//\n//     Extra additions to <type_traits>\n//===----------------------------------------------------------------------===//\n\ntemplate <typename T>\nstruct negation : std::integral_constant<bool, !bool(T::value)> {};\n\ntemplate <typename...> struct conjunction : std::true_type {};\ntemplate <typename B1> struct conjunction<B1> : B1 {};\ntemplate <typename B1, typename... Bn>\nstruct conjunction<B1, Bn...>\n    : std::conditional<bool(B1::value), conjunction<Bn...>, B1>::type {};\n\ntemplate <typename T> struct make_const_ptr {\n  using type =\n      typename std::add_pointer<typename std::add_const<T>::type>::type;\n};\n\ntemplate <typename T> struct make_const_ref {\n  using type = typename std::add_lvalue_reference<\n      typename std::add_const<T>::type>::type;\n};\n\n/// Utilities for detecting if a given trait holds for some set of arguments\n/// 'Args'. For example, the given trait could be used to detect if a given type\n/// has a copy assignment operator:\n///   template<class T>\n///   using has_copy_assign_t = decltype(std::declval<T&>()\n///                                                 = std::declval<const T&>());\n///   bool fooHasCopyAssign = is_detected<has_copy_assign_t, FooClass>::value;\nnamespace detail {\ntemplate <typename...> using void_t = void;\ntemplate <class, template <class...> class Op, class... Args> struct detector {\n  using value_t = std::false_type;\n};\ntemplate <template <class...> class Op, class... Args>\nstruct detector<void_t<Op<Args...>>, Op, Args...> {\n  using value_t = std::true_type;\n};\n} // end namespace detail\n\ntemplate <template <class...> class Op, class... Args>\nusing is_detected = typename detail::detector<void, Op, Args...>::value_t;\n\n/// Check if a Callable type can be invoked with the given set of arg types.\nnamespace detail {\ntemplate <typename Callable, typename... Args>\nusing is_invocable =\n    decltype(std::declval<Callable &>()(std::declval<Args>()...));\n} // namespace detail\n\ntemplate <typename Callable, typename... Args>\nusing is_invocable = is_detected<detail::is_invocable, Callable, Args...>;\n\n/// This class provides various trait information about a callable object.\n///   * To access the number of arguments: Traits::num_args\n///   * To access the type of an argument: Traits::arg_t<Index>\n///   * To access the type of the result:  Traits::result_t\ntemplate <typename T, bool isClass = std::is_class<T>::value>\nstruct function_traits : public function_traits<decltype(&T::operator())> {};\n\n/// Overload for class function types.\ntemplate <typename ClassType, typename ReturnType, typename... Args>\nstruct function_traits<ReturnType (ClassType::*)(Args...) const, false> {\n  /// The number of arguments to this function.\n  enum { num_args = sizeof...(Args) };\n\n  /// The result type of this function.\n  using result_t = ReturnType;\n\n  /// The type of an argument to this function.\n  template <size_t Index>\n  using arg_t = typename std::tuple_element<Index, std::tuple<Args...>>::type;\n};\n/// Overload for class function types.\ntemplate <typename ClassType, typename ReturnType, typename... Args>\nstruct function_traits<ReturnType (ClassType::*)(Args...), false>\n    : function_traits<ReturnType (ClassType::*)(Args...) const> {};\n/// Overload for non-class function types.\ntemplate <typename ReturnType, typename... Args>\nstruct function_traits<ReturnType (*)(Args...), false> {\n  /// The number of arguments to this function.\n  enum { num_args = sizeof...(Args) };\n\n  /// The result type of this function.\n  using result_t = ReturnType;\n\n  /// The type of an argument to this function.\n  template <size_t i>\n  using arg_t = typename std::tuple_element<i, std::tuple<Args...>>::type;\n};\n/// Overload for non-class function type references.\ntemplate <typename ReturnType, typename... Args>\nstruct function_traits<ReturnType (&)(Args...), false>\n    : public function_traits<ReturnType (*)(Args...)> {};\n\n//===----------------------------------------------------------------------===//\n//     Extra additions to <functional>\n//===----------------------------------------------------------------------===//\n\ntemplate <class Ty> struct identity {\n  using argument_type = Ty;\n\n  Ty &operator()(Ty &self) const {\n    return self;\n  }\n  const Ty &operator()(const Ty &self) const {\n    return self;\n  }\n};\n\n/// An efficient, type-erasing, non-owning reference to a callable. This is\n/// intended for use as the type of a function parameter that is not used\n/// after the function in question returns.\n///\n/// This class does not own the callable, so it is not in general safe to store\n/// a function_ref.\ntemplate<typename Fn> class function_ref;\n\ntemplate<typename Ret, typename ...Params>\nclass function_ref<Ret(Params...)> {\n  Ret (*callback)(intptr_t callable, Params ...params) = nullptr;\n  intptr_t callable;\n\n  template<typename Callable>\n  static Ret callback_fn(intptr_t callable, Params ...params) {\n    return (*reinterpret_cast<Callable*>(callable))(\n        std::forward<Params>(params)...);\n  }\n\npublic:\n  function_ref() = default;\n  function_ref(std::nullptr_t) {}\n\n  template <typename Callable>\n  function_ref(\n      Callable &&callable,\n      // This is not the copy-constructor.\n      std::enable_if_t<\n          !std::is_same<std::remove_cv_t<std::remove_reference_t<Callable>>,\n                        function_ref>::value> * = nullptr,\n      // Functor must be callable and return a suitable type.\n      std::enable_if_t<std::is_void<Ret>::value ||\n                       std::is_convertible<decltype(std::declval<Callable>()(\n                                               std::declval<Params>()...)),\n                                           Ret>::value> * = nullptr)\n      : callback(callback_fn<typename std::remove_reference<Callable>::type>),\n        callable(reinterpret_cast<intptr_t>(&callable)) {}\n\n  Ret operator()(Params ...params) const {\n    return callback(callable, std::forward<Params>(params)...);\n  }\n\n  explicit operator bool() const { return callback; }\n};\n\n//===----------------------------------------------------------------------===//\n//     Extra additions to <iterator>\n//===----------------------------------------------------------------------===//\n\nnamespace adl_detail {\n\nusing std::begin;\n\ntemplate <typename ContainerTy>\ndecltype(auto) adl_begin(ContainerTy &&container) {\n  return begin(std::forward<ContainerTy>(container));\n}\n\nusing std::end;\n\ntemplate <typename ContainerTy>\ndecltype(auto) adl_end(ContainerTy &&container) {\n  return end(std::forward<ContainerTy>(container));\n}\n\nusing std::swap;\n\ntemplate <typename T>\nvoid adl_swap(T &&lhs, T &&rhs) noexcept(noexcept(swap(std::declval<T>(),\n                                                       std::declval<T>()))) {\n  swap(std::forward<T>(lhs), std::forward<T>(rhs));\n}\n\n} // end namespace adl_detail\n\ntemplate <typename ContainerTy>\ndecltype(auto) adl_begin(ContainerTy &&container) {\n  return adl_detail::adl_begin(std::forward<ContainerTy>(container));\n}\n\ntemplate <typename ContainerTy>\ndecltype(auto) adl_end(ContainerTy &&container) {\n  return adl_detail::adl_end(std::forward<ContainerTy>(container));\n}\n\ntemplate <typename T>\nvoid adl_swap(T &&lhs, T &&rhs) noexcept(\n    noexcept(adl_detail::adl_swap(std::declval<T>(), std::declval<T>()))) {\n  adl_detail::adl_swap(std::forward<T>(lhs), std::forward<T>(rhs));\n}\n\n/// Test whether \\p RangeOrContainer is empty. Similar to C++17 std::empty.\ntemplate <typename T>\nconstexpr bool empty(const T &RangeOrContainer) {\n  return adl_begin(RangeOrContainer) == adl_end(RangeOrContainer);\n}\n\n/// Returns true if the given container only contains a single element.\ntemplate <typename ContainerTy> bool hasSingleElement(ContainerTy &&C) {\n  auto B = std::begin(C), E = std::end(C);\n  return B != E && std::next(B) == E;\n}\n\n/// Return a range covering \\p RangeOrContainer with the first N elements\n/// excluded.\ntemplate <typename T> auto drop_begin(T &&RangeOrContainer, size_t N = 1) {\n  return make_range(std::next(adl_begin(RangeOrContainer), N),\n                    adl_end(RangeOrContainer));\n}\n\n// mapped_iterator - This is a simple iterator adapter that causes a function to\n// be applied whenever operator* is invoked on the iterator.\n\ntemplate <typename ItTy, typename FuncTy,\n          typename FuncReturnTy =\n            decltype(std::declval<FuncTy>()(*std::declval<ItTy>()))>\nclass mapped_iterator\n    : public iterator_adaptor_base<\n             mapped_iterator<ItTy, FuncTy>, ItTy,\n             typename std::iterator_traits<ItTy>::iterator_category,\n             typename std::remove_reference<FuncReturnTy>::type> {\npublic:\n  mapped_iterator(ItTy U, FuncTy F)\n    : mapped_iterator::iterator_adaptor_base(std::move(U)), F(std::move(F)) {}\n\n  ItTy getCurrent() { return this->I; }\n\n  FuncReturnTy operator*() const { return F(*this->I); }\n\nprivate:\n  FuncTy F;\n};\n\n// map_iterator - Provide a convenient way to create mapped_iterators, just like\n// make_pair is useful for creating pairs...\ntemplate <class ItTy, class FuncTy>\ninline mapped_iterator<ItTy, FuncTy> map_iterator(ItTy I, FuncTy F) {\n  return mapped_iterator<ItTy, FuncTy>(std::move(I), std::move(F));\n}\n\ntemplate <class ContainerTy, class FuncTy>\nauto map_range(ContainerTy &&C, FuncTy F) {\n  return make_range(map_iterator(C.begin(), F), map_iterator(C.end(), F));\n}\n\n/// Helper to determine if type T has a member called rbegin().\ntemplate <typename Ty> class has_rbegin_impl {\n  using yes = char[1];\n  using no = char[2];\n\n  template <typename Inner>\n  static yes& test(Inner *I, decltype(I->rbegin()) * = nullptr);\n\n  template <typename>\n  static no& test(...);\n\npublic:\n  static const bool value = sizeof(test<Ty>(nullptr)) == sizeof(yes);\n};\n\n/// Metafunction to determine if T& or T has a member called rbegin().\ntemplate <typename Ty>\nstruct has_rbegin : has_rbegin_impl<typename std::remove_reference<Ty>::type> {\n};\n\n// Returns an iterator_range over the given container which iterates in reverse.\n// Note that the container must have rbegin()/rend() methods for this to work.\ntemplate <typename ContainerTy>\nauto reverse(ContainerTy &&C,\n             std::enable_if_t<has_rbegin<ContainerTy>::value> * = nullptr) {\n  return make_range(C.rbegin(), C.rend());\n}\n\n// Returns a std::reverse_iterator wrapped around the given iterator.\ntemplate <typename IteratorTy>\nstd::reverse_iterator<IteratorTy> make_reverse_iterator(IteratorTy It) {\n  return std::reverse_iterator<IteratorTy>(It);\n}\n\n// Returns an iterator_range over the given container which iterates in reverse.\n// Note that the container must have begin()/end() methods which return\n// bidirectional iterators for this to work.\ntemplate <typename ContainerTy>\nauto reverse(ContainerTy &&C,\n             std::enable_if_t<!has_rbegin<ContainerTy>::value> * = nullptr) {\n  return make_range(llvm::make_reverse_iterator(std::end(C)),\n                    llvm::make_reverse_iterator(std::begin(C)));\n}\n\n/// An iterator adaptor that filters the elements of given inner iterators.\n///\n/// The predicate parameter should be a callable object that accepts the wrapped\n/// iterator's reference type and returns a bool. When incrementing or\n/// decrementing the iterator, it will call the predicate on each element and\n/// skip any where it returns false.\n///\n/// \\code\n///   int A[] = { 1, 2, 3, 4 };\n///   auto R = make_filter_range(A, [](int N) { return N % 2 == 1; });\n///   // R contains { 1, 3 }.\n/// \\endcode\n///\n/// Note: filter_iterator_base implements support for forward iteration.\n/// filter_iterator_impl exists to provide support for bidirectional iteration,\n/// conditional on whether the wrapped iterator supports it.\ntemplate <typename WrappedIteratorT, typename PredicateT, typename IterTag>\nclass filter_iterator_base\n    : public iterator_adaptor_base<\n          filter_iterator_base<WrappedIteratorT, PredicateT, IterTag>,\n          WrappedIteratorT,\n          typename std::common_type<\n              IterTag, typename std::iterator_traits<\n                           WrappedIteratorT>::iterator_category>::type> {\n  using BaseT = iterator_adaptor_base<\n      filter_iterator_base<WrappedIteratorT, PredicateT, IterTag>,\n      WrappedIteratorT,\n      typename std::common_type<\n          IterTag, typename std::iterator_traits<\n                       WrappedIteratorT>::iterator_category>::type>;\n\nprotected:\n  WrappedIteratorT End;\n  PredicateT Pred;\n\n  void findNextValid() {\n    while (this->I != End && !Pred(*this->I))\n      BaseT::operator++();\n  }\n\n  // Construct the iterator. The begin iterator needs to know where the end\n  // is, so that it can properly stop when it gets there. The end iterator only\n  // needs the predicate to support bidirectional iteration.\n  filter_iterator_base(WrappedIteratorT Begin, WrappedIteratorT End,\n                       PredicateT Pred)\n      : BaseT(Begin), End(End), Pred(Pred) {\n    findNextValid();\n  }\n\npublic:\n  using BaseT::operator++;\n\n  filter_iterator_base &operator++() {\n    BaseT::operator++();\n    findNextValid();\n    return *this;\n  }\n};\n\n/// Specialization of filter_iterator_base for forward iteration only.\ntemplate <typename WrappedIteratorT, typename PredicateT,\n          typename IterTag = std::forward_iterator_tag>\nclass filter_iterator_impl\n    : public filter_iterator_base<WrappedIteratorT, PredicateT, IterTag> {\n  using BaseT = filter_iterator_base<WrappedIteratorT, PredicateT, IterTag>;\n\npublic:\n  filter_iterator_impl(WrappedIteratorT Begin, WrappedIteratorT End,\n                       PredicateT Pred)\n      : BaseT(Begin, End, Pred) {}\n};\n\n/// Specialization of filter_iterator_base for bidirectional iteration.\ntemplate <typename WrappedIteratorT, typename PredicateT>\nclass filter_iterator_impl<WrappedIteratorT, PredicateT,\n                           std::bidirectional_iterator_tag>\n    : public filter_iterator_base<WrappedIteratorT, PredicateT,\n                                  std::bidirectional_iterator_tag> {\n  using BaseT = filter_iterator_base<WrappedIteratorT, PredicateT,\n                                     std::bidirectional_iterator_tag>;\n  void findPrevValid() {\n    while (!this->Pred(*this->I))\n      BaseT::operator--();\n  }\n\npublic:\n  using BaseT::operator--;\n\n  filter_iterator_impl(WrappedIteratorT Begin, WrappedIteratorT End,\n                       PredicateT Pred)\n      : BaseT(Begin, End, Pred) {}\n\n  filter_iterator_impl &operator--() {\n    BaseT::operator--();\n    findPrevValid();\n    return *this;\n  }\n};\n\nnamespace detail {\n\ntemplate <bool is_bidirectional> struct fwd_or_bidi_tag_impl {\n  using type = std::forward_iterator_tag;\n};\n\ntemplate <> struct fwd_or_bidi_tag_impl<true> {\n  using type = std::bidirectional_iterator_tag;\n};\n\n/// Helper which sets its type member to forward_iterator_tag if the category\n/// of \\p IterT does not derive from bidirectional_iterator_tag, and to\n/// bidirectional_iterator_tag otherwise.\ntemplate <typename IterT> struct fwd_or_bidi_tag {\n  using type = typename fwd_or_bidi_tag_impl<std::is_base_of<\n      std::bidirectional_iterator_tag,\n      typename std::iterator_traits<IterT>::iterator_category>::value>::type;\n};\n\n} // namespace detail\n\n/// Defines filter_iterator to a suitable specialization of\n/// filter_iterator_impl, based on the underlying iterator's category.\ntemplate <typename WrappedIteratorT, typename PredicateT>\nusing filter_iterator = filter_iterator_impl<\n    WrappedIteratorT, PredicateT,\n    typename detail::fwd_or_bidi_tag<WrappedIteratorT>::type>;\n\n/// Convenience function that takes a range of elements and a predicate,\n/// and return a new filter_iterator range.\n///\n/// FIXME: Currently if RangeT && is a rvalue reference to a temporary, the\n/// lifetime of that temporary is not kept by the returned range object, and the\n/// temporary is going to be dropped on the floor after the make_iterator_range\n/// full expression that contains this function call.\ntemplate <typename RangeT, typename PredicateT>\niterator_range<filter_iterator<detail::IterOfRange<RangeT>, PredicateT>>\nmake_filter_range(RangeT &&Range, PredicateT Pred) {\n  using FilterIteratorT =\n      filter_iterator<detail::IterOfRange<RangeT>, PredicateT>;\n  return make_range(\n      FilterIteratorT(std::begin(std::forward<RangeT>(Range)),\n                      std::end(std::forward<RangeT>(Range)), Pred),\n      FilterIteratorT(std::end(std::forward<RangeT>(Range)),\n                      std::end(std::forward<RangeT>(Range)), Pred));\n}\n\n/// A pseudo-iterator adaptor that is designed to implement \"early increment\"\n/// style loops.\n///\n/// This is *not a normal iterator* and should almost never be used directly. It\n/// is intended primarily to be used with range based for loops and some range\n/// algorithms.\n///\n/// The iterator isn't quite an `OutputIterator` or an `InputIterator` but\n/// somewhere between them. The constraints of these iterators are:\n///\n/// - On construction or after being incremented, it is comparable and\n///   dereferencable. It is *not* incrementable.\n/// - After being dereferenced, it is neither comparable nor dereferencable, it\n///   is only incrementable.\n///\n/// This means you can only dereference the iterator once, and you can only\n/// increment it once between dereferences.\ntemplate <typename WrappedIteratorT>\nclass early_inc_iterator_impl\n    : public iterator_adaptor_base<early_inc_iterator_impl<WrappedIteratorT>,\n                                   WrappedIteratorT, std::input_iterator_tag> {\n  using BaseT =\n      iterator_adaptor_base<early_inc_iterator_impl<WrappedIteratorT>,\n                            WrappedIteratorT, std::input_iterator_tag>;\n\n  using PointerT = typename std::iterator_traits<WrappedIteratorT>::pointer;\n\nprotected:\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n  bool IsEarlyIncremented = false;\n#endif\n\npublic:\n  early_inc_iterator_impl(WrappedIteratorT I) : BaseT(I) {}\n\n  using BaseT::operator*;\n  decltype(*std::declval<WrappedIteratorT>()) operator*() {\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    assert(!IsEarlyIncremented && \"Cannot dereference twice!\");\n    IsEarlyIncremented = true;\n#endif\n    return *(this->I)++;\n  }\n\n  using BaseT::operator++;\n  early_inc_iterator_impl &operator++() {\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    assert(IsEarlyIncremented && \"Cannot increment before dereferencing!\");\n    IsEarlyIncremented = false;\n#endif\n    return *this;\n  }\n\n  friend bool operator==(const early_inc_iterator_impl &LHS,\n                         const early_inc_iterator_impl &RHS) {\n#if LLVM_ENABLE_ABI_BREAKING_CHECKS\n    assert(!LHS.IsEarlyIncremented && \"Cannot compare after dereferencing!\");\n#endif\n    return (const BaseT &)LHS == (const BaseT &)RHS;\n  }\n};\n\n/// Make a range that does early increment to allow mutation of the underlying\n/// range without disrupting iteration.\n///\n/// The underlying iterator will be incremented immediately after it is\n/// dereferenced, allowing deletion of the current node or insertion of nodes to\n/// not disrupt iteration provided they do not invalidate the *next* iterator --\n/// the current iterator can be invalidated.\n///\n/// This requires a very exact pattern of use that is only really suitable to\n/// range based for loops and other range algorithms that explicitly guarantee\n/// to dereference exactly once each element, and to increment exactly once each\n/// element.\ntemplate <typename RangeT>\niterator_range<early_inc_iterator_impl<detail::IterOfRange<RangeT>>>\nmake_early_inc_range(RangeT &&Range) {\n  using EarlyIncIteratorT =\n      early_inc_iterator_impl<detail::IterOfRange<RangeT>>;\n  return make_range(EarlyIncIteratorT(std::begin(std::forward<RangeT>(Range))),\n                    EarlyIncIteratorT(std::end(std::forward<RangeT>(Range))));\n}\n\n// forward declarations required by zip_shortest/zip_first/zip_longest\ntemplate <typename R, typename UnaryPredicate>\nbool all_of(R &&range, UnaryPredicate P);\ntemplate <typename R, typename UnaryPredicate>\nbool any_of(R &&range, UnaryPredicate P);\n\nnamespace detail {\n\nusing std::declval;\n\n// We have to alias this since inlining the actual type at the usage site\n// in the parameter list of iterator_facade_base<> below ICEs MSVC 2017.\ntemplate<typename... Iters> struct ZipTupleType {\n  using type = std::tuple<decltype(*declval<Iters>())...>;\n};\n\ntemplate <typename ZipType, typename... Iters>\nusing zip_traits = iterator_facade_base<\n    ZipType, typename std::common_type<std::bidirectional_iterator_tag,\n                                       typename std::iterator_traits<\n                                           Iters>::iterator_category...>::type,\n    // ^ TODO: Implement random access methods.\n    typename ZipTupleType<Iters...>::type,\n    typename std::iterator_traits<typename std::tuple_element<\n        0, std::tuple<Iters...>>::type>::difference_type,\n    // ^ FIXME: This follows boost::make_zip_iterator's assumption that all\n    // inner iterators have the same difference_type. It would fail if, for\n    // instance, the second field's difference_type were non-numeric while the\n    // first is.\n    typename ZipTupleType<Iters...>::type *,\n    typename ZipTupleType<Iters...>::type>;\n\ntemplate <typename ZipType, typename... Iters>\nstruct zip_common : public zip_traits<ZipType, Iters...> {\n  using Base = zip_traits<ZipType, Iters...>;\n  using value_type = typename Base::value_type;\n\n  std::tuple<Iters...> iterators;\n\nprotected:\n  template <size_t... Ns> value_type deref(std::index_sequence<Ns...>) const {\n    return value_type(*std::get<Ns>(iterators)...);\n  }\n\n  template <size_t... Ns>\n  decltype(iterators) tup_inc(std::index_sequence<Ns...>) const {\n    return std::tuple<Iters...>(std::next(std::get<Ns>(iterators))...);\n  }\n\n  template <size_t... Ns>\n  decltype(iterators) tup_dec(std::index_sequence<Ns...>) const {\n    return std::tuple<Iters...>(std::prev(std::get<Ns>(iterators))...);\n  }\n\npublic:\n  zip_common(Iters &&... ts) : iterators(std::forward<Iters>(ts)...) {}\n\n  value_type operator*() { return deref(std::index_sequence_for<Iters...>{}); }\n\n  const value_type operator*() const {\n    return deref(std::index_sequence_for<Iters...>{});\n  }\n\n  ZipType &operator++() {\n    iterators = tup_inc(std::index_sequence_for<Iters...>{});\n    return *reinterpret_cast<ZipType *>(this);\n  }\n\n  ZipType &operator--() {\n    static_assert(Base::IsBidirectional,\n                  \"All inner iterators must be at least bidirectional.\");\n    iterators = tup_dec(std::index_sequence_for<Iters...>{});\n    return *reinterpret_cast<ZipType *>(this);\n  }\n};\n\ntemplate <typename... Iters>\nstruct zip_first : public zip_common<zip_first<Iters...>, Iters...> {\n  using Base = zip_common<zip_first<Iters...>, Iters...>;\n\n  bool operator==(const zip_first<Iters...> &other) const {\n    return std::get<0>(this->iterators) == std::get<0>(other.iterators);\n  }\n\n  zip_first(Iters &&... ts) : Base(std::forward<Iters>(ts)...) {}\n};\n\ntemplate <typename... Iters>\nclass zip_shortest : public zip_common<zip_shortest<Iters...>, Iters...> {\n  template <size_t... Ns>\n  bool test(const zip_shortest<Iters...> &other,\n            std::index_sequence<Ns...>) const {\n    return all_of(std::initializer_list<bool>{std::get<Ns>(this->iterators) !=\n                                              std::get<Ns>(other.iterators)...},\n                  identity<bool>{});\n  }\n\npublic:\n  using Base = zip_common<zip_shortest<Iters...>, Iters...>;\n\n  zip_shortest(Iters &&... ts) : Base(std::forward<Iters>(ts)...) {}\n\n  bool operator==(const zip_shortest<Iters...> &other) const {\n    return !test(other, std::index_sequence_for<Iters...>{});\n  }\n};\n\ntemplate <template <typename...> class ItType, typename... Args> class zippy {\npublic:\n  using iterator = ItType<decltype(std::begin(std::declval<Args>()))...>;\n  using iterator_category = typename iterator::iterator_category;\n  using value_type = typename iterator::value_type;\n  using difference_type = typename iterator::difference_type;\n  using pointer = typename iterator::pointer;\n  using reference = typename iterator::reference;\n\nprivate:\n  std::tuple<Args...> ts;\n\n  template <size_t... Ns>\n  iterator begin_impl(std::index_sequence<Ns...>) const {\n    return iterator(std::begin(std::get<Ns>(ts))...);\n  }\n  template <size_t... Ns> iterator end_impl(std::index_sequence<Ns...>) const {\n    return iterator(std::end(std::get<Ns>(ts))...);\n  }\n\npublic:\n  zippy(Args &&... ts_) : ts(std::forward<Args>(ts_)...) {}\n\n  iterator begin() const {\n    return begin_impl(std::index_sequence_for<Args...>{});\n  }\n  iterator end() const { return end_impl(std::index_sequence_for<Args...>{}); }\n};\n\n} // end namespace detail\n\n/// zip iterator for two or more iteratable types.\ntemplate <typename T, typename U, typename... Args>\ndetail::zippy<detail::zip_shortest, T, U, Args...> zip(T &&t, U &&u,\n                                                       Args &&... args) {\n  return detail::zippy<detail::zip_shortest, T, U, Args...>(\n      std::forward<T>(t), std::forward<U>(u), std::forward<Args>(args)...);\n}\n\n/// zip iterator that, for the sake of efficiency, assumes the first iteratee to\n/// be the shortest.\ntemplate <typename T, typename U, typename... Args>\ndetail::zippy<detail::zip_first, T, U, Args...> zip_first(T &&t, U &&u,\n                                                          Args &&... args) {\n  return detail::zippy<detail::zip_first, T, U, Args...>(\n      std::forward<T>(t), std::forward<U>(u), std::forward<Args>(args)...);\n}\n\nnamespace detail {\ntemplate <typename Iter>\nIter next_or_end(const Iter &I, const Iter &End) {\n  if (I == End)\n    return End;\n  return std::next(I);\n}\n\ntemplate <typename Iter>\nauto deref_or_none(const Iter &I, const Iter &End) -> llvm::Optional<\n    std::remove_const_t<std::remove_reference_t<decltype(*I)>>> {\n  if (I == End)\n    return None;\n  return *I;\n}\n\ntemplate <typename Iter> struct ZipLongestItemType {\n  using type =\n      llvm::Optional<typename std::remove_const<typename std::remove_reference<\n          decltype(*std::declval<Iter>())>::type>::type>;\n};\n\ntemplate <typename... Iters> struct ZipLongestTupleType {\n  using type = std::tuple<typename ZipLongestItemType<Iters>::type...>;\n};\n\ntemplate <typename... Iters>\nclass zip_longest_iterator\n    : public iterator_facade_base<\n          zip_longest_iterator<Iters...>,\n          typename std::common_type<\n              std::forward_iterator_tag,\n              typename std::iterator_traits<Iters>::iterator_category...>::type,\n          typename ZipLongestTupleType<Iters...>::type,\n          typename std::iterator_traits<typename std::tuple_element<\n              0, std::tuple<Iters...>>::type>::difference_type,\n          typename ZipLongestTupleType<Iters...>::type *,\n          typename ZipLongestTupleType<Iters...>::type> {\npublic:\n  using value_type = typename ZipLongestTupleType<Iters...>::type;\n\nprivate:\n  std::tuple<Iters...> iterators;\n  std::tuple<Iters...> end_iterators;\n\n  template <size_t... Ns>\n  bool test(const zip_longest_iterator<Iters...> &other,\n            std::index_sequence<Ns...>) const {\n    return llvm::any_of(\n        std::initializer_list<bool>{std::get<Ns>(this->iterators) !=\n                                    std::get<Ns>(other.iterators)...},\n        identity<bool>{});\n  }\n\n  template <size_t... Ns> value_type deref(std::index_sequence<Ns...>) const {\n    return value_type(\n        deref_or_none(std::get<Ns>(iterators), std::get<Ns>(end_iterators))...);\n  }\n\n  template <size_t... Ns>\n  decltype(iterators) tup_inc(std::index_sequence<Ns...>) const {\n    return std::tuple<Iters...>(\n        next_or_end(std::get<Ns>(iterators), std::get<Ns>(end_iterators))...);\n  }\n\npublic:\n  zip_longest_iterator(std::pair<Iters &&, Iters &&>... ts)\n      : iterators(std::forward<Iters>(ts.first)...),\n        end_iterators(std::forward<Iters>(ts.second)...) {}\n\n  value_type operator*() { return deref(std::index_sequence_for<Iters...>{}); }\n\n  value_type operator*() const {\n    return deref(std::index_sequence_for<Iters...>{});\n  }\n\n  zip_longest_iterator<Iters...> &operator++() {\n    iterators = tup_inc(std::index_sequence_for<Iters...>{});\n    return *this;\n  }\n\n  bool operator==(const zip_longest_iterator<Iters...> &other) const {\n    return !test(other, std::index_sequence_for<Iters...>{});\n  }\n};\n\ntemplate <typename... Args> class zip_longest_range {\npublic:\n  using iterator =\n      zip_longest_iterator<decltype(adl_begin(std::declval<Args>()))...>;\n  using iterator_category = typename iterator::iterator_category;\n  using value_type = typename iterator::value_type;\n  using difference_type = typename iterator::difference_type;\n  using pointer = typename iterator::pointer;\n  using reference = typename iterator::reference;\n\nprivate:\n  std::tuple<Args...> ts;\n\n  template <size_t... Ns>\n  iterator begin_impl(std::index_sequence<Ns...>) const {\n    return iterator(std::make_pair(adl_begin(std::get<Ns>(ts)),\n                                   adl_end(std::get<Ns>(ts)))...);\n  }\n\n  template <size_t... Ns> iterator end_impl(std::index_sequence<Ns...>) const {\n    return iterator(std::make_pair(adl_end(std::get<Ns>(ts)),\n                                   adl_end(std::get<Ns>(ts)))...);\n  }\n\npublic:\n  zip_longest_range(Args &&... ts_) : ts(std::forward<Args>(ts_)...) {}\n\n  iterator begin() const {\n    return begin_impl(std::index_sequence_for<Args...>{});\n  }\n  iterator end() const { return end_impl(std::index_sequence_for<Args...>{}); }\n};\n} // namespace detail\n\n/// Iterate over two or more iterators at the same time. Iteration continues\n/// until all iterators reach the end. The llvm::Optional only contains a value\n/// if the iterator has not reached the end.\ntemplate <typename T, typename U, typename... Args>\ndetail::zip_longest_range<T, U, Args...> zip_longest(T &&t, U &&u,\n                                                     Args &&... args) {\n  return detail::zip_longest_range<T, U, Args...>(\n      std::forward<T>(t), std::forward<U>(u), std::forward<Args>(args)...);\n}\n\n/// Iterator wrapper that concatenates sequences together.\n///\n/// This can concatenate different iterators, even with different types, into\n/// a single iterator provided the value types of all the concatenated\n/// iterators expose `reference` and `pointer` types that can be converted to\n/// `ValueT &` and `ValueT *` respectively. It doesn't support more\n/// interesting/customized pointer or reference types.\n///\n/// Currently this only supports forward or higher iterator categories as\n/// inputs and always exposes a forward iterator interface.\ntemplate <typename ValueT, typename... IterTs>\nclass concat_iterator\n    : public iterator_facade_base<concat_iterator<ValueT, IterTs...>,\n                                  std::forward_iterator_tag, ValueT> {\n  using BaseT = typename concat_iterator::iterator_facade_base;\n\n  /// We store both the current and end iterators for each concatenated\n  /// sequence in a tuple of pairs.\n  ///\n  /// Note that something like iterator_range seems nice at first here, but the\n  /// range properties are of little benefit and end up getting in the way\n  /// because we need to do mutation on the current iterators.\n  std::tuple<IterTs...> Begins;\n  std::tuple<IterTs...> Ends;\n\n  /// Attempts to increment a specific iterator.\n  ///\n  /// Returns true if it was able to increment the iterator. Returns false if\n  /// the iterator is already at the end iterator.\n  template <size_t Index> bool incrementHelper() {\n    auto &Begin = std::get<Index>(Begins);\n    auto &End = std::get<Index>(Ends);\n    if (Begin == End)\n      return false;\n\n    ++Begin;\n    return true;\n  }\n\n  /// Increments the first non-end iterator.\n  ///\n  /// It is an error to call this with all iterators at the end.\n  template <size_t... Ns> void increment(std::index_sequence<Ns...>) {\n    // Build a sequence of functions to increment each iterator if possible.\n    bool (concat_iterator::*IncrementHelperFns[])() = {\n        &concat_iterator::incrementHelper<Ns>...};\n\n    // Loop over them, and stop as soon as we succeed at incrementing one.\n    for (auto &IncrementHelperFn : IncrementHelperFns)\n      if ((this->*IncrementHelperFn)())\n        return;\n\n    llvm_unreachable(\"Attempted to increment an end concat iterator!\");\n  }\n\n  /// Returns null if the specified iterator is at the end. Otherwise,\n  /// dereferences the iterator and returns the address of the resulting\n  /// reference.\n  template <size_t Index> ValueT *getHelper() const {\n    auto &Begin = std::get<Index>(Begins);\n    auto &End = std::get<Index>(Ends);\n    if (Begin == End)\n      return nullptr;\n\n    return &*Begin;\n  }\n\n  /// Finds the first non-end iterator, dereferences, and returns the resulting\n  /// reference.\n  ///\n  /// It is an error to call this with all iterators at the end.\n  template <size_t... Ns> ValueT &get(std::index_sequence<Ns...>) const {\n    // Build a sequence of functions to get from iterator if possible.\n    ValueT *(concat_iterator::*GetHelperFns[])() const = {\n        &concat_iterator::getHelper<Ns>...};\n\n    // Loop over them, and return the first result we find.\n    for (auto &GetHelperFn : GetHelperFns)\n      if (ValueT *P = (this->*GetHelperFn)())\n        return *P;\n\n    llvm_unreachable(\"Attempted to get a pointer from an end concat iterator!\");\n  }\n\npublic:\n  /// Constructs an iterator from a sequence of ranges.\n  ///\n  /// We need the full range to know how to switch between each of the\n  /// iterators.\n  template <typename... RangeTs>\n  explicit concat_iterator(RangeTs &&... Ranges)\n      : Begins(std::begin(Ranges)...), Ends(std::end(Ranges)...) {}\n\n  using BaseT::operator++;\n\n  concat_iterator &operator++() {\n    increment(std::index_sequence_for<IterTs...>());\n    return *this;\n  }\n\n  ValueT &operator*() const {\n    return get(std::index_sequence_for<IterTs...>());\n  }\n\n  bool operator==(const concat_iterator &RHS) const {\n    return Begins == RHS.Begins && Ends == RHS.Ends;\n  }\n};\n\nnamespace detail {\n\n/// Helper to store a sequence of ranges being concatenated and access them.\n///\n/// This is designed to facilitate providing actual storage when temporaries\n/// are passed into the constructor such that we can use it as part of range\n/// based for loops.\ntemplate <typename ValueT, typename... RangeTs> class concat_range {\npublic:\n  using iterator =\n      concat_iterator<ValueT,\n                      decltype(std::begin(std::declval<RangeTs &>()))...>;\n\nprivate:\n  std::tuple<RangeTs...> Ranges;\n\n  template <size_t... Ns> iterator begin_impl(std::index_sequence<Ns...>) {\n    return iterator(std::get<Ns>(Ranges)...);\n  }\n  template <size_t... Ns> iterator end_impl(std::index_sequence<Ns...>) {\n    return iterator(make_range(std::end(std::get<Ns>(Ranges)),\n                               std::end(std::get<Ns>(Ranges)))...);\n  }\n\npublic:\n  concat_range(RangeTs &&... Ranges)\n      : Ranges(std::forward<RangeTs>(Ranges)...) {}\n\n  iterator begin() { return begin_impl(std::index_sequence_for<RangeTs...>{}); }\n  iterator end() { return end_impl(std::index_sequence_for<RangeTs...>{}); }\n};\n\n} // end namespace detail\n\n/// Concatenated range across two or more ranges.\n///\n/// The desired value type must be explicitly specified.\ntemplate <typename ValueT, typename... RangeTs>\ndetail::concat_range<ValueT, RangeTs...> concat(RangeTs &&... Ranges) {\n  static_assert(sizeof...(RangeTs) > 1,\n                \"Need more than one range to concatenate!\");\n  return detail::concat_range<ValueT, RangeTs...>(\n      std::forward<RangeTs>(Ranges)...);\n}\n\n/// A utility class used to implement an iterator that contains some base object\n/// and an index. The iterator moves the index but keeps the base constant.\ntemplate <typename DerivedT, typename BaseT, typename T,\n          typename PointerT = T *, typename ReferenceT = T &>\nclass indexed_accessor_iterator\n    : public llvm::iterator_facade_base<DerivedT,\n                                        std::random_access_iterator_tag, T,\n                                        std::ptrdiff_t, PointerT, ReferenceT> {\npublic:\n  ptrdiff_t operator-(const indexed_accessor_iterator &rhs) const {\n    assert(base == rhs.base && \"incompatible iterators\");\n    return index - rhs.index;\n  }\n  bool operator==(const indexed_accessor_iterator &rhs) const {\n    return base == rhs.base && index == rhs.index;\n  }\n  bool operator<(const indexed_accessor_iterator &rhs) const {\n    assert(base == rhs.base && \"incompatible iterators\");\n    return index < rhs.index;\n  }\n\n  DerivedT &operator+=(ptrdiff_t offset) {\n    this->index += offset;\n    return static_cast<DerivedT &>(*this);\n  }\n  DerivedT &operator-=(ptrdiff_t offset) {\n    this->index -= offset;\n    return static_cast<DerivedT &>(*this);\n  }\n\n  /// Returns the current index of the iterator.\n  ptrdiff_t getIndex() const { return index; }\n\n  /// Returns the current base of the iterator.\n  const BaseT &getBase() const { return base; }\n\nprotected:\n  indexed_accessor_iterator(BaseT base, ptrdiff_t index)\n      : base(base), index(index) {}\n  BaseT base;\n  ptrdiff_t index;\n};\n\nnamespace detail {\n/// The class represents the base of a range of indexed_accessor_iterators. It\n/// provides support for many different range functionalities, e.g.\n/// drop_front/slice/etc.. Derived range classes must implement the following\n/// static methods:\n///   * ReferenceT dereference_iterator(const BaseT &base, ptrdiff_t index)\n///     - Dereference an iterator pointing to the base object at the given\n///       index.\n///   * BaseT offset_base(const BaseT &base, ptrdiff_t index)\n///     - Return a new base that is offset from the provide base by 'index'\n///       elements.\ntemplate <typename DerivedT, typename BaseT, typename T,\n          typename PointerT = T *, typename ReferenceT = T &>\nclass indexed_accessor_range_base {\npublic:\n  using RangeBaseT =\n      indexed_accessor_range_base<DerivedT, BaseT, T, PointerT, ReferenceT>;\n\n  /// An iterator element of this range.\n  class iterator : public indexed_accessor_iterator<iterator, BaseT, T,\n                                                    PointerT, ReferenceT> {\n  public:\n    // Index into this iterator, invoking a static method on the derived type.\n    ReferenceT operator*() const {\n      return DerivedT::dereference_iterator(this->getBase(), this->getIndex());\n    }\n\n  private:\n    iterator(BaseT owner, ptrdiff_t curIndex)\n        : indexed_accessor_iterator<iterator, BaseT, T, PointerT, ReferenceT>(\n              owner, curIndex) {}\n\n    /// Allow access to the constructor.\n    friend indexed_accessor_range_base<DerivedT, BaseT, T, PointerT,\n                                       ReferenceT>;\n  };\n\n  indexed_accessor_range_base(iterator begin, iterator end)\n      : base(offset_base(begin.getBase(), begin.getIndex())),\n        count(end.getIndex() - begin.getIndex()) {}\n  indexed_accessor_range_base(const iterator_range<iterator> &range)\n      : indexed_accessor_range_base(range.begin(), range.end()) {}\n  indexed_accessor_range_base(BaseT base, ptrdiff_t count)\n      : base(base), count(count) {}\n\n  iterator begin() const { return iterator(base, 0); }\n  iterator end() const { return iterator(base, count); }\n  ReferenceT operator[](size_t Index) const {\n    assert(Index < size() && \"invalid index for value range\");\n    return DerivedT::dereference_iterator(base, static_cast<ptrdiff_t>(Index));\n  }\n  ReferenceT front() const {\n    assert(!empty() && \"expected non-empty range\");\n    return (*this)[0];\n  }\n  ReferenceT back() const {\n    assert(!empty() && \"expected non-empty range\");\n    return (*this)[size() - 1];\n  }\n\n  /// Compare this range with another.\n  template <typename OtherT> bool operator==(const OtherT &other) const {\n    return size() ==\n               static_cast<size_t>(std::distance(other.begin(), other.end())) &&\n           std::equal(begin(), end(), other.begin());\n  }\n  template <typename OtherT> bool operator!=(const OtherT &other) const {\n    return !(*this == other);\n  }\n\n  /// Return the size of this range.\n  size_t size() const { return count; }\n\n  /// Return if the range is empty.\n  bool empty() const { return size() == 0; }\n\n  /// Drop the first N elements, and keep M elements.\n  DerivedT slice(size_t n, size_t m) const {\n    assert(n + m <= size() && \"invalid size specifiers\");\n    return DerivedT(offset_base(base, n), m);\n  }\n\n  /// Drop the first n elements.\n  DerivedT drop_front(size_t n = 1) const {\n    assert(size() >= n && \"Dropping more elements than exist\");\n    return slice(n, size() - n);\n  }\n  /// Drop the last n elements.\n  DerivedT drop_back(size_t n = 1) const {\n    assert(size() >= n && \"Dropping more elements than exist\");\n    return DerivedT(base, size() - n);\n  }\n\n  /// Take the first n elements.\n  DerivedT take_front(size_t n = 1) const {\n    return n < size() ? drop_back(size() - n)\n                      : static_cast<const DerivedT &>(*this);\n  }\n\n  /// Take the last n elements.\n  DerivedT take_back(size_t n = 1) const {\n    return n < size() ? drop_front(size() - n)\n                      : static_cast<const DerivedT &>(*this);\n  }\n\n  /// Allow conversion to any type accepting an iterator_range.\n  template <typename RangeT, typename = std::enable_if_t<std::is_constructible<\n                                 RangeT, iterator_range<iterator>>::value>>\n  operator RangeT() const {\n    return RangeT(iterator_range<iterator>(*this));\n  }\n\n  /// Returns the base of this range.\n  const BaseT &getBase() const { return base; }\n\nprivate:\n  /// Offset the given base by the given amount.\n  static BaseT offset_base(const BaseT &base, size_t n) {\n    return n == 0 ? base : DerivedT::offset_base(base, n);\n  }\n\nprotected:\n  indexed_accessor_range_base(const indexed_accessor_range_base &) = default;\n  indexed_accessor_range_base(indexed_accessor_range_base &&) = default;\n  indexed_accessor_range_base &\n  operator=(const indexed_accessor_range_base &) = default;\n\n  /// The base that owns the provided range of values.\n  BaseT base;\n  /// The size from the owning range.\n  ptrdiff_t count;\n};\n} // end namespace detail\n\n/// This class provides an implementation of a range of\n/// indexed_accessor_iterators where the base is not indexable. Ranges with\n/// bases that are offsetable should derive from indexed_accessor_range_base\n/// instead. Derived range classes are expected to implement the following\n/// static method:\n///   * ReferenceT dereference(const BaseT &base, ptrdiff_t index)\n///     - Dereference an iterator pointing to a parent base at the given index.\ntemplate <typename DerivedT, typename BaseT, typename T,\n          typename PointerT = T *, typename ReferenceT = T &>\nclass indexed_accessor_range\n    : public detail::indexed_accessor_range_base<\n          DerivedT, std::pair<BaseT, ptrdiff_t>, T, PointerT, ReferenceT> {\npublic:\n  indexed_accessor_range(BaseT base, ptrdiff_t startIndex, ptrdiff_t count)\n      : detail::indexed_accessor_range_base<\n            DerivedT, std::pair<BaseT, ptrdiff_t>, T, PointerT, ReferenceT>(\n            std::make_pair(base, startIndex), count) {}\n  using detail::indexed_accessor_range_base<\n      DerivedT, std::pair<BaseT, ptrdiff_t>, T, PointerT,\n      ReferenceT>::indexed_accessor_range_base;\n\n  /// Returns the current base of the range.\n  const BaseT &getBase() const { return this->base.first; }\n\n  /// Returns the current start index of the range.\n  ptrdiff_t getStartIndex() const { return this->base.second; }\n\n  /// See `detail::indexed_accessor_range_base` for details.\n  static std::pair<BaseT, ptrdiff_t>\n  offset_base(const std::pair<BaseT, ptrdiff_t> &base, ptrdiff_t index) {\n    // We encode the internal base as a pair of the derived base and a start\n    // index into the derived base.\n    return std::make_pair(base.first, base.second + index);\n  }\n  /// See `detail::indexed_accessor_range_base` for details.\n  static ReferenceT\n  dereference_iterator(const std::pair<BaseT, ptrdiff_t> &base,\n                       ptrdiff_t index) {\n    return DerivedT::dereference(base.first, base.second + index);\n  }\n};\n\n/// Given a container of pairs, return a range over the first elements.\ntemplate <typename ContainerTy> auto make_first_range(ContainerTy &&c) {\n  return llvm::map_range(\n      std::forward<ContainerTy>(c),\n      [](decltype((*std::begin(c))) elt) -> decltype((elt.first)) {\n        return elt.first;\n      });\n}\n\n/// Given a container of pairs, return a range over the second elements.\ntemplate <typename ContainerTy> auto make_second_range(ContainerTy &&c) {\n  return llvm::map_range(\n      std::forward<ContainerTy>(c),\n      [](decltype((*std::begin(c))) elt) -> decltype((elt.second)) {\n        return elt.second;\n      });\n}\n\n//===----------------------------------------------------------------------===//\n//     Extra additions to <utility>\n//===----------------------------------------------------------------------===//\n\n/// Function object to check whether the first component of a std::pair\n/// compares less than the first component of another std::pair.\nstruct less_first {\n  template <typename T> bool operator()(const T &lhs, const T &rhs) const {\n    return lhs.first < rhs.first;\n  }\n};\n\n/// Function object to check whether the second component of a std::pair\n/// compares less than the second component of another std::pair.\nstruct less_second {\n  template <typename T> bool operator()(const T &lhs, const T &rhs) const {\n    return lhs.second < rhs.second;\n  }\n};\n\n/// \\brief Function object to apply a binary function to the first component of\n/// a std::pair.\ntemplate<typename FuncTy>\nstruct on_first {\n  FuncTy func;\n\n  template <typename T>\n  decltype(auto) operator()(const T &lhs, const T &rhs) const {\n    return func(lhs.first, rhs.first);\n  }\n};\n\n/// Utility type to build an inheritance chain that makes it easy to rank\n/// overload candidates.\ntemplate <int N> struct rank : rank<N - 1> {};\ntemplate <> struct rank<0> {};\n\n/// traits class for checking whether type T is one of any of the given\n/// types in the variadic list.\ntemplate <typename T, typename... Ts> struct is_one_of {\n  static const bool value = false;\n};\n\ntemplate <typename T, typename U, typename... Ts>\nstruct is_one_of<T, U, Ts...> {\n  static const bool value =\n      std::is_same<T, U>::value || is_one_of<T, Ts...>::value;\n};\n\n/// traits class for checking whether type T is a base class for all\n///  the given types in the variadic list.\ntemplate <typename T, typename... Ts> struct are_base_of {\n  static const bool value = true;\n};\n\ntemplate <typename T, typename U, typename... Ts>\nstruct are_base_of<T, U, Ts...> {\n  static const bool value =\n      std::is_base_of<T, U>::value && are_base_of<T, Ts...>::value;\n};\n\n//===----------------------------------------------------------------------===//\n//     Extra additions for arrays\n//===----------------------------------------------------------------------===//\n\n// We have a copy here so that LLVM behaves the same when using different\n// standard libraries.\ntemplate <class Iterator, class RNG>\nvoid shuffle(Iterator first, Iterator last, RNG &&g) {\n  // It would be better to use a std::uniform_int_distribution,\n  // but that would be stdlib dependent.\n  typedef\n      typename std::iterator_traits<Iterator>::difference_type difference_type;\n  for (auto size = last - first; size > 1; ++first, (void)--size) {\n    difference_type offset = g() % size;\n    // Avoid self-assignment due to incorrect assertions in libstdc++\n    // containers (https://gcc.gnu.org/bugzilla/show_bug.cgi?id=85828).\n    if (offset != difference_type(0))\n      std::iter_swap(first, first + offset);\n  }\n}\n\n/// Find the length of an array.\ntemplate <class T, std::size_t N>\nconstexpr inline size_t array_lengthof(T (&)[N]) {\n  return N;\n}\n\n/// Adapt std::less<T> for array_pod_sort.\ntemplate<typename T>\ninline int array_pod_sort_comparator(const void *P1, const void *P2) {\n  if (std::less<T>()(*reinterpret_cast<const T*>(P1),\n                     *reinterpret_cast<const T*>(P2)))\n    return -1;\n  if (std::less<T>()(*reinterpret_cast<const T*>(P2),\n                     *reinterpret_cast<const T*>(P1)))\n    return 1;\n  return 0;\n}\n\n/// get_array_pod_sort_comparator - This is an internal helper function used to\n/// get type deduction of T right.\ntemplate<typename T>\ninline int (*get_array_pod_sort_comparator(const T &))\n             (const void*, const void*) {\n  return array_pod_sort_comparator<T>;\n}\n\n#ifdef EXPENSIVE_CHECKS\nnamespace detail {\n\ninline unsigned presortShuffleEntropy() {\n  static unsigned Result(std::random_device{}());\n  return Result;\n}\n\ntemplate <class IteratorTy>\ninline void presortShuffle(IteratorTy Start, IteratorTy End) {\n  std::mt19937 Generator(presortShuffleEntropy());\n  llvm::shuffle(Start, End, Generator);\n}\n\n} // end namespace detail\n#endif\n\n/// array_pod_sort - This sorts an array with the specified start and end\n/// extent.  This is just like std::sort, except that it calls qsort instead of\n/// using an inlined template.  qsort is slightly slower than std::sort, but\n/// most sorts are not performance critical in LLVM and std::sort has to be\n/// template instantiated for each type, leading to significant measured code\n/// bloat.  This function should generally be used instead of std::sort where\n/// possible.\n///\n/// This function assumes that you have simple POD-like types that can be\n/// compared with std::less and can be moved with memcpy.  If this isn't true,\n/// you should use std::sort.\n///\n/// NOTE: If qsort_r were portable, we could allow a custom comparator and\n/// default to std::less.\ntemplate<class IteratorTy>\ninline void array_pod_sort(IteratorTy Start, IteratorTy End) {\n  // Don't inefficiently call qsort with one element or trigger undefined\n  // behavior with an empty sequence.\n  auto NElts = End - Start;\n  if (NElts <= 1) return;\n#ifdef EXPENSIVE_CHECKS\n  detail::presortShuffle<IteratorTy>(Start, End);\n#endif\n  qsort(&*Start, NElts, sizeof(*Start), get_array_pod_sort_comparator(*Start));\n}\n\ntemplate <class IteratorTy>\ninline void array_pod_sort(\n    IteratorTy Start, IteratorTy End,\n    int (*Compare)(\n        const typename std::iterator_traits<IteratorTy>::value_type *,\n        const typename std::iterator_traits<IteratorTy>::value_type *)) {\n  // Don't inefficiently call qsort with one element or trigger undefined\n  // behavior with an empty sequence.\n  auto NElts = End - Start;\n  if (NElts <= 1) return;\n#ifdef EXPENSIVE_CHECKS\n  detail::presortShuffle<IteratorTy>(Start, End);\n#endif\n  qsort(&*Start, NElts, sizeof(*Start),\n        reinterpret_cast<int (*)(const void *, const void *)>(Compare));\n}\n\nnamespace detail {\ntemplate <typename T>\n// We can use qsort if the iterator type is a pointer and the underlying value\n// is trivially copyable.\nusing sort_trivially_copyable = conjunction<\n    std::is_pointer<T>,\n    std::is_trivially_copyable<typename std::iterator_traits<T>::value_type>>;\n} // namespace detail\n\n// Provide wrappers to std::sort which shuffle the elements before sorting\n// to help uncover non-deterministic behavior (PR35135).\ntemplate <typename IteratorTy,\n          std::enable_if_t<!detail::sort_trivially_copyable<IteratorTy>::value,\n                           int> = 0>\ninline void sort(IteratorTy Start, IteratorTy End) {\n#ifdef EXPENSIVE_CHECKS\n  detail::presortShuffle<IteratorTy>(Start, End);\n#endif\n  std::sort(Start, End);\n}\n\n// Forward trivially copyable types to array_pod_sort. This avoids a large\n// amount of code bloat for a minor performance hit.\ntemplate <typename IteratorTy,\n          std::enable_if_t<detail::sort_trivially_copyable<IteratorTy>::value,\n                           int> = 0>\ninline void sort(IteratorTy Start, IteratorTy End) {\n  array_pod_sort(Start, End);\n}\n\ntemplate <typename Container> inline void sort(Container &&C) {\n  llvm::sort(adl_begin(C), adl_end(C));\n}\n\ntemplate <typename IteratorTy, typename Compare>\ninline void sort(IteratorTy Start, IteratorTy End, Compare Comp) {\n#ifdef EXPENSIVE_CHECKS\n  detail::presortShuffle<IteratorTy>(Start, End);\n#endif\n  std::sort(Start, End, Comp);\n}\n\ntemplate <typename Container, typename Compare>\ninline void sort(Container &&C, Compare Comp) {\n  llvm::sort(adl_begin(C), adl_end(C), Comp);\n}\n\n//===----------------------------------------------------------------------===//\n//     Extra additions to <algorithm>\n//===----------------------------------------------------------------------===//\n\n/// Get the size of a range. This is a wrapper function around std::distance\n/// which is only enabled when the operation is O(1).\ntemplate <typename R>\nauto size(R &&Range,\n          std::enable_if_t<\n              std::is_base_of<std::random_access_iterator_tag,\n                              typename std::iterator_traits<decltype(\n                                  Range.begin())>::iterator_category>::value,\n              void> * = nullptr) {\n  return std::distance(Range.begin(), Range.end());\n}\n\n/// Provide wrappers to std::for_each which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename UnaryFunction>\nUnaryFunction for_each(R &&Range, UnaryFunction F) {\n  return std::for_each(adl_begin(Range), adl_end(Range), F);\n}\n\n/// Provide wrappers to std::all_of which take ranges instead of having to pass\n/// begin/end explicitly.\ntemplate <typename R, typename UnaryPredicate>\nbool all_of(R &&Range, UnaryPredicate P) {\n  return std::all_of(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Provide wrappers to std::any_of which take ranges instead of having to pass\n/// begin/end explicitly.\ntemplate <typename R, typename UnaryPredicate>\nbool any_of(R &&Range, UnaryPredicate P) {\n  return std::any_of(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Provide wrappers to std::none_of which take ranges instead of having to pass\n/// begin/end explicitly.\ntemplate <typename R, typename UnaryPredicate>\nbool none_of(R &&Range, UnaryPredicate P) {\n  return std::none_of(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Provide wrappers to std::find which take ranges instead of having to pass\n/// begin/end explicitly.\ntemplate <typename R, typename T> auto find(R &&Range, const T &Val) {\n  return std::find(adl_begin(Range), adl_end(Range), Val);\n}\n\n/// Provide wrappers to std::find_if which take ranges instead of having to pass\n/// begin/end explicitly.\ntemplate <typename R, typename UnaryPredicate>\nauto find_if(R &&Range, UnaryPredicate P) {\n  return std::find_if(adl_begin(Range), adl_end(Range), P);\n}\n\ntemplate <typename R, typename UnaryPredicate>\nauto find_if_not(R &&Range, UnaryPredicate P) {\n  return std::find_if_not(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Provide wrappers to std::remove_if which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename UnaryPredicate>\nauto remove_if(R &&Range, UnaryPredicate P) {\n  return std::remove_if(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Provide wrappers to std::copy_if which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename OutputIt, typename UnaryPredicate>\nOutputIt copy_if(R &&Range, OutputIt Out, UnaryPredicate P) {\n  return std::copy_if(adl_begin(Range), adl_end(Range), Out, P);\n}\n\ntemplate <typename R, typename OutputIt>\nOutputIt copy(R &&Range, OutputIt Out) {\n  return std::copy(adl_begin(Range), adl_end(Range), Out);\n}\n\n/// Provide wrappers to std::move which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename OutputIt>\nOutputIt move(R &&Range, OutputIt Out) {\n  return std::move(adl_begin(Range), adl_end(Range), Out);\n}\n\n/// Wrapper function around std::find to detect if an element exists\n/// in a container.\ntemplate <typename R, typename E>\nbool is_contained(R &&Range, const E &Element) {\n  return std::find(adl_begin(Range), adl_end(Range), Element) != adl_end(Range);\n}\n\n/// Wrapper function around std::is_sorted to check if elements in a range \\p R\n/// are sorted with respect to a comparator \\p C.\ntemplate <typename R, typename Compare> bool is_sorted(R &&Range, Compare C) {\n  return std::is_sorted(adl_begin(Range), adl_end(Range), C);\n}\n\n/// Wrapper function around std::is_sorted to check if elements in a range \\p R\n/// are sorted in non-descending order.\ntemplate <typename R> bool is_sorted(R &&Range) {\n  return std::is_sorted(adl_begin(Range), adl_end(Range));\n}\n\n/// Wrapper function around std::count to count the number of times an element\n/// \\p Element occurs in the given range \\p Range.\ntemplate <typename R, typename E> auto count(R &&Range, const E &Element) {\n  return std::count(adl_begin(Range), adl_end(Range), Element);\n}\n\n/// Wrapper function around std::count_if to count the number of times an\n/// element satisfying a given predicate occurs in a range.\ntemplate <typename R, typename UnaryPredicate>\nauto count_if(R &&Range, UnaryPredicate P) {\n  return std::count_if(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Wrapper function around std::transform to apply a function to a range and\n/// store the result elsewhere.\ntemplate <typename R, typename OutputIt, typename UnaryFunction>\nOutputIt transform(R &&Range, OutputIt d_first, UnaryFunction F) {\n  return std::transform(adl_begin(Range), adl_end(Range), d_first, F);\n}\n\n/// Provide wrappers to std::partition which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename UnaryPredicate>\nauto partition(R &&Range, UnaryPredicate P) {\n  return std::partition(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Provide wrappers to std::lower_bound which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename T> auto lower_bound(R &&Range, T &&Value) {\n  return std::lower_bound(adl_begin(Range), adl_end(Range),\n                          std::forward<T>(Value));\n}\n\ntemplate <typename R, typename T, typename Compare>\nauto lower_bound(R &&Range, T &&Value, Compare C) {\n  return std::lower_bound(adl_begin(Range), adl_end(Range),\n                          std::forward<T>(Value), C);\n}\n\n/// Provide wrappers to std::upper_bound which take ranges instead of having to\n/// pass begin/end explicitly.\ntemplate <typename R, typename T> auto upper_bound(R &&Range, T &&Value) {\n  return std::upper_bound(adl_begin(Range), adl_end(Range),\n                          std::forward<T>(Value));\n}\n\ntemplate <typename R, typename T, typename Compare>\nauto upper_bound(R &&Range, T &&Value, Compare C) {\n  return std::upper_bound(adl_begin(Range), adl_end(Range),\n                          std::forward<T>(Value), C);\n}\n\ntemplate <typename R>\nvoid stable_sort(R &&Range) {\n  std::stable_sort(adl_begin(Range), adl_end(Range));\n}\n\ntemplate <typename R, typename Compare>\nvoid stable_sort(R &&Range, Compare C) {\n  std::stable_sort(adl_begin(Range), adl_end(Range), C);\n}\n\n/// Binary search for the first iterator in a range where a predicate is false.\n/// Requires that C is always true below some limit, and always false above it.\ntemplate <typename R, typename Predicate,\n          typename Val = decltype(*adl_begin(std::declval<R>()))>\nauto partition_point(R &&Range, Predicate P) {\n  return std::partition_point(adl_begin(Range), adl_end(Range), P);\n}\n\n/// Wrapper function around std::equal to detect if all elements\n/// in a container are same.\ntemplate <typename R>\nbool is_splat(R &&Range) {\n  size_t range_size = size(Range);\n  return range_size != 0 && (range_size == 1 ||\n         std::equal(adl_begin(Range) + 1, adl_end(Range), adl_begin(Range)));\n}\n\n/// Provide a container algorithm similar to C++ Library Fundamentals v2's\n/// `erase_if` which is equivalent to:\n///\n///   C.erase(remove_if(C, pred), C.end());\n///\n/// This version works for any container with an erase method call accepting\n/// two iterators.\ntemplate <typename Container, typename UnaryPredicate>\nvoid erase_if(Container &C, UnaryPredicate P) {\n  C.erase(remove_if(C, P), C.end());\n}\n\n/// Wrapper function to remove a value from a container:\n///\n/// C.erase(remove(C.begin(), C.end(), V), C.end());\ntemplate <typename Container, typename ValueType>\nvoid erase_value(Container &C, ValueType V) {\n  C.erase(std::remove(C.begin(), C.end(), V), C.end());\n}\n\n/// Wrapper function to append a range to a container.\n///\n/// C.insert(C.end(), R.begin(), R.end());\ntemplate <typename Container, typename Range>\ninline void append_range(Container &C, Range &&R) {\n  C.insert(C.end(), R.begin(), R.end());\n}\n\n/// Given a sequence container Cont, replace the range [ContIt, ContEnd) with\n/// the range [ValIt, ValEnd) (which is not from the same container).\ntemplate<typename Container, typename RandomAccessIterator>\nvoid replace(Container &Cont, typename Container::iterator ContIt,\n             typename Container::iterator ContEnd, RandomAccessIterator ValIt,\n             RandomAccessIterator ValEnd) {\n  while (true) {\n    if (ValIt == ValEnd) {\n      Cont.erase(ContIt, ContEnd);\n      return;\n    } else if (ContIt == ContEnd) {\n      Cont.insert(ContIt, ValIt, ValEnd);\n      return;\n    }\n    *ContIt++ = *ValIt++;\n  }\n}\n\n/// Given a sequence container Cont, replace the range [ContIt, ContEnd) with\n/// the range R.\ntemplate<typename Container, typename Range = std::initializer_list<\n                                 typename Container::value_type>>\nvoid replace(Container &Cont, typename Container::iterator ContIt,\n             typename Container::iterator ContEnd, Range R) {\n  replace(Cont, ContIt, ContEnd, R.begin(), R.end());\n}\n\n/// An STL-style algorithm similar to std::for_each that applies a second\n/// functor between every pair of elements.\n///\n/// This provides the control flow logic to, for example, print a\n/// comma-separated list:\n/// \\code\n///   interleave(names.begin(), names.end(),\n///              [&](StringRef name) { os << name; },\n///              [&] { os << \", \"; });\n/// \\endcode\ntemplate <typename ForwardIterator, typename UnaryFunctor,\n          typename NullaryFunctor,\n          typename = typename std::enable_if<\n              !std::is_constructible<StringRef, UnaryFunctor>::value &&\n              !std::is_constructible<StringRef, NullaryFunctor>::value>::type>\ninline void interleave(ForwardIterator begin, ForwardIterator end,\n                       UnaryFunctor each_fn, NullaryFunctor between_fn) {\n  if (begin == end)\n    return;\n  each_fn(*begin);\n  ++begin;\n  for (; begin != end; ++begin) {\n    between_fn();\n    each_fn(*begin);\n  }\n}\n\ntemplate <typename Container, typename UnaryFunctor, typename NullaryFunctor,\n          typename = typename std::enable_if<\n              !std::is_constructible<StringRef, UnaryFunctor>::value &&\n              !std::is_constructible<StringRef, NullaryFunctor>::value>::type>\ninline void interleave(const Container &c, UnaryFunctor each_fn,\n                       NullaryFunctor between_fn) {\n  interleave(c.begin(), c.end(), each_fn, between_fn);\n}\n\n/// Overload of interleave for the common case of string separator.\ntemplate <typename Container, typename UnaryFunctor, typename StreamT,\n          typename T = detail::ValueOfRange<Container>>\ninline void interleave(const Container &c, StreamT &os, UnaryFunctor each_fn,\n                       const StringRef &separator) {\n  interleave(c.begin(), c.end(), each_fn, [&] { os << separator; });\n}\ntemplate <typename Container, typename StreamT,\n          typename T = detail::ValueOfRange<Container>>\ninline void interleave(const Container &c, StreamT &os,\n                       const StringRef &separator) {\n  interleave(\n      c, os, [&](const T &a) { os << a; }, separator);\n}\n\ntemplate <typename Container, typename UnaryFunctor, typename StreamT,\n          typename T = detail::ValueOfRange<Container>>\ninline void interleaveComma(const Container &c, StreamT &os,\n                            UnaryFunctor each_fn) {\n  interleave(c, os, each_fn, \", \");\n}\ntemplate <typename Container, typename StreamT,\n          typename T = detail::ValueOfRange<Container>>\ninline void interleaveComma(const Container &c, StreamT &os) {\n  interleaveComma(c, os, [&](const T &a) { os << a; });\n}\n\n//===----------------------------------------------------------------------===//\n//     Extra additions to <memory>\n//===----------------------------------------------------------------------===//\n\nstruct FreeDeleter {\n  void operator()(void* v) {\n    ::free(v);\n  }\n};\n\ntemplate<typename First, typename Second>\nstruct pair_hash {\n  size_t operator()(const std::pair<First, Second> &P) const {\n    return std::hash<First>()(P.first) * 31 + std::hash<Second>()(P.second);\n  }\n};\n\n/// Binary functor that adapts to any other binary functor after dereferencing\n/// operands.\ntemplate <typename T> struct deref {\n  T func;\n\n  // Could be further improved to cope with non-derivable functors and\n  // non-binary functors (should be a variadic template member function\n  // operator()).\n  template <typename A, typename B> auto operator()(A &lhs, B &rhs) const {\n    assert(lhs);\n    assert(rhs);\n    return func(*lhs, *rhs);\n  }\n};\n\nnamespace detail {\n\ntemplate <typename R> class enumerator_iter;\n\ntemplate <typename R> struct result_pair {\n  using value_reference =\n      typename std::iterator_traits<IterOfRange<R>>::reference;\n\n  friend class enumerator_iter<R>;\n\n  result_pair() = default;\n  result_pair(std::size_t Index, IterOfRange<R> Iter)\n      : Index(Index), Iter(Iter) {}\n\n  result_pair(const result_pair<R> &Other)\n      : Index(Other.Index), Iter(Other.Iter) {}\n  result_pair &operator=(const result_pair &Other) {\n    Index = Other.Index;\n    Iter = Other.Iter;\n    return *this;\n  }\n\n  std::size_t index() const { return Index; }\n  const value_reference value() const { return *Iter; }\n  value_reference value() { return *Iter; }\n\nprivate:\n  std::size_t Index = std::numeric_limits<std::size_t>::max();\n  IterOfRange<R> Iter;\n};\n\ntemplate <typename R>\nclass enumerator_iter\n    : public iterator_facade_base<\n          enumerator_iter<R>, std::forward_iterator_tag, result_pair<R>,\n          typename std::iterator_traits<IterOfRange<R>>::difference_type,\n          typename std::iterator_traits<IterOfRange<R>>::pointer,\n          typename std::iterator_traits<IterOfRange<R>>::reference> {\n  using result_type = result_pair<R>;\n\npublic:\n  explicit enumerator_iter(IterOfRange<R> EndIter)\n      : Result(std::numeric_limits<size_t>::max(), EndIter) {}\n\n  enumerator_iter(std::size_t Index, IterOfRange<R> Iter)\n      : Result(Index, Iter) {}\n\n  result_type &operator*() { return Result; }\n  const result_type &operator*() const { return Result; }\n\n  enumerator_iter &operator++() {\n    assert(Result.Index != std::numeric_limits<size_t>::max());\n    ++Result.Iter;\n    ++Result.Index;\n    return *this;\n  }\n\n  bool operator==(const enumerator_iter &RHS) const {\n    // Don't compare indices here, only iterators.  It's possible for an end\n    // iterator to have different indices depending on whether it was created\n    // by calling std::end() versus incrementing a valid iterator.\n    return Result.Iter == RHS.Result.Iter;\n  }\n\n  enumerator_iter(const enumerator_iter &Other) : Result(Other.Result) {}\n  enumerator_iter &operator=(const enumerator_iter &Other) {\n    Result = Other.Result;\n    return *this;\n  }\n\nprivate:\n  result_type Result;\n};\n\ntemplate <typename R> class enumerator {\npublic:\n  explicit enumerator(R &&Range) : TheRange(std::forward<R>(Range)) {}\n\n  enumerator_iter<R> begin() {\n    return enumerator_iter<R>(0, std::begin(TheRange));\n  }\n\n  enumerator_iter<R> end() {\n    return enumerator_iter<R>(std::end(TheRange));\n  }\n\nprivate:\n  R TheRange;\n};\n\n} // end namespace detail\n\n/// Given an input range, returns a new range whose values are are pair (A,B)\n/// such that A is the 0-based index of the item in the sequence, and B is\n/// the value from the original sequence.  Example:\n///\n/// std::vector<char> Items = {'A', 'B', 'C', 'D'};\n/// for (auto X : enumerate(Items)) {\n///   printf(\"Item %d - %c\\n\", X.index(), X.value());\n/// }\n///\n/// Output:\n///   Item 0 - A\n///   Item 1 - B\n///   Item 2 - C\n///   Item 3 - D\n///\ntemplate <typename R> detail::enumerator<R> enumerate(R &&TheRange) {\n  return detail::enumerator<R>(std::forward<R>(TheRange));\n}\n\nnamespace detail {\n\ntemplate <typename F, typename Tuple, std::size_t... I>\ndecltype(auto) apply_tuple_impl(F &&f, Tuple &&t, std::index_sequence<I...>) {\n  return std::forward<F>(f)(std::get<I>(std::forward<Tuple>(t))...);\n}\n\n} // end namespace detail\n\n/// Given an input tuple (a1, a2, ..., an), pass the arguments of the\n/// tuple variadically to f as if by calling f(a1, a2, ..., an) and\n/// return the result.\ntemplate <typename F, typename Tuple>\ndecltype(auto) apply_tuple(F &&f, Tuple &&t) {\n  using Indices = std::make_index_sequence<\n      std::tuple_size<typename std::decay<Tuple>::type>::value>;\n\n  return detail::apply_tuple_impl(std::forward<F>(f), std::forward<Tuple>(t),\n                                  Indices{});\n}\n\n/// Return true if the sequence [Begin, End) has exactly N items. Runs in O(N)\n/// time. Not meant for use with random-access iterators.\n/// Can optionally take a predicate to filter lazily some items.\ntemplate <typename IterTy,\n          typename Pred = bool (*)(const decltype(*std::declval<IterTy>()) &)>\nbool hasNItems(\n    IterTy &&Begin, IterTy &&End, unsigned N,\n    Pred &&ShouldBeCounted =\n        [](const decltype(*std::declval<IterTy>()) &) { return true; },\n    std::enable_if_t<\n        !std::is_base_of<std::random_access_iterator_tag,\n                         typename std::iterator_traits<std::remove_reference_t<\n                             decltype(Begin)>>::iterator_category>::value,\n        void> * = nullptr) {\n  for (; N; ++Begin) {\n    if (Begin == End)\n      return false; // Too few.\n    N -= ShouldBeCounted(*Begin);\n  }\n  for (; Begin != End; ++Begin)\n    if (ShouldBeCounted(*Begin))\n      return false; // Too many.\n  return true;\n}\n\n/// Return true if the sequence [Begin, End) has N or more items. Runs in O(N)\n/// time. Not meant for use with random-access iterators.\n/// Can optionally take a predicate to lazily filter some items.\ntemplate <typename IterTy,\n          typename Pred = bool (*)(const decltype(*std::declval<IterTy>()) &)>\nbool hasNItemsOrMore(\n    IterTy &&Begin, IterTy &&End, unsigned N,\n    Pred &&ShouldBeCounted =\n        [](const decltype(*std::declval<IterTy>()) &) { return true; },\n    std::enable_if_t<\n        !std::is_base_of<std::random_access_iterator_tag,\n                         typename std::iterator_traits<std::remove_reference_t<\n                             decltype(Begin)>>::iterator_category>::value,\n        void> * = nullptr) {\n  for (; N; ++Begin) {\n    if (Begin == End)\n      return false; // Too few.\n    N -= ShouldBeCounted(*Begin);\n  }\n  return true;\n}\n\n/// Returns true if the sequence [Begin, End) has N or less items. Can\n/// optionally take a predicate to lazily filter some items.\ntemplate <typename IterTy,\n          typename Pred = bool (*)(const decltype(*std::declval<IterTy>()) &)>\nbool hasNItemsOrLess(\n    IterTy &&Begin, IterTy &&End, unsigned N,\n    Pred &&ShouldBeCounted = [](const decltype(*std::declval<IterTy>()) &) {\n      return true;\n    }) {\n  assert(N != std::numeric_limits<unsigned>::max());\n  return !hasNItemsOrMore(Begin, End, N + 1, ShouldBeCounted);\n}\n\n/// Returns true if the given container has exactly N items\ntemplate <typename ContainerTy> bool hasNItems(ContainerTy &&C, unsigned N) {\n  return hasNItems(std::begin(C), std::end(C), N);\n}\n\n/// Returns true if the given container has N or more items\ntemplate <typename ContainerTy>\nbool hasNItemsOrMore(ContainerTy &&C, unsigned N) {\n  return hasNItemsOrMore(std::begin(C), std::end(C), N);\n}\n\n/// Returns true if the given container has N or less items\ntemplate <typename ContainerTy>\nbool hasNItemsOrLess(ContainerTy &&C, unsigned N) {\n  return hasNItemsOrLess(std::begin(C), std::end(C), N);\n}\n\n/// Returns a raw pointer that represents the same address as the argument.\n///\n/// This implementation can be removed once we move to C++20 where it's defined\n/// as std::to_address().\n///\n/// The std::pointer_traits<>::to_address(p) variations of these overloads has\n/// not been implemented.\ntemplate <class Ptr> auto to_address(const Ptr &P) { return P.operator->(); }\ntemplate <class T> constexpr T *to_address(T *P) { return P; }\n\n} // end namespace llvm\n\n#endif // LLVM_ADT_STLEXTRAS_H\n"}, "54": {"id": 54, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IRBuilder.h", "content": "//===- llvm/IRBuilder.h - Builder for LLVM Instructions ---------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file defines the IRBuilder class, which is used as a convenient way\n// to create LLVM instructions with a consistent and simplified interface.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_IR_IRBUILDER_H\n#define LLVM_IR_IRBUILDER_H\n\n#include \"llvm-c/Types.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/Constant.h\"\n#include \"llvm/IR/ConstantFolder.h\"\n#include \"llvm/IR/Constants.h\"\n#include \"llvm/IR/DataLayout.h\"\n#include \"llvm/IR/DebugInfoMetadata.h\"\n#include \"llvm/IR/DebugLoc.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/GlobalVariable.h\"\n#include \"llvm/IR/InstrTypes.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/IntrinsicInst.h\"\n#include \"llvm/IR/LLVMContext.h\"\n#include \"llvm/IR/Module.h\"\n#include \"llvm/IR/Operator.h\"\n#include \"llvm/IR/Type.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/AtomicOrdering.h\"\n#include \"llvm/Support/CBindingWrapping.h\"\n#include \"llvm/Support/Casting.h\"\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <functional>\n#include <utility>\n\nnamespace llvm {\n\nclass APInt;\nclass MDNode;\nclass Use;\n\n/// This provides the default implementation of the IRBuilder\n/// 'InsertHelper' method that is called whenever an instruction is created by\n/// IRBuilder and needs to be inserted.\n///\n/// By default, this inserts the instruction at the insertion point.\nclass IRBuilderDefaultInserter {\npublic:\n  virtual ~IRBuilderDefaultInserter();\n\n  virtual void InsertHelper(Instruction *I, const Twine &Name,\n                            BasicBlock *BB,\n                            BasicBlock::iterator InsertPt) const {\n    if (BB) BB->getInstList().insert(InsertPt, I);\n    I->setName(Name);\n  }\n};\n\n/// Provides an 'InsertHelper' that calls a user-provided callback after\n/// performing the default insertion.\nclass IRBuilderCallbackInserter : public IRBuilderDefaultInserter {\n  std::function<void(Instruction *)> Callback;\n\npublic:\n  virtual ~IRBuilderCallbackInserter();\n\n  IRBuilderCallbackInserter(std::function<void(Instruction *)> Callback)\n      : Callback(std::move(Callback)) {}\n\n  void InsertHelper(Instruction *I, const Twine &Name,\n                    BasicBlock *BB,\n                    BasicBlock::iterator InsertPt) const override {\n    IRBuilderDefaultInserter::InsertHelper(I, Name, BB, InsertPt);\n    Callback(I);\n  }\n};\n\n/// Common base class shared among various IRBuilders.\nclass IRBuilderBase {\n  /// Pairs of (metadata kind, MDNode *) that should be added to all newly\n  /// created instructions, like !dbg metadata.\n  SmallVector<std::pair<unsigned, MDNode *>, 2> MetadataToCopy;\n\n  /// Add or update the an entry (Kind, MD) to MetadataToCopy, if \\p MD is not\n  /// null. If \\p MD is null, remove the entry with \\p Kind.\n  void AddOrRemoveMetadataToCopy(unsigned Kind, MDNode *MD) {\n    if (!MD) {\n      erase_if(MetadataToCopy, [Kind](const std::pair<unsigned, MDNode *> &KV) {\n        return KV.first == Kind;\n      });\n      return;\n    }\n\n    for (auto &KV : MetadataToCopy)\n      if (KV.first == Kind) {\n        KV.second = MD;\n        return;\n      }\n\n    MetadataToCopy.emplace_back(Kind, MD);\n  }\n\nprotected:\n  BasicBlock *BB;\n  BasicBlock::iterator InsertPt;\n  LLVMContext &Context;\n  const IRBuilderFolder &Folder;\n  const IRBuilderDefaultInserter &Inserter;\n\n  MDNode *DefaultFPMathTag;\n  FastMathFlags FMF;\n\n  bool IsFPConstrained;\n  fp::ExceptionBehavior DefaultConstrainedExcept;\n  RoundingMode DefaultConstrainedRounding;\n\n  ArrayRef<OperandBundleDef> DefaultOperandBundles;\n\npublic:\n  IRBuilderBase(LLVMContext &context, const IRBuilderFolder &Folder,\n                const IRBuilderDefaultInserter &Inserter,\n                MDNode *FPMathTag, ArrayRef<OperandBundleDef> OpBundles)\n      : Context(context), Folder(Folder), Inserter(Inserter),\n        DefaultFPMathTag(FPMathTag), IsFPConstrained(false),\n        DefaultConstrainedExcept(fp::ebStrict),\n        DefaultConstrainedRounding(RoundingMode::Dynamic),\n        DefaultOperandBundles(OpBundles) {\n    ClearInsertionPoint();\n  }\n\n  /// Insert and return the specified instruction.\n  template<typename InstTy>\n  InstTy *Insert(InstTy *I, const Twine &Name = \"\") const {\n    Inserter.InsertHelper(I, Name, BB, InsertPt);\n    AddMetadataToInst(I);\n    return I;\n  }\n\n  /// No-op overload to handle constants.\n  Constant *Insert(Constant *C, const Twine& = \"\") const {\n    return C;\n  }\n\n  Value *Insert(Value *V, const Twine &Name = \"\") const {\n    if (Instruction *I = dyn_cast<Instruction>(V))\n      return Insert(I, Name);\n    assert(isa<Constant>(V));\n    return V;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Builder configuration methods\n  //===--------------------------------------------------------------------===//\n\n  /// Clear the insertion point: created instructions will not be\n  /// inserted into a block.\n  void ClearInsertionPoint() {\n    BB = nullptr;\n    InsertPt = BasicBlock::iterator();\n  }\n\n  BasicBlock *GetInsertBlock() const { return BB; }\n  BasicBlock::iterator GetInsertPoint() const { return InsertPt; }\n  LLVMContext &getContext() const { return Context; }\n\n  /// This specifies that created instructions should be appended to the\n  /// end of the specified block.\n  void SetInsertPoint(BasicBlock *TheBB) {\n    BB = TheBB;\n    InsertPt = BB->end();\n  }\n\n  /// This specifies that created instructions should be inserted before\n  /// the specified instruction.\n  void SetInsertPoint(Instruction *I) {\n    BB = I->getParent();\n    InsertPt = I->getIterator();\n    assert(InsertPt != BB->end() && \"Can't read debug loc from end()\");\n    SetCurrentDebugLocation(I->getDebugLoc());\n  }\n\n  /// This specifies that created instructions should be inserted at the\n  /// specified point.\n  void SetInsertPoint(BasicBlock *TheBB, BasicBlock::iterator IP) {\n    BB = TheBB;\n    InsertPt = IP;\n    if (IP != TheBB->end())\n      SetCurrentDebugLocation(IP->getDebugLoc());\n  }\n\n  /// Set location information used by debugging information.\n  void SetCurrentDebugLocation(DebugLoc L) {\n    AddOrRemoveMetadataToCopy(LLVMContext::MD_dbg, L.getAsMDNode());\n  }\n\n  /// Collect metadata with IDs \\p MetadataKinds from \\p Src which should be\n  /// added to all created instructions. Entries present in MedataDataToCopy but\n  /// not on \\p Src will be dropped from MetadataToCopy.\n  void CollectMetadataToCopy(Instruction *Src,\n                             ArrayRef<unsigned> MetadataKinds) {\n    for (unsigned K : MetadataKinds)\n      AddOrRemoveMetadataToCopy(K, Src->getMetadata(K));\n  }\n\n  /// Get location information used by debugging information.\n  DebugLoc getCurrentDebugLocation() const {\n    for (auto &KV : MetadataToCopy)\n      if (KV.first == LLVMContext::MD_dbg)\n        return {cast<DILocation>(KV.second)};\n\n    return {};\n  }\n\n  /// If this builder has a current debug location, set it on the\n  /// specified instruction.\n  void SetInstDebugLocation(Instruction *I) const {\n    for (const auto &KV : MetadataToCopy)\n      if (KV.first == LLVMContext::MD_dbg) {\n        I->setDebugLoc(DebugLoc(KV.second));\n        return;\n      }\n  }\n\n  /// Add all entries in MetadataToCopy to \\p I.\n  void AddMetadataToInst(Instruction *I) const {\n    for (auto &KV : MetadataToCopy)\n      I->setMetadata(KV.first, KV.second);\n  }\n\n  /// Get the return type of the current function that we're emitting\n  /// into.\n  Type *getCurrentFunctionReturnType() const;\n\n  /// InsertPoint - A saved insertion point.\n  class InsertPoint {\n    BasicBlock *Block = nullptr;\n    BasicBlock::iterator Point;\n\n  public:\n    /// Creates a new insertion point which doesn't point to anything.\n    InsertPoint() = default;\n\n    /// Creates a new insertion point at the given location.\n    InsertPoint(BasicBlock *InsertBlock, BasicBlock::iterator InsertPoint)\n        : Block(InsertBlock), Point(InsertPoint) {}\n\n    /// Returns true if this insert point is set.\n    bool isSet() const { return (Block != nullptr); }\n\n    BasicBlock *getBlock() const { return Block; }\n    BasicBlock::iterator getPoint() const { return Point; }\n  };\n\n  /// Returns the current insert point.\n  InsertPoint saveIP() const {\n    return InsertPoint(GetInsertBlock(), GetInsertPoint());\n  }\n\n  /// Returns the current insert point, clearing it in the process.\n  InsertPoint saveAndClearIP() {\n    InsertPoint IP(GetInsertBlock(), GetInsertPoint());\n    ClearInsertionPoint();\n    return IP;\n  }\n\n  /// Sets the current insert point to a previously-saved location.\n  void restoreIP(InsertPoint IP) {\n    if (IP.isSet())\n      SetInsertPoint(IP.getBlock(), IP.getPoint());\n    else\n      ClearInsertionPoint();\n  }\n\n  /// Get the floating point math metadata being used.\n  MDNode *getDefaultFPMathTag() const { return DefaultFPMathTag; }\n\n  /// Get the flags to be applied to created floating point ops\n  FastMathFlags getFastMathFlags() const { return FMF; }\n\n  FastMathFlags &getFastMathFlags() { return FMF; }\n\n  /// Clear the fast-math flags.\n  void clearFastMathFlags() { FMF.clear(); }\n\n  /// Set the floating point math metadata to be used.\n  void setDefaultFPMathTag(MDNode *FPMathTag) { DefaultFPMathTag = FPMathTag; }\n\n  /// Set the fast-math flags to be used with generated fp-math operators\n  void setFastMathFlags(FastMathFlags NewFMF) { FMF = NewFMF; }\n\n  /// Enable/Disable use of constrained floating point math. When\n  /// enabled the CreateF<op>() calls instead create constrained\n  /// floating point intrinsic calls. Fast math flags are unaffected\n  /// by this setting.\n  void setIsFPConstrained(bool IsCon) { IsFPConstrained = IsCon; }\n\n  /// Query for the use of constrained floating point math\n  bool getIsFPConstrained() { return IsFPConstrained; }\n\n  /// Set the exception handling to be used with constrained floating point\n  void setDefaultConstrainedExcept(fp::ExceptionBehavior NewExcept) {\n#ifndef NDEBUG\n    Optional<StringRef> ExceptStr = ExceptionBehaviorToStr(NewExcept);\n    assert(ExceptStr.hasValue() && \"Garbage strict exception behavior!\");\n#endif\n    DefaultConstrainedExcept = NewExcept;\n  }\n\n  /// Set the rounding mode handling to be used with constrained floating point\n  void setDefaultConstrainedRounding(RoundingMode NewRounding) {\n#ifndef NDEBUG\n    Optional<StringRef> RoundingStr = RoundingModeToStr(NewRounding);\n    assert(RoundingStr.hasValue() && \"Garbage strict rounding mode!\");\n#endif\n    DefaultConstrainedRounding = NewRounding;\n  }\n\n  /// Get the exception handling used with constrained floating point\n  fp::ExceptionBehavior getDefaultConstrainedExcept() {\n    return DefaultConstrainedExcept;\n  }\n\n  /// Get the rounding mode handling used with constrained floating point\n  RoundingMode getDefaultConstrainedRounding() {\n    return DefaultConstrainedRounding;\n  }\n\n  void setConstrainedFPFunctionAttr() {\n    assert(BB && \"Must have a basic block to set any function attributes!\");\n\n    Function *F = BB->getParent();\n    if (!F->hasFnAttribute(Attribute::StrictFP)) {\n      F->addFnAttr(Attribute::StrictFP);\n    }\n  }\n\n  void setConstrainedFPCallAttr(CallBase *I) {\n    I->addAttribute(AttributeList::FunctionIndex, Attribute::StrictFP);\n  }\n\n  void setDefaultOperandBundles(ArrayRef<OperandBundleDef> OpBundles) {\n    DefaultOperandBundles = OpBundles;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // RAII helpers.\n  //===--------------------------------------------------------------------===//\n\n  // RAII object that stores the current insertion point and restores it\n  // when the object is destroyed. This includes the debug location.\n  class InsertPointGuard {\n    IRBuilderBase &Builder;\n    AssertingVH<BasicBlock> Block;\n    BasicBlock::iterator Point;\n    DebugLoc DbgLoc;\n\n  public:\n    InsertPointGuard(IRBuilderBase &B)\n        : Builder(B), Block(B.GetInsertBlock()), Point(B.GetInsertPoint()),\n          DbgLoc(B.getCurrentDebugLocation()) {}\n\n    InsertPointGuard(const InsertPointGuard &) = delete;\n    InsertPointGuard &operator=(const InsertPointGuard &) = delete;\n\n    ~InsertPointGuard() {\n      Builder.restoreIP(InsertPoint(Block, Point));\n      Builder.SetCurrentDebugLocation(DbgLoc);\n    }\n  };\n\n  // RAII object that stores the current fast math settings and restores\n  // them when the object is destroyed.\n  class FastMathFlagGuard {\n    IRBuilderBase &Builder;\n    FastMathFlags FMF;\n    MDNode *FPMathTag;\n    bool IsFPConstrained;\n    fp::ExceptionBehavior DefaultConstrainedExcept;\n    RoundingMode DefaultConstrainedRounding;\n\n  public:\n    FastMathFlagGuard(IRBuilderBase &B)\n        : Builder(B), FMF(B.FMF), FPMathTag(B.DefaultFPMathTag),\n          IsFPConstrained(B.IsFPConstrained),\n          DefaultConstrainedExcept(B.DefaultConstrainedExcept),\n          DefaultConstrainedRounding(B.DefaultConstrainedRounding) {}\n\n    FastMathFlagGuard(const FastMathFlagGuard &) = delete;\n    FastMathFlagGuard &operator=(const FastMathFlagGuard &) = delete;\n\n    ~FastMathFlagGuard() {\n      Builder.FMF = FMF;\n      Builder.DefaultFPMathTag = FPMathTag;\n      Builder.IsFPConstrained = IsFPConstrained;\n      Builder.DefaultConstrainedExcept = DefaultConstrainedExcept;\n      Builder.DefaultConstrainedRounding = DefaultConstrainedRounding;\n    }\n  };\n\n  // RAII object that stores the current default operand bundles and restores\n  // them when the object is destroyed.\n  class OperandBundlesGuard {\n    IRBuilderBase &Builder;\n    ArrayRef<OperandBundleDef> DefaultOperandBundles;\n\n  public:\n    OperandBundlesGuard(IRBuilderBase &B)\n        : Builder(B), DefaultOperandBundles(B.DefaultOperandBundles) {}\n\n    OperandBundlesGuard(const OperandBundlesGuard &) = delete;\n    OperandBundlesGuard &operator=(const OperandBundlesGuard &) = delete;\n\n    ~OperandBundlesGuard() {\n      Builder.DefaultOperandBundles = DefaultOperandBundles;\n    }\n  };\n\n\n  //===--------------------------------------------------------------------===//\n  // Miscellaneous creation methods.\n  //===--------------------------------------------------------------------===//\n\n  /// Make a new global variable with initializer type i8*\n  ///\n  /// Make a new global variable with an initializer that has array of i8 type\n  /// filled in with the null terminated string value specified.  The new global\n  /// variable will be marked mergable with any others of the same contents.  If\n  /// Name is specified, it is the name of the global variable created.\n  ///\n  /// If no module is given via \\p M, it is take from the insertion point basic\n  /// block.\n  GlobalVariable *CreateGlobalString(StringRef Str, const Twine &Name = \"\",\n                                     unsigned AddressSpace = 0,\n                                     Module *M = nullptr);\n\n  /// Get a constant value representing either true or false.\n  ConstantInt *getInt1(bool V) {\n    return ConstantInt::get(getInt1Ty(), V);\n  }\n\n  /// Get the constant value for i1 true.\n  ConstantInt *getTrue() {\n    return ConstantInt::getTrue(Context);\n  }\n\n  /// Get the constant value for i1 false.\n  ConstantInt *getFalse() {\n    return ConstantInt::getFalse(Context);\n  }\n\n  /// Get a constant 8-bit value.\n  ConstantInt *getInt8(uint8_t C) {\n    return ConstantInt::get(getInt8Ty(), C);\n  }\n\n  /// Get a constant 16-bit value.\n  ConstantInt *getInt16(uint16_t C) {\n    return ConstantInt::get(getInt16Ty(), C);\n  }\n\n  /// Get a constant 32-bit value.\n  ConstantInt *getInt32(uint32_t C) {\n    return ConstantInt::get(getInt32Ty(), C);\n  }\n\n  /// Get a constant 64-bit value.\n  ConstantInt *getInt64(uint64_t C) {\n    return ConstantInt::get(getInt64Ty(), C);\n  }\n\n  /// Get a constant N-bit value, zero extended or truncated from\n  /// a 64-bit value.\n  ConstantInt *getIntN(unsigned N, uint64_t C) {\n    return ConstantInt::get(getIntNTy(N), C);\n  }\n\n  /// Get a constant integer value.\n  ConstantInt *getInt(const APInt &AI) {\n    return ConstantInt::get(Context, AI);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Type creation methods\n  //===--------------------------------------------------------------------===//\n\n  /// Fetch the type representing a single bit\n  IntegerType *getInt1Ty() {\n    return Type::getInt1Ty(Context);\n  }\n\n  /// Fetch the type representing an 8-bit integer.\n  IntegerType *getInt8Ty() {\n    return Type::getInt8Ty(Context);\n  }\n\n  /// Fetch the type representing a 16-bit integer.\n  IntegerType *getInt16Ty() {\n    return Type::getInt16Ty(Context);\n  }\n\n  /// Fetch the type representing a 32-bit integer.\n  IntegerType *getInt32Ty() {\n    return Type::getInt32Ty(Context);\n  }\n\n  /// Fetch the type representing a 64-bit integer.\n  IntegerType *getInt64Ty() {\n    return Type::getInt64Ty(Context);\n  }\n\n  /// Fetch the type representing a 128-bit integer.\n  IntegerType *getInt128Ty() { return Type::getInt128Ty(Context); }\n\n  /// Fetch the type representing an N-bit integer.\n  IntegerType *getIntNTy(unsigned N) {\n    return Type::getIntNTy(Context, N);\n  }\n\n  /// Fetch the type representing a 16-bit floating point value.\n  Type *getHalfTy() {\n    return Type::getHalfTy(Context);\n  }\n\n  /// Fetch the type representing a 16-bit brain floating point value.\n  Type *getBFloatTy() {\n    return Type::getBFloatTy(Context);\n  }\n\n  /// Fetch the type representing a 32-bit floating point value.\n  Type *getFloatTy() {\n    return Type::getFloatTy(Context);\n  }\n\n  /// Fetch the type representing a 64-bit floating point value.\n  Type *getDoubleTy() {\n    return Type::getDoubleTy(Context);\n  }\n\n  /// Fetch the type representing void.\n  Type *getVoidTy() {\n    return Type::getVoidTy(Context);\n  }\n\n  /// Fetch the type representing a pointer to an 8-bit integer value.\n  PointerType *getInt8PtrTy(unsigned AddrSpace = 0) {\n    return Type::getInt8PtrTy(Context, AddrSpace);\n  }\n\n  /// Fetch the type representing a pointer to an integer value.\n  IntegerType *getIntPtrTy(const DataLayout &DL, unsigned AddrSpace = 0) {\n    return DL.getIntPtrType(Context, AddrSpace);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Intrinsic creation methods\n  //===--------------------------------------------------------------------===//\n\n  /// Create and insert a memset to the specified pointer and the\n  /// specified value.\n  ///\n  /// If the pointer isn't an i8*, it will be converted. If a TBAA tag is\n  /// specified, it will be added to the instruction. Likewise with alias.scope\n  /// and noalias tags.\n  CallInst *CreateMemSet(Value *Ptr, Value *Val, uint64_t Size,\n                         MaybeAlign Align, bool isVolatile = false,\n                         MDNode *TBAATag = nullptr, MDNode *ScopeTag = nullptr,\n                         MDNode *NoAliasTag = nullptr) {\n    return CreateMemSet(Ptr, Val, getInt64(Size), Align, isVolatile,\n                        TBAATag, ScopeTag, NoAliasTag);\n  }\n\n  CallInst *CreateMemSet(Value *Ptr, Value *Val, Value *Size, MaybeAlign Align,\n                         bool isVolatile = false, MDNode *TBAATag = nullptr,\n                         MDNode *ScopeTag = nullptr,\n                         MDNode *NoAliasTag = nullptr);\n\n  /// Create and insert an element unordered-atomic memset of the region of\n  /// memory starting at the given pointer to the given value.\n  ///\n  /// If the pointer isn't an i8*, it will be converted. If a TBAA tag is\n  /// specified, it will be added to the instruction. Likewise with alias.scope\n  /// and noalias tags.\n  CallInst *CreateElementUnorderedAtomicMemSet(Value *Ptr, Value *Val,\n                                               uint64_t Size, Align Alignment,\n                                               uint32_t ElementSize,\n                                               MDNode *TBAATag = nullptr,\n                                               MDNode *ScopeTag = nullptr,\n                                               MDNode *NoAliasTag = nullptr) {\n    return CreateElementUnorderedAtomicMemSet(Ptr, Val, getInt64(Size),\n                                              Align(Alignment), ElementSize,\n                                              TBAATag, ScopeTag, NoAliasTag);\n  }\n\n  CallInst *CreateElementUnorderedAtomicMemSet(Value *Ptr, Value *Val,\n                                               Value *Size, Align Alignment,\n                                               uint32_t ElementSize,\n                                               MDNode *TBAATag = nullptr,\n                                               MDNode *ScopeTag = nullptr,\n                                               MDNode *NoAliasTag = nullptr);\n\n  /// Create and insert a memcpy between the specified pointers.\n  ///\n  /// If the pointers aren't i8*, they will be converted.  If a TBAA tag is\n  /// specified, it will be added to the instruction. Likewise with alias.scope\n  /// and noalias tags.\n  CallInst *CreateMemCpy(Value *Dst, MaybeAlign DstAlign, Value *Src,\n                         MaybeAlign SrcAlign, uint64_t Size,\n                         bool isVolatile = false, MDNode *TBAATag = nullptr,\n                         MDNode *TBAAStructTag = nullptr,\n                         MDNode *ScopeTag = nullptr,\n                         MDNode *NoAliasTag = nullptr) {\n    return CreateMemCpy(Dst, DstAlign, Src, SrcAlign, getInt64(Size),\n                        isVolatile, TBAATag, TBAAStructTag, ScopeTag,\n                        NoAliasTag);\n  }\n\n  CallInst *CreateMemTransferInst(\n      Intrinsic::ID IntrID, Value *Dst, MaybeAlign DstAlign, Value *Src,\n      MaybeAlign SrcAlign, Value *Size, bool isVolatile = false,\n      MDNode *TBAATag = nullptr, MDNode *TBAAStructTag = nullptr,\n      MDNode *ScopeTag = nullptr, MDNode *NoAliasTag = nullptr);\n\n  CallInst *CreateMemCpy(Value *Dst, MaybeAlign DstAlign, Value *Src,\n                         MaybeAlign SrcAlign, Value *Size,\n                         bool isVolatile = false, MDNode *TBAATag = nullptr,\n                         MDNode *TBAAStructTag = nullptr,\n                         MDNode *ScopeTag = nullptr,\n                         MDNode *NoAliasTag = nullptr) {\n    return CreateMemTransferInst(Intrinsic::memcpy, Dst, DstAlign, Src,\n                                 SrcAlign, Size, isVolatile, TBAATag,\n                                 TBAAStructTag, ScopeTag, NoAliasTag);\n  }\n\n  CallInst *CreateMemCpyInline(Value *Dst, MaybeAlign DstAlign, Value *Src,\n                               MaybeAlign SrcAlign, Value *Size);\n\n  /// Create and insert an element unordered-atomic memcpy between the\n  /// specified pointers.\n  ///\n  /// DstAlign/SrcAlign are the alignments of the Dst/Src pointers, respectively.\n  ///\n  /// If the pointers aren't i8*, they will be converted.  If a TBAA tag is\n  /// specified, it will be added to the instruction. Likewise with alias.scope\n  /// and noalias tags.\n  CallInst *CreateElementUnorderedAtomicMemCpy(\n      Value *Dst, Align DstAlign, Value *Src, Align SrcAlign, Value *Size,\n      uint32_t ElementSize, MDNode *TBAATag = nullptr,\n      MDNode *TBAAStructTag = nullptr, MDNode *ScopeTag = nullptr,\n      MDNode *NoAliasTag = nullptr);\n\n  CallInst *CreateMemMove(Value *Dst, MaybeAlign DstAlign, Value *Src,\n                          MaybeAlign SrcAlign, uint64_t Size,\n                          bool isVolatile = false, MDNode *TBAATag = nullptr,\n                          MDNode *ScopeTag = nullptr,\n                          MDNode *NoAliasTag = nullptr) {\n    return CreateMemMove(Dst, DstAlign, Src, SrcAlign, getInt64(Size),\n                         isVolatile, TBAATag, ScopeTag, NoAliasTag);\n  }\n\n  CallInst *CreateMemMove(Value *Dst, MaybeAlign DstAlign, Value *Src,\n                          MaybeAlign SrcAlign, Value *Size,\n                          bool isVolatile = false, MDNode *TBAATag = nullptr,\n                          MDNode *ScopeTag = nullptr,\n                          MDNode *NoAliasTag = nullptr);\n\n  /// \\brief Create and insert an element unordered-atomic memmove between the\n  /// specified pointers.\n  ///\n  /// DstAlign/SrcAlign are the alignments of the Dst/Src pointers,\n  /// respectively.\n  ///\n  /// If the pointers aren't i8*, they will be converted.  If a TBAA tag is\n  /// specified, it will be added to the instruction. Likewise with alias.scope\n  /// and noalias tags.\n  CallInst *CreateElementUnorderedAtomicMemMove(\n      Value *Dst, Align DstAlign, Value *Src, Align SrcAlign, Value *Size,\n      uint32_t ElementSize, MDNode *TBAATag = nullptr,\n      MDNode *TBAAStructTag = nullptr, MDNode *ScopeTag = nullptr,\n      MDNode *NoAliasTag = nullptr);\n\n  /// Create a vector fadd reduction intrinsic of the source vector.\n  /// The first parameter is a scalar accumulator value for ordered reductions.\n  CallInst *CreateFAddReduce(Value *Acc, Value *Src);\n\n  /// Create a vector fmul reduction intrinsic of the source vector.\n  /// The first parameter is a scalar accumulator value for ordered reductions.\n  CallInst *CreateFMulReduce(Value *Acc, Value *Src);\n\n  /// Create a vector int add reduction intrinsic of the source vector.\n  CallInst *CreateAddReduce(Value *Src);\n\n  /// Create a vector int mul reduction intrinsic of the source vector.\n  CallInst *CreateMulReduce(Value *Src);\n\n  /// Create a vector int AND reduction intrinsic of the source vector.\n  CallInst *CreateAndReduce(Value *Src);\n\n  /// Create a vector int OR reduction intrinsic of the source vector.\n  CallInst *CreateOrReduce(Value *Src);\n\n  /// Create a vector int XOR reduction intrinsic of the source vector.\n  CallInst *CreateXorReduce(Value *Src);\n\n  /// Create a vector integer max reduction intrinsic of the source\n  /// vector.\n  CallInst *CreateIntMaxReduce(Value *Src, bool IsSigned = false);\n\n  /// Create a vector integer min reduction intrinsic of the source\n  /// vector.\n  CallInst *CreateIntMinReduce(Value *Src, bool IsSigned = false);\n\n  /// Create a vector float max reduction intrinsic of the source\n  /// vector.\n  CallInst *CreateFPMaxReduce(Value *Src);\n\n  /// Create a vector float min reduction intrinsic of the source\n  /// vector.\n  CallInst *CreateFPMinReduce(Value *Src);\n\n  /// Create a lifetime.start intrinsic.\n  ///\n  /// If the pointer isn't i8* it will be converted.\n  CallInst *CreateLifetimeStart(Value *Ptr, ConstantInt *Size = nullptr);\n\n  /// Create a lifetime.end intrinsic.\n  ///\n  /// If the pointer isn't i8* it will be converted.\n  CallInst *CreateLifetimeEnd(Value *Ptr, ConstantInt *Size = nullptr);\n\n  /// Create a call to invariant.start intrinsic.\n  ///\n  /// If the pointer isn't i8* it will be converted.\n  CallInst *CreateInvariantStart(Value *Ptr, ConstantInt *Size = nullptr);\n\n  /// Create a call to Masked Load intrinsic\n  CallInst *CreateMaskedLoad(Value *Ptr, Align Alignment, Value *Mask,\n                             Value *PassThru = nullptr, const Twine &Name = \"\");\n\n  /// Create a call to Masked Store intrinsic\n  CallInst *CreateMaskedStore(Value *Val, Value *Ptr, Align Alignment,\n                              Value *Mask);\n\n  /// Create a call to Masked Gather intrinsic\n  CallInst *CreateMaskedGather(Value *Ptrs, Align Alignment,\n                               Value *Mask = nullptr, Value *PassThru = nullptr,\n                               const Twine &Name = \"\");\n\n  /// Create a call to Masked Scatter intrinsic\n  CallInst *CreateMaskedScatter(Value *Val, Value *Ptrs, Align Alignment,\n                                Value *Mask = nullptr);\n\n  /// Create an assume intrinsic call that allows the optimizer to\n  /// assume that the provided condition will be true.\n  ///\n  /// The optional argument \\p OpBundles specifies operand bundles that are\n  /// added to the call instruction.\n  CallInst *CreateAssumption(Value *Cond,\n                             ArrayRef<OperandBundleDef> OpBundles = llvm::None);\n\n  /// Create a llvm.experimental.noalias.scope.decl intrinsic call.\n  Instruction *CreateNoAliasScopeDeclaration(Value *Scope);\n  Instruction *CreateNoAliasScopeDeclaration(MDNode *ScopeTag) {\n    return CreateNoAliasScopeDeclaration(\n        MetadataAsValue::get(Context, ScopeTag));\n  }\n\n  /// Create a call to the experimental.gc.statepoint intrinsic to\n  /// start a new statepoint sequence.\n  CallInst *CreateGCStatepointCall(uint64_t ID, uint32_t NumPatchBytes,\n                                   Value *ActualCallee,\n                                   ArrayRef<Value *> CallArgs,\n                                   Optional<ArrayRef<Value *>> DeoptArgs,\n                                   ArrayRef<Value *> GCArgs,\n                                   const Twine &Name = \"\");\n\n  /// Create a call to the experimental.gc.statepoint intrinsic to\n  /// start a new statepoint sequence.\n  CallInst *CreateGCStatepointCall(uint64_t ID, uint32_t NumPatchBytes,\n                                   Value *ActualCallee, uint32_t Flags,\n                                   ArrayRef<Value *> CallArgs,\n                                   Optional<ArrayRef<Use>> TransitionArgs,\n                                   Optional<ArrayRef<Use>> DeoptArgs,\n                                   ArrayRef<Value *> GCArgs,\n                                   const Twine &Name = \"\");\n\n  /// Conveninence function for the common case when CallArgs are filled\n  /// in using makeArrayRef(CS.arg_begin(), CS.arg_end()); Use needs to be\n  /// .get()'ed to get the Value pointer.\n  CallInst *CreateGCStatepointCall(uint64_t ID, uint32_t NumPatchBytes,\n                                   Value *ActualCallee, ArrayRef<Use> CallArgs,\n                                   Optional<ArrayRef<Value *>> DeoptArgs,\n                                   ArrayRef<Value *> GCArgs,\n                                   const Twine &Name = \"\");\n\n  /// Create an invoke to the experimental.gc.statepoint intrinsic to\n  /// start a new statepoint sequence.\n  InvokeInst *\n  CreateGCStatepointInvoke(uint64_t ID, uint32_t NumPatchBytes,\n                           Value *ActualInvokee, BasicBlock *NormalDest,\n                           BasicBlock *UnwindDest, ArrayRef<Value *> InvokeArgs,\n                           Optional<ArrayRef<Value *>> DeoptArgs,\n                           ArrayRef<Value *> GCArgs, const Twine &Name = \"\");\n\n  /// Create an invoke to the experimental.gc.statepoint intrinsic to\n  /// start a new statepoint sequence.\n  InvokeInst *CreateGCStatepointInvoke(\n      uint64_t ID, uint32_t NumPatchBytes, Value *ActualInvokee,\n      BasicBlock *NormalDest, BasicBlock *UnwindDest, uint32_t Flags,\n      ArrayRef<Value *> InvokeArgs, Optional<ArrayRef<Use>> TransitionArgs,\n      Optional<ArrayRef<Use>> DeoptArgs, ArrayRef<Value *> GCArgs,\n      const Twine &Name = \"\");\n\n  // Convenience function for the common case when CallArgs are filled in using\n  // makeArrayRef(CS.arg_begin(), CS.arg_end()); Use needs to be .get()'ed to\n  // get the Value *.\n  InvokeInst *\n  CreateGCStatepointInvoke(uint64_t ID, uint32_t NumPatchBytes,\n                           Value *ActualInvokee, BasicBlock *NormalDest,\n                           BasicBlock *UnwindDest, ArrayRef<Use> InvokeArgs,\n                           Optional<ArrayRef<Value *>> DeoptArgs,\n                           ArrayRef<Value *> GCArgs, const Twine &Name = \"\");\n\n  /// Create a call to the experimental.gc.result intrinsic to extract\n  /// the result from a call wrapped in a statepoint.\n  CallInst *CreateGCResult(Instruction *Statepoint,\n                           Type *ResultType,\n                           const Twine &Name = \"\");\n\n  /// Create a call to the experimental.gc.relocate intrinsics to\n  /// project the relocated value of one pointer from the statepoint.\n  CallInst *CreateGCRelocate(Instruction *Statepoint,\n                             int BaseOffset,\n                             int DerivedOffset,\n                             Type *ResultType,\n                             const Twine &Name = \"\");\n\n  /// Create a call to llvm.vscale, multiplied by \\p Scaling. The type of VScale\n  /// will be the same type as that of \\p Scaling.\n  Value *CreateVScale(Constant *Scaling, const Twine &Name = \"\");\n\n  /// Create a call to intrinsic \\p ID with 1 operand which is mangled on its\n  /// type.\n  CallInst *CreateUnaryIntrinsic(Intrinsic::ID ID, Value *V,\n                                 Instruction *FMFSource = nullptr,\n                                 const Twine &Name = \"\");\n\n  /// Create a call to intrinsic \\p ID with 2 operands which is mangled on the\n  /// first type.\n  CallInst *CreateBinaryIntrinsic(Intrinsic::ID ID, Value *LHS, Value *RHS,\n                                  Instruction *FMFSource = nullptr,\n                                  const Twine &Name = \"\");\n\n  /// Create a call to intrinsic \\p ID with \\p args, mangled using \\p Types. If\n  /// \\p FMFSource is provided, copy fast-math-flags from that instruction to\n  /// the intrinsic.\n  CallInst *CreateIntrinsic(Intrinsic::ID ID, ArrayRef<Type *> Types,\n                            ArrayRef<Value *> Args,\n                            Instruction *FMFSource = nullptr,\n                            const Twine &Name = \"\");\n\n  /// Create call to the minnum intrinsic.\n  CallInst *CreateMinNum(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateBinaryIntrinsic(Intrinsic::minnum, LHS, RHS, nullptr, Name);\n  }\n\n  /// Create call to the maxnum intrinsic.\n  CallInst *CreateMaxNum(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateBinaryIntrinsic(Intrinsic::maxnum, LHS, RHS, nullptr, Name);\n  }\n\n  /// Create call to the minimum intrinsic.\n  CallInst *CreateMinimum(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateBinaryIntrinsic(Intrinsic::minimum, LHS, RHS, nullptr, Name);\n  }\n\n  /// Create call to the maximum intrinsic.\n  CallInst *CreateMaximum(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateBinaryIntrinsic(Intrinsic::maximum, LHS, RHS, nullptr, Name);\n  }\n\n  /// Create a call to the experimental.vector.extract intrinsic.\n  CallInst *CreateExtractVector(Type *DstType, Value *SrcVec, Value *Idx,\n                                const Twine &Name = \"\") {\n    return CreateIntrinsic(Intrinsic::experimental_vector_extract,\n                           {DstType, SrcVec->getType()}, {SrcVec, Idx}, nullptr,\n                           Name);\n  }\n\n  /// Create a call to the experimental.vector.insert intrinsic.\n  CallInst *CreateInsertVector(Type *DstType, Value *SrcVec, Value *SubVec,\n                               Value *Idx, const Twine &Name = \"\") {\n    return CreateIntrinsic(Intrinsic::experimental_vector_insert,\n                           {DstType, SubVec->getType()}, {SrcVec, SubVec, Idx},\n                           nullptr, Name);\n  }\n\nprivate:\n  /// Create a call to a masked intrinsic with given Id.\n  CallInst *CreateMaskedIntrinsic(Intrinsic::ID Id, ArrayRef<Value *> Ops,\n                                  ArrayRef<Type *> OverloadedTypes,\n                                  const Twine &Name = \"\");\n\n  Value *getCastedInt8PtrValue(Value *Ptr);\n\n  //===--------------------------------------------------------------------===//\n  // Instruction creation methods: Terminators\n  //===--------------------------------------------------------------------===//\n\nprivate:\n  /// Helper to add branch weight and unpredictable metadata onto an\n  /// instruction.\n  /// \\returns The annotated instruction.\n  template <typename InstTy>\n  InstTy *addBranchMetadata(InstTy *I, MDNode *Weights, MDNode *Unpredictable) {\n    if (Weights)\n      I->setMetadata(LLVMContext::MD_prof, Weights);\n    if (Unpredictable)\n      I->setMetadata(LLVMContext::MD_unpredictable, Unpredictable);\n    return I;\n  }\n\npublic:\n  /// Create a 'ret void' instruction.\n  ReturnInst *CreateRetVoid() {\n    return Insert(ReturnInst::Create(Context));\n  }\n\n  /// Create a 'ret <val>' instruction.\n  ReturnInst *CreateRet(Value *V) {\n    return Insert(ReturnInst::Create(Context, V));\n  }\n\n  /// Create a sequence of N insertvalue instructions,\n  /// with one Value from the retVals array each, that build a aggregate\n  /// return value one value at a time, and a ret instruction to return\n  /// the resulting aggregate value.\n  ///\n  /// This is a convenience function for code that uses aggregate return values\n  /// as a vehicle for having multiple return values.\n  ReturnInst *CreateAggregateRet(Value *const *retVals, unsigned N) {\n    Value *V = UndefValue::get(getCurrentFunctionReturnType());\n    for (unsigned i = 0; i != N; ++i)\n      V = CreateInsertValue(V, retVals[i], i, \"mrv\");\n    return Insert(ReturnInst::Create(Context, V));\n  }\n\n  /// Create an unconditional 'br label X' instruction.\n  BranchInst *CreateBr(BasicBlock *Dest) {\n    return Insert(BranchInst::Create(Dest));\n  }\n\n  /// Create a conditional 'br Cond, TrueDest, FalseDest'\n  /// instruction.\n  BranchInst *CreateCondBr(Value *Cond, BasicBlock *True, BasicBlock *False,\n                           MDNode *BranchWeights = nullptr,\n                           MDNode *Unpredictable = nullptr) {\n    return Insert(addBranchMetadata(BranchInst::Create(True, False, Cond),\n                                    BranchWeights, Unpredictable));\n  }\n\n  /// Create a conditional 'br Cond, TrueDest, FalseDest'\n  /// instruction. Copy branch meta data if available.\n  BranchInst *CreateCondBr(Value *Cond, BasicBlock *True, BasicBlock *False,\n                           Instruction *MDSrc) {\n    BranchInst *Br = BranchInst::Create(True, False, Cond);\n    if (MDSrc) {\n      unsigned WL[4] = {LLVMContext::MD_prof, LLVMContext::MD_unpredictable,\n                        LLVMContext::MD_make_implicit, LLVMContext::MD_dbg};\n      Br->copyMetadata(*MDSrc, makeArrayRef(&WL[0], 4));\n    }\n    return Insert(Br);\n  }\n\n  /// Create a switch instruction with the specified value, default dest,\n  /// and with a hint for the number of cases that will be added (for efficient\n  /// allocation).\n  SwitchInst *CreateSwitch(Value *V, BasicBlock *Dest, unsigned NumCases = 10,\n                           MDNode *BranchWeights = nullptr,\n                           MDNode *Unpredictable = nullptr) {\n    return Insert(addBranchMetadata(SwitchInst::Create(V, Dest, NumCases),\n                                    BranchWeights, Unpredictable));\n  }\n\n  /// Create an indirect branch instruction with the specified address\n  /// operand, with an optional hint for the number of destinations that will be\n  /// added (for efficient allocation).\n  IndirectBrInst *CreateIndirectBr(Value *Addr, unsigned NumDests = 10) {\n    return Insert(IndirectBrInst::Create(Addr, NumDests));\n  }\n\n  /// Create an invoke instruction.\n  InvokeInst *CreateInvoke(FunctionType *Ty, Value *Callee,\n                           BasicBlock *NormalDest, BasicBlock *UnwindDest,\n                           ArrayRef<Value *> Args,\n                           ArrayRef<OperandBundleDef> OpBundles,\n                           const Twine &Name = \"\") {\n    InvokeInst *II =\n        InvokeInst::Create(Ty, Callee, NormalDest, UnwindDest, Args, OpBundles);\n    if (IsFPConstrained)\n      setConstrainedFPCallAttr(II);\n    return Insert(II, Name);\n  }\n  InvokeInst *CreateInvoke(FunctionType *Ty, Value *Callee,\n                           BasicBlock *NormalDest, BasicBlock *UnwindDest,\n                           ArrayRef<Value *> Args = None,\n                           const Twine &Name = \"\") {\n    InvokeInst *II =\n        InvokeInst::Create(Ty, Callee, NormalDest, UnwindDest, Args);\n    if (IsFPConstrained)\n      setConstrainedFPCallAttr(II);\n    return Insert(II, Name);\n  }\n\n  InvokeInst *CreateInvoke(FunctionCallee Callee, BasicBlock *NormalDest,\n                           BasicBlock *UnwindDest, ArrayRef<Value *> Args,\n                           ArrayRef<OperandBundleDef> OpBundles,\n                           const Twine &Name = \"\") {\n    return CreateInvoke(Callee.getFunctionType(), Callee.getCallee(),\n                        NormalDest, UnwindDest, Args, OpBundles, Name);\n  }\n\n  InvokeInst *CreateInvoke(FunctionCallee Callee, BasicBlock *NormalDest,\n                           BasicBlock *UnwindDest,\n                           ArrayRef<Value *> Args = None,\n                           const Twine &Name = \"\") {\n    return CreateInvoke(Callee.getFunctionType(), Callee.getCallee(),\n                        NormalDest, UnwindDest, Args, Name);\n  }\n\n  /// \\brief Create a callbr instruction.\n  CallBrInst *CreateCallBr(FunctionType *Ty, Value *Callee,\n                           BasicBlock *DefaultDest,\n                           ArrayRef<BasicBlock *> IndirectDests,\n                           ArrayRef<Value *> Args = None,\n                           const Twine &Name = \"\") {\n    return Insert(CallBrInst::Create(Ty, Callee, DefaultDest, IndirectDests,\n                                     Args), Name);\n  }\n  CallBrInst *CreateCallBr(FunctionType *Ty, Value *Callee,\n                           BasicBlock *DefaultDest,\n                           ArrayRef<BasicBlock *> IndirectDests,\n                           ArrayRef<Value *> Args,\n                           ArrayRef<OperandBundleDef> OpBundles,\n                           const Twine &Name = \"\") {\n    return Insert(\n        CallBrInst::Create(Ty, Callee, DefaultDest, IndirectDests, Args,\n                           OpBundles), Name);\n  }\n\n  CallBrInst *CreateCallBr(FunctionCallee Callee, BasicBlock *DefaultDest,\n                           ArrayRef<BasicBlock *> IndirectDests,\n                           ArrayRef<Value *> Args = None,\n                           const Twine &Name = \"\") {\n    return CreateCallBr(Callee.getFunctionType(), Callee.getCallee(),\n                        DefaultDest, IndirectDests, Args, Name);\n  }\n  CallBrInst *CreateCallBr(FunctionCallee Callee, BasicBlock *DefaultDest,\n                           ArrayRef<BasicBlock *> IndirectDests,\n                           ArrayRef<Value *> Args,\n                           ArrayRef<OperandBundleDef> OpBundles,\n                           const Twine &Name = \"\") {\n    return CreateCallBr(Callee.getFunctionType(), Callee.getCallee(),\n                        DefaultDest, IndirectDests, Args, Name);\n  }\n\n  ResumeInst *CreateResume(Value *Exn) {\n    return Insert(ResumeInst::Create(Exn));\n  }\n\n  CleanupReturnInst *CreateCleanupRet(CleanupPadInst *CleanupPad,\n                                      BasicBlock *UnwindBB = nullptr) {\n    return Insert(CleanupReturnInst::Create(CleanupPad, UnwindBB));\n  }\n\n  CatchSwitchInst *CreateCatchSwitch(Value *ParentPad, BasicBlock *UnwindBB,\n                                     unsigned NumHandlers,\n                                     const Twine &Name = \"\") {\n    return Insert(CatchSwitchInst::Create(ParentPad, UnwindBB, NumHandlers),\n                  Name);\n  }\n\n  CatchPadInst *CreateCatchPad(Value *ParentPad, ArrayRef<Value *> Args,\n                               const Twine &Name = \"\") {\n    return Insert(CatchPadInst::Create(ParentPad, Args), Name);\n  }\n\n  CleanupPadInst *CreateCleanupPad(Value *ParentPad,\n                                   ArrayRef<Value *> Args = None,\n                                   const Twine &Name = \"\") {\n    return Insert(CleanupPadInst::Create(ParentPad, Args), Name);\n  }\n\n  CatchReturnInst *CreateCatchRet(CatchPadInst *CatchPad, BasicBlock *BB) {\n    return Insert(CatchReturnInst::Create(CatchPad, BB));\n  }\n\n  UnreachableInst *CreateUnreachable() {\n    return Insert(new UnreachableInst(Context));\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Instruction creation methods: Binary Operators\n  //===--------------------------------------------------------------------===//\nprivate:\n  BinaryOperator *CreateInsertNUWNSWBinOp(BinaryOperator::BinaryOps Opc,\n                                          Value *LHS, Value *RHS,\n                                          const Twine &Name,\n                                          bool HasNUW, bool HasNSW) {\n    BinaryOperator *BO = Insert(BinaryOperator::Create(Opc, LHS, RHS), Name);\n    if (HasNUW) BO->setHasNoUnsignedWrap();\n    if (HasNSW) BO->setHasNoSignedWrap();\n    return BO;\n  }\n\n  Instruction *setFPAttrs(Instruction *I, MDNode *FPMD,\n                          FastMathFlags FMF) const {\n    if (!FPMD)\n      FPMD = DefaultFPMathTag;\n    if (FPMD)\n      I->setMetadata(LLVMContext::MD_fpmath, FPMD);\n    I->setFastMathFlags(FMF);\n    return I;\n  }\n\n  Value *foldConstant(Instruction::BinaryOps Opc, Value *L,\n                      Value *R, const Twine &Name) const {\n    auto *LC = dyn_cast<Constant>(L);\n    auto *RC = dyn_cast<Constant>(R);\n    return (LC && RC) ? Insert(Folder.CreateBinOp(Opc, LC, RC), Name) : nullptr;\n  }\n\n  Value *getConstrainedFPRounding(Optional<RoundingMode> Rounding) {\n    RoundingMode UseRounding = DefaultConstrainedRounding;\n\n    if (Rounding.hasValue())\n      UseRounding = Rounding.getValue();\n\n    Optional<StringRef> RoundingStr = RoundingModeToStr(UseRounding);\n    assert(RoundingStr.hasValue() && \"Garbage strict rounding mode!\");\n    auto *RoundingMDS = MDString::get(Context, RoundingStr.getValue());\n\n    return MetadataAsValue::get(Context, RoundingMDS);\n  }\n\n  Value *getConstrainedFPExcept(Optional<fp::ExceptionBehavior> Except) {\n    fp::ExceptionBehavior UseExcept = DefaultConstrainedExcept;\n\n    if (Except.hasValue())\n      UseExcept = Except.getValue();\n\n    Optional<StringRef> ExceptStr = ExceptionBehaviorToStr(UseExcept);\n    assert(ExceptStr.hasValue() && \"Garbage strict exception behavior!\");\n    auto *ExceptMDS = MDString::get(Context, ExceptStr.getValue());\n\n    return MetadataAsValue::get(Context, ExceptMDS);\n  }\n\n  Value *getConstrainedFPPredicate(CmpInst::Predicate Predicate) {\n    assert(CmpInst::isFPPredicate(Predicate) &&\n           Predicate != CmpInst::FCMP_FALSE &&\n           Predicate != CmpInst::FCMP_TRUE &&\n           \"Invalid constrained FP comparison predicate!\");\n\n    StringRef PredicateStr = CmpInst::getPredicateName(Predicate);\n    auto *PredicateMDS = MDString::get(Context, PredicateStr);\n\n    return MetadataAsValue::get(Context, PredicateMDS);\n  }\n\npublic:\n  Value *CreateAdd(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateAdd(LC, RC, HasNUW, HasNSW), Name);\n    return CreateInsertNUWNSWBinOp(Instruction::Add, LHS, RHS, Name,\n                                   HasNUW, HasNSW);\n  }\n\n  Value *CreateNSWAdd(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateAdd(LHS, RHS, Name, false, true);\n  }\n\n  Value *CreateNUWAdd(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateAdd(LHS, RHS, Name, true, false);\n  }\n\n  Value *CreateSub(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateSub(LC, RC, HasNUW, HasNSW), Name);\n    return CreateInsertNUWNSWBinOp(Instruction::Sub, LHS, RHS, Name,\n                                   HasNUW, HasNSW);\n  }\n\n  Value *CreateNSWSub(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateSub(LHS, RHS, Name, false, true);\n  }\n\n  Value *CreateNUWSub(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateSub(LHS, RHS, Name, true, false);\n  }\n\n  Value *CreateMul(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateMul(LC, RC, HasNUW, HasNSW), Name);\n    return CreateInsertNUWNSWBinOp(Instruction::Mul, LHS, RHS, Name,\n                                   HasNUW, HasNSW);\n  }\n\n  Value *CreateNSWMul(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateMul(LHS, RHS, Name, false, true);\n  }\n\n  Value *CreateNUWMul(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateMul(LHS, RHS, Name, true, false);\n  }\n\n  Value *CreateUDiv(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateUDiv(LC, RC, isExact), Name);\n    if (!isExact)\n      return Insert(BinaryOperator::CreateUDiv(LHS, RHS), Name);\n    return Insert(BinaryOperator::CreateExactUDiv(LHS, RHS), Name);\n  }\n\n  Value *CreateExactUDiv(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateUDiv(LHS, RHS, Name, true);\n  }\n\n  Value *CreateSDiv(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateSDiv(LC, RC, isExact), Name);\n    if (!isExact)\n      return Insert(BinaryOperator::CreateSDiv(LHS, RHS), Name);\n    return Insert(BinaryOperator::CreateExactSDiv(LHS, RHS), Name);\n  }\n\n  Value *CreateExactSDiv(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateSDiv(LHS, RHS, Name, true);\n  }\n\n  Value *CreateURem(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    if (Value *V = foldConstant(Instruction::URem, LHS, RHS, Name)) return V;\n    return Insert(BinaryOperator::CreateURem(LHS, RHS), Name);\n  }\n\n  Value *CreateSRem(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    if (Value *V = foldConstant(Instruction::SRem, LHS, RHS, Name)) return V;\n    return Insert(BinaryOperator::CreateSRem(LHS, RHS), Name);\n  }\n\n  Value *CreateShl(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateShl(LC, RC, HasNUW, HasNSW), Name);\n    return CreateInsertNUWNSWBinOp(Instruction::Shl, LHS, RHS, Name,\n                                   HasNUW, HasNSW);\n  }\n\n  Value *CreateShl(Value *LHS, const APInt &RHS, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    return CreateShl(LHS, ConstantInt::get(LHS->getType(), RHS), Name,\n                     HasNUW, HasNSW);\n  }\n\n  Value *CreateShl(Value *LHS, uint64_t RHS, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    return CreateShl(LHS, ConstantInt::get(LHS->getType(), RHS), Name,\n                     HasNUW, HasNSW);\n  }\n\n  Value *CreateLShr(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateLShr(LC, RC, isExact), Name);\n    if (!isExact)\n      return Insert(BinaryOperator::CreateLShr(LHS, RHS), Name);\n    return Insert(BinaryOperator::CreateExactLShr(LHS, RHS), Name);\n  }\n\n  Value *CreateLShr(Value *LHS, const APInt &RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    return CreateLShr(LHS, ConstantInt::get(LHS->getType(), RHS), Name,isExact);\n  }\n\n  Value *CreateLShr(Value *LHS, uint64_t RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    return CreateLShr(LHS, ConstantInt::get(LHS->getType(), RHS), Name,isExact);\n  }\n\n  Value *CreateAShr(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateAShr(LC, RC, isExact), Name);\n    if (!isExact)\n      return Insert(BinaryOperator::CreateAShr(LHS, RHS), Name);\n    return Insert(BinaryOperator::CreateExactAShr(LHS, RHS), Name);\n  }\n\n  Value *CreateAShr(Value *LHS, const APInt &RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    return CreateAShr(LHS, ConstantInt::get(LHS->getType(), RHS), Name,isExact);\n  }\n\n  Value *CreateAShr(Value *LHS, uint64_t RHS, const Twine &Name = \"\",\n                    bool isExact = false) {\n    return CreateAShr(LHS, ConstantInt::get(LHS->getType(), RHS), Name,isExact);\n  }\n\n  Value *CreateAnd(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    if (auto *RC = dyn_cast<Constant>(RHS)) {\n      if (isa<ConstantInt>(RC) && cast<ConstantInt>(RC)->isMinusOne())\n        return LHS;  // LHS & -1 -> LHS\n      if (auto *LC = dyn_cast<Constant>(LHS))\n        return Insert(Folder.CreateAnd(LC, RC), Name);\n    }\n    return Insert(BinaryOperator::CreateAnd(LHS, RHS), Name);\n  }\n\n  Value *CreateAnd(Value *LHS, const APInt &RHS, const Twine &Name = \"\") {\n    return CreateAnd(LHS, ConstantInt::get(LHS->getType(), RHS), Name);\n  }\n\n  Value *CreateAnd(Value *LHS, uint64_t RHS, const Twine &Name = \"\") {\n    return CreateAnd(LHS, ConstantInt::get(LHS->getType(), RHS), Name);\n  }\n\n  Value *CreateAnd(ArrayRef<Value*> Ops) {\n    assert(!Ops.empty());\n    Value *Accum = Ops[0];\n    for (unsigned i = 1; i < Ops.size(); i++)\n      Accum = CreateAnd(Accum, Ops[i]);\n    return Accum;\n  }\n\n  Value *CreateOr(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    if (auto *RC = dyn_cast<Constant>(RHS)) {\n      if (RC->isNullValue())\n        return LHS;  // LHS | 0 -> LHS\n      if (auto *LC = dyn_cast<Constant>(LHS))\n        return Insert(Folder.CreateOr(LC, RC), Name);\n    }\n    return Insert(BinaryOperator::CreateOr(LHS, RHS), Name);\n  }\n\n  Value *CreateOr(Value *LHS, const APInt &RHS, const Twine &Name = \"\") {\n    return CreateOr(LHS, ConstantInt::get(LHS->getType(), RHS), Name);\n  }\n\n  Value *CreateOr(Value *LHS, uint64_t RHS, const Twine &Name = \"\") {\n    return CreateOr(LHS, ConstantInt::get(LHS->getType(), RHS), Name);\n  }\n\n  Value *CreateOr(ArrayRef<Value*> Ops) {\n    assert(!Ops.empty());\n    Value *Accum = Ops[0];\n    for (unsigned i = 1; i < Ops.size(); i++)\n      Accum = CreateOr(Accum, Ops[i]);\n    return Accum;\n  }\n\n  Value *CreateXor(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    if (Value *V = foldConstant(Instruction::Xor, LHS, RHS, Name)) return V;\n    return Insert(BinaryOperator::CreateXor(LHS, RHS), Name);\n  }\n\n  Value *CreateXor(Value *LHS, const APInt &RHS, const Twine &Name = \"\") {\n    return CreateXor(LHS, ConstantInt::get(LHS->getType(), RHS), Name);\n  }\n\n  Value *CreateXor(Value *LHS, uint64_t RHS, const Twine &Name = \"\") {\n    return CreateXor(LHS, ConstantInt::get(LHS->getType(), RHS), Name);\n  }\n\n  Value *CreateFAdd(Value *L, Value *R, const Twine &Name = \"\",\n                    MDNode *FPMD = nullptr) {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fadd,\n                                      L, R, nullptr, Name, FPMD);\n\n    if (Value *V = foldConstant(Instruction::FAdd, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFAdd(L, R), FPMD, FMF);\n    return Insert(I, Name);\n  }\n\n  /// Copy fast-math-flags from an instruction rather than using the builder's\n  /// default FMF.\n  Value *CreateFAddFMF(Value *L, Value *R, Instruction *FMFSource,\n                       const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fadd,\n                                      L, R, FMFSource, Name);\n\n    if (Value *V = foldConstant(Instruction::FAdd, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFAdd(L, R), nullptr,\n                                FMFSource->getFastMathFlags());\n    return Insert(I, Name);\n  }\n\n  Value *CreateFSub(Value *L, Value *R, const Twine &Name = \"\",\n                    MDNode *FPMD = nullptr) {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fsub,\n                                      L, R, nullptr, Name, FPMD);\n\n    if (Value *V = foldConstant(Instruction::FSub, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFSub(L, R), FPMD, FMF);\n    return Insert(I, Name);\n  }\n\n  /// Copy fast-math-flags from an instruction rather than using the builder's\n  /// default FMF.\n  Value *CreateFSubFMF(Value *L, Value *R, Instruction *FMFSource,\n                       const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fsub,\n                                      L, R, FMFSource, Name);\n\n    if (Value *V = foldConstant(Instruction::FSub, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFSub(L, R), nullptr,\n                                FMFSource->getFastMathFlags());\n    return Insert(I, Name);\n  }\n\n  Value *CreateFMul(Value *L, Value *R, const Twine &Name = \"\",\n                    MDNode *FPMD = nullptr) {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fmul,\n                                      L, R, nullptr, Name, FPMD);\n\n    if (Value *V = foldConstant(Instruction::FMul, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFMul(L, R), FPMD, FMF);\n    return Insert(I, Name);\n  }\n\n  /// Copy fast-math-flags from an instruction rather than using the builder's\n  /// default FMF.\n  Value *CreateFMulFMF(Value *L, Value *R, Instruction *FMFSource,\n                       const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fmul,\n                                      L, R, FMFSource, Name);\n\n    if (Value *V = foldConstant(Instruction::FMul, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFMul(L, R), nullptr,\n                                FMFSource->getFastMathFlags());\n    return Insert(I, Name);\n  }\n\n  Value *CreateFDiv(Value *L, Value *R, const Twine &Name = \"\",\n                    MDNode *FPMD = nullptr) {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fdiv,\n                                      L, R, nullptr, Name, FPMD);\n\n    if (Value *V = foldConstant(Instruction::FDiv, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFDiv(L, R), FPMD, FMF);\n    return Insert(I, Name);\n  }\n\n  /// Copy fast-math-flags from an instruction rather than using the builder's\n  /// default FMF.\n  Value *CreateFDivFMF(Value *L, Value *R, Instruction *FMFSource,\n                       const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_fdiv,\n                                      L, R, FMFSource, Name);\n\n    if (Value *V = foldConstant(Instruction::FDiv, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFDiv(L, R), nullptr,\n                                FMFSource->getFastMathFlags());\n    return Insert(I, Name);\n  }\n\n  Value *CreateFRem(Value *L, Value *R, const Twine &Name = \"\",\n                    MDNode *FPMD = nullptr) {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_frem,\n                                      L, R, nullptr, Name, FPMD);\n\n    if (Value *V = foldConstant(Instruction::FRem, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFRem(L, R), FPMD, FMF);\n    return Insert(I, Name);\n  }\n\n  /// Copy fast-math-flags from an instruction rather than using the builder's\n  /// default FMF.\n  Value *CreateFRemFMF(Value *L, Value *R, Instruction *FMFSource,\n                       const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPBinOp(Intrinsic::experimental_constrained_frem,\n                                      L, R, FMFSource, Name);\n\n    if (Value *V = foldConstant(Instruction::FRem, L, R, Name)) return V;\n    Instruction *I = setFPAttrs(BinaryOperator::CreateFRem(L, R), nullptr,\n                                FMFSource->getFastMathFlags());\n    return Insert(I, Name);\n  }\n\n  Value *CreateBinOp(Instruction::BinaryOps Opc,\n                     Value *LHS, Value *RHS, const Twine &Name = \"\",\n                     MDNode *FPMathTag = nullptr) {\n    if (Value *V = foldConstant(Opc, LHS, RHS, Name)) return V;\n    Instruction *BinOp = BinaryOperator::Create(Opc, LHS, RHS);\n    if (isa<FPMathOperator>(BinOp))\n      setFPAttrs(BinOp, FPMathTag, FMF);\n    return Insert(BinOp, Name);\n  }\n\n  Value *CreateLogicalAnd(Value *Cond1, Value *Cond2, const Twine &Name = \"\") {\n    assert(Cond2->getType()->isIntOrIntVectorTy(1));\n    return CreateSelect(Cond1, Cond2,\n                        ConstantInt::getNullValue(Cond2->getType()), Name);\n  }\n\n  Value *CreateLogicalOr(Value *Cond1, Value *Cond2, const Twine &Name = \"\") {\n    assert(Cond2->getType()->isIntOrIntVectorTy(1));\n    return CreateSelect(Cond1, ConstantInt::getAllOnesValue(Cond2->getType()),\n                        Cond2, Name);\n  }\n\n  CallInst *CreateConstrainedFPBinOp(\n      Intrinsic::ID ID, Value *L, Value *R, Instruction *FMFSource = nullptr,\n      const Twine &Name = \"\", MDNode *FPMathTag = nullptr,\n      Optional<RoundingMode> Rounding = None,\n      Optional<fp::ExceptionBehavior> Except = None);\n\n  Value *CreateNeg(Value *V, const Twine &Name = \"\",\n                   bool HasNUW = false, bool HasNSW = false) {\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateNeg(VC, HasNUW, HasNSW), Name);\n    BinaryOperator *BO = Insert(BinaryOperator::CreateNeg(V), Name);\n    if (HasNUW) BO->setHasNoUnsignedWrap();\n    if (HasNSW) BO->setHasNoSignedWrap();\n    return BO;\n  }\n\n  Value *CreateNSWNeg(Value *V, const Twine &Name = \"\") {\n    return CreateNeg(V, Name, false, true);\n  }\n\n  Value *CreateNUWNeg(Value *V, const Twine &Name = \"\") {\n    return CreateNeg(V, Name, true, false);\n  }\n\n  Value *CreateFNeg(Value *V, const Twine &Name = \"\",\n                    MDNode *FPMathTag = nullptr) {\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateFNeg(VC), Name);\n    return Insert(setFPAttrs(UnaryOperator::CreateFNeg(V), FPMathTag, FMF),\n                  Name);\n  }\n\n  /// Copy fast-math-flags from an instruction rather than using the builder's\n  /// default FMF.\n  Value *CreateFNegFMF(Value *V, Instruction *FMFSource,\n                       const Twine &Name = \"\") {\n   if (auto *VC = dyn_cast<Constant>(V))\n     return Insert(Folder.CreateFNeg(VC), Name);\n   return Insert(setFPAttrs(UnaryOperator::CreateFNeg(V), nullptr,\n                            FMFSource->getFastMathFlags()),\n                 Name);\n  }\n\n  Value *CreateNot(Value *V, const Twine &Name = \"\") {\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateNot(VC), Name);\n    return Insert(BinaryOperator::CreateNot(V), Name);\n  }\n\n  Value *CreateUnOp(Instruction::UnaryOps Opc,\n                    Value *V, const Twine &Name = \"\",\n                    MDNode *FPMathTag = nullptr) {\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateUnOp(Opc, VC), Name);\n    Instruction *UnOp = UnaryOperator::Create(Opc, V);\n    if (isa<FPMathOperator>(UnOp))\n      setFPAttrs(UnOp, FPMathTag, FMF);\n    return Insert(UnOp, Name);\n  }\n\n  /// Create either a UnaryOperator or BinaryOperator depending on \\p Opc.\n  /// Correct number of operands must be passed accordingly.\n  Value *CreateNAryOp(unsigned Opc, ArrayRef<Value *> Ops,\n                      const Twine &Name = \"\", MDNode *FPMathTag = nullptr);\n\n  //===--------------------------------------------------------------------===//\n  // Instruction creation methods: Memory Instructions\n  //===--------------------------------------------------------------------===//\n\n  AllocaInst *CreateAlloca(Type *Ty, unsigned AddrSpace,\n                           Value *ArraySize = nullptr, const Twine &Name = \"\") {\n    const DataLayout &DL = BB->getModule()->getDataLayout();\n    Align AllocaAlign = DL.getPrefTypeAlign(Ty);\n    return Insert(new AllocaInst(Ty, AddrSpace, ArraySize, AllocaAlign), Name);\n  }\n\n  AllocaInst *CreateAlloca(Type *Ty, Value *ArraySize = nullptr,\n                           const Twine &Name = \"\") {\n    const DataLayout &DL = BB->getModule()->getDataLayout();\n    Align AllocaAlign = DL.getPrefTypeAlign(Ty);\n    unsigned AddrSpace = DL.getAllocaAddrSpace();\n    return Insert(new AllocaInst(Ty, AddrSpace, ArraySize, AllocaAlign), Name);\n  }\n\n  /// Provided to resolve 'CreateLoad(Ty, Ptr, \"...\")' correctly, instead of\n  /// converting the string to 'bool' for the isVolatile parameter.\n  LoadInst *CreateLoad(Type *Ty, Value *Ptr, const char *Name) {\n    return CreateAlignedLoad(Ty, Ptr, MaybeAlign(), Name);\n  }\n\n  LoadInst *CreateLoad(Type *Ty, Value *Ptr, const Twine &Name = \"\") {\n    return CreateAlignedLoad(Ty, Ptr, MaybeAlign(), Name);\n  }\n\n  LoadInst *CreateLoad(Type *Ty, Value *Ptr, bool isVolatile,\n                       const Twine &Name = \"\") {\n    return CreateAlignedLoad(Ty, Ptr, MaybeAlign(), isVolatile, Name);\n  }\n\n  // Deprecated [opaque pointer types]\n  LoadInst *CreateLoad(Value *Ptr, const char *Name) {\n    return CreateLoad(Ptr->getType()->getPointerElementType(), Ptr, Name);\n  }\n\n  // Deprecated [opaque pointer types]\n  LoadInst *CreateLoad(Value *Ptr, const Twine &Name = \"\") {\n    return CreateLoad(Ptr->getType()->getPointerElementType(), Ptr, Name);\n  }\n\n  // Deprecated [opaque pointer types]\n  LoadInst *CreateLoad(Value *Ptr, bool isVolatile, const Twine &Name = \"\") {\n    return CreateLoad(Ptr->getType()->getPointerElementType(), Ptr, isVolatile,\n                      Name);\n  }\n\n  StoreInst *CreateStore(Value *Val, Value *Ptr, bool isVolatile = false) {\n    return CreateAlignedStore(Val, Ptr, MaybeAlign(), isVolatile);\n  }\n\n  LoadInst *CreateAlignedLoad(Type *Ty, Value *Ptr, MaybeAlign Align,\n                              const char *Name) {\n    return CreateAlignedLoad(Ty, Ptr, Align, /*isVolatile*/false, Name);\n  }\n\n  LoadInst *CreateAlignedLoad(Type *Ty, Value *Ptr, MaybeAlign Align,\n                              const Twine &Name = \"\") {\n    return CreateAlignedLoad(Ty, Ptr, Align, /*isVolatile*/false, Name);\n  }\n\n  LoadInst *CreateAlignedLoad(Type *Ty, Value *Ptr, MaybeAlign Align,\n                              bool isVolatile, const Twine &Name = \"\") {\n    if (!Align) {\n      const DataLayout &DL = BB->getModule()->getDataLayout();\n      Align = DL.getABITypeAlign(Ty);\n    }\n    return Insert(new LoadInst(Ty, Ptr, Twine(), isVolatile, *Align), Name);\n  }\n\n  // Deprecated [opaque pointer types]\n  LoadInst *CreateAlignedLoad(Value *Ptr, MaybeAlign Align, const char *Name) {\n    return CreateAlignedLoad(Ptr->getType()->getPointerElementType(), Ptr,\n                             Align, Name);\n  }\n  // Deprecated [opaque pointer types]\n  LoadInst *CreateAlignedLoad(Value *Ptr, MaybeAlign Align,\n                              const Twine &Name = \"\") {\n    return CreateAlignedLoad(Ptr->getType()->getPointerElementType(), Ptr,\n                             Align, Name);\n  }\n  // Deprecated [opaque pointer types]\n  LoadInst *CreateAlignedLoad(Value *Ptr, MaybeAlign Align, bool isVolatile,\n                              const Twine &Name = \"\") {\n    return CreateAlignedLoad(Ptr->getType()->getPointerElementType(), Ptr,\n                             Align, isVolatile, Name);\n  }\n\n  StoreInst *CreateAlignedStore(Value *Val, Value *Ptr, MaybeAlign Align,\n                                bool isVolatile = false) {\n    if (!Align) {\n      const DataLayout &DL = BB->getModule()->getDataLayout();\n      Align = DL.getABITypeAlign(Val->getType());\n    }\n    return Insert(new StoreInst(Val, Ptr, isVolatile, *Align));\n  }\n  FenceInst *CreateFence(AtomicOrdering Ordering,\n                         SyncScope::ID SSID = SyncScope::System,\n                         const Twine &Name = \"\") {\n    return Insert(new FenceInst(Context, Ordering, SSID), Name);\n  }\n\n  AtomicCmpXchgInst *\n  CreateAtomicCmpXchg(Value *Ptr, Value *Cmp, Value *New, MaybeAlign Align,\n                      AtomicOrdering SuccessOrdering,\n                      AtomicOrdering FailureOrdering,\n                      SyncScope::ID SSID = SyncScope::System) {\n    if (!Align) {\n      const DataLayout &DL = BB->getModule()->getDataLayout();\n      Align = llvm::Align(DL.getTypeStoreSize(New->getType()));\n    }\n\n    return Insert(new AtomicCmpXchgInst(Ptr, Cmp, New, *Align, SuccessOrdering,\n                                        FailureOrdering, SSID));\n  }\n\n  AtomicRMWInst *CreateAtomicRMW(AtomicRMWInst::BinOp Op, Value *Ptr,\n                                 Value *Val, MaybeAlign Align,\n                                 AtomicOrdering Ordering,\n                                 SyncScope::ID SSID = SyncScope::System) {\n    if (!Align) {\n      const DataLayout &DL = BB->getModule()->getDataLayout();\n      Align = llvm::Align(DL.getTypeStoreSize(Val->getType()));\n    }\n\n    return Insert(new AtomicRMWInst(Op, Ptr, Val, *Align, Ordering, SSID));\n  }\n\n  Value *CreateGEP(Value *Ptr, ArrayRef<Value *> IdxList,\n                   const Twine &Name = \"\") {\n    return CreateGEP(nullptr, Ptr, IdxList, Name);\n  }\n\n  Value *CreateGEP(Type *Ty, Value *Ptr, ArrayRef<Value *> IdxList,\n                   const Twine &Name = \"\") {\n    if (auto *PC = dyn_cast<Constant>(Ptr)) {\n      // Every index must be constant.\n      size_t i, e;\n      for (i = 0, e = IdxList.size(); i != e; ++i)\n        if (!isa<Constant>(IdxList[i]))\n          break;\n      if (i == e)\n        return Insert(Folder.CreateGetElementPtr(Ty, PC, IdxList), Name);\n    }\n    return Insert(GetElementPtrInst::Create(Ty, Ptr, IdxList), Name);\n  }\n\n  Value *CreateInBoundsGEP(Value *Ptr, ArrayRef<Value *> IdxList,\n                           const Twine &Name = \"\") {\n    return CreateInBoundsGEP(nullptr, Ptr, IdxList, Name);\n  }\n\n  Value *CreateInBoundsGEP(Type *Ty, Value *Ptr, ArrayRef<Value *> IdxList,\n                           const Twine &Name = \"\") {\n    if (auto *PC = dyn_cast<Constant>(Ptr)) {\n      // Every index must be constant.\n      size_t i, e;\n      for (i = 0, e = IdxList.size(); i != e; ++i)\n        if (!isa<Constant>(IdxList[i]))\n          break;\n      if (i == e)\n        return Insert(Folder.CreateInBoundsGetElementPtr(Ty, PC, IdxList),\n                      Name);\n    }\n    return Insert(GetElementPtrInst::CreateInBounds(Ty, Ptr, IdxList), Name);\n  }\n\n  Value *CreateGEP(Value *Ptr, Value *Idx, const Twine &Name = \"\") {\n    return CreateGEP(nullptr, Ptr, Idx, Name);\n  }\n\n  Value *CreateGEP(Type *Ty, Value *Ptr, Value *Idx, const Twine &Name = \"\") {\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      if (auto *IC = dyn_cast<Constant>(Idx))\n        return Insert(Folder.CreateGetElementPtr(Ty, PC, IC), Name);\n    return Insert(GetElementPtrInst::Create(Ty, Ptr, Idx), Name);\n  }\n\n  Value *CreateInBoundsGEP(Type *Ty, Value *Ptr, Value *Idx,\n                           const Twine &Name = \"\") {\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      if (auto *IC = dyn_cast<Constant>(Idx))\n        return Insert(Folder.CreateInBoundsGetElementPtr(Ty, PC, IC), Name);\n    return Insert(GetElementPtrInst::CreateInBounds(Ty, Ptr, Idx), Name);\n  }\n\n  Value *CreateConstGEP1_32(Value *Ptr, unsigned Idx0, const Twine &Name = \"\") {\n    return CreateConstGEP1_32(nullptr, Ptr, Idx0, Name);\n  }\n\n  Value *CreateConstGEP1_32(Type *Ty, Value *Ptr, unsigned Idx0,\n                            const Twine &Name = \"\") {\n    Value *Idx = ConstantInt::get(Type::getInt32Ty(Context), Idx0);\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateGetElementPtr(Ty, PC, Idx), Name);\n\n    return Insert(GetElementPtrInst::Create(Ty, Ptr, Idx), Name);\n  }\n\n  Value *CreateConstInBoundsGEP1_32(Type *Ty, Value *Ptr, unsigned Idx0,\n                                    const Twine &Name = \"\") {\n    Value *Idx = ConstantInt::get(Type::getInt32Ty(Context), Idx0);\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateInBoundsGetElementPtr(Ty, PC, Idx), Name);\n\n    return Insert(GetElementPtrInst::CreateInBounds(Ty, Ptr, Idx), Name);\n  }\n\n  Value *CreateConstGEP2_32(Type *Ty, Value *Ptr, unsigned Idx0, unsigned Idx1,\n                            const Twine &Name = \"\") {\n    Value *Idxs[] = {\n      ConstantInt::get(Type::getInt32Ty(Context), Idx0),\n      ConstantInt::get(Type::getInt32Ty(Context), Idx1)\n    };\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateGetElementPtr(Ty, PC, Idxs), Name);\n\n    return Insert(GetElementPtrInst::Create(Ty, Ptr, Idxs), Name);\n  }\n\n  Value *CreateConstInBoundsGEP2_32(Type *Ty, Value *Ptr, unsigned Idx0,\n                                    unsigned Idx1, const Twine &Name = \"\") {\n    Value *Idxs[] = {\n      ConstantInt::get(Type::getInt32Ty(Context), Idx0),\n      ConstantInt::get(Type::getInt32Ty(Context), Idx1)\n    };\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateInBoundsGetElementPtr(Ty, PC, Idxs), Name);\n\n    return Insert(GetElementPtrInst::CreateInBounds(Ty, Ptr, Idxs), Name);\n  }\n\n  Value *CreateConstGEP1_64(Type *Ty, Value *Ptr, uint64_t Idx0,\n                            const Twine &Name = \"\") {\n    Value *Idx = ConstantInt::get(Type::getInt64Ty(Context), Idx0);\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateGetElementPtr(Ty, PC, Idx), Name);\n\n    return Insert(GetElementPtrInst::Create(Ty, Ptr, Idx), Name);\n  }\n\n  Value *CreateConstGEP1_64(Value *Ptr, uint64_t Idx0, const Twine &Name = \"\") {\n    return CreateConstGEP1_64(nullptr, Ptr, Idx0, Name);\n  }\n\n  Value *CreateConstInBoundsGEP1_64(Type *Ty, Value *Ptr, uint64_t Idx0,\n                                    const Twine &Name = \"\") {\n    Value *Idx = ConstantInt::get(Type::getInt64Ty(Context), Idx0);\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateInBoundsGetElementPtr(Ty, PC, Idx), Name);\n\n    return Insert(GetElementPtrInst::CreateInBounds(Ty, Ptr, Idx), Name);\n  }\n\n  Value *CreateConstInBoundsGEP1_64(Value *Ptr, uint64_t Idx0,\n                                    const Twine &Name = \"\") {\n    return CreateConstInBoundsGEP1_64(nullptr, Ptr, Idx0, Name);\n  }\n\n  Value *CreateConstGEP2_64(Type *Ty, Value *Ptr, uint64_t Idx0, uint64_t Idx1,\n                            const Twine &Name = \"\") {\n    Value *Idxs[] = {\n      ConstantInt::get(Type::getInt64Ty(Context), Idx0),\n      ConstantInt::get(Type::getInt64Ty(Context), Idx1)\n    };\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateGetElementPtr(Ty, PC, Idxs), Name);\n\n    return Insert(GetElementPtrInst::Create(Ty, Ptr, Idxs), Name);\n  }\n\n  Value *CreateConstGEP2_64(Value *Ptr, uint64_t Idx0, uint64_t Idx1,\n                            const Twine &Name = \"\") {\n    return CreateConstGEP2_64(nullptr, Ptr, Idx0, Idx1, Name);\n  }\n\n  Value *CreateConstInBoundsGEP2_64(Type *Ty, Value *Ptr, uint64_t Idx0,\n                                    uint64_t Idx1, const Twine &Name = \"\") {\n    Value *Idxs[] = {\n      ConstantInt::get(Type::getInt64Ty(Context), Idx0),\n      ConstantInt::get(Type::getInt64Ty(Context), Idx1)\n    };\n\n    if (auto *PC = dyn_cast<Constant>(Ptr))\n      return Insert(Folder.CreateInBoundsGetElementPtr(Ty, PC, Idxs), Name);\n\n    return Insert(GetElementPtrInst::CreateInBounds(Ty, Ptr, Idxs), Name);\n  }\n\n  Value *CreateConstInBoundsGEP2_64(Value *Ptr, uint64_t Idx0, uint64_t Idx1,\n                                    const Twine &Name = \"\") {\n    return CreateConstInBoundsGEP2_64(nullptr, Ptr, Idx0, Idx1, Name);\n  }\n\n  Value *CreateStructGEP(Type *Ty, Value *Ptr, unsigned Idx,\n                         const Twine &Name = \"\") {\n    return CreateConstInBoundsGEP2_32(Ty, Ptr, 0, Idx, Name);\n  }\n\n  Value *CreateStructGEP(Value *Ptr, unsigned Idx, const Twine &Name = \"\") {\n    return CreateConstInBoundsGEP2_32(nullptr, Ptr, 0, Idx, Name);\n  }\n\n  /// Same as CreateGlobalString, but return a pointer with \"i8*\" type\n  /// instead of a pointer to array of i8.\n  ///\n  /// If no module is given via \\p M, it is take from the insertion point basic\n  /// block.\n  Constant *CreateGlobalStringPtr(StringRef Str, const Twine &Name = \"\",\n                                  unsigned AddressSpace = 0,\n                                  Module *M = nullptr) {\n    GlobalVariable *GV = CreateGlobalString(Str, Name, AddressSpace, M);\n    Constant *Zero = ConstantInt::get(Type::getInt32Ty(Context), 0);\n    Constant *Indices[] = {Zero, Zero};\n    return ConstantExpr::getInBoundsGetElementPtr(GV->getValueType(), GV,\n                                                  Indices);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Instruction creation methods: Cast/Conversion Operators\n  //===--------------------------------------------------------------------===//\n\n  Value *CreateTrunc(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    return CreateCast(Instruction::Trunc, V, DestTy, Name);\n  }\n\n  Value *CreateZExt(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    return CreateCast(Instruction::ZExt, V, DestTy, Name);\n  }\n\n  Value *CreateSExt(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    return CreateCast(Instruction::SExt, V, DestTy, Name);\n  }\n\n  /// Create a ZExt or Trunc from the integer value V to DestTy. Return\n  /// the value untouched if the type of V is already DestTy.\n  Value *CreateZExtOrTrunc(Value *V, Type *DestTy,\n                           const Twine &Name = \"\") {\n    assert(V->getType()->isIntOrIntVectorTy() &&\n           DestTy->isIntOrIntVectorTy() &&\n           \"Can only zero extend/truncate integers!\");\n    Type *VTy = V->getType();\n    if (VTy->getScalarSizeInBits() < DestTy->getScalarSizeInBits())\n      return CreateZExt(V, DestTy, Name);\n    if (VTy->getScalarSizeInBits() > DestTy->getScalarSizeInBits())\n      return CreateTrunc(V, DestTy, Name);\n    return V;\n  }\n\n  /// Create a SExt or Trunc from the integer value V to DestTy. Return\n  /// the value untouched if the type of V is already DestTy.\n  Value *CreateSExtOrTrunc(Value *V, Type *DestTy,\n                           const Twine &Name = \"\") {\n    assert(V->getType()->isIntOrIntVectorTy() &&\n           DestTy->isIntOrIntVectorTy() &&\n           \"Can only sign extend/truncate integers!\");\n    Type *VTy = V->getType();\n    if (VTy->getScalarSizeInBits() < DestTy->getScalarSizeInBits())\n      return CreateSExt(V, DestTy, Name);\n    if (VTy->getScalarSizeInBits() > DestTy->getScalarSizeInBits())\n      return CreateTrunc(V, DestTy, Name);\n    return V;\n  }\n\n  Value *CreateFPToUI(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPCast(Intrinsic::experimental_constrained_fptoui,\n                                     V, DestTy, nullptr, Name);\n    return CreateCast(Instruction::FPToUI, V, DestTy, Name);\n  }\n\n  Value *CreateFPToSI(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPCast(Intrinsic::experimental_constrained_fptosi,\n                                     V, DestTy, nullptr, Name);\n    return CreateCast(Instruction::FPToSI, V, DestTy, Name);\n  }\n\n  Value *CreateUIToFP(Value *V, Type *DestTy, const Twine &Name = \"\"){\n    if (IsFPConstrained)\n      return CreateConstrainedFPCast(Intrinsic::experimental_constrained_uitofp,\n                                     V, DestTy, nullptr, Name);\n    return CreateCast(Instruction::UIToFP, V, DestTy, Name);\n  }\n\n  Value *CreateSIToFP(Value *V, Type *DestTy, const Twine &Name = \"\"){\n    if (IsFPConstrained)\n      return CreateConstrainedFPCast(Intrinsic::experimental_constrained_sitofp,\n                                     V, DestTy, nullptr, Name);\n    return CreateCast(Instruction::SIToFP, V, DestTy, Name);\n  }\n\n  Value *CreateFPTrunc(Value *V, Type *DestTy,\n                       const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPCast(\n          Intrinsic::experimental_constrained_fptrunc, V, DestTy, nullptr,\n          Name);\n    return CreateCast(Instruction::FPTrunc, V, DestTy, Name);\n  }\n\n  Value *CreateFPExt(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    if (IsFPConstrained)\n      return CreateConstrainedFPCast(Intrinsic::experimental_constrained_fpext,\n                                     V, DestTy, nullptr, Name);\n    return CreateCast(Instruction::FPExt, V, DestTy, Name);\n  }\n\n  Value *CreatePtrToInt(Value *V, Type *DestTy,\n                        const Twine &Name = \"\") {\n    return CreateCast(Instruction::PtrToInt, V, DestTy, Name);\n  }\n\n  Value *CreateIntToPtr(Value *V, Type *DestTy,\n                        const Twine &Name = \"\") {\n    return CreateCast(Instruction::IntToPtr, V, DestTy, Name);\n  }\n\n  Value *CreateBitCast(Value *V, Type *DestTy,\n                       const Twine &Name = \"\") {\n    return CreateCast(Instruction::BitCast, V, DestTy, Name);\n  }\n\n  Value *CreateAddrSpaceCast(Value *V, Type *DestTy,\n                             const Twine &Name = \"\") {\n    return CreateCast(Instruction::AddrSpaceCast, V, DestTy, Name);\n  }\n\n  Value *CreateZExtOrBitCast(Value *V, Type *DestTy,\n                             const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateZExtOrBitCast(VC, DestTy), Name);\n    return Insert(CastInst::CreateZExtOrBitCast(V, DestTy), Name);\n  }\n\n  Value *CreateSExtOrBitCast(Value *V, Type *DestTy,\n                             const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateSExtOrBitCast(VC, DestTy), Name);\n    return Insert(CastInst::CreateSExtOrBitCast(V, DestTy), Name);\n  }\n\n  Value *CreateTruncOrBitCast(Value *V, Type *DestTy,\n                              const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateTruncOrBitCast(VC, DestTy), Name);\n    return Insert(CastInst::CreateTruncOrBitCast(V, DestTy), Name);\n  }\n\n  Value *CreateCast(Instruction::CastOps Op, Value *V, Type *DestTy,\n                    const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateCast(Op, VC, DestTy), Name);\n    return Insert(CastInst::Create(Op, V, DestTy), Name);\n  }\n\n  Value *CreatePointerCast(Value *V, Type *DestTy,\n                           const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreatePointerCast(VC, DestTy), Name);\n    return Insert(CastInst::CreatePointerCast(V, DestTy), Name);\n  }\n\n  Value *CreatePointerBitCastOrAddrSpaceCast(Value *V, Type *DestTy,\n                                             const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n\n    if (auto *VC = dyn_cast<Constant>(V)) {\n      return Insert(Folder.CreatePointerBitCastOrAddrSpaceCast(VC, DestTy),\n                    Name);\n    }\n\n    return Insert(CastInst::CreatePointerBitCastOrAddrSpaceCast(V, DestTy),\n                  Name);\n  }\n\n  Value *CreateIntCast(Value *V, Type *DestTy, bool isSigned,\n                       const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateIntCast(VC, DestTy, isSigned), Name);\n    return Insert(CastInst::CreateIntegerCast(V, DestTy, isSigned), Name);\n  }\n\n  Value *CreateBitOrPointerCast(Value *V, Type *DestTy,\n                                const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (V->getType()->isPtrOrPtrVectorTy() && DestTy->isIntOrIntVectorTy())\n      return CreatePtrToInt(V, DestTy, Name);\n    if (V->getType()->isIntOrIntVectorTy() && DestTy->isPtrOrPtrVectorTy())\n      return CreateIntToPtr(V, DestTy, Name);\n\n    return CreateBitCast(V, DestTy, Name);\n  }\n\n  Value *CreateFPCast(Value *V, Type *DestTy, const Twine &Name = \"\") {\n    if (V->getType() == DestTy)\n      return V;\n    if (auto *VC = dyn_cast<Constant>(V))\n      return Insert(Folder.CreateFPCast(VC, DestTy), Name);\n    return Insert(CastInst::CreateFPCast(V, DestTy), Name);\n  }\n\n  CallInst *CreateConstrainedFPCast(\n      Intrinsic::ID ID, Value *V, Type *DestTy,\n      Instruction *FMFSource = nullptr, const Twine &Name = \"\",\n      MDNode *FPMathTag = nullptr,\n      Optional<RoundingMode> Rounding = None,\n      Optional<fp::ExceptionBehavior> Except = None);\n\n  // Provided to resolve 'CreateIntCast(Ptr, Ptr, \"...\")', giving a\n  // compile time error, instead of converting the string to bool for the\n  // isSigned parameter.\n  Value *CreateIntCast(Value *, Type *, const char *) = delete;\n\n  //===--------------------------------------------------------------------===//\n  // Instruction creation methods: Compare Instructions\n  //===--------------------------------------------------------------------===//\n\n  Value *CreateICmpEQ(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_EQ, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpNE(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_NE, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpUGT(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_UGT, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpUGE(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_UGE, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpULT(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_ULT, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpULE(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_ULE, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpSGT(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_SGT, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpSGE(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_SGE, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpSLT(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_SLT, LHS, RHS, Name);\n  }\n\n  Value *CreateICmpSLE(Value *LHS, Value *RHS, const Twine &Name = \"\") {\n    return CreateICmp(ICmpInst::ICMP_SLE, LHS, RHS, Name);\n  }\n\n  Value *CreateFCmpOEQ(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_OEQ, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpOGT(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_OGT, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpOGE(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_OGE, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpOLT(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_OLT, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpOLE(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_OLE, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpONE(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_ONE, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpORD(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_ORD, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpUNO(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_UNO, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpUEQ(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_UEQ, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpUGT(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_UGT, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpUGE(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_UGE, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpULT(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_ULT, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpULE(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_ULE, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateFCmpUNE(Value *LHS, Value *RHS, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    return CreateFCmp(FCmpInst::FCMP_UNE, LHS, RHS, Name, FPMathTag);\n  }\n\n  Value *CreateICmp(CmpInst::Predicate P, Value *LHS, Value *RHS,\n                    const Twine &Name = \"\") {\n    if (auto *LC = dyn_cast<Constant>(LHS))\n      if (auto *RC = dyn_cast<Constant>(RHS))\n        return Insert(Folder.CreateICmp(P, LC, RC), Name);\n    return Insert(new ICmpInst(P, LHS, RHS), Name);\n  }\n\n  // Create a quiet floating-point comparison (i.e. one that raises an FP\n  // exception only in the case where an input is a signaling NaN).\n  // Note that this differs from CreateFCmpS only if IsFPConstrained is true.\n  Value *CreateFCmp(CmpInst::Predicate P, Value *LHS, Value *RHS,\n                    const Twine &Name = \"\", MDNode *FPMathTag = nullptr) {\n    return CreateFCmpHelper(P, LHS, RHS, Name, FPMathTag, false);\n  }\n\n  Value *CreateCmp(CmpInst::Predicate Pred, Value *LHS, Value *RHS,\n                   const Twine &Name = \"\", MDNode *FPMathTag = nullptr) {\n    return CmpInst::isFPPredicate(Pred)\n               ? CreateFCmp(Pred, LHS, RHS, Name, FPMathTag)\n               : CreateICmp(Pred, LHS, RHS, Name);\n  }\n\n  // Create a signaling floating-point comparison (i.e. one that raises an FP\n  // exception whenever an input is any NaN, signaling or quiet).\n  // Note that this differs from CreateFCmp only if IsFPConstrained is true.\n  Value *CreateFCmpS(CmpInst::Predicate P, Value *LHS, Value *RHS,\n                     const Twine &Name = \"\", MDNode *FPMathTag = nullptr) {\n    return CreateFCmpHelper(P, LHS, RHS, Name, FPMathTag, true);\n  }\n\nprivate:\n  // Helper routine to create either a signaling or a quiet FP comparison.\n  Value *CreateFCmpHelper(CmpInst::Predicate P, Value *LHS, Value *RHS,\n                          const Twine &Name, MDNode *FPMathTag,\n                          bool IsSignaling);\n\npublic:\n  CallInst *CreateConstrainedFPCmp(\n      Intrinsic::ID ID, CmpInst::Predicate P, Value *L, Value *R,\n      const Twine &Name = \"\", Optional<fp::ExceptionBehavior> Except = None);\n\n  //===--------------------------------------------------------------------===//\n  // Instruction creation methods: Other Instructions\n  //===--------------------------------------------------------------------===//\n\n  PHINode *CreatePHI(Type *Ty, unsigned NumReservedValues,\n                     const Twine &Name = \"\") {\n    PHINode *Phi = PHINode::Create(Ty, NumReservedValues);\n    if (isa<FPMathOperator>(Phi))\n      setFPAttrs(Phi, nullptr /* MDNode* */, FMF);\n    return Insert(Phi, Name);\n  }\n\n  CallInst *CreateCall(FunctionType *FTy, Value *Callee,\n                       ArrayRef<Value *> Args = None, const Twine &Name = \"\",\n                       MDNode *FPMathTag = nullptr) {\n    CallInst *CI = CallInst::Create(FTy, Callee, Args, DefaultOperandBundles);\n    if (IsFPConstrained)\n      setConstrainedFPCallAttr(CI);\n    if (isa<FPMathOperator>(CI))\n      setFPAttrs(CI, FPMathTag, FMF);\n    return Insert(CI, Name);\n  }\n\n  CallInst *CreateCall(FunctionType *FTy, Value *Callee, ArrayRef<Value *> Args,\n                       ArrayRef<OperandBundleDef> OpBundles,\n                       const Twine &Name = \"\", MDNode *FPMathTag = nullptr) {\n    CallInst *CI = CallInst::Create(FTy, Callee, Args, OpBundles);\n    if (IsFPConstrained)\n      setConstrainedFPCallAttr(CI);\n    if (isa<FPMathOperator>(CI))\n      setFPAttrs(CI, FPMathTag, FMF);\n    return Insert(CI, Name);\n  }\n\n  CallInst *CreateCall(FunctionCallee Callee, ArrayRef<Value *> Args = None,\n                       const Twine &Name = \"\", MDNode *FPMathTag = nullptr) {\n    return CreateCall(Callee.getFunctionType(), Callee.getCallee(), Args, Name,\n                      FPMathTag);\n  }\n\n  CallInst *CreateCall(FunctionCallee Callee, ArrayRef<Value *> Args,\n                       ArrayRef<OperandBundleDef> OpBundles,\n                       const Twine &Name = \"\", MDNode *FPMathTag = nullptr) {\n    return CreateCall(Callee.getFunctionType(), Callee.getCallee(), Args,\n                      OpBundles, Name, FPMathTag);\n  }\n\n  CallInst *CreateConstrainedFPCall(\n      Function *Callee, ArrayRef<Value *> Args, const Twine &Name = \"\",\n      Optional<RoundingMode> Rounding = None,\n      Optional<fp::ExceptionBehavior> Except = None);\n\n  Value *CreateSelect(Value *C, Value *True, Value *False,\n                      const Twine &Name = \"\", Instruction *MDFrom = nullptr);\n\n  VAArgInst *CreateVAArg(Value *List, Type *Ty, const Twine &Name = \"\") {\n    return Insert(new VAArgInst(List, Ty), Name);\n  }\n\n  Value *CreateExtractElement(Value *Vec, Value *Idx,\n                              const Twine &Name = \"\") {\n    if (auto *VC = dyn_cast<Constant>(Vec))\n      if (auto *IC = dyn_cast<Constant>(Idx))\n        return Insert(Folder.CreateExtractElement(VC, IC), Name);\n    return Insert(ExtractElementInst::Create(Vec, Idx), Name);\n  }\n\n  Value *CreateExtractElement(Value *Vec, uint64_t Idx,\n                              const Twine &Name = \"\") {\n    return CreateExtractElement(Vec, getInt64(Idx), Name);\n  }\n\n  Value *CreateInsertElement(Value *Vec, Value *NewElt, Value *Idx,\n                             const Twine &Name = \"\") {\n    if (auto *VC = dyn_cast<Constant>(Vec))\n      if (auto *NC = dyn_cast<Constant>(NewElt))\n        if (auto *IC = dyn_cast<Constant>(Idx))\n          return Insert(Folder.CreateInsertElement(VC, NC, IC), Name);\n    return Insert(InsertElementInst::Create(Vec, NewElt, Idx), Name);\n  }\n\n  Value *CreateInsertElement(Value *Vec, Value *NewElt, uint64_t Idx,\n                             const Twine &Name = \"\") {\n    return CreateInsertElement(Vec, NewElt, getInt64(Idx), Name);\n  }\n\n  Value *CreateShuffleVector(Value *V1, Value *V2, Value *Mask,\n                             const Twine &Name = \"\") {\n    SmallVector<int, 16> IntMask;\n    ShuffleVectorInst::getShuffleMask(cast<Constant>(Mask), IntMask);\n    return CreateShuffleVector(V1, V2, IntMask, Name);\n  }\n\n  LLVM_ATTRIBUTE_DEPRECATED(Value *CreateShuffleVector(Value *V1, Value *V2,\n                                                       ArrayRef<uint32_t> Mask,\n                                                       const Twine &Name = \"\"),\n                            \"Pass indices as 'int' instead\") {\n    SmallVector<int, 16> IntMask;\n    IntMask.assign(Mask.begin(), Mask.end());\n    return CreateShuffleVector(V1, V2, IntMask, Name);\n  }\n\n  /// See class ShuffleVectorInst for a description of the mask representation.\n  Value *CreateShuffleVector(Value *V1, Value *V2, ArrayRef<int> Mask,\n                             const Twine &Name = \"\") {\n    if (auto *V1C = dyn_cast<Constant>(V1))\n      if (auto *V2C = dyn_cast<Constant>(V2))\n        return Insert(Folder.CreateShuffleVector(V1C, V2C, Mask), Name);\n    return Insert(new ShuffleVectorInst(V1, V2, Mask), Name);\n  }\n\n  /// Create a unary shuffle. The second vector operand of the IR instruction\n  /// is poison.\n  Value *CreateShuffleVector(Value *V, ArrayRef<int> Mask,\n                             const Twine &Name = \"\") {\n    return CreateShuffleVector(V, PoisonValue::get(V->getType()), Mask, Name);\n  }\n\n  Value *CreateExtractValue(Value *Agg,\n                            ArrayRef<unsigned> Idxs,\n                            const Twine &Name = \"\") {\n    if (auto *AggC = dyn_cast<Constant>(Agg))\n      return Insert(Folder.CreateExtractValue(AggC, Idxs), Name);\n    return Insert(ExtractValueInst::Create(Agg, Idxs), Name);\n  }\n\n  Value *CreateInsertValue(Value *Agg, Value *Val,\n                           ArrayRef<unsigned> Idxs,\n                           const Twine &Name = \"\") {\n    if (auto *AggC = dyn_cast<Constant>(Agg))\n      if (auto *ValC = dyn_cast<Constant>(Val))\n        return Insert(Folder.CreateInsertValue(AggC, ValC, Idxs), Name);\n    return Insert(InsertValueInst::Create(Agg, Val, Idxs), Name);\n  }\n\n  LandingPadInst *CreateLandingPad(Type *Ty, unsigned NumClauses,\n                                   const Twine &Name = \"\") {\n    return Insert(LandingPadInst::Create(Ty, NumClauses), Name);\n  }\n\n  Value *CreateFreeze(Value *V, const Twine &Name = \"\") {\n    return Insert(new FreezeInst(V), Name);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Utility creation methods\n  //===--------------------------------------------------------------------===//\n\n  /// Return an i1 value testing if \\p Arg is null.\n  Value *CreateIsNull(Value *Arg, const Twine &Name = \"\") {\n    return CreateICmpEQ(Arg, Constant::getNullValue(Arg->getType()),\n                        Name);\n  }\n\n  /// Return an i1 value testing if \\p Arg is not null.\n  Value *CreateIsNotNull(Value *Arg, const Twine &Name = \"\") {\n    return CreateICmpNE(Arg, Constant::getNullValue(Arg->getType()),\n                        Name);\n  }\n\n  /// Return the i64 difference between two pointer values, dividing out\n  /// the size of the pointed-to objects.\n  ///\n  /// This is intended to implement C-style pointer subtraction. As such, the\n  /// pointers must be appropriately aligned for their element types and\n  /// pointing into the same object.\n  Value *CreatePtrDiff(Value *LHS, Value *RHS, const Twine &Name = \"\");\n\n  /// Create a launder.invariant.group intrinsic call. If Ptr type is\n  /// different from pointer to i8, it's casted to pointer to i8 in the same\n  /// address space before call and casted back to Ptr type after call.\n  Value *CreateLaunderInvariantGroup(Value *Ptr);\n\n  /// \\brief Create a strip.invariant.group intrinsic call. If Ptr type is\n  /// different from pointer to i8, it's casted to pointer to i8 in the same\n  /// address space before call and casted back to Ptr type after call.\n  Value *CreateStripInvariantGroup(Value *Ptr);\n\n  /// Return a vector value that contains \\arg V broadcasted to \\p\n  /// NumElts elements.\n  Value *CreateVectorSplat(unsigned NumElts, Value *V, const Twine &Name = \"\");\n\n  /// Return a vector value that contains \\arg V broadcasted to \\p\n  /// EC elements.\n  Value *CreateVectorSplat(ElementCount EC, Value *V, const Twine &Name = \"\");\n\n  /// Return a value that has been extracted from a larger integer type.\n  Value *CreateExtractInteger(const DataLayout &DL, Value *From,\n                              IntegerType *ExtractedTy, uint64_t Offset,\n                              const Twine &Name);\n\n  Value *CreatePreserveArrayAccessIndex(Type *ElTy, Value *Base,\n                                        unsigned Dimension, unsigned LastIndex,\n                                        MDNode *DbgInfo);\n\n  Value *CreatePreserveUnionAccessIndex(Value *Base, unsigned FieldIndex,\n                                        MDNode *DbgInfo);\n\n  Value *CreatePreserveStructAccessIndex(Type *ElTy, Value *Base,\n                                         unsigned Index, unsigned FieldIndex,\n                                         MDNode *DbgInfo);\n\nprivate:\n  /// Helper function that creates an assume intrinsic call that\n  /// represents an alignment assumption on the provided pointer \\p PtrValue\n  /// with offset \\p OffsetValue and alignment value \\p AlignValue.\n  CallInst *CreateAlignmentAssumptionHelper(const DataLayout &DL,\n                                            Value *PtrValue, Value *AlignValue,\n                                            Value *OffsetValue);\n\npublic:\n  /// Create an assume intrinsic call that represents an alignment\n  /// assumption on the provided pointer.\n  ///\n  /// An optional offset can be provided, and if it is provided, the offset\n  /// must be subtracted from the provided pointer to get the pointer with the\n  /// specified alignment.\n  CallInst *CreateAlignmentAssumption(const DataLayout &DL, Value *PtrValue,\n                                      unsigned Alignment,\n                                      Value *OffsetValue = nullptr);\n\n  /// Create an assume intrinsic call that represents an alignment\n  /// assumption on the provided pointer.\n  ///\n  /// An optional offset can be provided, and if it is provided, the offset\n  /// must be subtracted from the provided pointer to get the pointer with the\n  /// specified alignment.\n  ///\n  /// This overload handles the condition where the Alignment is dependent\n  /// on an existing value rather than a static value.\n  CallInst *CreateAlignmentAssumption(const DataLayout &DL, Value *PtrValue,\n                                      Value *Alignment,\n                                      Value *OffsetValue = nullptr);\n};\n\n/// This provides a uniform API for creating instructions and inserting\n/// them into a basic block: either at the end of a BasicBlock, or at a specific\n/// iterator location in a block.\n///\n/// Note that the builder does not expose the full generality of LLVM\n/// instructions.  For access to extra instruction properties, use the mutators\n/// (e.g. setVolatile) on the instructions after they have been\n/// created. Convenience state exists to specify fast-math flags and fp-math\n/// tags.\n///\n/// The first template argument specifies a class to use for creating constants.\n/// This defaults to creating minimally folded constants.  The second template\n/// argument allows clients to specify custom insertion hooks that are called on\n/// every newly created insertion.\ntemplate <typename FolderTy = ConstantFolder,\n          typename InserterTy = IRBuilderDefaultInserter>\nclass IRBuilder : public IRBuilderBase {\nprivate:\n  FolderTy Folder;\n  InserterTy Inserter;\n\npublic:\n  IRBuilder(LLVMContext &C, FolderTy Folder, InserterTy Inserter = InserterTy(),\n            MDNode *FPMathTag = nullptr,\n            ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(C, this->Folder, this->Inserter, FPMathTag, OpBundles),\n        Folder(Folder), Inserter(Inserter) {}\n\n  explicit IRBuilder(LLVMContext &C, MDNode *FPMathTag = nullptr,\n                     ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(C, this->Folder, this->Inserter, FPMathTag, OpBundles) {}\n\n  explicit IRBuilder(BasicBlock *TheBB, FolderTy Folder,\n                     MDNode *FPMathTag = nullptr,\n                     ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(TheBB->getContext(), this->Folder, this->Inserter,\n                      FPMathTag, OpBundles), Folder(Folder) {\n    SetInsertPoint(TheBB);\n  }\n\n  explicit IRBuilder(BasicBlock *TheBB, MDNode *FPMathTag = nullptr,\n                     ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(TheBB->getContext(), this->Folder, this->Inserter,\n                      FPMathTag, OpBundles) {\n    SetInsertPoint(TheBB);\n  }\n\n  explicit IRBuilder(Instruction *IP, MDNode *FPMathTag = nullptr,\n                     ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(IP->getContext(), this->Folder, this->Inserter,\n                      FPMathTag, OpBundles) {\n    SetInsertPoint(IP);\n  }\n\n  IRBuilder(BasicBlock *TheBB, BasicBlock::iterator IP, FolderTy Folder,\n            MDNode *FPMathTag = nullptr,\n            ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(TheBB->getContext(), this->Folder, this->Inserter,\n                      FPMathTag, OpBundles), Folder(Folder) {\n    SetInsertPoint(TheBB, IP);\n  }\n\n  IRBuilder(BasicBlock *TheBB, BasicBlock::iterator IP,\n            MDNode *FPMathTag = nullptr,\n            ArrayRef<OperandBundleDef> OpBundles = None)\n      : IRBuilderBase(TheBB->getContext(), this->Folder, this->Inserter,\n                      FPMathTag, OpBundles) {\n    SetInsertPoint(TheBB, IP);\n  }\n\n  /// Avoid copying the full IRBuilder. Prefer using InsertPointGuard\n  /// or FastMathFlagGuard instead.\n  IRBuilder(const IRBuilder &) = delete;\n\n  InserterTy &getInserter() { return Inserter; }\n};\n\n// Create wrappers for C Binding types (see CBindingWrapping.h).\nDEFINE_SIMPLE_CONVERSION_FUNCTIONS(IRBuilder<>, LLVMBuilderRef)\n\n} // end namespace llvm\n\n#endif // LLVM_IR_IRBUILDER_H\n"}, "59": {"id": 59, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ProfileData/InstrProf.h", "content": "//===- InstrProf.h - Instrumented profiling format support ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Instrumentation-based profiling data is generated by instrumented\n// binaries through library functions in compiler-rt, and read by the clang\n// frontend to feed PGO.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_PROFILEDATA_INSTRPROF_H\n#define LLVM_PROFILEDATA_INSTRPROF_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/STLExtras.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/StringSet.h\"\n#include \"llvm/ADT/Triple.h\"\n#include \"llvm/IR/GlobalValue.h\"\n#include \"llvm/IR/ProfileSummary.h\"\n#include \"llvm/ProfileData/InstrProfData.inc\"\n#include \"llvm/Support/CommandLine.h\"\n#include \"llvm/Support/Compiler.h\"\n#include \"llvm/Support/Endian.h\"\n#include \"llvm/Support/Error.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"llvm/Support/Host.h\"\n#include \"llvm/Support/MD5.h\"\n#include \"llvm/Support/MathExtras.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <cstring>\n#include <list>\n#include <memory>\n#include <string>\n#include <system_error>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\nclass Function;\nclass GlobalVariable;\nstruct InstrProfRecord;\nclass InstrProfSymtab;\nclass Instruction;\nclass MDNode;\nclass Module;\n\nenum InstrProfSectKind {\n#define INSTR_PROF_SECT_ENTRY(Kind, SectNameCommon, SectNameCoff, Prefix) Kind,\n#include \"llvm/ProfileData/InstrProfData.inc\"\n};\n\n/// Return the name of the profile section corresponding to \\p IPSK.\n///\n/// The name of the section depends on the object format type \\p OF. If\n/// \\p AddSegmentInfo is true, a segment prefix and additional linker hints may\n/// be added to the section name (this is the default).\nstd::string getInstrProfSectionName(InstrProfSectKind IPSK,\n                                    Triple::ObjectFormatType OF,\n                                    bool AddSegmentInfo = true);\n\n/// Return the name profile runtime entry point to do value profiling\n/// for a given site.\ninline StringRef getInstrProfValueProfFuncName() {\n  return INSTR_PROF_VALUE_PROF_FUNC_STR;\n}\n\n/// Return the name profile runtime entry point to do memop size value\n/// profiling.\ninline StringRef getInstrProfValueProfMemOpFuncName() {\n  return INSTR_PROF_VALUE_PROF_MEMOP_FUNC_STR;\n}\n\n/// Return the name prefix of variables containing instrumented function names.\ninline StringRef getInstrProfNameVarPrefix() { return \"__profn_\"; }\n\n/// Return the name prefix of variables containing per-function control data.\ninline StringRef getInstrProfDataVarPrefix() { return \"__profd_\"; }\n\n/// Return the name prefix of profile counter variables.\ninline StringRef getInstrProfCountersVarPrefix() { return \"__profc_\"; }\n\n/// Return the name prefix of value profile variables.\ninline StringRef getInstrProfValuesVarPrefix() { return \"__profvp_\"; }\n\n/// Return the name of value profile node array variables:\ninline StringRef getInstrProfVNodesVarName() { return \"__llvm_prf_vnodes\"; }\n\n/// Return the name of the variable holding the strings (possibly compressed)\n/// of all function's PGO names.\ninline StringRef getInstrProfNamesVarName() {\n  return \"__llvm_prf_nm\";\n}\n\n/// Return the name of a covarage mapping variable (internal linkage)\n/// for each instrumented source module. Such variables are allocated\n/// in the __llvm_covmap section.\ninline StringRef getCoverageMappingVarName() {\n  return \"__llvm_coverage_mapping\";\n}\n\n/// Return the name of the internal variable recording the array\n/// of PGO name vars referenced by the coverage mapping. The owning\n/// functions of those names are not emitted by FE (e.g, unused inline\n/// functions.)\ninline StringRef getCoverageUnusedNamesVarName() {\n  return \"__llvm_coverage_names\";\n}\n\n/// Return the name of function that registers all the per-function control\n/// data at program startup time by calling __llvm_register_function. This\n/// function has internal linkage and is called by  __llvm_profile_init\n/// runtime method. This function is not generated for these platforms:\n/// Darwin, Linux, and FreeBSD.\ninline StringRef getInstrProfRegFuncsName() {\n  return \"__llvm_profile_register_functions\";\n}\n\n/// Return the name of the runtime interface that registers per-function control\n/// data for one instrumented function.\ninline StringRef getInstrProfRegFuncName() {\n  return \"__llvm_profile_register_function\";\n}\n\n/// Return the name of the runtime interface that registers the PGO name strings.\ninline StringRef getInstrProfNamesRegFuncName() {\n  return \"__llvm_profile_register_names_function\";\n}\n\n/// Return the name of the runtime initialization method that is generated by\n/// the compiler. The function calls __llvm_profile_register_functions and\n/// __llvm_profile_override_default_filename functions if needed. This function\n/// has internal linkage and invoked at startup time via init_array.\ninline StringRef getInstrProfInitFuncName() { return \"__llvm_profile_init\"; }\n\n/// Return the name of the hook variable defined in profile runtime library.\n/// A reference to the variable causes the linker to link in the runtime\n/// initialization module (which defines the hook variable).\ninline StringRef getInstrProfRuntimeHookVarName() {\n  return INSTR_PROF_QUOTE(INSTR_PROF_PROFILE_RUNTIME_VAR);\n}\n\ninline StringRef getInstrProfCounterBiasVarName() {\n  return \"__llvm_profile_counter_bias\";\n}\n\n/// Return the marker used to separate PGO names during serialization.\ninline StringRef getInstrProfNameSeparator() { return \"\\01\"; }\n\n/// Return the modified name for function \\c F suitable to be\n/// used the key for profile lookup. Variable \\c InLTO indicates if this\n/// is called in LTO optimization passes.\nstd::string getPGOFuncName(const Function &F, bool InLTO = false,\n                           uint64_t Version = INSTR_PROF_INDEX_VERSION);\n\n/// Return the modified name for a function suitable to be\n/// used the key for profile lookup. The function's original\n/// name is \\c RawFuncName and has linkage of type \\c Linkage.\n/// The function is defined in module \\c FileName.\nstd::string getPGOFuncName(StringRef RawFuncName,\n                           GlobalValue::LinkageTypes Linkage,\n                           StringRef FileName,\n                           uint64_t Version = INSTR_PROF_INDEX_VERSION);\n\n/// Return the name of the global variable used to store a function\n/// name in PGO instrumentation. \\c FuncName is the name of the function\n/// returned by the \\c getPGOFuncName call.\nstd::string getPGOFuncNameVarName(StringRef FuncName,\n                                  GlobalValue::LinkageTypes Linkage);\n\n/// Create and return the global variable for function name used in PGO\n/// instrumentation. \\c FuncName is the name of the function returned\n/// by \\c getPGOFuncName call.\nGlobalVariable *createPGOFuncNameVar(Function &F, StringRef PGOFuncName);\n\n/// Create and return the global variable for function name used in PGO\n/// instrumentation.  /// \\c FuncName is the name of the function\n/// returned by \\c getPGOFuncName call, \\c M is the owning module,\n/// and \\c Linkage is the linkage of the instrumented function.\nGlobalVariable *createPGOFuncNameVar(Module &M,\n                                     GlobalValue::LinkageTypes Linkage,\n                                     StringRef PGOFuncName);\n\n/// Return the initializer in string of the PGO name var \\c NameVar.\nStringRef getPGOFuncNameVarInitializer(GlobalVariable *NameVar);\n\n/// Given a PGO function name, remove the filename prefix and return\n/// the original (static) function name.\nStringRef getFuncNameWithoutPrefix(StringRef PGOFuncName,\n                                   StringRef FileName = \"<unknown>\");\n\n/// Given a vector of strings (function PGO names) \\c NameStrs, the\n/// method generates a combined string \\c Result thatis ready to be\n/// serialized.  The \\c Result string is comprised of three fields:\n/// The first field is the legnth of the uncompressed strings, and the\n/// the second field is the length of the zlib-compressed string.\n/// Both fields are encoded in ULEB128.  If \\c doCompress is false, the\n///  third field is the uncompressed strings; otherwise it is the\n/// compressed string. When the string compression is off, the\n/// second field will have value zero.\nError collectPGOFuncNameStrings(ArrayRef<std::string> NameStrs,\n                                bool doCompression, std::string &Result);\n\n/// Produce \\c Result string with the same format described above. The input\n/// is vector of PGO function name variables that are referenced.\nError collectPGOFuncNameStrings(ArrayRef<GlobalVariable *> NameVars,\n                                std::string &Result, bool doCompression = true);\n\n/// \\c NameStrings is a string composed of one of more sub-strings encoded in\n/// the format described above. The substrings are separated by 0 or more zero\n/// bytes. This method decodes the string and populates the \\c Symtab.\nError readPGOFuncNameStrings(StringRef NameStrings, InstrProfSymtab &Symtab);\n\n/// Check if INSTR_PROF_RAW_VERSION_VAR is defined. This global is only being\n/// set in IR PGO compilation.\nbool isIRPGOFlagSet(const Module *M);\n\n/// Check if we can safely rename this Comdat function. Instances of the same\n/// comdat function may have different control flows thus can not share the\n/// same counter variable.\nbool canRenameComdatFunc(const Function &F, bool CheckAddressTaken = false);\n\nenum InstrProfValueKind : uint32_t {\n#define VALUE_PROF_KIND(Enumerator, Value, Descr) Enumerator = Value,\n#include \"llvm/ProfileData/InstrProfData.inc\"\n};\n\n/// Get the value profile data for value site \\p SiteIdx from \\p InstrProfR\n/// and annotate the instruction \\p Inst with the value profile meta data.\n/// Annotate up to \\p MaxMDCount (default 3) number of records per value site.\nvoid annotateValueSite(Module &M, Instruction &Inst,\n                       const InstrProfRecord &InstrProfR,\n                       InstrProfValueKind ValueKind, uint32_t SiteIndx,\n                       uint32_t MaxMDCount = 3);\n\n/// Same as the above interface but using an ArrayRef, as well as \\p Sum.\nvoid annotateValueSite(Module &M, Instruction &Inst,\n                       ArrayRef<InstrProfValueData> VDs, uint64_t Sum,\n                       InstrProfValueKind ValueKind, uint32_t MaxMDCount);\n\n/// Magic number in the value profile data showing a target has been\n/// promoted for the instruction and shouldn't be promoted again.\nconst uint64_t NOMORE_ICP_MAGICNUM = -1;\n\n/// Extract the value profile data from \\p Inst which is annotated with\n/// value profile meta data. Return false if there is no value data annotated,\n/// otherwise  return true.\nbool getValueProfDataFromInst(const Instruction &Inst,\n                              InstrProfValueKind ValueKind,\n                              uint32_t MaxNumValueData,\n                              InstrProfValueData ValueData[],\n                              uint32_t &ActualNumValueData, uint64_t &TotalC,\n                              bool GetNoICPValue = false);\n\ninline StringRef getPGOFuncNameMetadataName() { return \"PGOFuncName\"; }\n\n/// Return the PGOFuncName meta data associated with a function.\nMDNode *getPGOFuncNameMetadata(const Function &F);\n\n/// Create the PGOFuncName meta data if PGOFuncName is different from\n/// function's raw name. This should only apply to internal linkage functions\n/// declared by users only.\nvoid createPGOFuncNameMetadata(Function &F, StringRef PGOFuncName);\n\n/// Check if we can use Comdat for profile variables. This will eliminate\n/// the duplicated profile variables for Comdat functions.\nbool needsComdatForCounter(const Function &F, const Module &M);\n\nconst std::error_category &instrprof_category();\n\nenum class instrprof_error {\n  success = 0,\n  eof,\n  unrecognized_format,\n  bad_magic,\n  bad_header,\n  unsupported_version,\n  unsupported_hash_type,\n  too_large,\n  truncated,\n  malformed,\n  unknown_function,\n  invalid_prof,\n  hash_mismatch,\n  count_mismatch,\n  counter_overflow,\n  value_site_count_mismatch,\n  compress_failed,\n  uncompress_failed,\n  empty_raw_profile,\n  zlib_unavailable\n};\n\ninline std::error_code make_error_code(instrprof_error E) {\n  return std::error_code(static_cast<int>(E), instrprof_category());\n}\n\nclass InstrProfError : public ErrorInfo<InstrProfError> {\npublic:\n  InstrProfError(instrprof_error Err) : Err(Err) {\n    assert(Err != instrprof_error::success && \"Not an error\");\n  }\n\n  std::string message() const override;\n\n  void log(raw_ostream &OS) const override { OS << message(); }\n\n  std::error_code convertToErrorCode() const override {\n    return make_error_code(Err);\n  }\n\n  instrprof_error get() const { return Err; }\n\n  /// Consume an Error and return the raw enum value contained within it. The\n  /// Error must either be a success value, or contain a single InstrProfError.\n  static instrprof_error take(Error E) {\n    auto Err = instrprof_error::success;\n    handleAllErrors(std::move(E), [&Err](const InstrProfError &IPE) {\n      assert(Err == instrprof_error::success && \"Multiple errors encountered\");\n      Err = IPE.get();\n    });\n    return Err;\n  }\n\n  static char ID;\n\nprivate:\n  instrprof_error Err;\n};\n\nclass SoftInstrProfErrors {\n  /// Count the number of soft instrprof_errors encountered and keep track of\n  /// the first such error for reporting purposes.\n\n  /// The first soft error encountered.\n  instrprof_error FirstError = instrprof_error::success;\n\n  /// The number of hash mismatches.\n  unsigned NumHashMismatches = 0;\n\n  /// The number of count mismatches.\n  unsigned NumCountMismatches = 0;\n\n  /// The number of counter overflows.\n  unsigned NumCounterOverflows = 0;\n\n  /// The number of value site count mismatches.\n  unsigned NumValueSiteCountMismatches = 0;\n\npublic:\n  SoftInstrProfErrors() = default;\n\n  ~SoftInstrProfErrors() {\n    assert(FirstError == instrprof_error::success &&\n           \"Unchecked soft error encountered\");\n  }\n\n  /// Track a soft error (\\p IE) and increment its associated counter.\n  void addError(instrprof_error IE);\n\n  /// Get the number of hash mismatches.\n  unsigned getNumHashMismatches() const { return NumHashMismatches; }\n\n  /// Get the number of count mismatches.\n  unsigned getNumCountMismatches() const { return NumCountMismatches; }\n\n  /// Get the number of counter overflows.\n  unsigned getNumCounterOverflows() const { return NumCounterOverflows; }\n\n  /// Get the number of value site count mismatches.\n  unsigned getNumValueSiteCountMismatches() const {\n    return NumValueSiteCountMismatches;\n  }\n\n  /// Return the first encountered error and reset FirstError to a success\n  /// value.\n  Error takeError() {\n    if (FirstError == instrprof_error::success)\n      return Error::success();\n    auto E = make_error<InstrProfError>(FirstError);\n    FirstError = instrprof_error::success;\n    return E;\n  }\n};\n\nnamespace object {\n\nclass SectionRef;\n\n} // end namespace object\n\nnamespace IndexedInstrProf {\n\nuint64_t ComputeHash(StringRef K);\n\n} // end namespace IndexedInstrProf\n\n/// A symbol table used for function PGO name look-up with keys\n/// (such as pointers, md5hash values) to the function. A function's\n/// PGO name or name's md5hash are used in retrieving the profile\n/// data of the function. See \\c getPGOFuncName() method for details\n/// on how PGO name is formed.\nclass InstrProfSymtab {\npublic:\n  using AddrHashMap = std::vector<std::pair<uint64_t, uint64_t>>;\n\nprivate:\n  StringRef Data;\n  uint64_t Address = 0;\n  // Unique name strings.\n  StringSet<> NameTab;\n  // A map from MD5 keys to function name strings.\n  std::vector<std::pair<uint64_t, StringRef>> MD5NameMap;\n  // A map from MD5 keys to function define. We only populate this map\n  // when build the Symtab from a Module.\n  std::vector<std::pair<uint64_t, Function *>> MD5FuncMap;\n  // A map from function runtime address to function name MD5 hash.\n  // This map is only populated and used by raw instr profile reader.\n  AddrHashMap AddrToMD5Map;\n  bool Sorted = false;\n\n  static StringRef getExternalSymbol() {\n    return \"** External Symbol **\";\n  }\n\n  // If the symtab is created by a series of calls to \\c addFuncName, \\c\n  // finalizeSymtab needs to be called before looking up function names.\n  // This is required because the underlying map is a vector (for space\n  // efficiency) which needs to be sorted.\n  inline void finalizeSymtab();\n\npublic:\n  InstrProfSymtab() = default;\n\n  /// Create InstrProfSymtab from an object file section which\n  /// contains function PGO names. When section may contain raw\n  /// string data or string data in compressed form. This method\n  /// only initialize the symtab with reference to the data and\n  /// the section base address. The decompression will be delayed\n  /// until before it is used. See also \\c create(StringRef) method.\n  Error create(object::SectionRef &Section);\n\n  /// This interface is used by reader of CoverageMapping test\n  /// format.\n  inline Error create(StringRef D, uint64_t BaseAddr);\n\n  /// \\c NameStrings is a string composed of one of more sub-strings\n  ///  encoded in the format described in \\c collectPGOFuncNameStrings.\n  /// This method is a wrapper to \\c readPGOFuncNameStrings method.\n  inline Error create(StringRef NameStrings);\n\n  /// A wrapper interface to populate the PGO symtab with functions\n  /// decls from module \\c M. This interface is used by transformation\n  /// passes such as indirect function call promotion. Variable \\c InLTO\n  /// indicates if this is called from LTO optimization passes.\n  Error create(Module &M, bool InLTO = false);\n\n  /// Create InstrProfSymtab from a set of names iteratable from\n  /// \\p IterRange. This interface is used by IndexedProfReader.\n  template <typename NameIterRange> Error create(const NameIterRange &IterRange);\n\n  /// Update the symtab by adding \\p FuncName to the table. This interface\n  /// is used by the raw and text profile readers.\n  Error addFuncName(StringRef FuncName) {\n    if (FuncName.empty())\n      return make_error<InstrProfError>(instrprof_error::malformed);\n    auto Ins = NameTab.insert(FuncName);\n    if (Ins.second) {\n      MD5NameMap.push_back(std::make_pair(\n          IndexedInstrProf::ComputeHash(FuncName), Ins.first->getKey()));\n      Sorted = false;\n    }\n    return Error::success();\n  }\n\n  /// Map a function address to its name's MD5 hash. This interface\n  /// is only used by the raw profiler reader.\n  void mapAddress(uint64_t Addr, uint64_t MD5Val) {\n    AddrToMD5Map.push_back(std::make_pair(Addr, MD5Val));\n  }\n\n  /// Return a function's hash, or 0, if the function isn't in this SymTab.\n  uint64_t getFunctionHashFromAddress(uint64_t Address);\n\n  /// Return function's PGO name from the function name's symbol\n  /// address in the object file. If an error occurs, return\n  /// an empty string.\n  StringRef getFuncName(uint64_t FuncNameAddress, size_t NameSize);\n\n  /// Return function's PGO name from the name's md5 hash value.\n  /// If not found, return an empty string.\n  inline StringRef getFuncName(uint64_t FuncMD5Hash);\n\n  /// Just like getFuncName, except that it will return a non-empty StringRef\n  /// if the function is external to this symbol table. All such cases\n  /// will be represented using the same StringRef value.\n  inline StringRef getFuncNameOrExternalSymbol(uint64_t FuncMD5Hash);\n\n  /// True if Symbol is the value used to represent external symbols.\n  static bool isExternalSymbol(const StringRef &Symbol) {\n    return Symbol == InstrProfSymtab::getExternalSymbol();\n  }\n\n  /// Return function from the name's md5 hash. Return nullptr if not found.\n  inline Function *getFunction(uint64_t FuncMD5Hash);\n\n  /// Return the function's original assembly name by stripping off\n  /// the prefix attached (to symbols with priviate linkage). For\n  /// global functions, it returns the same string as getFuncName.\n  inline StringRef getOrigFuncName(uint64_t FuncMD5Hash);\n\n  /// Return the name section data.\n  inline StringRef getNameData() const { return Data; }\n};\n\nError InstrProfSymtab::create(StringRef D, uint64_t BaseAddr) {\n  Data = D;\n  Address = BaseAddr;\n  return Error::success();\n}\n\nError InstrProfSymtab::create(StringRef NameStrings) {\n  return readPGOFuncNameStrings(NameStrings, *this);\n}\n\ntemplate <typename NameIterRange>\nError InstrProfSymtab::create(const NameIterRange &IterRange) {\n  for (auto Name : IterRange)\n    if (Error E = addFuncName(Name))\n      return E;\n\n  finalizeSymtab();\n  return Error::success();\n}\n\nvoid InstrProfSymtab::finalizeSymtab() {\n  if (Sorted)\n    return;\n  llvm::sort(MD5NameMap, less_first());\n  llvm::sort(MD5FuncMap, less_first());\n  llvm::sort(AddrToMD5Map, less_first());\n  AddrToMD5Map.erase(std::unique(AddrToMD5Map.begin(), AddrToMD5Map.end()),\n                     AddrToMD5Map.end());\n  Sorted = true;\n}\n\nStringRef InstrProfSymtab::getFuncNameOrExternalSymbol(uint64_t FuncMD5Hash) {\n  StringRef ret = getFuncName(FuncMD5Hash);\n  if (ret.empty())\n    return InstrProfSymtab::getExternalSymbol();\n  return ret;\n}\n\nStringRef InstrProfSymtab::getFuncName(uint64_t FuncMD5Hash) {\n  finalizeSymtab();\n  auto Result = llvm::lower_bound(MD5NameMap, FuncMD5Hash,\n                                  [](const std::pair<uint64_t, StringRef> &LHS,\n                                     uint64_t RHS) { return LHS.first < RHS; });\n  if (Result != MD5NameMap.end() && Result->first == FuncMD5Hash)\n    return Result->second;\n  return StringRef();\n}\n\nFunction* InstrProfSymtab::getFunction(uint64_t FuncMD5Hash) {\n  finalizeSymtab();\n  auto Result = llvm::lower_bound(MD5FuncMap, FuncMD5Hash,\n                                  [](const std::pair<uint64_t, Function *> &LHS,\n                                     uint64_t RHS) { return LHS.first < RHS; });\n  if (Result != MD5FuncMap.end() && Result->first == FuncMD5Hash)\n    return Result->second;\n  return nullptr;\n}\n\n// See also getPGOFuncName implementation. These two need to be\n// matched.\nStringRef InstrProfSymtab::getOrigFuncName(uint64_t FuncMD5Hash) {\n  StringRef PGOName = getFuncName(FuncMD5Hash);\n  size_t S = PGOName.find_first_of(':');\n  if (S == StringRef::npos)\n    return PGOName;\n  return PGOName.drop_front(S + 1);\n}\n\n// To store the sums of profile count values, or the percentage of\n// the sums of the total count values.\nstruct CountSumOrPercent {\n  uint64_t NumEntries;\n  double CountSum;\n  double ValueCounts[IPVK_Last - IPVK_First + 1];\n  CountSumOrPercent() : NumEntries(0), CountSum(0.0f), ValueCounts() {}\n  void reset() {\n    NumEntries = 0;\n    CountSum = 0.0f;\n    for (unsigned I = 0; I < IPVK_Last - IPVK_First + 1; I++)\n      ValueCounts[I] = 0.0f;\n  }\n};\n\n// Function level or program level overlap information.\nstruct OverlapStats {\n  enum OverlapStatsLevel { ProgramLevel, FunctionLevel };\n  // Sum of the total count values for the base profile.\n  CountSumOrPercent Base;\n  // Sum of the total count values for the test profile.\n  CountSumOrPercent Test;\n  // Overlap lap score. Should be in range of [0.0f to 1.0f].\n  CountSumOrPercent Overlap;\n  CountSumOrPercent Mismatch;\n  CountSumOrPercent Unique;\n  OverlapStatsLevel Level;\n  const std::string *BaseFilename;\n  const std::string *TestFilename;\n  StringRef FuncName;\n  uint64_t FuncHash;\n  bool Valid;\n\n  OverlapStats(OverlapStatsLevel L = ProgramLevel)\n      : Level(L), BaseFilename(nullptr), TestFilename(nullptr), FuncHash(0),\n        Valid(false) {}\n\n  void dump(raw_fd_ostream &OS) const;\n\n  void setFuncInfo(StringRef Name, uint64_t Hash) {\n    FuncName = Name;\n    FuncHash = Hash;\n  }\n\n  Error accumulateCounts(const std::string &BaseFilename,\n                         const std::string &TestFilename, bool IsCS);\n  void addOneMismatch(const CountSumOrPercent &MismatchFunc);\n  void addOneUnique(const CountSumOrPercent &UniqueFunc);\n\n  static inline double score(uint64_t Val1, uint64_t Val2, double Sum1,\n                             double Sum2) {\n    if (Sum1 < 1.0f || Sum2 < 1.0f)\n      return 0.0f;\n    return std::min(Val1 / Sum1, Val2 / Sum2);\n  }\n};\n\n// This is used to filter the functions whose overlap information\n// to be output.\nstruct OverlapFuncFilters {\n  uint64_t ValueCutoff;\n  const std::string NameFilter;\n};\n\nstruct InstrProfValueSiteRecord {\n  /// Value profiling data pairs at a given value site.\n  std::list<InstrProfValueData> ValueData;\n\n  InstrProfValueSiteRecord() { ValueData.clear(); }\n  template <class InputIterator>\n  InstrProfValueSiteRecord(InputIterator F, InputIterator L)\n      : ValueData(F, L) {}\n\n  /// Sort ValueData ascending by Value\n  void sortByTargetValues() {\n    ValueData.sort(\n        [](const InstrProfValueData &left, const InstrProfValueData &right) {\n          return left.Value < right.Value;\n        });\n  }\n  /// Sort ValueData Descending by Count\n  inline void sortByCount();\n\n  /// Merge data from another InstrProfValueSiteRecord\n  /// Optionally scale merged counts by \\p Weight.\n  void merge(InstrProfValueSiteRecord &Input, uint64_t Weight,\n             function_ref<void(instrprof_error)> Warn);\n  /// Scale up value profile data counts by N (Numerator) / D (Denominator).\n  void scale(uint64_t N, uint64_t D, function_ref<void(instrprof_error)> Warn);\n\n  /// Compute the overlap b/w this record and Input record.\n  void overlap(InstrProfValueSiteRecord &Input, uint32_t ValueKind,\n               OverlapStats &Overlap, OverlapStats &FuncLevelOverlap);\n};\n\n/// Profiling information for a single function.\nstruct InstrProfRecord {\n  std::vector<uint64_t> Counts;\n\n  InstrProfRecord() = default;\n  InstrProfRecord(std::vector<uint64_t> Counts) : Counts(std::move(Counts)) {}\n  InstrProfRecord(InstrProfRecord &&) = default;\n  InstrProfRecord(const InstrProfRecord &RHS)\n      : Counts(RHS.Counts),\n        ValueData(RHS.ValueData\n                      ? std::make_unique<ValueProfData>(*RHS.ValueData)\n                      : nullptr) {}\n  InstrProfRecord &operator=(InstrProfRecord &&) = default;\n  InstrProfRecord &operator=(const InstrProfRecord &RHS) {\n    Counts = RHS.Counts;\n    if (!RHS.ValueData) {\n      ValueData = nullptr;\n      return *this;\n    }\n    if (!ValueData)\n      ValueData = std::make_unique<ValueProfData>(*RHS.ValueData);\n    else\n      *ValueData = *RHS.ValueData;\n    return *this;\n  }\n\n  /// Return the number of value profile kinds with non-zero number\n  /// of profile sites.\n  inline uint32_t getNumValueKinds() const;\n  /// Return the number of instrumented sites for ValueKind.\n  inline uint32_t getNumValueSites(uint32_t ValueKind) const;\n\n  /// Return the total number of ValueData for ValueKind.\n  inline uint32_t getNumValueData(uint32_t ValueKind) const;\n\n  /// Return the number of value data collected for ValueKind at profiling\n  /// site: Site.\n  inline uint32_t getNumValueDataForSite(uint32_t ValueKind,\n                                         uint32_t Site) const;\n\n  /// Return the array of profiled values at \\p Site. If \\p TotalC\n  /// is not null, the total count of all target values at this site\n  /// will be stored in \\c *TotalC.\n  inline std::unique_ptr<InstrProfValueData[]>\n  getValueForSite(uint32_t ValueKind, uint32_t Site,\n                  uint64_t *TotalC = nullptr) const;\n\n  /// Get the target value/counts of kind \\p ValueKind collected at site\n  /// \\p Site and store the result in array \\p Dest. Return the total\n  /// counts of all target values at this site.\n  inline uint64_t getValueForSite(InstrProfValueData Dest[], uint32_t ValueKind,\n                                  uint32_t Site) const;\n\n  /// Reserve space for NumValueSites sites.\n  inline void reserveSites(uint32_t ValueKind, uint32_t NumValueSites);\n\n  /// Add ValueData for ValueKind at value Site.\n  void addValueData(uint32_t ValueKind, uint32_t Site,\n                    InstrProfValueData *VData, uint32_t N,\n                    InstrProfSymtab *SymTab);\n\n  /// Merge the counts in \\p Other into this one.\n  /// Optionally scale merged counts by \\p Weight.\n  void merge(InstrProfRecord &Other, uint64_t Weight,\n             function_ref<void(instrprof_error)> Warn);\n\n  /// Scale up profile counts (including value profile data) by\n  /// a factor of (N / D).\n  void scale(uint64_t N, uint64_t D, function_ref<void(instrprof_error)> Warn);\n\n  /// Sort value profile data (per site) by count.\n  void sortValueData() {\n    for (uint32_t Kind = IPVK_First; Kind <= IPVK_Last; ++Kind)\n      for (auto &SR : getValueSitesForKind(Kind))\n        SR.sortByCount();\n  }\n\n  /// Clear value data entries and edge counters.\n  void Clear() {\n    Counts.clear();\n    clearValueData();\n  }\n\n  /// Clear value data entries\n  void clearValueData() { ValueData = nullptr; }\n\n  /// Compute the sums of all counts and store in Sum.\n  void accumulateCounts(CountSumOrPercent &Sum) const;\n\n  /// Compute the overlap b/w this IntrprofRecord and Other.\n  void overlap(InstrProfRecord &Other, OverlapStats &Overlap,\n               OverlapStats &FuncLevelOverlap, uint64_t ValueCutoff);\n\n  /// Compute the overlap of value profile counts.\n  void overlapValueProfData(uint32_t ValueKind, InstrProfRecord &Src,\n                            OverlapStats &Overlap,\n                            OverlapStats &FuncLevelOverlap);\n\nprivate:\n  struct ValueProfData {\n    std::vector<InstrProfValueSiteRecord> IndirectCallSites;\n    std::vector<InstrProfValueSiteRecord> MemOPSizes;\n  };\n  std::unique_ptr<ValueProfData> ValueData;\n\n  MutableArrayRef<InstrProfValueSiteRecord>\n  getValueSitesForKind(uint32_t ValueKind) {\n    // Cast to /add/ const (should be an implicit_cast, ideally, if that's ever\n    // implemented in LLVM) to call the const overload of this function, then\n    // cast away the constness from the result.\n    auto AR = const_cast<const InstrProfRecord *>(this)->getValueSitesForKind(\n        ValueKind);\n    return makeMutableArrayRef(\n        const_cast<InstrProfValueSiteRecord *>(AR.data()), AR.size());\n  }\n  ArrayRef<InstrProfValueSiteRecord>\n  getValueSitesForKind(uint32_t ValueKind) const {\n    if (!ValueData)\n      return None;\n    switch (ValueKind) {\n    case IPVK_IndirectCallTarget:\n      return ValueData->IndirectCallSites;\n    case IPVK_MemOPSize:\n      return ValueData->MemOPSizes;\n    default:\n      llvm_unreachable(\"Unknown value kind!\");\n    }\n  }\n\n  std::vector<InstrProfValueSiteRecord> &\n  getOrCreateValueSitesForKind(uint32_t ValueKind) {\n    if (!ValueData)\n      ValueData = std::make_unique<ValueProfData>();\n    switch (ValueKind) {\n    case IPVK_IndirectCallTarget:\n      return ValueData->IndirectCallSites;\n    case IPVK_MemOPSize:\n      return ValueData->MemOPSizes;\n    default:\n      llvm_unreachable(\"Unknown value kind!\");\n    }\n  }\n\n  // Map indirect call target name hash to name string.\n  uint64_t remapValue(uint64_t Value, uint32_t ValueKind,\n                      InstrProfSymtab *SymTab);\n\n  // Merge Value Profile data from Src record to this record for ValueKind.\n  // Scale merged value counts by \\p Weight.\n  void mergeValueProfData(uint32_t ValkeKind, InstrProfRecord &Src,\n                          uint64_t Weight,\n                          function_ref<void(instrprof_error)> Warn);\n\n  // Scale up value profile data count by N (Numerator) / D (Denominator).\n  void scaleValueProfData(uint32_t ValueKind, uint64_t N, uint64_t D,\n                          function_ref<void(instrprof_error)> Warn);\n};\n\nstruct NamedInstrProfRecord : InstrProfRecord {\n  StringRef Name;\n  uint64_t Hash;\n\n  // We reserve this bit as the flag for context sensitive profile record.\n  static const int CS_FLAG_IN_FUNC_HASH = 60;\n\n  NamedInstrProfRecord() = default;\n  NamedInstrProfRecord(StringRef Name, uint64_t Hash,\n                       std::vector<uint64_t> Counts)\n      : InstrProfRecord(std::move(Counts)), Name(Name), Hash(Hash) {}\n\n  static bool hasCSFlagInHash(uint64_t FuncHash) {\n    return ((FuncHash >> CS_FLAG_IN_FUNC_HASH) & 1);\n  }\n  static void setCSFlagInHash(uint64_t &FuncHash) {\n    FuncHash |= ((uint64_t)1 << CS_FLAG_IN_FUNC_HASH);\n  }\n};\n\nuint32_t InstrProfRecord::getNumValueKinds() const {\n  uint32_t NumValueKinds = 0;\n  for (uint32_t Kind = IPVK_First; Kind <= IPVK_Last; ++Kind)\n    NumValueKinds += !(getValueSitesForKind(Kind).empty());\n  return NumValueKinds;\n}\n\nuint32_t InstrProfRecord::getNumValueData(uint32_t ValueKind) const {\n  uint32_t N = 0;\n  for (auto &SR : getValueSitesForKind(ValueKind))\n    N += SR.ValueData.size();\n  return N;\n}\n\nuint32_t InstrProfRecord::getNumValueSites(uint32_t ValueKind) const {\n  return getValueSitesForKind(ValueKind).size();\n}\n\nuint32_t InstrProfRecord::getNumValueDataForSite(uint32_t ValueKind,\n                                                 uint32_t Site) const {\n  return getValueSitesForKind(ValueKind)[Site].ValueData.size();\n}\n\nstd::unique_ptr<InstrProfValueData[]>\nInstrProfRecord::getValueForSite(uint32_t ValueKind, uint32_t Site,\n                                 uint64_t *TotalC) const {\n  uint64_t Dummy = 0;\n  uint64_t &TotalCount = (TotalC == nullptr ? Dummy : *TotalC);\n  uint32_t N = getNumValueDataForSite(ValueKind, Site);\n  if (N == 0) {\n    TotalCount = 0;\n    return std::unique_ptr<InstrProfValueData[]>(nullptr);\n  }\n\n  auto VD = std::make_unique<InstrProfValueData[]>(N);\n  TotalCount = getValueForSite(VD.get(), ValueKind, Site);\n\n  return VD;\n}\n\nuint64_t InstrProfRecord::getValueForSite(InstrProfValueData Dest[],\n                                          uint32_t ValueKind,\n                                          uint32_t Site) const {\n  uint32_t I = 0;\n  uint64_t TotalCount = 0;\n  for (auto V : getValueSitesForKind(ValueKind)[Site].ValueData) {\n    Dest[I].Value = V.Value;\n    Dest[I].Count = V.Count;\n    TotalCount = SaturatingAdd(TotalCount, V.Count);\n    I++;\n  }\n  return TotalCount;\n}\n\nvoid InstrProfRecord::reserveSites(uint32_t ValueKind, uint32_t NumValueSites) {\n  if (!NumValueSites)\n    return;\n  getOrCreateValueSitesForKind(ValueKind).reserve(NumValueSites);\n}\n\ninline support::endianness getHostEndianness() {\n  return sys::IsLittleEndianHost ? support::little : support::big;\n}\n\n// Include definitions for value profile data\n#define INSTR_PROF_VALUE_PROF_DATA\n#include \"llvm/ProfileData/InstrProfData.inc\"\n\nvoid InstrProfValueSiteRecord::sortByCount() {\n  ValueData.sort(\n      [](const InstrProfValueData &left, const InstrProfValueData &right) {\n        return left.Count > right.Count;\n      });\n  // Now truncate\n  size_t max_s = INSTR_PROF_MAX_NUM_VAL_PER_SITE;\n  if (ValueData.size() > max_s)\n    ValueData.resize(max_s);\n}\n\nnamespace IndexedInstrProf {\n\nenum class HashT : uint32_t {\n  MD5,\n  Last = MD5\n};\n\ninline uint64_t ComputeHash(HashT Type, StringRef K) {\n  switch (Type) {\n  case HashT::MD5:\n    return MD5Hash(K);\n  }\n  llvm_unreachable(\"Unhandled hash type\");\n}\n\nconst uint64_t Magic = 0x8169666f72706cff; // \"\\xfflprofi\\x81\"\n\nenum ProfVersion {\n  // Version 1 is the first version. In this version, the value of\n  // a key/value pair can only include profile data of a single function.\n  // Due to this restriction, the number of block counters for a given\n  // function is not recorded but derived from the length of the value.\n  Version1 = 1,\n  // The version 2 format supports recording profile data of multiple\n  // functions which share the same key in one value field. To support this,\n  // the number block counters is recorded as an uint64_t field right after the\n  // function structural hash.\n  Version2 = 2,\n  // Version 3 supports value profile data. The value profile data is expected\n  // to follow the block counter profile data.\n  Version3 = 3,\n  // In this version, profile summary data \\c IndexedInstrProf::Summary is\n  // stored after the profile header.\n  Version4 = 4,\n  // In this version, the frontend PGO stable hash algorithm defaults to V2.\n  Version5 = 5,\n  // In this version, the frontend PGO stable hash algorithm got fixed and\n  // may produce hashes different from Version5.\n  Version6 = 6,\n  // An additional counter is added around logical operators.\n  Version7 = 7,\n  // The current version is 7.\n  CurrentVersion = INSTR_PROF_INDEX_VERSION\n};\nconst uint64_t Version = ProfVersion::CurrentVersion;\n\nconst HashT HashType = HashT::MD5;\n\ninline uint64_t ComputeHash(StringRef K) { return ComputeHash(HashType, K); }\n\n// This structure defines the file header of the LLVM profile\n// data file in indexed-format.\nstruct Header {\n  uint64_t Magic;\n  uint64_t Version;\n  uint64_t Unused; // Becomes unused since version 4\n  uint64_t HashType;\n  uint64_t HashOffset;\n};\n\n// Profile summary data recorded in the profile data file in indexed\n// format. It is introduced in version 4. The summary data follows\n// right after the profile file header.\nstruct Summary {\n  struct Entry {\n    uint64_t Cutoff; ///< The required percentile of total execution count.\n    uint64_t\n        MinBlockCount;  ///< The minimum execution count for this percentile.\n    uint64_t NumBlocks; ///< Number of blocks >= the minumum execution count.\n  };\n  // The field kind enumerator to assigned value mapping should remain\n  // unchanged  when a new kind is added or an old kind gets deleted in\n  // the future.\n  enum SummaryFieldKind {\n    /// The total number of functions instrumented.\n    TotalNumFunctions = 0,\n    /// Total number of instrumented blocks/edges.\n    TotalNumBlocks = 1,\n    /// The maximal execution count among all functions.\n    /// This field does not exist for profile data from IR based\n    /// instrumentation.\n    MaxFunctionCount = 2,\n    /// Max block count of the program.\n    MaxBlockCount = 3,\n    /// Max internal block count of the program (excluding entry blocks).\n    MaxInternalBlockCount = 4,\n    /// The sum of all instrumented block counts.\n    TotalBlockCount = 5,\n    NumKinds = TotalBlockCount + 1\n  };\n\n  // The number of summmary fields following the summary header.\n  uint64_t NumSummaryFields;\n  // The number of Cutoff Entries (Summary::Entry) following summary fields.\n  uint64_t NumCutoffEntries;\n\n  Summary() = delete;\n  Summary(uint32_t Size) { memset(this, 0, Size); }\n\n  void operator delete(void *ptr) { ::operator delete(ptr); }\n\n  static uint32_t getSize(uint32_t NumSumFields, uint32_t NumCutoffEntries) {\n    return sizeof(Summary) + NumCutoffEntries * sizeof(Entry) +\n           NumSumFields * sizeof(uint64_t);\n  }\n\n  const uint64_t *getSummaryDataBase() const {\n    return reinterpret_cast<const uint64_t *>(this + 1);\n  }\n\n  uint64_t *getSummaryDataBase() {\n    return reinterpret_cast<uint64_t *>(this + 1);\n  }\n\n  const Entry *getCutoffEntryBase() const {\n    return reinterpret_cast<const Entry *>(\n        &getSummaryDataBase()[NumSummaryFields]);\n  }\n\n  Entry *getCutoffEntryBase() {\n    return reinterpret_cast<Entry *>(&getSummaryDataBase()[NumSummaryFields]);\n  }\n\n  uint64_t get(SummaryFieldKind K) const {\n    return getSummaryDataBase()[K];\n  }\n\n  void set(SummaryFieldKind K, uint64_t V) {\n    getSummaryDataBase()[K] = V;\n  }\n\n  const Entry &getEntry(uint32_t I) const { return getCutoffEntryBase()[I]; }\n\n  void setEntry(uint32_t I, const ProfileSummaryEntry &E) {\n    Entry &ER = getCutoffEntryBase()[I];\n    ER.Cutoff = E.Cutoff;\n    ER.MinBlockCount = E.MinCount;\n    ER.NumBlocks = E.NumCounts;\n  }\n};\n\ninline std::unique_ptr<Summary> allocSummary(uint32_t TotalSize) {\n  return std::unique_ptr<Summary>(new (::operator new(TotalSize))\n                                      Summary(TotalSize));\n}\n\n} // end namespace IndexedInstrProf\n\nnamespace RawInstrProf {\n\n// Version 1: First version\n// Version 2: Added value profile data section. Per-function control data\n// struct has more fields to describe value profile information.\n// Version 3: Compressed name section support. Function PGO name reference\n// from control data struct is changed from raw pointer to Name's MD5 value.\n// Version 4: ValueDataBegin and ValueDataSizes fields are removed from the\n// raw header.\n// Version 5: Bit 60 of FuncHash is reserved for the flag for the context\n// sensitive records.\nconst uint64_t Version = INSTR_PROF_RAW_VERSION;\n\ntemplate <class IntPtrT> inline uint64_t getMagic();\ntemplate <> inline uint64_t getMagic<uint64_t>() {\n  return INSTR_PROF_RAW_MAGIC_64;\n}\n\ntemplate <> inline uint64_t getMagic<uint32_t>() {\n  return INSTR_PROF_RAW_MAGIC_32;\n}\n\n// Per-function profile data header/control structure.\n// The definition should match the structure defined in\n// compiler-rt/lib/profile/InstrProfiling.h.\n// It should also match the synthesized type in\n// Transforms/Instrumentation/InstrProfiling.cpp:getOrCreateRegionCounters.\ntemplate <class IntPtrT> struct alignas(8) ProfileData {\n  #define INSTR_PROF_DATA(Type, LLVMType, Name, Init) Type Name;\n  #include \"llvm/ProfileData/InstrProfData.inc\"\n};\n\n// File header structure of the LLVM profile data in raw format.\n// The definition should match the header referenced in\n// compiler-rt/lib/profile/InstrProfilingFile.c  and\n// InstrProfilingBuffer.c.\nstruct Header {\n#define INSTR_PROF_RAW_HEADER(Type, Name, Init) const Type Name;\n#include \"llvm/ProfileData/InstrProfData.inc\"\n};\n\n} // end namespace RawInstrProf\n\n// Parse MemOP Size range option.\nvoid getMemOPSizeRangeFromOption(StringRef Str, int64_t &RangeStart,\n                                 int64_t &RangeLast);\n\n// Create a COMDAT variable INSTR_PROF_RAW_VERSION_VAR to make the runtime\n// aware this is an ir_level profile so it can set the version flag.\nvoid createIRLevelProfileFlagVar(Module &M, bool IsCS,\n                                 bool InstrEntryBBEnabled);\n\n// Create the variable for the profile file name.\nvoid createProfileFileNameVar(Module &M, StringRef InstrProfileOutput);\n\n// Whether to compress function names in profile records, and filenames in\n// code coverage mappings. Used by the Instrumentation library and unit tests.\nextern cl::opt<bool> DoInstrProfNameCompression;\n\n} // end namespace llvm\n#endif // LLVM_PROFILEDATA_INSTRPROF_H\n"}, "60": {"id": 60, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ProfileData/InstrProfReader.h", "content": "//===- InstrProfReader.h - Instrumented profiling readers -------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This file contains support for reading profiling data for instrumentation\n// based PGO and coverage.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_PROFILEDATA_INSTRPROFREADER_H\n#define LLVM_PROFILEDATA_INSTRPROFREADER_H\n\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/IR/ProfileSummary.h\"\n#include \"llvm/ProfileData/InstrProf.h\"\n#include \"llvm/Support/Endian.h\"\n#include \"llvm/Support/Error.h\"\n#include \"llvm/Support/LineIterator.h\"\n#include \"llvm/Support/MemoryBuffer.h\"\n#include \"llvm/Support/OnDiskHashTable.h\"\n#include \"llvm/Support/SwapByteOrder.h\"\n#include <algorithm>\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <iterator>\n#include <memory>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\nclass InstrProfReader;\n\n/// A file format agnostic iterator over profiling data.\nclass InstrProfIterator : public std::iterator<std::input_iterator_tag,\n                                               NamedInstrProfRecord> {\n  InstrProfReader *Reader = nullptr;\n  value_type Record;\n\n  void Increment();\n\npublic:\n  InstrProfIterator() = default;\n  InstrProfIterator(InstrProfReader *Reader) : Reader(Reader) { Increment(); }\n\n  InstrProfIterator &operator++() { Increment(); return *this; }\n  bool operator==(const InstrProfIterator &RHS) const {\n    return Reader == RHS.Reader;\n  }\n  bool operator!=(const InstrProfIterator &RHS) const {\n    return Reader != RHS.Reader;\n  }\n  value_type &operator*() { return Record; }\n  value_type *operator->() { return &Record; }\n};\n\n/// Base class and interface for reading profiling data of any known instrprof\n/// format. Provides an iterator over NamedInstrProfRecords.\nclass InstrProfReader {\n  instrprof_error LastError = instrprof_error::success;\n\npublic:\n  InstrProfReader() = default;\n  virtual ~InstrProfReader() = default;\n\n  /// Read the header.  Required before reading first record.\n  virtual Error readHeader() = 0;\n\n  /// Read a single record.\n  virtual Error readNextRecord(NamedInstrProfRecord &Record) = 0;\n\n  /// Iterator over profile data.\n  InstrProfIterator begin() { return InstrProfIterator(this); }\n  InstrProfIterator end() { return InstrProfIterator(); }\n\n  virtual bool isIRLevelProfile() const = 0;\n\n  virtual bool hasCSIRLevelProfile() const = 0;\n\n  virtual bool instrEntryBBEnabled() const = 0;\n\n  /// Return the PGO symtab. There are three different readers:\n  /// Raw, Text, and Indexed profile readers. The first two types\n  /// of readers are used only by llvm-profdata tool, while the indexed\n  /// profile reader is also used by llvm-cov tool and the compiler (\n  /// backend or frontend). Since creating PGO symtab can create\n  /// significant runtime and memory overhead (as it touches data\n  /// for the whole program), InstrProfSymtab for the indexed profile\n  /// reader should be created on demand and it is recommended to be\n  /// only used for dumping purpose with llvm-proftool, not with the\n  /// compiler.\n  virtual InstrProfSymtab &getSymtab() = 0;\n\n  /// Compute the sum of counts and return in Sum.\n  void accumulateCounts(CountSumOrPercent &Sum, bool IsCS);\n\nprotected:\n  std::unique_ptr<InstrProfSymtab> Symtab;\n\n  /// Set the current error and return same.\n  Error error(instrprof_error Err) {\n    LastError = Err;\n    if (Err == instrprof_error::success)\n      return Error::success();\n    return make_error<InstrProfError>(Err);\n  }\n\n  Error error(Error &&E) { return error(InstrProfError::take(std::move(E))); }\n\n  /// Clear the current error and return a successful one.\n  Error success() { return error(instrprof_error::success); }\n\npublic:\n  /// Return true if the reader has finished reading the profile data.\n  bool isEOF() { return LastError == instrprof_error::eof; }\n\n  /// Return true if the reader encountered an error reading profiling data.\n  bool hasError() { return LastError != instrprof_error::success && !isEOF(); }\n\n  /// Get the current error.\n  Error getError() {\n    if (hasError())\n      return make_error<InstrProfError>(LastError);\n    return Error::success();\n  }\n\n  /// Factory method to create an appropriately typed reader for the given\n  /// instrprof file.\n  static Expected<std::unique_ptr<InstrProfReader>> create(const Twine &Path);\n\n  static Expected<std::unique_ptr<InstrProfReader>>\n  create(std::unique_ptr<MemoryBuffer> Buffer);\n};\n\n/// Reader for the simple text based instrprof format.\n///\n/// This format is a simple text format that's suitable for test data. Records\n/// are separated by one or more blank lines, and record fields are separated by\n/// new lines.\n///\n/// Each record consists of a function name, a function hash, a number of\n/// counters, and then each counter value, in that order.\nclass TextInstrProfReader : public InstrProfReader {\nprivate:\n  /// The profile data file contents.\n  std::unique_ptr<MemoryBuffer> DataBuffer;\n  /// Iterator over the profile data.\n  line_iterator Line;\n  bool IsIRLevelProfile = false;\n  bool HasCSIRLevelProfile = false;\n  bool InstrEntryBBEnabled = false;\n\n  Error readValueProfileData(InstrProfRecord &Record);\n\npublic:\n  TextInstrProfReader(std::unique_ptr<MemoryBuffer> DataBuffer_)\n      : DataBuffer(std::move(DataBuffer_)), Line(*DataBuffer, true, '#') {}\n  TextInstrProfReader(const TextInstrProfReader &) = delete;\n  TextInstrProfReader &operator=(const TextInstrProfReader &) = delete;\n\n  /// Return true if the given buffer is in text instrprof format.\n  static bool hasFormat(const MemoryBuffer &Buffer);\n\n  bool isIRLevelProfile() const override { return IsIRLevelProfile; }\n\n  bool hasCSIRLevelProfile() const override { return HasCSIRLevelProfile; }\n\n  bool instrEntryBBEnabled() const override { return InstrEntryBBEnabled; }\n\n  /// Read the header.\n  Error readHeader() override;\n\n  /// Read a single record.\n  Error readNextRecord(NamedInstrProfRecord &Record) override;\n\n  InstrProfSymtab &getSymtab() override {\n    assert(Symtab.get());\n    return *Symtab.get();\n  }\n};\n\n/// Reader for the raw instrprof binary format from runtime.\n///\n/// This format is a raw memory dump of the instrumentation-baed profiling data\n/// from the runtime.  It has no index.\n///\n/// Templated on the unsigned type whose size matches pointers on the platform\n/// that wrote the profile.\ntemplate <class IntPtrT>\nclass RawInstrProfReader : public InstrProfReader {\nprivate:\n  /// The profile data file contents.\n  std::unique_ptr<MemoryBuffer> DataBuffer;\n  bool ShouldSwapBytes;\n  // The value of the version field of the raw profile data header. The lower 56\n  // bits specifies the format version and the most significant 8 bits specify\n  // the variant types of the profile.\n  uint64_t Version;\n  uint64_t CountersDelta;\n  uint64_t NamesDelta;\n  const RawInstrProf::ProfileData<IntPtrT> *Data;\n  const RawInstrProf::ProfileData<IntPtrT> *DataEnd;\n  const uint64_t *CountersStart;\n  const char *NamesStart;\n  uint64_t NamesSize;\n  // After value profile is all read, this pointer points to\n  // the header of next profile data (if exists)\n  const uint8_t *ValueDataStart;\n  uint32_t ValueKindLast;\n  uint32_t CurValueDataSize;\n\npublic:\n  RawInstrProfReader(std::unique_ptr<MemoryBuffer> DataBuffer)\n      : DataBuffer(std::move(DataBuffer)) {}\n  RawInstrProfReader(const RawInstrProfReader &) = delete;\n  RawInstrProfReader &operator=(const RawInstrProfReader &) = delete;\n\n  static bool hasFormat(const MemoryBuffer &DataBuffer);\n  Error readHeader() override;\n  Error readNextRecord(NamedInstrProfRecord &Record) override;\n\n  bool isIRLevelProfile() const override {\n    return (Version & VARIANT_MASK_IR_PROF) != 0;\n  }\n\n  bool hasCSIRLevelProfile() const override {\n    return (Version & VARIANT_MASK_CSIR_PROF) != 0;\n  }\n\n  bool instrEntryBBEnabled() const override {\n    return (Version & VARIANT_MASK_INSTR_ENTRY) != 0;\n  }\n\n  InstrProfSymtab &getSymtab() override {\n    assert(Symtab.get());\n    return *Symtab.get();\n  }\n\nprivate:\n  Error createSymtab(InstrProfSymtab &Symtab);\n  Error readNextHeader(const char *CurrentPos);\n  Error readHeader(const RawInstrProf::Header &Header);\n\n  template <class IntT> IntT swap(IntT Int) const {\n    return ShouldSwapBytes ? sys::getSwappedBytes(Int) : Int;\n  }\n\n  support::endianness getDataEndianness() const {\n    support::endianness HostEndian = getHostEndianness();\n    if (!ShouldSwapBytes)\n      return HostEndian;\n    if (HostEndian == support::little)\n      return support::big;\n    else\n      return support::little;\n  }\n\n  inline uint8_t getNumPaddingBytes(uint64_t SizeInBytes) {\n    return 7 & (sizeof(uint64_t) - SizeInBytes % sizeof(uint64_t));\n  }\n\n  Error readName(NamedInstrProfRecord &Record);\n  Error readFuncHash(NamedInstrProfRecord &Record);\n  Error readRawCounts(InstrProfRecord &Record);\n  Error readValueProfilingData(InstrProfRecord &Record);\n  bool atEnd() const { return Data == DataEnd; }\n\n  void advanceData() {\n    Data++;\n    ValueDataStart += CurValueDataSize;\n  }\n\n  const char *getNextHeaderPos() const {\n      assert(atEnd());\n      return (const char *)ValueDataStart;\n  }\n\n  /// Get the offset of \\p CounterPtr from the start of the counters section of\n  /// the profile. The offset has units of \"number of counters\", i.e. increasing\n  /// the offset by 1 corresponds to an increase in the *byte offset* by 8.\n  ptrdiff_t getCounterOffset(IntPtrT CounterPtr) const {\n    return (swap(CounterPtr) - CountersDelta) / sizeof(uint64_t);\n  }\n\n  const uint64_t *getCounter(ptrdiff_t Offset) const {\n    return CountersStart + Offset;\n  }\n\n  StringRef getName(uint64_t NameRef) const {\n    return Symtab->getFuncName(swap(NameRef));\n  }\n};\n\nusing RawInstrProfReader32 = RawInstrProfReader<uint32_t>;\nusing RawInstrProfReader64 = RawInstrProfReader<uint64_t>;\n\nnamespace IndexedInstrProf {\n\nenum class HashT : uint32_t;\n\n} // end namespace IndexedInstrProf\n\n/// Trait for lookups into the on-disk hash table for the binary instrprof\n/// format.\nclass InstrProfLookupTrait {\n  std::vector<NamedInstrProfRecord> DataBuffer;\n  IndexedInstrProf::HashT HashType;\n  unsigned FormatVersion;\n  // Endianness of the input value profile data.\n  // It should be LE by default, but can be changed\n  // for testing purpose.\n  support::endianness ValueProfDataEndianness = support::little;\n\npublic:\n  InstrProfLookupTrait(IndexedInstrProf::HashT HashType, unsigned FormatVersion)\n      : HashType(HashType), FormatVersion(FormatVersion) {}\n\n  using data_type = ArrayRef<NamedInstrProfRecord>;\n\n  using internal_key_type = StringRef;\n  using external_key_type = StringRef;\n  using hash_value_type = uint64_t;\n  using offset_type = uint64_t;\n\n  static bool EqualKey(StringRef A, StringRef B) { return A == B; }\n  static StringRef GetInternalKey(StringRef K) { return K; }\n  static StringRef GetExternalKey(StringRef K) { return K; }\n\n  hash_value_type ComputeHash(StringRef K);\n\n  static std::pair<offset_type, offset_type>\n  ReadKeyDataLength(const unsigned char *&D) {\n    using namespace support;\n\n    offset_type KeyLen = endian::readNext<offset_type, little, unaligned>(D);\n    offset_type DataLen = endian::readNext<offset_type, little, unaligned>(D);\n    return std::make_pair(KeyLen, DataLen);\n  }\n\n  StringRef ReadKey(const unsigned char *D, offset_type N) {\n    return StringRef((const char *)D, N);\n  }\n\n  bool readValueProfilingData(const unsigned char *&D,\n                              const unsigned char *const End);\n  data_type ReadData(StringRef K, const unsigned char *D, offset_type N);\n\n  // Used for testing purpose only.\n  void setValueProfDataEndianness(support::endianness Endianness) {\n    ValueProfDataEndianness = Endianness;\n  }\n};\n\nstruct InstrProfReaderIndexBase {\n  virtual ~InstrProfReaderIndexBase() = default;\n\n  // Read all the profile records with the same key pointed to the current\n  // iterator.\n  virtual Error getRecords(ArrayRef<NamedInstrProfRecord> &Data) = 0;\n\n  // Read all the profile records with the key equal to FuncName\n  virtual Error getRecords(StringRef FuncName,\n                                     ArrayRef<NamedInstrProfRecord> &Data) = 0;\n  virtual void advanceToNextKey() = 0;\n  virtual bool atEnd() const = 0;\n  virtual void setValueProfDataEndianness(support::endianness Endianness) = 0;\n  virtual uint64_t getVersion() const = 0;\n  virtual bool isIRLevelProfile() const = 0;\n  virtual bool hasCSIRLevelProfile() const = 0;\n  virtual bool instrEntryBBEnabled() const = 0;\n  virtual Error populateSymtab(InstrProfSymtab &) = 0;\n};\n\nusing OnDiskHashTableImplV3 =\n    OnDiskIterableChainedHashTable<InstrProfLookupTrait>;\n\ntemplate <typename HashTableImpl>\nclass InstrProfReaderItaniumRemapper;\n\ntemplate <typename HashTableImpl>\nclass InstrProfReaderIndex : public InstrProfReaderIndexBase {\nprivate:\n  std::unique_ptr<HashTableImpl> HashTable;\n  typename HashTableImpl::data_iterator RecordIterator;\n  uint64_t FormatVersion;\n\n  friend class InstrProfReaderItaniumRemapper<HashTableImpl>;\n\npublic:\n  InstrProfReaderIndex(const unsigned char *Buckets,\n                       const unsigned char *const Payload,\n                       const unsigned char *const Base,\n                       IndexedInstrProf::HashT HashType, uint64_t Version);\n  ~InstrProfReaderIndex() override = default;\n\n  Error getRecords(ArrayRef<NamedInstrProfRecord> &Data) override;\n  Error getRecords(StringRef FuncName,\n                   ArrayRef<NamedInstrProfRecord> &Data) override;\n  void advanceToNextKey() override { RecordIterator++; }\n\n  bool atEnd() const override {\n    return RecordIterator == HashTable->data_end();\n  }\n\n  void setValueProfDataEndianness(support::endianness Endianness) override {\n    HashTable->getInfoObj().setValueProfDataEndianness(Endianness);\n  }\n\n  uint64_t getVersion() const override { return GET_VERSION(FormatVersion); }\n\n  bool isIRLevelProfile() const override {\n    return (FormatVersion & VARIANT_MASK_IR_PROF) != 0;\n  }\n\n  bool hasCSIRLevelProfile() const override {\n    return (FormatVersion & VARIANT_MASK_CSIR_PROF) != 0;\n  }\n\n  bool instrEntryBBEnabled() const override {\n    return (FormatVersion & VARIANT_MASK_INSTR_ENTRY) != 0;\n  }\n\n  Error populateSymtab(InstrProfSymtab &Symtab) override {\n    return Symtab.create(HashTable->keys());\n  }\n};\n\n/// Name matcher supporting fuzzy matching of symbol names to names in profiles.\nclass InstrProfReaderRemapper {\npublic:\n  virtual ~InstrProfReaderRemapper() {}\n  virtual Error populateRemappings() { return Error::success(); }\n  virtual Error getRecords(StringRef FuncName,\n                           ArrayRef<NamedInstrProfRecord> &Data) = 0;\n};\n\n/// Reader for the indexed binary instrprof format.\nclass IndexedInstrProfReader : public InstrProfReader {\nprivate:\n  /// The profile data file contents.\n  std::unique_ptr<MemoryBuffer> DataBuffer;\n  /// The profile remapping file contents.\n  std::unique_ptr<MemoryBuffer> RemappingBuffer;\n  /// The index into the profile data.\n  std::unique_ptr<InstrProfReaderIndexBase> Index;\n  /// The profile remapping file contents.\n  std::unique_ptr<InstrProfReaderRemapper> Remapper;\n  /// Profile summary data.\n  std::unique_ptr<ProfileSummary> Summary;\n  /// Context sensitive profile summary data.\n  std::unique_ptr<ProfileSummary> CS_Summary;\n  // Index to the current record in the record array.\n  unsigned RecordIndex;\n\n  // Read the profile summary. Return a pointer pointing to one byte past the\n  // end of the summary data if it exists or the input \\c Cur.\n  // \\c UseCS indicates whether to use the context-sensitive profile summary.\n  const unsigned char *readSummary(IndexedInstrProf::ProfVersion Version,\n                                   const unsigned char *Cur, bool UseCS);\n\npublic:\n  IndexedInstrProfReader(\n      std::unique_ptr<MemoryBuffer> DataBuffer,\n      std::unique_ptr<MemoryBuffer> RemappingBuffer = nullptr)\n      : DataBuffer(std::move(DataBuffer)),\n        RemappingBuffer(std::move(RemappingBuffer)), RecordIndex(0) {}\n  IndexedInstrProfReader(const IndexedInstrProfReader &) = delete;\n  IndexedInstrProfReader &operator=(const IndexedInstrProfReader &) = delete;\n\n  /// Return the profile version.\n  uint64_t getVersion() const { return Index->getVersion(); }\n  bool isIRLevelProfile() const override { return Index->isIRLevelProfile(); }\n  bool hasCSIRLevelProfile() const override {\n    return Index->hasCSIRLevelProfile();\n  }\n\n  bool instrEntryBBEnabled() const override {\n    return Index->instrEntryBBEnabled();\n  }\n\n  /// Return true if the given buffer is in an indexed instrprof format.\n  static bool hasFormat(const MemoryBuffer &DataBuffer);\n\n  /// Read the file header.\n  Error readHeader() override;\n  /// Read a single record.\n  Error readNextRecord(NamedInstrProfRecord &Record) override;\n\n  /// Return the NamedInstrProfRecord associated with FuncName and FuncHash\n  Expected<InstrProfRecord> getInstrProfRecord(StringRef FuncName,\n                                               uint64_t FuncHash);\n\n  /// Fill Counts with the profile data for the given function name.\n  Error getFunctionCounts(StringRef FuncName, uint64_t FuncHash,\n                          std::vector<uint64_t> &Counts);\n\n  /// Return the maximum of all known function counts.\n  /// \\c UseCS indicates whether to use the context-sensitive count.\n  uint64_t getMaximumFunctionCount(bool UseCS) {\n    if (UseCS) {\n      assert(CS_Summary && \"No context sensitive profile summary\");\n      return CS_Summary->getMaxFunctionCount();\n    } else {\n      assert(Summary && \"No profile summary\");\n      return Summary->getMaxFunctionCount();\n    }\n  }\n\n  /// Factory method to create an indexed reader.\n  static Expected<std::unique_ptr<IndexedInstrProfReader>>\n  create(const Twine &Path, const Twine &RemappingPath = \"\");\n\n  static Expected<std::unique_ptr<IndexedInstrProfReader>>\n  create(std::unique_ptr<MemoryBuffer> Buffer,\n         std::unique_ptr<MemoryBuffer> RemappingBuffer = nullptr);\n\n  // Used for testing purpose only.\n  void setValueProfDataEndianness(support::endianness Endianness) {\n    Index->setValueProfDataEndianness(Endianness);\n  }\n\n  // See description in the base class. This interface is designed\n  // to be used by llvm-profdata (for dumping). Avoid using this when\n  // the client is the compiler.\n  InstrProfSymtab &getSymtab() override;\n\n  /// Return the profile summary.\n  /// \\c UseCS indicates whether to use the context-sensitive summary.\n  ProfileSummary &getSummary(bool UseCS) {\n    if (UseCS) {\n      assert(CS_Summary && \"No context sensitive summary\");\n      return *(CS_Summary.get());\n    } else {\n      assert(Summary && \"No profile summary\");\n      return *(Summary.get());\n    }\n  }\n};\n\n} // end namespace llvm\n\n#endif // LLVM_PROFILEDATA_INSTRPROFREADER_H\n"}, "66": {"id": 66, "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Support/LineIterator.h", "content": "//===- LineIterator.h - Iterator to read a text buffer's lines --*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_SUPPORT_LINEITERATOR_H\n#define LLVM_SUPPORT_LINEITERATOR_H\n\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/Support/DataTypes.h\"\n#include \"llvm/Support/MemoryBufferRef.h\"\n#include <iterator>\n\nnamespace llvm {\n\nclass MemoryBuffer;\n\n/// A forward iterator which reads text lines from a buffer.\n///\n/// This class provides a forward iterator interface for reading one line at\n/// a time from a buffer. When default constructed the iterator will be the\n/// \"end\" iterator.\n///\n/// The iterator is aware of what line number it is currently processing. It\n/// strips blank lines by default, and comment lines given a comment-starting\n/// character.\n///\n/// Note that this iterator requires the buffer to be nul terminated.\nclass line_iterator\n    : public std::iterator<std::forward_iterator_tag, StringRef> {\n  Optional<MemoryBufferRef> Buffer;\n  char CommentMarker = '\\0';\n  bool SkipBlanks = true;\n\n  unsigned LineNumber = 1;\n  StringRef CurrentLine;\n\npublic:\n  /// Default construct an \"end\" iterator.\n  line_iterator() = default;\n\n  /// Construct a new iterator around an unowned memory buffer.\n  explicit line_iterator(const MemoryBufferRef &Buffer, bool SkipBlanks = true,\n                         char CommentMarker = '\\0');\n\n  /// Construct a new iterator around some memory buffer.\n  explicit line_iterator(const MemoryBuffer &Buffer, bool SkipBlanks = true,\n                         char CommentMarker = '\\0');\n\n  /// Return true if we've reached EOF or are an \"end\" iterator.\n  bool is_at_eof() const { return !Buffer; }\n\n  /// Return true if we're an \"end\" iterator or have reached EOF.\n  bool is_at_end() const { return is_at_eof(); }\n\n  /// Return the current line number. May return any number at EOF.\n  int64_t line_number() const { return LineNumber; }\n\n  /// Advance to the next (non-empty, non-comment) line.\n  line_iterator &operator++() {\n    advance();\n    return *this;\n  }\n  line_iterator operator++(int) {\n    line_iterator tmp(*this);\n    advance();\n    return tmp;\n  }\n\n  /// Get the current line as a \\c StringRef.\n  StringRef operator*() const { return CurrentLine; }\n  const StringRef *operator->() const { return &CurrentLine; }\n\n  friend bool operator==(const line_iterator &LHS, const line_iterator &RHS) {\n    return LHS.Buffer == RHS.Buffer &&\n           LHS.CurrentLine.begin() == RHS.CurrentLine.begin();\n  }\n\n  friend bool operator!=(const line_iterator &LHS, const line_iterator &RHS) {\n    return !(LHS == RHS);\n  }\n\nprivate:\n  /// Advance the iterator to the next line.\n  void advance();\n};\n}\n\n#endif\n"}}, "reports": [{"events": [{"location": {"col": 10, "file": 2, "line": 21}, "message": "'clang/AST/DeclNodes.inc' file not found"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/ASTFwd.h", "reportHash": "33a05be8d240acdf8a352c94adf7b2fd", "checkerName": "clang-diagnostic-error", "reviewStatus": null, "severity": "CRITICAL"}, {"events": [{"location": {"col": 9, "file": 3, "line": 38}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/CharUnits.h", "reportHash": "1e11feebfd25fe8edc1efd5f56a32dbd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 4, "line": 26}, "message": "destructor '~CurrentSourceLocExprScope' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/CurrentSourceLocExprScope.h", "reportHash": "65619dc4a92e6362d7ca1969f17ae666", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 15, "line": 174}, "message": "destructor '~ItaniumMangleContext' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Mangle.h", "reportHash": "cc438642c025c0d2b35052a4ca9647b1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 15, "line": 206}, "message": "destructor '~MicrosoftMangleContext' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Mangle.h", "reportHash": "24147155733f6cd7350560f0051eb020", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 17, "line": 34}, "message": "default constructor 'PrintingCallbacks' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/PrettyPrinter.h", "reportHash": "fe5862bbc3abf7fc60a135b3d31bdcbd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 22, "line": 29}, "message": "destructor '~VTableComponent' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/VTableBuilder.h", "reportHash": "90696a897d053cf4c2f82c8cd661a5f3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 22, "line": 29}, "message": "move constructor 'VTableComponent' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/VTableBuilder.h", "reportHash": "baca413f42732ac4da5e52104fc0cb54", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 30, "line": 152}, "message": "default constructor 'SanitizerSet' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/Basic/Sanitizers.h", "reportHash": "0b377560fab0722e851685e62badcaa3", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 30, "line": 152}, "message": "destructor '~SanitizerSet' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/Basic/Sanitizers.h", "reportHash": "63a09877c4f4f299e1fa231859de0fab", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 30, "line": 152}, "message": "move constructor 'SanitizerSet' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/Basic/Sanitizers.h", "reportHash": "7349effbcf6e83d1f41f3c944bf87348", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 5, "file": 32, "line": 922}, "message": "default constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/Basic/TargetInfo.h", "reportHash": "1db2d6f427b6e32192db28559bff8e20", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 34, "line": 32}, "message": "destructor '~ABIArgInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "9d3cc13046244f5240efb78ae6d00c28", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 34, "line": 32}, "message": "move constructor 'ABIArgInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "84b4cdc1813f309887972463e7ae802c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 34, "line": 92}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "2b94d0e4edc5f8747d0b505cd3d82d8d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 34, "line": 92}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "d2663c955d695fd6529e167d4ba51e88", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 34, "line": 96}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "2b94d0e4edc5f8747d0b505cd3d82d8d", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 34, "line": 96}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "d2663c955d695fd6529e167d4ba51e88", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 34, "line": 461}, "message": "destructor '~RequiredArgs' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "8fa6f86cefaec2ca71d156b8cba12586", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 34, "line": 461}, "message": "move constructor 'RequiredArgs' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "d8f35eee6177596c28adf86f045af701", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 11, "file": 34, "line": 485}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "e93984f851a7c2ffdc84bb3e54da8347", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 35, "line": 129}, "message": "destructor '~SwiftABIInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/ABIInfo.h", "reportHash": "eff2a341a751284c6f7451121cfcd25a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 36, "line": 25}, "message": "destructor '~CGBuilderInserter' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGBuilder.h", "reportHash": "7b35404f4682fb9f529112454c30231b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 37, "line": 67}, "message": "move constructor 'CGCallee' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "reportHash": "f0048b24f751d88d45afccac4183b073", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 37, "line": 362}, "message": "move constructor 'ReturnValueSlot' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "reportHash": "abda98a5fcdaea41ddfe89b84f4feac5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 38, "line": 25}, "message": "destructor '~CGOpenMPRuntimeAMDGCN' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeAMDGCN.h", "reportHash": "53983c0e4a5412a7db0dddf67d4e5ef5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 39, "line": 243}, "message": "destructor '~JumpDest' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "06cd797e4e63fa901b0abb386903832e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 39, "line": 243}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "61c20b348efca25b47391e2aeaf0eabd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 39, "line": 243}, "message": "move constructor 'JumpDest' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "1710807c708d226080b9018009d5b2cd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 458}, "message": "destructor '~AbstractCallee' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "8da35bab176f71987469e321cc6d43cd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 458}, "message": "move constructor 'AbstractCallee' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "c6bba73bc09c0ebe31a77fd46ff72830", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 1182}, "message": "destructor '~PeepholeProtection' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "51e12c0be642367b34668935dbc0fd06", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 1182}, "message": "move constructor 'PeepholeProtection' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "fa03f61dd9bfedd8b0d027835ed0a009", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 1196}, "message": "move constructor 'OpaqueValueMappingData' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "52f667df97c1ceb513f3c49028dc2139", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 2974}, "message": "move constructor 'AutoVarEmission' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "a7542973e3975dd0cb801f912eb5e100", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 12, "file": 39, "line": 3002}, "message": "default constructor 'Invalid' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "2d361cbf95b178e318011cbc77e89d26", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 12, "file": 39, "line": 3002}, "message": "destructor '~Invalid' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "93c7d311337fd85244d4b86fe9e8fc2b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 12, "file": 39, "line": 3002}, "message": "move constructor 'Invalid' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "cd263e2fbdd041ccf7b0123e82f28273", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 3062}, "message": "destructor '~ParamValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "abd946590ca824075fd61c9108b01492", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 3062}, "message": "move constructor 'ParamValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "152ca5c8b0d7fe69fe4997746425182f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 39, "line": 3843}, "message": "move constructor 'ConstantEmission' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "57e2b904be1df69d3e6d603fc3259be7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 39, "line": 4729}, "message": "destructor '~FeatureListStatus' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "c288e2f0300d8885d3a78b2a46dee931", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 39, "line": 4729}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "bae624492af6de65f1f76a73dd5cc204", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 40, "line": 36}, "message": "default constructor 'BranchFixup' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/EHScopeStack.h", "reportHash": "81d4c2052719f6a335792b2953c48b89", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 40, "line": 36}, "message": "destructor '~BranchFixup' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/EHScopeStack.h", "reportHash": "704ba53450e4e86a1596004b2849856e", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 40, "line": 101}, "message": "destructor '~stable_iterator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/EHScopeStack.h", "reportHash": "48cf8430468ba110b226658de551f651", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 40, "line": 101}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/EHScopeStack.h", "reportHash": "a1a8b1a991e8907db1f1b67b555802be", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 40, "line": 101}, "message": "move constructor 'stable_iterator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/EHScopeStack.h", "reportHash": "1f8d8a9455c796f0ca779ae379a6acf8", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 50, "line": 1270}, "message": "default constructor 'less_first' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ADT/STLExtras.h", "reportHash": "57cc5a3a206c061b2907257ece990be5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 50, "line": 1270}, "message": "destructor '~less_first' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ADT/STLExtras.h", "reportHash": "fc3797602175212c1d67263050494e2a", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 54, "line": 63}, "message": "default constructor 'IRBuilderDefaultInserter' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IRBuilder.h", "reportHash": "42f804f2bcdf06f2bc1b0b812bb4b3b7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 54, "line": 251}, "message": "move constructor 'InsertPoint' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/IR/IRBuilder.h", "reportHash": "0dc5ab10d95dc9661e2647a3e436d42b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 35, "file": 59, "line": 327}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ProfileData/InstrProf.h", "reportHash": "b46fa13d9ed59ec9ab48d28ac0cb8758", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 60, "line": 41}, "message": "move constructor 'InstrProfIterator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/ProfileData/InstrProfReader.h", "reportHash": "5e00129f4950de30ad04dd98d9f38298", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 66, "line": 33}, "message": "move constructor 'line_iterator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/llvm/include/llvm/Support/LineIterator.h", "reportHash": "c9d7921638ec82716eb203208cafd6d5", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
