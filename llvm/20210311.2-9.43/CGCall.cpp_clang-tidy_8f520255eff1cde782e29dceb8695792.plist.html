<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"21": {"id": 21, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Type.h", "content": "//===- Type.h - C Language Family Type Representation -----------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// C Language Family Type Representation\n///\n/// This file defines the clang::Type interface and subclasses, used to\n/// represent types for languages in the C family.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_TYPE_H\n#define LLVM_CLANG_AST_TYPE_H\n\n#include \"clang/AST/DependenceFlags.h\"\n#include \"clang/AST/NestedNameSpecifier.h\"\n#include \"clang/AST/TemplateName.h\"\n#include \"clang/Basic/AddressSpaces.h\"\n#include \"clang/Basic/AttrKinds.h\"\n#include \"clang/Basic/Diagnostic.h\"\n#include \"clang/Basic/ExceptionSpecificationType.h\"\n#include \"clang/Basic/LLVM.h\"\n#include \"clang/Basic/Linkage.h\"\n#include \"clang/Basic/PartialDiagnostic.h\"\n#include \"clang/Basic/SourceLocation.h\"\n#include \"clang/Basic/Specifiers.h\"\n#include \"clang/Basic/Visibility.h\"\n#include \"llvm/ADT/APInt.h\"\n#include \"llvm/ADT/APSInt.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/PointerUnion.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/Twine.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/Compiler.h\"\n#include \"llvm/Support/ErrorHandling.h\"\n#include \"llvm/Support/PointerLikeTypeTraits.h\"\n#include \"llvm/Support/TrailingObjects.h\"\n#include \"llvm/Support/type_traits.h\"\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <cstring>\n#include <string>\n#include <type_traits>\n#include <utility>\n\nnamespace clang {\n\nclass ExtQuals;\nclass QualType;\nclass ConceptDecl;\nclass TagDecl;\nclass TemplateParameterList;\nclass Type;\n\nenum {\n  TypeAlignmentInBits = 4,\n  TypeAlignment = 1 << TypeAlignmentInBits\n};\n\nnamespace serialization {\n  template <class T> class AbstractTypeReader;\n  template <class T> class AbstractTypeWriter;\n}\n\n} // namespace clang\n\nnamespace llvm {\n\n  template <typename T>\n  struct PointerLikeTypeTraits;\n  template<>\n  struct PointerLikeTypeTraits< ::clang::Type*> {\n    static inline void *getAsVoidPointer(::clang::Type *P) { return P; }\n\n    static inline ::clang::Type *getFromVoidPointer(void *P) {\n      return static_cast< ::clang::Type*>(P);\n    }\n\n    static constexpr int NumLowBitsAvailable = clang::TypeAlignmentInBits;\n  };\n\n  template<>\n  struct PointerLikeTypeTraits< ::clang::ExtQuals*> {\n    static inline void *getAsVoidPointer(::clang::ExtQuals *P) { return P; }\n\n    static inline ::clang::ExtQuals *getFromVoidPointer(void *P) {\n      return static_cast< ::clang::ExtQuals*>(P);\n    }\n\n    static constexpr int NumLowBitsAvailable = clang::TypeAlignmentInBits;\n  };\n\n} // namespace llvm\n\nnamespace clang {\n\nclass ASTContext;\ntemplate <typename> class CanQual;\nclass CXXRecordDecl;\nclass DeclContext;\nclass EnumDecl;\nclass Expr;\nclass ExtQualsTypeCommonBase;\nclass FunctionDecl;\nclass IdentifierInfo;\nclass NamedDecl;\nclass ObjCInterfaceDecl;\nclass ObjCProtocolDecl;\nclass ObjCTypeParamDecl;\nstruct PrintingPolicy;\nclass RecordDecl;\nclass Stmt;\nclass TagDecl;\nclass TemplateArgument;\nclass TemplateArgumentListInfo;\nclass TemplateArgumentLoc;\nclass TemplateTypeParmDecl;\nclass TypedefNameDecl;\nclass UnresolvedUsingTypenameDecl;\n\nusing CanQualType = CanQual<Type>;\n\n// Provide forward declarations for all of the *Type classes.\n#define TYPE(Class, Base) class Class##Type;\n#include \"clang/AST/TypeNodes.inc\"\n\n/// The collection of all-type qualifiers we support.\n/// Clang supports five independent qualifiers:\n/// * C99: const, volatile, and restrict\n/// * MS: __unaligned\n/// * Embedded C (TR18037): address spaces\n/// * Objective C: the GC attributes (none, weak, or strong)\nclass Qualifiers {\npublic:\n  enum TQ { // NOTE: These flags must be kept in sync with DeclSpec::TQ.\n    Const    = 0x1,\n    Restrict = 0x2,\n    Volatile = 0x4,\n    CVRMask = Const | Volatile | Restrict\n  };\n\n  enum GC {\n    GCNone = 0,\n    Weak,\n    Strong\n  };\n\n  enum ObjCLifetime {\n    /// There is no lifetime qualification on this type.\n    OCL_None,\n\n    /// This object can be modified without requiring retains or\n    /// releases.\n    OCL_ExplicitNone,\n\n    /// Assigning into this object requires the old value to be\n    /// released and the new value to be retained.  The timing of the\n    /// release of the old value is inexact: it may be moved to\n    /// immediately after the last known point where the value is\n    /// live.\n    OCL_Strong,\n\n    /// Reading or writing from this object requires a barrier call.\n    OCL_Weak,\n\n    /// Assigning into this object requires a lifetime extension.\n    OCL_Autoreleasing\n  };\n\n  enum {\n    /// The maximum supported address space number.\n    /// 23 bits should be enough for anyone.\n    MaxAddressSpace = 0x7fffffu,\n\n    /// The width of the \"fast\" qualifier mask.\n    FastWidth = 3,\n\n    /// The fast qualifier mask.\n    FastMask = (1 << FastWidth) - 1\n  };\n\n  /// Returns the common set of qualifiers while removing them from\n  /// the given sets.\n  static Qualifiers removeCommonQualifiers(Qualifiers &L, Qualifiers &R) {\n    // If both are only CVR-qualified, bit operations are sufficient.\n    if (!(L.Mask & ~CVRMask) && !(R.Mask & ~CVRMask)) {\n      Qualifiers Q;\n      Q.Mask = L.Mask & R.Mask;\n      L.Mask &= ~Q.Mask;\n      R.Mask &= ~Q.Mask;\n      return Q;\n    }\n\n    Qualifiers Q;\n    unsigned CommonCRV = L.getCVRQualifiers() & R.getCVRQualifiers();\n    Q.addCVRQualifiers(CommonCRV);\n    L.removeCVRQualifiers(CommonCRV);\n    R.removeCVRQualifiers(CommonCRV);\n\n    if (L.getObjCGCAttr() == R.getObjCGCAttr()) {\n      Q.setObjCGCAttr(L.getObjCGCAttr());\n      L.removeObjCGCAttr();\n      R.removeObjCGCAttr();\n    }\n\n    if (L.getObjCLifetime() == R.getObjCLifetime()) {\n      Q.setObjCLifetime(L.getObjCLifetime());\n      L.removeObjCLifetime();\n      R.removeObjCLifetime();\n    }\n\n    if (L.getAddressSpace() == R.getAddressSpace()) {\n      Q.setAddressSpace(L.getAddressSpace());\n      L.removeAddressSpace();\n      R.removeAddressSpace();\n    }\n    return Q;\n  }\n\n  static Qualifiers fromFastMask(unsigned Mask) {\n    Qualifiers Qs;\n    Qs.addFastQualifiers(Mask);\n    return Qs;\n  }\n\n  static Qualifiers fromCVRMask(unsigned CVR) {\n    Qualifiers Qs;\n    Qs.addCVRQualifiers(CVR);\n    return Qs;\n  }\n\n  static Qualifiers fromCVRUMask(unsigned CVRU) {\n    Qualifiers Qs;\n    Qs.addCVRUQualifiers(CVRU);\n    return Qs;\n  }\n\n  // Deserialize qualifiers from an opaque representation.\n  static Qualifiers fromOpaqueValue(unsigned opaque) {\n    Qualifiers Qs;\n    Qs.Mask = opaque;\n    return Qs;\n  }\n\n  // Serialize these qualifiers into an opaque representation.\n  unsigned getAsOpaqueValue() const {\n    return Mask;\n  }\n\n  bool hasConst() const { return Mask & Const; }\n  bool hasOnlyConst() const { return Mask == Const; }\n  void removeConst() { Mask &= ~Const; }\n  void addConst() { Mask |= Const; }\n\n  bool hasVolatile() const { return Mask & Volatile; }\n  bool hasOnlyVolatile() const { return Mask == Volatile; }\n  void removeVolatile() { Mask &= ~Volatile; }\n  void addVolatile() { Mask |= Volatile; }\n\n  bool hasRestrict() const { return Mask & Restrict; }\n  bool hasOnlyRestrict() const { return Mask == Restrict; }\n  void removeRestrict() { Mask &= ~Restrict; }\n  void addRestrict() { Mask |= Restrict; }\n\n  bool hasCVRQualifiers() const { return getCVRQualifiers(); }\n  unsigned getCVRQualifiers() const { return Mask & CVRMask; }\n  unsigned getCVRUQualifiers() const { return Mask & (CVRMask | UMask); }\n\n  void setCVRQualifiers(unsigned mask) {\n    assert(!(mask & ~CVRMask) && \"bitmask contains non-CVR bits\");\n    Mask = (Mask & ~CVRMask) | mask;\n  }\n  void removeCVRQualifiers(unsigned mask) {\n    assert(!(mask & ~CVRMask) && \"bitmask contains non-CVR bits\");\n    Mask &= ~mask;\n  }\n  void removeCVRQualifiers() {\n    removeCVRQualifiers(CVRMask);\n  }\n  void addCVRQualifiers(unsigned mask) {\n    assert(!(mask & ~CVRMask) && \"bitmask contains non-CVR bits\");\n    Mask |= mask;\n  }\n  void addCVRUQualifiers(unsigned mask) {\n    assert(!(mask & ~CVRMask & ~UMask) && \"bitmask contains non-CVRU bits\");\n    Mask |= mask;\n  }\n\n  bool hasUnaligned() const { return Mask & UMask; }\n  void setUnaligned(bool flag) {\n    Mask = (Mask & ~UMask) | (flag ? UMask : 0);\n  }\n  void removeUnaligned() { Mask &= ~UMask; }\n  void addUnaligned() { Mask |= UMask; }\n\n  bool hasObjCGCAttr() const { return Mask & GCAttrMask; }\n  GC getObjCGCAttr() const { return GC((Mask & GCAttrMask) >> GCAttrShift); }\n  void setObjCGCAttr(GC type) {\n    Mask = (Mask & ~GCAttrMask) | (type << GCAttrShift);\n  }\n  void removeObjCGCAttr() { setObjCGCAttr(GCNone); }\n  void addObjCGCAttr(GC type) {\n    assert(type);\n    setObjCGCAttr(type);\n  }\n  Qualifiers withoutObjCGCAttr() const {\n    Qualifiers qs = *this;\n    qs.removeObjCGCAttr();\n    return qs;\n  }\n  Qualifiers withoutObjCLifetime() const {\n    Qualifiers qs = *this;\n    qs.removeObjCLifetime();\n    return qs;\n  }\n  Qualifiers withoutAddressSpace() const {\n    Qualifiers qs = *this;\n    qs.removeAddressSpace();\n    return qs;\n  }\n\n  bool hasObjCLifetime() const { return Mask & LifetimeMask; }\n  ObjCLifetime getObjCLifetime() const {\n    return ObjCLifetime((Mask & LifetimeMask) >> LifetimeShift);\n  }\n  void setObjCLifetime(ObjCLifetime type) {\n    Mask = (Mask & ~LifetimeMask) | (type << LifetimeShift);\n  }\n  void removeObjCLifetime() { setObjCLifetime(OCL_None); }\n  void addObjCLifetime(ObjCLifetime type) {\n    assert(type);\n    assert(!hasObjCLifetime());\n    Mask |= (type << LifetimeShift);\n  }\n\n  /// True if the lifetime is neither None or ExplicitNone.\n  bool hasNonTrivialObjCLifetime() const {\n    ObjCLifetime lifetime = getObjCLifetime();\n    return (lifetime > OCL_ExplicitNone);\n  }\n\n  /// True if the lifetime is either strong or weak.\n  bool hasStrongOrWeakObjCLifetime() const {\n    ObjCLifetime lifetime = getObjCLifetime();\n    return (lifetime == OCL_Strong || lifetime == OCL_Weak);\n  }\n\n  bool hasAddressSpace() const { return Mask & AddressSpaceMask; }\n  LangAS getAddressSpace() const {\n    return static_cast<LangAS>(Mask >> AddressSpaceShift);\n  }\n  bool hasTargetSpecificAddressSpace() const {\n    return isTargetAddressSpace(getAddressSpace());\n  }\n  /// Get the address space attribute value to be printed by diagnostics.\n  unsigned getAddressSpaceAttributePrintValue() const {\n    auto Addr = getAddressSpace();\n    // This function is not supposed to be used with language specific\n    // address spaces. If that happens, the diagnostic message should consider\n    // printing the QualType instead of the address space value.\n    assert(Addr == LangAS::Default || hasTargetSpecificAddressSpace());\n    if (Addr != LangAS::Default)\n      return toTargetAddressSpace(Addr);\n    // TODO: The diagnostic messages where Addr may be 0 should be fixed\n    // since it cannot differentiate the situation where 0 denotes the default\n    // address space or user specified __attribute__((address_space(0))).\n    return 0;\n  }\n  void setAddressSpace(LangAS space) {\n    assert((unsigned)space <= MaxAddressSpace);\n    Mask = (Mask & ~AddressSpaceMask)\n         | (((uint32_t) space) << AddressSpaceShift);\n  }\n  void removeAddressSpace() { setAddressSpace(LangAS::Default); }\n  void addAddressSpace(LangAS space) {\n    assert(space != LangAS::Default);\n    setAddressSpace(space);\n  }\n\n  // Fast qualifiers are those that can be allocated directly\n  // on a QualType object.\n  bool hasFastQualifiers() const { return getFastQualifiers(); }\n  unsigned getFastQualifiers() const { return Mask & FastMask; }\n  void setFastQualifiers(unsigned mask) {\n    assert(!(mask & ~FastMask) && \"bitmask contains non-fast qualifier bits\");\n    Mask = (Mask & ~FastMask) | mask;\n  }\n  void removeFastQualifiers(unsigned mask) {\n    assert(!(mask & ~FastMask) && \"bitmask contains non-fast qualifier bits\");\n    Mask &= ~mask;\n  }\n  void removeFastQualifiers() {\n    removeFastQualifiers(FastMask);\n  }\n  void addFastQualifiers(unsigned mask) {\n    assert(!(mask & ~FastMask) && \"bitmask contains non-fast qualifier bits\");\n    Mask |= mask;\n  }\n\n  /// Return true if the set contains any qualifiers which require an ExtQuals\n  /// node to be allocated.\n  bool hasNonFastQualifiers() const { return Mask & ~FastMask; }\n  Qualifiers getNonFastQualifiers() const {\n    Qualifiers Quals = *this;\n    Quals.setFastQualifiers(0);\n    return Quals;\n  }\n\n  /// Return true if the set contains any qualifiers.\n  bool hasQualifiers() const { return Mask; }\n  bool empty() const { return !Mask; }\n\n  /// Add the qualifiers from the given set to this set.\n  void addQualifiers(Qualifiers Q) {\n    // If the other set doesn't have any non-boolean qualifiers, just\n    // bit-or it in.\n    if (!(Q.Mask & ~CVRMask))\n      Mask |= Q.Mask;\n    else {\n      Mask |= (Q.Mask & CVRMask);\n      if (Q.hasAddressSpace())\n        addAddressSpace(Q.getAddressSpace());\n      if (Q.hasObjCGCAttr())\n        addObjCGCAttr(Q.getObjCGCAttr());\n      if (Q.hasObjCLifetime())\n        addObjCLifetime(Q.getObjCLifetime());\n    }\n  }\n\n  /// Remove the qualifiers from the given set from this set.\n  void removeQualifiers(Qualifiers Q) {\n    // If the other set doesn't have any non-boolean qualifiers, just\n    // bit-and the inverse in.\n    if (!(Q.Mask & ~CVRMask))\n      Mask &= ~Q.Mask;\n    else {\n      Mask &= ~(Q.Mask & CVRMask);\n      if (getObjCGCAttr() == Q.getObjCGCAttr())\n        removeObjCGCAttr();\n      if (getObjCLifetime() == Q.getObjCLifetime())\n        removeObjCLifetime();\n      if (getAddressSpace() == Q.getAddressSpace())\n        removeAddressSpace();\n    }\n  }\n\n  /// Add the qualifiers from the given set to this set, given that\n  /// they don't conflict.\n  void addConsistentQualifiers(Qualifiers qs) {\n    assert(getAddressSpace() == qs.getAddressSpace() ||\n           !hasAddressSpace() || !qs.hasAddressSpace());\n    assert(getObjCGCAttr() == qs.getObjCGCAttr() ||\n           !hasObjCGCAttr() || !qs.hasObjCGCAttr());\n    assert(getObjCLifetime() == qs.getObjCLifetime() ||\n           !hasObjCLifetime() || !qs.hasObjCLifetime());\n    Mask |= qs.Mask;\n  }\n\n  /// Returns true if address space A is equal to or a superset of B.\n  /// OpenCL v2.0 defines conversion rules (OpenCLC v2.0 s6.5.5) and notion of\n  /// overlapping address spaces.\n  /// CL1.1 or CL1.2:\n  ///   every address space is a superset of itself.\n  /// CL2.0 adds:\n  ///   __generic is a superset of any address space except for __constant.\n  static bool isAddressSpaceSupersetOf(LangAS A, LangAS B) {\n    // Address spaces must match exactly.\n    return A == B ||\n           // Otherwise in OpenCLC v2.0 s6.5.5: every address space except\n           // for __constant can be used as __generic.\n           (A == LangAS::opencl_generic && B != LangAS::opencl_constant) ||\n           // We also define global_device and global_host address spaces,\n           // to distinguish global pointers allocated on host from pointers\n           // allocated on device, which are a subset of __global.\n           (A == LangAS::opencl_global && (B == LangAS::opencl_global_device ||\n                                           B == LangAS::opencl_global_host)) ||\n           // Consider pointer size address spaces to be equivalent to default.\n           ((isPtrSizeAddressSpace(A) || A == LangAS::Default) &&\n            (isPtrSizeAddressSpace(B) || B == LangAS::Default));\n  }\n\n  /// Returns true if the address space in these qualifiers is equal to or\n  /// a superset of the address space in the argument qualifiers.\n  bool isAddressSpaceSupersetOf(Qualifiers other) const {\n    return isAddressSpaceSupersetOf(getAddressSpace(), other.getAddressSpace());\n  }\n\n  /// Determines if these qualifiers compatibly include another set.\n  /// Generally this answers the question of whether an object with the other\n  /// qualifiers can be safely used as an object with these qualifiers.\n  bool compatiblyIncludes(Qualifiers other) const {\n    return isAddressSpaceSupersetOf(other) &&\n           // ObjC GC qualifiers can match, be added, or be removed, but can't\n           // be changed.\n           (getObjCGCAttr() == other.getObjCGCAttr() || !hasObjCGCAttr() ||\n            !other.hasObjCGCAttr()) &&\n           // ObjC lifetime qualifiers must match exactly.\n           getObjCLifetime() == other.getObjCLifetime() &&\n           // CVR qualifiers may subset.\n           (((Mask & CVRMask) | (other.Mask & CVRMask)) == (Mask & CVRMask)) &&\n           // U qualifier may superset.\n           (!other.hasUnaligned() || hasUnaligned());\n  }\n\n  /// Determines if these qualifiers compatibly include another set of\n  /// qualifiers from the narrow perspective of Objective-C ARC lifetime.\n  ///\n  /// One set of Objective-C lifetime qualifiers compatibly includes the other\n  /// if the lifetime qualifiers match, or if both are non-__weak and the\n  /// including set also contains the 'const' qualifier, or both are non-__weak\n  /// and one is None (which can only happen in non-ARC modes).\n  bool compatiblyIncludesObjCLifetime(Qualifiers other) const {\n    if (getObjCLifetime() == other.getObjCLifetime())\n      return true;\n\n    if (getObjCLifetime() == OCL_Weak || other.getObjCLifetime() == OCL_Weak)\n      return false;\n\n    if (getObjCLifetime() == OCL_None || other.getObjCLifetime() == OCL_None)\n      return true;\n\n    return hasConst();\n  }\n\n  /// Determine whether this set of qualifiers is a strict superset of\n  /// another set of qualifiers, not considering qualifier compatibility.\n  bool isStrictSupersetOf(Qualifiers Other) const;\n\n  bool operator==(Qualifiers Other) const { return Mask == Other.Mask; }\n  bool operator!=(Qualifiers Other) const { return Mask != Other.Mask; }\n\n  explicit operator bool() const { return hasQualifiers(); }\n\n  Qualifiers &operator+=(Qualifiers R) {\n    addQualifiers(R);\n    return *this;\n  }\n\n  // Union two qualifier sets.  If an enumerated qualifier appears\n  // in both sets, use the one from the right.\n  friend Qualifiers operator+(Qualifiers L, Qualifiers R) {\n    L += R;\n    return L;\n  }\n\n  Qualifiers &operator-=(Qualifiers R) {\n    removeQualifiers(R);\n    return *this;\n  }\n\n  /// Compute the difference between two qualifier sets.\n  friend Qualifiers operator-(Qualifiers L, Qualifiers R) {\n    L -= R;\n    return L;\n  }\n\n  std::string getAsString() const;\n  std::string getAsString(const PrintingPolicy &Policy) const;\n\n  static std::string getAddrSpaceAsString(LangAS AS);\n\n  bool isEmptyWhenPrinted(const PrintingPolicy &Policy) const;\n  void print(raw_ostream &OS, const PrintingPolicy &Policy,\n             bool appendSpaceIfNonEmpty = false) const;\n\n  void Profile(llvm::FoldingSetNodeID &ID) const {\n    ID.AddInteger(Mask);\n  }\n\nprivate:\n  // bits:     |0 1 2|3|4 .. 5|6  ..  8|9   ...   31|\n  //           |C R V|U|GCAttr|Lifetime|AddressSpace|\n  uint32_t Mask = 0;\n\n  static const uint32_t UMask = 0x8;\n  static const uint32_t UShift = 3;\n  static const uint32_t GCAttrMask = 0x30;\n  static const uint32_t GCAttrShift = 4;\n  static const uint32_t LifetimeMask = 0x1C0;\n  static const uint32_t LifetimeShift = 6;\n  static const uint32_t AddressSpaceMask =\n      ~(CVRMask | UMask | GCAttrMask | LifetimeMask);\n  static const uint32_t AddressSpaceShift = 9;\n};\n\n/// A std::pair-like structure for storing a qualified type split\n/// into its local qualifiers and its locally-unqualified type.\nstruct SplitQualType {\n  /// The locally-unqualified type.\n  const Type *Ty = nullptr;\n\n  /// The local qualifiers.\n  Qualifiers Quals;\n\n  SplitQualType() = default;\n  SplitQualType(const Type *ty, Qualifiers qs) : Ty(ty), Quals(qs) {}\n\n  SplitQualType getSingleStepDesugaredType() const; // end of this file\n\n  // Make std::tie work.\n  std::pair<const Type *,Qualifiers> asPair() const {\n    return std::pair<const Type *, Qualifiers>(Ty, Quals);\n  }\n\n  friend bool operator==(SplitQualType a, SplitQualType b) {\n    return a.Ty == b.Ty && a.Quals == b.Quals;\n  }\n  friend bool operator!=(SplitQualType a, SplitQualType b) {\n    return a.Ty != b.Ty || a.Quals != b.Quals;\n  }\n};\n\n/// The kind of type we are substituting Objective-C type arguments into.\n///\n/// The kind of substitution affects the replacement of type parameters when\n/// no concrete type information is provided, e.g., when dealing with an\n/// unspecialized type.\nenum class ObjCSubstitutionContext {\n  /// An ordinary type.\n  Ordinary,\n\n  /// The result type of a method or function.\n  Result,\n\n  /// The parameter type of a method or function.\n  Parameter,\n\n  /// The type of a property.\n  Property,\n\n  /// The superclass of a type.\n  Superclass,\n};\n\n/// A (possibly-)qualified type.\n///\n/// For efficiency, we don't store CV-qualified types as nodes on their\n/// own: instead each reference to a type stores the qualifiers.  This\n/// greatly reduces the number of nodes we need to allocate for types (for\n/// example we only need one for 'int', 'const int', 'volatile int',\n/// 'const volatile int', etc).\n///\n/// As an added efficiency bonus, instead of making this a pair, we\n/// just store the two bits we care about in the low bits of the\n/// pointer.  To handle the packing/unpacking, we make QualType be a\n/// simple wrapper class that acts like a smart pointer.  A third bit\n/// indicates whether there are extended qualifiers present, in which\n/// case the pointer points to a special structure.\nclass QualType {\n  friend class QualifierCollector;\n\n  // Thankfully, these are efficiently composable.\n  llvm::PointerIntPair<llvm::PointerUnion<const Type *, const ExtQuals *>,\n                       Qualifiers::FastWidth> Value;\n\n  const ExtQuals *getExtQualsUnsafe() const {\n    return Value.getPointer().get<const ExtQuals*>();\n  }\n\n  const Type *getTypePtrUnsafe() const {\n    return Value.getPointer().get<const Type*>();\n  }\n\n  const ExtQualsTypeCommonBase *getCommonPtr() const {\n    assert(!isNull() && \"Cannot retrieve a NULL type pointer\");\n    auto CommonPtrVal = reinterpret_cast<uintptr_t>(Value.getOpaqueValue());\n    CommonPtrVal &= ~(uintptr_t)((1 << TypeAlignmentInBits) - 1);\n    return reinterpret_cast<ExtQualsTypeCommonBase*>(CommonPtrVal);\n  }\n\npublic:\n  QualType() = default;\n  QualType(const Type *Ptr, unsigned Quals) : Value(Ptr, Quals) {}\n  QualType(const ExtQuals *Ptr, unsigned Quals) : Value(Ptr, Quals) {}\n\n  unsigned getLocalFastQualifiers() const { return Value.getInt(); }\n  void setLocalFastQualifiers(unsigned Quals) { Value.setInt(Quals); }\n\n  /// Retrieves a pointer to the underlying (unqualified) type.\n  ///\n  /// This function requires that the type not be NULL. If the type might be\n  /// NULL, use the (slightly less efficient) \\c getTypePtrOrNull().\n  const Type *getTypePtr() const;\n\n  const Type *getTypePtrOrNull() const;\n\n  /// Retrieves a pointer to the name of the base type.\n  const IdentifierInfo *getBaseTypeIdentifier() const;\n\n  /// Divides a QualType into its unqualified type and a set of local\n  /// qualifiers.\n  SplitQualType split() const;\n\n  void *getAsOpaquePtr() const { return Value.getOpaqueValue(); }\n\n  static QualType getFromOpaquePtr(const void *Ptr) {\n    QualType T;\n    T.Value.setFromOpaqueValue(const_cast<void*>(Ptr));\n    return T;\n  }\n\n  const Type &operator*() const {\n    return *getTypePtr();\n  }\n\n  const Type *operator->() const {\n    return getTypePtr();\n  }\n\n  bool isCanonical() const;\n  bool isCanonicalAsParam() const;\n\n  /// Return true if this QualType doesn't point to a type yet.\n  bool isNull() const {\n    return Value.getPointer().isNull();\n  }\n\n  /// Determine whether this particular QualType instance has the\n  /// \"const\" qualifier set, without looking through typedefs that may have\n  /// added \"const\" at a different level.\n  bool isLocalConstQualified() const {\n    return (getLocalFastQualifiers() & Qualifiers::Const);\n  }\n\n  /// Determine whether this type is const-qualified.\n  bool isConstQualified() const;\n\n  /// Determine whether this particular QualType instance has the\n  /// \"restrict\" qualifier set, without looking through typedefs that may have\n  /// added \"restrict\" at a different level.\n  bool isLocalRestrictQualified() const {\n    return (getLocalFastQualifiers() & Qualifiers::Restrict);\n  }\n\n  /// Determine whether this type is restrict-qualified.\n  bool isRestrictQualified() const;\n\n  /// Determine whether this particular QualType instance has the\n  /// \"volatile\" qualifier set, without looking through typedefs that may have\n  /// added \"volatile\" at a different level.\n  bool isLocalVolatileQualified() const {\n    return (getLocalFastQualifiers() & Qualifiers::Volatile);\n  }\n\n  /// Determine whether this type is volatile-qualified.\n  bool isVolatileQualified() const;\n\n  /// Determine whether this particular QualType instance has any\n  /// qualifiers, without looking through any typedefs that might add\n  /// qualifiers at a different level.\n  bool hasLocalQualifiers() const {\n    return getLocalFastQualifiers() || hasLocalNonFastQualifiers();\n  }\n\n  /// Determine whether this type has any qualifiers.\n  bool hasQualifiers() const;\n\n  /// Determine whether this particular QualType instance has any\n  /// \"non-fast\" qualifiers, e.g., those that are stored in an ExtQualType\n  /// instance.\n  bool hasLocalNonFastQualifiers() const {\n    return Value.getPointer().is<const ExtQuals*>();\n  }\n\n  /// Retrieve the set of qualifiers local to this particular QualType\n  /// instance, not including any qualifiers acquired through typedefs or\n  /// other sugar.\n  Qualifiers getLocalQualifiers() const;\n\n  /// Retrieve the set of qualifiers applied to this type.\n  Qualifiers getQualifiers() const;\n\n  /// Retrieve the set of CVR (const-volatile-restrict) qualifiers\n  /// local to this particular QualType instance, not including any qualifiers\n  /// acquired through typedefs or other sugar.\n  unsigned getLocalCVRQualifiers() const {\n    return getLocalFastQualifiers();\n  }\n\n  /// Retrieve the set of CVR (const-volatile-restrict) qualifiers\n  /// applied to this type.\n  unsigned getCVRQualifiers() const;\n\n  bool isConstant(const ASTContext& Ctx) const {\n    return QualType::isConstant(*this, Ctx);\n  }\n\n  /// Determine whether this is a Plain Old Data (POD) type (C++ 3.9p10).\n  bool isPODType(const ASTContext &Context) const;\n\n  /// Return true if this is a POD type according to the rules of the C++98\n  /// standard, regardless of the current compilation's language.\n  bool isCXX98PODType(const ASTContext &Context) const;\n\n  /// Return true if this is a POD type according to the more relaxed rules\n  /// of the C++11 standard, regardless of the current compilation's language.\n  /// (C++0x [basic.types]p9). Note that, unlike\n  /// CXXRecordDecl::isCXX11StandardLayout, this takes DRs into account.\n  bool isCXX11PODType(const ASTContext &Context) const;\n\n  /// Return true if this is a trivial type per (C++0x [basic.types]p9)\n  bool isTrivialType(const ASTContext &Context) const;\n\n  /// Return true if this is a trivially copyable type (C++0x [basic.types]p9)\n  bool isTriviallyCopyableType(const ASTContext &Context) const;\n\n\n  /// Returns true if it is a class and it might be dynamic.\n  bool mayBeDynamicClass() const;\n\n  /// Returns true if it is not a class or if the class might not be dynamic.\n  bool mayBeNotDynamicClass() const;\n\n  // Don't promise in the API that anything besides 'const' can be\n  // easily added.\n\n  /// Add the `const` type qualifier to this QualType.\n  void addConst() {\n    addFastQualifiers(Qualifiers::Const);\n  }\n  QualType withConst() const {\n    return withFastQualifiers(Qualifiers::Const);\n  }\n\n  /// Add the `volatile` type qualifier to this QualType.\n  void addVolatile() {\n    addFastQualifiers(Qualifiers::Volatile);\n  }\n  QualType withVolatile() const {\n    return withFastQualifiers(Qualifiers::Volatile);\n  }\n\n  /// Add the `restrict` qualifier to this QualType.\n  void addRestrict() {\n    addFastQualifiers(Qualifiers::Restrict);\n  }\n  QualType withRestrict() const {\n    return withFastQualifiers(Qualifiers::Restrict);\n  }\n\n  QualType withCVRQualifiers(unsigned CVR) const {\n    return withFastQualifiers(CVR);\n  }\n\n  void addFastQualifiers(unsigned TQs) {\n    assert(!(TQs & ~Qualifiers::FastMask)\n           && \"non-fast qualifier bits set in mask!\");\n    Value.setInt(Value.getInt() | TQs);\n  }\n\n  void removeLocalConst();\n  void removeLocalVolatile();\n  void removeLocalRestrict();\n  void removeLocalCVRQualifiers(unsigned Mask);\n\n  void removeLocalFastQualifiers() { Value.setInt(0); }\n  void removeLocalFastQualifiers(unsigned Mask) {\n    assert(!(Mask & ~Qualifiers::FastMask) && \"mask has non-fast qualifiers\");\n    Value.setInt(Value.getInt() & ~Mask);\n  }\n\n  // Creates a type with the given qualifiers in addition to any\n  // qualifiers already on this type.\n  QualType withFastQualifiers(unsigned TQs) const {\n    QualType T = *this;\n    T.addFastQualifiers(TQs);\n    return T;\n  }\n\n  // Creates a type with exactly the given fast qualifiers, removing\n  // any existing fast qualifiers.\n  QualType withExactLocalFastQualifiers(unsigned TQs) const {\n    return withoutLocalFastQualifiers().withFastQualifiers(TQs);\n  }\n\n  // Removes fast qualifiers, but leaves any extended qualifiers in place.\n  QualType withoutLocalFastQualifiers() const {\n    QualType T = *this;\n    T.removeLocalFastQualifiers();\n    return T;\n  }\n\n  QualType getCanonicalType() const;\n\n  /// Return this type with all of the instance-specific qualifiers\n  /// removed, but without removing any qualifiers that may have been applied\n  /// through typedefs.\n  QualType getLocalUnqualifiedType() const { return QualType(getTypePtr(), 0); }\n\n  /// Retrieve the unqualified variant of the given type,\n  /// removing as little sugar as possible.\n  ///\n  /// This routine looks through various kinds of sugar to find the\n  /// least-desugared type that is unqualified. For example, given:\n  ///\n  /// \\code\n  /// typedef int Integer;\n  /// typedef const Integer CInteger;\n  /// typedef CInteger DifferenceType;\n  /// \\endcode\n  ///\n  /// Executing \\c getUnqualifiedType() on the type \\c DifferenceType will\n  /// desugar until we hit the type \\c Integer, which has no qualifiers on it.\n  ///\n  /// The resulting type might still be qualified if it's sugar for an array\n  /// type.  To strip qualifiers even from within a sugared array type, use\n  /// ASTContext::getUnqualifiedArrayType.\n  inline QualType getUnqualifiedType() const;\n\n  /// Retrieve the unqualified variant of the given type, removing as little\n  /// sugar as possible.\n  ///\n  /// Like getUnqualifiedType(), but also returns the set of\n  /// qualifiers that were built up.\n  ///\n  /// The resulting type might still be qualified if it's sugar for an array\n  /// type.  To strip qualifiers even from within a sugared array type, use\n  /// ASTContext::getUnqualifiedArrayType.\n  inline SplitQualType getSplitUnqualifiedType() const;\n\n  /// Determine whether this type is more qualified than the other\n  /// given type, requiring exact equality for non-CVR qualifiers.\n  bool isMoreQualifiedThan(QualType Other) const;\n\n  /// Determine whether this type is at least as qualified as the other\n  /// given type, requiring exact equality for non-CVR qualifiers.\n  bool isAtLeastAsQualifiedAs(QualType Other) const;\n\n  QualType getNonReferenceType() const;\n\n  /// Determine the type of a (typically non-lvalue) expression with the\n  /// specified result type.\n  ///\n  /// This routine should be used for expressions for which the return type is\n  /// explicitly specified (e.g., in a cast or call) and isn't necessarily\n  /// an lvalue. It removes a top-level reference (since there are no\n  /// expressions of reference type) and deletes top-level cvr-qualifiers\n  /// from non-class types (in C++) or all types (in C).\n  QualType getNonLValueExprType(const ASTContext &Context) const;\n\n  /// Remove an outer pack expansion type (if any) from this type. Used as part\n  /// of converting the type of a declaration to the type of an expression that\n  /// references that expression. It's meaningless for an expression to have a\n  /// pack expansion type.\n  QualType getNonPackExpansionType() const;\n\n  /// Return the specified type with any \"sugar\" removed from\n  /// the type.  This takes off typedefs, typeof's etc.  If the outer level of\n  /// the type is already concrete, it returns it unmodified.  This is similar\n  /// to getting the canonical type, but it doesn't remove *all* typedefs.  For\n  /// example, it returns \"T*\" as \"T*\", (not as \"int*\"), because the pointer is\n  /// concrete.\n  ///\n  /// Qualifiers are left in place.\n  QualType getDesugaredType(const ASTContext &Context) const {\n    return getDesugaredType(*this, Context);\n  }\n\n  SplitQualType getSplitDesugaredType() const {\n    return getSplitDesugaredType(*this);\n  }\n\n  /// Return the specified type with one level of \"sugar\" removed from\n  /// the type.\n  ///\n  /// This routine takes off the first typedef, typeof, etc. If the outer level\n  /// of the type is already concrete, it returns it unmodified.\n  QualType getSingleStepDesugaredType(const ASTContext &Context) const {\n    return getSingleStepDesugaredTypeImpl(*this, Context);\n  }\n\n  /// Returns the specified type after dropping any\n  /// outer-level parentheses.\n  QualType IgnoreParens() const {\n    if (isa<ParenType>(*this))\n      return QualType::IgnoreParens(*this);\n    return *this;\n  }\n\n  /// Indicate whether the specified types and qualifiers are identical.\n  friend bool operator==(const QualType &LHS, const QualType &RHS) {\n    return LHS.Value == RHS.Value;\n  }\n  friend bool operator!=(const QualType &LHS, const QualType &RHS) {\n    return LHS.Value != RHS.Value;\n  }\n  friend bool operator<(const QualType &LHS, const QualType &RHS) {\n    return LHS.Value < RHS.Value;\n  }\n\n  static std::string getAsString(SplitQualType split,\n                                 const PrintingPolicy &Policy) {\n    return getAsString(split.Ty, split.Quals, Policy);\n  }\n  static std::string getAsString(const Type *ty, Qualifiers qs,\n                                 const PrintingPolicy &Policy);\n\n  std::string getAsString() const;\n  std::string getAsString(const PrintingPolicy &Policy) const;\n\n  void print(raw_ostream &OS, const PrintingPolicy &Policy,\n             const Twine &PlaceHolder = Twine(),\n             unsigned Indentation = 0) const;\n\n  static void print(SplitQualType split, raw_ostream &OS,\n                    const PrintingPolicy &policy, const Twine &PlaceHolder,\n                    unsigned Indentation = 0) {\n    return print(split.Ty, split.Quals, OS, policy, PlaceHolder, Indentation);\n  }\n\n  static void print(const Type *ty, Qualifiers qs,\n                    raw_ostream &OS, const PrintingPolicy &policy,\n                    const Twine &PlaceHolder,\n                    unsigned Indentation = 0);\n\n  void getAsStringInternal(std::string &Str,\n                           const PrintingPolicy &Policy) const;\n\n  static void getAsStringInternal(SplitQualType split, std::string &out,\n                                  const PrintingPolicy &policy) {\n    return getAsStringInternal(split.Ty, split.Quals, out, policy);\n  }\n\n  static void getAsStringInternal(const Type *ty, Qualifiers qs,\n                                  std::string &out,\n                                  const PrintingPolicy &policy);\n\n  class StreamedQualTypeHelper {\n    const QualType &T;\n    const PrintingPolicy &Policy;\n    const Twine &PlaceHolder;\n    unsigned Indentation;\n\n  public:\n    StreamedQualTypeHelper(const QualType &T, const PrintingPolicy &Policy,\n                           const Twine &PlaceHolder, unsigned Indentation)\n        : T(T), Policy(Policy), PlaceHolder(PlaceHolder),\n          Indentation(Indentation) {}\n\n    friend raw_ostream &operator<<(raw_ostream &OS,\n                                   const StreamedQualTypeHelper &SQT) {\n      SQT.T.print(OS, SQT.Policy, SQT.PlaceHolder, SQT.Indentation);\n      return OS;\n    }\n  };\n\n  StreamedQualTypeHelper stream(const PrintingPolicy &Policy,\n                                const Twine &PlaceHolder = Twine(),\n                                unsigned Indentation = 0) const {\n    return StreamedQualTypeHelper(*this, Policy, PlaceHolder, Indentation);\n  }\n\n  void dump(const char *s) const;\n  void dump() const;\n  void dump(llvm::raw_ostream &OS, const ASTContext &Context) const;\n\n  void Profile(llvm::FoldingSetNodeID &ID) const {\n    ID.AddPointer(getAsOpaquePtr());\n  }\n\n  /// Check if this type has any address space qualifier.\n  inline bool hasAddressSpace() const;\n\n  /// Return the address space of this type.\n  inline LangAS getAddressSpace() const;\n\n  /// Returns true if address space qualifiers overlap with T address space\n  /// qualifiers.\n  /// OpenCL C defines conversion rules for pointers to different address spaces\n  /// and notion of overlapping address spaces.\n  /// CL1.1 or CL1.2:\n  ///   address spaces overlap iff they are they same.\n  /// OpenCL C v2.0 s6.5.5 adds:\n  ///   __generic overlaps with any address space except for __constant.\n  bool isAddressSpaceOverlapping(QualType T) const {\n    Qualifiers Q = getQualifiers();\n    Qualifiers TQ = T.getQualifiers();\n    // Address spaces overlap if at least one of them is a superset of another\n    return Q.isAddressSpaceSupersetOf(TQ) || TQ.isAddressSpaceSupersetOf(Q);\n  }\n\n  /// Returns gc attribute of this type.\n  inline Qualifiers::GC getObjCGCAttr() const;\n\n  /// true when Type is objc's weak.\n  bool isObjCGCWeak() const {\n    return getObjCGCAttr() == Qualifiers::Weak;\n  }\n\n  /// true when Type is objc's strong.\n  bool isObjCGCStrong() const {\n    return getObjCGCAttr() == Qualifiers::Strong;\n  }\n\n  /// Returns lifetime attribute of this type.\n  Qualifiers::ObjCLifetime getObjCLifetime() const {\n    return getQualifiers().getObjCLifetime();\n  }\n\n  bool hasNonTrivialObjCLifetime() const {\n    return getQualifiers().hasNonTrivialObjCLifetime();\n  }\n\n  bool hasStrongOrWeakObjCLifetime() const {\n    return getQualifiers().hasStrongOrWeakObjCLifetime();\n  }\n\n  // true when Type is objc's weak and weak is enabled but ARC isn't.\n  bool isNonWeakInMRRWithObjCWeak(const ASTContext &Context) const;\n\n  enum PrimitiveDefaultInitializeKind {\n    /// The type does not fall into any of the following categories. Note that\n    /// this case is zero-valued so that values of this enum can be used as a\n    /// boolean condition for non-triviality.\n    PDIK_Trivial,\n\n    /// The type is an Objective-C retainable pointer type that is qualified\n    /// with the ARC __strong qualifier.\n    PDIK_ARCStrong,\n\n    /// The type is an Objective-C retainable pointer type that is qualified\n    /// with the ARC __weak qualifier.\n    PDIK_ARCWeak,\n\n    /// The type is a struct containing a field whose type is not PCK_Trivial.\n    PDIK_Struct\n  };\n\n  /// Functions to query basic properties of non-trivial C struct types.\n\n  /// Check if this is a non-trivial type that would cause a C struct\n  /// transitively containing this type to be non-trivial to default initialize\n  /// and return the kind.\n  PrimitiveDefaultInitializeKind\n  isNonTrivialToPrimitiveDefaultInitialize() const;\n\n  enum PrimitiveCopyKind {\n    /// The type does not fall into any of the following categories. Note that\n    /// this case is zero-valued so that values of this enum can be used as a\n    /// boolean condition for non-triviality.\n    PCK_Trivial,\n\n    /// The type would be trivial except that it is volatile-qualified. Types\n    /// that fall into one of the other non-trivial cases may additionally be\n    /// volatile-qualified.\n    PCK_VolatileTrivial,\n\n    /// The type is an Objective-C retainable pointer type that is qualified\n    /// with the ARC __strong qualifier.\n    PCK_ARCStrong,\n\n    /// The type is an Objective-C retainable pointer type that is qualified\n    /// with the ARC __weak qualifier.\n    PCK_ARCWeak,\n\n    /// The type is a struct containing a field whose type is neither\n    /// PCK_Trivial nor PCK_VolatileTrivial.\n    /// Note that a C++ struct type does not necessarily match this; C++ copying\n    /// semantics are too complex to express here, in part because they depend\n    /// on the exact constructor or assignment operator that is chosen by\n    /// overload resolution to do the copy.\n    PCK_Struct\n  };\n\n  /// Check if this is a non-trivial type that would cause a C struct\n  /// transitively containing this type to be non-trivial to copy and return the\n  /// kind.\n  PrimitiveCopyKind isNonTrivialToPrimitiveCopy() const;\n\n  /// Check if this is a non-trivial type that would cause a C struct\n  /// transitively containing this type to be non-trivial to destructively\n  /// move and return the kind. Destructive move in this context is a C++-style\n  /// move in which the source object is placed in a valid but unspecified state\n  /// after it is moved, as opposed to a truly destructive move in which the\n  /// source object is placed in an uninitialized state.\n  PrimitiveCopyKind isNonTrivialToPrimitiveDestructiveMove() const;\n\n  enum DestructionKind {\n    DK_none,\n    DK_cxx_destructor,\n    DK_objc_strong_lifetime,\n    DK_objc_weak_lifetime,\n    DK_nontrivial_c_struct\n  };\n\n  /// Returns a nonzero value if objects of this type require\n  /// non-trivial work to clean up after.  Non-zero because it's\n  /// conceivable that qualifiers (objc_gc(weak)?) could make\n  /// something require destruction.\n  DestructionKind isDestructedType() const {\n    return isDestructedTypeImpl(*this);\n  }\n\n  /// Check if this is or contains a C union that is non-trivial to\n  /// default-initialize, which is a union that has a member that is non-trivial\n  /// to default-initialize. If this returns true,\n  /// isNonTrivialToPrimitiveDefaultInitialize returns PDIK_Struct.\n  bool hasNonTrivialToPrimitiveDefaultInitializeCUnion() const;\n\n  /// Check if this is or contains a C union that is non-trivial to destruct,\n  /// which is a union that has a member that is non-trivial to destruct. If\n  /// this returns true, isDestructedType returns DK_nontrivial_c_struct.\n  bool hasNonTrivialToPrimitiveDestructCUnion() const;\n\n  /// Check if this is or contains a C union that is non-trivial to copy, which\n  /// is a union that has a member that is non-trivial to copy. If this returns\n  /// true, isNonTrivialToPrimitiveCopy returns PCK_Struct.\n  bool hasNonTrivialToPrimitiveCopyCUnion() const;\n\n  /// Determine whether expressions of the given type are forbidden\n  /// from being lvalues in C.\n  ///\n  /// The expression types that are forbidden to be lvalues are:\n  ///   - 'void', but not qualified void\n  ///   - function types\n  ///\n  /// The exact rule here is C99 6.3.2.1:\n  ///   An lvalue is an expression with an object type or an incomplete\n  ///   type other than void.\n  bool isCForbiddenLValueType() const;\n\n  /// Substitute type arguments for the Objective-C type parameters used in the\n  /// subject type.\n  ///\n  /// \\param ctx ASTContext in which the type exists.\n  ///\n  /// \\param typeArgs The type arguments that will be substituted for the\n  /// Objective-C type parameters in the subject type, which are generally\n  /// computed via \\c Type::getObjCSubstitutions. If empty, the type\n  /// parameters will be replaced with their bounds or id/Class, as appropriate\n  /// for the context.\n  ///\n  /// \\param context The context in which the subject type was written.\n  ///\n  /// \\returns the resulting type.\n  QualType substObjCTypeArgs(ASTContext &ctx,\n                             ArrayRef<QualType> typeArgs,\n                             ObjCSubstitutionContext context) const;\n\n  /// Substitute type arguments from an object type for the Objective-C type\n  /// parameters used in the subject type.\n  ///\n  /// This operation combines the computation of type arguments for\n  /// substitution (\\c Type::getObjCSubstitutions) with the actual process of\n  /// substitution (\\c QualType::substObjCTypeArgs) for the convenience of\n  /// callers that need to perform a single substitution in isolation.\n  ///\n  /// \\param objectType The type of the object whose member type we're\n  /// substituting into. For example, this might be the receiver of a message\n  /// or the base of a property access.\n  ///\n  /// \\param dc The declaration context from which the subject type was\n  /// retrieved, which indicates (for example) which type parameters should\n  /// be substituted.\n  ///\n  /// \\param context The context in which the subject type was written.\n  ///\n  /// \\returns the subject type after replacing all of the Objective-C type\n  /// parameters with their corresponding arguments.\n  QualType substObjCMemberType(QualType objectType,\n                               const DeclContext *dc,\n                               ObjCSubstitutionContext context) const;\n\n  /// Strip Objective-C \"__kindof\" types from the given type.\n  QualType stripObjCKindOfType(const ASTContext &ctx) const;\n\n  /// Remove all qualifiers including _Atomic.\n  QualType getAtomicUnqualifiedType() const;\n\nprivate:\n  // These methods are implemented in a separate translation unit;\n  // \"static\"-ize them to avoid creating temporary QualTypes in the\n  // caller.\n  static bool isConstant(QualType T, const ASTContext& Ctx);\n  static QualType getDesugaredType(QualType T, const ASTContext &Context);\n  static SplitQualType getSplitDesugaredType(QualType T);\n  static SplitQualType getSplitUnqualifiedTypeImpl(QualType type);\n  static QualType getSingleStepDesugaredTypeImpl(QualType type,\n                                                 const ASTContext &C);\n  static QualType IgnoreParens(QualType T);\n  static DestructionKind isDestructedTypeImpl(QualType type);\n\n  /// Check if \\param RD is or contains a non-trivial C union.\n  static bool hasNonTrivialToPrimitiveDefaultInitializeCUnion(const RecordDecl *RD);\n  static bool hasNonTrivialToPrimitiveDestructCUnion(const RecordDecl *RD);\n  static bool hasNonTrivialToPrimitiveCopyCUnion(const RecordDecl *RD);\n};\n\n} // namespace clang\n\nnamespace llvm {\n\n/// Implement simplify_type for QualType, so that we can dyn_cast from QualType\n/// to a specific Type class.\ntemplate<> struct simplify_type< ::clang::QualType> {\n  using SimpleType = const ::clang::Type *;\n\n  static SimpleType getSimplifiedValue(::clang::QualType Val) {\n    return Val.getTypePtr();\n  }\n};\n\n// Teach SmallPtrSet that QualType is \"basically a pointer\".\ntemplate<>\nstruct PointerLikeTypeTraits<clang::QualType> {\n  static inline void *getAsVoidPointer(clang::QualType P) {\n    return P.getAsOpaquePtr();\n  }\n\n  static inline clang::QualType getFromVoidPointer(void *P) {\n    return clang::QualType::getFromOpaquePtr(P);\n  }\n\n  // Various qualifiers go in low bits.\n  static constexpr int NumLowBitsAvailable = 0;\n};\n\n} // namespace llvm\n\nnamespace clang {\n\n/// Base class that is common to both the \\c ExtQuals and \\c Type\n/// classes, which allows \\c QualType to access the common fields between the\n/// two.\nclass ExtQualsTypeCommonBase {\n  friend class ExtQuals;\n  friend class QualType;\n  friend class Type;\n\n  /// The \"base\" type of an extended qualifiers type (\\c ExtQuals) or\n  /// a self-referential pointer (for \\c Type).\n  ///\n  /// This pointer allows an efficient mapping from a QualType to its\n  /// underlying type pointer.\n  const Type *const BaseType;\n\n  /// The canonical type of this type.  A QualType.\n  QualType CanonicalType;\n\n  ExtQualsTypeCommonBase(const Type *baseType, QualType canon)\n      : BaseType(baseType), CanonicalType(canon) {}\n};\n\n/// We can encode up to four bits in the low bits of a\n/// type pointer, but there are many more type qualifiers that we want\n/// to be able to apply to an arbitrary type.  Therefore we have this\n/// struct, intended to be heap-allocated and used by QualType to\n/// store qualifiers.\n///\n/// The current design tags the 'const', 'restrict', and 'volatile' qualifiers\n/// in three low bits on the QualType pointer; a fourth bit records whether\n/// the pointer is an ExtQuals node. The extended qualifiers (address spaces,\n/// Objective-C GC attributes) are much more rare.\nclass ExtQuals : public ExtQualsTypeCommonBase, public llvm::FoldingSetNode {\n  // NOTE: changing the fast qualifiers should be straightforward as\n  // long as you don't make 'const' non-fast.\n  // 1. Qualifiers:\n  //    a) Modify the bitmasks (Qualifiers::TQ and DeclSpec::TQ).\n  //       Fast qualifiers must occupy the low-order bits.\n  //    b) Update Qualifiers::FastWidth and FastMask.\n  // 2. QualType:\n  //    a) Update is{Volatile,Restrict}Qualified(), defined inline.\n  //    b) Update remove{Volatile,Restrict}, defined near the end of\n  //       this header.\n  // 3. ASTContext:\n  //    a) Update get{Volatile,Restrict}Type.\n\n  /// The immutable set of qualifiers applied by this node. Always contains\n  /// extended qualifiers.\n  Qualifiers Quals;\n\n  ExtQuals *this_() { return this; }\n\npublic:\n  ExtQuals(const Type *baseType, QualType canon, Qualifiers quals)\n      : ExtQualsTypeCommonBase(baseType,\n                               canon.isNull() ? QualType(this_(), 0) : canon),\n        Quals(quals) {\n    assert(Quals.hasNonFastQualifiers()\n           && \"ExtQuals created with no fast qualifiers\");\n    assert(!Quals.hasFastQualifiers()\n           && \"ExtQuals created with fast qualifiers\");\n  }\n\n  Qualifiers getQualifiers() const { return Quals; }\n\n  bool hasObjCGCAttr() const { return Quals.hasObjCGCAttr(); }\n  Qualifiers::GC getObjCGCAttr() const { return Quals.getObjCGCAttr(); }\n\n  bool hasObjCLifetime() const { return Quals.hasObjCLifetime(); }\n  Qualifiers::ObjCLifetime getObjCLifetime() const {\n    return Quals.getObjCLifetime();\n  }\n\n  bool hasAddressSpace() const { return Quals.hasAddressSpace(); }\n  LangAS getAddressSpace() const { return Quals.getAddressSpace(); }\n\n  const Type *getBaseType() const { return BaseType; }\n\npublic:\n  void Profile(llvm::FoldingSetNodeID &ID) const {\n    Profile(ID, getBaseType(), Quals);\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      const Type *BaseType,\n                      Qualifiers Quals) {\n    assert(!Quals.hasFastQualifiers() && \"fast qualifiers in ExtQuals hash!\");\n    ID.AddPointer(BaseType);\n    Quals.Profile(ID);\n  }\n};\n\n/// The kind of C++11 ref-qualifier associated with a function type.\n/// This determines whether a member function's \"this\" object can be an\n/// lvalue, rvalue, or neither.\nenum RefQualifierKind {\n  /// No ref-qualifier was provided.\n  RQ_None = 0,\n\n  /// An lvalue ref-qualifier was provided (\\c &).\n  RQ_LValue,\n\n  /// An rvalue ref-qualifier was provided (\\c &&).\n  RQ_RValue\n};\n\n/// Which keyword(s) were used to create an AutoType.\nenum class AutoTypeKeyword {\n  /// auto\n  Auto,\n\n  /// decltype(auto)\n  DecltypeAuto,\n\n  /// __auto_type (GNU extension)\n  GNUAutoType\n};\n\n/// The base class of the type hierarchy.\n///\n/// A central concept with types is that each type always has a canonical\n/// type.  A canonical type is the type with any typedef names stripped out\n/// of it or the types it references.  For example, consider:\n///\n///  typedef int  foo;\n///  typedef foo* bar;\n///    'int *'    'foo *'    'bar'\n///\n/// There will be a Type object created for 'int'.  Since int is canonical, its\n/// CanonicalType pointer points to itself.  There is also a Type for 'foo' (a\n/// TypedefType).  Its CanonicalType pointer points to the 'int' Type.  Next\n/// there is a PointerType that represents 'int*', which, like 'int', is\n/// canonical.  Finally, there is a PointerType type for 'foo*' whose canonical\n/// type is 'int*', and there is a TypedefType for 'bar', whose canonical type\n/// is also 'int*'.\n///\n/// Non-canonical types are useful for emitting diagnostics, without losing\n/// information about typedefs being used.  Canonical types are useful for type\n/// comparisons (they allow by-pointer equality tests) and useful for reasoning\n/// about whether something has a particular form (e.g. is a function type),\n/// because they implicitly, recursively, strip all typedefs out of a type.\n///\n/// Types, once created, are immutable.\n///\nclass alignas(8) Type : public ExtQualsTypeCommonBase {\npublic:\n  enum TypeClass {\n#define TYPE(Class, Base) Class,\n#define LAST_TYPE(Class) TypeLast = Class\n#define ABSTRACT_TYPE(Class, Base)\n#include \"clang/AST/TypeNodes.inc\"\n  };\n\nprivate:\n  /// Bitfields required by the Type class.\n  class TypeBitfields {\n    friend class Type;\n    template <class T> friend class TypePropertyCache;\n\n    /// TypeClass bitfield - Enum that specifies what subclass this belongs to.\n    unsigned TC : 8;\n\n    /// Store information on the type dependency.\n    unsigned Dependence : llvm::BitWidth<TypeDependence>;\n\n    /// True if the cache (i.e. the bitfields here starting with\n    /// 'Cache') is valid.\n    mutable unsigned CacheValid : 1;\n\n    /// Linkage of this type.\n    mutable unsigned CachedLinkage : 3;\n\n    /// Whether this type involves and local or unnamed types.\n    mutable unsigned CachedLocalOrUnnamed : 1;\n\n    /// Whether this type comes from an AST file.\n    mutable unsigned FromAST : 1;\n\n    bool isCacheValid() const {\n      return CacheValid;\n    }\n\n    Linkage getLinkage() const {\n      assert(isCacheValid() && \"getting linkage from invalid cache\");\n      return static_cast<Linkage>(CachedLinkage);\n    }\n\n    bool hasLocalOrUnnamedType() const {\n      assert(isCacheValid() && \"getting linkage from invalid cache\");\n      return CachedLocalOrUnnamed;\n    }\n  };\n  enum { NumTypeBits = 8 + llvm::BitWidth<TypeDependence> + 6 };\n\nprotected:\n  // These classes allow subclasses to somewhat cleanly pack bitfields\n  // into Type.\n\n  class ArrayTypeBitfields {\n    friend class ArrayType;\n\n    unsigned : NumTypeBits;\n\n    /// CVR qualifiers from declarations like\n    /// 'int X[static restrict 4]'. For function parameters only.\n    unsigned IndexTypeQuals : 3;\n\n    /// Storage class qualifiers from declarations like\n    /// 'int X[static restrict 4]'. For function parameters only.\n    /// Actually an ArrayType::ArraySizeModifier.\n    unsigned SizeModifier : 3;\n  };\n\n  class ConstantArrayTypeBitfields {\n    friend class ConstantArrayType;\n\n    unsigned : NumTypeBits + 3 + 3;\n\n    /// Whether we have a stored size expression.\n    unsigned HasStoredSizeExpr : 1;\n  };\n\n  class BuiltinTypeBitfields {\n    friend class BuiltinType;\n\n    unsigned : NumTypeBits;\n\n    /// The kind (BuiltinType::Kind) of builtin type this is.\n    unsigned Kind : 8;\n  };\n\n  /// FunctionTypeBitfields store various bits belonging to FunctionProtoType.\n  /// Only common bits are stored here. Additional uncommon bits are stored\n  /// in a trailing object after FunctionProtoType.\n  class FunctionTypeBitfields {\n    friend class FunctionProtoType;\n    friend class FunctionType;\n\n    unsigned : NumTypeBits;\n\n    /// Extra information which affects how the function is called, like\n    /// regparm and the calling convention.\n    unsigned ExtInfo : 13;\n\n    /// The ref-qualifier associated with a \\c FunctionProtoType.\n    ///\n    /// This is a value of type \\c RefQualifierKind.\n    unsigned RefQualifier : 2;\n\n    /// Used only by FunctionProtoType, put here to pack with the\n    /// other bitfields.\n    /// The qualifiers are part of FunctionProtoType because...\n    ///\n    /// C++ 8.3.5p4: The return type, the parameter type list and the\n    /// cv-qualifier-seq, [...], are part of the function type.\n    unsigned FastTypeQuals : Qualifiers::FastWidth;\n    /// Whether this function has extended Qualifiers.\n    unsigned HasExtQuals : 1;\n\n    /// The number of parameters this function has, not counting '...'.\n    /// According to [implimits] 8 bits should be enough here but this is\n    /// somewhat easy to exceed with metaprogramming and so we would like to\n    /// keep NumParams as wide as reasonably possible.\n    unsigned NumParams : 16;\n\n    /// The type of exception specification this function has.\n    unsigned ExceptionSpecType : 4;\n\n    /// Whether this function has extended parameter information.\n    unsigned HasExtParameterInfos : 1;\n\n    /// Whether the function is variadic.\n    unsigned Variadic : 1;\n\n    /// Whether this function has a trailing return type.\n    unsigned HasTrailingReturn : 1;\n  };\n\n  class ObjCObjectTypeBitfields {\n    friend class ObjCObjectType;\n\n    unsigned : NumTypeBits;\n\n    /// The number of type arguments stored directly on this object type.\n    unsigned NumTypeArgs : 7;\n\n    /// The number of protocols stored directly on this object type.\n    unsigned NumProtocols : 6;\n\n    /// Whether this is a \"kindof\" type.\n    unsigned IsKindOf : 1;\n  };\n\n  class ReferenceTypeBitfields {\n    friend class ReferenceType;\n\n    unsigned : NumTypeBits;\n\n    /// True if the type was originally spelled with an lvalue sigil.\n    /// This is never true of rvalue references but can also be false\n    /// on lvalue references because of C++0x [dcl.typedef]p9,\n    /// as follows:\n    ///\n    ///   typedef int &ref;    // lvalue, spelled lvalue\n    ///   typedef int &&rvref; // rvalue\n    ///   ref &a;              // lvalue, inner ref, spelled lvalue\n    ///   ref &&a;             // lvalue, inner ref\n    ///   rvref &a;            // lvalue, inner ref, spelled lvalue\n    ///   rvref &&a;           // rvalue, inner ref\n    unsigned SpelledAsLValue : 1;\n\n    /// True if the inner type is a reference type.  This only happens\n    /// in non-canonical forms.\n    unsigned InnerRef : 1;\n  };\n\n  class TypeWithKeywordBitfields {\n    friend class TypeWithKeyword;\n\n    unsigned : NumTypeBits;\n\n    /// An ElaboratedTypeKeyword.  8 bits for efficient access.\n    unsigned Keyword : 8;\n  };\n\n  enum { NumTypeWithKeywordBits = 8 };\n\n  class ElaboratedTypeBitfields {\n    friend class ElaboratedType;\n\n    unsigned : NumTypeBits;\n    unsigned : NumTypeWithKeywordBits;\n\n    /// Whether the ElaboratedType has a trailing OwnedTagDecl.\n    unsigned HasOwnedTagDecl : 1;\n  };\n\n  class VectorTypeBitfields {\n    friend class VectorType;\n    friend class DependentVectorType;\n\n    unsigned : NumTypeBits;\n\n    /// The kind of vector, either a generic vector type or some\n    /// target-specific vector type such as for AltiVec or Neon.\n    unsigned VecKind : 3;\n    /// The number of elements in the vector.\n    uint32_t NumElements;\n  };\n\n  class AttributedTypeBitfields {\n    friend class AttributedType;\n\n    unsigned : NumTypeBits;\n\n    /// An AttributedType::Kind\n    unsigned AttrKind : 32 - NumTypeBits;\n  };\n\n  class AutoTypeBitfields {\n    friend class AutoType;\n\n    unsigned : NumTypeBits;\n\n    /// Was this placeholder type spelled as 'auto', 'decltype(auto)',\n    /// or '__auto_type'?  AutoTypeKeyword value.\n    unsigned Keyword : 2;\n\n    /// The number of template arguments in the type-constraints, which is\n    /// expected to be able to hold at least 1024 according to [implimits].\n    /// However as this limit is somewhat easy to hit with template\n    /// metaprogramming we'd prefer to keep it as large as possible.\n    /// At the moment it has been left as a non-bitfield since this type\n    /// safely fits in 64 bits as an unsigned, so there is no reason to\n    /// introduce the performance impact of a bitfield.\n    unsigned NumArgs;\n  };\n\n  class SubstTemplateTypeParmPackTypeBitfields {\n    friend class SubstTemplateTypeParmPackType;\n\n    unsigned : NumTypeBits;\n\n    /// The number of template arguments in \\c Arguments, which is\n    /// expected to be able to hold at least 1024 according to [implimits].\n    /// However as this limit is somewhat easy to hit with template\n    /// metaprogramming we'd prefer to keep it as large as possible.\n    /// At the moment it has been left as a non-bitfield since this type\n    /// safely fits in 64 bits as an unsigned, so there is no reason to\n    /// introduce the performance impact of a bitfield.\n    unsigned NumArgs;\n  };\n\n  class TemplateSpecializationTypeBitfields {\n    friend class TemplateSpecializationType;\n\n    unsigned : NumTypeBits;\n\n    /// Whether this template specialization type is a substituted type alias.\n    unsigned TypeAlias : 1;\n\n    /// The number of template arguments named in this class template\n    /// specialization, which is expected to be able to hold at least 1024\n    /// according to [implimits]. However, as this limit is somewhat easy to\n    /// hit with template metaprogramming we'd prefer to keep it as large\n    /// as possible. At the moment it has been left as a non-bitfield since\n    /// this type safely fits in 64 bits as an unsigned, so there is no reason\n    /// to introduce the performance impact of a bitfield.\n    unsigned NumArgs;\n  };\n\n  class DependentTemplateSpecializationTypeBitfields {\n    friend class DependentTemplateSpecializationType;\n\n    unsigned : NumTypeBits;\n    unsigned : NumTypeWithKeywordBits;\n\n    /// The number of template arguments named in this class template\n    /// specialization, which is expected to be able to hold at least 1024\n    /// according to [implimits]. However, as this limit is somewhat easy to\n    /// hit with template metaprogramming we'd prefer to keep it as large\n    /// as possible. At the moment it has been left as a non-bitfield since\n    /// this type safely fits in 64 bits as an unsigned, so there is no reason\n    /// to introduce the performance impact of a bitfield.\n    unsigned NumArgs;\n  };\n\n  class PackExpansionTypeBitfields {\n    friend class PackExpansionType;\n\n    unsigned : NumTypeBits;\n\n    /// The number of expansions that this pack expansion will\n    /// generate when substituted (+1), which is expected to be able to\n    /// hold at least 1024 according to [implimits]. However, as this limit\n    /// is somewhat easy to hit with template metaprogramming we'd prefer to\n    /// keep it as large as possible. At the moment it has been left as a\n    /// non-bitfield since this type safely fits in 64 bits as an unsigned, so\n    /// there is no reason to introduce the performance impact of a bitfield.\n    ///\n    /// This field will only have a non-zero value when some of the parameter\n    /// packs that occur within the pattern have been substituted but others\n    /// have not.\n    unsigned NumExpansions;\n  };\n\n  union {\n    TypeBitfields TypeBits;\n    ArrayTypeBitfields ArrayTypeBits;\n    ConstantArrayTypeBitfields ConstantArrayTypeBits;\n    AttributedTypeBitfields AttributedTypeBits;\n    AutoTypeBitfields AutoTypeBits;\n    BuiltinTypeBitfields BuiltinTypeBits;\n    FunctionTypeBitfields FunctionTypeBits;\n    ObjCObjectTypeBitfields ObjCObjectTypeBits;\n    ReferenceTypeBitfields ReferenceTypeBits;\n    TypeWithKeywordBitfields TypeWithKeywordBits;\n    ElaboratedTypeBitfields ElaboratedTypeBits;\n    VectorTypeBitfields VectorTypeBits;\n    SubstTemplateTypeParmPackTypeBitfields SubstTemplateTypeParmPackTypeBits;\n    TemplateSpecializationTypeBitfields TemplateSpecializationTypeBits;\n    DependentTemplateSpecializationTypeBitfields\n      DependentTemplateSpecializationTypeBits;\n    PackExpansionTypeBitfields PackExpansionTypeBits;\n  };\n\nprivate:\n  template <class T> friend class TypePropertyCache;\n\n  /// Set whether this type comes from an AST file.\n  void setFromAST(bool V = true) const {\n    TypeBits.FromAST = V;\n  }\n\nprotected:\n  friend class ASTContext;\n\n  Type(TypeClass tc, QualType canon, TypeDependence Dependence)\n      : ExtQualsTypeCommonBase(this,\n                               canon.isNull() ? QualType(this_(), 0) : canon) {\n    static_assert(sizeof(*this) <= 8 + sizeof(ExtQualsTypeCommonBase),\n                  \"changing bitfields changed sizeof(Type)!\");\n    static_assert(alignof(decltype(*this)) % sizeof(void *) == 0,\n                  \"Insufficient alignment!\");\n    TypeBits.TC = tc;\n    TypeBits.Dependence = static_cast<unsigned>(Dependence);\n    TypeBits.CacheValid = false;\n    TypeBits.CachedLocalOrUnnamed = false;\n    TypeBits.CachedLinkage = NoLinkage;\n    TypeBits.FromAST = false;\n  }\n\n  // silence VC++ warning C4355: 'this' : used in base member initializer list\n  Type *this_() { return this; }\n\n  void setDependence(TypeDependence D) {\n    TypeBits.Dependence = static_cast<unsigned>(D);\n  }\n\n  void addDependence(TypeDependence D) { setDependence(getDependence() | D); }\n\npublic:\n  friend class ASTReader;\n  friend class ASTWriter;\n  template <class T> friend class serialization::AbstractTypeReader;\n  template <class T> friend class serialization::AbstractTypeWriter;\n\n  Type(const Type &) = delete;\n  Type(Type &&) = delete;\n  Type &operator=(const Type &) = delete;\n  Type &operator=(Type &&) = delete;\n\n  TypeClass getTypeClass() const { return static_cast<TypeClass>(TypeBits.TC); }\n\n  /// Whether this type comes from an AST file.\n  bool isFromAST() const { return TypeBits.FromAST; }\n\n  /// Whether this type is or contains an unexpanded parameter\n  /// pack, used to support C++0x variadic templates.\n  ///\n  /// A type that contains a parameter pack shall be expanded by the\n  /// ellipsis operator at some point. For example, the typedef in the\n  /// following example contains an unexpanded parameter pack 'T':\n  ///\n  /// \\code\n  /// template<typename ...T>\n  /// struct X {\n  ///   typedef T* pointer_types; // ill-formed; T is a parameter pack.\n  /// };\n  /// \\endcode\n  ///\n  /// Note that this routine does not specify which\n  bool containsUnexpandedParameterPack() const {\n    return getDependence() & TypeDependence::UnexpandedPack;\n  }\n\n  /// Determines if this type would be canonical if it had no further\n  /// qualification.\n  bool isCanonicalUnqualified() const {\n    return CanonicalType == QualType(this, 0);\n  }\n\n  /// Pull a single level of sugar off of this locally-unqualified type.\n  /// Users should generally prefer SplitQualType::getSingleStepDesugaredType()\n  /// or QualType::getSingleStepDesugaredType(const ASTContext&).\n  QualType getLocallyUnqualifiedSingleStepDesugaredType() const;\n\n  /// As an extension, we classify types as one of \"sized\" or \"sizeless\";\n  /// every type is one or the other.  Standard types are all sized;\n  /// sizeless types are purely an extension.\n  ///\n  /// Sizeless types contain data with no specified size, alignment,\n  /// or layout.\n  bool isSizelessType() const;\n  bool isSizelessBuiltinType() const;\n\n  /// Determines if this is a sizeless type supported by the\n  /// 'arm_sve_vector_bits' type attribute, which can be applied to a single\n  /// SVE vector or predicate, excluding tuple types such as svint32x4_t.\n  bool isVLSTBuiltinType() const;\n\n  /// Returns the representative type for the element of an SVE builtin type.\n  /// This is used to represent fixed-length SVE vectors created with the\n  /// 'arm_sve_vector_bits' type attribute as VectorType.\n  QualType getSveEltType(const ASTContext &Ctx) const;\n\n  /// Types are partitioned into 3 broad categories (C99 6.2.5p1):\n  /// object types, function types, and incomplete types.\n\n  /// Return true if this is an incomplete type.\n  /// A type that can describe objects, but which lacks information needed to\n  /// determine its size (e.g. void, or a fwd declared struct). Clients of this\n  /// routine will need to determine if the size is actually required.\n  ///\n  /// Def If non-null, and the type refers to some kind of declaration\n  /// that can be completed (such as a C struct, C++ class, or Objective-C\n  /// class), will be set to the declaration.\n  bool isIncompleteType(NamedDecl **Def = nullptr) const;\n\n  /// Return true if this is an incomplete or object\n  /// type, in other words, not a function type.\n  bool isIncompleteOrObjectType() const {\n    return !isFunctionType();\n  }\n\n  /// Determine whether this type is an object type.\n  bool isObjectType() const {\n    // C++ [basic.types]p8:\n    //   An object type is a (possibly cv-qualified) type that is not a\n    //   function type, not a reference type, and not a void type.\n    return !isReferenceType() && !isFunctionType() && !isVoidType();\n  }\n\n  /// Return true if this is a literal type\n  /// (C++11 [basic.types]p10)\n  bool isLiteralType(const ASTContext &Ctx) const;\n\n  /// Determine if this type is a structural type, per C++20 [temp.param]p7.\n  bool isStructuralType() const;\n\n  /// Test if this type is a standard-layout type.\n  /// (C++0x [basic.type]p9)\n  bool isStandardLayoutType() const;\n\n  /// Helper methods to distinguish type categories. All type predicates\n  /// operate on the canonical type, ignoring typedefs and qualifiers.\n\n  /// Returns true if the type is a builtin type.\n  bool isBuiltinType() const;\n\n  /// Test for a particular builtin type.\n  bool isSpecificBuiltinType(unsigned K) const;\n\n  /// Test for a type which does not represent an actual type-system type but\n  /// is instead used as a placeholder for various convenient purposes within\n  /// Clang.  All such types are BuiltinTypes.\n  bool isPlaceholderType() const;\n  const BuiltinType *getAsPlaceholderType() const;\n\n  /// Test for a specific placeholder type.\n  bool isSpecificPlaceholderType(unsigned K) const;\n\n  /// Test for a placeholder type other than Overload; see\n  /// BuiltinType::isNonOverloadPlaceholderType.\n  bool isNonOverloadPlaceholderType() const;\n\n  /// isIntegerType() does *not* include complex integers (a GCC extension).\n  /// isComplexIntegerType() can be used to test for complex integers.\n  bool isIntegerType() const;     // C99 6.2.5p17 (int, char, bool, enum)\n  bool isEnumeralType() const;\n\n  /// Determine whether this type is a scoped enumeration type.\n  bool isScopedEnumeralType() const;\n  bool isBooleanType() const;\n  bool isCharType() const;\n  bool isWideCharType() const;\n  bool isChar8Type() const;\n  bool isChar16Type() const;\n  bool isChar32Type() const;\n  bool isAnyCharacterType() const;\n  bool isIntegralType(const ASTContext &Ctx) const;\n\n  /// Determine whether this type is an integral or enumeration type.\n  bool isIntegralOrEnumerationType() const;\n\n  /// Determine whether this type is an integral or unscoped enumeration type.\n  bool isIntegralOrUnscopedEnumerationType() const;\n  bool isUnscopedEnumerationType() const;\n\n  /// Floating point categories.\n  bool isRealFloatingType() const; // C99 6.2.5p10 (float, double, long double)\n  /// isComplexType() does *not* include complex integers (a GCC extension).\n  /// isComplexIntegerType() can be used to test for complex integers.\n  bool isComplexType() const;      // C99 6.2.5p11 (complex)\n  bool isAnyComplexType() const;   // C99 6.2.5p11 (complex) + Complex Int.\n  bool isFloatingType() const;     // C99 6.2.5p11 (real floating + complex)\n  bool isHalfType() const;         // OpenCL 6.1.1.1, NEON (IEEE 754-2008 half)\n  bool isFloat16Type() const;      // C11 extension ISO/IEC TS 18661\n  bool isBFloat16Type() const;\n  bool isFloat128Type() const;\n  bool isRealType() const;         // C99 6.2.5p17 (real floating + integer)\n  bool isArithmeticType() const;   // C99 6.2.5p18 (integer + floating)\n  bool isVoidType() const;         // C99 6.2.5p19\n  bool isScalarType() const;       // C99 6.2.5p21 (arithmetic + pointers)\n  bool isAggregateType() const;\n  bool isFundamentalType() const;\n  bool isCompoundType() const;\n\n  // Type Predicates: Check to see if this type is structurally the specified\n  // type, ignoring typedefs and qualifiers.\n  bool isFunctionType() const;\n  bool isFunctionNoProtoType() const { return getAs<FunctionNoProtoType>(); }\n  bool isFunctionProtoType() const { return getAs<FunctionProtoType>(); }\n  bool isPointerType() const;\n  bool isAnyPointerType() const;   // Any C pointer or ObjC object pointer\n  bool isBlockPointerType() const;\n  bool isVoidPointerType() const;\n  bool isReferenceType() const;\n  bool isLValueReferenceType() const;\n  bool isRValueReferenceType() const;\n  bool isObjectPointerType() const;\n  bool isFunctionPointerType() const;\n  bool isFunctionReferenceType() const;\n  bool isMemberPointerType() const;\n  bool isMemberFunctionPointerType() const;\n  bool isMemberDataPointerType() const;\n  bool isArrayType() const;\n  bool isConstantArrayType() const;\n  bool isIncompleteArrayType() const;\n  bool isVariableArrayType() const;\n  bool isDependentSizedArrayType() const;\n  bool isRecordType() const;\n  bool isClassType() const;\n  bool isStructureType() const;\n  bool isObjCBoxableRecordType() const;\n  bool isInterfaceType() const;\n  bool isStructureOrClassType() const;\n  bool isUnionType() const;\n  bool isComplexIntegerType() const;            // GCC _Complex integer type.\n  bool isVectorType() const;                    // GCC vector type.\n  bool isExtVectorType() const;                 // Extended vector type.\n  bool isMatrixType() const;                    // Matrix type.\n  bool isConstantMatrixType() const;            // Constant matrix type.\n  bool isDependentAddressSpaceType() const;     // value-dependent address space qualifier\n  bool isObjCObjectPointerType() const;         // pointer to ObjC object\n  bool isObjCRetainableType() const;            // ObjC object or block pointer\n  bool isObjCLifetimeType() const;              // (array of)* retainable type\n  bool isObjCIndirectLifetimeType() const;      // (pointer to)* lifetime type\n  bool isObjCNSObjectType() const;              // __attribute__((NSObject))\n  bool isObjCIndependentClassType() const;      // __attribute__((objc_independent_class))\n  // FIXME: change this to 'raw' interface type, so we can used 'interface' type\n  // for the common case.\n  bool isObjCObjectType() const;                // NSString or typeof(*(id)0)\n  bool isObjCQualifiedInterfaceType() const;    // NSString<foo>\n  bool isObjCQualifiedIdType() const;           // id<foo>\n  bool isObjCQualifiedClassType() const;        // Class<foo>\n  bool isObjCObjectOrInterfaceType() const;\n  bool isObjCIdType() const;                    // id\n  bool isDecltypeType() const;\n  /// Was this type written with the special inert-in-ARC __unsafe_unretained\n  /// qualifier?\n  ///\n  /// This approximates the answer to the following question: if this\n  /// translation unit were compiled in ARC, would this type be qualified\n  /// with __unsafe_unretained?\n  bool isObjCInertUnsafeUnretainedType() const {\n    return hasAttr(attr::ObjCInertUnsafeUnretained);\n  }\n\n  /// Whether the type is Objective-C 'id' or a __kindof type of an\n  /// object type, e.g., __kindof NSView * or __kindof id\n  /// <NSCopying>.\n  ///\n  /// \\param bound Will be set to the bound on non-id subtype types,\n  /// which will be (possibly specialized) Objective-C class type, or\n  /// null for 'id.\n  bool isObjCIdOrObjectKindOfType(const ASTContext &ctx,\n                                  const ObjCObjectType *&bound) const;\n\n  bool isObjCClassType() const;                 // Class\n\n  /// Whether the type is Objective-C 'Class' or a __kindof type of an\n  /// Class type, e.g., __kindof Class <NSCopying>.\n  ///\n  /// Unlike \\c isObjCIdOrObjectKindOfType, there is no relevant bound\n  /// here because Objective-C's type system cannot express \"a class\n  /// object for a subclass of NSFoo\".\n  bool isObjCClassOrClassKindOfType() const;\n\n  bool isBlockCompatibleObjCPointerType(ASTContext &ctx) const;\n  bool isObjCSelType() const;                 // Class\n  bool isObjCBuiltinType() const;               // 'id' or 'Class'\n  bool isObjCARCBridgableType() const;\n  bool isCARCBridgableType() const;\n  bool isTemplateTypeParmType() const;          // C++ template type parameter\n  bool isNullPtrType() const;                   // C++11 std::nullptr_t\n  bool isNothrowT() const;                      // C++   std::nothrow_t\n  bool isAlignValT() const;                     // C++17 std::align_val_t\n  bool isStdByteType() const;                   // C++17 std::byte\n  bool isAtomicType() const;                    // C11 _Atomic()\n  bool isUndeducedAutoType() const;             // C++11 auto or\n                                                // C++14 decltype(auto)\n  bool isTypedefNameType() const;               // typedef or alias template\n\n#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \\\n  bool is##Id##Type() const;\n#include \"clang/Basic/OpenCLImageTypes.def\"\n\n  bool isImageType() const;                     // Any OpenCL image type\n\n  bool isSamplerT() const;                      // OpenCL sampler_t\n  bool isEventT() const;                        // OpenCL event_t\n  bool isClkEventT() const;                     // OpenCL clk_event_t\n  bool isQueueT() const;                        // OpenCL queue_t\n  bool isReserveIDT() const;                    // OpenCL reserve_id_t\n\n#define EXT_OPAQUE_TYPE(ExtType, Id, Ext) \\\n  bool is##Id##Type() const;\n#include \"clang/Basic/OpenCLExtensionTypes.def\"\n  // Type defined in cl_intel_device_side_avc_motion_estimation OpenCL extension\n  bool isOCLIntelSubgroupAVCType() const;\n  bool isOCLExtOpaqueType() const;              // Any OpenCL extension type\n\n  bool isPipeType() const;                      // OpenCL pipe type\n  bool isExtIntType() const;                    // Extended Int Type\n  bool isOpenCLSpecificType() const;            // Any OpenCL specific type\n\n  /// Determines if this type, which must satisfy\n  /// isObjCLifetimeType(), is implicitly __unsafe_unretained rather\n  /// than implicitly __strong.\n  bool isObjCARCImplicitlyUnretainedType() const;\n\n  /// Check if the type is the CUDA device builtin surface type.\n  bool isCUDADeviceBuiltinSurfaceType() const;\n  /// Check if the type is the CUDA device builtin texture type.\n  bool isCUDADeviceBuiltinTextureType() const;\n\n  /// Return the implicit lifetime for this type, which must not be dependent.\n  Qualifiers::ObjCLifetime getObjCARCImplicitLifetime() const;\n\n  enum ScalarTypeKind {\n    STK_CPointer,\n    STK_BlockPointer,\n    STK_ObjCObjectPointer,\n    STK_MemberPointer,\n    STK_Bool,\n    STK_Integral,\n    STK_Floating,\n    STK_IntegralComplex,\n    STK_FloatingComplex,\n    STK_FixedPoint\n  };\n\n  /// Given that this is a scalar type, classify it.\n  ScalarTypeKind getScalarTypeKind() const;\n\n  TypeDependence getDependence() const {\n    return static_cast<TypeDependence>(TypeBits.Dependence);\n  }\n\n  /// Whether this type is an error type.\n  bool containsErrors() const {\n    return getDependence() & TypeDependence::Error;\n  }\n\n  /// Whether this type is a dependent type, meaning that its definition\n  /// somehow depends on a template parameter (C++ [temp.dep.type]).\n  bool isDependentType() const {\n    return getDependence() & TypeDependence::Dependent;\n  }\n\n  /// Determine whether this type is an instantiation-dependent type,\n  /// meaning that the type involves a template parameter (even if the\n  /// definition does not actually depend on the type substituted for that\n  /// template parameter).\n  bool isInstantiationDependentType() const {\n    return getDependence() & TypeDependence::Instantiation;\n  }\n\n  /// Determine whether this type is an undeduced type, meaning that\n  /// it somehow involves a C++11 'auto' type or similar which has not yet been\n  /// deduced.\n  bool isUndeducedType() const;\n\n  /// Whether this type is a variably-modified type (C99 6.7.5).\n  bool isVariablyModifiedType() const {\n    return getDependence() & TypeDependence::VariablyModified;\n  }\n\n  /// Whether this type involves a variable-length array type\n  /// with a definite size.\n  bool hasSizedVLAType() const;\n\n  /// Whether this type is or contains a local or unnamed type.\n  bool hasUnnamedOrLocalType() const;\n\n  bool isOverloadableType() const;\n\n  /// Determine wither this type is a C++ elaborated-type-specifier.\n  bool isElaboratedTypeSpecifier() const;\n\n  bool canDecayToPointerType() const;\n\n  /// Whether this type is represented natively as a pointer.  This includes\n  /// pointers, references, block pointers, and Objective-C interface,\n  /// qualified id, and qualified interface types, as well as nullptr_t.\n  bool hasPointerRepresentation() const;\n\n  /// Whether this type can represent an objective pointer type for the\n  /// purpose of GC'ability\n  bool hasObjCPointerRepresentation() const;\n\n  /// Determine whether this type has an integer representation\n  /// of some sort, e.g., it is an integer type or a vector.\n  bool hasIntegerRepresentation() const;\n\n  /// Determine whether this type has an signed integer representation\n  /// of some sort, e.g., it is an signed integer type or a vector.\n  bool hasSignedIntegerRepresentation() const;\n\n  /// Determine whether this type has an unsigned integer representation\n  /// of some sort, e.g., it is an unsigned integer type or a vector.\n  bool hasUnsignedIntegerRepresentation() const;\n\n  /// Determine whether this type has a floating-point representation\n  /// of some sort, e.g., it is a floating-point type or a vector thereof.\n  bool hasFloatingRepresentation() const;\n\n  // Type Checking Functions: Check to see if this type is structurally the\n  // specified type, ignoring typedefs and qualifiers, and return a pointer to\n  // the best type we can.\n  const RecordType *getAsStructureType() const;\n  /// NOTE: getAs*ArrayType are methods on ASTContext.\n  const RecordType *getAsUnionType() const;\n  const ComplexType *getAsComplexIntegerType() const; // GCC complex int type.\n  const ObjCObjectType *getAsObjCInterfaceType() const;\n\n  // The following is a convenience method that returns an ObjCObjectPointerType\n  // for object declared using an interface.\n  const ObjCObjectPointerType *getAsObjCInterfacePointerType() const;\n  const ObjCObjectPointerType *getAsObjCQualifiedIdType() const;\n  const ObjCObjectPointerType *getAsObjCQualifiedClassType() const;\n  const ObjCObjectType *getAsObjCQualifiedInterfaceType() const;\n\n  /// Retrieves the CXXRecordDecl that this type refers to, either\n  /// because the type is a RecordType or because it is the injected-class-name\n  /// type of a class template or class template partial specialization.\n  CXXRecordDecl *getAsCXXRecordDecl() const;\n\n  /// Retrieves the RecordDecl this type refers to.\n  RecordDecl *getAsRecordDecl() const;\n\n  /// Retrieves the TagDecl that this type refers to, either\n  /// because the type is a TagType or because it is the injected-class-name\n  /// type of a class template or class template partial specialization.\n  TagDecl *getAsTagDecl() const;\n\n  /// If this is a pointer or reference to a RecordType, return the\n  /// CXXRecordDecl that the type refers to.\n  ///\n  /// If this is not a pointer or reference, or the type being pointed to does\n  /// not refer to a CXXRecordDecl, returns NULL.\n  const CXXRecordDecl *getPointeeCXXRecordDecl() const;\n\n  /// Get the DeducedType whose type will be deduced for a variable with\n  /// an initializer of this type. This looks through declarators like pointer\n  /// types, but not through decltype or typedefs.\n  DeducedType *getContainedDeducedType() const;\n\n  /// Get the AutoType whose type will be deduced for a variable with\n  /// an initializer of this type. This looks through declarators like pointer\n  /// types, but not through decltype or typedefs.\n  AutoType *getContainedAutoType() const {\n    return dyn_cast_or_null<AutoType>(getContainedDeducedType());\n  }\n\n  /// Determine whether this type was written with a leading 'auto'\n  /// corresponding to a trailing return type (possibly for a nested\n  /// function type within a pointer to function type or similar).\n  bool hasAutoForTrailingReturnType() const;\n\n  /// Member-template getAs<specific type>'.  Look through sugar for\n  /// an instance of \\<specific type>.   This scheme will eventually\n  /// replace the specific getAsXXXX methods above.\n  ///\n  /// There are some specializations of this member template listed\n  /// immediately following this class.\n  template <typename T> const T *getAs() const;\n\n  /// Member-template getAsAdjusted<specific type>. Look through specific kinds\n  /// of sugar (parens, attributes, etc) for an instance of \\<specific type>.\n  /// This is used when you need to walk over sugar nodes that represent some\n  /// kind of type adjustment from a type that was written as a \\<specific type>\n  /// to another type that is still canonically a \\<specific type>.\n  template <typename T> const T *getAsAdjusted() const;\n\n  /// A variant of getAs<> for array types which silently discards\n  /// qualifiers from the outermost type.\n  const ArrayType *getAsArrayTypeUnsafe() const;\n\n  /// Member-template castAs<specific type>.  Look through sugar for\n  /// the underlying instance of \\<specific type>.\n  ///\n  /// This method has the same relationship to getAs<T> as cast<T> has\n  /// to dyn_cast<T>; which is to say, the underlying type *must*\n  /// have the intended type, and this method will never return null.\n  template <typename T> const T *castAs() const;\n\n  /// A variant of castAs<> for array type which silently discards\n  /// qualifiers from the outermost type.\n  const ArrayType *castAsArrayTypeUnsafe() const;\n\n  /// Determine whether this type had the specified attribute applied to it\n  /// (looking through top-level type sugar).\n  bool hasAttr(attr::Kind AK) const;\n\n  /// Get the base element type of this type, potentially discarding type\n  /// qualifiers.  This should never be used when type qualifiers\n  /// are meaningful.\n  const Type *getBaseElementTypeUnsafe() const;\n\n  /// If this is an array type, return the element type of the array,\n  /// potentially with type qualifiers missing.\n  /// This should never be used when type qualifiers are meaningful.\n  const Type *getArrayElementTypeNoTypeQual() const;\n\n  /// If this is a pointer type, return the pointee type.\n  /// If this is an array type, return the array element type.\n  /// This should never be used when type qualifiers are meaningful.\n  const Type *getPointeeOrArrayElementType() const;\n\n  /// If this is a pointer, ObjC object pointer, or block\n  /// pointer, this returns the respective pointee.\n  QualType getPointeeType() const;\n\n  /// Return the specified type with any \"sugar\" removed from the type,\n  /// removing any typedefs, typeofs, etc., as well as any qualifiers.\n  const Type *getUnqualifiedDesugaredType() const;\n\n  /// More type predicates useful for type checking/promotion\n  bool isPromotableIntegerType() const; // C99 6.3.1.1p2\n\n  /// Return true if this is an integer type that is\n  /// signed, according to C99 6.2.5p4 [char, signed char, short, int, long..],\n  /// or an enum decl which has a signed representation.\n  bool isSignedIntegerType() const;\n\n  /// Return true if this is an integer type that is\n  /// unsigned, according to C99 6.2.5p6 [which returns true for _Bool],\n  /// or an enum decl which has an unsigned representation.\n  bool isUnsignedIntegerType() const;\n\n  /// Determines whether this is an integer type that is signed or an\n  /// enumeration types whose underlying type is a signed integer type.\n  bool isSignedIntegerOrEnumerationType() const;\n\n  /// Determines whether this is an integer type that is unsigned or an\n  /// enumeration types whose underlying type is a unsigned integer type.\n  bool isUnsignedIntegerOrEnumerationType() const;\n\n  /// Return true if this is a fixed point type according to\n  /// ISO/IEC JTC1 SC22 WG14 N1169.\n  bool isFixedPointType() const;\n\n  /// Return true if this is a fixed point or integer type.\n  bool isFixedPointOrIntegerType() const;\n\n  /// Return true if this is a saturated fixed point type according to\n  /// ISO/IEC JTC1 SC22 WG14 N1169. This type can be signed or unsigned.\n  bool isSaturatedFixedPointType() const;\n\n  /// Return true if this is a saturated fixed point type according to\n  /// ISO/IEC JTC1 SC22 WG14 N1169. This type can be signed or unsigned.\n  bool isUnsaturatedFixedPointType() const;\n\n  /// Return true if this is a fixed point type that is signed according\n  /// to ISO/IEC JTC1 SC22 WG14 N1169. This type can also be saturated.\n  bool isSignedFixedPointType() const;\n\n  /// Return true if this is a fixed point type that is unsigned according\n  /// to ISO/IEC JTC1 SC22 WG14 N1169. This type can also be saturated.\n  bool isUnsignedFixedPointType() const;\n\n  /// Return true if this is not a variable sized type,\n  /// according to the rules of C99 6.7.5p3.  It is not legal to call this on\n  /// incomplete types.\n  bool isConstantSizeType() const;\n\n  /// Returns true if this type can be represented by some\n  /// set of type specifiers.\n  bool isSpecifierType() const;\n\n  /// Determine the linkage of this type.\n  Linkage getLinkage() const;\n\n  /// Determine the visibility of this type.\n  Visibility getVisibility() const {\n    return getLinkageAndVisibility().getVisibility();\n  }\n\n  /// Return true if the visibility was explicitly set is the code.\n  bool isVisibilityExplicit() const {\n    return getLinkageAndVisibility().isVisibilityExplicit();\n  }\n\n  /// Determine the linkage and visibility of this type.\n  LinkageInfo getLinkageAndVisibility() const;\n\n  /// True if the computed linkage is valid. Used for consistency\n  /// checking. Should always return true.\n  bool isLinkageValid() const;\n\n  /// Determine the nullability of the given type.\n  ///\n  /// Note that nullability is only captured as sugar within the type\n  /// system, not as part of the canonical type, so nullability will\n  /// be lost by canonicalization and desugaring.\n  Optional<NullabilityKind> getNullability(const ASTContext &context) const;\n\n  /// Determine whether the given type can have a nullability\n  /// specifier applied to it, i.e., if it is any kind of pointer type.\n  ///\n  /// \\param ResultIfUnknown The value to return if we don't yet know whether\n  ///        this type can have nullability because it is dependent.\n  bool canHaveNullability(bool ResultIfUnknown = true) const;\n\n  /// Retrieve the set of substitutions required when accessing a member\n  /// of the Objective-C receiver type that is declared in the given context.\n  ///\n  /// \\c *this is the type of the object we're operating on, e.g., the\n  /// receiver for a message send or the base of a property access, and is\n  /// expected to be of some object or object pointer type.\n  ///\n  /// \\param dc The declaration context for which we are building up a\n  /// substitution mapping, which should be an Objective-C class, extension,\n  /// category, or method within.\n  ///\n  /// \\returns an array of type arguments that can be substituted for\n  /// the type parameters of the given declaration context in any type described\n  /// within that context, or an empty optional to indicate that no\n  /// substitution is required.\n  Optional<ArrayRef<QualType>>\n  getObjCSubstitutions(const DeclContext *dc) const;\n\n  /// Determines if this is an ObjC interface type that may accept type\n  /// parameters.\n  bool acceptsObjCTypeParams() const;\n\n  const char *getTypeClassName() const;\n\n  QualType getCanonicalTypeInternal() const {\n    return CanonicalType;\n  }\n\n  CanQualType getCanonicalTypeUnqualified() const; // in CanonicalType.h\n  void dump() const;\n  void dump(llvm::raw_ostream &OS, const ASTContext &Context) const;\n};\n\n/// This will check for a TypedefType by removing any existing sugar\n/// until it reaches a TypedefType or a non-sugared type.\ntemplate <> const TypedefType *Type::getAs() const;\n\n/// This will check for a TemplateSpecializationType by removing any\n/// existing sugar until it reaches a TemplateSpecializationType or a\n/// non-sugared type.\ntemplate <> const TemplateSpecializationType *Type::getAs() const;\n\n/// This will check for an AttributedType by removing any existing sugar\n/// until it reaches an AttributedType or a non-sugared type.\ntemplate <> const AttributedType *Type::getAs() const;\n\n// We can do canonical leaf types faster, because we don't have to\n// worry about preserving child type decoration.\n#define TYPE(Class, Base)\n#define LEAF_TYPE(Class) \\\ntemplate <> inline const Class##Type *Type::getAs() const { \\\n  return dyn_cast<Class##Type>(CanonicalType); \\\n} \\\ntemplate <> inline const Class##Type *Type::castAs() const { \\\n  return cast<Class##Type>(CanonicalType); \\\n}\n#include \"clang/AST/TypeNodes.inc\"\n\n/// This class is used for builtin types like 'int'.  Builtin\n/// types are always canonical and have a literal name field.\nclass BuiltinType : public Type {\npublic:\n  enum Kind {\n// OpenCL image types\n#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) Id,\n#include \"clang/Basic/OpenCLImageTypes.def\"\n// OpenCL extension types\n#define EXT_OPAQUE_TYPE(ExtType, Id, Ext) Id,\n#include \"clang/Basic/OpenCLExtensionTypes.def\"\n// SVE Types\n#define SVE_TYPE(Name, Id, SingletonId) Id,\n#include \"clang/Basic/AArch64SVEACLETypes.def\"\n// PPC MMA Types\n#define PPC_VECTOR_TYPE(Name, Id, Size) Id,\n#include \"clang/Basic/PPCTypes.def\"\n// RVV Types\n#define RVV_TYPE(Name, Id, SingletonId) Id,\n#include \"clang/Basic/RISCVVTypes.def\"\n// All other builtin types\n#define BUILTIN_TYPE(Id, SingletonId) Id,\n#define LAST_BUILTIN_TYPE(Id) LastKind = Id\n#include \"clang/AST/BuiltinTypes.def\"\n  };\n\nprivate:\n  friend class ASTContext; // ASTContext creates these.\n\n  BuiltinType(Kind K)\n      : Type(Builtin, QualType(),\n             K == Dependent ? TypeDependence::DependentInstantiation\n                            : TypeDependence::None) {\n    BuiltinTypeBits.Kind = K;\n  }\n\npublic:\n  Kind getKind() const { return static_cast<Kind>(BuiltinTypeBits.Kind); }\n  StringRef getName(const PrintingPolicy &Policy) const;\n\n  const char *getNameAsCString(const PrintingPolicy &Policy) const {\n    // The StringRef is null-terminated.\n    StringRef str = getName(Policy);\n    assert(!str.empty() && str.data()[str.size()] == '\\0');\n    return str.data();\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  bool isInteger() const {\n    return getKind() >= Bool && getKind() <= Int128;\n  }\n\n  bool isSignedInteger() const {\n    return getKind() >= Char_S && getKind() <= Int128;\n  }\n\n  bool isUnsignedInteger() const {\n    return getKind() >= Bool && getKind() <= UInt128;\n  }\n\n  bool isFloatingPoint() const {\n    return getKind() >= Half && getKind() <= Float128;\n  }\n\n  /// Determines whether the given kind corresponds to a placeholder type.\n  static bool isPlaceholderTypeKind(Kind K) {\n    return K >= Overload;\n  }\n\n  /// Determines whether this type is a placeholder type, i.e. a type\n  /// which cannot appear in arbitrary positions in a fully-formed\n  /// expression.\n  bool isPlaceholderType() const {\n    return isPlaceholderTypeKind(getKind());\n  }\n\n  /// Determines whether this type is a placeholder type other than\n  /// Overload.  Most placeholder types require only syntactic\n  /// information about their context in order to be resolved (e.g.\n  /// whether it is a call expression), which means they can (and\n  /// should) be resolved in an earlier \"phase\" of analysis.\n  /// Overload expressions sometimes pick up further information\n  /// from their context, like whether the context expects a\n  /// specific function-pointer type, and so frequently need\n  /// special treatment.\n  bool isNonOverloadPlaceholderType() const {\n    return getKind() > Overload;\n  }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Builtin; }\n};\n\n/// Complex values, per C99 6.2.5p11.  This supports the C99 complex\n/// types (_Complex float etc) as well as the GCC integer complex extensions.\nclass ComplexType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType ElementType;\n\n  ComplexType(QualType Element, QualType CanonicalPtr)\n      : Type(Complex, CanonicalPtr, Element->getDependence()),\n        ElementType(Element) {}\n\npublic:\n  QualType getElementType() const { return ElementType; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getElementType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Element) {\n    ID.AddPointer(Element.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Complex; }\n};\n\n/// Sugar for parentheses used when specifying types.\nclass ParenType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType Inner;\n\n  ParenType(QualType InnerType, QualType CanonType)\n      : Type(Paren, CanonType, InnerType->getDependence()), Inner(InnerType) {}\n\npublic:\n  QualType getInnerType() const { return Inner; }\n\n  bool isSugared() const { return true; }\n  QualType desugar() const { return getInnerType(); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getInnerType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Inner) {\n    Inner.Profile(ID);\n  }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Paren; }\n};\n\n/// PointerType - C99 6.7.5.1 - Pointer Declarators.\nclass PointerType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType PointeeType;\n\n  PointerType(QualType Pointee, QualType CanonicalPtr)\n      : Type(Pointer, CanonicalPtr, Pointee->getDependence()),\n        PointeeType(Pointee) {}\n\npublic:\n  QualType getPointeeType() const { return PointeeType; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getPointeeType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Pointee) {\n    ID.AddPointer(Pointee.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Pointer; }\n};\n\n/// Represents a type which was implicitly adjusted by the semantic\n/// engine for arbitrary reasons.  For example, array and function types can\n/// decay, and function types can have their calling conventions adjusted.\nclass AdjustedType : public Type, public llvm::FoldingSetNode {\n  QualType OriginalTy;\n  QualType AdjustedTy;\n\nprotected:\n  friend class ASTContext; // ASTContext creates these.\n\n  AdjustedType(TypeClass TC, QualType OriginalTy, QualType AdjustedTy,\n               QualType CanonicalPtr)\n      : Type(TC, CanonicalPtr, OriginalTy->getDependence()),\n        OriginalTy(OriginalTy), AdjustedTy(AdjustedTy) {}\n\npublic:\n  QualType getOriginalType() const { return OriginalTy; }\n  QualType getAdjustedType() const { return AdjustedTy; }\n\n  bool isSugared() const { return true; }\n  QualType desugar() const { return AdjustedTy; }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, OriginalTy, AdjustedTy);\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Orig, QualType New) {\n    ID.AddPointer(Orig.getAsOpaquePtr());\n    ID.AddPointer(New.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Adjusted || T->getTypeClass() == Decayed;\n  }\n};\n\n/// Represents a pointer type decayed from an array or function type.\nclass DecayedType : public AdjustedType {\n  friend class ASTContext; // ASTContext creates these.\n\n  inline\n  DecayedType(QualType OriginalType, QualType Decayed, QualType Canonical);\n\npublic:\n  QualType getDecayedType() const { return getAdjustedType(); }\n\n  inline QualType getPointeeType() const;\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Decayed; }\n};\n\n/// Pointer to a block type.\n/// This type is to represent types syntactically represented as\n/// \"void (^)(int)\", etc. Pointee is required to always be a function type.\nclass BlockPointerType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  // Block is some kind of pointer type\n  QualType PointeeType;\n\n  BlockPointerType(QualType Pointee, QualType CanonicalCls)\n      : Type(BlockPointer, CanonicalCls, Pointee->getDependence()),\n        PointeeType(Pointee) {}\n\npublic:\n  // Get the pointee type. Pointee is required to always be a function type.\n  QualType getPointeeType() const { return PointeeType; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n      Profile(ID, getPointeeType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Pointee) {\n      ID.AddPointer(Pointee.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == BlockPointer;\n  }\n};\n\n/// Base for LValueReferenceType and RValueReferenceType\nclass ReferenceType : public Type, public llvm::FoldingSetNode {\n  QualType PointeeType;\n\nprotected:\n  ReferenceType(TypeClass tc, QualType Referencee, QualType CanonicalRef,\n                bool SpelledAsLValue)\n      : Type(tc, CanonicalRef, Referencee->getDependence()),\n        PointeeType(Referencee) {\n    ReferenceTypeBits.SpelledAsLValue = SpelledAsLValue;\n    ReferenceTypeBits.InnerRef = Referencee->isReferenceType();\n  }\n\npublic:\n  bool isSpelledAsLValue() const { return ReferenceTypeBits.SpelledAsLValue; }\n  bool isInnerRef() const { return ReferenceTypeBits.InnerRef; }\n\n  QualType getPointeeTypeAsWritten() const { return PointeeType; }\n\n  QualType getPointeeType() const {\n    // FIXME: this might strip inner qualifiers; okay?\n    const ReferenceType *T = this;\n    while (T->isInnerRef())\n      T = T->PointeeType->castAs<ReferenceType>();\n    return T->PointeeType;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, PointeeType, isSpelledAsLValue());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      QualType Referencee,\n                      bool SpelledAsLValue) {\n    ID.AddPointer(Referencee.getAsOpaquePtr());\n    ID.AddBoolean(SpelledAsLValue);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == LValueReference ||\n           T->getTypeClass() == RValueReference;\n  }\n};\n\n/// An lvalue reference type, per C++11 [dcl.ref].\nclass LValueReferenceType : public ReferenceType {\n  friend class ASTContext; // ASTContext creates these\n\n  LValueReferenceType(QualType Referencee, QualType CanonicalRef,\n                      bool SpelledAsLValue)\n      : ReferenceType(LValueReference, Referencee, CanonicalRef,\n                      SpelledAsLValue) {}\n\npublic:\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == LValueReference;\n  }\n};\n\n/// An rvalue reference type, per C++11 [dcl.ref].\nclass RValueReferenceType : public ReferenceType {\n  friend class ASTContext; // ASTContext creates these\n\n  RValueReferenceType(QualType Referencee, QualType CanonicalRef)\n       : ReferenceType(RValueReference, Referencee, CanonicalRef, false) {}\n\npublic:\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == RValueReference;\n  }\n};\n\n/// A pointer to member type per C++ 8.3.3 - Pointers to members.\n///\n/// This includes both pointers to data members and pointer to member functions.\nclass MemberPointerType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType PointeeType;\n\n  /// The class of which the pointee is a member. Must ultimately be a\n  /// RecordType, but could be a typedef or a template parameter too.\n  const Type *Class;\n\n  MemberPointerType(QualType Pointee, const Type *Cls, QualType CanonicalPtr)\n      : Type(MemberPointer, CanonicalPtr,\n             (Cls->getDependence() & ~TypeDependence::VariablyModified) |\n                 Pointee->getDependence()),\n        PointeeType(Pointee), Class(Cls) {}\n\npublic:\n  QualType getPointeeType() const { return PointeeType; }\n\n  /// Returns true if the member type (i.e. the pointee type) is a\n  /// function type rather than a data-member type.\n  bool isMemberFunctionPointer() const {\n    return PointeeType->isFunctionProtoType();\n  }\n\n  /// Returns true if the member type (i.e. the pointee type) is a\n  /// data type rather than a function type.\n  bool isMemberDataPointer() const {\n    return !PointeeType->isFunctionProtoType();\n  }\n\n  const Type *getClass() const { return Class; }\n  CXXRecordDecl *getMostRecentCXXRecordDecl() const;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getPointeeType(), getClass());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Pointee,\n                      const Type *Class) {\n    ID.AddPointer(Pointee.getAsOpaquePtr());\n    ID.AddPointer(Class);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == MemberPointer;\n  }\n};\n\n/// Represents an array type, per C99 6.7.5.2 - Array Declarators.\nclass ArrayType : public Type, public llvm::FoldingSetNode {\npublic:\n  /// Capture whether this is a normal array (e.g. int X[4])\n  /// an array with a static size (e.g. int X[static 4]), or an array\n  /// with a star size (e.g. int X[*]).\n  /// 'static' is only allowed on function parameters.\n  enum ArraySizeModifier {\n    Normal, Static, Star\n  };\n\nprivate:\n  /// The element type of the array.\n  QualType ElementType;\n\nprotected:\n  friend class ASTContext; // ASTContext creates these.\n\n  ArrayType(TypeClass tc, QualType et, QualType can, ArraySizeModifier sm,\n            unsigned tq, const Expr *sz = nullptr);\n\npublic:\n  QualType getElementType() const { return ElementType; }\n\n  ArraySizeModifier getSizeModifier() const {\n    return ArraySizeModifier(ArrayTypeBits.SizeModifier);\n  }\n\n  Qualifiers getIndexTypeQualifiers() const {\n    return Qualifiers::fromCVRMask(getIndexTypeCVRQualifiers());\n  }\n\n  unsigned getIndexTypeCVRQualifiers() const {\n    return ArrayTypeBits.IndexTypeQuals;\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ConstantArray ||\n           T->getTypeClass() == VariableArray ||\n           T->getTypeClass() == IncompleteArray ||\n           T->getTypeClass() == DependentSizedArray;\n  }\n};\n\n/// Represents the canonical version of C arrays with a specified constant size.\n/// For example, the canonical type for 'int A[4 + 4*100]' is a\n/// ConstantArrayType where the element type is 'int' and the size is 404.\nclass ConstantArrayType final\n    : public ArrayType,\n      private llvm::TrailingObjects<ConstantArrayType, const Expr *> {\n  friend class ASTContext; // ASTContext creates these.\n  friend TrailingObjects;\n\n  llvm::APInt Size; // Allows us to unique the type.\n\n  ConstantArrayType(QualType et, QualType can, const llvm::APInt &size,\n                    const Expr *sz, ArraySizeModifier sm, unsigned tq)\n      : ArrayType(ConstantArray, et, can, sm, tq, sz), Size(size) {\n    ConstantArrayTypeBits.HasStoredSizeExpr = sz != nullptr;\n    if (ConstantArrayTypeBits.HasStoredSizeExpr) {\n      assert(!can.isNull() && \"canonical constant array should not have size\");\n      *getTrailingObjects<const Expr*>() = sz;\n    }\n  }\n\n  unsigned numTrailingObjects(OverloadToken<const Expr*>) const {\n    return ConstantArrayTypeBits.HasStoredSizeExpr;\n  }\n\npublic:\n  const llvm::APInt &getSize() const { return Size; }\n  const Expr *getSizeExpr() const {\n    return ConstantArrayTypeBits.HasStoredSizeExpr\n               ? *getTrailingObjects<const Expr *>()\n               : nullptr;\n  }\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  /// Determine the number of bits required to address a member of\n  // an array with the given element type and number of elements.\n  static unsigned getNumAddressingBits(const ASTContext &Context,\n                                       QualType ElementType,\n                                       const llvm::APInt &NumElements);\n\n  /// Determine the maximum number of active bits that an array's size\n  /// can require, which limits the maximum size of the array.\n  static unsigned getMaxSizeBits(const ASTContext &Context);\n\n  void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Ctx) {\n    Profile(ID, Ctx, getElementType(), getSize(), getSizeExpr(),\n            getSizeModifier(), getIndexTypeCVRQualifiers());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Ctx,\n                      QualType ET, const llvm::APInt &ArraySize,\n                      const Expr *SizeExpr, ArraySizeModifier SizeMod,\n                      unsigned TypeQuals);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ConstantArray;\n  }\n};\n\n/// Represents a C array with an unspecified size.  For example 'int A[]' has\n/// an IncompleteArrayType where the element type is 'int' and the size is\n/// unspecified.\nclass IncompleteArrayType : public ArrayType {\n  friend class ASTContext; // ASTContext creates these.\n\n  IncompleteArrayType(QualType et, QualType can,\n                      ArraySizeModifier sm, unsigned tq)\n      : ArrayType(IncompleteArray, et, can, sm, tq) {}\n\npublic:\n  friend class StmtIteratorBase;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == IncompleteArray;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getElementType(), getSizeModifier(),\n            getIndexTypeCVRQualifiers());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType ET,\n                      ArraySizeModifier SizeMod, unsigned TypeQuals) {\n    ID.AddPointer(ET.getAsOpaquePtr());\n    ID.AddInteger(SizeMod);\n    ID.AddInteger(TypeQuals);\n  }\n};\n\n/// Represents a C array with a specified size that is not an\n/// integer-constant-expression.  For example, 'int s[x+foo()]'.\n/// Since the size expression is an arbitrary expression, we store it as such.\n///\n/// Note: VariableArrayType's aren't uniqued (since the expressions aren't) and\n/// should not be: two lexically equivalent variable array types could mean\n/// different things, for example, these variables do not have the same type\n/// dynamically:\n///\n/// void foo(int x) {\n///   int Y[x];\n///   ++x;\n///   int Z[x];\n/// }\nclass VariableArrayType : public ArrayType {\n  friend class ASTContext; // ASTContext creates these.\n\n  /// An assignment-expression. VLA's are only permitted within\n  /// a function block.\n  Stmt *SizeExpr;\n\n  /// The range spanned by the left and right array brackets.\n  SourceRange Brackets;\n\n  VariableArrayType(QualType et, QualType can, Expr *e,\n                    ArraySizeModifier sm, unsigned tq,\n                    SourceRange brackets)\n      : ArrayType(VariableArray, et, can, sm, tq, e),\n        SizeExpr((Stmt*) e), Brackets(brackets) {}\n\npublic:\n  friend class StmtIteratorBase;\n\n  Expr *getSizeExpr() const {\n    // We use C-style casts instead of cast<> here because we do not wish\n    // to have a dependency of Type.h on Stmt.h/Expr.h.\n    return (Expr*) SizeExpr;\n  }\n\n  SourceRange getBracketsRange() const { return Brackets; }\n  SourceLocation getLBracketLoc() const { return Brackets.getBegin(); }\n  SourceLocation getRBracketLoc() const { return Brackets.getEnd(); }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == VariableArray;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    llvm_unreachable(\"Cannot unique VariableArrayTypes.\");\n  }\n};\n\n/// Represents an array type in C++ whose size is a value-dependent expression.\n///\n/// For example:\n/// \\code\n/// template<typename T, int Size>\n/// class array {\n///   T data[Size];\n/// };\n/// \\endcode\n///\n/// For these types, we won't actually know what the array bound is\n/// until template instantiation occurs, at which point this will\n/// become either a ConstantArrayType or a VariableArrayType.\nclass DependentSizedArrayType : public ArrayType {\n  friend class ASTContext; // ASTContext creates these.\n\n  const ASTContext &Context;\n\n  /// An assignment expression that will instantiate to the\n  /// size of the array.\n  ///\n  /// The expression itself might be null, in which case the array\n  /// type will have its size deduced from an initializer.\n  Stmt *SizeExpr;\n\n  /// The range spanned by the left and right array brackets.\n  SourceRange Brackets;\n\n  DependentSizedArrayType(const ASTContext &Context, QualType et, QualType can,\n                          Expr *e, ArraySizeModifier sm, unsigned tq,\n                          SourceRange brackets);\n\npublic:\n  friend class StmtIteratorBase;\n\n  Expr *getSizeExpr() const {\n    // We use C-style casts instead of cast<> here because we do not wish\n    // to have a dependency of Type.h on Stmt.h/Expr.h.\n    return (Expr*) SizeExpr;\n  }\n\n  SourceRange getBracketsRange() const { return Brackets; }\n  SourceLocation getLBracketLoc() const { return Brackets.getBegin(); }\n  SourceLocation getRBracketLoc() const { return Brackets.getEnd(); }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentSizedArray;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getElementType(),\n            getSizeModifier(), getIndexTypeCVRQualifiers(), getSizeExpr());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      QualType ET, ArraySizeModifier SizeMod,\n                      unsigned TypeQuals, Expr *E);\n};\n\n/// Represents an extended address space qualifier where the input address space\n/// value is dependent. Non-dependent address spaces are not represented with a\n/// special Type subclass; they are stored on an ExtQuals node as part of a QualType.\n///\n/// For example:\n/// \\code\n/// template<typename T, int AddrSpace>\n/// class AddressSpace {\n///   typedef T __attribute__((address_space(AddrSpace))) type;\n/// }\n/// \\endcode\nclass DependentAddressSpaceType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n\n  const ASTContext &Context;\n  Expr *AddrSpaceExpr;\n  QualType PointeeType;\n  SourceLocation loc;\n\n  DependentAddressSpaceType(const ASTContext &Context, QualType PointeeType,\n                            QualType can, Expr *AddrSpaceExpr,\n                            SourceLocation loc);\n\npublic:\n  Expr *getAddrSpaceExpr() const { return AddrSpaceExpr; }\n  QualType getPointeeType() const { return PointeeType; }\n  SourceLocation getAttributeLoc() const { return loc; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentAddressSpace;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getPointeeType(), getAddrSpaceExpr());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      QualType PointeeType, Expr *AddrSpaceExpr);\n};\n\n/// Represents an extended vector type where either the type or size is\n/// dependent.\n///\n/// For example:\n/// \\code\n/// template<typename T, int Size>\n/// class vector {\n///   typedef T __attribute__((ext_vector_type(Size))) type;\n/// }\n/// \\endcode\nclass DependentSizedExtVectorType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n\n  const ASTContext &Context;\n  Expr *SizeExpr;\n\n  /// The element type of the array.\n  QualType ElementType;\n\n  SourceLocation loc;\n\n  DependentSizedExtVectorType(const ASTContext &Context, QualType ElementType,\n                              QualType can, Expr *SizeExpr, SourceLocation loc);\n\npublic:\n  Expr *getSizeExpr() const { return SizeExpr; }\n  QualType getElementType() const { return ElementType; }\n  SourceLocation getAttributeLoc() const { return loc; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentSizedExtVector;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getElementType(), getSizeExpr());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      QualType ElementType, Expr *SizeExpr);\n};\n\n\n/// Represents a GCC generic vector type. This type is created using\n/// __attribute__((vector_size(n)), where \"n\" specifies the vector size in\n/// bytes; or from an Altivec __vector or vector declaration.\n/// Since the constructor takes the number of vector elements, the\n/// client is responsible for converting the size into the number of elements.\nclass VectorType : public Type, public llvm::FoldingSetNode {\npublic:\n  enum VectorKind {\n    /// not a target-specific vector type\n    GenericVector,\n\n    /// is AltiVec vector\n    AltiVecVector,\n\n    /// is AltiVec 'vector Pixel'\n    AltiVecPixel,\n\n    /// is AltiVec 'vector bool ...'\n    AltiVecBool,\n\n    /// is ARM Neon vector\n    NeonVector,\n\n    /// is ARM Neon polynomial vector\n    NeonPolyVector,\n\n    /// is AArch64 SVE fixed-length data vector\n    SveFixedLengthDataVector,\n\n    /// is AArch64 SVE fixed-length predicate vector\n    SveFixedLengthPredicateVector\n  };\n\nprotected:\n  friend class ASTContext; // ASTContext creates these.\n\n  /// The element type of the vector.\n  QualType ElementType;\n\n  VectorType(QualType vecType, unsigned nElements, QualType canonType,\n             VectorKind vecKind);\n\n  VectorType(TypeClass tc, QualType vecType, unsigned nElements,\n             QualType canonType, VectorKind vecKind);\n\npublic:\n  QualType getElementType() const { return ElementType; }\n  unsigned getNumElements() const { return VectorTypeBits.NumElements; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  VectorKind getVectorKind() const {\n    return VectorKind(VectorTypeBits.VecKind);\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getElementType(), getNumElements(),\n            getTypeClass(), getVectorKind());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType ElementType,\n                      unsigned NumElements, TypeClass TypeClass,\n                      VectorKind VecKind) {\n    ID.AddPointer(ElementType.getAsOpaquePtr());\n    ID.AddInteger(NumElements);\n    ID.AddInteger(TypeClass);\n    ID.AddInteger(VecKind);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Vector || T->getTypeClass() == ExtVector;\n  }\n};\n\n/// Represents a vector type where either the type or size is dependent.\n////\n/// For example:\n/// \\code\n/// template<typename T, int Size>\n/// class vector {\n///   typedef T __attribute__((vector_size(Size))) type;\n/// }\n/// \\endcode\nclass DependentVectorType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n\n  const ASTContext &Context;\n  QualType ElementType;\n  Expr *SizeExpr;\n  SourceLocation Loc;\n\n  DependentVectorType(const ASTContext &Context, QualType ElementType,\n                           QualType CanonType, Expr *SizeExpr,\n                           SourceLocation Loc, VectorType::VectorKind vecKind);\n\npublic:\n  Expr *getSizeExpr() const { return SizeExpr; }\n  QualType getElementType() const { return ElementType; }\n  SourceLocation getAttributeLoc() const { return Loc; }\n  VectorType::VectorKind getVectorKind() const {\n    return VectorType::VectorKind(VectorTypeBits.VecKind);\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentVector;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getElementType(), getSizeExpr(), getVectorKind());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      QualType ElementType, const Expr *SizeExpr,\n                      VectorType::VectorKind VecKind);\n};\n\n/// ExtVectorType - Extended vector type. This type is created using\n/// __attribute__((ext_vector_type(n)), where \"n\" is the number of elements.\n/// Unlike vector_size, ext_vector_type is only allowed on typedef's. This\n/// class enables syntactic extensions, like Vector Components for accessing\n/// points (as .xyzw), colors (as .rgba), and textures (modeled after OpenGL\n/// Shading Language).\nclass ExtVectorType : public VectorType {\n  friend class ASTContext; // ASTContext creates these.\n\n  ExtVectorType(QualType vecType, unsigned nElements, QualType canonType)\n      : VectorType(ExtVector, vecType, nElements, canonType, GenericVector) {}\n\npublic:\n  static int getPointAccessorIdx(char c) {\n    switch (c) {\n    default: return -1;\n    case 'x': case 'r': return 0;\n    case 'y': case 'g': return 1;\n    case 'z': case 'b': return 2;\n    case 'w': case 'a': return 3;\n    }\n  }\n\n  static int getNumericAccessorIdx(char c) {\n    switch (c) {\n      default: return -1;\n      case '0': return 0;\n      case '1': return 1;\n      case '2': return 2;\n      case '3': return 3;\n      case '4': return 4;\n      case '5': return 5;\n      case '6': return 6;\n      case '7': return 7;\n      case '8': return 8;\n      case '9': return 9;\n      case 'A':\n      case 'a': return 10;\n      case 'B':\n      case 'b': return 11;\n      case 'C':\n      case 'c': return 12;\n      case 'D':\n      case 'd': return 13;\n      case 'E':\n      case 'e': return 14;\n      case 'F':\n      case 'f': return 15;\n    }\n  }\n\n  static int getAccessorIdx(char c, bool isNumericAccessor) {\n    if (isNumericAccessor)\n      return getNumericAccessorIdx(c);\n    else\n      return getPointAccessorIdx(c);\n  }\n\n  bool isAccessorWithinNumElements(char c, bool isNumericAccessor) const {\n    if (int idx = getAccessorIdx(c, isNumericAccessor)+1)\n      return unsigned(idx-1) < getNumElements();\n    return false;\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ExtVector;\n  }\n};\n\n/// Represents a matrix type, as defined in the Matrix Types clang extensions.\n/// __attribute__((matrix_type(rows, columns))), where \"rows\" specifies\n/// number of rows and \"columns\" specifies the number of columns.\nclass MatrixType : public Type, public llvm::FoldingSetNode {\nprotected:\n  friend class ASTContext;\n\n  /// The element type of the matrix.\n  QualType ElementType;\n\n  MatrixType(QualType ElementTy, QualType CanonElementTy);\n\n  MatrixType(TypeClass TypeClass, QualType ElementTy, QualType CanonElementTy,\n             const Expr *RowExpr = nullptr, const Expr *ColumnExpr = nullptr);\n\npublic:\n  /// Returns type of the elements being stored in the matrix\n  QualType getElementType() const { return ElementType; }\n\n  /// Valid elements types are the following:\n  /// * an integer type (as in C2x 6.2.5p19), but excluding enumerated types\n  ///   and _Bool\n  /// * the standard floating types float or double\n  /// * a half-precision floating point type, if one is supported on the target\n  static bool isValidElementType(QualType T) {\n    return T->isDependentType() ||\n           (T->isRealType() && !T->isBooleanType() && !T->isEnumeralType());\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ConstantMatrix ||\n           T->getTypeClass() == DependentSizedMatrix;\n  }\n};\n\n/// Represents a concrete matrix type with constant number of rows and columns\nclass ConstantMatrixType final : public MatrixType {\nprotected:\n  friend class ASTContext;\n\n  /// The element type of the matrix.\n  // FIXME: Appears to be unused? There is also MatrixType::ElementType...\n  QualType ElementType;\n\n  /// Number of rows and columns.\n  unsigned NumRows;\n  unsigned NumColumns;\n\n  static constexpr unsigned MaxElementsPerDimension = (1 << 20) - 1;\n\n  ConstantMatrixType(QualType MatrixElementType, unsigned NRows,\n                     unsigned NColumns, QualType CanonElementType);\n\n  ConstantMatrixType(TypeClass typeClass, QualType MatrixType, unsigned NRows,\n                     unsigned NColumns, QualType CanonElementType);\n\npublic:\n  /// Returns the number of rows in the matrix.\n  unsigned getNumRows() const { return NumRows; }\n\n  /// Returns the number of columns in the matrix.\n  unsigned getNumColumns() const { return NumColumns; }\n\n  /// Returns the number of elements required to embed the matrix into a vector.\n  unsigned getNumElementsFlattened() const {\n    return getNumRows() * getNumColumns();\n  }\n\n  /// Returns true if \\p NumElements is a valid matrix dimension.\n  static constexpr bool isDimensionValid(size_t NumElements) {\n    return NumElements > 0 && NumElements <= MaxElementsPerDimension;\n  }\n\n  /// Returns the maximum number of elements per dimension.\n  static constexpr unsigned getMaxElementsPerDimension() {\n    return MaxElementsPerDimension;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getElementType(), getNumRows(), getNumColumns(),\n            getTypeClass());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType ElementType,\n                      unsigned NumRows, unsigned NumColumns,\n                      TypeClass TypeClass) {\n    ID.AddPointer(ElementType.getAsOpaquePtr());\n    ID.AddInteger(NumRows);\n    ID.AddInteger(NumColumns);\n    ID.AddInteger(TypeClass);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ConstantMatrix;\n  }\n};\n\n/// Represents a matrix type where the type and the number of rows and columns\n/// is dependent on a template.\nclass DependentSizedMatrixType final : public MatrixType {\n  friend class ASTContext;\n\n  const ASTContext &Context;\n  Expr *RowExpr;\n  Expr *ColumnExpr;\n\n  SourceLocation loc;\n\n  DependentSizedMatrixType(const ASTContext &Context, QualType ElementType,\n                           QualType CanonicalType, Expr *RowExpr,\n                           Expr *ColumnExpr, SourceLocation loc);\n\npublic:\n  QualType getElementType() const { return ElementType; }\n  Expr *getRowExpr() const { return RowExpr; }\n  Expr *getColumnExpr() const { return ColumnExpr; }\n  SourceLocation getAttributeLoc() const { return loc; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentSizedMatrix;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getElementType(), getRowExpr(), getColumnExpr());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      QualType ElementType, Expr *RowExpr, Expr *ColumnExpr);\n};\n\n/// FunctionType - C99 6.7.5.3 - Function Declarators.  This is the common base\n/// class of FunctionNoProtoType and FunctionProtoType.\nclass FunctionType : public Type {\n  // The type returned by the function.\n  QualType ResultType;\n\npublic:\n  /// Interesting information about a specific parameter that can't simply\n  /// be reflected in parameter's type. This is only used by FunctionProtoType\n  /// but is in FunctionType to make this class available during the\n  /// specification of the bases of FunctionProtoType.\n  ///\n  /// It makes sense to model language features this way when there's some\n  /// sort of parameter-specific override (such as an attribute) that\n  /// affects how the function is called.  For example, the ARC ns_consumed\n  /// attribute changes whether a parameter is passed at +0 (the default)\n  /// or +1 (ns_consumed).  This must be reflected in the function type,\n  /// but isn't really a change to the parameter type.\n  ///\n  /// One serious disadvantage of modelling language features this way is\n  /// that they generally do not work with language features that attempt\n  /// to destructure types.  For example, template argument deduction will\n  /// not be able to match a parameter declared as\n  ///   T (*)(U)\n  /// against an argument of type\n  ///   void (*)(__attribute__((ns_consumed)) id)\n  /// because the substitution of T=void, U=id into the former will\n  /// not produce the latter.\n  class ExtParameterInfo {\n    enum {\n      ABIMask = 0x0F,\n      IsConsumed = 0x10,\n      HasPassObjSize = 0x20,\n      IsNoEscape = 0x40,\n    };\n    unsigned char Data = 0;\n\n  public:\n    ExtParameterInfo() = default;\n\n    /// Return the ABI treatment of this parameter.\n    ParameterABI getABI() const { return ParameterABI(Data & ABIMask); }\n    ExtParameterInfo withABI(ParameterABI kind) const {\n      ExtParameterInfo copy = *this;\n      copy.Data = (copy.Data & ~ABIMask) | unsigned(kind);\n      return copy;\n    }\n\n    /// Is this parameter considered \"consumed\" by Objective-C ARC?\n    /// Consumed parameters must have retainable object type.\n    bool isConsumed() const { return (Data & IsConsumed); }\n    ExtParameterInfo withIsConsumed(bool consumed) const {\n      ExtParameterInfo copy = *this;\n      if (consumed)\n        copy.Data |= IsConsumed;\n      else\n        copy.Data &= ~IsConsumed;\n      return copy;\n    }\n\n    bool hasPassObjectSize() const { return Data & HasPassObjSize; }\n    ExtParameterInfo withHasPassObjectSize() const {\n      ExtParameterInfo Copy = *this;\n      Copy.Data |= HasPassObjSize;\n      return Copy;\n    }\n\n    bool isNoEscape() const { return Data & IsNoEscape; }\n    ExtParameterInfo withIsNoEscape(bool NoEscape) const {\n      ExtParameterInfo Copy = *this;\n      if (NoEscape)\n        Copy.Data |= IsNoEscape;\n      else\n        Copy.Data &= ~IsNoEscape;\n      return Copy;\n    }\n\n    unsigned char getOpaqueValue() const { return Data; }\n    static ExtParameterInfo getFromOpaqueValue(unsigned char data) {\n      ExtParameterInfo result;\n      result.Data = data;\n      return result;\n    }\n\n    friend bool operator==(ExtParameterInfo lhs, ExtParameterInfo rhs) {\n      return lhs.Data == rhs.Data;\n    }\n\n    friend bool operator!=(ExtParameterInfo lhs, ExtParameterInfo rhs) {\n      return lhs.Data != rhs.Data;\n    }\n  };\n\n  /// A class which abstracts out some details necessary for\n  /// making a call.\n  ///\n  /// It is not actually used directly for storing this information in\n  /// a FunctionType, although FunctionType does currently use the\n  /// same bit-pattern.\n  ///\n  // If you add a field (say Foo), other than the obvious places (both,\n  // constructors, compile failures), what you need to update is\n  // * Operator==\n  // * getFoo\n  // * withFoo\n  // * functionType. Add Foo, getFoo.\n  // * ASTContext::getFooType\n  // * ASTContext::mergeFunctionTypes\n  // * FunctionNoProtoType::Profile\n  // * FunctionProtoType::Profile\n  // * TypePrinter::PrintFunctionProto\n  // * AST read and write\n  // * Codegen\n  class ExtInfo {\n    friend class FunctionType;\n\n    // Feel free to rearrange or add bits, but if you go over 16, you'll need to\n    // adjust the Bits field below, and if you add bits, you'll need to adjust\n    // Type::FunctionTypeBitfields::ExtInfo as well.\n\n    // |  CC  |noreturn|produces|nocallersavedregs|regparm|nocfcheck|cmsenscall|\n    // |0 .. 4|   5    |    6   |       7         |8 .. 10|    11   |    12    |\n    //\n    // regparm is either 0 (no regparm attribute) or the regparm value+1.\n    enum { CallConvMask = 0x1F };\n    enum { NoReturnMask = 0x20 };\n    enum { ProducesResultMask = 0x40 };\n    enum { NoCallerSavedRegsMask = 0x80 };\n    enum {\n      RegParmMask =  0x700,\n      RegParmOffset = 8\n    };\n    enum { NoCfCheckMask = 0x800 };\n    enum { CmseNSCallMask = 0x1000 };\n    uint16_t Bits = CC_C;\n\n    ExtInfo(unsigned Bits) : Bits(static_cast<uint16_t>(Bits)) {}\n\n  public:\n    // Constructor with no defaults. Use this when you know that you\n    // have all the elements (when reading an AST file for example).\n    ExtInfo(bool noReturn, bool hasRegParm, unsigned regParm, CallingConv cc,\n            bool producesResult, bool noCallerSavedRegs, bool NoCfCheck,\n            bool cmseNSCall) {\n      assert((!hasRegParm || regParm < 7) && \"Invalid regparm value\");\n      Bits = ((unsigned)cc) | (noReturn ? NoReturnMask : 0) |\n             (producesResult ? ProducesResultMask : 0) |\n             (noCallerSavedRegs ? NoCallerSavedRegsMask : 0) |\n             (hasRegParm ? ((regParm + 1) << RegParmOffset) : 0) |\n             (NoCfCheck ? NoCfCheckMask : 0) |\n             (cmseNSCall ? CmseNSCallMask : 0);\n    }\n\n    // Constructor with all defaults. Use when for example creating a\n    // function known to use defaults.\n    ExtInfo() = default;\n\n    // Constructor with just the calling convention, which is an important part\n    // of the canonical type.\n    ExtInfo(CallingConv CC) : Bits(CC) {}\n\n    bool getNoReturn() const { return Bits & NoReturnMask; }\n    bool getProducesResult() const { return Bits & ProducesResultMask; }\n    bool getCmseNSCall() const { return Bits & CmseNSCallMask; }\n    bool getNoCallerSavedRegs() const { return Bits & NoCallerSavedRegsMask; }\n    bool getNoCfCheck() const { return Bits & NoCfCheckMask; }\n    bool getHasRegParm() const { return ((Bits & RegParmMask) >> RegParmOffset) != 0; }\n\n    unsigned getRegParm() const {\n      unsigned RegParm = (Bits & RegParmMask) >> RegParmOffset;\n      if (RegParm > 0)\n        --RegParm;\n      return RegParm;\n    }\n\n    CallingConv getCC() const { return CallingConv(Bits & CallConvMask); }\n\n    bool operator==(ExtInfo Other) const {\n      return Bits == Other.Bits;\n    }\n    bool operator!=(ExtInfo Other) const {\n      return Bits != Other.Bits;\n    }\n\n    // Note that we don't have setters. That is by design, use\n    // the following with methods instead of mutating these objects.\n\n    ExtInfo withNoReturn(bool noReturn) const {\n      if (noReturn)\n        return ExtInfo(Bits | NoReturnMask);\n      else\n        return ExtInfo(Bits & ~NoReturnMask);\n    }\n\n    ExtInfo withProducesResult(bool producesResult) const {\n      if (producesResult)\n        return ExtInfo(Bits | ProducesResultMask);\n      else\n        return ExtInfo(Bits & ~ProducesResultMask);\n    }\n\n    ExtInfo withCmseNSCall(bool cmseNSCall) const {\n      if (cmseNSCall)\n        return ExtInfo(Bits | CmseNSCallMask);\n      else\n        return ExtInfo(Bits & ~CmseNSCallMask);\n    }\n\n    ExtInfo withNoCallerSavedRegs(bool noCallerSavedRegs) const {\n      if (noCallerSavedRegs)\n        return ExtInfo(Bits | NoCallerSavedRegsMask);\n      else\n        return ExtInfo(Bits & ~NoCallerSavedRegsMask);\n    }\n\n    ExtInfo withNoCfCheck(bool noCfCheck) const {\n      if (noCfCheck)\n        return ExtInfo(Bits | NoCfCheckMask);\n      else\n        return ExtInfo(Bits & ~NoCfCheckMask);\n    }\n\n    ExtInfo withRegParm(unsigned RegParm) const {\n      assert(RegParm < 7 && \"Invalid regparm value\");\n      return ExtInfo((Bits & ~RegParmMask) |\n                     ((RegParm + 1) << RegParmOffset));\n    }\n\n    ExtInfo withCallingConv(CallingConv cc) const {\n      return ExtInfo((Bits & ~CallConvMask) | (unsigned) cc);\n    }\n\n    void Profile(llvm::FoldingSetNodeID &ID) const {\n      ID.AddInteger(Bits);\n    }\n  };\n\n  /// A simple holder for a QualType representing a type in an\n  /// exception specification. Unfortunately needed by FunctionProtoType\n  /// because TrailingObjects cannot handle repeated types.\n  struct ExceptionType { QualType Type; };\n\n  /// A simple holder for various uncommon bits which do not fit in\n  /// FunctionTypeBitfields. Aligned to alignof(void *) to maintain the\n  /// alignment of subsequent objects in TrailingObjects. You must update\n  /// hasExtraBitfields in FunctionProtoType after adding extra data here.\n  struct alignas(void *) FunctionTypeExtraBitfields {\n    /// The number of types in the exception specification.\n    /// A whole unsigned is not needed here and according to\n    /// [implimits] 8 bits would be enough here.\n    unsigned NumExceptionType;\n  };\n\nprotected:\n  FunctionType(TypeClass tc, QualType res, QualType Canonical,\n               TypeDependence Dependence, ExtInfo Info)\n      : Type(tc, Canonical, Dependence), ResultType(res) {\n    FunctionTypeBits.ExtInfo = Info.Bits;\n  }\n\n  Qualifiers getFastTypeQuals() const {\n    return Qualifiers::fromFastMask(FunctionTypeBits.FastTypeQuals);\n  }\n\npublic:\n  QualType getReturnType() const { return ResultType; }\n\n  bool getHasRegParm() const { return getExtInfo().getHasRegParm(); }\n  unsigned getRegParmType() const { return getExtInfo().getRegParm(); }\n\n  /// Determine whether this function type includes the GNU noreturn\n  /// attribute. The C++11 [[noreturn]] attribute does not affect the function\n  /// type.\n  bool getNoReturnAttr() const { return getExtInfo().getNoReturn(); }\n\n  bool getCmseNSCallAttr() const { return getExtInfo().getCmseNSCall(); }\n  CallingConv getCallConv() const { return getExtInfo().getCC(); }\n  ExtInfo getExtInfo() const { return ExtInfo(FunctionTypeBits.ExtInfo); }\n\n  static_assert((~Qualifiers::FastMask & Qualifiers::CVRMask) == 0,\n                \"Const, volatile and restrict are assumed to be a subset of \"\n                \"the fast qualifiers.\");\n\n  bool isConst() const { return getFastTypeQuals().hasConst(); }\n  bool isVolatile() const { return getFastTypeQuals().hasVolatile(); }\n  bool isRestrict() const { return getFastTypeQuals().hasRestrict(); }\n\n  /// Determine the type of an expression that calls a function of\n  /// this type.\n  QualType getCallResultType(const ASTContext &Context) const {\n    return getReturnType().getNonLValueExprType(Context);\n  }\n\n  static StringRef getNameForCallConv(CallingConv CC);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == FunctionNoProto ||\n           T->getTypeClass() == FunctionProto;\n  }\n};\n\n/// Represents a K&R-style 'int foo()' function, which has\n/// no information available about its arguments.\nclass FunctionNoProtoType : public FunctionType, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  FunctionNoProtoType(QualType Result, QualType Canonical, ExtInfo Info)\n      : FunctionType(FunctionNoProto, Result, Canonical,\n                     Result->getDependence() &\n                         ~(TypeDependence::DependentInstantiation |\n                           TypeDependence::UnexpandedPack),\n                     Info) {}\n\npublic:\n  // No additional state past what FunctionType provides.\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getReturnType(), getExtInfo());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType ResultType,\n                      ExtInfo Info) {\n    Info.Profile(ID);\n    ID.AddPointer(ResultType.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == FunctionNoProto;\n  }\n};\n\n/// Represents a prototype with parameter type info, e.g.\n/// 'int foo(int)' or 'int foo(void)'.  'void' is represented as having no\n/// parameters, not as having a single void parameter. Such a type can have\n/// an exception specification, but this specification is not part of the\n/// canonical type. FunctionProtoType has several trailing objects, some of\n/// which optional. For more information about the trailing objects see\n/// the first comment inside FunctionProtoType.\nclass FunctionProtoType final\n    : public FunctionType,\n      public llvm::FoldingSetNode,\n      private llvm::TrailingObjects<\n          FunctionProtoType, QualType, SourceLocation,\n          FunctionType::FunctionTypeExtraBitfields, FunctionType::ExceptionType,\n          Expr *, FunctionDecl *, FunctionType::ExtParameterInfo, Qualifiers> {\n  friend class ASTContext; // ASTContext creates these.\n  friend TrailingObjects;\n\n  // FunctionProtoType is followed by several trailing objects, some of\n  // which optional. They are in order:\n  //\n  // * An array of getNumParams() QualType holding the parameter types.\n  //   Always present. Note that for the vast majority of FunctionProtoType,\n  //   these will be the only trailing objects.\n  //\n  // * Optionally if the function is variadic, the SourceLocation of the\n  //   ellipsis.\n  //\n  // * Optionally if some extra data is stored in FunctionTypeExtraBitfields\n  //   (see FunctionTypeExtraBitfields and FunctionTypeBitfields):\n  //   a single FunctionTypeExtraBitfields. Present if and only if\n  //   hasExtraBitfields() is true.\n  //\n  // * Optionally exactly one of:\n  //   * an array of getNumExceptions() ExceptionType,\n  //   * a single Expr *,\n  //   * a pair of FunctionDecl *,\n  //   * a single FunctionDecl *\n  //   used to store information about the various types of exception\n  //   specification. See getExceptionSpecSize for the details.\n  //\n  // * Optionally an array of getNumParams() ExtParameterInfo holding\n  //   an ExtParameterInfo for each of the parameters. Present if and\n  //   only if hasExtParameterInfos() is true.\n  //\n  // * Optionally a Qualifiers object to represent extra qualifiers that can't\n  //   be represented by FunctionTypeBitfields.FastTypeQuals. Present if and only\n  //   if hasExtQualifiers() is true.\n  //\n  // The optional FunctionTypeExtraBitfields has to be before the data\n  // related to the exception specification since it contains the number\n  // of exception types.\n  //\n  // We put the ExtParameterInfos last.  If all were equal, it would make\n  // more sense to put these before the exception specification, because\n  // it's much easier to skip past them compared to the elaborate switch\n  // required to skip the exception specification.  However, all is not\n  // equal; ExtParameterInfos are used to model very uncommon features,\n  // and it's better not to burden the more common paths.\n\npublic:\n  /// Holds information about the various types of exception specification.\n  /// ExceptionSpecInfo is not stored as such in FunctionProtoType but is\n  /// used to group together the various bits of information about the\n  /// exception specification.\n  struct ExceptionSpecInfo {\n    /// The kind of exception specification this is.\n    ExceptionSpecificationType Type = EST_None;\n\n    /// Explicitly-specified list of exception types.\n    ArrayRef<QualType> Exceptions;\n\n    /// Noexcept expression, if this is a computed noexcept specification.\n    Expr *NoexceptExpr = nullptr;\n\n    /// The function whose exception specification this is, for\n    /// EST_Unevaluated and EST_Uninstantiated.\n    FunctionDecl *SourceDecl = nullptr;\n\n    /// The function template whose exception specification this is instantiated\n    /// from, for EST_Uninstantiated.\n    FunctionDecl *SourceTemplate = nullptr;\n\n    ExceptionSpecInfo() = default;\n\n    ExceptionSpecInfo(ExceptionSpecificationType EST) : Type(EST) {}\n  };\n\n  /// Extra information about a function prototype. ExtProtoInfo is not\n  /// stored as such in FunctionProtoType but is used to group together\n  /// the various bits of extra information about a function prototype.\n  struct ExtProtoInfo {\n    FunctionType::ExtInfo ExtInfo;\n    bool Variadic : 1;\n    bool HasTrailingReturn : 1;\n    Qualifiers TypeQuals;\n    RefQualifierKind RefQualifier = RQ_None;\n    ExceptionSpecInfo ExceptionSpec;\n    const ExtParameterInfo *ExtParameterInfos = nullptr;\n    SourceLocation EllipsisLoc;\n\n    ExtProtoInfo() : Variadic(false), HasTrailingReturn(false) {}\n\n    ExtProtoInfo(CallingConv CC)\n        : ExtInfo(CC), Variadic(false), HasTrailingReturn(false) {}\n\n    ExtProtoInfo withExceptionSpec(const ExceptionSpecInfo &ESI) {\n      ExtProtoInfo Result(*this);\n      Result.ExceptionSpec = ESI;\n      return Result;\n    }\n  };\n\nprivate:\n  unsigned numTrailingObjects(OverloadToken<QualType>) const {\n    return getNumParams();\n  }\n\n  unsigned numTrailingObjects(OverloadToken<SourceLocation>) const {\n    return isVariadic();\n  }\n\n  unsigned numTrailingObjects(OverloadToken<FunctionTypeExtraBitfields>) const {\n    return hasExtraBitfields();\n  }\n\n  unsigned numTrailingObjects(OverloadToken<ExceptionType>) const {\n    return getExceptionSpecSize().NumExceptionType;\n  }\n\n  unsigned numTrailingObjects(OverloadToken<Expr *>) const {\n    return getExceptionSpecSize().NumExprPtr;\n  }\n\n  unsigned numTrailingObjects(OverloadToken<FunctionDecl *>) const {\n    return getExceptionSpecSize().NumFunctionDeclPtr;\n  }\n\n  unsigned numTrailingObjects(OverloadToken<ExtParameterInfo>) const {\n    return hasExtParameterInfos() ? getNumParams() : 0;\n  }\n\n  /// Determine whether there are any argument types that\n  /// contain an unexpanded parameter pack.\n  static bool containsAnyUnexpandedParameterPack(const QualType *ArgArray,\n                                                 unsigned numArgs) {\n    for (unsigned Idx = 0; Idx < numArgs; ++Idx)\n      if (ArgArray[Idx]->containsUnexpandedParameterPack())\n        return true;\n\n    return false;\n  }\n\n  FunctionProtoType(QualType result, ArrayRef<QualType> params,\n                    QualType canonical, const ExtProtoInfo &epi);\n\n  /// This struct is returned by getExceptionSpecSize and is used to\n  /// translate an ExceptionSpecificationType to the number and kind\n  /// of trailing objects related to the exception specification.\n  struct ExceptionSpecSizeHolder {\n    unsigned NumExceptionType;\n    unsigned NumExprPtr;\n    unsigned NumFunctionDeclPtr;\n  };\n\n  /// Return the number and kind of trailing objects\n  /// related to the exception specification.\n  static ExceptionSpecSizeHolder\n  getExceptionSpecSize(ExceptionSpecificationType EST, unsigned NumExceptions) {\n    switch (EST) {\n    case EST_None:\n    case EST_DynamicNone:\n    case EST_MSAny:\n    case EST_BasicNoexcept:\n    case EST_Unparsed:\n    case EST_NoThrow:\n      return {0, 0, 0};\n\n    case EST_Dynamic:\n      return {NumExceptions, 0, 0};\n\n    case EST_DependentNoexcept:\n    case EST_NoexceptFalse:\n    case EST_NoexceptTrue:\n      return {0, 1, 0};\n\n    case EST_Uninstantiated:\n      return {0, 0, 2};\n\n    case EST_Unevaluated:\n      return {0, 0, 1};\n    }\n    llvm_unreachable(\"bad exception specification kind\");\n  }\n\n  /// Return the number and kind of trailing objects\n  /// related to the exception specification.\n  ExceptionSpecSizeHolder getExceptionSpecSize() const {\n    return getExceptionSpecSize(getExceptionSpecType(), getNumExceptions());\n  }\n\n  /// Whether the trailing FunctionTypeExtraBitfields is present.\n  static bool hasExtraBitfields(ExceptionSpecificationType EST) {\n    // If the exception spec type is EST_Dynamic then we have > 0 exception\n    // types and the exact number is stored in FunctionTypeExtraBitfields.\n    return EST == EST_Dynamic;\n  }\n\n  /// Whether the trailing FunctionTypeExtraBitfields is present.\n  bool hasExtraBitfields() const {\n    return hasExtraBitfields(getExceptionSpecType());\n  }\n\n  bool hasExtQualifiers() const {\n    return FunctionTypeBits.HasExtQuals;\n  }\n\npublic:\n  unsigned getNumParams() const { return FunctionTypeBits.NumParams; }\n\n  QualType getParamType(unsigned i) const {\n    assert(i < getNumParams() && \"invalid parameter index\");\n    return param_type_begin()[i];\n  }\n\n  ArrayRef<QualType> getParamTypes() const {\n    return llvm::makeArrayRef(param_type_begin(), param_type_end());\n  }\n\n  ExtProtoInfo getExtProtoInfo() const {\n    ExtProtoInfo EPI;\n    EPI.ExtInfo = getExtInfo();\n    EPI.Variadic = isVariadic();\n    EPI.EllipsisLoc = getEllipsisLoc();\n    EPI.HasTrailingReturn = hasTrailingReturn();\n    EPI.ExceptionSpec = getExceptionSpecInfo();\n    EPI.TypeQuals = getMethodQuals();\n    EPI.RefQualifier = getRefQualifier();\n    EPI.ExtParameterInfos = getExtParameterInfosOrNull();\n    return EPI;\n  }\n\n  /// Get the kind of exception specification on this function.\n  ExceptionSpecificationType getExceptionSpecType() const {\n    return static_cast<ExceptionSpecificationType>(\n        FunctionTypeBits.ExceptionSpecType);\n  }\n\n  /// Return whether this function has any kind of exception spec.\n  bool hasExceptionSpec() const { return getExceptionSpecType() != EST_None; }\n\n  /// Return whether this function has a dynamic (throw) exception spec.\n  bool hasDynamicExceptionSpec() const {\n    return isDynamicExceptionSpec(getExceptionSpecType());\n  }\n\n  /// Return whether this function has a noexcept exception spec.\n  bool hasNoexceptExceptionSpec() const {\n    return isNoexceptExceptionSpec(getExceptionSpecType());\n  }\n\n  /// Return whether this function has a dependent exception spec.\n  bool hasDependentExceptionSpec() const;\n\n  /// Return whether this function has an instantiation-dependent exception\n  /// spec.\n  bool hasInstantiationDependentExceptionSpec() const;\n\n  /// Return all the available information about this type's exception spec.\n  ExceptionSpecInfo getExceptionSpecInfo() const {\n    ExceptionSpecInfo Result;\n    Result.Type = getExceptionSpecType();\n    if (Result.Type == EST_Dynamic) {\n      Result.Exceptions = exceptions();\n    } else if (isComputedNoexcept(Result.Type)) {\n      Result.NoexceptExpr = getNoexceptExpr();\n    } else if (Result.Type == EST_Uninstantiated) {\n      Result.SourceDecl = getExceptionSpecDecl();\n      Result.SourceTemplate = getExceptionSpecTemplate();\n    } else if (Result.Type == EST_Unevaluated) {\n      Result.SourceDecl = getExceptionSpecDecl();\n    }\n    return Result;\n  }\n\n  /// Return the number of types in the exception specification.\n  unsigned getNumExceptions() const {\n    return getExceptionSpecType() == EST_Dynamic\n               ? getTrailingObjects<FunctionTypeExtraBitfields>()\n                     ->NumExceptionType\n               : 0;\n  }\n\n  /// Return the ith exception type, where 0 <= i < getNumExceptions().\n  QualType getExceptionType(unsigned i) const {\n    assert(i < getNumExceptions() && \"Invalid exception number!\");\n    return exception_begin()[i];\n  }\n\n  /// Return the expression inside noexcept(expression), or a null pointer\n  /// if there is none (because the exception spec is not of this form).\n  Expr *getNoexceptExpr() const {\n    if (!isComputedNoexcept(getExceptionSpecType()))\n      return nullptr;\n    return *getTrailingObjects<Expr *>();\n  }\n\n  /// If this function type has an exception specification which hasn't\n  /// been determined yet (either because it has not been evaluated or because\n  /// it has not been instantiated), this is the function whose exception\n  /// specification is represented by this type.\n  FunctionDecl *getExceptionSpecDecl() const {\n    if (getExceptionSpecType() != EST_Uninstantiated &&\n        getExceptionSpecType() != EST_Unevaluated)\n      return nullptr;\n    return getTrailingObjects<FunctionDecl *>()[0];\n  }\n\n  /// If this function type has an uninstantiated exception\n  /// specification, this is the function whose exception specification\n  /// should be instantiated to find the exception specification for\n  /// this type.\n  FunctionDecl *getExceptionSpecTemplate() const {\n    if (getExceptionSpecType() != EST_Uninstantiated)\n      return nullptr;\n    return getTrailingObjects<FunctionDecl *>()[1];\n  }\n\n  /// Determine whether this function type has a non-throwing exception\n  /// specification.\n  CanThrowResult canThrow() const;\n\n  /// Determine whether this function type has a non-throwing exception\n  /// specification. If this depends on template arguments, returns\n  /// \\c ResultIfDependent.\n  bool isNothrow(bool ResultIfDependent = false) const {\n    return ResultIfDependent ? canThrow() != CT_Can : canThrow() == CT_Cannot;\n  }\n\n  /// Whether this function prototype is variadic.\n  bool isVariadic() const { return FunctionTypeBits.Variadic; }\n\n  SourceLocation getEllipsisLoc() const {\n    return isVariadic() ? *getTrailingObjects<SourceLocation>()\n                        : SourceLocation();\n  }\n\n  /// Determines whether this function prototype contains a\n  /// parameter pack at the end.\n  ///\n  /// A function template whose last parameter is a parameter pack can be\n  /// called with an arbitrary number of arguments, much like a variadic\n  /// function.\n  bool isTemplateVariadic() const;\n\n  /// Whether this function prototype has a trailing return type.\n  bool hasTrailingReturn() const { return FunctionTypeBits.HasTrailingReturn; }\n\n  Qualifiers getMethodQuals() const {\n    if (hasExtQualifiers())\n      return *getTrailingObjects<Qualifiers>();\n    else\n      return getFastTypeQuals();\n  }\n\n  /// Retrieve the ref-qualifier associated with this function type.\n  RefQualifierKind getRefQualifier() const {\n    return static_cast<RefQualifierKind>(FunctionTypeBits.RefQualifier);\n  }\n\n  using param_type_iterator = const QualType *;\n  using param_type_range = llvm::iterator_range<param_type_iterator>;\n\n  param_type_range param_types() const {\n    return param_type_range(param_type_begin(), param_type_end());\n  }\n\n  param_type_iterator param_type_begin() const {\n    return getTrailingObjects<QualType>();\n  }\n\n  param_type_iterator param_type_end() const {\n    return param_type_begin() + getNumParams();\n  }\n\n  using exception_iterator = const QualType *;\n\n  ArrayRef<QualType> exceptions() const {\n    return llvm::makeArrayRef(exception_begin(), exception_end());\n  }\n\n  exception_iterator exception_begin() const {\n    return reinterpret_cast<exception_iterator>(\n        getTrailingObjects<ExceptionType>());\n  }\n\n  exception_iterator exception_end() const {\n    return exception_begin() + getNumExceptions();\n  }\n\n  /// Is there any interesting extra information for any of the parameters\n  /// of this function type?\n  bool hasExtParameterInfos() const {\n    return FunctionTypeBits.HasExtParameterInfos;\n  }\n\n  ArrayRef<ExtParameterInfo> getExtParameterInfos() const {\n    assert(hasExtParameterInfos());\n    return ArrayRef<ExtParameterInfo>(getTrailingObjects<ExtParameterInfo>(),\n                                      getNumParams());\n  }\n\n  /// Return a pointer to the beginning of the array of extra parameter\n  /// information, if present, or else null if none of the parameters\n  /// carry it.  This is equivalent to getExtProtoInfo().ExtParameterInfos.\n  const ExtParameterInfo *getExtParameterInfosOrNull() const {\n    if (!hasExtParameterInfos())\n      return nullptr;\n    return getTrailingObjects<ExtParameterInfo>();\n  }\n\n  ExtParameterInfo getExtParameterInfo(unsigned I) const {\n    assert(I < getNumParams() && \"parameter index out of range\");\n    if (hasExtParameterInfos())\n      return getTrailingObjects<ExtParameterInfo>()[I];\n    return ExtParameterInfo();\n  }\n\n  ParameterABI getParameterABI(unsigned I) const {\n    assert(I < getNumParams() && \"parameter index out of range\");\n    if (hasExtParameterInfos())\n      return getTrailingObjects<ExtParameterInfo>()[I].getABI();\n    return ParameterABI::Ordinary;\n  }\n\n  bool isParamConsumed(unsigned I) const {\n    assert(I < getNumParams() && \"parameter index out of range\");\n    if (hasExtParameterInfos())\n      return getTrailingObjects<ExtParameterInfo>()[I].isConsumed();\n    return false;\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void printExceptionSpecification(raw_ostream &OS,\n                                   const PrintingPolicy &Policy) const;\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == FunctionProto;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Ctx);\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Result,\n                      param_type_iterator ArgTys, unsigned NumArgs,\n                      const ExtProtoInfo &EPI, const ASTContext &Context,\n                      bool Canonical);\n};\n\n/// Represents the dependent type named by a dependently-scoped\n/// typename using declaration, e.g.\n///   using typename Base<T>::foo;\n///\n/// Template instantiation turns these into the underlying type.\nclass UnresolvedUsingType : public Type {\n  friend class ASTContext; // ASTContext creates these.\n\n  UnresolvedUsingTypenameDecl *Decl;\n\n  UnresolvedUsingType(const UnresolvedUsingTypenameDecl *D)\n      : Type(UnresolvedUsing, QualType(),\n             TypeDependence::DependentInstantiation),\n        Decl(const_cast<UnresolvedUsingTypenameDecl *>(D)) {}\n\npublic:\n  UnresolvedUsingTypenameDecl *getDecl() const { return Decl; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == UnresolvedUsing;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    return Profile(ID, Decl);\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      UnresolvedUsingTypenameDecl *D) {\n    ID.AddPointer(D);\n  }\n};\n\nclass TypedefType : public Type {\n  TypedefNameDecl *Decl;\n\nprivate:\n  friend class ASTContext; // ASTContext creates these.\n\n  TypedefType(TypeClass tc, const TypedefNameDecl *D, QualType underlying,\n              QualType can);\n\npublic:\n  TypedefNameDecl *getDecl() const { return Decl; }\n\n  bool isSugared() const { return true; }\n  QualType desugar() const;\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Typedef; }\n};\n\n/// Sugar type that represents a type that was qualified by a qualifier written\n/// as a macro invocation.\nclass MacroQualifiedType : public Type {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType UnderlyingTy;\n  const IdentifierInfo *MacroII;\n\n  MacroQualifiedType(QualType UnderlyingTy, QualType CanonTy,\n                     const IdentifierInfo *MacroII)\n      : Type(MacroQualified, CanonTy, UnderlyingTy->getDependence()),\n        UnderlyingTy(UnderlyingTy), MacroII(MacroII) {\n    assert(isa<AttributedType>(UnderlyingTy) &&\n           \"Expected a macro qualified type to only wrap attributed types.\");\n  }\n\npublic:\n  const IdentifierInfo *getMacroIdentifier() const { return MacroII; }\n  QualType getUnderlyingType() const { return UnderlyingTy; }\n\n  /// Return this attributed type's modified type with no qualifiers attached to\n  /// it.\n  QualType getModifiedType() const;\n\n  bool isSugared() const { return true; }\n  QualType desugar() const;\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == MacroQualified;\n  }\n};\n\n/// Represents a `typeof` (or __typeof__) expression (a GCC extension).\nclass TypeOfExprType : public Type {\n  Expr *TOExpr;\n\nprotected:\n  friend class ASTContext; // ASTContext creates these.\n\n  TypeOfExprType(Expr *E, QualType can = QualType());\n\npublic:\n  Expr *getUnderlyingExpr() const { return TOExpr; }\n\n  /// Remove a single level of sugar.\n  QualType desugar() const;\n\n  /// Returns whether this type directly provides sugar.\n  bool isSugared() const;\n\n  static bool classof(const Type *T) { return T->getTypeClass() == TypeOfExpr; }\n};\n\n/// Internal representation of canonical, dependent\n/// `typeof(expr)` types.\n///\n/// This class is used internally by the ASTContext to manage\n/// canonical, dependent types, only. Clients will only see instances\n/// of this class via TypeOfExprType nodes.\nclass DependentTypeOfExprType\n  : public TypeOfExprType, public llvm::FoldingSetNode {\n  const ASTContext &Context;\n\npublic:\n  DependentTypeOfExprType(const ASTContext &Context, Expr *E)\n      : TypeOfExprType(E), Context(Context) {}\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getUnderlyingExpr());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      Expr *E);\n};\n\n/// Represents `typeof(type)`, a GCC extension.\nclass TypeOfType : public Type {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType TOType;\n\n  TypeOfType(QualType T, QualType can)\n      : Type(TypeOf, can, T->getDependence()), TOType(T) {\n    assert(!isa<TypedefType>(can) && \"Invalid canonical type\");\n  }\n\npublic:\n  QualType getUnderlyingType() const { return TOType; }\n\n  /// Remove a single level of sugar.\n  QualType desugar() const { return getUnderlyingType(); }\n\n  /// Returns whether this type directly provides sugar.\n  bool isSugared() const { return true; }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == TypeOf; }\n};\n\n/// Represents the type `decltype(expr)` (C++11).\nclass DecltypeType : public Type {\n  Expr *E;\n  QualType UnderlyingType;\n\nprotected:\n  friend class ASTContext; // ASTContext creates these.\n\n  DecltypeType(Expr *E, QualType underlyingType, QualType can = QualType());\n\npublic:\n  Expr *getUnderlyingExpr() const { return E; }\n  QualType getUnderlyingType() const { return UnderlyingType; }\n\n  /// Remove a single level of sugar.\n  QualType desugar() const;\n\n  /// Returns whether this type directly provides sugar.\n  bool isSugared() const;\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Decltype; }\n};\n\n/// Internal representation of canonical, dependent\n/// decltype(expr) types.\n///\n/// This class is used internally by the ASTContext to manage\n/// canonical, dependent types, only. Clients will only see instances\n/// of this class via DecltypeType nodes.\nclass DependentDecltypeType : public DecltypeType, public llvm::FoldingSetNode {\n  const ASTContext &Context;\n\npublic:\n  DependentDecltypeType(const ASTContext &Context, Expr *E);\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, getUnderlyingExpr());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      Expr *E);\n};\n\n/// A unary type transform, which is a type constructed from another.\nclass UnaryTransformType : public Type {\npublic:\n  enum UTTKind {\n    EnumUnderlyingType\n  };\n\nprivate:\n  /// The untransformed type.\n  QualType BaseType;\n\n  /// The transformed type if not dependent, otherwise the same as BaseType.\n  QualType UnderlyingType;\n\n  UTTKind UKind;\n\nprotected:\n  friend class ASTContext;\n\n  UnaryTransformType(QualType BaseTy, QualType UnderlyingTy, UTTKind UKind,\n                     QualType CanonicalTy);\n\npublic:\n  bool isSugared() const { return !isDependentType(); }\n  QualType desugar() const { return UnderlyingType; }\n\n  QualType getUnderlyingType() const { return UnderlyingType; }\n  QualType getBaseType() const { return BaseType; }\n\n  UTTKind getUTTKind() const { return UKind; }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == UnaryTransform;\n  }\n};\n\n/// Internal representation of canonical, dependent\n/// __underlying_type(type) types.\n///\n/// This class is used internally by the ASTContext to manage\n/// canonical, dependent types, only. Clients will only see instances\n/// of this class via UnaryTransformType nodes.\nclass DependentUnaryTransformType : public UnaryTransformType,\n                                    public llvm::FoldingSetNode {\npublic:\n  DependentUnaryTransformType(const ASTContext &C, QualType BaseType,\n                              UTTKind UKind);\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getBaseType(), getUTTKind());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType BaseType,\n                      UTTKind UKind) {\n    ID.AddPointer(BaseType.getAsOpaquePtr());\n    ID.AddInteger((unsigned)UKind);\n  }\n};\n\nclass TagType : public Type {\n  friend class ASTReader;\n  template <class T> friend class serialization::AbstractTypeReader;\n\n  /// Stores the TagDecl associated with this type. The decl may point to any\n  /// TagDecl that declares the entity.\n  TagDecl *decl;\n\nprotected:\n  TagType(TypeClass TC, const TagDecl *D, QualType can);\n\npublic:\n  TagDecl *getDecl() const;\n\n  /// Determines whether this type is in the process of being defined.\n  bool isBeingDefined() const;\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Enum || T->getTypeClass() == Record;\n  }\n};\n\n/// A helper class that allows the use of isa/cast/dyncast\n/// to detect TagType objects of structs/unions/classes.\nclass RecordType : public TagType {\nprotected:\n  friend class ASTContext; // ASTContext creates these.\n\n  explicit RecordType(const RecordDecl *D)\n      : TagType(Record, reinterpret_cast<const TagDecl*>(D), QualType()) {}\n  explicit RecordType(TypeClass TC, RecordDecl *D)\n      : TagType(TC, reinterpret_cast<const TagDecl*>(D), QualType()) {}\n\npublic:\n  RecordDecl *getDecl() const {\n    return reinterpret_cast<RecordDecl*>(TagType::getDecl());\n  }\n\n  /// Recursively check all fields in the record for const-ness. If any field\n  /// is declared const, return true. Otherwise, return false.\n  bool hasConstFields() const;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Record; }\n};\n\n/// A helper class that allows the use of isa/cast/dyncast\n/// to detect TagType objects of enums.\nclass EnumType : public TagType {\n  friend class ASTContext; // ASTContext creates these.\n\n  explicit EnumType(const EnumDecl *D)\n      : TagType(Enum, reinterpret_cast<const TagDecl*>(D), QualType()) {}\n\npublic:\n  EnumDecl *getDecl() const {\n    return reinterpret_cast<EnumDecl*>(TagType::getDecl());\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Enum; }\n};\n\n/// An attributed type is a type to which a type attribute has been applied.\n///\n/// The \"modified type\" is the fully-sugared type to which the attributed\n/// type was applied; generally it is not canonically equivalent to the\n/// attributed type. The \"equivalent type\" is the minimally-desugared type\n/// which the type is canonically equivalent to.\n///\n/// For example, in the following attributed type:\n///     int32_t __attribute__((vector_size(16)))\n///   - the modified type is the TypedefType for int32_t\n///   - the equivalent type is VectorType(16, int32_t)\n///   - the canonical type is VectorType(16, int)\nclass AttributedType : public Type, public llvm::FoldingSetNode {\npublic:\n  using Kind = attr::Kind;\n\nprivate:\n  friend class ASTContext; // ASTContext creates these\n\n  QualType ModifiedType;\n  QualType EquivalentType;\n\n  AttributedType(QualType canon, attr::Kind attrKind, QualType modified,\n                 QualType equivalent)\n      : Type(Attributed, canon, equivalent->getDependence()),\n        ModifiedType(modified), EquivalentType(equivalent) {\n    AttributedTypeBits.AttrKind = attrKind;\n  }\n\npublic:\n  Kind getAttrKind() const {\n    return static_cast<Kind>(AttributedTypeBits.AttrKind);\n  }\n\n  QualType getModifiedType() const { return ModifiedType; }\n  QualType getEquivalentType() const { return EquivalentType; }\n\n  bool isSugared() const { return true; }\n  QualType desugar() const { return getEquivalentType(); }\n\n  /// Does this attribute behave like a type qualifier?\n  ///\n  /// A type qualifier adjusts a type to provide specialized rules for\n  /// a specific object, like the standard const and volatile qualifiers.\n  /// This includes attributes controlling things like nullability,\n  /// address spaces, and ARC ownership.  The value of the object is still\n  /// largely described by the modified type.\n  ///\n  /// In contrast, many type attributes \"rewrite\" their modified type to\n  /// produce a fundamentally different type, not necessarily related in any\n  /// formalizable way to the original type.  For example, calling convention\n  /// and vector attributes are not simple type qualifiers.\n  ///\n  /// Type qualifiers are often, but not always, reflected in the canonical\n  /// type.\n  bool isQualifier() const;\n\n  bool isMSTypeSpec() const;\n\n  bool isCallingConv() const;\n\n  llvm::Optional<NullabilityKind> getImmediateNullability() const;\n\n  /// Retrieve the attribute kind corresponding to the given\n  /// nullability kind.\n  static Kind getNullabilityAttrKind(NullabilityKind kind) {\n    switch (kind) {\n    case NullabilityKind::NonNull:\n      return attr::TypeNonNull;\n\n    case NullabilityKind::Nullable:\n      return attr::TypeNullable;\n\n    case NullabilityKind::NullableResult:\n      return attr::TypeNullableResult;\n\n    case NullabilityKind::Unspecified:\n      return attr::TypeNullUnspecified;\n    }\n    llvm_unreachable(\"Unknown nullability kind.\");\n  }\n\n  /// Strip off the top-level nullability annotation on the given\n  /// type, if it's there.\n  ///\n  /// \\param T The type to strip. If the type is exactly an\n  /// AttributedType specifying nullability (without looking through\n  /// type sugar), the nullability is returned and this type changed\n  /// to the underlying modified type.\n  ///\n  /// \\returns the top-level nullability, if present.\n  static Optional<NullabilityKind> stripOuterNullability(QualType &T);\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getAttrKind(), ModifiedType, EquivalentType);\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, Kind attrKind,\n                      QualType modified, QualType equivalent) {\n    ID.AddInteger(attrKind);\n    ID.AddPointer(modified.getAsOpaquePtr());\n    ID.AddPointer(equivalent.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Attributed;\n  }\n};\n\nclass TemplateTypeParmType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  // Helper data collector for canonical types.\n  struct CanonicalTTPTInfo {\n    unsigned Depth : 15;\n    unsigned ParameterPack : 1;\n    unsigned Index : 16;\n  };\n\n  union {\n    // Info for the canonical type.\n    CanonicalTTPTInfo CanTTPTInfo;\n\n    // Info for the non-canonical type.\n    TemplateTypeParmDecl *TTPDecl;\n  };\n\n  /// Build a non-canonical type.\n  TemplateTypeParmType(TemplateTypeParmDecl *TTPDecl, QualType Canon)\n      : Type(TemplateTypeParm, Canon,\n             TypeDependence::DependentInstantiation |\n                 (Canon->getDependence() & TypeDependence::UnexpandedPack)),\n        TTPDecl(TTPDecl) {}\n\n  /// Build the canonical type.\n  TemplateTypeParmType(unsigned D, unsigned I, bool PP)\n      : Type(TemplateTypeParm, QualType(this, 0),\n             TypeDependence::DependentInstantiation |\n                 (PP ? TypeDependence::UnexpandedPack : TypeDependence::None)) {\n    CanTTPTInfo.Depth = D;\n    CanTTPTInfo.Index = I;\n    CanTTPTInfo.ParameterPack = PP;\n  }\n\n  const CanonicalTTPTInfo& getCanTTPTInfo() const {\n    QualType Can = getCanonicalTypeInternal();\n    return Can->castAs<TemplateTypeParmType>()->CanTTPTInfo;\n  }\n\npublic:\n  unsigned getDepth() const { return getCanTTPTInfo().Depth; }\n  unsigned getIndex() const { return getCanTTPTInfo().Index; }\n  bool isParameterPack() const { return getCanTTPTInfo().ParameterPack; }\n\n  TemplateTypeParmDecl *getDecl() const {\n    return isCanonicalUnqualified() ? nullptr : TTPDecl;\n  }\n\n  IdentifierInfo *getIdentifier() const;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getDepth(), getIndex(), isParameterPack(), getDecl());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, unsigned Depth,\n                      unsigned Index, bool ParameterPack,\n                      TemplateTypeParmDecl *TTPDecl) {\n    ID.AddInteger(Depth);\n    ID.AddInteger(Index);\n    ID.AddBoolean(ParameterPack);\n    ID.AddPointer(TTPDecl);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == TemplateTypeParm;\n  }\n};\n\n/// Represents the result of substituting a type for a template\n/// type parameter.\n///\n/// Within an instantiated template, all template type parameters have\n/// been replaced with these.  They are used solely to record that a\n/// type was originally written as a template type parameter;\n/// therefore they are never canonical.\nclass SubstTemplateTypeParmType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n\n  // The original type parameter.\n  const TemplateTypeParmType *Replaced;\n\n  SubstTemplateTypeParmType(const TemplateTypeParmType *Param, QualType Canon)\n      : Type(SubstTemplateTypeParm, Canon, Canon->getDependence()),\n        Replaced(Param) {}\n\npublic:\n  /// Gets the template parameter that was substituted for.\n  const TemplateTypeParmType *getReplacedParameter() const {\n    return Replaced;\n  }\n\n  /// Gets the type that was substituted for the template\n  /// parameter.\n  QualType getReplacementType() const {\n    return getCanonicalTypeInternal();\n  }\n\n  bool isSugared() const { return true; }\n  QualType desugar() const { return getReplacementType(); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getReplacedParameter(), getReplacementType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      const TemplateTypeParmType *Replaced,\n                      QualType Replacement) {\n    ID.AddPointer(Replaced);\n    ID.AddPointer(Replacement.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == SubstTemplateTypeParm;\n  }\n};\n\n/// Represents the result of substituting a set of types for a template\n/// type parameter pack.\n///\n/// When a pack expansion in the source code contains multiple parameter packs\n/// and those parameter packs correspond to different levels of template\n/// parameter lists, this type node is used to represent a template type\n/// parameter pack from an outer level, which has already had its argument pack\n/// substituted but that still lives within a pack expansion that itself\n/// could not be instantiated. When actually performing a substitution into\n/// that pack expansion (e.g., when all template parameters have corresponding\n/// arguments), this type will be replaced with the \\c SubstTemplateTypeParmType\n/// at the current pack substitution index.\nclass SubstTemplateTypeParmPackType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n\n  /// The original type parameter.\n  const TemplateTypeParmType *Replaced;\n\n  /// A pointer to the set of template arguments that this\n  /// parameter pack is instantiated with.\n  const TemplateArgument *Arguments;\n\n  SubstTemplateTypeParmPackType(const TemplateTypeParmType *Param,\n                                QualType Canon,\n                                const TemplateArgument &ArgPack);\n\npublic:\n  IdentifierInfo *getIdentifier() const { return Replaced->getIdentifier(); }\n\n  /// Gets the template parameter that was substituted for.\n  const TemplateTypeParmType *getReplacedParameter() const {\n    return Replaced;\n  }\n\n  unsigned getNumArgs() const {\n    return SubstTemplateTypeParmPackTypeBits.NumArgs;\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  TemplateArgument getArgumentPack() const;\n\n  void Profile(llvm::FoldingSetNodeID &ID);\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      const TemplateTypeParmType *Replaced,\n                      const TemplateArgument &ArgPack);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == SubstTemplateTypeParmPack;\n  }\n};\n\n/// Common base class for placeholders for types that get replaced by\n/// placeholder type deduction: C++11 auto, C++14 decltype(auto), C++17 deduced\n/// class template types, and constrained type names.\n///\n/// These types are usually a placeholder for a deduced type. However, before\n/// the initializer is attached, or (usually) if the initializer is\n/// type-dependent, there is no deduced type and the type is canonical. In\n/// the latter case, it is also a dependent type.\nclass DeducedType : public Type {\nprotected:\n  DeducedType(TypeClass TC, QualType DeducedAsType,\n              TypeDependence ExtraDependence)\n      : Type(TC,\n             // FIXME: Retain the sugared deduced type?\n             DeducedAsType.isNull() ? QualType(this, 0)\n                                    : DeducedAsType.getCanonicalType(),\n             ExtraDependence | (DeducedAsType.isNull()\n                                    ? TypeDependence::None\n                                    : DeducedAsType->getDependence() &\n                                          ~TypeDependence::VariablyModified)) {}\n\npublic:\n  bool isSugared() const { return !isCanonicalUnqualified(); }\n  QualType desugar() const { return getCanonicalTypeInternal(); }\n\n  /// Get the type deduced for this placeholder type, or null if it's\n  /// either not been deduced or was deduced to a dependent type.\n  QualType getDeducedType() const {\n    return !isCanonicalUnqualified() ? getCanonicalTypeInternal() : QualType();\n  }\n  bool isDeduced() const {\n    return !isCanonicalUnqualified() || isDependentType();\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Auto ||\n           T->getTypeClass() == DeducedTemplateSpecialization;\n  }\n};\n\n/// Represents a C++11 auto or C++14 decltype(auto) type, possibly constrained\n/// by a type-constraint.\nclass alignas(8) AutoType : public DeducedType, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  ConceptDecl *TypeConstraintConcept;\n\n  AutoType(QualType DeducedAsType, AutoTypeKeyword Keyword,\n           TypeDependence ExtraDependence, ConceptDecl *CD,\n           ArrayRef<TemplateArgument> TypeConstraintArgs);\n\n  const TemplateArgument *getArgBuffer() const {\n    return reinterpret_cast<const TemplateArgument*>(this+1);\n  }\n\n  TemplateArgument *getArgBuffer() {\n    return reinterpret_cast<TemplateArgument*>(this+1);\n  }\n\npublic:\n  /// Retrieve the template arguments.\n  const TemplateArgument *getArgs() const {\n    return getArgBuffer();\n  }\n\n  /// Retrieve the number of template arguments.\n  unsigned getNumArgs() const {\n    return AutoTypeBits.NumArgs;\n  }\n\n  const TemplateArgument &getArg(unsigned Idx) const; // in TemplateBase.h\n\n  ArrayRef<TemplateArgument> getTypeConstraintArguments() const {\n    return {getArgs(), getNumArgs()};\n  }\n\n  ConceptDecl *getTypeConstraintConcept() const {\n    return TypeConstraintConcept;\n  }\n\n  bool isConstrained() const {\n    return TypeConstraintConcept != nullptr;\n  }\n\n  bool isDecltypeAuto() const {\n    return getKeyword() == AutoTypeKeyword::DecltypeAuto;\n  }\n\n  AutoTypeKeyword getKeyword() const {\n    return (AutoTypeKeyword)AutoTypeBits.Keyword;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context) {\n    Profile(ID, Context, getDeducedType(), getKeyword(), isDependentType(),\n            getTypeConstraintConcept(), getTypeConstraintArguments());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      QualType Deduced, AutoTypeKeyword Keyword,\n                      bool IsDependent, ConceptDecl *CD,\n                      ArrayRef<TemplateArgument> Arguments);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Auto;\n  }\n};\n\n/// Represents a C++17 deduced template specialization type.\nclass DeducedTemplateSpecializationType : public DeducedType,\n                                          public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  /// The name of the template whose arguments will be deduced.\n  TemplateName Template;\n\n  DeducedTemplateSpecializationType(TemplateName Template,\n                                    QualType DeducedAsType,\n                                    bool IsDeducedAsDependent)\n      : DeducedType(DeducedTemplateSpecialization, DeducedAsType,\n                    toTypeDependence(Template.getDependence()) |\n                        (IsDeducedAsDependent\n                             ? TypeDependence::DependentInstantiation\n                             : TypeDependence::None)),\n        Template(Template) {}\n\npublic:\n  /// Retrieve the name of the template that we are deducing.\n  TemplateName getTemplateName() const { return Template;}\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getTemplateName(), getDeducedType(), isDependentType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, TemplateName Template,\n                      QualType Deduced, bool IsDependent) {\n    Template.Profile(ID);\n    ID.AddPointer(Deduced.getAsOpaquePtr());\n    ID.AddBoolean(IsDependent);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DeducedTemplateSpecialization;\n  }\n};\n\n/// Represents a type template specialization; the template\n/// must be a class template, a type alias template, or a template\n/// template parameter.  A template which cannot be resolved to one of\n/// these, e.g. because it is written with a dependent scope\n/// specifier, is instead represented as a\n/// @c DependentTemplateSpecializationType.\n///\n/// A non-dependent template specialization type is always \"sugar\",\n/// typically for a \\c RecordType.  For example, a class template\n/// specialization type of \\c vector<int> will refer to a tag type for\n/// the instantiation \\c std::vector<int, std::allocator<int>>\n///\n/// Template specializations are dependent if either the template or\n/// any of the template arguments are dependent, in which case the\n/// type may also be canonical.\n///\n/// Instances of this type are allocated with a trailing array of\n/// TemplateArguments, followed by a QualType representing the\n/// non-canonical aliased type when the template is a type alias\n/// template.\nclass alignas(8) TemplateSpecializationType\n    : public Type,\n      public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  /// The name of the template being specialized.  This is\n  /// either a TemplateName::Template (in which case it is a\n  /// ClassTemplateDecl*, a TemplateTemplateParmDecl*, or a\n  /// TypeAliasTemplateDecl*), a\n  /// TemplateName::SubstTemplateTemplateParmPack, or a\n  /// TemplateName::SubstTemplateTemplateParm (in which case the\n  /// replacement must, recursively, be one of these).\n  TemplateName Template;\n\n  TemplateSpecializationType(TemplateName T,\n                             ArrayRef<TemplateArgument> Args,\n                             QualType Canon,\n                             QualType Aliased);\n\npublic:\n  /// Determine whether any of the given template arguments are dependent.\n  ///\n  /// The converted arguments should be supplied when known; whether an\n  /// argument is dependent can depend on the conversions performed on it\n  /// (for example, a 'const int' passed as a template argument might be\n  /// dependent if the parameter is a reference but non-dependent if the\n  /// parameter is an int).\n  ///\n  /// Note that the \\p Args parameter is unused: this is intentional, to remind\n  /// the caller that they need to pass in the converted arguments, not the\n  /// specified arguments.\n  static bool\n  anyDependentTemplateArguments(ArrayRef<TemplateArgumentLoc> Args,\n                                ArrayRef<TemplateArgument> Converted);\n  static bool\n  anyDependentTemplateArguments(const TemplateArgumentListInfo &,\n                                ArrayRef<TemplateArgument> Converted);\n  static bool anyInstantiationDependentTemplateArguments(\n      ArrayRef<TemplateArgumentLoc> Args);\n\n  /// True if this template specialization type matches a current\n  /// instantiation in the context in which it is found.\n  bool isCurrentInstantiation() const {\n    return isa<InjectedClassNameType>(getCanonicalTypeInternal());\n  }\n\n  /// Determine if this template specialization type is for a type alias\n  /// template that has been substituted.\n  ///\n  /// Nearly every template specialization type whose template is an alias\n  /// template will be substituted. However, this is not the case when\n  /// the specialization contains a pack expansion but the template alias\n  /// does not have a corresponding parameter pack, e.g.,\n  ///\n  /// \\code\n  /// template<typename T, typename U, typename V> struct S;\n  /// template<typename T, typename U> using A = S<T, int, U>;\n  /// template<typename... Ts> struct X {\n  ///   typedef A<Ts...> type; // not a type alias\n  /// };\n  /// \\endcode\n  bool isTypeAlias() const { return TemplateSpecializationTypeBits.TypeAlias; }\n\n  /// Get the aliased type, if this is a specialization of a type alias\n  /// template.\n  QualType getAliasedType() const {\n    assert(isTypeAlias() && \"not a type alias template specialization\");\n    return *reinterpret_cast<const QualType*>(end());\n  }\n\n  using iterator = const TemplateArgument *;\n\n  iterator begin() const { return getArgs(); }\n  iterator end() const; // defined inline in TemplateBase.h\n\n  /// Retrieve the name of the template that we are specializing.\n  TemplateName getTemplateName() const { return Template; }\n\n  /// Retrieve the template arguments.\n  const TemplateArgument *getArgs() const {\n    return reinterpret_cast<const TemplateArgument *>(this + 1);\n  }\n\n  /// Retrieve the number of template arguments.\n  unsigned getNumArgs() const {\n    return TemplateSpecializationTypeBits.NumArgs;\n  }\n\n  /// Retrieve a specific template argument as a type.\n  /// \\pre \\c isArgType(Arg)\n  const TemplateArgument &getArg(unsigned Idx) const; // in TemplateBase.h\n\n  ArrayRef<TemplateArgument> template_arguments() const {\n    return {getArgs(), getNumArgs()};\n  }\n\n  bool isSugared() const {\n    return !isDependentType() || isCurrentInstantiation() || isTypeAlias();\n  }\n\n  QualType desugar() const {\n    return isTypeAlias() ? getAliasedType() : getCanonicalTypeInternal();\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Ctx) {\n    Profile(ID, Template, template_arguments(), Ctx);\n    if (isTypeAlias())\n      getAliasedType().Profile(ID);\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, TemplateName T,\n                      ArrayRef<TemplateArgument> Args,\n                      const ASTContext &Context);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == TemplateSpecialization;\n  }\n};\n\n/// Print a template argument list, including the '<' and '>'\n/// enclosing the template arguments.\nvoid printTemplateArgumentList(raw_ostream &OS,\n                               ArrayRef<TemplateArgument> Args,\n                               const PrintingPolicy &Policy,\n                               const TemplateParameterList *TPL = nullptr);\n\nvoid printTemplateArgumentList(raw_ostream &OS,\n                               ArrayRef<TemplateArgumentLoc> Args,\n                               const PrintingPolicy &Policy,\n                               const TemplateParameterList *TPL = nullptr);\n\nvoid printTemplateArgumentList(raw_ostream &OS,\n                               const TemplateArgumentListInfo &Args,\n                               const PrintingPolicy &Policy,\n                               const TemplateParameterList *TPL = nullptr);\n\n/// The injected class name of a C++ class template or class\n/// template partial specialization.  Used to record that a type was\n/// spelled with a bare identifier rather than as a template-id; the\n/// equivalent for non-templated classes is just RecordType.\n///\n/// Injected class name types are always dependent.  Template\n/// instantiation turns these into RecordTypes.\n///\n/// Injected class name types are always canonical.  This works\n/// because it is impossible to compare an injected class name type\n/// with the corresponding non-injected template type, for the same\n/// reason that it is impossible to directly compare template\n/// parameters from different dependent contexts: injected class name\n/// types can only occur within the scope of a particular templated\n/// declaration, and within that scope every template specialization\n/// will canonicalize to the injected class name (when appropriate\n/// according to the rules of the language).\nclass InjectedClassNameType : public Type {\n  friend class ASTContext; // ASTContext creates these.\n  friend class ASTNodeImporter;\n  friend class ASTReader; // FIXME: ASTContext::getInjectedClassNameType is not\n                          // currently suitable for AST reading, too much\n                          // interdependencies.\n  template <class T> friend class serialization::AbstractTypeReader;\n\n  CXXRecordDecl *Decl;\n\n  /// The template specialization which this type represents.\n  /// For example, in\n  ///   template <class T> class A { ... };\n  /// this is A<T>, whereas in\n  ///   template <class X, class Y> class A<B<X,Y> > { ... };\n  /// this is A<B<X,Y> >.\n  ///\n  /// It is always unqualified, always a template specialization type,\n  /// and always dependent.\n  QualType InjectedType;\n\n  InjectedClassNameType(CXXRecordDecl *D, QualType TST)\n      : Type(InjectedClassName, QualType(),\n             TypeDependence::DependentInstantiation),\n        Decl(D), InjectedType(TST) {\n    assert(isa<TemplateSpecializationType>(TST));\n    assert(!TST.hasQualifiers());\n    assert(TST->isDependentType());\n  }\n\npublic:\n  QualType getInjectedSpecializationType() const { return InjectedType; }\n\n  const TemplateSpecializationType *getInjectedTST() const {\n    return cast<TemplateSpecializationType>(InjectedType.getTypePtr());\n  }\n\n  TemplateName getTemplateName() const {\n    return getInjectedTST()->getTemplateName();\n  }\n\n  CXXRecordDecl *getDecl() const;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == InjectedClassName;\n  }\n};\n\n/// The kind of a tag type.\nenum TagTypeKind {\n  /// The \"struct\" keyword.\n  TTK_Struct,\n\n  /// The \"__interface\" keyword.\n  TTK_Interface,\n\n  /// The \"union\" keyword.\n  TTK_Union,\n\n  /// The \"class\" keyword.\n  TTK_Class,\n\n  /// The \"enum\" keyword.\n  TTK_Enum\n};\n\n/// The elaboration keyword that precedes a qualified type name or\n/// introduces an elaborated-type-specifier.\nenum ElaboratedTypeKeyword {\n  /// The \"struct\" keyword introduces the elaborated-type-specifier.\n  ETK_Struct,\n\n  /// The \"__interface\" keyword introduces the elaborated-type-specifier.\n  ETK_Interface,\n\n  /// The \"union\" keyword introduces the elaborated-type-specifier.\n  ETK_Union,\n\n  /// The \"class\" keyword introduces the elaborated-type-specifier.\n  ETK_Class,\n\n  /// The \"enum\" keyword introduces the elaborated-type-specifier.\n  ETK_Enum,\n\n  /// The \"typename\" keyword precedes the qualified type name, e.g.,\n  /// \\c typename T::type.\n  ETK_Typename,\n\n  /// No keyword precedes the qualified type name.\n  ETK_None\n};\n\n/// A helper class for Type nodes having an ElaboratedTypeKeyword.\n/// The keyword in stored in the free bits of the base class.\n/// Also provides a few static helpers for converting and printing\n/// elaborated type keyword and tag type kind enumerations.\nclass TypeWithKeyword : public Type {\nprotected:\n  TypeWithKeyword(ElaboratedTypeKeyword Keyword, TypeClass tc,\n                  QualType Canonical, TypeDependence Dependence)\n      : Type(tc, Canonical, Dependence) {\n    TypeWithKeywordBits.Keyword = Keyword;\n  }\n\npublic:\n  ElaboratedTypeKeyword getKeyword() const {\n    return static_cast<ElaboratedTypeKeyword>(TypeWithKeywordBits.Keyword);\n  }\n\n  /// Converts a type specifier (DeclSpec::TST) into an elaborated type keyword.\n  static ElaboratedTypeKeyword getKeywordForTypeSpec(unsigned TypeSpec);\n\n  /// Converts a type specifier (DeclSpec::TST) into a tag type kind.\n  /// It is an error to provide a type specifier which *isn't* a tag kind here.\n  static TagTypeKind getTagTypeKindForTypeSpec(unsigned TypeSpec);\n\n  /// Converts a TagTypeKind into an elaborated type keyword.\n  static ElaboratedTypeKeyword getKeywordForTagTypeKind(TagTypeKind Tag);\n\n  /// Converts an elaborated type keyword into a TagTypeKind.\n  /// It is an error to provide an elaborated type keyword\n  /// which *isn't* a tag kind here.\n  static TagTypeKind getTagTypeKindForKeyword(ElaboratedTypeKeyword Keyword);\n\n  static bool KeywordIsTagTypeKind(ElaboratedTypeKeyword Keyword);\n\n  static StringRef getKeywordName(ElaboratedTypeKeyword Keyword);\n\n  static StringRef getTagTypeKindName(TagTypeKind Kind) {\n    return getKeywordName(getKeywordForTagTypeKind(Kind));\n  }\n\n  class CannotCastToThisType {};\n  static CannotCastToThisType classof(const Type *);\n};\n\n/// Represents a type that was referred to using an elaborated type\n/// keyword, e.g., struct S, or via a qualified name, e.g., N::M::type,\n/// or both.\n///\n/// This type is used to keep track of a type name as written in the\n/// source code, including tag keywords and any nested-name-specifiers.\n/// The type itself is always \"sugar\", used to express what was written\n/// in the source code but containing no additional semantic information.\nclass ElaboratedType final\n    : public TypeWithKeyword,\n      public llvm::FoldingSetNode,\n      private llvm::TrailingObjects<ElaboratedType, TagDecl *> {\n  friend class ASTContext; // ASTContext creates these\n  friend TrailingObjects;\n\n  /// The nested name specifier containing the qualifier.\n  NestedNameSpecifier *NNS;\n\n  /// The type that this qualified name refers to.\n  QualType NamedType;\n\n  /// The (re)declaration of this tag type owned by this occurrence is stored\n  /// as a trailing object if there is one. Use getOwnedTagDecl to obtain\n  /// it, or obtain a null pointer if there is none.\n\n  ElaboratedType(ElaboratedTypeKeyword Keyword, NestedNameSpecifier *NNS,\n                 QualType NamedType, QualType CanonType, TagDecl *OwnedTagDecl)\n      : TypeWithKeyword(Keyword, Elaborated, CanonType,\n                        // Any semantic dependence on the qualifier will have\n                        // been incorporated into NamedType. We still need to\n                        // track syntactic (instantiation / error / pack)\n                        // dependence on the qualifier.\n                        NamedType->getDependence() |\n                            (NNS ? toSyntacticDependence(\n                                       toTypeDependence(NNS->getDependence()))\n                                 : TypeDependence::None)),\n        NNS(NNS), NamedType(NamedType) {\n    ElaboratedTypeBits.HasOwnedTagDecl = false;\n    if (OwnedTagDecl) {\n      ElaboratedTypeBits.HasOwnedTagDecl = true;\n      *getTrailingObjects<TagDecl *>() = OwnedTagDecl;\n    }\n    assert(!(Keyword == ETK_None && NNS == nullptr) &&\n           \"ElaboratedType cannot have elaborated type keyword \"\n           \"and name qualifier both null.\");\n  }\n\npublic:\n  /// Retrieve the qualification on this type.\n  NestedNameSpecifier *getQualifier() const { return NNS; }\n\n  /// Retrieve the type named by the qualified-id.\n  QualType getNamedType() const { return NamedType; }\n\n  /// Remove a single level of sugar.\n  QualType desugar() const { return getNamedType(); }\n\n  /// Returns whether this type directly provides sugar.\n  bool isSugared() const { return true; }\n\n  /// Return the (re)declaration of this type owned by this occurrence of this\n  /// type, or nullptr if there is none.\n  TagDecl *getOwnedTagDecl() const {\n    return ElaboratedTypeBits.HasOwnedTagDecl ? *getTrailingObjects<TagDecl *>()\n                                              : nullptr;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getKeyword(), NNS, NamedType, getOwnedTagDecl());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, ElaboratedTypeKeyword Keyword,\n                      NestedNameSpecifier *NNS, QualType NamedType,\n                      TagDecl *OwnedTagDecl) {\n    ID.AddInteger(Keyword);\n    ID.AddPointer(NNS);\n    NamedType.Profile(ID);\n    ID.AddPointer(OwnedTagDecl);\n  }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == Elaborated; }\n};\n\n/// Represents a qualified type name for which the type name is\n/// dependent.\n///\n/// DependentNameType represents a class of dependent types that involve a\n/// possibly dependent nested-name-specifier (e.g., \"T::\") followed by a\n/// name of a type. The DependentNameType may start with a \"typename\" (for a\n/// typename-specifier), \"class\", \"struct\", \"union\", or \"enum\" (for a\n/// dependent elaborated-type-specifier), or nothing (in contexts where we\n/// know that we must be referring to a type, e.g., in a base class specifier).\n/// Typically the nested-name-specifier is dependent, but in MSVC compatibility\n/// mode, this type is used with non-dependent names to delay name lookup until\n/// instantiation.\nclass DependentNameType : public TypeWithKeyword, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  /// The nested name specifier containing the qualifier.\n  NestedNameSpecifier *NNS;\n\n  /// The type that this typename specifier refers to.\n  const IdentifierInfo *Name;\n\n  DependentNameType(ElaboratedTypeKeyword Keyword, NestedNameSpecifier *NNS,\n                    const IdentifierInfo *Name, QualType CanonType)\n      : TypeWithKeyword(Keyword, DependentName, CanonType,\n                        TypeDependence::DependentInstantiation |\n                            toTypeDependence(NNS->getDependence())),\n        NNS(NNS), Name(Name) {}\n\npublic:\n  /// Retrieve the qualification on this type.\n  NestedNameSpecifier *getQualifier() const { return NNS; }\n\n  /// Retrieve the type named by the typename specifier as an identifier.\n  ///\n  /// This routine will return a non-NULL identifier pointer when the\n  /// form of the original typename was terminated by an identifier,\n  /// e.g., \"typename T::type\".\n  const IdentifierInfo *getIdentifier() const {\n    return Name;\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getKeyword(), NNS, Name);\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, ElaboratedTypeKeyword Keyword,\n                      NestedNameSpecifier *NNS, const IdentifierInfo *Name) {\n    ID.AddInteger(Keyword);\n    ID.AddPointer(NNS);\n    ID.AddPointer(Name);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentName;\n  }\n};\n\n/// Represents a template specialization type whose template cannot be\n/// resolved, e.g.\n///   A<T>::template B<T>\nclass alignas(8) DependentTemplateSpecializationType\n    : public TypeWithKeyword,\n      public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  /// The nested name specifier containing the qualifier.\n  NestedNameSpecifier *NNS;\n\n  /// The identifier of the template.\n  const IdentifierInfo *Name;\n\n  DependentTemplateSpecializationType(ElaboratedTypeKeyword Keyword,\n                                      NestedNameSpecifier *NNS,\n                                      const IdentifierInfo *Name,\n                                      ArrayRef<TemplateArgument> Args,\n                                      QualType Canon);\n\n  const TemplateArgument *getArgBuffer() const {\n    return reinterpret_cast<const TemplateArgument*>(this+1);\n  }\n\n  TemplateArgument *getArgBuffer() {\n    return reinterpret_cast<TemplateArgument*>(this+1);\n  }\n\npublic:\n  NestedNameSpecifier *getQualifier() const { return NNS; }\n  const IdentifierInfo *getIdentifier() const { return Name; }\n\n  /// Retrieve the template arguments.\n  const TemplateArgument *getArgs() const {\n    return getArgBuffer();\n  }\n\n  /// Retrieve the number of template arguments.\n  unsigned getNumArgs() const {\n    return DependentTemplateSpecializationTypeBits.NumArgs;\n  }\n\n  const TemplateArgument &getArg(unsigned Idx) const; // in TemplateBase.h\n\n  ArrayRef<TemplateArgument> template_arguments() const {\n    return {getArgs(), getNumArgs()};\n  }\n\n  using iterator = const TemplateArgument *;\n\n  iterator begin() const { return getArgs(); }\n  iterator end() const; // inline in TemplateBase.h\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context) {\n    Profile(ID, Context, getKeyword(), NNS, Name, {getArgs(), getNumArgs()});\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      const ASTContext &Context,\n                      ElaboratedTypeKeyword Keyword,\n                      NestedNameSpecifier *Qualifier,\n                      const IdentifierInfo *Name,\n                      ArrayRef<TemplateArgument> Args);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentTemplateSpecialization;\n  }\n};\n\n/// Represents a pack expansion of types.\n///\n/// Pack expansions are part of C++11 variadic templates. A pack\n/// expansion contains a pattern, which itself contains one or more\n/// \"unexpanded\" parameter packs. When instantiated, a pack expansion\n/// produces a series of types, each instantiated from the pattern of\n/// the expansion, where the Ith instantiation of the pattern uses the\n/// Ith arguments bound to each of the unexpanded parameter packs. The\n/// pack expansion is considered to \"expand\" these unexpanded\n/// parameter packs.\n///\n/// \\code\n/// template<typename ...Types> struct tuple;\n///\n/// template<typename ...Types>\n/// struct tuple_of_references {\n///   typedef tuple<Types&...> type;\n/// };\n/// \\endcode\n///\n/// Here, the pack expansion \\c Types&... is represented via a\n/// PackExpansionType whose pattern is Types&.\nclass PackExpansionType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these\n\n  /// The pattern of the pack expansion.\n  QualType Pattern;\n\n  PackExpansionType(QualType Pattern, QualType Canon,\n                    Optional<unsigned> NumExpansions)\n      : Type(PackExpansion, Canon,\n             (Pattern->getDependence() | TypeDependence::Dependent |\n              TypeDependence::Instantiation) &\n                 ~TypeDependence::UnexpandedPack),\n        Pattern(Pattern) {\n    PackExpansionTypeBits.NumExpansions =\n        NumExpansions ? *NumExpansions + 1 : 0;\n  }\n\npublic:\n  /// Retrieve the pattern of this pack expansion, which is the\n  /// type that will be repeatedly instantiated when instantiating the\n  /// pack expansion itself.\n  QualType getPattern() const { return Pattern; }\n\n  /// Retrieve the number of expansions that this pack expansion will\n  /// generate, if known.\n  Optional<unsigned> getNumExpansions() const {\n    if (PackExpansionTypeBits.NumExpansions)\n      return PackExpansionTypeBits.NumExpansions - 1;\n    return None;\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getPattern(), getNumExpansions());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType Pattern,\n                      Optional<unsigned> NumExpansions) {\n    ID.AddPointer(Pattern.getAsOpaquePtr());\n    ID.AddBoolean(NumExpansions.hasValue());\n    if (NumExpansions)\n      ID.AddInteger(*NumExpansions);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == PackExpansion;\n  }\n};\n\n/// This class wraps the list of protocol qualifiers. For types that can\n/// take ObjC protocol qualifers, they can subclass this class.\ntemplate <class T>\nclass ObjCProtocolQualifiers {\nprotected:\n  ObjCProtocolQualifiers() = default;\n\n  ObjCProtocolDecl * const *getProtocolStorage() const {\n    return const_cast<ObjCProtocolQualifiers*>(this)->getProtocolStorage();\n  }\n\n  ObjCProtocolDecl **getProtocolStorage() {\n    return static_cast<T*>(this)->getProtocolStorageImpl();\n  }\n\n  void setNumProtocols(unsigned N) {\n    static_cast<T*>(this)->setNumProtocolsImpl(N);\n  }\n\n  void initialize(ArrayRef<ObjCProtocolDecl *> protocols) {\n    setNumProtocols(protocols.size());\n    assert(getNumProtocols() == protocols.size() &&\n           \"bitfield overflow in protocol count\");\n    if (!protocols.empty())\n      memcpy(getProtocolStorage(), protocols.data(),\n             protocols.size() * sizeof(ObjCProtocolDecl*));\n  }\n\npublic:\n  using qual_iterator = ObjCProtocolDecl * const *;\n  using qual_range = llvm::iterator_range<qual_iterator>;\n\n  qual_range quals() const { return qual_range(qual_begin(), qual_end()); }\n  qual_iterator qual_begin() const { return getProtocolStorage(); }\n  qual_iterator qual_end() const { return qual_begin() + getNumProtocols(); }\n\n  bool qual_empty() const { return getNumProtocols() == 0; }\n\n  /// Return the number of qualifying protocols in this type, or 0 if\n  /// there are none.\n  unsigned getNumProtocols() const {\n    return static_cast<const T*>(this)->getNumProtocolsImpl();\n  }\n\n  /// Fetch a protocol by index.\n  ObjCProtocolDecl *getProtocol(unsigned I) const {\n    assert(I < getNumProtocols() && \"Out-of-range protocol access\");\n    return qual_begin()[I];\n  }\n\n  /// Retrieve all of the protocol qualifiers.\n  ArrayRef<ObjCProtocolDecl *> getProtocols() const {\n    return ArrayRef<ObjCProtocolDecl *>(qual_begin(), getNumProtocols());\n  }\n};\n\n/// Represents a type parameter type in Objective C. It can take\n/// a list of protocols.\nclass ObjCTypeParamType : public Type,\n                          public ObjCProtocolQualifiers<ObjCTypeParamType>,\n                          public llvm::FoldingSetNode {\n  friend class ASTContext;\n  friend class ObjCProtocolQualifiers<ObjCTypeParamType>;\n\n  /// The number of protocols stored on this type.\n  unsigned NumProtocols : 6;\n\n  ObjCTypeParamDecl *OTPDecl;\n\n  /// The protocols are stored after the ObjCTypeParamType node. In the\n  /// canonical type, the list of protocols are sorted alphabetically\n  /// and uniqued.\n  ObjCProtocolDecl **getProtocolStorageImpl();\n\n  /// Return the number of qualifying protocols in this interface type,\n  /// or 0 if there are none.\n  unsigned getNumProtocolsImpl() const {\n    return NumProtocols;\n  }\n\n  void setNumProtocolsImpl(unsigned N) {\n    NumProtocols = N;\n  }\n\n  ObjCTypeParamType(const ObjCTypeParamDecl *D,\n                    QualType can,\n                    ArrayRef<ObjCProtocolDecl *> protocols);\n\npublic:\n  bool isSugared() const { return true; }\n  QualType desugar() const { return getCanonicalTypeInternal(); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ObjCTypeParam;\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID);\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      const ObjCTypeParamDecl *OTPDecl,\n                      QualType CanonicalType,\n                      ArrayRef<ObjCProtocolDecl *> protocols);\n\n  ObjCTypeParamDecl *getDecl() const { return OTPDecl; }\n};\n\n/// Represents a class type in Objective C.\n///\n/// Every Objective C type is a combination of a base type, a set of\n/// type arguments (optional, for parameterized classes) and a list of\n/// protocols.\n///\n/// Given the following declarations:\n/// \\code\n///   \\@class C<T>;\n///   \\@protocol P;\n/// \\endcode\n///\n/// 'C' is an ObjCInterfaceType C.  It is sugar for an ObjCObjectType\n/// with base C and no protocols.\n///\n/// 'C<P>' is an unspecialized ObjCObjectType with base C and protocol list [P].\n/// 'C<C*>' is a specialized ObjCObjectType with type arguments 'C*' and no\n/// protocol list.\n/// 'C<C*><P>' is a specialized ObjCObjectType with base C, type arguments 'C*',\n/// and protocol list [P].\n///\n/// 'id' is a TypedefType which is sugar for an ObjCObjectPointerType whose\n/// pointee is an ObjCObjectType with base BuiltinType::ObjCIdType\n/// and no protocols.\n///\n/// 'id<P>' is an ObjCObjectPointerType whose pointee is an ObjCObjectType\n/// with base BuiltinType::ObjCIdType and protocol list [P].  Eventually\n/// this should get its own sugar class to better represent the source.\nclass ObjCObjectType : public Type,\n                       public ObjCProtocolQualifiers<ObjCObjectType> {\n  friend class ObjCProtocolQualifiers<ObjCObjectType>;\n\n  // ObjCObjectType.NumTypeArgs - the number of type arguments stored\n  // after the ObjCObjectPointerType node.\n  // ObjCObjectType.NumProtocols - the number of protocols stored\n  // after the type arguments of ObjCObjectPointerType node.\n  //\n  // These protocols are those written directly on the type.  If\n  // protocol qualifiers ever become additive, the iterators will need\n  // to get kindof complicated.\n  //\n  // In the canonical object type, these are sorted alphabetically\n  // and uniqued.\n\n  /// Either a BuiltinType or an InterfaceType or sugar for either.\n  QualType BaseType;\n\n  /// Cached superclass type.\n  mutable llvm::PointerIntPair<const ObjCObjectType *, 1, bool>\n    CachedSuperClassType;\n\n  QualType *getTypeArgStorage();\n  const QualType *getTypeArgStorage() const {\n    return const_cast<ObjCObjectType *>(this)->getTypeArgStorage();\n  }\n\n  ObjCProtocolDecl **getProtocolStorageImpl();\n  /// Return the number of qualifying protocols in this interface type,\n  /// or 0 if there are none.\n  unsigned getNumProtocolsImpl() const {\n    return ObjCObjectTypeBits.NumProtocols;\n  }\n  void setNumProtocolsImpl(unsigned N) {\n    ObjCObjectTypeBits.NumProtocols = N;\n  }\n\nprotected:\n  enum Nonce_ObjCInterface { Nonce_ObjCInterface };\n\n  ObjCObjectType(QualType Canonical, QualType Base,\n                 ArrayRef<QualType> typeArgs,\n                 ArrayRef<ObjCProtocolDecl *> protocols,\n                 bool isKindOf);\n\n  ObjCObjectType(enum Nonce_ObjCInterface)\n      : Type(ObjCInterface, QualType(), TypeDependence::None),\n        BaseType(QualType(this_(), 0)) {\n    ObjCObjectTypeBits.NumProtocols = 0;\n    ObjCObjectTypeBits.NumTypeArgs = 0;\n    ObjCObjectTypeBits.IsKindOf = 0;\n  }\n\n  void computeSuperClassTypeSlow() const;\n\npublic:\n  /// Gets the base type of this object type.  This is always (possibly\n  /// sugar for) one of:\n  ///  - the 'id' builtin type (as opposed to the 'id' type visible to the\n  ///    user, which is a typedef for an ObjCObjectPointerType)\n  ///  - the 'Class' builtin type (same caveat)\n  ///  - an ObjCObjectType (currently always an ObjCInterfaceType)\n  QualType getBaseType() const { return BaseType; }\n\n  bool isObjCId() const {\n    return getBaseType()->isSpecificBuiltinType(BuiltinType::ObjCId);\n  }\n\n  bool isObjCClass() const {\n    return getBaseType()->isSpecificBuiltinType(BuiltinType::ObjCClass);\n  }\n\n  bool isObjCUnqualifiedId() const { return qual_empty() && isObjCId(); }\n  bool isObjCUnqualifiedClass() const { return qual_empty() && isObjCClass(); }\n  bool isObjCUnqualifiedIdOrClass() const {\n    if (!qual_empty()) return false;\n    if (const BuiltinType *T = getBaseType()->getAs<BuiltinType>())\n      return T->getKind() == BuiltinType::ObjCId ||\n             T->getKind() == BuiltinType::ObjCClass;\n    return false;\n  }\n  bool isObjCQualifiedId() const { return !qual_empty() && isObjCId(); }\n  bool isObjCQualifiedClass() const { return !qual_empty() && isObjCClass(); }\n\n  /// Gets the interface declaration for this object type, if the base type\n  /// really is an interface.\n  ObjCInterfaceDecl *getInterface() const;\n\n  /// Determine whether this object type is \"specialized\", meaning\n  /// that it has type arguments.\n  bool isSpecialized() const;\n\n  /// Determine whether this object type was written with type arguments.\n  bool isSpecializedAsWritten() const {\n    return ObjCObjectTypeBits.NumTypeArgs > 0;\n  }\n\n  /// Determine whether this object type is \"unspecialized\", meaning\n  /// that it has no type arguments.\n  bool isUnspecialized() const { return !isSpecialized(); }\n\n  /// Determine whether this object type is \"unspecialized\" as\n  /// written, meaning that it has no type arguments.\n  bool isUnspecializedAsWritten() const { return !isSpecializedAsWritten(); }\n\n  /// Retrieve the type arguments of this object type (semantically).\n  ArrayRef<QualType> getTypeArgs() const;\n\n  /// Retrieve the type arguments of this object type as they were\n  /// written.\n  ArrayRef<QualType> getTypeArgsAsWritten() const {\n    return llvm::makeArrayRef(getTypeArgStorage(),\n                              ObjCObjectTypeBits.NumTypeArgs);\n  }\n\n  /// Whether this is a \"__kindof\" type as written.\n  bool isKindOfTypeAsWritten() const { return ObjCObjectTypeBits.IsKindOf; }\n\n  /// Whether this ia a \"__kindof\" type (semantically).\n  bool isKindOfType() const;\n\n  /// Retrieve the type of the superclass of this object type.\n  ///\n  /// This operation substitutes any type arguments into the\n  /// superclass of the current class type, potentially producing a\n  /// specialization of the superclass type. Produces a null type if\n  /// there is no superclass.\n  QualType getSuperClassType() const {\n    if (!CachedSuperClassType.getInt())\n      computeSuperClassTypeSlow();\n\n    assert(CachedSuperClassType.getInt() && \"Superclass not set?\");\n    return QualType(CachedSuperClassType.getPointer(), 0);\n  }\n\n  /// Strip off the Objective-C \"kindof\" type and (with it) any\n  /// protocol qualifiers.\n  QualType stripObjCKindOfTypeAndQuals(const ASTContext &ctx) const;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ObjCObject ||\n           T->getTypeClass() == ObjCInterface;\n  }\n};\n\n/// A class providing a concrete implementation\n/// of ObjCObjectType, so as to not increase the footprint of\n/// ObjCInterfaceType.  Code outside of ASTContext and the core type\n/// system should not reference this type.\nclass ObjCObjectTypeImpl : public ObjCObjectType, public llvm::FoldingSetNode {\n  friend class ASTContext;\n\n  // If anyone adds fields here, ObjCObjectType::getProtocolStorage()\n  // will need to be modified.\n\n  ObjCObjectTypeImpl(QualType Canonical, QualType Base,\n                     ArrayRef<QualType> typeArgs,\n                     ArrayRef<ObjCProtocolDecl *> protocols,\n                     bool isKindOf)\n      : ObjCObjectType(Canonical, Base, typeArgs, protocols, isKindOf) {}\n\npublic:\n  void Profile(llvm::FoldingSetNodeID &ID);\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      QualType Base,\n                      ArrayRef<QualType> typeArgs,\n                      ArrayRef<ObjCProtocolDecl *> protocols,\n                      bool isKindOf);\n};\n\ninline QualType *ObjCObjectType::getTypeArgStorage() {\n  return reinterpret_cast<QualType *>(static_cast<ObjCObjectTypeImpl*>(this)+1);\n}\n\ninline ObjCProtocolDecl **ObjCObjectType::getProtocolStorageImpl() {\n    return reinterpret_cast<ObjCProtocolDecl**>(\n             getTypeArgStorage() + ObjCObjectTypeBits.NumTypeArgs);\n}\n\ninline ObjCProtocolDecl **ObjCTypeParamType::getProtocolStorageImpl() {\n    return reinterpret_cast<ObjCProtocolDecl**>(\n             static_cast<ObjCTypeParamType*>(this)+1);\n}\n\n/// Interfaces are the core concept in Objective-C for object oriented design.\n/// They basically correspond to C++ classes.  There are two kinds of interface\n/// types: normal interfaces like `NSString`, and qualified interfaces, which\n/// are qualified with a protocol list like `NSString<NSCopyable, NSAmazing>`.\n///\n/// ObjCInterfaceType guarantees the following properties when considered\n/// as a subtype of its superclass, ObjCObjectType:\n///   - There are no protocol qualifiers.  To reinforce this, code which\n///     tries to invoke the protocol methods via an ObjCInterfaceType will\n///     fail to compile.\n///   - It is its own base type.  That is, if T is an ObjCInterfaceType*,\n///     T->getBaseType() == QualType(T, 0).\nclass ObjCInterfaceType : public ObjCObjectType {\n  friend class ASTContext; // ASTContext creates these.\n  friend class ASTReader;\n  friend class ObjCInterfaceDecl;\n  template <class T> friend class serialization::AbstractTypeReader;\n\n  mutable ObjCInterfaceDecl *Decl;\n\n  ObjCInterfaceType(const ObjCInterfaceDecl *D)\n      : ObjCObjectType(Nonce_ObjCInterface),\n        Decl(const_cast<ObjCInterfaceDecl*>(D)) {}\n\npublic:\n  /// Get the declaration of this interface.\n  ObjCInterfaceDecl *getDecl() const { return Decl; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ObjCInterface;\n  }\n\n  // Nonsense to \"hide\" certain members of ObjCObjectType within this\n  // class.  People asking for protocols on an ObjCInterfaceType are\n  // not going to get what they want: ObjCInterfaceTypes are\n  // guaranteed to have no protocols.\n  enum {\n    qual_iterator,\n    qual_begin,\n    qual_end,\n    getNumProtocols,\n    getProtocol\n  };\n};\n\ninline ObjCInterfaceDecl *ObjCObjectType::getInterface() const {\n  QualType baseType = getBaseType();\n  while (const auto *ObjT = baseType->getAs<ObjCObjectType>()) {\n    if (const auto *T = dyn_cast<ObjCInterfaceType>(ObjT))\n      return T->getDecl();\n\n    baseType = ObjT->getBaseType();\n  }\n\n  return nullptr;\n}\n\n/// Represents a pointer to an Objective C object.\n///\n/// These are constructed from pointer declarators when the pointee type is\n/// an ObjCObjectType (or sugar for one).  In addition, the 'id' and 'Class'\n/// types are typedefs for these, and the protocol-qualified types 'id<P>'\n/// and 'Class<P>' are translated into these.\n///\n/// Pointers to pointers to Objective C objects are still PointerTypes;\n/// only the first level of pointer gets it own type implementation.\nclass ObjCObjectPointerType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType PointeeType;\n\n  ObjCObjectPointerType(QualType Canonical, QualType Pointee)\n      : Type(ObjCObjectPointer, Canonical, Pointee->getDependence()),\n        PointeeType(Pointee) {}\n\npublic:\n  /// Gets the type pointed to by this ObjC pointer.\n  /// The result will always be an ObjCObjectType or sugar thereof.\n  QualType getPointeeType() const { return PointeeType; }\n\n  /// Gets the type pointed to by this ObjC pointer.  Always returns non-null.\n  ///\n  /// This method is equivalent to getPointeeType() except that\n  /// it discards any typedefs (or other sugar) between this\n  /// type and the \"outermost\" object type.  So for:\n  /// \\code\n  ///   \\@class A; \\@protocol P; \\@protocol Q;\n  ///   typedef A<P> AP;\n  ///   typedef A A1;\n  ///   typedef A1<P> A1P;\n  ///   typedef A1P<Q> A1PQ;\n  /// \\endcode\n  /// For 'A*', getObjectType() will return 'A'.\n  /// For 'A<P>*', getObjectType() will return 'A<P>'.\n  /// For 'AP*', getObjectType() will return 'A<P>'.\n  /// For 'A1*', getObjectType() will return 'A'.\n  /// For 'A1<P>*', getObjectType() will return 'A1<P>'.\n  /// For 'A1P*', getObjectType() will return 'A1<P>'.\n  /// For 'A1PQ*', getObjectType() will return 'A1<Q>', because\n  ///   adding protocols to a protocol-qualified base discards the\n  ///   old qualifiers (for now).  But if it didn't, getObjectType()\n  ///   would return 'A1P<Q>' (and we'd have to make iterating over\n  ///   qualifiers more complicated).\n  const ObjCObjectType *getObjectType() const {\n    return PointeeType->castAs<ObjCObjectType>();\n  }\n\n  /// If this pointer points to an Objective C\n  /// \\@interface type, gets the type for that interface.  Any protocol\n  /// qualifiers on the interface are ignored.\n  ///\n  /// \\return null if the base type for this pointer is 'id' or 'Class'\n  const ObjCInterfaceType *getInterfaceType() const;\n\n  /// If this pointer points to an Objective \\@interface\n  /// type, gets the declaration for that interface.\n  ///\n  /// \\return null if the base type for this pointer is 'id' or 'Class'\n  ObjCInterfaceDecl *getInterfaceDecl() const {\n    return getObjectType()->getInterface();\n  }\n\n  /// True if this is equivalent to the 'id' type, i.e. if\n  /// its object type is the primitive 'id' type with no protocols.\n  bool isObjCIdType() const {\n    return getObjectType()->isObjCUnqualifiedId();\n  }\n\n  /// True if this is equivalent to the 'Class' type,\n  /// i.e. if its object tive is the primitive 'Class' type with no protocols.\n  bool isObjCClassType() const {\n    return getObjectType()->isObjCUnqualifiedClass();\n  }\n\n  /// True if this is equivalent to the 'id' or 'Class' type,\n  bool isObjCIdOrClassType() const {\n    return getObjectType()->isObjCUnqualifiedIdOrClass();\n  }\n\n  /// True if this is equivalent to 'id<P>' for some non-empty set of\n  /// protocols.\n  bool isObjCQualifiedIdType() const {\n    return getObjectType()->isObjCQualifiedId();\n  }\n\n  /// True if this is equivalent to 'Class<P>' for some non-empty set of\n  /// protocols.\n  bool isObjCQualifiedClassType() const {\n    return getObjectType()->isObjCQualifiedClass();\n  }\n\n  /// Whether this is a \"__kindof\" type.\n  bool isKindOfType() const { return getObjectType()->isKindOfType(); }\n\n  /// Whether this type is specialized, meaning that it has type arguments.\n  bool isSpecialized() const { return getObjectType()->isSpecialized(); }\n\n  /// Whether this type is specialized, meaning that it has type arguments.\n  bool isSpecializedAsWritten() const {\n    return getObjectType()->isSpecializedAsWritten();\n  }\n\n  /// Whether this type is unspecialized, meaning that is has no type arguments.\n  bool isUnspecialized() const { return getObjectType()->isUnspecialized(); }\n\n  /// Determine whether this object type is \"unspecialized\" as\n  /// written, meaning that it has no type arguments.\n  bool isUnspecializedAsWritten() const { return !isSpecializedAsWritten(); }\n\n  /// Retrieve the type arguments for this type.\n  ArrayRef<QualType> getTypeArgs() const {\n    return getObjectType()->getTypeArgs();\n  }\n\n  /// Retrieve the type arguments for this type.\n  ArrayRef<QualType> getTypeArgsAsWritten() const {\n    return getObjectType()->getTypeArgsAsWritten();\n  }\n\n  /// An iterator over the qualifiers on the object type.  Provided\n  /// for convenience.  This will always iterate over the full set of\n  /// protocols on a type, not just those provided directly.\n  using qual_iterator = ObjCObjectType::qual_iterator;\n  using qual_range = llvm::iterator_range<qual_iterator>;\n\n  qual_range quals() const { return qual_range(qual_begin(), qual_end()); }\n\n  qual_iterator qual_begin() const {\n    return getObjectType()->qual_begin();\n  }\n\n  qual_iterator qual_end() const {\n    return getObjectType()->qual_end();\n  }\n\n  bool qual_empty() const { return getObjectType()->qual_empty(); }\n\n  /// Return the number of qualifying protocols on the object type.\n  unsigned getNumProtocols() const {\n    return getObjectType()->getNumProtocols();\n  }\n\n  /// Retrieve a qualifying protocol by index on the object type.\n  ObjCProtocolDecl *getProtocol(unsigned I) const {\n    return getObjectType()->getProtocol(I);\n  }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  /// Retrieve the type of the superclass of this object pointer type.\n  ///\n  /// This operation substitutes any type arguments into the\n  /// superclass of the current class type, potentially producing a\n  /// pointer to a specialization of the superclass type. Produces a\n  /// null type if there is no superclass.\n  QualType getSuperClassType() const;\n\n  /// Strip off the Objective-C \"kindof\" type and (with it) any\n  /// protocol qualifiers.\n  const ObjCObjectPointerType *stripObjCKindOfTypeAndQuals(\n                                 const ASTContext &ctx) const;\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getPointeeType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType T) {\n    ID.AddPointer(T.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == ObjCObjectPointer;\n  }\n};\n\nclass AtomicType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType ValueType;\n\n  AtomicType(QualType ValTy, QualType Canonical)\n      : Type(Atomic, Canonical, ValTy->getDependence()), ValueType(ValTy) {}\n\npublic:\n  /// Gets the type contained by this atomic type, i.e.\n  /// the type returned by performing an atomic load of this atomic type.\n  QualType getValueType() const { return ValueType; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getValueType());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType T) {\n    ID.AddPointer(T.getAsOpaquePtr());\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Atomic;\n  }\n};\n\n/// PipeType - OpenCL20.\nclass PipeType : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext; // ASTContext creates these.\n\n  QualType ElementType;\n  bool isRead;\n\n  PipeType(QualType elemType, QualType CanonicalPtr, bool isRead)\n      : Type(Pipe, CanonicalPtr, elemType->getDependence()),\n        ElementType(elemType), isRead(isRead) {}\n\npublic:\n  QualType getElementType() const { return ElementType; }\n\n  bool isSugared() const { return false; }\n\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, getElementType(), isReadOnly());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, QualType T, bool isRead) {\n    ID.AddPointer(T.getAsOpaquePtr());\n    ID.AddBoolean(isRead);\n  }\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == Pipe;\n  }\n\n  bool isReadOnly() const { return isRead; }\n};\n\n/// A fixed int type of a specified bitwidth.\nclass ExtIntType final : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n  unsigned IsUnsigned : 1;\n  unsigned NumBits : 24;\n\nprotected:\n  ExtIntType(bool isUnsigned, unsigned NumBits);\n\npublic:\n  bool isUnsigned() const { return IsUnsigned; }\n  bool isSigned() const { return !IsUnsigned; }\n  unsigned getNumBits() const { return NumBits; }\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, isUnsigned(), getNumBits());\n  }\n\n  static void Profile(llvm::FoldingSetNodeID &ID, bool IsUnsigned,\n                      unsigned NumBits) {\n    ID.AddBoolean(IsUnsigned);\n    ID.AddInteger(NumBits);\n  }\n\n  static bool classof(const Type *T) { return T->getTypeClass() == ExtInt; }\n};\n\nclass DependentExtIntType final : public Type, public llvm::FoldingSetNode {\n  friend class ASTContext;\n  const ASTContext &Context;\n  llvm::PointerIntPair<Expr*, 1, bool> ExprAndUnsigned;\n\nprotected:\n  DependentExtIntType(const ASTContext &Context, bool IsUnsigned,\n                      Expr *NumBits);\n\npublic:\n  bool isUnsigned() const;\n  bool isSigned() const { return !isUnsigned(); }\n  Expr *getNumBitsExpr() const;\n\n  bool isSugared() const { return false; }\n  QualType desugar() const { return QualType(this, 0); }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    Profile(ID, Context, isUnsigned(), getNumBitsExpr());\n  }\n  static void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &Context,\n                      bool IsUnsigned, Expr *NumBitsExpr);\n\n  static bool classof(const Type *T) {\n    return T->getTypeClass() == DependentExtInt;\n  }\n};\n\n/// A qualifier set is used to build a set of qualifiers.\nclass QualifierCollector : public Qualifiers {\npublic:\n  QualifierCollector(Qualifiers Qs = Qualifiers()) : Qualifiers(Qs) {}\n\n  /// Collect any qualifiers on the given type and return an\n  /// unqualified type.  The qualifiers are assumed to be consistent\n  /// with those already in the type.\n  const Type *strip(QualType type) {\n    addFastQualifiers(type.getLocalFastQualifiers());\n    if (!type.hasLocalNonFastQualifiers())\n      return type.getTypePtrUnsafe();\n\n    const ExtQuals *extQuals = type.getExtQualsUnsafe();\n    addConsistentQualifiers(extQuals->getQualifiers());\n    return extQuals->getBaseType();\n  }\n\n  /// Apply the collected qualifiers to the given type.\n  QualType apply(const ASTContext &Context, QualType QT) const;\n\n  /// Apply the collected qualifiers to the given type.\n  QualType apply(const ASTContext &Context, const Type* T) const;\n};\n\n/// A container of type source information.\n///\n/// A client can read the relevant info using TypeLoc wrappers, e.g:\n/// @code\n/// TypeLoc TL = TypeSourceInfo->getTypeLoc();\n/// TL.getBeginLoc().print(OS, SrcMgr);\n/// @endcode\nclass alignas(8) TypeSourceInfo {\n  // Contains a memory block after the class, used for type source information,\n  // allocated by ASTContext.\n  friend class ASTContext;\n\n  QualType Ty;\n\n  TypeSourceInfo(QualType ty) : Ty(ty) {}\n\npublic:\n  /// Return the type wrapped by this type source info.\n  QualType getType() const { return Ty; }\n\n  /// Return the TypeLoc wrapper for the type source info.\n  TypeLoc getTypeLoc() const; // implemented in TypeLoc.h\n\n  /// Override the type stored in this TypeSourceInfo. Use with caution!\n  void overrideType(QualType T) { Ty = T; }\n};\n\n// Inline function definitions.\n\ninline SplitQualType SplitQualType::getSingleStepDesugaredType() const {\n  SplitQualType desugar =\n    Ty->getLocallyUnqualifiedSingleStepDesugaredType().split();\n  desugar.Quals.addConsistentQualifiers(Quals);\n  return desugar;\n}\n\ninline const Type *QualType::getTypePtr() const {\n  return getCommonPtr()->BaseType;\n}\n\ninline const Type *QualType::getTypePtrOrNull() const {\n  return (isNull() ? nullptr : getCommonPtr()->BaseType);\n}\n\ninline SplitQualType QualType::split() const {\n  if (!hasLocalNonFastQualifiers())\n    return SplitQualType(getTypePtrUnsafe(),\n                         Qualifiers::fromFastMask(getLocalFastQualifiers()));\n\n  const ExtQuals *eq = getExtQualsUnsafe();\n  Qualifiers qs = eq->getQualifiers();\n  qs.addFastQualifiers(getLocalFastQualifiers());\n  return SplitQualType(eq->getBaseType(), qs);\n}\n\ninline Qualifiers QualType::getLocalQualifiers() const {\n  Qualifiers Quals;\n  if (hasLocalNonFastQualifiers())\n    Quals = getExtQualsUnsafe()->getQualifiers();\n  Quals.addFastQualifiers(getLocalFastQualifiers());\n  return Quals;\n}\n\ninline Qualifiers QualType::getQualifiers() const {\n  Qualifiers quals = getCommonPtr()->CanonicalType.getLocalQualifiers();\n  quals.addFastQualifiers(getLocalFastQualifiers());\n  return quals;\n}\n\ninline unsigned QualType::getCVRQualifiers() const {\n  unsigned cvr = getCommonPtr()->CanonicalType.getLocalCVRQualifiers();\n  cvr |= getLocalCVRQualifiers();\n  return cvr;\n}\n\ninline QualType QualType::getCanonicalType() const {\n  QualType canon = getCommonPtr()->CanonicalType;\n  return canon.withFastQualifiers(getLocalFastQualifiers());\n}\n\ninline bool QualType::isCanonical() const {\n  return getTypePtr()->isCanonicalUnqualified();\n}\n\ninline bool QualType::isCanonicalAsParam() const {\n  if (!isCanonical()) return false;\n  if (hasLocalQualifiers()) return false;\n\n  const Type *T = getTypePtr();\n  if (T->isVariablyModifiedType() && T->hasSizedVLAType())\n    return false;\n\n  return !isa<FunctionType>(T) && !isa<ArrayType>(T);\n}\n\ninline bool QualType::isConstQualified() const {\n  return isLocalConstQualified() ||\n         getCommonPtr()->CanonicalType.isLocalConstQualified();\n}\n\ninline bool QualType::isRestrictQualified() const {\n  return isLocalRestrictQualified() ||\n         getCommonPtr()->CanonicalType.isLocalRestrictQualified();\n}\n\n\ninline bool QualType::isVolatileQualified() const {\n  return isLocalVolatileQualified() ||\n         getCommonPtr()->CanonicalType.isLocalVolatileQualified();\n}\n\ninline bool QualType::hasQualifiers() const {\n  return hasLocalQualifiers() ||\n         getCommonPtr()->CanonicalType.hasLocalQualifiers();\n}\n\ninline QualType QualType::getUnqualifiedType() const {\n  if (!getTypePtr()->getCanonicalTypeInternal().hasLocalQualifiers())\n    return QualType(getTypePtr(), 0);\n\n  return QualType(getSplitUnqualifiedTypeImpl(*this).Ty, 0);\n}\n\ninline SplitQualType QualType::getSplitUnqualifiedType() const {\n  if (!getTypePtr()->getCanonicalTypeInternal().hasLocalQualifiers())\n    return split();\n\n  return getSplitUnqualifiedTypeImpl(*this);\n}\n\ninline void QualType::removeLocalConst() {\n  removeLocalFastQualifiers(Qualifiers::Const);\n}\n\ninline void QualType::removeLocalRestrict() {\n  removeLocalFastQualifiers(Qualifiers::Restrict);\n}\n\ninline void QualType::removeLocalVolatile() {\n  removeLocalFastQualifiers(Qualifiers::Volatile);\n}\n\ninline void QualType::removeLocalCVRQualifiers(unsigned Mask) {\n  assert(!(Mask & ~Qualifiers::CVRMask) && \"mask has non-CVR bits\");\n  static_assert((int)Qualifiers::CVRMask == (int)Qualifiers::FastMask,\n                \"Fast bits differ from CVR bits!\");\n\n  // Fast path: we don't need to touch the slow qualifiers.\n  removeLocalFastQualifiers(Mask);\n}\n\n/// Check if this type has any address space qualifier.\ninline bool QualType::hasAddressSpace() const {\n  return getQualifiers().hasAddressSpace();\n}\n\n/// Return the address space of this type.\ninline LangAS QualType::getAddressSpace() const {\n  return getQualifiers().getAddressSpace();\n}\n\n/// Return the gc attribute of this type.\ninline Qualifiers::GC QualType::getObjCGCAttr() const {\n  return getQualifiers().getObjCGCAttr();\n}\n\ninline bool QualType::hasNonTrivialToPrimitiveDefaultInitializeCUnion() const {\n  if (auto *RD = getTypePtr()->getBaseElementTypeUnsafe()->getAsRecordDecl())\n    return hasNonTrivialToPrimitiveDefaultInitializeCUnion(RD);\n  return false;\n}\n\ninline bool QualType::hasNonTrivialToPrimitiveDestructCUnion() const {\n  if (auto *RD = getTypePtr()->getBaseElementTypeUnsafe()->getAsRecordDecl())\n    return hasNonTrivialToPrimitiveDestructCUnion(RD);\n  return false;\n}\n\ninline bool QualType::hasNonTrivialToPrimitiveCopyCUnion() const {\n  if (auto *RD = getTypePtr()->getBaseElementTypeUnsafe()->getAsRecordDecl())\n    return hasNonTrivialToPrimitiveCopyCUnion(RD);\n  return false;\n}\n\ninline FunctionType::ExtInfo getFunctionExtInfo(const Type &t) {\n  if (const auto *PT = t.getAs<PointerType>()) {\n    if (const auto *FT = PT->getPointeeType()->getAs<FunctionType>())\n      return FT->getExtInfo();\n  } else if (const auto *FT = t.getAs<FunctionType>())\n    return FT->getExtInfo();\n\n  return FunctionType::ExtInfo();\n}\n\ninline FunctionType::ExtInfo getFunctionExtInfo(QualType t) {\n  return getFunctionExtInfo(*t);\n}\n\n/// Determine whether this type is more\n/// qualified than the Other type. For example, \"const volatile int\"\n/// is more qualified than \"const int\", \"volatile int\", and\n/// \"int\". However, it is not more qualified than \"const volatile\n/// int\".\ninline bool QualType::isMoreQualifiedThan(QualType other) const {\n  Qualifiers MyQuals = getQualifiers();\n  Qualifiers OtherQuals = other.getQualifiers();\n  return (MyQuals != OtherQuals && MyQuals.compatiblyIncludes(OtherQuals));\n}\n\n/// Determine whether this type is at last\n/// as qualified as the Other type. For example, \"const volatile\n/// int\" is at least as qualified as \"const int\", \"volatile int\",\n/// \"int\", and \"const volatile int\".\ninline bool QualType::isAtLeastAsQualifiedAs(QualType other) const {\n  Qualifiers OtherQuals = other.getQualifiers();\n\n  // Ignore __unaligned qualifier if this type is a void.\n  if (getUnqualifiedType()->isVoidType())\n    OtherQuals.removeUnaligned();\n\n  return getQualifiers().compatiblyIncludes(OtherQuals);\n}\n\n/// If Type is a reference type (e.g., const\n/// int&), returns the type that the reference refers to (\"const\n/// int\"). Otherwise, returns the type itself. This routine is used\n/// throughout Sema to implement C++ 5p6:\n///\n///   If an expression initially has the type \"reference to T\" (8.3.2,\n///   8.5.3), the type is adjusted to \"T\" prior to any further\n///   analysis, the expression designates the object or function\n///   denoted by the reference, and the expression is an lvalue.\ninline QualType QualType::getNonReferenceType() const {\n  if (const auto *RefType = (*this)->getAs<ReferenceType>())\n    return RefType->getPointeeType();\n  else\n    return *this;\n}\n\ninline bool QualType::isCForbiddenLValueType() const {\n  return ((getTypePtr()->isVoidType() && !hasQualifiers()) ||\n          getTypePtr()->isFunctionType());\n}\n\n/// Tests whether the type is categorized as a fundamental type.\n///\n/// \\returns True for types specified in C++0x [basic.fundamental].\ninline bool Type::isFundamentalType() const {\n  return isVoidType() ||\n         isNullPtrType() ||\n         // FIXME: It's really annoying that we don't have an\n         // 'isArithmeticType()' which agrees with the standard definition.\n         (isArithmeticType() && !isEnumeralType());\n}\n\n/// Tests whether the type is categorized as a compound type.\n///\n/// \\returns True for types specified in C++0x [basic.compound].\ninline bool Type::isCompoundType() const {\n  // C++0x [basic.compound]p1:\n  //   Compound types can be constructed in the following ways:\n  //    -- arrays of objects of a given type [...];\n  return isArrayType() ||\n  //    -- functions, which have parameters of given types [...];\n         isFunctionType() ||\n  //    -- pointers to void or objects or functions [...];\n         isPointerType() ||\n  //    -- references to objects or functions of a given type. [...]\n         isReferenceType() ||\n  //    -- classes containing a sequence of objects of various types, [...];\n         isRecordType() ||\n  //    -- unions, which are classes capable of containing objects of different\n  //               types at different times;\n         isUnionType() ||\n  //    -- enumerations, which comprise a set of named constant values. [...];\n         isEnumeralType() ||\n  //    -- pointers to non-static class members, [...].\n         isMemberPointerType();\n}\n\ninline bool Type::isFunctionType() const {\n  return isa<FunctionType>(CanonicalType);\n}\n\ninline bool Type::isPointerType() const {\n  return isa<PointerType>(CanonicalType);\n}\n\ninline bool Type::isAnyPointerType() const {\n  return isPointerType() || isObjCObjectPointerType();\n}\n\ninline bool Type::isBlockPointerType() const {\n  return isa<BlockPointerType>(CanonicalType);\n}\n\ninline bool Type::isReferenceType() const {\n  return isa<ReferenceType>(CanonicalType);\n}\n\ninline bool Type::isLValueReferenceType() const {\n  return isa<LValueReferenceType>(CanonicalType);\n}\n\ninline bool Type::isRValueReferenceType() const {\n  return isa<RValueReferenceType>(CanonicalType);\n}\n\ninline bool Type::isObjectPointerType() const {\n  // Note: an \"object pointer type\" is not the same thing as a pointer to an\n  // object type; rather, it is a pointer to an object type or a pointer to cv\n  // void.\n  if (const auto *T = getAs<PointerType>())\n    return !T->getPointeeType()->isFunctionType();\n  else\n    return false;\n}\n\ninline bool Type::isFunctionPointerType() const {\n  if (const auto *T = getAs<PointerType>())\n    return T->getPointeeType()->isFunctionType();\n  else\n    return false;\n}\n\ninline bool Type::isFunctionReferenceType() const {\n  if (const auto *T = getAs<ReferenceType>())\n    return T->getPointeeType()->isFunctionType();\n  else\n    return false;\n}\n\ninline bool Type::isMemberPointerType() const {\n  return isa<MemberPointerType>(CanonicalType);\n}\n\ninline bool Type::isMemberFunctionPointerType() const {\n  if (const auto *T = getAs<MemberPointerType>())\n    return T->isMemberFunctionPointer();\n  else\n    return false;\n}\n\ninline bool Type::isMemberDataPointerType() const {\n  if (const auto *T = getAs<MemberPointerType>())\n    return T->isMemberDataPointer();\n  else\n    return false;\n}\n\ninline bool Type::isArrayType() const {\n  return isa<ArrayType>(CanonicalType);\n}\n\ninline bool Type::isConstantArrayType() const {\n  return isa<ConstantArrayType>(CanonicalType);\n}\n\ninline bool Type::isIncompleteArrayType() const {\n  return isa<IncompleteArrayType>(CanonicalType);\n}\n\ninline bool Type::isVariableArrayType() const {\n  return isa<VariableArrayType>(CanonicalType);\n}\n\ninline bool Type::isDependentSizedArrayType() const {\n  return isa<DependentSizedArrayType>(CanonicalType);\n}\n\ninline bool Type::isBuiltinType() const {\n  return isa<BuiltinType>(CanonicalType);\n}\n\ninline bool Type::isRecordType() const {\n  return isa<RecordType>(CanonicalType);\n}\n\ninline bool Type::isEnumeralType() const {\n  return isa<EnumType>(CanonicalType);\n}\n\ninline bool Type::isAnyComplexType() const {\n  return isa<ComplexType>(CanonicalType);\n}\n\ninline bool Type::isVectorType() const {\n  return isa<VectorType>(CanonicalType);\n}\n\ninline bool Type::isExtVectorType() const {\n  return isa<ExtVectorType>(CanonicalType);\n}\n\ninline bool Type::isMatrixType() const {\n  return isa<MatrixType>(CanonicalType);\n}\n\ninline bool Type::isConstantMatrixType() const {\n  return isa<ConstantMatrixType>(CanonicalType);\n}\n\ninline bool Type::isDependentAddressSpaceType() const {\n  return isa<DependentAddressSpaceType>(CanonicalType);\n}\n\ninline bool Type::isObjCObjectPointerType() const {\n  return isa<ObjCObjectPointerType>(CanonicalType);\n}\n\ninline bool Type::isObjCObjectType() const {\n  return isa<ObjCObjectType>(CanonicalType);\n}\n\ninline bool Type::isObjCObjectOrInterfaceType() const {\n  return isa<ObjCInterfaceType>(CanonicalType) ||\n    isa<ObjCObjectType>(CanonicalType);\n}\n\ninline bool Type::isAtomicType() const {\n  return isa<AtomicType>(CanonicalType);\n}\n\ninline bool Type::isUndeducedAutoType() const {\n  return isa<AutoType>(CanonicalType);\n}\n\ninline bool Type::isObjCQualifiedIdType() const {\n  if (const auto *OPT = getAs<ObjCObjectPointerType>())\n    return OPT->isObjCQualifiedIdType();\n  return false;\n}\n\ninline bool Type::isObjCQualifiedClassType() const {\n  if (const auto *OPT = getAs<ObjCObjectPointerType>())\n    return OPT->isObjCQualifiedClassType();\n  return false;\n}\n\ninline bool Type::isObjCIdType() const {\n  if (const auto *OPT = getAs<ObjCObjectPointerType>())\n    return OPT->isObjCIdType();\n  return false;\n}\n\ninline bool Type::isObjCClassType() const {\n  if (const auto *OPT = getAs<ObjCObjectPointerType>())\n    return OPT->isObjCClassType();\n  return false;\n}\n\ninline bool Type::isObjCSelType() const {\n  if (const auto *OPT = getAs<PointerType>())\n    return OPT->getPointeeType()->isSpecificBuiltinType(BuiltinType::ObjCSel);\n  return false;\n}\n\ninline bool Type::isObjCBuiltinType() const {\n  return isObjCIdType() || isObjCClassType() || isObjCSelType();\n}\n\ninline bool Type::isDecltypeType() const {\n  return isa<DecltypeType>(this);\n}\n\n#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \\\n  inline bool Type::is##Id##Type() const { \\\n    return isSpecificBuiltinType(BuiltinType::Id); \\\n  }\n#include \"clang/Basic/OpenCLImageTypes.def\"\n\ninline bool Type::isSamplerT() const {\n  return isSpecificBuiltinType(BuiltinType::OCLSampler);\n}\n\ninline bool Type::isEventT() const {\n  return isSpecificBuiltinType(BuiltinType::OCLEvent);\n}\n\ninline bool Type::isClkEventT() const {\n  return isSpecificBuiltinType(BuiltinType::OCLClkEvent);\n}\n\ninline bool Type::isQueueT() const {\n  return isSpecificBuiltinType(BuiltinType::OCLQueue);\n}\n\ninline bool Type::isReserveIDT() const {\n  return isSpecificBuiltinType(BuiltinType::OCLReserveID);\n}\n\ninline bool Type::isImageType() const {\n#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) is##Id##Type() ||\n  return\n#include \"clang/Basic/OpenCLImageTypes.def\"\n      false; // end boolean or operation\n}\n\ninline bool Type::isPipeType() const {\n  return isa<PipeType>(CanonicalType);\n}\n\ninline bool Type::isExtIntType() const {\n  return isa<ExtIntType>(CanonicalType);\n}\n\n#define EXT_OPAQUE_TYPE(ExtType, Id, Ext) \\\n  inline bool Type::is##Id##Type() const { \\\n    return isSpecificBuiltinType(BuiltinType::Id); \\\n  }\n#include \"clang/Basic/OpenCLExtensionTypes.def\"\n\ninline bool Type::isOCLIntelSubgroupAVCType() const {\n#define INTEL_SUBGROUP_AVC_TYPE(ExtType, Id) \\\n  isOCLIntelSubgroupAVC##Id##Type() ||\n  return\n#include \"clang/Basic/OpenCLExtensionTypes.def\"\n    false; // end of boolean or operation\n}\n\ninline bool Type::isOCLExtOpaqueType() const {\n#define EXT_OPAQUE_TYPE(ExtType, Id, Ext) is##Id##Type() ||\n  return\n#include \"clang/Basic/OpenCLExtensionTypes.def\"\n    false; // end of boolean or operation\n}\n\ninline bool Type::isOpenCLSpecificType() const {\n  return isSamplerT() || isEventT() || isImageType() || isClkEventT() ||\n         isQueueT() || isReserveIDT() || isPipeType() || isOCLExtOpaqueType();\n}\n\ninline bool Type::isTemplateTypeParmType() const {\n  return isa<TemplateTypeParmType>(CanonicalType);\n}\n\ninline bool Type::isSpecificBuiltinType(unsigned K) const {\n  if (const BuiltinType *BT = getAs<BuiltinType>()) {\n    return BT->getKind() == static_cast<BuiltinType::Kind>(K);\n  }\n  return false;\n}\n\ninline bool Type::isPlaceholderType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(this))\n    return BT->isPlaceholderType();\n  return false;\n}\n\ninline const BuiltinType *Type::getAsPlaceholderType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(this))\n    if (BT->isPlaceholderType())\n      return BT;\n  return nullptr;\n}\n\ninline bool Type::isSpecificPlaceholderType(unsigned K) const {\n  assert(BuiltinType::isPlaceholderTypeKind((BuiltinType::Kind) K));\n  return isSpecificBuiltinType(K);\n}\n\ninline bool Type::isNonOverloadPlaceholderType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(this))\n    return BT->isNonOverloadPlaceholderType();\n  return false;\n}\n\ninline bool Type::isVoidType() const {\n  return isSpecificBuiltinType(BuiltinType::Void);\n}\n\ninline bool Type::isHalfType() const {\n  // FIXME: Should we allow complex __fp16? Probably not.\n  return isSpecificBuiltinType(BuiltinType::Half);\n}\n\ninline bool Type::isFloat16Type() const {\n  return isSpecificBuiltinType(BuiltinType::Float16);\n}\n\ninline bool Type::isBFloat16Type() const {\n  return isSpecificBuiltinType(BuiltinType::BFloat16);\n}\n\ninline bool Type::isFloat128Type() const {\n  return isSpecificBuiltinType(BuiltinType::Float128);\n}\n\ninline bool Type::isNullPtrType() const {\n  return isSpecificBuiltinType(BuiltinType::NullPtr);\n}\n\nbool IsEnumDeclComplete(EnumDecl *);\nbool IsEnumDeclScoped(EnumDecl *);\n\ninline bool Type::isIntegerType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType))\n    return BT->getKind() >= BuiltinType::Bool &&\n           BT->getKind() <= BuiltinType::Int128;\n  if (const EnumType *ET = dyn_cast<EnumType>(CanonicalType)) {\n    // Incomplete enum types are not treated as integer types.\n    // FIXME: In C++, enum types are never integer types.\n    return IsEnumDeclComplete(ET->getDecl()) &&\n      !IsEnumDeclScoped(ET->getDecl());\n  }\n  return isExtIntType();\n}\n\ninline bool Type::isFixedPointType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType)) {\n    return BT->getKind() >= BuiltinType::ShortAccum &&\n           BT->getKind() <= BuiltinType::SatULongFract;\n  }\n  return false;\n}\n\ninline bool Type::isFixedPointOrIntegerType() const {\n  return isFixedPointType() || isIntegerType();\n}\n\ninline bool Type::isSaturatedFixedPointType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType)) {\n    return BT->getKind() >= BuiltinType::SatShortAccum &&\n           BT->getKind() <= BuiltinType::SatULongFract;\n  }\n  return false;\n}\n\ninline bool Type::isUnsaturatedFixedPointType() const {\n  return isFixedPointType() && !isSaturatedFixedPointType();\n}\n\ninline bool Type::isSignedFixedPointType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType)) {\n    return ((BT->getKind() >= BuiltinType::ShortAccum &&\n             BT->getKind() <= BuiltinType::LongAccum) ||\n            (BT->getKind() >= BuiltinType::ShortFract &&\n             BT->getKind() <= BuiltinType::LongFract) ||\n            (BT->getKind() >= BuiltinType::SatShortAccum &&\n             BT->getKind() <= BuiltinType::SatLongAccum) ||\n            (BT->getKind() >= BuiltinType::SatShortFract &&\n             BT->getKind() <= BuiltinType::SatLongFract));\n  }\n  return false;\n}\n\ninline bool Type::isUnsignedFixedPointType() const {\n  return isFixedPointType() && !isSignedFixedPointType();\n}\n\ninline bool Type::isScalarType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType))\n    return BT->getKind() > BuiltinType::Void &&\n           BT->getKind() <= BuiltinType::NullPtr;\n  if (const EnumType *ET = dyn_cast<EnumType>(CanonicalType))\n    // Enums are scalar types, but only if they are defined.  Incomplete enums\n    // are not treated as scalar types.\n    return IsEnumDeclComplete(ET->getDecl());\n  return isa<PointerType>(CanonicalType) ||\n         isa<BlockPointerType>(CanonicalType) ||\n         isa<MemberPointerType>(CanonicalType) ||\n         isa<ComplexType>(CanonicalType) ||\n         isa<ObjCObjectPointerType>(CanonicalType) ||\n         isExtIntType();\n}\n\ninline bool Type::isIntegralOrEnumerationType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType))\n    return BT->getKind() >= BuiltinType::Bool &&\n           BT->getKind() <= BuiltinType::Int128;\n\n  // Check for a complete enum type; incomplete enum types are not properly an\n  // enumeration type in the sense required here.\n  if (const auto *ET = dyn_cast<EnumType>(CanonicalType))\n    return IsEnumDeclComplete(ET->getDecl());\n\n  return isExtIntType();\n}\n\ninline bool Type::isBooleanType() const {\n  if (const auto *BT = dyn_cast<BuiltinType>(CanonicalType))\n    return BT->getKind() == BuiltinType::Bool;\n  return false;\n}\n\ninline bool Type::isUndeducedType() const {\n  auto *DT = getContainedDeducedType();\n  return DT && !DT->isDeduced();\n}\n\n/// Determines whether this is a type for which one can define\n/// an overloaded operator.\ninline bool Type::isOverloadableType() const {\n  return isDependentType() || isRecordType() || isEnumeralType();\n}\n\n/// Determines whether this type is written as a typedef-name.\ninline bool Type::isTypedefNameType() const {\n  if (getAs<TypedefType>())\n    return true;\n  if (auto *TST = getAs<TemplateSpecializationType>())\n    return TST->isTypeAlias();\n  return false;\n}\n\n/// Determines whether this type can decay to a pointer type.\ninline bool Type::canDecayToPointerType() const {\n  return isFunctionType() || isArrayType();\n}\n\ninline bool Type::hasPointerRepresentation() const {\n  return (isPointerType() || isReferenceType() || isBlockPointerType() ||\n          isObjCObjectPointerType() || isNullPtrType());\n}\n\ninline bool Type::hasObjCPointerRepresentation() const {\n  return isObjCObjectPointerType();\n}\n\ninline const Type *Type::getBaseElementTypeUnsafe() const {\n  const Type *type = this;\n  while (const ArrayType *arrayType = type->getAsArrayTypeUnsafe())\n    type = arrayType->getElementType().getTypePtr();\n  return type;\n}\n\ninline const Type *Type::getPointeeOrArrayElementType() const {\n  const Type *type = this;\n  if (type->isAnyPointerType())\n    return type->getPointeeType().getTypePtr();\n  else if (type->isArrayType())\n    return type->getBaseElementTypeUnsafe();\n  return type;\n}\n/// Insertion operator for partial diagnostics. This allows sending adress\n/// spaces into a diagnostic with <<.\ninline const StreamingDiagnostic &operator<<(const StreamingDiagnostic &PD,\n                                             LangAS AS) {\n  PD.AddTaggedVal(static_cast<std::underlying_type_t<LangAS>>(AS),\n                  DiagnosticsEngine::ArgumentKind::ak_addrspace);\n  return PD;\n}\n\n/// Insertion operator for partial diagnostics. This allows sending Qualifiers\n/// into a diagnostic with <<.\ninline const StreamingDiagnostic &operator<<(const StreamingDiagnostic &PD,\n                                             Qualifiers Q) {\n  PD.AddTaggedVal(Q.getAsOpaqueValue(),\n                  DiagnosticsEngine::ArgumentKind::ak_qual);\n  return PD;\n}\n\n/// Insertion operator for partial diagnostics.  This allows sending QualType's\n/// into a diagnostic with <<.\ninline const StreamingDiagnostic &operator<<(const StreamingDiagnostic &PD,\n                                             QualType T) {\n  PD.AddTaggedVal(reinterpret_cast<intptr_t>(T.getAsOpaquePtr()),\n                  DiagnosticsEngine::ak_qualtype);\n  return PD;\n}\n\n// Helper class template that is used by Type::getAs to ensure that one does\n// not try to look through a qualified type to get to an array type.\ntemplate <typename T>\nusing TypeIsArrayType =\n    std::integral_constant<bool, std::is_same<T, ArrayType>::value ||\n                                     std::is_base_of<ArrayType, T>::value>;\n\n// Member-template getAs<specific type>'.\ntemplate <typename T> const T *Type::getAs() const {\n  static_assert(!TypeIsArrayType<T>::value,\n                \"ArrayType cannot be used with getAs!\");\n\n  // If this is directly a T type, return it.\n  if (const auto *Ty = dyn_cast<T>(this))\n    return Ty;\n\n  // If the canonical form of this type isn't the right kind, reject it.\n  if (!isa<T>(CanonicalType))\n    return nullptr;\n\n  // If this is a typedef for the type, strip the typedef off without\n  // losing all typedef information.\n  return cast<T>(getUnqualifiedDesugaredType());\n}\n\ntemplate <typename T> const T *Type::getAsAdjusted() const {\n  static_assert(!TypeIsArrayType<T>::value, \"ArrayType cannot be used with getAsAdjusted!\");\n\n  // If this is directly a T type, return it.\n  if (const auto *Ty = dyn_cast<T>(this))\n    return Ty;\n\n  // If the canonical form of this type isn't the right kind, reject it.\n  if (!isa<T>(CanonicalType))\n    return nullptr;\n\n  // Strip off type adjustments that do not modify the underlying nature of the\n  // type.\n  const Type *Ty = this;\n  while (Ty) {\n    if (const auto *A = dyn_cast<AttributedType>(Ty))\n      Ty = A->getModifiedType().getTypePtr();\n    else if (const auto *E = dyn_cast<ElaboratedType>(Ty))\n      Ty = E->desugar().getTypePtr();\n    else if (const auto *P = dyn_cast<ParenType>(Ty))\n      Ty = P->desugar().getTypePtr();\n    else if (const auto *A = dyn_cast<AdjustedType>(Ty))\n      Ty = A->desugar().getTypePtr();\n    else if (const auto *M = dyn_cast<MacroQualifiedType>(Ty))\n      Ty = M->desugar().getTypePtr();\n    else\n      break;\n  }\n\n  // Just because the canonical type is correct does not mean we can use cast<>,\n  // since we may not have stripped off all the sugar down to the base type.\n  return dyn_cast<T>(Ty);\n}\n\ninline const ArrayType *Type::getAsArrayTypeUnsafe() const {\n  // If this is directly an array type, return it.\n  if (const auto *arr = dyn_cast<ArrayType>(this))\n    return arr;\n\n  // If the canonical form of this type isn't the right kind, reject it.\n  if (!isa<ArrayType>(CanonicalType))\n    return nullptr;\n\n  // If this is a typedef for the type, strip the typedef off without\n  // losing all typedef information.\n  return cast<ArrayType>(getUnqualifiedDesugaredType());\n}\n\ntemplate <typename T> const T *Type::castAs() const {\n  static_assert(!TypeIsArrayType<T>::value,\n                \"ArrayType cannot be used with castAs!\");\n\n  if (const auto *ty = dyn_cast<T>(this)) return ty;\n  assert(isa<T>(CanonicalType));\n  return cast<T>(getUnqualifiedDesugaredType());\n}\n\ninline const ArrayType *Type::castAsArrayTypeUnsafe() const {\n  assert(isa<ArrayType>(CanonicalType));\n  if (const auto *arr = dyn_cast<ArrayType>(this)) return arr;\n  return cast<ArrayType>(getUnqualifiedDesugaredType());\n}\n\nDecayedType::DecayedType(QualType OriginalType, QualType DecayedPtr,\n                         QualType CanonicalPtr)\n    : AdjustedType(Decayed, OriginalType, DecayedPtr, CanonicalPtr) {\n#ifndef NDEBUG\n  QualType Adjusted = getAdjustedType();\n  (void)AttributedType::stripOuterNullability(Adjusted);\n  assert(isa<PointerType>(Adjusted));\n#endif\n}\n\nQualType DecayedType::getPointeeType() const {\n  QualType Decayed = getDecayedType();\n  (void)AttributedType::stripOuterNullability(Decayed);\n  return cast<PointerType>(Decayed)->getPointeeType();\n}\n\n// Get the decimal string representation of a fixed point type, represented\n// as a scaled integer.\n// TODO: At some point, we should change the arguments to instead just accept an\n// APFixedPoint instead of APSInt and scale.\nvoid FixedPointValueToString(SmallVectorImpl<char> &Str, llvm::APSInt Val,\n                             unsigned Scale);\n\n} // namespace clang\n\n#endif // LLVM_CLANG_AST_TYPE_H\n"}, "35": {"id": 35, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "content": "//==-- CGFunctionInfo.h - Representation of function argument/return types -==//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// Defines CGFunctionInfo and associated types used in representing the\n// LLVM source types and ABI-coerced types for function arguments and\n// return values.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_CODEGEN_CGFUNCTIONINFO_H\n#define LLVM_CLANG_CODEGEN_CGFUNCTIONINFO_H\n\n#include \"clang/AST/CanonicalType.h\"\n#include \"clang/AST/CharUnits.h\"\n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/Type.h\"\n#include \"llvm/IR/DerivedTypes.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/Support/TrailingObjects.h\"\n#include <cassert>\n\nnamespace clang {\nnamespace CodeGen {\n\n/// ABIArgInfo - Helper class to encapsulate information about how a\n/// specific C type should be passed to or returned from a function.\nclass ABIArgInfo {\npublic:\n  enum Kind : uint8_t {\n    /// Direct - Pass the argument directly using the normal converted LLVM\n    /// type, or by coercing to another specified type stored in\n    /// 'CoerceToType').  If an offset is specified (in UIntData), then the\n    /// argument passed is offset by some number of bytes in the memory\n    /// representation. A dummy argument is emitted before the real argument\n    /// if the specified type stored in \"PaddingType\" is not zero.\n    Direct,\n\n    /// Extend - Valid only for integer argument types. Same as 'direct'\n    /// but also emit a zero/sign extension attribute.\n    Extend,\n\n    /// Indirect - Pass the argument indirectly via a hidden pointer with the\n    /// specified alignment (0 indicates default alignment) and address space.\n    Indirect,\n\n    /// IndirectAliased - Similar to Indirect, but the pointer may be to an\n    /// object that is otherwise referenced.  The object is known to not be\n    /// modified through any other references for the duration of the call, and\n    /// the callee must not itself modify the object.  Because C allows\n    /// parameter variables to be modified and guarantees that they have unique\n    /// addresses, the callee must defensively copy the object into a local\n    /// variable if it might be modified or its address might be compared.\n    /// Since those are uncommon, in principle this convention allows programs\n    /// to avoid copies in more situations.  However, it may introduce *extra*\n    /// copies if the callee fails to prove that a copy is unnecessary and the\n    /// caller naturally produces an unaliased object for the argument.\n    IndirectAliased,\n\n    /// Ignore - Ignore the argument (treat as void). Useful for void and\n    /// empty structs.\n    Ignore,\n\n    /// Expand - Only valid for aggregate argument types. The structure should\n    /// be expanded into consecutive arguments for its constituent fields.\n    /// Currently expand is only allowed on structures whose fields\n    /// are all scalar types or are themselves expandable types.\n    Expand,\n\n    /// CoerceAndExpand - Only valid for aggregate argument types. The\n    /// structure should be expanded into consecutive arguments corresponding\n    /// to the non-array elements of the type stored in CoerceToType.\n    /// Array elements in the type are assumed to be padding and skipped.\n    CoerceAndExpand,\n\n    /// InAlloca - Pass the argument directly using the LLVM inalloca attribute.\n    /// This is similar to indirect with byval, except it only applies to\n    /// arguments stored in memory and forbids any implicit copies.  When\n    /// applied to a return type, it means the value is returned indirectly via\n    /// an implicit sret parameter stored in the argument struct.\n    InAlloca,\n    KindFirst = Direct,\n    KindLast = InAlloca\n  };\n\nprivate:\n  llvm::Type *TypeData; // canHaveCoerceToType()\n  union {\n    llvm::Type *PaddingType; // canHavePaddingType()\n    llvm::Type *UnpaddedCoerceAndExpandType; // isCoerceAndExpand()\n  };\n  union {\n    unsigned DirectOffset;     // isDirect() || isExtend()\n    unsigned IndirectAlign;    // isIndirect()\n    unsigned AllocaFieldIndex; // isInAlloca()\n  };\n  Kind TheKind;\n  unsigned IndirectAddrSpace : 24; // isIndirect()\n  bool PaddingInReg : 1;\n  bool InAllocaSRet : 1;    // isInAlloca()\n  bool InAllocaIndirect : 1;// isInAlloca()\n  bool IndirectByVal : 1;   // isIndirect()\n  bool IndirectRealign : 1; // isIndirect()\n  bool SRetAfterThis : 1;   // isIndirect()\n  bool InReg : 1;           // isDirect() || isExtend() || isIndirect()\n  bool CanBeFlattened: 1;   // isDirect()\n  bool SignExt : 1;         // isExtend()\n\n  bool canHavePaddingType() const {\n    return isDirect() || isExtend() || isIndirect() || isIndirectAliased() ||\n           isExpand();\n  }\n  void setPaddingType(llvm::Type *T) {\n    assert(canHavePaddingType());\n    PaddingType = T;\n  }\n\n  void setUnpaddedCoerceToType(llvm::Type *T) {\n    assert(isCoerceAndExpand());\n    UnpaddedCoerceAndExpandType = T;\n  }\n\npublic:\n  ABIArgInfo(Kind K = Direct)\n      : TypeData(nullptr), PaddingType(nullptr), DirectOffset(0), TheKind(K),\n        IndirectAddrSpace(0), PaddingInReg(false), InAllocaSRet(false),\n        InAllocaIndirect(false), IndirectByVal(false), IndirectRealign(false),\n        SRetAfterThis(false), InReg(false), CanBeFlattened(false),\n        SignExt(false) {}\n\n  static ABIArgInfo getDirect(llvm::Type *T = nullptr, unsigned Offset = 0,\n                              llvm::Type *Padding = nullptr,\n                              bool CanBeFlattened = true) {\n    auto AI = ABIArgInfo(Direct);\n    AI.setCoerceToType(T);\n    AI.setPaddingType(Padding);\n    AI.setDirectOffset(Offset);\n    AI.setCanBeFlattened(CanBeFlattened);\n    return AI;\n  }\n  static ABIArgInfo getDirectInReg(llvm::Type *T = nullptr) {\n    auto AI = getDirect(T);\n    AI.setInReg(true);\n    return AI;\n  }\n\n  static ABIArgInfo getSignExtend(QualType Ty, llvm::Type *T = nullptr) {\n    assert(Ty->isIntegralOrEnumerationType() && \"Unexpected QualType\");\n    auto AI = ABIArgInfo(Extend);\n    AI.setCoerceToType(T);\n    AI.setPaddingType(nullptr);\n    AI.setDirectOffset(0);\n    AI.setSignExt(true);\n    return AI;\n  }\n\n  static ABIArgInfo getZeroExtend(QualType Ty, llvm::Type *T = nullptr) {\n    assert(Ty->isIntegralOrEnumerationType() && \"Unexpected QualType\");\n    auto AI = ABIArgInfo(Extend);\n    AI.setCoerceToType(T);\n    AI.setPaddingType(nullptr);\n    AI.setDirectOffset(0);\n    AI.setSignExt(false);\n    return AI;\n  }\n\n  // ABIArgInfo will record the argument as being extended based on the sign\n  // of its type.\n  static ABIArgInfo getExtend(QualType Ty, llvm::Type *T = nullptr) {\n    assert(Ty->isIntegralOrEnumerationType() && \"Unexpected QualType\");\n    if (Ty->hasSignedIntegerRepresentation())\n      return getSignExtend(Ty, T);\n    return getZeroExtend(Ty, T);\n  }\n\n  static ABIArgInfo getExtendInReg(QualType Ty, llvm::Type *T = nullptr) {\n    auto AI = getExtend(Ty, T);\n    AI.setInReg(true);\n    return AI;\n  }\n  static ABIArgInfo getIgnore() {\n    return ABIArgInfo(Ignore);\n  }\n  static ABIArgInfo getIndirect(CharUnits Alignment, bool ByVal = true,\n                                bool Realign = false,\n                                llvm::Type *Padding = nullptr) {\n    auto AI = ABIArgInfo(Indirect);\n    AI.setIndirectAlign(Alignment);\n    AI.setIndirectByVal(ByVal);\n    AI.setIndirectRealign(Realign);\n    AI.setSRetAfterThis(false);\n    AI.setPaddingType(Padding);\n    return AI;\n  }\n\n  /// Pass this in memory using the IR byref attribute.\n  static ABIArgInfo getIndirectAliased(CharUnits Alignment, unsigned AddrSpace,\n                                       bool Realign = false,\n                                       llvm::Type *Padding = nullptr) {\n    auto AI = ABIArgInfo(IndirectAliased);\n    AI.setIndirectAlign(Alignment);\n    AI.setIndirectRealign(Realign);\n    AI.setPaddingType(Padding);\n    AI.setIndirectAddrSpace(AddrSpace);\n    return AI;\n  }\n\n  static ABIArgInfo getIndirectInReg(CharUnits Alignment, bool ByVal = true,\n                                     bool Realign = false) {\n    auto AI = getIndirect(Alignment, ByVal, Realign);\n    AI.setInReg(true);\n    return AI;\n  }\n  static ABIArgInfo getInAlloca(unsigned FieldIndex, bool Indirect = false) {\n    auto AI = ABIArgInfo(InAlloca);\n    AI.setInAllocaFieldIndex(FieldIndex);\n    AI.setInAllocaIndirect(Indirect);\n    return AI;\n  }\n  static ABIArgInfo getExpand() {\n    auto AI = ABIArgInfo(Expand);\n    AI.setPaddingType(nullptr);\n    return AI;\n  }\n  static ABIArgInfo getExpandWithPadding(bool PaddingInReg,\n                                         llvm::Type *Padding) {\n    auto AI = getExpand();\n    AI.setPaddingInReg(PaddingInReg);\n    AI.setPaddingType(Padding);\n    return AI;\n  }\n\n  /// \\param unpaddedCoerceToType The coerce-to type with padding elements\n  ///   removed, canonicalized to a single element if it would otherwise\n  ///   have exactly one element.\n  static ABIArgInfo getCoerceAndExpand(llvm::StructType *coerceToType,\n                                       llvm::Type *unpaddedCoerceToType) {\n#ifndef NDEBUG\n    // Sanity checks on unpaddedCoerceToType.\n\n    // Assert that we only have a struct type if there are multiple elements.\n    auto unpaddedStruct = dyn_cast<llvm::StructType>(unpaddedCoerceToType);\n    assert(!unpaddedStruct || unpaddedStruct->getNumElements() != 1);\n\n    // Assert that all the non-padding elements have a corresponding element\n    // in the unpadded type.\n    unsigned unpaddedIndex = 0;\n    for (auto eltType : coerceToType->elements()) {\n      if (isPaddingForCoerceAndExpand(eltType)) continue;\n      if (unpaddedStruct) {\n        assert(unpaddedStruct->getElementType(unpaddedIndex) == eltType);\n      } else {\n        assert(unpaddedIndex == 0 && unpaddedCoerceToType == eltType);\n      }\n      unpaddedIndex++;\n    }\n\n    // Assert that there aren't extra elements in the unpadded type.\n    if (unpaddedStruct) {\n      assert(unpaddedStruct->getNumElements() == unpaddedIndex);\n    } else {\n      assert(unpaddedIndex == 1);\n    }\n#endif\n\n    auto AI = ABIArgInfo(CoerceAndExpand);\n    AI.setCoerceToType(coerceToType);\n    AI.setUnpaddedCoerceToType(unpaddedCoerceToType);\n    return AI;\n  }\n\n  static bool isPaddingForCoerceAndExpand(llvm::Type *eltType) {\n    if (eltType->isArrayTy()) {\n      assert(eltType->getArrayElementType()->isIntegerTy(8));\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  Kind getKind() const { return TheKind; }\n  bool isDirect() const { return TheKind == Direct; }\n  bool isInAlloca() const { return TheKind == InAlloca; }\n  bool isExtend() const { return TheKind == Extend; }\n  bool isIgnore() const { return TheKind == Ignore; }\n  bool isIndirect() const { return TheKind == Indirect; }\n  bool isIndirectAliased() const { return TheKind == IndirectAliased; }\n  bool isExpand() const { return TheKind == Expand; }\n  bool isCoerceAndExpand() const { return TheKind == CoerceAndExpand; }\n\n  bool canHaveCoerceToType() const {\n    return isDirect() || isExtend() || isCoerceAndExpand();\n  }\n\n  // Direct/Extend accessors\n  unsigned getDirectOffset() const {\n    assert((isDirect() || isExtend()) && \"Not a direct or extend kind\");\n    return DirectOffset;\n  }\n  void setDirectOffset(unsigned Offset) {\n    assert((isDirect() || isExtend()) && \"Not a direct or extend kind\");\n    DirectOffset = Offset;\n  }\n\n  bool isSignExt() const {\n    assert(isExtend() && \"Invalid kind!\");\n    return SignExt;\n  }\n  void setSignExt(bool SExt) {\n    assert(isExtend() && \"Invalid kind!\");\n    SignExt = SExt;\n  }\n\n  llvm::Type *getPaddingType() const {\n    return (canHavePaddingType() ? PaddingType : nullptr);\n  }\n\n  bool getPaddingInReg() const {\n    return PaddingInReg;\n  }\n  void setPaddingInReg(bool PIR) {\n    PaddingInReg = PIR;\n  }\n\n  llvm::Type *getCoerceToType() const {\n    assert(canHaveCoerceToType() && \"Invalid kind!\");\n    return TypeData;\n  }\n\n  void setCoerceToType(llvm::Type *T) {\n    assert(canHaveCoerceToType() && \"Invalid kind!\");\n    TypeData = T;\n  }\n\n  llvm::StructType *getCoerceAndExpandType() const {\n    assert(isCoerceAndExpand());\n    return cast<llvm::StructType>(TypeData);\n  }\n\n  llvm::Type *getUnpaddedCoerceAndExpandType() const {\n    assert(isCoerceAndExpand());\n    return UnpaddedCoerceAndExpandType;\n  }\n\n  ArrayRef<llvm::Type *>getCoerceAndExpandTypeSequence() const {\n    assert(isCoerceAndExpand());\n    if (auto structTy =\n          dyn_cast<llvm::StructType>(UnpaddedCoerceAndExpandType)) {\n      return structTy->elements();\n    } else {\n      return llvm::makeArrayRef(&UnpaddedCoerceAndExpandType, 1);\n    }\n  }\n\n  bool getInReg() const {\n    assert((isDirect() || isExtend() || isIndirect()) && \"Invalid kind!\");\n    return InReg;\n  }\n\n  void setInReg(bool IR) {\n    assert((isDirect() || isExtend() || isIndirect()) && \"Invalid kind!\");\n    InReg = IR;\n  }\n\n  // Indirect accessors\n  CharUnits getIndirectAlign() const {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    return CharUnits::fromQuantity(IndirectAlign);\n  }\n  void setIndirectAlign(CharUnits IA) {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    IndirectAlign = IA.getQuantity();\n  }\n\n  bool getIndirectByVal() const {\n    assert(isIndirect() && \"Invalid kind!\");\n    return IndirectByVal;\n  }\n  void setIndirectByVal(bool IBV) {\n    assert(isIndirect() && \"Invalid kind!\");\n    IndirectByVal = IBV;\n  }\n\n  unsigned getIndirectAddrSpace() const {\n    assert(isIndirectAliased() && \"Invalid kind!\");\n    return IndirectAddrSpace;\n  }\n\n  void setIndirectAddrSpace(unsigned AddrSpace) {\n    assert(isIndirectAliased() && \"Invalid kind!\");\n    IndirectAddrSpace = AddrSpace;\n  }\n\n  bool getIndirectRealign() const {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    return IndirectRealign;\n  }\n  void setIndirectRealign(bool IR) {\n    assert((isIndirect() || isIndirectAliased()) && \"Invalid kind!\");\n    IndirectRealign = IR;\n  }\n\n  bool isSRetAfterThis() const {\n    assert(isIndirect() && \"Invalid kind!\");\n    return SRetAfterThis;\n  }\n  void setSRetAfterThis(bool AfterThis) {\n    assert(isIndirect() && \"Invalid kind!\");\n    SRetAfterThis = AfterThis;\n  }\n\n  unsigned getInAllocaFieldIndex() const {\n    assert(isInAlloca() && \"Invalid kind!\");\n    return AllocaFieldIndex;\n  }\n  void setInAllocaFieldIndex(unsigned FieldIndex) {\n    assert(isInAlloca() && \"Invalid kind!\");\n    AllocaFieldIndex = FieldIndex;\n  }\n\n  unsigned getInAllocaIndirect() const {\n    assert(isInAlloca() && \"Invalid kind!\");\n    return InAllocaIndirect;\n  }\n  void setInAllocaIndirect(bool Indirect) {\n    assert(isInAlloca() && \"Invalid kind!\");\n    InAllocaIndirect = Indirect;\n  }\n\n  /// Return true if this field of an inalloca struct should be returned\n  /// to implement a struct return calling convention.\n  bool getInAllocaSRet() const {\n    assert(isInAlloca() && \"Invalid kind!\");\n    return InAllocaSRet;\n  }\n\n  void setInAllocaSRet(bool SRet) {\n    assert(isInAlloca() && \"Invalid kind!\");\n    InAllocaSRet = SRet;\n  }\n\n  bool getCanBeFlattened() const {\n    assert(isDirect() && \"Invalid kind!\");\n    return CanBeFlattened;\n  }\n\n  void setCanBeFlattened(bool Flatten) {\n    assert(isDirect() && \"Invalid kind!\");\n    CanBeFlattened = Flatten;\n  }\n\n  void dump() const;\n};\n\n/// A class for recording the number of arguments that a function\n/// signature requires.\nclass RequiredArgs {\n  /// The number of required arguments, or ~0 if the signature does\n  /// not permit optional arguments.\n  unsigned NumRequired;\npublic:\n  enum All_t { All };\n\n  RequiredArgs(All_t _) : NumRequired(~0U) {}\n  explicit RequiredArgs(unsigned n) : NumRequired(n) {\n    assert(n != ~0U);\n  }\n\n  /// Compute the arguments required by the given formal prototype,\n  /// given that there may be some additional, non-formal arguments\n  /// in play.\n  ///\n  /// If FD is not null, this will consider pass_object_size params in FD.\n  static RequiredArgs forPrototypePlus(const FunctionProtoType *prototype,\n                                       unsigned additional) {\n    if (!prototype->isVariadic()) return All;\n\n    if (prototype->hasExtParameterInfos())\n      additional += llvm::count_if(\n          prototype->getExtParameterInfos(),\n          [](const FunctionProtoType::ExtParameterInfo &ExtInfo) {\n            return ExtInfo.hasPassObjectSize();\n          });\n\n    return RequiredArgs(prototype->getNumParams() + additional);\n  }\n\n  static RequiredArgs forPrototypePlus(CanQual<FunctionProtoType> prototype,\n                                       unsigned additional) {\n    return forPrototypePlus(prototype.getTypePtr(), additional);\n  }\n\n  static RequiredArgs forPrototype(const FunctionProtoType *prototype) {\n    return forPrototypePlus(prototype, 0);\n  }\n\n  static RequiredArgs forPrototype(CanQual<FunctionProtoType> prototype) {\n    return forPrototypePlus(prototype.getTypePtr(), 0);\n  }\n\n  bool allowsOptionalArgs() const { return NumRequired != ~0U; }\n  unsigned getNumRequiredArgs() const {\n    assert(allowsOptionalArgs());\n    return NumRequired;\n  }\n\n  unsigned getOpaqueData() const { return NumRequired; }\n  static RequiredArgs getFromOpaqueData(unsigned value) {\n    if (value == ~0U) return All;\n    return RequiredArgs(value);\n  }\n};\n\n// Implementation detail of CGFunctionInfo, factored out so it can be named\n// in the TrailingObjects base class of CGFunctionInfo.\nstruct CGFunctionInfoArgInfo {\n  CanQualType type;\n  ABIArgInfo info;\n};\n\n/// CGFunctionInfo - Class to encapsulate the information about a\n/// function definition.\nclass CGFunctionInfo final\n    : public llvm::FoldingSetNode,\n      private llvm::TrailingObjects<CGFunctionInfo, CGFunctionInfoArgInfo,\n                                    FunctionProtoType::ExtParameterInfo> {\n  typedef CGFunctionInfoArgInfo ArgInfo;\n  typedef FunctionProtoType::ExtParameterInfo ExtParameterInfo;\n\n  /// The LLVM::CallingConv to use for this function (as specified by the\n  /// user).\n  unsigned CallingConvention : 8;\n\n  /// The LLVM::CallingConv to actually use for this function, which may\n  /// depend on the ABI.\n  unsigned EffectiveCallingConvention : 8;\n\n  /// The clang::CallingConv that this was originally created with.\n  unsigned ASTCallingConvention : 6;\n\n  /// Whether this is an instance method.\n  unsigned InstanceMethod : 1;\n\n  /// Whether this is a chain call.\n  unsigned ChainCall : 1;\n\n  /// Whether this function is a CMSE nonsecure call\n  unsigned CmseNSCall : 1;\n\n  /// Whether this function is noreturn.\n  unsigned NoReturn : 1;\n\n  /// Whether this function is returns-retained.\n  unsigned ReturnsRetained : 1;\n\n  /// Whether this function saved caller registers.\n  unsigned NoCallerSavedRegs : 1;\n\n  /// How many arguments to pass inreg.\n  unsigned HasRegParm : 1;\n  unsigned RegParm : 3;\n\n  /// Whether this function has nocf_check attribute.\n  unsigned NoCfCheck : 1;\n\n  RequiredArgs Required;\n\n  /// The struct representing all arguments passed in memory.  Only used when\n  /// passing non-trivial types with inalloca.  Not part of the profile.\n  llvm::StructType *ArgStruct;\n  unsigned ArgStructAlign : 31;\n  unsigned HasExtParameterInfos : 1;\n\n  unsigned NumArgs;\n\n  ArgInfo *getArgsBuffer() {\n    return getTrailingObjects<ArgInfo>();\n  }\n  const ArgInfo *getArgsBuffer() const {\n    return getTrailingObjects<ArgInfo>();\n  }\n\n  ExtParameterInfo *getExtParameterInfosBuffer() {\n    return getTrailingObjects<ExtParameterInfo>();\n  }\n  const ExtParameterInfo *getExtParameterInfosBuffer() const{\n    return getTrailingObjects<ExtParameterInfo>();\n  }\n\n  CGFunctionInfo() : Required(RequiredArgs::All) {}\n\npublic:\n  static CGFunctionInfo *create(unsigned llvmCC,\n                                bool instanceMethod,\n                                bool chainCall,\n                                const FunctionType::ExtInfo &extInfo,\n                                ArrayRef<ExtParameterInfo> paramInfos,\n                                CanQualType resultType,\n                                ArrayRef<CanQualType> argTypes,\n                                RequiredArgs required);\n  void operator delete(void *p) { ::operator delete(p); }\n\n  // Friending class TrailingObjects is apparently not good enough for MSVC,\n  // so these have to be public.\n  friend class TrailingObjects;\n  size_t numTrailingObjects(OverloadToken<ArgInfo>) const {\n    return NumArgs + 1;\n  }\n  size_t numTrailingObjects(OverloadToken<ExtParameterInfo>) const {\n    return (HasExtParameterInfos ? NumArgs : 0);\n  }\n\n  typedef const ArgInfo *const_arg_iterator;\n  typedef ArgInfo *arg_iterator;\n\n  MutableArrayRef<ArgInfo> arguments() {\n    return MutableArrayRef<ArgInfo>(arg_begin(), NumArgs);\n  }\n  ArrayRef<ArgInfo> arguments() const {\n    return ArrayRef<ArgInfo>(arg_begin(), NumArgs);\n  }\n\n  const_arg_iterator arg_begin() const { return getArgsBuffer() + 1; }\n  const_arg_iterator arg_end() const { return getArgsBuffer() + 1 + NumArgs; }\n  arg_iterator arg_begin() { return getArgsBuffer() + 1; }\n  arg_iterator arg_end() { return getArgsBuffer() + 1 + NumArgs; }\n\n  unsigned  arg_size() const { return NumArgs; }\n\n  bool isVariadic() const { return Required.allowsOptionalArgs(); }\n  RequiredArgs getRequiredArgs() const { return Required; }\n  unsigned getNumRequiredArgs() const {\n    return isVariadic() ? getRequiredArgs().getNumRequiredArgs() : arg_size();\n  }\n\n  bool isInstanceMethod() const { return InstanceMethod; }\n\n  bool isChainCall() const { return ChainCall; }\n\n  bool isCmseNSCall() const { return CmseNSCall; }\n\n  bool isNoReturn() const { return NoReturn; }\n\n  /// In ARC, whether this function retains its return value.  This\n  /// is not always reliable for call sites.\n  bool isReturnsRetained() const { return ReturnsRetained; }\n\n  /// Whether this function no longer saves caller registers.\n  bool isNoCallerSavedRegs() const { return NoCallerSavedRegs; }\n\n  /// Whether this function has nocf_check attribute.\n  bool isNoCfCheck() const { return NoCfCheck; }\n\n  /// getASTCallingConvention() - Return the AST-specified calling\n  /// convention.\n  CallingConv getASTCallingConvention() const {\n    return CallingConv(ASTCallingConvention);\n  }\n\n  /// getCallingConvention - Return the user specified calling\n  /// convention, which has been translated into an LLVM CC.\n  unsigned getCallingConvention() const { return CallingConvention; }\n\n  /// getEffectiveCallingConvention - Return the actual calling convention to\n  /// use, which may depend on the ABI.\n  unsigned getEffectiveCallingConvention() const {\n    return EffectiveCallingConvention;\n  }\n  void setEffectiveCallingConvention(unsigned Value) {\n    EffectiveCallingConvention = Value;\n  }\n\n  bool getHasRegParm() const { return HasRegParm; }\n  unsigned getRegParm() const { return RegParm; }\n\n  FunctionType::ExtInfo getExtInfo() const {\n    return FunctionType::ExtInfo(isNoReturn(), getHasRegParm(), getRegParm(),\n                                 getASTCallingConvention(), isReturnsRetained(),\n                                 isNoCallerSavedRegs(), isNoCfCheck(),\n                                 isCmseNSCall());\n  }\n\n  CanQualType getReturnType() const { return getArgsBuffer()[0].type; }\n\n  ABIArgInfo &getReturnInfo() { return getArgsBuffer()[0].info; }\n  const ABIArgInfo &getReturnInfo() const { return getArgsBuffer()[0].info; }\n\n  ArrayRef<ExtParameterInfo> getExtParameterInfos() const {\n    if (!HasExtParameterInfos) return {};\n    return llvm::makeArrayRef(getExtParameterInfosBuffer(), NumArgs);\n  }\n  ExtParameterInfo getExtParameterInfo(unsigned argIndex) const {\n    assert(argIndex <= NumArgs);\n    if (!HasExtParameterInfos) return ExtParameterInfo();\n    return getExtParameterInfos()[argIndex];\n  }\n\n  /// Return true if this function uses inalloca arguments.\n  bool usesInAlloca() const { return ArgStruct; }\n\n  /// Get the struct type used to represent all the arguments in memory.\n  llvm::StructType *getArgStruct() const { return ArgStruct; }\n  CharUnits getArgStructAlignment() const {\n    return CharUnits::fromQuantity(ArgStructAlign);\n  }\n  void setArgStruct(llvm::StructType *Ty, CharUnits Align) {\n    ArgStruct = Ty;\n    ArgStructAlign = Align.getQuantity();\n  }\n\n  void Profile(llvm::FoldingSetNodeID &ID) {\n    ID.AddInteger(getASTCallingConvention());\n    ID.AddBoolean(InstanceMethod);\n    ID.AddBoolean(ChainCall);\n    ID.AddBoolean(NoReturn);\n    ID.AddBoolean(ReturnsRetained);\n    ID.AddBoolean(NoCallerSavedRegs);\n    ID.AddBoolean(HasRegParm);\n    ID.AddInteger(RegParm);\n    ID.AddBoolean(NoCfCheck);\n    ID.AddBoolean(CmseNSCall);\n    ID.AddInteger(Required.getOpaqueData());\n    ID.AddBoolean(HasExtParameterInfos);\n    if (HasExtParameterInfos) {\n      for (auto paramInfo : getExtParameterInfos())\n        ID.AddInteger(paramInfo.getOpaqueValue());\n    }\n    getReturnType().Profile(ID);\n    for (const auto &I : arguments())\n      I.type.Profile(ID);\n  }\n  static void Profile(llvm::FoldingSetNodeID &ID,\n                      bool InstanceMethod,\n                      bool ChainCall,\n                      const FunctionType::ExtInfo &info,\n                      ArrayRef<ExtParameterInfo> paramInfos,\n                      RequiredArgs required,\n                      CanQualType resultType,\n                      ArrayRef<CanQualType> argTypes) {\n    ID.AddInteger(info.getCC());\n    ID.AddBoolean(InstanceMethod);\n    ID.AddBoolean(ChainCall);\n    ID.AddBoolean(info.getNoReturn());\n    ID.AddBoolean(info.getProducesResult());\n    ID.AddBoolean(info.getNoCallerSavedRegs());\n    ID.AddBoolean(info.getHasRegParm());\n    ID.AddInteger(info.getRegParm());\n    ID.AddBoolean(info.getNoCfCheck());\n    ID.AddBoolean(info.getCmseNSCall());\n    ID.AddInteger(required.getOpaqueData());\n    ID.AddBoolean(!paramInfos.empty());\n    if (!paramInfos.empty()) {\n      for (auto paramInfo : paramInfos)\n        ID.AddInteger(paramInfo.getOpaqueValue());\n    }\n    resultType.Profile(ID);\n    for (ArrayRef<CanQualType>::iterator\n           i = argTypes.begin(), e = argTypes.end(); i != e; ++i) {\n      i->Profile(ID);\n    }\n  }\n};\n\n}  // end namespace CodeGen\n}  // end namespace clang\n\n#endif\n"}, "38": {"id": 38, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "content": "//===--- CGCall.cpp - Encapsulate calling convention details --------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// These classes wrap the information about a call or function\n// definition used to handle ABI compliancy.\n//\n//===----------------------------------------------------------------------===//\n\n#include \"CGCall.h\"\n#include \"ABIInfo.h\"\n#include \"CGBlocks.h\"\n#include \"CGCXXABI.h\"\n#include \"CGCleanup.h\"\n#include \"CGRecordLayout.h\"\n#include \"CodeGenFunction.h\"\n#include \"CodeGenModule.h\"\n#include \"TargetInfo.h\"\n#include \"clang/AST/Attr.h\"\n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/DeclCXX.h\"\n#include \"clang/AST/DeclObjC.h\"\n#include \"clang/Basic/CodeGenOptions.h\"\n#include \"clang/Basic/TargetBuiltins.h\"\n#include \"clang/Basic/TargetInfo.h\"\n#include \"clang/CodeGen/CGFunctionInfo.h\"\n#include \"clang/CodeGen/SwiftCallingConv.h\"\n#include \"llvm/ADT/StringExtras.h\"\n#include \"llvm/Analysis/ValueTracking.h\"\n#include \"llvm/IR/Assumptions.h\"\n#include \"llvm/IR/Attributes.h\"\n#include \"llvm/IR/CallingConv.h\"\n#include \"llvm/IR/DataLayout.h\"\n#include \"llvm/IR/InlineAsm.h\"\n#include \"llvm/IR/IntrinsicInst.h\"\n#include \"llvm/IR/Intrinsics.h\"\n#include \"llvm/Transforms/Utils/Local.h\"\nusing namespace clang;\nusing namespace CodeGen;\n\n/***/\n\nunsigned CodeGenTypes::ClangCallConvToLLVMCallConv(CallingConv CC) {\n  switch (CC) {\n  default: return llvm::CallingConv::C;\n  case CC_X86StdCall: return llvm::CallingConv::X86_StdCall;\n  case CC_X86FastCall: return llvm::CallingConv::X86_FastCall;\n  case CC_X86RegCall: return llvm::CallingConv::X86_RegCall;\n  case CC_X86ThisCall: return llvm::CallingConv::X86_ThisCall;\n  case CC_Win64: return llvm::CallingConv::Win64;\n  case CC_X86_64SysV: return llvm::CallingConv::X86_64_SysV;\n  case CC_AAPCS: return llvm::CallingConv::ARM_AAPCS;\n  case CC_AAPCS_VFP: return llvm::CallingConv::ARM_AAPCS_VFP;\n  case CC_IntelOclBicc: return llvm::CallingConv::Intel_OCL_BI;\n  // TODO: Add support for __pascal to LLVM.\n  case CC_X86Pascal: return llvm::CallingConv::C;\n  // TODO: Add support for __vectorcall to LLVM.\n  case CC_X86VectorCall: return llvm::CallingConv::X86_VectorCall;\n  case CC_AArch64VectorCall: return llvm::CallingConv::AArch64_VectorCall;\n  case CC_SpirFunction: return llvm::CallingConv::SPIR_FUNC;\n  case CC_OpenCLKernel: return CGM.getTargetCodeGenInfo().getOpenCLKernelCallingConv();\n  case CC_PreserveMost: return llvm::CallingConv::PreserveMost;\n  case CC_PreserveAll: return llvm::CallingConv::PreserveAll;\n  case CC_Swift: return llvm::CallingConv::Swift;\n  }\n}\n\n/// Derives the 'this' type for codegen purposes, i.e. ignoring method CVR\n/// qualification. Either or both of RD and MD may be null. A null RD indicates\n/// that there is no meaningful 'this' type, and a null MD can occur when\n/// calling a method pointer.\nCanQualType CodeGenTypes::DeriveThisType(const CXXRecordDecl *RD,\n                                         const CXXMethodDecl *MD) {\n  QualType RecTy;\n  if (RD)\n    RecTy = Context.getTagDeclType(RD)->getCanonicalTypeInternal();\n  else\n    RecTy = Context.VoidTy;\n\n  if (MD)\n    RecTy = Context.getAddrSpaceQualType(RecTy, MD->getMethodQualifiers().getAddressSpace());\n  return Context.getPointerType(CanQualType::CreateUnsafe(RecTy));\n}\n\n/// Returns the canonical formal type of the given C++ method.\nstatic CanQual<FunctionProtoType> GetFormalType(const CXXMethodDecl *MD) {\n  return MD->getType()->getCanonicalTypeUnqualified()\n           .getAs<FunctionProtoType>();\n}\n\n/// Returns the \"extra-canonicalized\" return type, which discards\n/// qualifiers on the return type.  Codegen doesn't care about them,\n/// and it makes ABI code a little easier to be able to assume that\n/// all parameter and return types are top-level unqualified.\nstatic CanQualType GetReturnType(QualType RetTy) {\n  return RetTy->getCanonicalTypeUnqualified().getUnqualifiedType();\n}\n\n/// Arrange the argument and result information for a value of the given\n/// unprototyped freestanding function type.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeFreeFunctionType(CanQual<FunctionNoProtoType> FTNP) {\n  // When translating an unprototyped function type, always use a\n  // variadic type.\n  return arrangeLLVMFunctionInfo(FTNP->getReturnType().getUnqualifiedType(),\n                                 /*instanceMethod=*/false,\n                                 /*chainCall=*/false, None,\n                                 FTNP->getExtInfo(), {}, RequiredArgs(0));\n}\n\nstatic void addExtParameterInfosForCall(\n         llvm::SmallVectorImpl<FunctionProtoType::ExtParameterInfo> &paramInfos,\n                                        const FunctionProtoType *proto,\n                                        unsigned prefixArgs,\n                                        unsigned totalArgs) {\n  assert(proto->hasExtParameterInfos());\n  assert(paramInfos.size() <= prefixArgs);\n  assert(proto->getNumParams() + prefixArgs <= totalArgs);\n\n  paramInfos.reserve(totalArgs);\n\n  // Add default infos for any prefix args that don't already have infos.\n  paramInfos.resize(prefixArgs);\n\n  // Add infos for the prototype.\n  for (const auto &ParamInfo : proto->getExtParameterInfos()) {\n    paramInfos.push_back(ParamInfo);\n    // pass_object_size params have no parameter info.\n    if (ParamInfo.hasPassObjectSize())\n      paramInfos.emplace_back();\n  }\n\n  assert(paramInfos.size() <= totalArgs &&\n         \"Did we forget to insert pass_object_size args?\");\n  // Add default infos for the variadic and/or suffix arguments.\n  paramInfos.resize(totalArgs);\n}\n\n/// Adds the formal parameters in FPT to the given prefix. If any parameter in\n/// FPT has pass_object_size attrs, then we'll add parameters for those, too.\nstatic void appendParameterTypes(const CodeGenTypes &CGT,\n                                 SmallVectorImpl<CanQualType> &prefix,\n              SmallVectorImpl<FunctionProtoType::ExtParameterInfo> &paramInfos,\n                                 CanQual<FunctionProtoType> FPT) {\n  // Fast path: don't touch param info if we don't need to.\n  if (!FPT->hasExtParameterInfos()) {\n    assert(paramInfos.empty() &&\n           \"We have paramInfos, but the prototype doesn't?\");\n    prefix.append(FPT->param_type_begin(), FPT->param_type_end());\n    return;\n  }\n\n  unsigned PrefixSize = prefix.size();\n  // In the vast majority of cases, we'll have precisely FPT->getNumParams()\n  // parameters; the only thing that can change this is the presence of\n  // pass_object_size. So, we preallocate for the common case.\n  prefix.reserve(prefix.size() + FPT->getNumParams());\n\n  auto ExtInfos = FPT->getExtParameterInfos();\n  assert(ExtInfos.size() == FPT->getNumParams());\n  for (unsigned I = 0, E = FPT->getNumParams(); I != E; ++I) {\n    prefix.push_back(FPT->getParamType(I));\n    if (ExtInfos[I].hasPassObjectSize())\n      prefix.push_back(CGT.getContext().getSizeType());\n  }\n\n  addExtParameterInfosForCall(paramInfos, FPT.getTypePtr(), PrefixSize,\n                              prefix.size());\n}\n\n/// Arrange the LLVM function layout for a value of the given function\n/// type, on top of any implicit parameters already stored.\nstatic const CGFunctionInfo &\narrangeLLVMFunctionInfo(CodeGenTypes &CGT, bool instanceMethod,\n                        SmallVectorImpl<CanQualType> &prefix,\n                        CanQual<FunctionProtoType> FTP) {\n  SmallVector<FunctionProtoType::ExtParameterInfo, 16> paramInfos;\n  RequiredArgs Required = RequiredArgs::forPrototypePlus(FTP, prefix.size());\n  // FIXME: Kill copy.\n  appendParameterTypes(CGT, prefix, paramInfos, FTP);\n  CanQualType resultType = FTP->getReturnType().getUnqualifiedType();\n\n  return CGT.arrangeLLVMFunctionInfo(resultType, instanceMethod,\n                                     /*chainCall=*/false, prefix,\n                                     FTP->getExtInfo(), paramInfos,\n                                     Required);\n}\n\n/// Arrange the argument and result information for a value of the\n/// given freestanding function type.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeFreeFunctionType(CanQual<FunctionProtoType> FTP) {\n  SmallVector<CanQualType, 16> argTypes;\n  return ::arrangeLLVMFunctionInfo(*this, /*instanceMethod=*/false, argTypes,\n                                   FTP);\n}\n\nstatic CallingConv getCallingConventionForDecl(const ObjCMethodDecl *D,\n                                               bool IsWindows) {\n  // Set the appropriate calling convention for the Function.\n  if (D->hasAttr<StdCallAttr>())\n    return CC_X86StdCall;\n\n  if (D->hasAttr<FastCallAttr>())\n    return CC_X86FastCall;\n\n  if (D->hasAttr<RegCallAttr>())\n    return CC_X86RegCall;\n\n  if (D->hasAttr<ThisCallAttr>())\n    return CC_X86ThisCall;\n\n  if (D->hasAttr<VectorCallAttr>())\n    return CC_X86VectorCall;\n\n  if (D->hasAttr<PascalAttr>())\n    return CC_X86Pascal;\n\n  if (PcsAttr *PCS = D->getAttr<PcsAttr>())\n    return (PCS->getPCS() == PcsAttr::AAPCS ? CC_AAPCS : CC_AAPCS_VFP);\n\n  if (D->hasAttr<AArch64VectorPcsAttr>())\n    return CC_AArch64VectorCall;\n\n  if (D->hasAttr<IntelOclBiccAttr>())\n    return CC_IntelOclBicc;\n\n  if (D->hasAttr<MSABIAttr>())\n    return IsWindows ? CC_C : CC_Win64;\n\n  if (D->hasAttr<SysVABIAttr>())\n    return IsWindows ? CC_X86_64SysV : CC_C;\n\n  if (D->hasAttr<PreserveMostAttr>())\n    return CC_PreserveMost;\n\n  if (D->hasAttr<PreserveAllAttr>())\n    return CC_PreserveAll;\n\n  return CC_C;\n}\n\n/// Arrange the argument and result information for a call to an\n/// unknown C++ non-static member function of the given abstract type.\n/// (A null RD means we don't have any meaningful \"this\" argument type,\n///  so fall back to a generic pointer type).\n/// The member function must be an ordinary function, i.e. not a\n/// constructor or destructor.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeCXXMethodType(const CXXRecordDecl *RD,\n                                   const FunctionProtoType *FTP,\n                                   const CXXMethodDecl *MD) {\n  SmallVector<CanQualType, 16> argTypes;\n\n  // Add the 'this' pointer.\n  argTypes.push_back(DeriveThisType(RD, MD));\n\n  return ::arrangeLLVMFunctionInfo(\n      *this, true, argTypes,\n      FTP->getCanonicalTypeUnqualified().getAs<FunctionProtoType>());\n}\n\n/// Set calling convention for CUDA/HIP kernel.\nstatic void setCUDAKernelCallingConvention(CanQualType &FTy, CodeGenModule &CGM,\n                                           const FunctionDecl *FD) {\n  if (FD->hasAttr<CUDAGlobalAttr>()) {\n    const FunctionType *FT = FTy->getAs<FunctionType>();\n    CGM.getTargetCodeGenInfo().setCUDAKernelCallingConvention(FT);\n    FTy = FT->getCanonicalTypeUnqualified();\n  }\n}\n\n/// Arrange the argument and result information for a declaration or\n/// definition of the given C++ non-static member function.  The\n/// member function must be an ordinary function, i.e. not a\n/// constructor or destructor.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeCXXMethodDeclaration(const CXXMethodDecl *MD) {\n  assert(!isa<CXXConstructorDecl>(MD) && \"wrong method for constructors!\");\n  assert(!isa<CXXDestructorDecl>(MD) && \"wrong method for destructors!\");\n\n  CanQualType FT = GetFormalType(MD).getAs<Type>();\n  setCUDAKernelCallingConvention(FT, CGM, MD);\n  auto prototype = FT.getAs<FunctionProtoType>();\n\n  if (MD->isInstance()) {\n    // The abstract case is perfectly fine.\n    const CXXRecordDecl *ThisType = TheCXXABI.getThisArgumentTypeForMethod(MD);\n    return arrangeCXXMethodType(ThisType, prototype.getTypePtr(), MD);\n  }\n\n  return arrangeFreeFunctionType(prototype);\n}\n\nbool CodeGenTypes::inheritingCtorHasParams(\n    const InheritedConstructor &Inherited, CXXCtorType Type) {\n  // Parameters are unnecessary if we're constructing a base class subobject\n  // and the inherited constructor lives in a virtual base.\n  return Type == Ctor_Complete ||\n         !Inherited.getShadowDecl()->constructsVirtualBase() ||\n         !Target.getCXXABI().hasConstructorVariants();\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeCXXStructorDeclaration(GlobalDecl GD) {\n  auto *MD = cast<CXXMethodDecl>(GD.getDecl());\n\n  SmallVector<CanQualType, 16> argTypes;\n  SmallVector<FunctionProtoType::ExtParameterInfo, 16> paramInfos;\n  argTypes.push_back(DeriveThisType(MD->getParent(), MD));\n\n  bool PassParams = true;\n\n  if (auto *CD = dyn_cast<CXXConstructorDecl>(MD)) {\n    // A base class inheriting constructor doesn't get forwarded arguments\n    // needed to construct a virtual base (or base class thereof).\n    if (auto Inherited = CD->getInheritedConstructor())\n      PassParams = inheritingCtorHasParams(Inherited, GD.getCtorType());\n  }\n\n  CanQual<FunctionProtoType> FTP = GetFormalType(MD);\n\n  // Add the formal parameters.\n  if (PassParams)\n    appendParameterTypes(*this, argTypes, paramInfos, FTP);\n\n  CGCXXABI::AddedStructorArgCounts AddedArgs =\n      TheCXXABI.buildStructorSignature(GD, argTypes);\n  if (!paramInfos.empty()) {\n    // Note: prefix implies after the first param.\n    if (AddedArgs.Prefix)\n      paramInfos.insert(paramInfos.begin() + 1, AddedArgs.Prefix,\n                        FunctionProtoType::ExtParameterInfo{});\n    if (AddedArgs.Suffix)\n      paramInfos.append(AddedArgs.Suffix,\n                        FunctionProtoType::ExtParameterInfo{});\n  }\n\n  RequiredArgs required =\n      (PassParams && MD->isVariadic() ? RequiredArgs(argTypes.size())\n                                      : RequiredArgs::All);\n\n  FunctionType::ExtInfo extInfo = FTP->getExtInfo();\n  CanQualType resultType = TheCXXABI.HasThisReturn(GD)\n                               ? argTypes.front()\n                               : TheCXXABI.hasMostDerivedReturn(GD)\n                                     ? CGM.getContext().VoidPtrTy\n                                     : Context.VoidTy;\n  return arrangeLLVMFunctionInfo(resultType, /*instanceMethod=*/true,\n                                 /*chainCall=*/false, argTypes, extInfo,\n                                 paramInfos, required);\n}\n\nstatic SmallVector<CanQualType, 16>\ngetArgTypesForCall(ASTContext &ctx, const CallArgList &args) {\n  SmallVector<CanQualType, 16> argTypes;\n  for (auto &arg : args)\n    argTypes.push_back(ctx.getCanonicalParamType(arg.Ty));\n  return argTypes;\n}\n\nstatic SmallVector<CanQualType, 16>\ngetArgTypesForDeclaration(ASTContext &ctx, const FunctionArgList &args) {\n  SmallVector<CanQualType, 16> argTypes;\n  for (auto &arg : args)\n    argTypes.push_back(ctx.getCanonicalParamType(arg->getType()));\n  return argTypes;\n}\n\nstatic llvm::SmallVector<FunctionProtoType::ExtParameterInfo, 16>\ngetExtParameterInfosForCall(const FunctionProtoType *proto,\n                            unsigned prefixArgs, unsigned totalArgs) {\n  llvm::SmallVector<FunctionProtoType::ExtParameterInfo, 16> result;\n  if (proto->hasExtParameterInfos()) {\n    addExtParameterInfosForCall(result, proto, prefixArgs, totalArgs);\n  }\n  return result;\n}\n\n/// Arrange a call to a C++ method, passing the given arguments.\n///\n/// ExtraPrefixArgs is the number of ABI-specific args passed after the `this`\n/// parameter.\n/// ExtraSuffixArgs is the number of ABI-specific args passed at the end of\n/// args.\n/// PassProtoArgs indicates whether `args` has args for the parameters in the\n/// given CXXConstructorDecl.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeCXXConstructorCall(const CallArgList &args,\n                                        const CXXConstructorDecl *D,\n                                        CXXCtorType CtorKind,\n                                        unsigned ExtraPrefixArgs,\n                                        unsigned ExtraSuffixArgs,\n                                        bool PassProtoArgs) {\n  // FIXME: Kill copy.\n  SmallVector<CanQualType, 16> ArgTypes;\n  for (const auto &Arg : args)\n    ArgTypes.push_back(Context.getCanonicalParamType(Arg.Ty));\n\n  // +1 for implicit this, which should always be args[0].\n  unsigned TotalPrefixArgs = 1 + ExtraPrefixArgs;\n\n  CanQual<FunctionProtoType> FPT = GetFormalType(D);\n  RequiredArgs Required = PassProtoArgs\n                              ? RequiredArgs::forPrototypePlus(\n                                    FPT, TotalPrefixArgs + ExtraSuffixArgs)\n                              : RequiredArgs::All;\n\n  GlobalDecl GD(D, CtorKind);\n  CanQualType ResultType = TheCXXABI.HasThisReturn(GD)\n                               ? ArgTypes.front()\n                               : TheCXXABI.hasMostDerivedReturn(GD)\n                                     ? CGM.getContext().VoidPtrTy\n                                     : Context.VoidTy;\n\n  FunctionType::ExtInfo Info = FPT->getExtInfo();\n  llvm::SmallVector<FunctionProtoType::ExtParameterInfo, 16> ParamInfos;\n  // If the prototype args are elided, we should only have ABI-specific args,\n  // which never have param info.\n  if (PassProtoArgs && FPT->hasExtParameterInfos()) {\n    // ABI-specific suffix arguments are treated the same as variadic arguments.\n    addExtParameterInfosForCall(ParamInfos, FPT.getTypePtr(), TotalPrefixArgs,\n                                ArgTypes.size());\n  }\n  return arrangeLLVMFunctionInfo(ResultType, /*instanceMethod=*/true,\n                                 /*chainCall=*/false, ArgTypes, Info,\n                                 ParamInfos, Required);\n}\n\n/// Arrange the argument and result information for the declaration or\n/// definition of the given function.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeFunctionDeclaration(const FunctionDecl *FD) {\n  if (const CXXMethodDecl *MD = dyn_cast<CXXMethodDecl>(FD))\n    if (MD->isInstance())\n      return arrangeCXXMethodDeclaration(MD);\n\n  CanQualType FTy = FD->getType()->getCanonicalTypeUnqualified();\n\n  assert(isa<FunctionType>(FTy));\n  setCUDAKernelCallingConvention(FTy, CGM, FD);\n\n  // When declaring a function without a prototype, always use a\n  // non-variadic type.\n  if (CanQual<FunctionNoProtoType> noProto = FTy.getAs<FunctionNoProtoType>()) {\n    return arrangeLLVMFunctionInfo(\n        noProto->getReturnType(), /*instanceMethod=*/false,\n        /*chainCall=*/false, None, noProto->getExtInfo(), {},RequiredArgs::All);\n  }\n\n  return arrangeFreeFunctionType(FTy.castAs<FunctionProtoType>());\n}\n\n/// Arrange the argument and result information for the declaration or\n/// definition of an Objective-C method.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeObjCMethodDeclaration(const ObjCMethodDecl *MD) {\n  // It happens that this is the same as a call with no optional\n  // arguments, except also using the formal 'self' type.\n  return arrangeObjCMessageSendSignature(MD, MD->getSelfDecl()->getType());\n}\n\n/// Arrange the argument and result information for the function type\n/// through which to perform a send to the given Objective-C method,\n/// using the given receiver type.  The receiver type is not always\n/// the 'self' type of the method or even an Objective-C pointer type.\n/// This is *not* the right method for actually performing such a\n/// message send, due to the possibility of optional arguments.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeObjCMessageSendSignature(const ObjCMethodDecl *MD,\n                                              QualType receiverType) {\n  SmallVector<CanQualType, 16> argTys;\n  SmallVector<FunctionProtoType::ExtParameterInfo, 4> extParamInfos(2);\n  argTys.push_back(Context.getCanonicalParamType(receiverType));\n  argTys.push_back(Context.getCanonicalParamType(Context.getObjCSelType()));\n  // FIXME: Kill copy?\n  for (const auto *I : MD->parameters()) {\n    argTys.push_back(Context.getCanonicalParamType(I->getType()));\n    auto extParamInfo = FunctionProtoType::ExtParameterInfo().withIsNoEscape(\n        I->hasAttr<NoEscapeAttr>());\n    extParamInfos.push_back(extParamInfo);\n  }\n\n  FunctionType::ExtInfo einfo;\n  bool IsWindows = getContext().getTargetInfo().getTriple().isOSWindows();\n  einfo = einfo.withCallingConv(getCallingConventionForDecl(MD, IsWindows));\n\n  if (getContext().getLangOpts().ObjCAutoRefCount &&\n      MD->hasAttr<NSReturnsRetainedAttr>())\n    einfo = einfo.withProducesResult(true);\n\n  RequiredArgs required =\n    (MD->isVariadic() ? RequiredArgs(argTys.size()) : RequiredArgs::All);\n\n  return arrangeLLVMFunctionInfo(\n      GetReturnType(MD->getReturnType()), /*instanceMethod=*/false,\n      /*chainCall=*/false, argTys, einfo, extParamInfos, required);\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeUnprototypedObjCMessageSend(QualType returnType,\n                                                 const CallArgList &args) {\n  auto argTypes = getArgTypesForCall(Context, args);\n  FunctionType::ExtInfo einfo;\n\n  return arrangeLLVMFunctionInfo(\n      GetReturnType(returnType), /*instanceMethod=*/false,\n      /*chainCall=*/false, argTypes, einfo, {}, RequiredArgs::All);\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeGlobalDeclaration(GlobalDecl GD) {\n  // FIXME: Do we need to handle ObjCMethodDecl?\n  const FunctionDecl *FD = cast<FunctionDecl>(GD.getDecl());\n\n  if (isa<CXXConstructorDecl>(GD.getDecl()) ||\n      isa<CXXDestructorDecl>(GD.getDecl()))\n    return arrangeCXXStructorDeclaration(GD);\n\n  return arrangeFunctionDeclaration(FD);\n}\n\n/// Arrange a thunk that takes 'this' as the first parameter followed by\n/// varargs.  Return a void pointer, regardless of the actual return type.\n/// The body of the thunk will end in a musttail call to a function of the\n/// correct type, and the caller will bitcast the function to the correct\n/// prototype.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeUnprototypedMustTailThunk(const CXXMethodDecl *MD) {\n  assert(MD->isVirtual() && \"only methods have thunks\");\n  CanQual<FunctionProtoType> FTP = GetFormalType(MD);\n  CanQualType ArgTys[] = {DeriveThisType(MD->getParent(), MD)};\n  return arrangeLLVMFunctionInfo(Context.VoidTy, /*instanceMethod=*/false,\n                                 /*chainCall=*/false, ArgTys,\n                                 FTP->getExtInfo(), {}, RequiredArgs(1));\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeMSCtorClosure(const CXXConstructorDecl *CD,\n                                   CXXCtorType CT) {\n  assert(CT == Ctor_CopyingClosure || CT == Ctor_DefaultClosure);\n\n  CanQual<FunctionProtoType> FTP = GetFormalType(CD);\n  SmallVector<CanQualType, 2> ArgTys;\n  const CXXRecordDecl *RD = CD->getParent();\n  ArgTys.push_back(DeriveThisType(RD, CD));\n  if (CT == Ctor_CopyingClosure)\n    ArgTys.push_back(*FTP->param_type_begin());\n  if (RD->getNumVBases() > 0)\n    ArgTys.push_back(Context.IntTy);\n  CallingConv CC = Context.getDefaultCallingConvention(\n      /*IsVariadic=*/false, /*IsCXXMethod=*/true);\n  return arrangeLLVMFunctionInfo(Context.VoidTy, /*instanceMethod=*/true,\n                                 /*chainCall=*/false, ArgTys,\n                                 FunctionType::ExtInfo(CC), {},\n                                 RequiredArgs::All);\n}\n\n/// Arrange a call as unto a free function, except possibly with an\n/// additional number of formal parameters considered required.\nstatic const CGFunctionInfo &\narrangeFreeFunctionLikeCall(CodeGenTypes &CGT,\n                            CodeGenModule &CGM,\n                            const CallArgList &args,\n                            const FunctionType *fnType,\n                            unsigned numExtraRequiredArgs,\n                            bool chainCall) {\n  assert(args.size() >= numExtraRequiredArgs);\n\n  llvm::SmallVector<FunctionProtoType::ExtParameterInfo, 16> paramInfos;\n\n  // In most cases, there are no optional arguments.\n  RequiredArgs required = RequiredArgs::All;\n\n  // If we have a variadic prototype, the required arguments are the\n  // extra prefix plus the arguments in the prototype.\n  if (const FunctionProtoType *proto = dyn_cast<FunctionProtoType>(fnType)) {\n    if (proto->isVariadic())\n      required = RequiredArgs::forPrototypePlus(proto, numExtraRequiredArgs);\n\n    if (proto->hasExtParameterInfos())\n      addExtParameterInfosForCall(paramInfos, proto, numExtraRequiredArgs,\n                                  args.size());\n\n  // If we don't have a prototype at all, but we're supposed to\n  // explicitly use the variadic convention for unprototyped calls,\n  // treat all of the arguments as required but preserve the nominal\n  // possibility of variadics.\n  } else if (CGM.getTargetCodeGenInfo()\n                .isNoProtoCallVariadic(args,\n                                       cast<FunctionNoProtoType>(fnType))) {\n    required = RequiredArgs(args.size());\n  }\n\n  // FIXME: Kill copy.\n  SmallVector<CanQualType, 16> argTypes;\n  for (const auto &arg : args)\n    argTypes.push_back(CGT.getContext().getCanonicalParamType(arg.Ty));\n  return CGT.arrangeLLVMFunctionInfo(GetReturnType(fnType->getReturnType()),\n                                     /*instanceMethod=*/false, chainCall,\n                                     argTypes, fnType->getExtInfo(), paramInfos,\n                                     required);\n}\n\n/// Figure out the rules for calling a function with the given formal\n/// type using the given arguments.  The arguments are necessary\n/// because the function might be unprototyped, in which case it's\n/// target-dependent in crazy ways.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeFreeFunctionCall(const CallArgList &args,\n                                      const FunctionType *fnType,\n                                      bool chainCall) {\n  return arrangeFreeFunctionLikeCall(*this, CGM, args, fnType,\n                                     chainCall ? 1 : 0, chainCall);\n}\n\n/// A block function is essentially a free function with an\n/// extra implicit argument.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeBlockFunctionCall(const CallArgList &args,\n                                       const FunctionType *fnType) {\n  return arrangeFreeFunctionLikeCall(*this, CGM, args, fnType, 1,\n                                     /*chainCall=*/false);\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeBlockFunctionDeclaration(const FunctionProtoType *proto,\n                                              const FunctionArgList &params) {\n  auto paramInfos = getExtParameterInfosForCall(proto, 1, params.size());\n  auto argTypes = getArgTypesForDeclaration(Context, params);\n\n  return arrangeLLVMFunctionInfo(GetReturnType(proto->getReturnType()),\n                                 /*instanceMethod*/ false, /*chainCall*/ false,\n                                 argTypes, proto->getExtInfo(), paramInfos,\n                                 RequiredArgs::forPrototypePlus(proto, 1));\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeBuiltinFunctionCall(QualType resultType,\n                                         const CallArgList &args) {\n  // FIXME: Kill copy.\n  SmallVector<CanQualType, 16> argTypes;\n  for (const auto &Arg : args)\n    argTypes.push_back(Context.getCanonicalParamType(Arg.Ty));\n  return arrangeLLVMFunctionInfo(\n      GetReturnType(resultType), /*instanceMethod=*/false,\n      /*chainCall=*/false, argTypes, FunctionType::ExtInfo(),\n      /*paramInfos=*/ {}, RequiredArgs::All);\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeBuiltinFunctionDeclaration(QualType resultType,\n                                                const FunctionArgList &args) {\n  auto argTypes = getArgTypesForDeclaration(Context, args);\n\n  return arrangeLLVMFunctionInfo(\n      GetReturnType(resultType), /*instanceMethod=*/false, /*chainCall=*/false,\n      argTypes, FunctionType::ExtInfo(), {}, RequiredArgs::All);\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeBuiltinFunctionDeclaration(CanQualType resultType,\n                                              ArrayRef<CanQualType> argTypes) {\n  return arrangeLLVMFunctionInfo(\n      resultType, /*instanceMethod=*/false, /*chainCall=*/false,\n      argTypes, FunctionType::ExtInfo(), {}, RequiredArgs::All);\n}\n\n/// Arrange a call to a C++ method, passing the given arguments.\n///\n/// numPrefixArgs is the number of ABI-specific prefix arguments we have. It\n/// does not count `this`.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeCXXMethodCall(const CallArgList &args,\n                                   const FunctionProtoType *proto,\n                                   RequiredArgs required,\n                                   unsigned numPrefixArgs) {\n  assert(numPrefixArgs + 1 <= args.size() &&\n         \"Emitting a call with less args than the required prefix?\");\n  // Add one to account for `this`. It's a bit awkward here, but we don't count\n  // `this` in similar places elsewhere.\n  auto paramInfos =\n    getExtParameterInfosForCall(proto, numPrefixArgs + 1, args.size());\n\n  // FIXME: Kill copy.\n  auto argTypes = getArgTypesForCall(Context, args);\n\n  FunctionType::ExtInfo info = proto->getExtInfo();\n  return arrangeLLVMFunctionInfo(\n      GetReturnType(proto->getReturnType()), /*instanceMethod=*/true,\n      /*chainCall=*/false, argTypes, info, paramInfos, required);\n}\n\nconst CGFunctionInfo &CodeGenTypes::arrangeNullaryFunction() {\n  return arrangeLLVMFunctionInfo(\n      getContext().VoidTy, /*instanceMethod=*/false, /*chainCall=*/false,\n      None, FunctionType::ExtInfo(), {}, RequiredArgs::All);\n}\n\nconst CGFunctionInfo &\nCodeGenTypes::arrangeCall(const CGFunctionInfo &signature,\n                          const CallArgList &args) {\n  assert(signature.arg_size() <= args.size());\n  if (signature.arg_size() == args.size())\n    return signature;\n\n  SmallVector<FunctionProtoType::ExtParameterInfo, 16> paramInfos;\n  auto sigParamInfos = signature.getExtParameterInfos();\n  if (!sigParamInfos.empty()) {\n    paramInfos.append(sigParamInfos.begin(), sigParamInfos.end());\n    paramInfos.resize(args.size());\n  }\n\n  auto argTypes = getArgTypesForCall(Context, args);\n\n  assert(signature.getRequiredArgs().allowsOptionalArgs());\n  return arrangeLLVMFunctionInfo(signature.getReturnType(),\n                                 signature.isInstanceMethod(),\n                                 signature.isChainCall(),\n                                 argTypes,\n                                 signature.getExtInfo(),\n                                 paramInfos,\n                                 signature.getRequiredArgs());\n}\n\nnamespace clang {\nnamespace CodeGen {\nvoid computeSPIRKernelABIInfo(CodeGenModule &CGM, CGFunctionInfo &FI);\n}\n}\n\n/// Arrange the argument and result information for an abstract value\n/// of a given function type.  This is the method which all of the\n/// above functions ultimately defer to.\nconst CGFunctionInfo &\nCodeGenTypes::arrangeLLVMFunctionInfo(CanQualType resultType,\n                                      bool instanceMethod,\n                                      bool chainCall,\n                                      ArrayRef<CanQualType> argTypes,\n                                      FunctionType::ExtInfo info,\n                     ArrayRef<FunctionProtoType::ExtParameterInfo> paramInfos,\n                                      RequiredArgs required) {\n  assert(llvm::all_of(argTypes,\n                      [](CanQualType T) { return T.isCanonicalAsParam(); }));\n\n  // Lookup or create unique function info.\n  llvm::FoldingSetNodeID ID;\n  CGFunctionInfo::Profile(ID, instanceMethod, chainCall, info, paramInfos,\n                          required, resultType, argTypes);\n\n  void *insertPos = nullptr;\n  CGFunctionInfo *FI = FunctionInfos.FindNodeOrInsertPos(ID, insertPos);\n  if (FI)\n    return *FI;\n\n  unsigned CC = ClangCallConvToLLVMCallConv(info.getCC());\n\n  // Construct the function info.  We co-allocate the ArgInfos.\n  FI = CGFunctionInfo::create(CC, instanceMethod, chainCall, info,\n                              paramInfos, resultType, argTypes, required);\n  FunctionInfos.InsertNode(FI, insertPos);\n\n  bool inserted = FunctionsBeingProcessed.insert(FI).second;\n  (void)inserted;\n  assert(inserted && \"Recursively being processed?\");\n\n  // Compute ABI information.\n  if (CC == llvm::CallingConv::SPIR_KERNEL) {\n    // Force target independent argument handling for the host visible\n    // kernel functions.\n    computeSPIRKernelABIInfo(CGM, *FI);\n  } else if (info.getCC() == CC_Swift) {\n    swiftcall::computeABIInfo(CGM, *FI);\n  } else {\n    getABIInfo().computeInfo(*FI);\n  }\n\n  // Loop over all of the computed argument and return value info.  If any of\n  // them are direct or extend without a specified coerce type, specify the\n  // default now.\n  ABIArgInfo &retInfo = FI->getReturnInfo();\n  if (retInfo.canHaveCoerceToType() && retInfo.getCoerceToType() == nullptr)\n    retInfo.setCoerceToType(ConvertType(FI->getReturnType()));\n\n  for (auto &I : FI->arguments())\n    if (I.info.canHaveCoerceToType() && I.info.getCoerceToType() == nullptr)\n      I.info.setCoerceToType(ConvertType(I.type));\n\n  bool erased = FunctionsBeingProcessed.erase(FI); (void)erased;\n  assert(erased && \"Not in set?\");\n\n  return *FI;\n}\n\nCGFunctionInfo *CGFunctionInfo::create(unsigned llvmCC,\n                                       bool instanceMethod,\n                                       bool chainCall,\n                                       const FunctionType::ExtInfo &info,\n                                       ArrayRef<ExtParameterInfo> paramInfos,\n                                       CanQualType resultType,\n                                       ArrayRef<CanQualType> argTypes,\n                                       RequiredArgs required) {\n  assert(paramInfos.empty() || paramInfos.size() == argTypes.size());\n  assert(!required.allowsOptionalArgs() ||\n         required.getNumRequiredArgs() <= argTypes.size());\n\n  void *buffer =\n    operator new(totalSizeToAlloc<ArgInfo,             ExtParameterInfo>(\n                                  argTypes.size() + 1, paramInfos.size()));\n\n  CGFunctionInfo *FI = new(buffer) CGFunctionInfo();\n  FI->CallingConvention = llvmCC;\n  FI->EffectiveCallingConvention = llvmCC;\n  FI->ASTCallingConvention = info.getCC();\n  FI->InstanceMethod = instanceMethod;\n  FI->ChainCall = chainCall;\n  FI->CmseNSCall = info.getCmseNSCall();\n  FI->NoReturn = info.getNoReturn();\n  FI->ReturnsRetained = info.getProducesResult();\n  FI->NoCallerSavedRegs = info.getNoCallerSavedRegs();\n  FI->NoCfCheck = info.getNoCfCheck();\n  FI->Required = required;\n  FI->HasRegParm = info.getHasRegParm();\n  FI->RegParm = info.getRegParm();\n  FI->ArgStruct = nullptr;\n  FI->ArgStructAlign = 0;\n  FI->NumArgs = argTypes.size();\n  FI->HasExtParameterInfos = !paramInfos.empty();\n  FI->getArgsBuffer()[0].type = resultType;\n  for (unsigned i = 0, e = argTypes.size(); i != e; ++i)\n    FI->getArgsBuffer()[i + 1].type = argTypes[i];\n  for (unsigned i = 0, e = paramInfos.size(); i != e; ++i)\n    FI->getExtParameterInfosBuffer()[i] = paramInfos[i];\n  return FI;\n}\n\n/***/\n\nnamespace {\n// ABIArgInfo::Expand implementation.\n\n// Specifies the way QualType passed as ABIArgInfo::Expand is expanded.\nstruct TypeExpansion {\n  enum TypeExpansionKind {\n    // Elements of constant arrays are expanded recursively.\n    TEK_ConstantArray,\n    // Record fields are expanded recursively (but if record is a union, only\n    // the field with the largest size is expanded).\n    TEK_Record,\n    // For complex types, real and imaginary parts are expanded recursively.\n    TEK_Complex,\n    // All other types are not expandable.\n    TEK_None\n  };\n\n  const TypeExpansionKind Kind;\n\n  TypeExpansion(TypeExpansionKind K) : Kind(K) {}\n  virtual ~TypeExpansion() {}\n};\n\nstruct ConstantArrayExpansion : TypeExpansion {\n  QualType EltTy;\n  uint64_t NumElts;\n\n  ConstantArrayExpansion(QualType EltTy, uint64_t NumElts)\n      : TypeExpansion(TEK_ConstantArray), EltTy(EltTy), NumElts(NumElts) {}\n  static bool classof(const TypeExpansion *TE) {\n    return TE->Kind == TEK_ConstantArray;\n  }\n};\n\nstruct RecordExpansion : TypeExpansion {\n  SmallVector<const CXXBaseSpecifier *, 1> Bases;\n\n  SmallVector<const FieldDecl *, 1> Fields;\n\n  RecordExpansion(SmallVector<const CXXBaseSpecifier *, 1> &&Bases,\n                  SmallVector<const FieldDecl *, 1> &&Fields)\n      : TypeExpansion(TEK_Record), Bases(std::move(Bases)),\n        Fields(std::move(Fields)) {}\n  static bool classof(const TypeExpansion *TE) {\n    return TE->Kind == TEK_Record;\n  }\n};\n\nstruct ComplexExpansion : TypeExpansion {\n  QualType EltTy;\n\n  ComplexExpansion(QualType EltTy) : TypeExpansion(TEK_Complex), EltTy(EltTy) {}\n  static bool classof(const TypeExpansion *TE) {\n    return TE->Kind == TEK_Complex;\n  }\n};\n\nstruct NoExpansion : TypeExpansion {\n  NoExpansion() : TypeExpansion(TEK_None) {}\n  static bool classof(const TypeExpansion *TE) {\n    return TE->Kind == TEK_None;\n  }\n};\n}  // namespace\n\nstatic std::unique_ptr<TypeExpansion>\ngetTypeExpansion(QualType Ty, const ASTContext &Context) {\n  if (const ConstantArrayType *AT = Context.getAsConstantArrayType(Ty)) {\n    return std::make_unique<ConstantArrayExpansion>(\n        AT->getElementType(), AT->getSize().getZExtValue());\n  }\n  if (const RecordType *RT = Ty->getAs<RecordType>()) {\n    SmallVector<const CXXBaseSpecifier *, 1> Bases;\n    SmallVector<const FieldDecl *, 1> Fields;\n    const RecordDecl *RD = RT->getDecl();\n    assert(!RD->hasFlexibleArrayMember() &&\n           \"Cannot expand structure with flexible array.\");\n    if (RD->isUnion()) {\n      // Unions can be here only in degenerative cases - all the fields are same\n      // after flattening. Thus we have to use the \"largest\" field.\n      const FieldDecl *LargestFD = nullptr;\n      CharUnits UnionSize = CharUnits::Zero();\n\n      for (const auto *FD : RD->fields()) {\n        if (FD->isZeroLengthBitField(Context))\n          continue;\n        assert(!FD->isBitField() &&\n               \"Cannot expand structure with bit-field members.\");\n        CharUnits FieldSize = Context.getTypeSizeInChars(FD->getType());\n        if (UnionSize < FieldSize) {\n          UnionSize = FieldSize;\n          LargestFD = FD;\n        }\n      }\n      if (LargestFD)\n        Fields.push_back(LargestFD);\n    } else {\n      if (const auto *CXXRD = dyn_cast<CXXRecordDecl>(RD)) {\n        assert(!CXXRD->isDynamicClass() &&\n               \"cannot expand vtable pointers in dynamic classes\");\n        for (const CXXBaseSpecifier &BS : CXXRD->bases())\n          Bases.push_back(&BS);\n      }\n\n      for (const auto *FD : RD->fields()) {\n        if (FD->isZeroLengthBitField(Context))\n          continue;\n        assert(!FD->isBitField() &&\n               \"Cannot expand structure with bit-field members.\");\n        Fields.push_back(FD);\n      }\n    }\n    return std::make_unique<RecordExpansion>(std::move(Bases),\n                                              std::move(Fields));\n  }\n  if (const ComplexType *CT = Ty->getAs<ComplexType>()) {\n    return std::make_unique<ComplexExpansion>(CT->getElementType());\n  }\n  return std::make_unique<NoExpansion>();\n}\n\nstatic int getExpansionSize(QualType Ty, const ASTContext &Context) {\n  auto Exp = getTypeExpansion(Ty, Context);\n  if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {\n    return CAExp->NumElts * getExpansionSize(CAExp->EltTy, Context);\n  }\n  if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {\n    int Res = 0;\n    for (auto BS : RExp->Bases)\n      Res += getExpansionSize(BS->getType(), Context);\n    for (auto FD : RExp->Fields)\n      Res += getExpansionSize(FD->getType(), Context);\n    return Res;\n  }\n  if (isa<ComplexExpansion>(Exp.get()))\n    return 2;\n  assert(isa<NoExpansion>(Exp.get()));\n  return 1;\n}\n\nvoid\nCodeGenTypes::getExpandedTypes(QualType Ty,\n                               SmallVectorImpl<llvm::Type *>::iterator &TI) {\n  auto Exp = getTypeExpansion(Ty, Context);\n  if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {\n    for (int i = 0, n = CAExp->NumElts; i < n; i++) {\n      getExpandedTypes(CAExp->EltTy, TI);\n    }\n  } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {\n    for (auto BS : RExp->Bases)\n      getExpandedTypes(BS->getType(), TI);\n    for (auto FD : RExp->Fields)\n      getExpandedTypes(FD->getType(), TI);\n  } else if (auto CExp = dyn_cast<ComplexExpansion>(Exp.get())) {\n    llvm::Type *EltTy = ConvertType(CExp->EltTy);\n    *TI++ = EltTy;\n    *TI++ = EltTy;\n  } else {\n    assert(isa<NoExpansion>(Exp.get()));\n    *TI++ = ConvertType(Ty);\n  }\n}\n\nstatic void forConstantArrayExpansion(CodeGenFunction &CGF,\n                                      ConstantArrayExpansion *CAE,\n                                      Address BaseAddr,\n                                      llvm::function_ref<void(Address)> Fn) {\n  CharUnits EltSize = CGF.getContext().getTypeSizeInChars(CAE->EltTy);\n  CharUnits EltAlign =\n    BaseAddr.getAlignment().alignmentOfArrayElement(EltSize);\n\n  for (int i = 0, n = CAE->NumElts; i < n; i++) {\n    llvm::Value *EltAddr =\n      CGF.Builder.CreateConstGEP2_32(nullptr, BaseAddr.getPointer(), 0, i);\n    Fn(Address(EltAddr, EltAlign));\n  }\n}\n\nvoid CodeGenFunction::ExpandTypeFromArgs(QualType Ty, LValue LV,\n                                         llvm::Function::arg_iterator &AI) {\n  assert(LV.isSimple() &&\n         \"Unexpected non-simple lvalue during struct expansion.\");\n\n  auto Exp = getTypeExpansion(Ty, getContext());\n  if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {\n    forConstantArrayExpansion(\n        *this, CAExp, LV.getAddress(*this), [&](Address EltAddr) {\n          LValue LV = MakeAddrLValue(EltAddr, CAExp->EltTy);\n          ExpandTypeFromArgs(CAExp->EltTy, LV, AI);\n        });\n  } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {\n    Address This = LV.getAddress(*this);\n    for (const CXXBaseSpecifier *BS : RExp->Bases) {\n      // Perform a single step derived-to-base conversion.\n      Address Base =\n          GetAddressOfBaseClass(This, Ty->getAsCXXRecordDecl(), &BS, &BS + 1,\n                                /*NullCheckValue=*/false, SourceLocation());\n      LValue SubLV = MakeAddrLValue(Base, BS->getType());\n\n      // Recurse onto bases.\n      ExpandTypeFromArgs(BS->getType(), SubLV, AI);\n    }\n    for (auto FD : RExp->Fields) {\n      // FIXME: What are the right qualifiers here?\n      LValue SubLV = EmitLValueForFieldInitialization(LV, FD);\n      ExpandTypeFromArgs(FD->getType(), SubLV, AI);\n    }\n  } else if (isa<ComplexExpansion>(Exp.get())) {\n    auto realValue = &*AI++;\n    auto imagValue = &*AI++;\n    EmitStoreOfComplex(ComplexPairTy(realValue, imagValue), LV, /*init*/ true);\n  } else {\n    // Call EmitStoreOfScalar except when the lvalue is a bitfield to emit a\n    // primitive store.\n    assert(isa<NoExpansion>(Exp.get()));\n    if (LV.isBitField())\n      EmitStoreThroughLValue(RValue::get(&*AI++), LV);\n    else\n      EmitStoreOfScalar(&*AI++, LV);\n  }\n}\n\nvoid CodeGenFunction::ExpandTypeToArgs(\n    QualType Ty, CallArg Arg, llvm::FunctionType *IRFuncTy,\n    SmallVectorImpl<llvm::Value *> &IRCallArgs, unsigned &IRCallArgPos) {\n  auto Exp = getTypeExpansion(Ty, getContext());\n  if (auto CAExp = dyn_cast<ConstantArrayExpansion>(Exp.get())) {\n    Address Addr = Arg.hasLValue() ? Arg.getKnownLValue().getAddress(*this)\n                                   : Arg.getKnownRValue().getAggregateAddress();\n    forConstantArrayExpansion(\n        *this, CAExp, Addr, [&](Address EltAddr) {\n          CallArg EltArg = CallArg(\n              convertTempToRValue(EltAddr, CAExp->EltTy, SourceLocation()),\n              CAExp->EltTy);\n          ExpandTypeToArgs(CAExp->EltTy, EltArg, IRFuncTy, IRCallArgs,\n                           IRCallArgPos);\n        });\n  } else if (auto RExp = dyn_cast<RecordExpansion>(Exp.get())) {\n    Address This = Arg.hasLValue() ? Arg.getKnownLValue().getAddress(*this)\n                                   : Arg.getKnownRValue().getAggregateAddress();\n    for (const CXXBaseSpecifier *BS : RExp->Bases) {\n      // Perform a single step derived-to-base conversion.\n      Address Base =\n          GetAddressOfBaseClass(This, Ty->getAsCXXRecordDecl(), &BS, &BS + 1,\n                                /*NullCheckValue=*/false, SourceLocation());\n      CallArg BaseArg = CallArg(RValue::getAggregate(Base), BS->getType());\n\n      // Recurse onto bases.\n      ExpandTypeToArgs(BS->getType(), BaseArg, IRFuncTy, IRCallArgs,\n                       IRCallArgPos);\n    }\n\n    LValue LV = MakeAddrLValue(This, Ty);\n    for (auto FD : RExp->Fields) {\n      CallArg FldArg =\n          CallArg(EmitRValueForField(LV, FD, SourceLocation()), FD->getType());\n      ExpandTypeToArgs(FD->getType(), FldArg, IRFuncTy, IRCallArgs,\n                       IRCallArgPos);\n    }\n  } else if (isa<ComplexExpansion>(Exp.get())) {\n    ComplexPairTy CV = Arg.getKnownRValue().getComplexVal();\n    IRCallArgs[IRCallArgPos++] = CV.first;\n    IRCallArgs[IRCallArgPos++] = CV.second;\n  } else {\n    assert(isa<NoExpansion>(Exp.get()));\n    auto RV = Arg.getKnownRValue();\n    assert(RV.isScalar() &&\n           \"Unexpected non-scalar rvalue during struct expansion.\");\n\n    // Insert a bitcast as needed.\n    llvm::Value *V = RV.getScalarVal();\n    if (IRCallArgPos < IRFuncTy->getNumParams() &&\n        V->getType() != IRFuncTy->getParamType(IRCallArgPos))\n      V = Builder.CreateBitCast(V, IRFuncTy->getParamType(IRCallArgPos));\n\n    IRCallArgs[IRCallArgPos++] = V;\n  }\n}\n\n/// Create a temporary allocation for the purposes of coercion.\nstatic Address CreateTempAllocaForCoercion(CodeGenFunction &CGF, llvm::Type *Ty,\n                                           CharUnits MinAlign,\n                                           const Twine &Name = \"tmp\") {\n  // Don't use an alignment that's worse than what LLVM would prefer.\n  auto PrefAlign = CGF.CGM.getDataLayout().getPrefTypeAlignment(Ty);\n  CharUnits Align = std::max(MinAlign, CharUnits::fromQuantity(PrefAlign));\n\n  return CGF.CreateTempAlloca(Ty, Align, Name + \".coerce\");\n}\n\n/// EnterStructPointerForCoercedAccess - Given a struct pointer that we are\n/// accessing some number of bytes out of it, try to gep into the struct to get\n/// at its inner goodness.  Dive as deep as possible without entering an element\n/// with an in-memory size smaller than DstSize.\nstatic Address\nEnterStructPointerForCoercedAccess(Address SrcPtr,\n                                   llvm::StructType *SrcSTy,\n                                   uint64_t DstSize, CodeGenFunction &CGF) {\n  // We can't dive into a zero-element struct.\n  if (SrcSTy->getNumElements() == 0) return SrcPtr;\n\n  llvm::Type *FirstElt = SrcSTy->getElementType(0);\n\n  // If the first elt is at least as large as what we're looking for, or if the\n  // first element is the same size as the whole struct, we can enter it. The\n  // comparison must be made on the store size and not the alloca size. Using\n  // the alloca size may overstate the size of the load.\n  uint64_t FirstEltSize =\n    CGF.CGM.getDataLayout().getTypeStoreSize(FirstElt);\n  if (FirstEltSize < DstSize &&\n      FirstEltSize < CGF.CGM.getDataLayout().getTypeStoreSize(SrcSTy))\n    return SrcPtr;\n\n  // GEP into the first element.\n  SrcPtr = CGF.Builder.CreateStructGEP(SrcPtr, 0, \"coerce.dive\");\n\n  // If the first element is a struct, recurse.\n  llvm::Type *SrcTy = SrcPtr.getElementType();\n  if (llvm::StructType *SrcSTy = dyn_cast<llvm::StructType>(SrcTy))\n    return EnterStructPointerForCoercedAccess(SrcPtr, SrcSTy, DstSize, CGF);\n\n  return SrcPtr;\n}\n\n/// CoerceIntOrPtrToIntOrPtr - Convert a value Val to the specific Ty where both\n/// are either integers or pointers.  This does a truncation of the value if it\n/// is too large or a zero extension if it is too small.\n///\n/// This behaves as if the value were coerced through memory, so on big-endian\n/// targets the high bits are preserved in a truncation, while little-endian\n/// targets preserve the low bits.\nstatic llvm::Value *CoerceIntOrPtrToIntOrPtr(llvm::Value *Val,\n                                             llvm::Type *Ty,\n                                             CodeGenFunction &CGF) {\n  if (Val->getType() == Ty)\n    return Val;\n\n  if (isa<llvm::PointerType>(Val->getType())) {\n    // If this is Pointer->Pointer avoid conversion to and from int.\n    if (isa<llvm::PointerType>(Ty))\n      return CGF.Builder.CreateBitCast(Val, Ty, \"coerce.val\");\n\n    // Convert the pointer to an integer so we can play with its width.\n    Val = CGF.Builder.CreatePtrToInt(Val, CGF.IntPtrTy, \"coerce.val.pi\");\n  }\n\n  llvm::Type *DestIntTy = Ty;\n  if (isa<llvm::PointerType>(DestIntTy))\n    DestIntTy = CGF.IntPtrTy;\n\n  if (Val->getType() != DestIntTy) {\n    const llvm::DataLayout &DL = CGF.CGM.getDataLayout();\n    if (DL.isBigEndian()) {\n      // Preserve the high bits on big-endian targets.\n      // That is what memory coercion does.\n      uint64_t SrcSize = DL.getTypeSizeInBits(Val->getType());\n      uint64_t DstSize = DL.getTypeSizeInBits(DestIntTy);\n\n      if (SrcSize > DstSize) {\n        Val = CGF.Builder.CreateLShr(Val, SrcSize - DstSize, \"coerce.highbits\");\n        Val = CGF.Builder.CreateTrunc(Val, DestIntTy, \"coerce.val.ii\");\n      } else {\n        Val = CGF.Builder.CreateZExt(Val, DestIntTy, \"coerce.val.ii\");\n        Val = CGF.Builder.CreateShl(Val, DstSize - SrcSize, \"coerce.highbits\");\n      }\n    } else {\n      // Little-endian targets preserve the low bits. No shifts required.\n      Val = CGF.Builder.CreateIntCast(Val, DestIntTy, false, \"coerce.val.ii\");\n    }\n  }\n\n  if (isa<llvm::PointerType>(Ty))\n    Val = CGF.Builder.CreateIntToPtr(Val, Ty, \"coerce.val.ip\");\n  return Val;\n}\n\n\n\n/// CreateCoercedLoad - Create a load from \\arg SrcPtr interpreted as\n/// a pointer to an object of type \\arg Ty, known to be aligned to\n/// \\arg SrcAlign bytes.\n///\n/// This safely handles the case when the src type is smaller than the\n/// destination type; in this situation the values of bits which not\n/// present in the src are undefined.\nstatic llvm::Value *CreateCoercedLoad(Address Src, llvm::Type *Ty,\n                                      CodeGenFunction &CGF) {\n  llvm::Type *SrcTy = Src.getElementType();\n\n  // If SrcTy and Ty are the same, just do a load.\n  if (SrcTy == Ty)\n    return CGF.Builder.CreateLoad(Src);\n\n  llvm::TypeSize DstSize = CGF.CGM.getDataLayout().getTypeAllocSize(Ty);\n\n  if (llvm::StructType *SrcSTy = dyn_cast<llvm::StructType>(SrcTy)) {\n    Src = EnterStructPointerForCoercedAccess(Src, SrcSTy,\n                                             DstSize.getFixedSize(), CGF);\n    SrcTy = Src.getElementType();\n  }\n\n  llvm::TypeSize SrcSize = CGF.CGM.getDataLayout().getTypeAllocSize(SrcTy);\n\n  // If the source and destination are integer or pointer types, just do an\n  // extension or truncation to the desired type.\n  if ((isa<llvm::IntegerType>(Ty) || isa<llvm::PointerType>(Ty)) &&\n      (isa<llvm::IntegerType>(SrcTy) || isa<llvm::PointerType>(SrcTy))) {\n    llvm::Value *Load = CGF.Builder.CreateLoad(Src);\n    return CoerceIntOrPtrToIntOrPtr(Load, Ty, CGF);\n  }\n\n  // If load is legal, just bitcast the src pointer.\n  if (!SrcSize.isScalable() && !DstSize.isScalable() &&\n      SrcSize.getFixedSize() >= DstSize.getFixedSize()) {\n    // Generally SrcSize is never greater than DstSize, since this means we are\n    // losing bits. However, this can happen in cases where the structure has\n    // additional padding, for example due to a user specified alignment.\n    //\n    // FIXME: Assert that we aren't truncating non-padding bits when have access\n    // to that information.\n    Src = CGF.Builder.CreateBitCast(Src,\n                                    Ty->getPointerTo(Src.getAddressSpace()));\n    return CGF.Builder.CreateLoad(Src);\n  }\n\n  // If coercing a fixed vector to a scalable vector for ABI compatibility, and\n  // the types match, use the llvm.experimental.vector.insert intrinsic to\n  // perform the conversion.\n  if (auto *ScalableDst = dyn_cast<llvm::ScalableVectorType>(Ty)) {\n    if (auto *FixedSrc = dyn_cast<llvm::FixedVectorType>(SrcTy)) {\n      if (ScalableDst->getElementType() == FixedSrc->getElementType()) {\n        auto *Load = CGF.Builder.CreateLoad(Src);\n        auto *UndefVec = llvm::UndefValue::get(ScalableDst);\n        auto *Zero = llvm::Constant::getNullValue(CGF.CGM.Int64Ty);\n        return CGF.Builder.CreateInsertVector(ScalableDst, UndefVec, Load, Zero,\n                                              \"castScalableSve\");\n      }\n    }\n  }\n\n  // Otherwise do coercion through memory. This is stupid, but simple.\n  Address Tmp =\n      CreateTempAllocaForCoercion(CGF, Ty, Src.getAlignment(), Src.getName());\n  CGF.Builder.CreateMemCpy(\n      Tmp.getPointer(), Tmp.getAlignment().getAsAlign(), Src.getPointer(),\n      Src.getAlignment().getAsAlign(),\n      llvm::ConstantInt::get(CGF.IntPtrTy, SrcSize.getKnownMinSize()));\n  return CGF.Builder.CreateLoad(Tmp);\n}\n\n// Function to store a first-class aggregate into memory.  We prefer to\n// store the elements rather than the aggregate to be more friendly to\n// fast-isel.\n// FIXME: Do we need to recurse here?\nvoid CodeGenFunction::EmitAggregateStore(llvm::Value *Val, Address Dest,\n                                         bool DestIsVolatile) {\n  // Prefer scalar stores to first-class aggregate stores.\n  if (llvm::StructType *STy = dyn_cast<llvm::StructType>(Val->getType())) {\n    for (unsigned i = 0, e = STy->getNumElements(); i != e; ++i) {\n      Address EltPtr = Builder.CreateStructGEP(Dest, i);\n      llvm::Value *Elt = Builder.CreateExtractValue(Val, i);\n      Builder.CreateStore(Elt, EltPtr, DestIsVolatile);\n    }\n  } else {\n    Builder.CreateStore(Val, Dest, DestIsVolatile);\n  }\n}\n\n/// CreateCoercedStore - Create a store to \\arg DstPtr from \\arg Src,\n/// where the source and destination may have different types.  The\n/// destination is known to be aligned to \\arg DstAlign bytes.\n///\n/// This safely handles the case when the src type is larger than the\n/// destination type; the upper bits of the src will be lost.\nstatic void CreateCoercedStore(llvm::Value *Src,\n                               Address Dst,\n                               bool DstIsVolatile,\n                               CodeGenFunction &CGF) {\n  llvm::Type *SrcTy = Src->getType();\n  llvm::Type *DstTy = Dst.getElementType();\n  if (SrcTy == DstTy) {\n    CGF.Builder.CreateStore(Src, Dst, DstIsVolatile);\n    return;\n  }\n\n  llvm::TypeSize SrcSize = CGF.CGM.getDataLayout().getTypeAllocSize(SrcTy);\n\n  if (llvm::StructType *DstSTy = dyn_cast<llvm::StructType>(DstTy)) {\n    Dst = EnterStructPointerForCoercedAccess(Dst, DstSTy,\n                                             SrcSize.getFixedSize(), CGF);\n    DstTy = Dst.getElementType();\n  }\n\n  llvm::PointerType *SrcPtrTy = llvm::dyn_cast<llvm::PointerType>(SrcTy);\n  llvm::PointerType *DstPtrTy = llvm::dyn_cast<llvm::PointerType>(DstTy);\n  if (SrcPtrTy && DstPtrTy &&\n      SrcPtrTy->getAddressSpace() != DstPtrTy->getAddressSpace()) {\n    Src = CGF.Builder.CreatePointerBitCastOrAddrSpaceCast(Src, DstTy);\n    CGF.Builder.CreateStore(Src, Dst, DstIsVolatile);\n    return;\n  }\n\n  // If the source and destination are integer or pointer types, just do an\n  // extension or truncation to the desired type.\n  if ((isa<llvm::IntegerType>(SrcTy) || isa<llvm::PointerType>(SrcTy)) &&\n      (isa<llvm::IntegerType>(DstTy) || isa<llvm::PointerType>(DstTy))) {\n    Src = CoerceIntOrPtrToIntOrPtr(Src, DstTy, CGF);\n    CGF.Builder.CreateStore(Src, Dst, DstIsVolatile);\n    return;\n  }\n\n  llvm::TypeSize DstSize = CGF.CGM.getDataLayout().getTypeAllocSize(DstTy);\n\n  // If store is legal, just bitcast the src pointer.\n  if (isa<llvm::ScalableVectorType>(SrcTy) ||\n      isa<llvm::ScalableVectorType>(DstTy) ||\n      SrcSize.getFixedSize() <= DstSize.getFixedSize()) {\n    Dst = CGF.Builder.CreateElementBitCast(Dst, SrcTy);\n    CGF.EmitAggregateStore(Src, Dst, DstIsVolatile);\n  } else {\n    // Otherwise do coercion through memory. This is stupid, but\n    // simple.\n\n    // Generally SrcSize is never greater than DstSize, since this means we are\n    // losing bits. However, this can happen in cases where the structure has\n    // additional padding, for example due to a user specified alignment.\n    //\n    // FIXME: Assert that we aren't truncating non-padding bits when have access\n    // to that information.\n    Address Tmp = CreateTempAllocaForCoercion(CGF, SrcTy, Dst.getAlignment());\n    CGF.Builder.CreateStore(Src, Tmp);\n    CGF.Builder.CreateMemCpy(\n        Dst.getPointer(), Dst.getAlignment().getAsAlign(), Tmp.getPointer(),\n        Tmp.getAlignment().getAsAlign(),\n        llvm::ConstantInt::get(CGF.IntPtrTy, DstSize.getFixedSize()));\n  }\n}\n\nstatic Address emitAddressAtOffset(CodeGenFunction &CGF, Address addr,\n                                   const ABIArgInfo &info) {\n  if (unsigned offset = info.getDirectOffset()) {\n    addr = CGF.Builder.CreateElementBitCast(addr, CGF.Int8Ty);\n    addr = CGF.Builder.CreateConstInBoundsByteGEP(addr,\n                                             CharUnits::fromQuantity(offset));\n    addr = CGF.Builder.CreateElementBitCast(addr, info.getCoerceToType());\n  }\n  return addr;\n}\n\nnamespace {\n\n/// Encapsulates information about the way function arguments from\n/// CGFunctionInfo should be passed to actual LLVM IR function.\nclass ClangToLLVMArgMapping {\n  static const unsigned InvalidIndex = ~0U;\n  unsigned InallocaArgNo;\n  unsigned SRetArgNo;\n  unsigned TotalIRArgs;\n\n  /// Arguments of LLVM IR function corresponding to single Clang argument.\n  struct IRArgs {\n    unsigned PaddingArgIndex;\n    // Argument is expanded to IR arguments at positions\n    // [FirstArgIndex, FirstArgIndex + NumberOfArgs).\n    unsigned FirstArgIndex;\n    unsigned NumberOfArgs;\n\n    IRArgs()\n        : PaddingArgIndex(InvalidIndex), FirstArgIndex(InvalidIndex),\n          NumberOfArgs(0) {}\n  };\n\n  SmallVector<IRArgs, 8> ArgInfo;\n\npublic:\n  ClangToLLVMArgMapping(const ASTContext &Context, const CGFunctionInfo &FI,\n                        bool OnlyRequiredArgs = false)\n      : InallocaArgNo(InvalidIndex), SRetArgNo(InvalidIndex), TotalIRArgs(0),\n        ArgInfo(OnlyRequiredArgs ? FI.getNumRequiredArgs() : FI.arg_size()) {\n    construct(Context, FI, OnlyRequiredArgs);\n  }\n\n  bool hasInallocaArg() const { return InallocaArgNo != InvalidIndex; }\n  unsigned getInallocaArgNo() const {\n    assert(hasInallocaArg());\n    return InallocaArgNo;\n  }\n\n  bool hasSRetArg() const { return SRetArgNo != InvalidIndex; }\n  unsigned getSRetArgNo() const {\n    assert(hasSRetArg());\n    return SRetArgNo;\n  }\n\n  unsigned totalIRArgs() const { return TotalIRArgs; }\n\n  bool hasPaddingArg(unsigned ArgNo) const {\n    assert(ArgNo < ArgInfo.size());\n    return ArgInfo[ArgNo].PaddingArgIndex != InvalidIndex;\n  }\n  unsigned getPaddingArgNo(unsigned ArgNo) const {\n    assert(hasPaddingArg(ArgNo));\n    return ArgInfo[ArgNo].PaddingArgIndex;\n  }\n\n  /// Returns index of first IR argument corresponding to ArgNo, and their\n  /// quantity.\n  std::pair<unsigned, unsigned> getIRArgs(unsigned ArgNo) const {\n    assert(ArgNo < ArgInfo.size());\n    return std::make_pair(ArgInfo[ArgNo].FirstArgIndex,\n                          ArgInfo[ArgNo].NumberOfArgs);\n  }\n\nprivate:\n  void construct(const ASTContext &Context, const CGFunctionInfo &FI,\n                 bool OnlyRequiredArgs);\n};\n\nvoid ClangToLLVMArgMapping::construct(const ASTContext &Context,\n                                      const CGFunctionInfo &FI,\n                                      bool OnlyRequiredArgs) {\n  unsigned IRArgNo = 0;\n  bool SwapThisWithSRet = false;\n  const ABIArgInfo &RetAI = FI.getReturnInfo();\n\n  if (RetAI.getKind() == ABIArgInfo::Indirect) {\n    SwapThisWithSRet = RetAI.isSRetAfterThis();\n    SRetArgNo = SwapThisWithSRet ? 1 : IRArgNo++;\n  }\n\n  unsigned ArgNo = 0;\n  unsigned NumArgs = OnlyRequiredArgs ? FI.getNumRequiredArgs() : FI.arg_size();\n  for (CGFunctionInfo::const_arg_iterator I = FI.arg_begin(); ArgNo < NumArgs;\n       ++I, ++ArgNo) {\n    assert(I != FI.arg_end());\n    QualType ArgType = I->type;\n    const ABIArgInfo &AI = I->info;\n    // Collect data about IR arguments corresponding to Clang argument ArgNo.\n    auto &IRArgs = ArgInfo[ArgNo];\n\n    if (AI.getPaddingType())\n      IRArgs.PaddingArgIndex = IRArgNo++;\n\n    switch (AI.getKind()) {\n    case ABIArgInfo::Extend:\n    case ABIArgInfo::Direct: {\n      // FIXME: handle sseregparm someday...\n      llvm::StructType *STy = dyn_cast<llvm::StructType>(AI.getCoerceToType());\n      if (AI.isDirect() && AI.getCanBeFlattened() && STy) {\n        IRArgs.NumberOfArgs = STy->getNumElements();\n      } else {\n        IRArgs.NumberOfArgs = 1;\n      }\n      break;\n    }\n    case ABIArgInfo::Indirect:\n    case ABIArgInfo::IndirectAliased:\n      IRArgs.NumberOfArgs = 1;\n      break;\n    case ABIArgInfo::Ignore:\n    case ABIArgInfo::InAlloca:\n      // ignore and inalloca doesn't have matching LLVM parameters.\n      IRArgs.NumberOfArgs = 0;\n      break;\n    case ABIArgInfo::CoerceAndExpand:\n      IRArgs.NumberOfArgs = AI.getCoerceAndExpandTypeSequence().size();\n      break;\n    case ABIArgInfo::Expand:\n      IRArgs.NumberOfArgs = getExpansionSize(ArgType, Context);\n      break;\n    }\n\n    if (IRArgs.NumberOfArgs > 0) {\n      IRArgs.FirstArgIndex = IRArgNo;\n      IRArgNo += IRArgs.NumberOfArgs;\n    }\n\n    // Skip over the sret parameter when it comes second.  We already handled it\n    // above.\n    if (IRArgNo == 1 && SwapThisWithSRet)\n      IRArgNo++;\n  }\n  assert(ArgNo == ArgInfo.size());\n\n  if (FI.usesInAlloca())\n    InallocaArgNo = IRArgNo++;\n\n  TotalIRArgs = IRArgNo;\n}\n}  // namespace\n\n/***/\n\nbool CodeGenModule::ReturnTypeUsesSRet(const CGFunctionInfo &FI) {\n  const auto &RI = FI.getReturnInfo();\n  return RI.isIndirect() || (RI.isInAlloca() && RI.getInAllocaSRet());\n}\n\nbool CodeGenModule::ReturnSlotInterferesWithArgs(const CGFunctionInfo &FI) {\n  return ReturnTypeUsesSRet(FI) &&\n         getTargetCodeGenInfo().doesReturnSlotInterfereWithArgs();\n}\n\nbool CodeGenModule::ReturnTypeUsesFPRet(QualType ResultType) {\n  if (const BuiltinType *BT = ResultType->getAs<BuiltinType>()) {\n    switch (BT->getKind()) {\n    default:\n      return false;\n    case BuiltinType::Float:\n      return getTarget().useObjCFPRetForRealType(TargetInfo::Float);\n    case BuiltinType::Double:\n      return getTarget().useObjCFPRetForRealType(TargetInfo::Double);\n    case BuiltinType::LongDouble:\n      return getTarget().useObjCFPRetForRealType(TargetInfo::LongDouble);\n    }\n  }\n\n  return false;\n}\n\nbool CodeGenModule::ReturnTypeUsesFP2Ret(QualType ResultType) {\n  if (const ComplexType *CT = ResultType->getAs<ComplexType>()) {\n    if (const BuiltinType *BT = CT->getElementType()->getAs<BuiltinType>()) {\n      if (BT->getKind() == BuiltinType::LongDouble)\n        return getTarget().useObjCFP2RetForComplexLongDouble();\n    }\n  }\n\n  return false;\n}\n\nllvm::FunctionType *CodeGenTypes::GetFunctionType(GlobalDecl GD) {\n  const CGFunctionInfo &FI = arrangeGlobalDeclaration(GD);\n  return GetFunctionType(FI);\n}\n\nllvm::FunctionType *\nCodeGenTypes::GetFunctionType(const CGFunctionInfo &FI) {\n\n  bool Inserted = FunctionsBeingProcessed.insert(&FI).second;\n  (void)Inserted;\n  assert(Inserted && \"Recursively being processed?\");\n\n  llvm::Type *resultType = nullptr;\n  const ABIArgInfo &retAI = FI.getReturnInfo();\n  switch (retAI.getKind()) {\n  case ABIArgInfo::Expand:\n  case ABIArgInfo::IndirectAliased:\n    llvm_unreachable(\"Invalid ABI kind for return argument\");\n\n  case ABIArgInfo::Extend:\n  case ABIArgInfo::Direct:\n    resultType = retAI.getCoerceToType();\n    break;\n\n  case ABIArgInfo::InAlloca:\n    if (retAI.getInAllocaSRet()) {\n      // sret things on win32 aren't void, they return the sret pointer.\n      QualType ret = FI.getReturnType();\n      llvm::Type *ty = ConvertType(ret);\n      unsigned addressSpace = Context.getTargetAddressSpace(ret);\n      resultType = llvm::PointerType::get(ty, addressSpace);\n    } else {\n      resultType = llvm::Type::getVoidTy(getLLVMContext());\n    }\n    break;\n\n  case ABIArgInfo::Indirect:\n  case ABIArgInfo::Ignore:\n    resultType = llvm::Type::getVoidTy(getLLVMContext());\n    break;\n\n  case ABIArgInfo::CoerceAndExpand:\n    resultType = retAI.getUnpaddedCoerceAndExpandType();\n    break;\n  }\n\n  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI, true);\n  SmallVector<llvm::Type*, 8> ArgTypes(IRFunctionArgs.totalIRArgs());\n\n  // Add type for sret argument.\n  if (IRFunctionArgs.hasSRetArg()) {\n    QualType Ret = FI.getReturnType();\n    llvm::Type *Ty = ConvertType(Ret);\n    unsigned AddressSpace = Context.getTargetAddressSpace(Ret);\n    ArgTypes[IRFunctionArgs.getSRetArgNo()] =\n        llvm::PointerType::get(Ty, AddressSpace);\n  }\n\n  // Add type for inalloca argument.\n  if (IRFunctionArgs.hasInallocaArg()) {\n    auto ArgStruct = FI.getArgStruct();\n    assert(ArgStruct);\n    ArgTypes[IRFunctionArgs.getInallocaArgNo()] = ArgStruct->getPointerTo();\n  }\n\n  // Add in all of the required arguments.\n  unsigned ArgNo = 0;\n  CGFunctionInfo::const_arg_iterator it = FI.arg_begin(),\n                                     ie = it + FI.getNumRequiredArgs();\n  for (; it != ie; ++it, ++ArgNo) {\n    const ABIArgInfo &ArgInfo = it->info;\n\n    // Insert a padding type to ensure proper alignment.\n    if (IRFunctionArgs.hasPaddingArg(ArgNo))\n      ArgTypes[IRFunctionArgs.getPaddingArgNo(ArgNo)] =\n          ArgInfo.getPaddingType();\n\n    unsigned FirstIRArg, NumIRArgs;\n    std::tie(FirstIRArg, NumIRArgs) = IRFunctionArgs.getIRArgs(ArgNo);\n\n    switch (ArgInfo.getKind()) {\n    case ABIArgInfo::Ignore:\n    case ABIArgInfo::InAlloca:\n      assert(NumIRArgs == 0);\n      break;\n\n    case ABIArgInfo::Indirect: {\n      assert(NumIRArgs == 1);\n      // indirect arguments are always on the stack, which is alloca addr space.\n      llvm::Type *LTy = ConvertTypeForMem(it->type);\n      ArgTypes[FirstIRArg] = LTy->getPointerTo(\n          CGM.getDataLayout().getAllocaAddrSpace());\n      break;\n    }\n    case ABIArgInfo::IndirectAliased: {\n      assert(NumIRArgs == 1);\n      llvm::Type *LTy = ConvertTypeForMem(it->type);\n      ArgTypes[FirstIRArg] = LTy->getPointerTo(ArgInfo.getIndirectAddrSpace());\n      break;\n    }\n    case ABIArgInfo::Extend:\n    case ABIArgInfo::Direct: {\n      // Fast-isel and the optimizer generally like scalar values better than\n      // FCAs, so we flatten them if this is safe to do for this argument.\n      llvm::Type *argType = ArgInfo.getCoerceToType();\n      llvm::StructType *st = dyn_cast<llvm::StructType>(argType);\n      if (st && ArgInfo.isDirect() && ArgInfo.getCanBeFlattened()) {\n        assert(NumIRArgs == st->getNumElements());\n        for (unsigned i = 0, e = st->getNumElements(); i != e; ++i)\n          ArgTypes[FirstIRArg + i] = st->getElementType(i);\n      } else {\n        assert(NumIRArgs == 1);\n        ArgTypes[FirstIRArg] = argType;\n      }\n      break;\n    }\n\n    case ABIArgInfo::CoerceAndExpand: {\n      auto ArgTypesIter = ArgTypes.begin() + FirstIRArg;\n      for (auto EltTy : ArgInfo.getCoerceAndExpandTypeSequence()) {\n        *ArgTypesIter++ = EltTy;\n      }\n      assert(ArgTypesIter == ArgTypes.begin() + FirstIRArg + NumIRArgs);\n      break;\n    }\n\n    case ABIArgInfo::Expand:\n      auto ArgTypesIter = ArgTypes.begin() + FirstIRArg;\n      getExpandedTypes(it->type, ArgTypesIter);\n      assert(ArgTypesIter == ArgTypes.begin() + FirstIRArg + NumIRArgs);\n      break;\n    }\n  }\n\n  bool Erased = FunctionsBeingProcessed.erase(&FI); (void)Erased;\n  assert(Erased && \"Not in set?\");\n\n  return llvm::FunctionType::get(resultType, ArgTypes, FI.isVariadic());\n}\n\nllvm::Type *CodeGenTypes::GetFunctionTypeForVTable(GlobalDecl GD) {\n  const CXXMethodDecl *MD = cast<CXXMethodDecl>(GD.getDecl());\n  const FunctionProtoType *FPT = MD->getType()->getAs<FunctionProtoType>();\n\n  if (!isFuncTypeConvertible(FPT))\n    return llvm::StructType::get(getLLVMContext());\n\n  return GetFunctionType(GD);\n}\n\nstatic void AddAttributesFromFunctionProtoType(ASTContext &Ctx,\n                                               llvm::AttrBuilder &FuncAttrs,\n                                               const FunctionProtoType *FPT) {\n  if (!FPT)\n    return;\n\n  if (!isUnresolvedExceptionSpec(FPT->getExceptionSpecType()) &&\n      FPT->isNothrow())\n    FuncAttrs.addAttribute(llvm::Attribute::NoUnwind);\n}\n\nbool CodeGenModule::MayDropFunctionReturn(const ASTContext &Context,\n                                          QualType ReturnType) {\n  // We can't just discard the return value for a record type with a\n  // complex destructor or a non-trivially copyable type.\n  if (const RecordType *RT =\n          ReturnType.getCanonicalType()->getAs<RecordType>()) {\n    if (const auto *ClassDecl = dyn_cast<CXXRecordDecl>(RT->getDecl()))\n      return ClassDecl->hasTrivialDestructor();\n  }\n  return ReturnType.isTriviallyCopyableType(Context);\n}\n\nvoid CodeGenModule::getDefaultFunctionAttributes(StringRef Name,\n                                                 bool HasOptnone,\n                                                 bool AttrOnCallSite,\n                                               llvm::AttrBuilder &FuncAttrs) {\n  // OptimizeNoneAttr takes precedence over -Os or -Oz. No warning needed.\n  if (!HasOptnone) {\n    if (CodeGenOpts.OptimizeSize)\n      FuncAttrs.addAttribute(llvm::Attribute::OptimizeForSize);\n    if (CodeGenOpts.OptimizeSize == 2)\n      FuncAttrs.addAttribute(llvm::Attribute::MinSize);\n  }\n\n  if (CodeGenOpts.DisableRedZone)\n    FuncAttrs.addAttribute(llvm::Attribute::NoRedZone);\n  if (CodeGenOpts.IndirectTlsSegRefs)\n    FuncAttrs.addAttribute(\"indirect-tls-seg-refs\");\n  if (CodeGenOpts.NoImplicitFloat)\n    FuncAttrs.addAttribute(llvm::Attribute::NoImplicitFloat);\n\n  if (AttrOnCallSite) {\n    // Attributes that should go on the call site only.\n    if (!CodeGenOpts.SimplifyLibCalls || LangOpts.isNoBuiltinFunc(Name))\n      FuncAttrs.addAttribute(llvm::Attribute::NoBuiltin);\n    if (!CodeGenOpts.TrapFuncName.empty())\n      FuncAttrs.addAttribute(\"trap-func-name\", CodeGenOpts.TrapFuncName);\n  } else {\n    StringRef FpKind;\n    switch (CodeGenOpts.getFramePointer()) {\n    case CodeGenOptions::FramePointerKind::None:\n      FpKind = \"none\";\n      break;\n    case CodeGenOptions::FramePointerKind::NonLeaf:\n      FpKind = \"non-leaf\";\n      break;\n    case CodeGenOptions::FramePointerKind::All:\n      FpKind = \"all\";\n      break;\n    }\n    FuncAttrs.addAttribute(\"frame-pointer\", FpKind);\n\n    if (CodeGenOpts.LessPreciseFPMAD)\n      FuncAttrs.addAttribute(\"less-precise-fpmad\", \"true\");\n\n    if (CodeGenOpts.NullPointerIsValid)\n      FuncAttrs.addAttribute(llvm::Attribute::NullPointerIsValid);\n\n    if (CodeGenOpts.FPDenormalMode != llvm::DenormalMode::getIEEE())\n      FuncAttrs.addAttribute(\"denormal-fp-math\",\n                             CodeGenOpts.FPDenormalMode.str());\n    if (CodeGenOpts.FP32DenormalMode != CodeGenOpts.FPDenormalMode) {\n      FuncAttrs.addAttribute(\n          \"denormal-fp-math-f32\",\n          CodeGenOpts.FP32DenormalMode.str());\n    }\n\n    if (LangOpts.getFPExceptionMode() == LangOptions::FPE_Ignore)\n      FuncAttrs.addAttribute(\"no-trapping-math\", \"true\");\n\n    // Strict (compliant) code is the default, so only add this attribute to\n    // indicate that we are trying to workaround a problem case.\n    if (!CodeGenOpts.StrictFloatCastOverflow)\n      FuncAttrs.addAttribute(\"strict-float-cast-overflow\", \"false\");\n\n    // TODO: Are these all needed?\n    // unsafe/inf/nan/nsz are handled by instruction-level FastMathFlags.\n    if (LangOpts.NoHonorInfs)\n      FuncAttrs.addAttribute(\"no-infs-fp-math\", \"true\");\n    if (LangOpts.NoHonorNaNs)\n      FuncAttrs.addAttribute(\"no-nans-fp-math\", \"true\");\n    if (LangOpts.UnsafeFPMath)\n      FuncAttrs.addAttribute(\"unsafe-fp-math\", \"true\");\n    if (CodeGenOpts.SoftFloat)\n      FuncAttrs.addAttribute(\"use-soft-float\", \"true\");\n    FuncAttrs.addAttribute(\"stack-protector-buffer-size\",\n                           llvm::utostr(CodeGenOpts.SSPBufferSize));\n    if (LangOpts.NoSignedZero)\n      FuncAttrs.addAttribute(\"no-signed-zeros-fp-math\", \"true\");\n\n    // TODO: Reciprocal estimate codegen options should apply to instructions?\n    const std::vector<std::string> &Recips = CodeGenOpts.Reciprocals;\n    if (!Recips.empty())\n      FuncAttrs.addAttribute(\"reciprocal-estimates\",\n                             llvm::join(Recips, \",\"));\n\n    if (!CodeGenOpts.PreferVectorWidth.empty() &&\n        CodeGenOpts.PreferVectorWidth != \"none\")\n      FuncAttrs.addAttribute(\"prefer-vector-width\",\n                             CodeGenOpts.PreferVectorWidth);\n\n    if (CodeGenOpts.StackRealignment)\n      FuncAttrs.addAttribute(\"stackrealign\");\n    if (CodeGenOpts.Backchain)\n      FuncAttrs.addAttribute(\"backchain\");\n    if (CodeGenOpts.EnableSegmentedStacks)\n      FuncAttrs.addAttribute(\"split-stack\");\n\n    if (CodeGenOpts.SpeculativeLoadHardening)\n      FuncAttrs.addAttribute(llvm::Attribute::SpeculativeLoadHardening);\n  }\n\n  if (getLangOpts().assumeFunctionsAreConvergent()) {\n    // Conservatively, mark all functions and calls in CUDA and OpenCL as\n    // convergent (meaning, they may call an intrinsically convergent op, such\n    // as __syncthreads() / barrier(), and so can't have certain optimizations\n    // applied around them).  LLVM will remove this attribute where it safely\n    // can.\n    FuncAttrs.addAttribute(llvm::Attribute::Convergent);\n  }\n\n  if (getLangOpts().CUDA && getLangOpts().CUDAIsDevice) {\n    // Exceptions aren't supported in CUDA device code.\n    FuncAttrs.addAttribute(llvm::Attribute::NoUnwind);\n  }\n\n  for (StringRef Attr : CodeGenOpts.DefaultFunctionAttrs) {\n    StringRef Var, Value;\n    std::tie(Var, Value) = Attr.split('=');\n    FuncAttrs.addAttribute(Var, Value);\n  }\n}\n\nvoid CodeGenModule::addDefaultFunctionDefinitionAttributes(llvm::Function &F) {\n  llvm::AttrBuilder FuncAttrs;\n  getDefaultFunctionAttributes(F.getName(), F.hasOptNone(),\n                               /* AttrOnCallSite = */ false, FuncAttrs);\n  // TODO: call GetCPUAndFeaturesAttributes?\n  F.addAttributes(llvm::AttributeList::FunctionIndex, FuncAttrs);\n}\n\nvoid CodeGenModule::addDefaultFunctionDefinitionAttributes(\n                                                   llvm::AttrBuilder &attrs) {\n  getDefaultFunctionAttributes(/*function name*/ \"\", /*optnone*/ false,\n                               /*for call*/ false, attrs);\n  GetCPUAndFeaturesAttributes(GlobalDecl(), attrs);\n}\n\nstatic void addNoBuiltinAttributes(llvm::AttrBuilder &FuncAttrs,\n                                   const LangOptions &LangOpts,\n                                   const NoBuiltinAttr *NBA = nullptr) {\n  auto AddNoBuiltinAttr = [&FuncAttrs](StringRef BuiltinName) {\n    SmallString<32> AttributeName;\n    AttributeName += \"no-builtin-\";\n    AttributeName += BuiltinName;\n    FuncAttrs.addAttribute(AttributeName);\n  };\n\n  // First, handle the language options passed through -fno-builtin.\n  if (LangOpts.NoBuiltin) {\n    // -fno-builtin disables them all.\n    FuncAttrs.addAttribute(\"no-builtins\");\n    return;\n  }\n\n  // Then, add attributes for builtins specified through -fno-builtin-<name>.\n  llvm::for_each(LangOpts.NoBuiltinFuncs, AddNoBuiltinAttr);\n\n  // Now, let's check the __attribute__((no_builtin(\"...\")) attribute added to\n  // the source.\n  if (!NBA)\n    return;\n\n  // If there is a wildcard in the builtin names specified through the\n  // attribute, disable them all.\n  if (llvm::is_contained(NBA->builtinNames(), \"*\")) {\n    FuncAttrs.addAttribute(\"no-builtins\");\n    return;\n  }\n\n  // And last, add the rest of the builtin names.\n  llvm::for_each(NBA->builtinNames(), AddNoBuiltinAttr);\n}\n\nstatic bool DetermineNoUndef(QualType QTy, CodeGenTypes &Types,\n                             const llvm::DataLayout &DL, const ABIArgInfo &AI,\n                             bool CheckCoerce = true) {\n  llvm::Type *Ty = Types.ConvertTypeForMem(QTy);\n  if (AI.getKind() == ABIArgInfo::Indirect)\n    return true;\n  if (AI.getKind() == ABIArgInfo::Extend)\n    return true;\n  if (!DL.typeSizeEqualsStoreSize(Ty))\n    // TODO: This will result in a modest amount of values not marked noundef\n    // when they could be. We care about values that *invisibly* contain undef\n    // bits from the perspective of LLVM IR.\n    return false;\n  if (CheckCoerce && AI.canHaveCoerceToType()) {\n    llvm::Type *CoerceTy = AI.getCoerceToType();\n    if (llvm::TypeSize::isKnownGT(DL.getTypeSizeInBits(CoerceTy),\n                                  DL.getTypeSizeInBits(Ty)))\n      // If we're coercing to a type with a greater size than the canonical one,\n      // we're introducing new undef bits.\n      // Coercing to a type of smaller or equal size is ok, as we know that\n      // there's no internal padding (typeSizeEqualsStoreSize).\n      return false;\n  }\n  if (QTy->isExtIntType())\n    return true;\n  if (QTy->isReferenceType())\n    return true;\n  if (QTy->isNullPtrType())\n    return false;\n  if (QTy->isMemberPointerType())\n    // TODO: Some member pointers are `noundef`, but it depends on the ABI. For\n    // now, never mark them.\n    return false;\n  if (QTy->isScalarType()) {\n    if (const ComplexType *Complex = dyn_cast<ComplexType>(QTy))\n      return DetermineNoUndef(Complex->getElementType(), Types, DL, AI, false);\n    return true;\n  }\n  if (const VectorType *Vector = dyn_cast<VectorType>(QTy))\n    return DetermineNoUndef(Vector->getElementType(), Types, DL, AI, false);\n  if (const MatrixType *Matrix = dyn_cast<MatrixType>(QTy))\n    return DetermineNoUndef(Matrix->getElementType(), Types, DL, AI, false);\n  if (const ArrayType *Array = dyn_cast<ArrayType>(QTy))\n    return DetermineNoUndef(Array->getElementType(), Types, DL, AI, false);\n\n  // TODO: Some structs may be `noundef`, in specific situations.\n  return false;\n}\n\n/// Construct the IR attribute list of a function or call.\n///\n/// When adding an attribute, please consider where it should be handled:\n///\n///   - getDefaultFunctionAttributes is for attributes that are essentially\n///     part of the global target configuration (but perhaps can be\n///     overridden on a per-function basis).  Adding attributes there\n///     will cause them to also be set in frontends that build on Clang's\n///     target-configuration logic, as well as for code defined in library\n///     modules such as CUDA's libdevice.\n///\n///   - ConstructAttributeList builds on top of getDefaultFunctionAttributes\n///     and adds declaration-specific, convention-specific, and\n///     frontend-specific logic.  The last is of particular importance:\n///     attributes that restrict how the frontend generates code must be\n///     added here rather than getDefaultFunctionAttributes.\n///\nvoid CodeGenModule::ConstructAttributeList(\n    StringRef Name, const CGFunctionInfo &FI, CGCalleeInfo CalleeInfo,\n    llvm::AttributeList &AttrList, unsigned &CallingConv, bool AttrOnCallSite) {\n  llvm::AttrBuilder FuncAttrs;\n  llvm::AttrBuilder RetAttrs;\n\n  // Collect function IR attributes from the CC lowering.\n  // We'll collect the paramete and result attributes later.\n  CallingConv = FI.getEffectiveCallingConvention();\n  if (FI.isNoReturn())\n    FuncAttrs.addAttribute(llvm::Attribute::NoReturn);\n  if (FI.isCmseNSCall())\n    FuncAttrs.addAttribute(\"cmse_nonsecure_call\");\n\n  // Collect function IR attributes from the callee prototype if we have one.\n  AddAttributesFromFunctionProtoType(getContext(), FuncAttrs,\n                                     CalleeInfo.getCalleeFunctionProtoType());\n\n  const Decl *TargetDecl = CalleeInfo.getCalleeDecl().getDecl();\n\n  bool HasOptnone = false;\n  // The NoBuiltinAttr attached to the target FunctionDecl.\n  const NoBuiltinAttr *NBA = nullptr;\n\n  // Collect function IR attributes based on declaration-specific\n  // information.\n  // FIXME: handle sseregparm someday...\n  if (TargetDecl) {\n    if (TargetDecl->hasAttr<ReturnsTwiceAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::ReturnsTwice);\n    if (TargetDecl->hasAttr<NoThrowAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::NoUnwind);\n    if (TargetDecl->hasAttr<NoReturnAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::NoReturn);\n    if (TargetDecl->hasAttr<ColdAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::Cold);\n    if (TargetDecl->hasAttr<HotAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::Hot);\n    if (TargetDecl->hasAttr<NoDuplicateAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::NoDuplicate);\n    if (TargetDecl->hasAttr<ConvergentAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::Convergent);\n\n    if (const FunctionDecl *Fn = dyn_cast<FunctionDecl>(TargetDecl)) {\n      AddAttributesFromFunctionProtoType(\n          getContext(), FuncAttrs, Fn->getType()->getAs<FunctionProtoType>());\n      if (AttrOnCallSite && Fn->isReplaceableGlobalAllocationFunction()) {\n        // A sane operator new returns a non-aliasing pointer.\n        auto Kind = Fn->getDeclName().getCXXOverloadedOperator();\n        if (getCodeGenOpts().AssumeSaneOperatorNew &&\n            (Kind == OO_New || Kind == OO_Array_New))\n          RetAttrs.addAttribute(llvm::Attribute::NoAlias);\n      }\n      const CXXMethodDecl *MD = dyn_cast<CXXMethodDecl>(Fn);\n      const bool IsVirtualCall = MD && MD->isVirtual();\n      // Don't use [[noreturn]], _Noreturn or [[no_builtin]] for a call to a\n      // virtual function. These attributes are not inherited by overloads.\n      if (!(AttrOnCallSite && IsVirtualCall)) {\n        if (Fn->isNoReturn())\n          FuncAttrs.addAttribute(llvm::Attribute::NoReturn);\n        NBA = Fn->getAttr<NoBuiltinAttr>();\n      }\n      // Only place nomerge attribute on call sites, never functions. This\n      // allows it to work on indirect virtual function calls.\n      if (AttrOnCallSite && TargetDecl->hasAttr<NoMergeAttr>())\n        FuncAttrs.addAttribute(llvm::Attribute::NoMerge);\n    }\n\n    // 'const', 'pure' and 'noalias' attributed functions are also nounwind.\n    if (TargetDecl->hasAttr<ConstAttr>()) {\n      FuncAttrs.addAttribute(llvm::Attribute::ReadNone);\n      FuncAttrs.addAttribute(llvm::Attribute::NoUnwind);\n      // gcc specifies that 'const' functions have greater restrictions than\n      // 'pure' functions, so they also cannot have infinite loops.\n      FuncAttrs.addAttribute(llvm::Attribute::WillReturn);\n    } else if (TargetDecl->hasAttr<PureAttr>()) {\n      FuncAttrs.addAttribute(llvm::Attribute::ReadOnly);\n      FuncAttrs.addAttribute(llvm::Attribute::NoUnwind);\n      // gcc specifies that 'pure' functions cannot have infinite loops.\n      FuncAttrs.addAttribute(llvm::Attribute::WillReturn);\n    } else if (TargetDecl->hasAttr<NoAliasAttr>()) {\n      FuncAttrs.addAttribute(llvm::Attribute::ArgMemOnly);\n      FuncAttrs.addAttribute(llvm::Attribute::NoUnwind);\n    }\n    if (TargetDecl->hasAttr<RestrictAttr>())\n      RetAttrs.addAttribute(llvm::Attribute::NoAlias);\n    if (TargetDecl->hasAttr<ReturnsNonNullAttr>() &&\n        !CodeGenOpts.NullPointerIsValid)\n      RetAttrs.addAttribute(llvm::Attribute::NonNull);\n    if (TargetDecl->hasAttr<AnyX86NoCallerSavedRegistersAttr>())\n      FuncAttrs.addAttribute(\"no_caller_saved_registers\");\n    if (TargetDecl->hasAttr<AnyX86NoCfCheckAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::NoCfCheck);\n    if (TargetDecl->hasAttr<LeafAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::NoCallback);\n\n    HasOptnone = TargetDecl->hasAttr<OptimizeNoneAttr>();\n    if (auto *AllocSize = TargetDecl->getAttr<AllocSizeAttr>()) {\n      Optional<unsigned> NumElemsParam;\n      if (AllocSize->getNumElemsParam().isValid())\n        NumElemsParam = AllocSize->getNumElemsParam().getLLVMIndex();\n      FuncAttrs.addAllocSizeAttr(AllocSize->getElemSizeParam().getLLVMIndex(),\n                                 NumElemsParam);\n    }\n\n    if (TargetDecl->hasAttr<OpenCLKernelAttr>()) {\n      if (getLangOpts().OpenCLVersion <= 120) {\n        // OpenCL v1.2 Work groups are always uniform\n        FuncAttrs.addAttribute(\"uniform-work-group-size\", \"true\");\n      } else {\n        // OpenCL v2.0 Work groups may be whether uniform or not.\n        // '-cl-uniform-work-group-size' compile option gets a hint\n        // to the compiler that the global work-size be a multiple of\n        // the work-group size specified to clEnqueueNDRangeKernel\n        // (i.e. work groups are uniform).\n        FuncAttrs.addAttribute(\"uniform-work-group-size\",\n                               llvm::toStringRef(CodeGenOpts.UniformWGSize));\n      }\n    }\n\n    std::string AssumptionValueStr;\n    for (AssumptionAttr *AssumptionA :\n         TargetDecl->specific_attrs<AssumptionAttr>()) {\n      std::string AS = AssumptionA->getAssumption().str();\n      if (!AS.empty() && !AssumptionValueStr.empty())\n        AssumptionValueStr += \",\";\n      AssumptionValueStr += AS;\n    }\n\n    if (!AssumptionValueStr.empty())\n      FuncAttrs.addAttribute(llvm::AssumptionAttrKey, AssumptionValueStr);\n  }\n\n  // Attach \"no-builtins\" attributes to:\n  // * call sites: both `nobuiltin` and \"no-builtins\" or \"no-builtin-<name>\".\n  // * definitions: \"no-builtins\" or \"no-builtin-<name>\" only.\n  // The attributes can come from:\n  // * LangOpts: -ffreestanding, -fno-builtin, -fno-builtin-<name>\n  // * FunctionDecl attributes: __attribute__((no_builtin(...)))\n  addNoBuiltinAttributes(FuncAttrs, getLangOpts(), NBA);\n\n  // Collect function IR attributes based on global settiings.\n  getDefaultFunctionAttributes(Name, HasOptnone, AttrOnCallSite, FuncAttrs);\n\n  // Override some default IR attributes based on declaration-specific\n  // information.\n  if (TargetDecl) {\n    if (TargetDecl->hasAttr<NoSpeculativeLoadHardeningAttr>())\n      FuncAttrs.removeAttribute(llvm::Attribute::SpeculativeLoadHardening);\n    if (TargetDecl->hasAttr<SpeculativeLoadHardeningAttr>())\n      FuncAttrs.addAttribute(llvm::Attribute::SpeculativeLoadHardening);\n    if (TargetDecl->hasAttr<NoSplitStackAttr>())\n      FuncAttrs.removeAttribute(\"split-stack\");\n\n    // Add NonLazyBind attribute to function declarations when -fno-plt\n    // is used.\n    // FIXME: what if we just haven't processed the function definition\n    // yet, or if it's an external definition like C99 inline?\n    if (CodeGenOpts.NoPLT) {\n      if (auto *Fn = dyn_cast<FunctionDecl>(TargetDecl)) {\n        if (!Fn->isDefined() && !AttrOnCallSite) {\n          FuncAttrs.addAttribute(llvm::Attribute::NonLazyBind);\n        }\n      }\n    }\n  }\n\n  // Add \"sample-profile-suffix-elision-policy\" attribute for internal linkage\n  // functions with -funique-internal-linkage-names.\n  if (TargetDecl && CodeGenOpts.UniqueInternalLinkageNames) {\n    if (auto *Fn = dyn_cast<FunctionDecl>(TargetDecl)) {\n      if (this->getFunctionLinkage(Fn) == llvm::GlobalValue::InternalLinkage)\n        FuncAttrs.addAttribute(\"sample-profile-suffix-elision-policy\",\n                               \"selected\");\n    }\n  }\n\n  // Collect non-call-site function IR attributes from declaration-specific\n  // information.\n  if (!AttrOnCallSite) {\n    if (TargetDecl && TargetDecl->hasAttr<CmseNSEntryAttr>())\n      FuncAttrs.addAttribute(\"cmse_nonsecure_entry\");\n\n    // Whether tail calls are enabled.\n    auto shouldDisableTailCalls = [&] {\n      // Should this be honored in getDefaultFunctionAttributes?\n      if (CodeGenOpts.DisableTailCalls)\n        return true;\n\n      if (!TargetDecl)\n        return false;\n\n      if (TargetDecl->hasAttr<DisableTailCallsAttr>() ||\n          TargetDecl->hasAttr<AnyX86InterruptAttr>())\n        return true;\n\n      if (CodeGenOpts.NoEscapingBlockTailCalls) {\n        if (const auto *BD = dyn_cast<BlockDecl>(TargetDecl))\n          if (!BD->doesNotEscape())\n            return true;\n      }\n\n      return false;\n    };\n    if (shouldDisableTailCalls())\n      FuncAttrs.addAttribute(\"disable-tail-calls\", \"true\");\n\n    // CPU/feature overrides.  addDefaultFunctionDefinitionAttributes\n    // handles these separately to set them based on the global defaults.\n    GetCPUAndFeaturesAttributes(CalleeInfo.getCalleeDecl(), FuncAttrs);\n  }\n\n  // Collect attributes from arguments and return values.\n  ClangToLLVMArgMapping IRFunctionArgs(getContext(), FI);\n\n  QualType RetTy = FI.getReturnType();\n  const ABIArgInfo &RetAI = FI.getReturnInfo();\n  const llvm::DataLayout &DL = getDataLayout();\n\n  // C++ explicitly makes returning undefined values UB. C's rule only applies\n  // to used values, so we never mark them noundef for now.\n  bool HasStrictReturn = getLangOpts().CPlusPlus;\n  if (TargetDecl) {\n    if (const FunctionDecl *FDecl = dyn_cast<FunctionDecl>(TargetDecl))\n      HasStrictReturn &= !FDecl->isExternC();\n    else if (const VarDecl *VDecl = dyn_cast<VarDecl>(TargetDecl))\n      // Function pointer\n      HasStrictReturn &= !VDecl->isExternC();\n  }\n\n  // We don't want to be too aggressive with the return checking, unless\n  // it's explicit in the code opts or we're using an appropriate sanitizer.\n  // Try to respect what the programmer intended.\n  HasStrictReturn &= getCodeGenOpts().StrictReturn ||\n                     !MayDropFunctionReturn(getContext(), RetTy) ||\n                     getLangOpts().Sanitize.has(SanitizerKind::Memory) ||\n                     getLangOpts().Sanitize.has(SanitizerKind::Return);\n\n  // Determine if the return type could be partially undef\n  if (CodeGenOpts.EnableNoundefAttrs && HasStrictReturn) {\n    if (!RetTy->isVoidType() && RetAI.getKind() != ABIArgInfo::Indirect &&\n        DetermineNoUndef(RetTy, getTypes(), DL, RetAI))\n      RetAttrs.addAttribute(llvm::Attribute::NoUndef);\n  }\n\n  switch (RetAI.getKind()) {\n  case ABIArgInfo::Extend:\n    if (RetAI.isSignExt())\n      RetAttrs.addAttribute(llvm::Attribute::SExt);\n    else\n      RetAttrs.addAttribute(llvm::Attribute::ZExt);\n    LLVM_FALLTHROUGH;\n  case ABIArgInfo::Direct:\n    if (RetAI.getInReg())\n      RetAttrs.addAttribute(llvm::Attribute::InReg);\n    break;\n  case ABIArgInfo::Ignore:\n    break;\n\n  case ABIArgInfo::InAlloca:\n  case ABIArgInfo::Indirect: {\n    // inalloca and sret disable readnone and readonly\n    FuncAttrs.removeAttribute(llvm::Attribute::ReadOnly)\n      .removeAttribute(llvm::Attribute::ReadNone);\n    break;\n  }\n\n  case ABIArgInfo::CoerceAndExpand:\n    break;\n\n  case ABIArgInfo::Expand:\n  case ABIArgInfo::IndirectAliased:\n    llvm_unreachable(\"Invalid ABI kind for return argument\");\n  }\n\n  if (const auto *RefTy = RetTy->getAs<ReferenceType>()) {\n    QualType PTy = RefTy->getPointeeType();\n    if (!PTy->isIncompleteType() && PTy->isConstantSizeType())\n      RetAttrs.addDereferenceableAttr(\n          getMinimumObjectSize(PTy).getQuantity());\n    if (getContext().getTargetAddressSpace(PTy) == 0 &&\n        !CodeGenOpts.NullPointerIsValid)\n      RetAttrs.addAttribute(llvm::Attribute::NonNull);\n    if (PTy->isObjectType()) {\n      llvm::Align Alignment =\n          getNaturalPointeeTypeAlignment(RetTy).getAsAlign();\n      RetAttrs.addAlignmentAttr(Alignment);\n    }\n  }\n\n  bool hasUsedSRet = false;\n  SmallVector<llvm::AttributeSet, 4> ArgAttrs(IRFunctionArgs.totalIRArgs());\n\n  // Attach attributes to sret.\n  if (IRFunctionArgs.hasSRetArg()) {\n    llvm::AttrBuilder SRETAttrs;\n    SRETAttrs.addStructRetAttr(getTypes().ConvertTypeForMem(RetTy));\n    hasUsedSRet = true;\n    if (RetAI.getInReg())\n      SRETAttrs.addAttribute(llvm::Attribute::InReg);\n    SRETAttrs.addAlignmentAttr(RetAI.getIndirectAlign().getQuantity());\n    ArgAttrs[IRFunctionArgs.getSRetArgNo()] =\n        llvm::AttributeSet::get(getLLVMContext(), SRETAttrs);\n  }\n\n  // Attach attributes to inalloca argument.\n  if (IRFunctionArgs.hasInallocaArg()) {\n    llvm::AttrBuilder Attrs;\n    Attrs.addAttribute(llvm::Attribute::InAlloca);\n    ArgAttrs[IRFunctionArgs.getInallocaArgNo()] =\n        llvm::AttributeSet::get(getLLVMContext(), Attrs);\n  }\n\n  // Apply `nonnull` and `dereferencable(N)` to the `this` argument.\n  if (FI.isInstanceMethod() && !IRFunctionArgs.hasInallocaArg() &&\n      !FI.arg_begin()->type->isVoidPointerType()) {\n    auto IRArgs = IRFunctionArgs.getIRArgs(0);\n\n    assert(IRArgs.second == 1 && \"Expected only a single `this` pointer.\");\n\n    llvm::AttrBuilder Attrs;\n\n    if (!CodeGenOpts.NullPointerIsValid &&\n        getContext().getTargetAddressSpace(FI.arg_begin()->type) == 0) {\n      Attrs.addAttribute(llvm::Attribute::NonNull);\n      Attrs.addDereferenceableAttr(\n          getMinimumObjectSize(\n              FI.arg_begin()->type.castAs<PointerType>()->getPointeeType())\n              .getQuantity());\n    } else {\n      // FIXME dereferenceable should be correct here, regardless of\n      // NullPointerIsValid. However, dereferenceable currently does not always\n      // respect NullPointerIsValid and may imply nonnull and break the program.\n      // See https://reviews.llvm.org/D66618 for discussions.\n      Attrs.addDereferenceableOrNullAttr(\n          getMinimumObjectSize(\n              FI.arg_begin()->type.castAs<PointerType>()->getPointeeType())\n              .getQuantity());\n    }\n\n    ArgAttrs[IRArgs.first] = llvm::AttributeSet::get(getLLVMContext(), Attrs);\n  }\n\n  unsigned ArgNo = 0;\n  for (CGFunctionInfo::const_arg_iterator I = FI.arg_begin(),\n                                          E = FI.arg_end();\n       I != E; ++I, ++ArgNo) {\n    QualType ParamType = I->type;\n    const ABIArgInfo &AI = I->info;\n    llvm::AttrBuilder Attrs;\n\n    // Add attribute for padding argument, if necessary.\n    if (IRFunctionArgs.hasPaddingArg(ArgNo)) {\n      if (AI.getPaddingInReg()) {\n        ArgAttrs[IRFunctionArgs.getPaddingArgNo(ArgNo)] =\n            llvm::AttributeSet::get(\n                getLLVMContext(),\n                llvm::AttrBuilder().addAttribute(llvm::Attribute::InReg));\n      }\n    }\n\n    // Decide whether the argument we're handling could be partially undef\n    bool ArgNoUndef = DetermineNoUndef(ParamType, getTypes(), DL, AI);\n    if (CodeGenOpts.EnableNoundefAttrs && ArgNoUndef)\n      Attrs.addAttribute(llvm::Attribute::NoUndef);\n\n    // 'restrict' -> 'noalias' is done in EmitFunctionProlog when we\n    // have the corresponding parameter variable.  It doesn't make\n    // sense to do it here because parameters are so messed up.\n    switch (AI.getKind()) {\n    case ABIArgInfo::Extend:\n      if (AI.isSignExt())\n        Attrs.addAttribute(llvm::Attribute::SExt);\n      else\n        Attrs.addAttribute(llvm::Attribute::ZExt);\n      LLVM_FALLTHROUGH;\n    case ABIArgInfo::Direct:\n      if (ArgNo == 0 && FI.isChainCall())\n        Attrs.addAttribute(llvm::Attribute::Nest);\n      else if (AI.getInReg())\n        Attrs.addAttribute(llvm::Attribute::InReg);\n      break;\n\n    case ABIArgInfo::Indirect: {\n      if (AI.getInReg())\n        Attrs.addAttribute(llvm::Attribute::InReg);\n\n      if (AI.getIndirectByVal())\n        Attrs.addByValAttr(getTypes().ConvertTypeForMem(ParamType));\n\n      auto *Decl = ParamType->getAsRecordDecl();\n      if (CodeGenOpts.PassByValueIsNoAlias && Decl &&\n          Decl->getArgPassingRestrictions() == RecordDecl::APK_CanPassInRegs)\n        // When calling the function, the pointer passed in will be the only\n        // reference to the underlying object. Mark it accordingly.\n        Attrs.addAttribute(llvm::Attribute::NoAlias);\n\n      // TODO: We could add the byref attribute if not byval, but it would\n      // require updating many testcases.\n\n      CharUnits Align = AI.getIndirectAlign();\n\n      // In a byval argument, it is important that the required\n      // alignment of the type is honored, as LLVM might be creating a\n      // *new* stack object, and needs to know what alignment to give\n      // it. (Sometimes it can deduce a sensible alignment on its own,\n      // but not if clang decides it must emit a packed struct, or the\n      // user specifies increased alignment requirements.)\n      //\n      // This is different from indirect *not* byval, where the object\n      // exists already, and the align attribute is purely\n      // informative.\n      assert(!Align.isZero());\n\n      // For now, only add this when we have a byval argument.\n      // TODO: be less lazy about updating test cases.\n      if (AI.getIndirectByVal())\n        Attrs.addAlignmentAttr(Align.getQuantity());\n\n      // byval disables readnone and readonly.\n      FuncAttrs.removeAttribute(llvm::Attribute::ReadOnly)\n        .removeAttribute(llvm::Attribute::ReadNone);\n\n      break;\n    }\n    case ABIArgInfo::IndirectAliased: {\n      CharUnits Align = AI.getIndirectAlign();\n      Attrs.addByRefAttr(getTypes().ConvertTypeForMem(ParamType));\n      Attrs.addAlignmentAttr(Align.getQuantity());\n      break;\n    }\n    case ABIArgInfo::Ignore:\n    case ABIArgInfo::Expand:\n    case ABIArgInfo::CoerceAndExpand:\n      break;\n\n    case ABIArgInfo::InAlloca:\n      // inalloca disables readnone and readonly.\n      FuncAttrs.removeAttribute(llvm::Attribute::ReadOnly)\n          .removeAttribute(llvm::Attribute::ReadNone);\n      continue;\n    }\n\n    if (const auto *RefTy = ParamType->getAs<ReferenceType>()) {\n      QualType PTy = RefTy->getPointeeType();\n      if (!PTy->isIncompleteType() && PTy->isConstantSizeType())\n        Attrs.addDereferenceableAttr(\n            getMinimumObjectSize(PTy).getQuantity());\n      if (getContext().getTargetAddressSpace(PTy) == 0 &&\n          !CodeGenOpts.NullPointerIsValid)\n        Attrs.addAttribute(llvm::Attribute::NonNull);\n      if (PTy->isObjectType()) {\n        llvm::Align Alignment =\n            getNaturalPointeeTypeAlignment(ParamType).getAsAlign();\n        Attrs.addAlignmentAttr(Alignment);\n      }\n    }\n\n    switch (FI.getExtParameterInfo(ArgNo).getABI()) {\n    case ParameterABI::Ordinary:\n      break;\n\n    case ParameterABI::SwiftIndirectResult: {\n      // Add 'sret' if we haven't already used it for something, but\n      // only if the result is void.\n      if (!hasUsedSRet && RetTy->isVoidType()) {\n        Attrs.addStructRetAttr(getTypes().ConvertTypeForMem(ParamType));\n        hasUsedSRet = true;\n      }\n\n      // Add 'noalias' in either case.\n      Attrs.addAttribute(llvm::Attribute::NoAlias);\n\n      // Add 'dereferenceable' and 'alignment'.\n      auto PTy = ParamType->getPointeeType();\n      if (!PTy->isIncompleteType() && PTy->isConstantSizeType()) {\n        auto info = getContext().getTypeInfoInChars(PTy);\n        Attrs.addDereferenceableAttr(info.Width.getQuantity());\n        Attrs.addAlignmentAttr(info.Align.getAsAlign());\n      }\n      break;\n    }\n\n    case ParameterABI::SwiftErrorResult:\n      Attrs.addAttribute(llvm::Attribute::SwiftError);\n      break;\n\n    case ParameterABI::SwiftContext:\n      Attrs.addAttribute(llvm::Attribute::SwiftSelf);\n      break;\n    }\n\n    if (FI.getExtParameterInfo(ArgNo).isNoEscape())\n      Attrs.addAttribute(llvm::Attribute::NoCapture);\n\n    if (Attrs.hasAttributes()) {\n      unsigned FirstIRArg, NumIRArgs;\n      std::tie(FirstIRArg, NumIRArgs) = IRFunctionArgs.getIRArgs(ArgNo);\n      for (unsigned i = 0; i < NumIRArgs; i++)\n        ArgAttrs[FirstIRArg + i] =\n            llvm::AttributeSet::get(getLLVMContext(), Attrs);\n    }\n  }\n  assert(ArgNo == FI.arg_size());\n\n  AttrList = llvm::AttributeList::get(\n      getLLVMContext(), llvm::AttributeSet::get(getLLVMContext(), FuncAttrs),\n      llvm::AttributeSet::get(getLLVMContext(), RetAttrs), ArgAttrs);\n}\n\n/// An argument came in as a promoted argument; demote it back to its\n/// declared type.\nstatic llvm::Value *emitArgumentDemotion(CodeGenFunction &CGF,\n                                         const VarDecl *var,\n                                         llvm::Value *value) {\n  llvm::Type *varType = CGF.ConvertType(var->getType());\n\n  // This can happen with promotions that actually don't change the\n  // underlying type, like the enum promotions.\n  if (value->getType() == varType) return value;\n\n  assert((varType->isIntegerTy() || varType->isFloatingPointTy())\n         && \"unexpected promotion type\");\n\n  if (isa<llvm::IntegerType>(varType))\n    return CGF.Builder.CreateTrunc(value, varType, \"arg.unpromote\");\n\n  return CGF.Builder.CreateFPCast(value, varType, \"arg.unpromote\");\n}\n\n/// Returns the attribute (either parameter attribute, or function\n/// attribute), which declares argument ArgNo to be non-null.\nstatic const NonNullAttr *getNonNullAttr(const Decl *FD, const ParmVarDecl *PVD,\n                                         QualType ArgType, unsigned ArgNo) {\n  // FIXME: __attribute__((nonnull)) can also be applied to:\n  //   - references to pointers, where the pointee is known to be\n  //     nonnull (apparently a Clang extension)\n  //   - transparent unions containing pointers\n  // In the former case, LLVM IR cannot represent the constraint. In\n  // the latter case, we have no guarantee that the transparent union\n  // is in fact passed as a pointer.\n  if (!ArgType->isAnyPointerType() && !ArgType->isBlockPointerType())\n    return nullptr;\n  // First, check attribute on parameter itself.\n  if (PVD) {\n    if (auto ParmNNAttr = PVD->getAttr<NonNullAttr>())\n      return ParmNNAttr;\n  }\n  // Check function attributes.\n  if (!FD)\n    return nullptr;\n  for (const auto *NNAttr : FD->specific_attrs<NonNullAttr>()) {\n    if (NNAttr->isNonNull(ArgNo))\n      return NNAttr;\n  }\n  return nullptr;\n}\n\nnamespace {\n  struct CopyBackSwiftError final : EHScopeStack::Cleanup {\n    Address Temp;\n    Address Arg;\n    CopyBackSwiftError(Address temp, Address arg) : Temp(temp), Arg(arg) {}\n    void Emit(CodeGenFunction &CGF, Flags flags) override {\n      llvm::Value *errorValue = CGF.Builder.CreateLoad(Temp);\n      CGF.Builder.CreateStore(errorValue, Arg);\n    }\n  };\n}\n\nvoid CodeGenFunction::EmitFunctionProlog(const CGFunctionInfo &FI,\n                                         llvm::Function *Fn,\n                                         const FunctionArgList &Args) {\n  if (CurCodeDecl && CurCodeDecl->hasAttr<NakedAttr>())\n    // Naked functions don't have prologues.\n    return;\n\n  // If this is an implicit-return-zero function, go ahead and\n  // initialize the return value.  TODO: it might be nice to have\n  // a more general mechanism for this that didn't require synthesized\n  // return statements.\n  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(CurCodeDecl)) {\n    if (FD->hasImplicitReturnZero()) {\n      QualType RetTy = FD->getReturnType().getUnqualifiedType();\n      llvm::Type* LLVMTy = CGM.getTypes().ConvertType(RetTy);\n      llvm::Constant* Zero = llvm::Constant::getNullValue(LLVMTy);\n      Builder.CreateStore(Zero, ReturnValue);\n    }\n  }\n\n  // FIXME: We no longer need the types from FunctionArgList; lift up and\n  // simplify.\n\n  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), FI);\n  assert(Fn->arg_size() == IRFunctionArgs.totalIRArgs());\n\n  // If we're using inalloca, all the memory arguments are GEPs off of the last\n  // parameter, which is a pointer to the complete memory area.\n  Address ArgStruct = Address::invalid();\n  if (IRFunctionArgs.hasInallocaArg()) {\n    ArgStruct = Address(Fn->getArg(IRFunctionArgs.getInallocaArgNo()),\n                        FI.getArgStructAlignment());\n\n    assert(ArgStruct.getType() == FI.getArgStruct()->getPointerTo());\n  }\n\n  // Name the struct return parameter.\n  if (IRFunctionArgs.hasSRetArg()) {\n    auto AI = Fn->getArg(IRFunctionArgs.getSRetArgNo());\n    AI->setName(\"agg.result\");\n    AI->addAttr(llvm::Attribute::NoAlias);\n  }\n\n  // Track if we received the parameter as a pointer (indirect, byval, or\n  // inalloca).  If already have a pointer, EmitParmDecl doesn't need to copy it\n  // into a local alloca for us.\n  SmallVector<ParamValue, 16> ArgVals;\n  ArgVals.reserve(Args.size());\n\n  // Create a pointer value for every parameter declaration.  This usually\n  // entails copying one or more LLVM IR arguments into an alloca.  Don't push\n  // any cleanups or do anything that might unwind.  We do that separately, so\n  // we can push the cleanups in the correct order for the ABI.\n  assert(FI.arg_size() == Args.size() &&\n         \"Mismatch between function signature & arguments.\");\n  unsigned ArgNo = 0;\n  CGFunctionInfo::const_arg_iterator info_it = FI.arg_begin();\n  for (FunctionArgList::const_iterator i = Args.begin(), e = Args.end();\n       i != e; ++i, ++info_it, ++ArgNo) {\n    const VarDecl *Arg = *i;\n    const ABIArgInfo &ArgI = info_it->info;\n\n    bool isPromoted =\n      isa<ParmVarDecl>(Arg) && cast<ParmVarDecl>(Arg)->isKNRPromoted();\n    // We are converting from ABIArgInfo type to VarDecl type directly, unless\n    // the parameter is promoted. In this case we convert to\n    // CGFunctionInfo::ArgInfo type with subsequent argument demotion.\n    QualType Ty = isPromoted ? info_it->type : Arg->getType();\n    assert(hasScalarEvaluationKind(Ty) ==\n           hasScalarEvaluationKind(Arg->getType()));\n\n    unsigned FirstIRArg, NumIRArgs;\n    std::tie(FirstIRArg, NumIRArgs) = IRFunctionArgs.getIRArgs(ArgNo);\n\n    switch (ArgI.getKind()) {\n    case ABIArgInfo::InAlloca: {\n      assert(NumIRArgs == 0);\n      auto FieldIndex = ArgI.getInAllocaFieldIndex();\n      Address V =\n          Builder.CreateStructGEP(ArgStruct, FieldIndex, Arg->getName());\n      if (ArgI.getInAllocaIndirect())\n        V = Address(Builder.CreateLoad(V),\n                    getContext().getTypeAlignInChars(Ty));\n      ArgVals.push_back(ParamValue::forIndirect(V));\n      break;\n    }\n\n    case ABIArgInfo::Indirect:\n    case ABIArgInfo::IndirectAliased: {\n      assert(NumIRArgs == 1);\n      Address ParamAddr =\n          Address(Fn->getArg(FirstIRArg), ArgI.getIndirectAlign());\n\n      if (!hasScalarEvaluationKind(Ty)) {\n        // Aggregates and complex variables are accessed by reference. All we\n        // need to do is realign the value, if requested. Also, if the address\n        // may be aliased, copy it to ensure that the parameter variable is\n        // mutable and has a unique adress, as C requires.\n        Address V = ParamAddr;\n        if (ArgI.getIndirectRealign() || ArgI.isIndirectAliased()) {\n          Address AlignedTemp = CreateMemTemp(Ty, \"coerce\");\n\n          // Copy from the incoming argument pointer to the temporary with the\n          // appropriate alignment.\n          //\n          // FIXME: We should have a common utility for generating an aggregate\n          // copy.\n          CharUnits Size = getContext().getTypeSizeInChars(Ty);\n          Builder.CreateMemCpy(\n              AlignedTemp.getPointer(), AlignedTemp.getAlignment().getAsAlign(),\n              ParamAddr.getPointer(), ParamAddr.getAlignment().getAsAlign(),\n              llvm::ConstantInt::get(IntPtrTy, Size.getQuantity()));\n          V = AlignedTemp;\n        }\n        ArgVals.push_back(ParamValue::forIndirect(V));\n      } else {\n        // Load scalar value from indirect argument.\n        llvm::Value *V =\n            EmitLoadOfScalar(ParamAddr, false, Ty, Arg->getBeginLoc());\n\n        if (isPromoted)\n          V = emitArgumentDemotion(*this, Arg, V);\n        ArgVals.push_back(ParamValue::forDirect(V));\n      }\n      break;\n    }\n\n    case ABIArgInfo::Extend:\n    case ABIArgInfo::Direct: {\n      auto AI = Fn->getArg(FirstIRArg);\n      llvm::Type *LTy = ConvertType(Arg->getType());\n\n      // Prepare parameter attributes. So far, only attributes for pointer\n      // parameters are prepared. See\n      // http://llvm.org/docs/LangRef.html#paramattrs.\n      if (ArgI.getDirectOffset() == 0 && LTy->isPointerTy() &&\n          ArgI.getCoerceToType()->isPointerTy()) {\n        assert(NumIRArgs == 1);\n\n        if (const ParmVarDecl *PVD = dyn_cast<ParmVarDecl>(Arg)) {\n          // Set `nonnull` attribute if any.\n          if (getNonNullAttr(CurCodeDecl, PVD, PVD->getType(),\n                             PVD->getFunctionScopeIndex()) &&\n              !CGM.getCodeGenOpts().NullPointerIsValid)\n            AI->addAttr(llvm::Attribute::NonNull);\n\n          QualType OTy = PVD->getOriginalType();\n          if (const auto *ArrTy =\n              getContext().getAsConstantArrayType(OTy)) {\n            // A C99 array parameter declaration with the static keyword also\n            // indicates dereferenceability, and if the size is constant we can\n            // use the dereferenceable attribute (which requires the size in\n            // bytes).\n            if (ArrTy->getSizeModifier() == ArrayType::Static) {\n              QualType ETy = ArrTy->getElementType();\n              llvm::Align Alignment =\n                  CGM.getNaturalTypeAlignment(ETy).getAsAlign();\n              AI->addAttrs(llvm::AttrBuilder().addAlignmentAttr(Alignment));\n              uint64_t ArrSize = ArrTy->getSize().getZExtValue();\n              if (!ETy->isIncompleteType() && ETy->isConstantSizeType() &&\n                  ArrSize) {\n                llvm::AttrBuilder Attrs;\n                Attrs.addDereferenceableAttr(\n                    getContext().getTypeSizeInChars(ETy).getQuantity() *\n                    ArrSize);\n                AI->addAttrs(Attrs);\n              } else if (getContext().getTargetInfo().getNullPointerValue(\n                             ETy.getAddressSpace()) == 0 &&\n                         !CGM.getCodeGenOpts().NullPointerIsValid) {\n                AI->addAttr(llvm::Attribute::NonNull);\n              }\n            }\n          } else if (const auto *ArrTy =\n                     getContext().getAsVariableArrayType(OTy)) {\n            // For C99 VLAs with the static keyword, we don't know the size so\n            // we can't use the dereferenceable attribute, but in addrspace(0)\n            // we know that it must be nonnull.\n            if (ArrTy->getSizeModifier() == VariableArrayType::Static) {\n              QualType ETy = ArrTy->getElementType();\n              llvm::Align Alignment =\n                  CGM.getNaturalTypeAlignment(ETy).getAsAlign();\n              AI->addAttrs(llvm::AttrBuilder().addAlignmentAttr(Alignment));\n              if (!getContext().getTargetAddressSpace(ETy) &&\n                  !CGM.getCodeGenOpts().NullPointerIsValid)\n                AI->addAttr(llvm::Attribute::NonNull);\n            }\n          }\n\n          // Set `align` attribute if any.\n          const auto *AVAttr = PVD->getAttr<AlignValueAttr>();\n          if (!AVAttr)\n            if (const auto *TOTy = dyn_cast<TypedefType>(OTy))\n              AVAttr = TOTy->getDecl()->getAttr<AlignValueAttr>();\n          if (AVAttr && !SanOpts.has(SanitizerKind::Alignment)) {\n            // If alignment-assumption sanitizer is enabled, we do *not* add\n            // alignment attribute here, but emit normal alignment assumption,\n            // so the UBSAN check could function.\n            llvm::ConstantInt *AlignmentCI =\n                cast<llvm::ConstantInt>(EmitScalarExpr(AVAttr->getAlignment()));\n            unsigned AlignmentInt =\n                AlignmentCI->getLimitedValue(llvm::Value::MaximumAlignment);\n            if (AI->getParamAlign().valueOrOne() < AlignmentInt) {\n              AI->removeAttr(llvm::Attribute::AttrKind::Alignment);\n              AI->addAttrs(llvm::AttrBuilder().addAlignmentAttr(\n                  llvm::Align(AlignmentInt)));\n            }\n          }\n        }\n\n        // Set 'noalias' if an argument type has the `restrict` qualifier.\n        if (Arg->getType().isRestrictQualified())\n          AI->addAttr(llvm::Attribute::NoAlias);\n      }\n\n      // Prepare the argument value. If we have the trivial case, handle it\n      // with no muss and fuss.\n      if (!isa<llvm::StructType>(ArgI.getCoerceToType()) &&\n          ArgI.getCoerceToType() == ConvertType(Ty) &&\n          ArgI.getDirectOffset() == 0) {\n        assert(NumIRArgs == 1);\n\n        // LLVM expects swifterror parameters to be used in very restricted\n        // ways.  Copy the value into a less-restricted temporary.\n        llvm::Value *V = AI;\n        if (FI.getExtParameterInfo(ArgNo).getABI()\n              == ParameterABI::SwiftErrorResult) {\n          QualType pointeeTy = Ty->getPointeeType();\n          assert(pointeeTy->isPointerType());\n          Address temp =\n            CreateMemTemp(pointeeTy, getPointerAlign(), \"swifterror.temp\");\n          Address arg = Address(V, getContext().getTypeAlignInChars(pointeeTy));\n          llvm::Value *incomingErrorValue = Builder.CreateLoad(arg);\n          Builder.CreateStore(incomingErrorValue, temp);\n          V = temp.getPointer();\n\n          // Push a cleanup to copy the value back at the end of the function.\n          // The convention does not guarantee that the value will be written\n          // back if the function exits with an unwind exception.\n          EHStack.pushCleanup<CopyBackSwiftError>(NormalCleanup, temp, arg);\n        }\n\n        // Ensure the argument is the correct type.\n        if (V->getType() != ArgI.getCoerceToType())\n          V = Builder.CreateBitCast(V, ArgI.getCoerceToType());\n\n        if (isPromoted)\n          V = emitArgumentDemotion(*this, Arg, V);\n\n        // Because of merging of function types from multiple decls it is\n        // possible for the type of an argument to not match the corresponding\n        // type in the function type. Since we are codegening the callee\n        // in here, add a cast to the argument type.\n        llvm::Type *LTy = ConvertType(Arg->getType());\n        if (V->getType() != LTy)\n          V = Builder.CreateBitCast(V, LTy);\n\n        ArgVals.push_back(ParamValue::forDirect(V));\n        break;\n      }\n\n      // VLST arguments are coerced to VLATs at the function boundary for\n      // ABI consistency. If this is a VLST that was coerced to\n      // a VLAT at the function boundary and the types match up, use\n      // llvm.experimental.vector.extract to convert back to the original\n      // VLST.\n      if (auto *VecTyTo = dyn_cast<llvm::FixedVectorType>(ConvertType(Ty))) {\n        auto *Coerced = Fn->getArg(FirstIRArg);\n        if (auto *VecTyFrom =\n                dyn_cast<llvm::ScalableVectorType>(Coerced->getType())) {\n          if (VecTyFrom->getElementType() == VecTyTo->getElementType()) {\n            llvm::Value *Zero = llvm::Constant::getNullValue(CGM.Int64Ty);\n\n            assert(NumIRArgs == 1);\n            Coerced->setName(Arg->getName() + \".coerce\");\n            ArgVals.push_back(ParamValue::forDirect(Builder.CreateExtractVector(\n                VecTyTo, Coerced, Zero, \"castFixedSve\")));\n            break;\n          }\n        }\n      }\n\n      Address Alloca = CreateMemTemp(Ty, getContext().getDeclAlign(Arg),\n                                     Arg->getName());\n\n      // Pointer to store into.\n      Address Ptr = emitAddressAtOffset(*this, Alloca, ArgI);\n\n      // Fast-isel and the optimizer generally like scalar values better than\n      // FCAs, so we flatten them if this is safe to do for this argument.\n      llvm::StructType *STy = dyn_cast<llvm::StructType>(ArgI.getCoerceToType());\n      if (ArgI.isDirect() && ArgI.getCanBeFlattened() && STy &&\n          STy->getNumElements() > 1) {\n        uint64_t SrcSize = CGM.getDataLayout().getTypeAllocSize(STy);\n        llvm::Type *DstTy = Ptr.getElementType();\n        uint64_t DstSize = CGM.getDataLayout().getTypeAllocSize(DstTy);\n\n        Address AddrToStoreInto = Address::invalid();\n        if (SrcSize <= DstSize) {\n          AddrToStoreInto = Builder.CreateElementBitCast(Ptr, STy);\n        } else {\n          AddrToStoreInto =\n            CreateTempAlloca(STy, Alloca.getAlignment(), \"coerce\");\n        }\n\n        assert(STy->getNumElements() == NumIRArgs);\n        for (unsigned i = 0, e = STy->getNumElements(); i != e; ++i) {\n          auto AI = Fn->getArg(FirstIRArg + i);\n          AI->setName(Arg->getName() + \".coerce\" + Twine(i));\n          Address EltPtr = Builder.CreateStructGEP(AddrToStoreInto, i);\n          Builder.CreateStore(AI, EltPtr);\n        }\n\n        if (SrcSize > DstSize) {\n          Builder.CreateMemCpy(Ptr, AddrToStoreInto, DstSize);\n        }\n\n      } else {\n        // Simple case, just do a coerced store of the argument into the alloca.\n        assert(NumIRArgs == 1);\n        auto AI = Fn->getArg(FirstIRArg);\n        AI->setName(Arg->getName() + \".coerce\");\n        CreateCoercedStore(AI, Ptr, /*DstIsVolatile=*/false, *this);\n      }\n\n      // Match to what EmitParmDecl is expecting for this type.\n      if (CodeGenFunction::hasScalarEvaluationKind(Ty)) {\n        llvm::Value *V =\n            EmitLoadOfScalar(Alloca, false, Ty, Arg->getBeginLoc());\n        if (isPromoted)\n          V = emitArgumentDemotion(*this, Arg, V);\n        ArgVals.push_back(ParamValue::forDirect(V));\n      } else {\n        ArgVals.push_back(ParamValue::forIndirect(Alloca));\n      }\n      break;\n    }\n\n    case ABIArgInfo::CoerceAndExpand: {\n      // Reconstruct into a temporary.\n      Address alloca = CreateMemTemp(Ty, getContext().getDeclAlign(Arg));\n      ArgVals.push_back(ParamValue::forIndirect(alloca));\n\n      auto coercionType = ArgI.getCoerceAndExpandType();\n      alloca = Builder.CreateElementBitCast(alloca, coercionType);\n\n      unsigned argIndex = FirstIRArg;\n      for (unsigned i = 0, e = coercionType->getNumElements(); i != e; ++i) {\n        llvm::Type *eltType = coercionType->getElementType(i);\n        if (ABIArgInfo::isPaddingForCoerceAndExpand(eltType))\n          continue;\n\n        auto eltAddr = Builder.CreateStructGEP(alloca, i);\n        auto elt = Fn->getArg(argIndex++);\n        Builder.CreateStore(elt, eltAddr);\n      }\n      assert(argIndex == FirstIRArg + NumIRArgs);\n      break;\n    }\n\n    case ABIArgInfo::Expand: {\n      // If this structure was expanded into multiple arguments then\n      // we need to create a temporary and reconstruct it from the\n      // arguments.\n      Address Alloca = CreateMemTemp(Ty, getContext().getDeclAlign(Arg));\n      LValue LV = MakeAddrLValue(Alloca, Ty);\n      ArgVals.push_back(ParamValue::forIndirect(Alloca));\n\n      auto FnArgIter = Fn->arg_begin() + FirstIRArg;\n      ExpandTypeFromArgs(Ty, LV, FnArgIter);\n      assert(FnArgIter == Fn->arg_begin() + FirstIRArg + NumIRArgs);\n      for (unsigned i = 0, e = NumIRArgs; i != e; ++i) {\n        auto AI = Fn->getArg(FirstIRArg + i);\n        AI->setName(Arg->getName() + \".\" + Twine(i));\n      }\n      break;\n    }\n\n    case ABIArgInfo::Ignore:\n      assert(NumIRArgs == 0);\n      // Initialize the local variable appropriately.\n      if (!hasScalarEvaluationKind(Ty)) {\n        ArgVals.push_back(ParamValue::forIndirect(CreateMemTemp(Ty)));\n      } else {\n        llvm::Value *U = llvm::UndefValue::get(ConvertType(Arg->getType()));\n        ArgVals.push_back(ParamValue::forDirect(U));\n      }\n      break;\n    }\n  }\n\n  if (getTarget().getCXXABI().areArgsDestroyedLeftToRightInCallee()) {\n    for (int I = Args.size() - 1; I >= 0; --I)\n      EmitParmDecl(*Args[I], ArgVals[I], I + 1);\n  } else {\n    for (unsigned I = 0, E = Args.size(); I != E; ++I)\n      EmitParmDecl(*Args[I], ArgVals[I], I + 1);\n  }\n}\n\nstatic void eraseUnusedBitCasts(llvm::Instruction *insn) {\n  while (insn->use_empty()) {\n    llvm::BitCastInst *bitcast = dyn_cast<llvm::BitCastInst>(insn);\n    if (!bitcast) return;\n\n    // This is \"safe\" because we would have used a ConstantExpr otherwise.\n    insn = cast<llvm::Instruction>(bitcast->getOperand(0));\n    bitcast->eraseFromParent();\n  }\n}\n\n/// Try to emit a fused autorelease of a return result.\nstatic llvm::Value *tryEmitFusedAutoreleaseOfResult(CodeGenFunction &CGF,\n                                                    llvm::Value *result) {\n  // We must be immediately followed the cast.\n  llvm::BasicBlock *BB = CGF.Builder.GetInsertBlock();\n  if (BB->empty()) return nullptr;\n  if (&BB->back() != result) return nullptr;\n\n  llvm::Type *resultType = result->getType();\n\n  // result is in a BasicBlock and is therefore an Instruction.\n  llvm::Instruction *generator = cast<llvm::Instruction>(result);\n\n  SmallVector<llvm::Instruction *, 4> InstsToKill;\n\n  // Look for:\n  //  %generator = bitcast %type1* %generator2 to %type2*\n  while (llvm::BitCastInst *bitcast = dyn_cast<llvm::BitCastInst>(generator)) {\n    // We would have emitted this as a constant if the operand weren't\n    // an Instruction.\n    generator = cast<llvm::Instruction>(bitcast->getOperand(0));\n\n    // Require the generator to be immediately followed by the cast.\n    if (generator->getNextNode() != bitcast)\n      return nullptr;\n\n    InstsToKill.push_back(bitcast);\n  }\n\n  // Look for:\n  //   %generator = call i8* @objc_retain(i8* %originalResult)\n  // or\n  //   %generator = call i8* @objc_retainAutoreleasedReturnValue(i8* %originalResult)\n  llvm::CallInst *call = dyn_cast<llvm::CallInst>(generator);\n  if (!call) return nullptr;\n\n  bool doRetainAutorelease;\n\n  if (call->getCalledOperand() == CGF.CGM.getObjCEntrypoints().objc_retain) {\n    doRetainAutorelease = true;\n  } else if (call->getCalledOperand() ==\n             CGF.CGM.getObjCEntrypoints().objc_retainAutoreleasedReturnValue) {\n    doRetainAutorelease = false;\n\n    // If we emitted an assembly marker for this call (and the\n    // ARCEntrypoints field should have been set if so), go looking\n    // for that call.  If we can't find it, we can't do this\n    // optimization.  But it should always be the immediately previous\n    // instruction, unless we needed bitcasts around the call.\n    if (CGF.CGM.getObjCEntrypoints().retainAutoreleasedReturnValueMarker) {\n      llvm::Instruction *prev = call->getPrevNode();\n      assert(prev);\n      if (isa<llvm::BitCastInst>(prev)) {\n        prev = prev->getPrevNode();\n        assert(prev);\n      }\n      assert(isa<llvm::CallInst>(prev));\n      assert(cast<llvm::CallInst>(prev)->getCalledOperand() ==\n             CGF.CGM.getObjCEntrypoints().retainAutoreleasedReturnValueMarker);\n      InstsToKill.push_back(prev);\n    }\n  } else {\n    return nullptr;\n  }\n\n  result = call->getArgOperand(0);\n  InstsToKill.push_back(call);\n\n  // Keep killing bitcasts, for sanity.  Note that we no longer care\n  // about precise ordering as long as there's exactly one use.\n  while (llvm::BitCastInst *bitcast = dyn_cast<llvm::BitCastInst>(result)) {\n    if (!bitcast->hasOneUse()) break;\n    InstsToKill.push_back(bitcast);\n    result = bitcast->getOperand(0);\n  }\n\n  // Delete all the unnecessary instructions, from latest to earliest.\n  for (auto *I : InstsToKill)\n    I->eraseFromParent();\n\n  // Do the fused retain/autorelease if we were asked to.\n  if (doRetainAutorelease)\n    result = CGF.EmitARCRetainAutoreleaseReturnValue(result);\n\n  // Cast back to the result type.\n  return CGF.Builder.CreateBitCast(result, resultType);\n}\n\n/// If this is a +1 of the value of an immutable 'self', remove it.\nstatic llvm::Value *tryRemoveRetainOfSelf(CodeGenFunction &CGF,\n                                          llvm::Value *result) {\n  // This is only applicable to a method with an immutable 'self'.\n  const ObjCMethodDecl *method =\n    dyn_cast_or_null<ObjCMethodDecl>(CGF.CurCodeDecl);\n  if (!method) return nullptr;\n  const VarDecl *self = method->getSelfDecl();\n  if (!self->getType().isConstQualified()) return nullptr;\n\n  // Look for a retain call.\n  llvm::CallInst *retainCall =\n    dyn_cast<llvm::CallInst>(result->stripPointerCasts());\n  if (!retainCall || retainCall->getCalledOperand() !=\n                         CGF.CGM.getObjCEntrypoints().objc_retain)\n    return nullptr;\n\n  // Look for an ordinary load of 'self'.\n  llvm::Value *retainedValue = retainCall->getArgOperand(0);\n  llvm::LoadInst *load =\n    dyn_cast<llvm::LoadInst>(retainedValue->stripPointerCasts());\n  if (!load || load->isAtomic() || load->isVolatile() ||\n      load->getPointerOperand() != CGF.GetAddrOfLocalVar(self).getPointer())\n    return nullptr;\n\n  // Okay!  Burn it all down.  This relies for correctness on the\n  // assumption that the retain is emitted as part of the return and\n  // that thereafter everything is used \"linearly\".\n  llvm::Type *resultType = result->getType();\n  eraseUnusedBitCasts(cast<llvm::Instruction>(result));\n  assert(retainCall->use_empty());\n  retainCall->eraseFromParent();\n  eraseUnusedBitCasts(cast<llvm::Instruction>(retainedValue));\n\n  return CGF.Builder.CreateBitCast(load, resultType);\n}\n\n/// Emit an ARC autorelease of the result of a function.\n///\n/// \\return the value to actually return from the function\nstatic llvm::Value *emitAutoreleaseOfResult(CodeGenFunction &CGF,\n                                            llvm::Value *result) {\n  // If we're returning 'self', kill the initial retain.  This is a\n  // heuristic attempt to \"encourage correctness\" in the really unfortunate\n  // case where we have a return of self during a dealloc and we desperately\n  // need to avoid the possible autorelease.\n  if (llvm::Value *self = tryRemoveRetainOfSelf(CGF, result))\n    return self;\n\n  // At -O0, try to emit a fused retain/autorelease.\n  if (CGF.shouldUseFusedARCCalls())\n    if (llvm::Value *fused = tryEmitFusedAutoreleaseOfResult(CGF, result))\n      return fused;\n\n  return CGF.EmitARCAutoreleaseReturnValue(result);\n}\n\n/// Heuristically search for a dominating store to the return-value slot.\nstatic llvm::StoreInst *findDominatingStoreToReturnValue(CodeGenFunction &CGF) {\n  // Check if a User is a store which pointerOperand is the ReturnValue.\n  // We are looking for stores to the ReturnValue, not for stores of the\n  // ReturnValue to some other location.\n  auto GetStoreIfValid = [&CGF](llvm::User *U) -> llvm::StoreInst * {\n    auto *SI = dyn_cast<llvm::StoreInst>(U);\n    if (!SI || SI->getPointerOperand() != CGF.ReturnValue.getPointer())\n      return nullptr;\n    // These aren't actually possible for non-coerced returns, and we\n    // only care about non-coerced returns on this code path.\n    assert(!SI->isAtomic() && !SI->isVolatile());\n    return SI;\n  };\n  // If there are multiple uses of the return-value slot, just check\n  // for something immediately preceding the IP.  Sometimes this can\n  // happen with how we generate implicit-returns; it can also happen\n  // with noreturn cleanups.\n  if (!CGF.ReturnValue.getPointer()->hasOneUse()) {\n    llvm::BasicBlock *IP = CGF.Builder.GetInsertBlock();\n    if (IP->empty()) return nullptr;\n    llvm::Instruction *I = &IP->back();\n\n    // Skip lifetime markers\n    for (llvm::BasicBlock::reverse_iterator II = IP->rbegin(),\n                                            IE = IP->rend();\n         II != IE; ++II) {\n      if (llvm::IntrinsicInst *Intrinsic =\n              dyn_cast<llvm::IntrinsicInst>(&*II)) {\n        if (Intrinsic->getIntrinsicID() == llvm::Intrinsic::lifetime_end) {\n          const llvm::Value *CastAddr = Intrinsic->getArgOperand(1);\n          ++II;\n          if (II == IE)\n            break;\n          if (isa<llvm::BitCastInst>(&*II) && (CastAddr == &*II))\n            continue;\n        }\n      }\n      I = &*II;\n      break;\n    }\n\n    return GetStoreIfValid(I);\n  }\n\n  llvm::StoreInst *store =\n      GetStoreIfValid(CGF.ReturnValue.getPointer()->user_back());\n  if (!store) return nullptr;\n\n  // Now do a first-and-dirty dominance check: just walk up the\n  // single-predecessors chain from the current insertion point.\n  llvm::BasicBlock *StoreBB = store->getParent();\n  llvm::BasicBlock *IP = CGF.Builder.GetInsertBlock();\n  while (IP != StoreBB) {\n    if (!(IP = IP->getSinglePredecessor()))\n      return nullptr;\n  }\n\n  // Okay, the store's basic block dominates the insertion point; we\n  // can do our thing.\n  return store;\n}\n\n// Helper functions for EmitCMSEClearRecord\n\n// Set the bits corresponding to a field having width `BitWidth` and located at\n// offset `BitOffset` (from the least significant bit) within a storage unit of\n// `Bits.size()` bytes. Each element of `Bits` corresponds to one target byte.\n// Use little-endian layout, i.e.`Bits[0]` is the LSB.\nstatic void setBitRange(SmallVectorImpl<uint64_t> &Bits, int BitOffset,\n                        int BitWidth, int CharWidth) {\n  assert(CharWidth <= 64);\n  assert(static_cast<unsigned>(BitWidth) <= Bits.size() * CharWidth);\n\n  int Pos = 0;\n  if (BitOffset >= CharWidth) {\n    Pos += BitOffset / CharWidth;\n    BitOffset = BitOffset % CharWidth;\n  }\n\n  const uint64_t Used = (uint64_t(1) << CharWidth) - 1;\n  if (BitOffset + BitWidth >= CharWidth) {\n    Bits[Pos++] |= (Used << BitOffset) & Used;\n    BitWidth -= CharWidth - BitOffset;\n    BitOffset = 0;\n  }\n\n  while (BitWidth >= CharWidth) {\n    Bits[Pos++] = Used;\n    BitWidth -= CharWidth;\n  }\n\n  if (BitWidth > 0)\n    Bits[Pos++] |= (Used >> (CharWidth - BitWidth)) << BitOffset;\n}\n\n// Set the bits corresponding to a field having width `BitWidth` and located at\n// offset `BitOffset` (from the least significant bit) within a storage unit of\n// `StorageSize` bytes, located at `StorageOffset` in `Bits`. Each element of\n// `Bits` corresponds to one target byte. Use target endian layout.\nstatic void setBitRange(SmallVectorImpl<uint64_t> &Bits, int StorageOffset,\n                        int StorageSize, int BitOffset, int BitWidth,\n                        int CharWidth, bool BigEndian) {\n\n  SmallVector<uint64_t, 8> TmpBits(StorageSize);\n  setBitRange(TmpBits, BitOffset, BitWidth, CharWidth);\n\n  if (BigEndian)\n    std::reverse(TmpBits.begin(), TmpBits.end());\n\n  for (uint64_t V : TmpBits)\n    Bits[StorageOffset++] |= V;\n}\n\nstatic void setUsedBits(CodeGenModule &, QualType, int,\n                        SmallVectorImpl<uint64_t> &);\n\n// Set the bits in `Bits`, which correspond to the value representations of\n// the actual members of the record type `RTy`. Note that this function does\n// not handle base classes, virtual tables, etc, since they cannot happen in\n// CMSE function arguments or return. The bit mask corresponds to the target\n// memory layout, i.e. it's endian dependent.\nstatic void setUsedBits(CodeGenModule &CGM, const RecordType *RTy, int Offset,\n                        SmallVectorImpl<uint64_t> &Bits) {\n  ASTContext &Context = CGM.getContext();\n  int CharWidth = Context.getCharWidth();\n  const RecordDecl *RD = RTy->getDecl()->getDefinition();\n  const ASTRecordLayout &ASTLayout = Context.getASTRecordLayout(RD);\n  const CGRecordLayout &Layout = CGM.getTypes().getCGRecordLayout(RD);\n\n  int Idx = 0;\n  for (auto I = RD->field_begin(), E = RD->field_end(); I != E; ++I, ++Idx) {\n    const FieldDecl *F = *I;\n\n    if (F->isUnnamedBitfield() || F->isZeroLengthBitField(Context) ||\n        F->getType()->isIncompleteArrayType())\n      continue;\n\n    if (F->isBitField()) {\n      const CGBitFieldInfo &BFI = Layout.getBitFieldInfo(F);\n      setBitRange(Bits, Offset + BFI.StorageOffset.getQuantity(),\n                  BFI.StorageSize / CharWidth, BFI.Offset,\n                  BFI.Size, CharWidth,\n                  CGM.getDataLayout().isBigEndian());\n      continue;\n    }\n\n    setUsedBits(CGM, F->getType(),\n                Offset + ASTLayout.getFieldOffset(Idx) / CharWidth, Bits);\n  }\n}\n\n// Set the bits in `Bits`, which correspond to the value representations of\n// the elements of an array type `ATy`.\nstatic void setUsedBits(CodeGenModule &CGM, const ConstantArrayType *ATy,\n                        int Offset, SmallVectorImpl<uint64_t> &Bits) {\n  const ASTContext &Context = CGM.getContext();\n\n  QualType ETy = Context.getBaseElementType(ATy);\n  int Size = Context.getTypeSizeInChars(ETy).getQuantity();\n  SmallVector<uint64_t, 4> TmpBits(Size);\n  setUsedBits(CGM, ETy, 0, TmpBits);\n\n  for (int I = 0, N = Context.getConstantArrayElementCount(ATy); I < N; ++I) {\n    auto Src = TmpBits.begin();\n    auto Dst = Bits.begin() + Offset + I * Size;\n    for (int J = 0; J < Size; ++J)\n      *Dst++ |= *Src++;\n  }\n}\n\n// Set the bits in `Bits`, which correspond to the value representations of\n// the type `QTy`.\nstatic void setUsedBits(CodeGenModule &CGM, QualType QTy, int Offset,\n                        SmallVectorImpl<uint64_t> &Bits) {\n  if (const auto *RTy = QTy->getAs<RecordType>())\n    return setUsedBits(CGM, RTy, Offset, Bits);\n\n  ASTContext &Context = CGM.getContext();\n  if (const auto *ATy = Context.getAsConstantArrayType(QTy))\n    return setUsedBits(CGM, ATy, Offset, Bits);\n\n  int Size = Context.getTypeSizeInChars(QTy).getQuantity();\n  if (Size <= 0)\n    return;\n\n  std::fill_n(Bits.begin() + Offset, Size,\n              (uint64_t(1) << Context.getCharWidth()) - 1);\n}\n\nstatic uint64_t buildMultiCharMask(const SmallVectorImpl<uint64_t> &Bits,\n                                   int Pos, int Size, int CharWidth,\n                                   bool BigEndian) {\n  assert(Size > 0);\n  uint64_t Mask = 0;\n  if (BigEndian) {\n    for (auto P = Bits.begin() + Pos, E = Bits.begin() + Pos + Size; P != E;\n         ++P)\n      Mask = (Mask << CharWidth) | *P;\n  } else {\n    auto P = Bits.begin() + Pos + Size, End = Bits.begin() + Pos;\n    do\n      Mask = (Mask << CharWidth) | *--P;\n    while (P != End);\n  }\n  return Mask;\n}\n\n// Emit code to clear the bits in a record, which aren't a part of any user\n// declared member, when the record is a function return.\nllvm::Value *CodeGenFunction::EmitCMSEClearRecord(llvm::Value *Src,\n                                                  llvm::IntegerType *ITy,\n                                                  QualType QTy) {\n  assert(Src->getType() == ITy);\n  assert(ITy->getScalarSizeInBits() <= 64);\n\n  const llvm::DataLayout &DataLayout = CGM.getDataLayout();\n  int Size = DataLayout.getTypeStoreSize(ITy);\n  SmallVector<uint64_t, 4> Bits(Size);\n  setUsedBits(CGM, QTy->castAs<RecordType>(), 0, Bits);\n\n  int CharWidth = CGM.getContext().getCharWidth();\n  uint64_t Mask =\n      buildMultiCharMask(Bits, 0, Size, CharWidth, DataLayout.isBigEndian());\n\n  return Builder.CreateAnd(Src, Mask, \"cmse.clear\");\n}\n\n// Emit code to clear the bits in a record, which aren't a part of any user\n// declared member, when the record is a function argument.\nllvm::Value *CodeGenFunction::EmitCMSEClearRecord(llvm::Value *Src,\n                                                  llvm::ArrayType *ATy,\n                                                  QualType QTy) {\n  const llvm::DataLayout &DataLayout = CGM.getDataLayout();\n  int Size = DataLayout.getTypeStoreSize(ATy);\n  SmallVector<uint64_t, 16> Bits(Size);\n  setUsedBits(CGM, QTy->castAs<RecordType>(), 0, Bits);\n\n  // Clear each element of the LLVM array.\n  int CharWidth = CGM.getContext().getCharWidth();\n  int CharsPerElt =\n      ATy->getArrayElementType()->getScalarSizeInBits() / CharWidth;\n  int MaskIndex = 0;\n  llvm::Value *R = llvm::UndefValue::get(ATy);\n  for (int I = 0, N = ATy->getArrayNumElements(); I != N; ++I) {\n    uint64_t Mask = buildMultiCharMask(Bits, MaskIndex, CharsPerElt, CharWidth,\n                                       DataLayout.isBigEndian());\n    MaskIndex += CharsPerElt;\n    llvm::Value *T0 = Builder.CreateExtractValue(Src, I);\n    llvm::Value *T1 = Builder.CreateAnd(T0, Mask, \"cmse.clear\");\n    R = Builder.CreateInsertValue(R, T1, I);\n  }\n\n  return R;\n}\n\nvoid CodeGenFunction::EmitFunctionEpilog(const CGFunctionInfo &FI,\n                                         bool EmitRetDbgLoc,\n                                         SourceLocation EndLoc) {\n  if (FI.isNoReturn()) {\n    // Noreturn functions don't return.\n    EmitUnreachable(EndLoc);\n    return;\n  }\n\n  if (CurCodeDecl && CurCodeDecl->hasAttr<NakedAttr>()) {\n    // Naked functions don't have epilogues.\n    Builder.CreateUnreachable();\n    return;\n  }\n\n  // Functions with no result always return void.\n  if (!ReturnValue.isValid()) {\n    Builder.CreateRetVoid();\n    return;\n  }\n\n  llvm::DebugLoc RetDbgLoc;\n  llvm::Value *RV = nullptr;\n  QualType RetTy = FI.getReturnType();\n  const ABIArgInfo &RetAI = FI.getReturnInfo();\n\n  switch (RetAI.getKind()) {\n  case ABIArgInfo::InAlloca:\n    // Aggregrates get evaluated directly into the destination.  Sometimes we\n    // need to return the sret value in a register, though.\n    assert(hasAggregateEvaluationKind(RetTy));\n    if (RetAI.getInAllocaSRet()) {\n      llvm::Function::arg_iterator EI = CurFn->arg_end();\n      --EI;\n      llvm::Value *ArgStruct = &*EI;\n      llvm::Value *SRet = Builder.CreateStructGEP(\n          nullptr, ArgStruct, RetAI.getInAllocaFieldIndex());\n      llvm::Type *Ty =\n          cast<llvm::GetElementPtrInst>(SRet)->getResultElementType();\n      RV = Builder.CreateAlignedLoad(Ty, SRet, getPointerAlign(), \"sret\");\n    }\n    break;\n\n  case ABIArgInfo::Indirect: {\n    auto AI = CurFn->arg_begin();\n    if (RetAI.isSRetAfterThis())\n      ++AI;\n    switch (getEvaluationKind(RetTy)) {\n    case TEK_Complex: {\n      ComplexPairTy RT =\n        EmitLoadOfComplex(MakeAddrLValue(ReturnValue, RetTy), EndLoc);\n      EmitStoreOfComplex(RT, MakeNaturalAlignAddrLValue(&*AI, RetTy),\n                         /*isInit*/ true);\n      break;\n    }\n    case TEK_Aggregate:\n      // Do nothing; aggregrates get evaluated directly into the destination.\n      break;\n    case TEK_Scalar:\n      EmitStoreOfScalar(Builder.CreateLoad(ReturnValue),\n                        MakeNaturalAlignAddrLValue(&*AI, RetTy),\n                        /*isInit*/ true);\n      break;\n    }\n    break;\n  }\n\n  case ABIArgInfo::Extend:\n  case ABIArgInfo::Direct:\n    if (RetAI.getCoerceToType() == ConvertType(RetTy) &&\n        RetAI.getDirectOffset() == 0) {\n      // The internal return value temp always will have pointer-to-return-type\n      // type, just do a load.\n\n      // If there is a dominating store to ReturnValue, we can elide\n      // the load, zap the store, and usually zap the alloca.\n      if (llvm::StoreInst *SI =\n              findDominatingStoreToReturnValue(*this)) {\n        // Reuse the debug location from the store unless there is\n        // cleanup code to be emitted between the store and return\n        // instruction.\n        if (EmitRetDbgLoc && !AutoreleaseResult)\n          RetDbgLoc = SI->getDebugLoc();\n        // Get the stored value and nuke the now-dead store.\n        RV = SI->getValueOperand();\n        SI->eraseFromParent();\n\n      // Otherwise, we have to do a simple load.\n      } else {\n        RV = Builder.CreateLoad(ReturnValue);\n      }\n    } else {\n      // If the value is offset in memory, apply the offset now.\n      Address V = emitAddressAtOffset(*this, ReturnValue, RetAI);\n\n      RV = CreateCoercedLoad(V, RetAI.getCoerceToType(), *this);\n    }\n\n    // In ARC, end functions that return a retainable type with a call\n    // to objc_autoreleaseReturnValue.\n    if (AutoreleaseResult) {\n#ifndef NDEBUG\n      // Type::isObjCRetainabletype has to be called on a QualType that hasn't\n      // been stripped of the typedefs, so we cannot use RetTy here. Get the\n      // original return type of FunctionDecl, CurCodeDecl, and BlockDecl from\n      // CurCodeDecl or BlockInfo.\n      QualType RT;\n\n      if (auto *FD = dyn_cast<FunctionDecl>(CurCodeDecl))\n        RT = FD->getReturnType();\n      else if (auto *MD = dyn_cast<ObjCMethodDecl>(CurCodeDecl))\n        RT = MD->getReturnType();\n      else if (isa<BlockDecl>(CurCodeDecl))\n        RT = BlockInfo->BlockExpression->getFunctionType()->getReturnType();\n      else\n        llvm_unreachable(\"Unexpected function/method type\");\n\n      assert(getLangOpts().ObjCAutoRefCount &&\n             !FI.isReturnsRetained() &&\n             RT->isObjCRetainableType());\n#endif\n      RV = emitAutoreleaseOfResult(*this, RV);\n    }\n\n    break;\n\n  case ABIArgInfo::Ignore:\n    break;\n\n  case ABIArgInfo::CoerceAndExpand: {\n    auto coercionType = RetAI.getCoerceAndExpandType();\n\n    // Load all of the coerced elements out into results.\n    llvm::SmallVector<llvm::Value*, 4> results;\n    Address addr = Builder.CreateElementBitCast(ReturnValue, coercionType);\n    for (unsigned i = 0, e = coercionType->getNumElements(); i != e; ++i) {\n      auto coercedEltType = coercionType->getElementType(i);\n      if (ABIArgInfo::isPaddingForCoerceAndExpand(coercedEltType))\n        continue;\n\n      auto eltAddr = Builder.CreateStructGEP(addr, i);\n      auto elt = Builder.CreateLoad(eltAddr);\n      results.push_back(elt);\n    }\n\n    // If we have one result, it's the single direct result type.\n    if (results.size() == 1) {\n      RV = results[0];\n\n    // Otherwise, we need to make a first-class aggregate.\n    } else {\n      // Construct a return type that lacks padding elements.\n      llvm::Type *returnType = RetAI.getUnpaddedCoerceAndExpandType();\n\n      RV = llvm::UndefValue::get(returnType);\n      for (unsigned i = 0, e = results.size(); i != e; ++i) {\n        RV = Builder.CreateInsertValue(RV, results[i], i);\n      }\n    }\n    break;\n  }\n  case ABIArgInfo::Expand:\n  case ABIArgInfo::IndirectAliased:\n    llvm_unreachable(\"Invalid ABI kind for return argument\");\n  }\n\n  llvm::Instruction *Ret;\n  if (RV) {\n    if (CurFuncDecl && CurFuncDecl->hasAttr<CmseNSEntryAttr>()) {\n      // For certain return types, clear padding bits, as they may reveal\n      // sensitive information.\n      // Small struct/union types are passed as integers.\n      auto *ITy = dyn_cast<llvm::IntegerType>(RV->getType());\n      if (ITy != nullptr && isa<RecordType>(RetTy.getCanonicalType()))\n        RV = EmitCMSEClearRecord(RV, ITy, RetTy);\n    }\n    EmitReturnValueCheck(RV);\n    Ret = Builder.CreateRet(RV);\n  } else {\n    Ret = Builder.CreateRetVoid();\n  }\n\n  if (RetDbgLoc)\n    Ret->setDebugLoc(std::move(RetDbgLoc));\n}\n\nvoid CodeGenFunction::EmitReturnValueCheck(llvm::Value *RV) {\n  // A current decl may not be available when emitting vtable thunks.\n  if (!CurCodeDecl)\n    return;\n\n  // If the return block isn't reachable, neither is this check, so don't emit\n  // it.\n  if (ReturnBlock.isValid() && ReturnBlock.getBlock()->use_empty())\n    return;\n\n  ReturnsNonNullAttr *RetNNAttr = nullptr;\n  if (SanOpts.has(SanitizerKind::ReturnsNonnullAttribute))\n    RetNNAttr = CurCodeDecl->getAttr<ReturnsNonNullAttr>();\n\n  if (!RetNNAttr && !requiresReturnValueNullabilityCheck())\n    return;\n\n  // Prefer the returns_nonnull attribute if it's present.\n  SourceLocation AttrLoc;\n  SanitizerMask CheckKind;\n  SanitizerHandler Handler;\n  if (RetNNAttr) {\n    assert(!requiresReturnValueNullabilityCheck() &&\n           \"Cannot check nullability and the nonnull attribute\");\n    AttrLoc = RetNNAttr->getLocation();\n    CheckKind = SanitizerKind::ReturnsNonnullAttribute;\n    Handler = SanitizerHandler::NonnullReturn;\n  } else {\n    if (auto *DD = dyn_cast<DeclaratorDecl>(CurCodeDecl))\n      if (auto *TSI = DD->getTypeSourceInfo())\n        if (auto FTL = TSI->getTypeLoc().getAsAdjusted<FunctionTypeLoc>())\n          AttrLoc = FTL.getReturnLoc().findNullabilityLoc();\n    CheckKind = SanitizerKind::NullabilityReturn;\n    Handler = SanitizerHandler::NullabilityReturn;\n  }\n\n  SanitizerScope SanScope(this);\n\n  // Make sure the \"return\" source location is valid. If we're checking a\n  // nullability annotation, make sure the preconditions for the check are met.\n  llvm::BasicBlock *Check = createBasicBlock(\"nullcheck\");\n  llvm::BasicBlock *NoCheck = createBasicBlock(\"no.nullcheck\");\n  llvm::Value *SLocPtr = Builder.CreateLoad(ReturnLocation, \"return.sloc.load\");\n  llvm::Value *CanNullCheck = Builder.CreateIsNotNull(SLocPtr);\n  if (requiresReturnValueNullabilityCheck())\n    CanNullCheck =\n        Builder.CreateAnd(CanNullCheck, RetValNullabilityPrecondition);\n  Builder.CreateCondBr(CanNullCheck, Check, NoCheck);\n  EmitBlock(Check);\n\n  // Now do the null check.\n  llvm::Value *Cond = Builder.CreateIsNotNull(RV);\n  llvm::Constant *StaticData[] = {EmitCheckSourceLocation(AttrLoc)};\n  llvm::Value *DynamicData[] = {SLocPtr};\n  EmitCheck(std::make_pair(Cond, CheckKind), Handler, StaticData, DynamicData);\n\n  EmitBlock(NoCheck);\n\n#ifndef NDEBUG\n  // The return location should not be used after the check has been emitted.\n  ReturnLocation = Address::invalid();\n#endif\n}\n\nstatic bool isInAllocaArgument(CGCXXABI &ABI, QualType type) {\n  const CXXRecordDecl *RD = type->getAsCXXRecordDecl();\n  return RD && ABI.getRecordArgABI(RD) == CGCXXABI::RAA_DirectInMemory;\n}\n\nstatic AggValueSlot createPlaceholderSlot(CodeGenFunction &CGF,\n                                          QualType Ty) {\n  // FIXME: Generate IR in one pass, rather than going back and fixing up these\n  // placeholders.\n  llvm::Type *IRTy = CGF.ConvertTypeForMem(Ty);\n  llvm::Type *IRPtrTy = IRTy->getPointerTo();\n  llvm::Value *Placeholder = llvm::UndefValue::get(IRPtrTy->getPointerTo());\n\n  // FIXME: When we generate this IR in one pass, we shouldn't need\n  // this win32-specific alignment hack.\n  CharUnits Align = CharUnits::fromQuantity(4);\n  Placeholder = CGF.Builder.CreateAlignedLoad(IRPtrTy, Placeholder, Align);\n\n  return AggValueSlot::forAddr(Address(Placeholder, Align),\n                               Ty.getQualifiers(),\n                               AggValueSlot::IsNotDestructed,\n                               AggValueSlot::DoesNotNeedGCBarriers,\n                               AggValueSlot::IsNotAliased,\n                               AggValueSlot::DoesNotOverlap);\n}\n\nvoid CodeGenFunction::EmitDelegateCallArg(CallArgList &args,\n                                          const VarDecl *param,\n                                          SourceLocation loc) {\n  // StartFunction converted the ABI-lowered parameter(s) into a\n  // local alloca.  We need to turn that into an r-value suitable\n  // for EmitCall.\n  Address local = GetAddrOfLocalVar(param);\n\n  QualType type = param->getType();\n\n  if (isInAllocaArgument(CGM.getCXXABI(), type)) {\n    CGM.ErrorUnsupported(param, \"forwarded non-trivially copyable parameter\");\n  }\n\n  // GetAddrOfLocalVar returns a pointer-to-pointer for references,\n  // but the argument needs to be the original pointer.\n  if (type->isReferenceType()) {\n    args.add(RValue::get(Builder.CreateLoad(local)), type);\n\n  // In ARC, move out of consumed arguments so that the release cleanup\n  // entered by StartFunction doesn't cause an over-release.  This isn't\n  // optimal -O0 code generation, but it should get cleaned up when\n  // optimization is enabled.  This also assumes that delegate calls are\n  // performed exactly once for a set of arguments, but that should be safe.\n  } else if (getLangOpts().ObjCAutoRefCount &&\n             param->hasAttr<NSConsumedAttr>() &&\n             type->isObjCRetainableType()) {\n    llvm::Value *ptr = Builder.CreateLoad(local);\n    auto null =\n      llvm::ConstantPointerNull::get(cast<llvm::PointerType>(ptr->getType()));\n    Builder.CreateStore(null, local);\n    args.add(RValue::get(ptr), type);\n\n  // For the most part, we just need to load the alloca, except that\n  // aggregate r-values are actually pointers to temporaries.\n  } else {\n    args.add(convertTempToRValue(local, type, loc), type);\n  }\n\n  // Deactivate the cleanup for the callee-destructed param that was pushed.\n  if (hasAggregateEvaluationKind(type) && !CurFuncIsThunk &&\n      type->castAs<RecordType>()->getDecl()->isParamDestroyedInCallee() &&\n      param->needsDestruction(getContext())) {\n    EHScopeStack::stable_iterator cleanup =\n        CalleeDestructedParamCleanups.lookup(cast<ParmVarDecl>(param));\n    assert(cleanup.isValid() &&\n           \"cleanup for callee-destructed param not recorded\");\n    // This unreachable is a temporary marker which will be removed later.\n    llvm::Instruction *isActive = Builder.CreateUnreachable();\n    args.addArgCleanupDeactivation(cleanup, isActive);\n  }\n}\n\nstatic bool isProvablyNull(llvm::Value *addr) {\n  return isa<llvm::ConstantPointerNull>(addr);\n}\n\n/// Emit the actual writing-back of a writeback.\nstatic void emitWriteback(CodeGenFunction &CGF,\n                          const CallArgList::Writeback &writeback) {\n  const LValue &srcLV = writeback.Source;\n  Address srcAddr = srcLV.getAddress(CGF);\n  assert(!isProvablyNull(srcAddr.getPointer()) &&\n         \"shouldn't have writeback for provably null argument\");\n\n  llvm::BasicBlock *contBB = nullptr;\n\n  // If the argument wasn't provably non-null, we need to null check\n  // before doing the store.\n  bool provablyNonNull = llvm::isKnownNonZero(srcAddr.getPointer(),\n                                              CGF.CGM.getDataLayout());\n  if (!provablyNonNull) {\n    llvm::BasicBlock *writebackBB = CGF.createBasicBlock(\"icr.writeback\");\n    contBB = CGF.createBasicBlock(\"icr.done\");\n\n    llvm::Value *isNull =\n      CGF.Builder.CreateIsNull(srcAddr.getPointer(), \"icr.isnull\");\n    CGF.Builder.CreateCondBr(isNull, contBB, writebackBB);\n    CGF.EmitBlock(writebackBB);\n  }\n\n  // Load the value to writeback.\n  llvm::Value *value = CGF.Builder.CreateLoad(writeback.Temporary);\n\n  // Cast it back, in case we're writing an id to a Foo* or something.\n  value = CGF.Builder.CreateBitCast(value, srcAddr.getElementType(),\n                                    \"icr.writeback-cast\");\n\n  // Perform the writeback.\n\n  // If we have a \"to use\" value, it's something we need to emit a use\n  // of.  This has to be carefully threaded in: if it's done after the\n  // release it's potentially undefined behavior (and the optimizer\n  // will ignore it), and if it happens before the retain then the\n  // optimizer could move the release there.\n  if (writeback.ToUse) {\n    assert(srcLV.getObjCLifetime() == Qualifiers::OCL_Strong);\n\n    // Retain the new value.  No need to block-copy here:  the block's\n    // being passed up the stack.\n    value = CGF.EmitARCRetainNonBlock(value);\n\n    // Emit the intrinsic use here.\n    CGF.EmitARCIntrinsicUse(writeback.ToUse);\n\n    // Load the old value (primitively).\n    llvm::Value *oldValue = CGF.EmitLoadOfScalar(srcLV, SourceLocation());\n\n    // Put the new value in place (primitively).\n    CGF.EmitStoreOfScalar(value, srcLV, /*init*/ false);\n\n    // Release the old value.\n    CGF.EmitARCRelease(oldValue, srcLV.isARCPreciseLifetime());\n\n  // Otherwise, we can just do a normal lvalue store.\n  } else {\n    CGF.EmitStoreThroughLValue(RValue::get(value), srcLV);\n  }\n\n  // Jump to the continuation block.\n  if (!provablyNonNull)\n    CGF.EmitBlock(contBB);\n}\n\nstatic void emitWritebacks(CodeGenFunction &CGF,\n                           const CallArgList &args) {\n  for (const auto &I : args.writebacks())\n    emitWriteback(CGF, I);\n}\n\nstatic void deactivateArgCleanupsBeforeCall(CodeGenFunction &CGF,\n                                            const CallArgList &CallArgs) {\n  ArrayRef<CallArgList::CallArgCleanup> Cleanups =\n    CallArgs.getCleanupsToDeactivate();\n  // Iterate in reverse to increase the likelihood of popping the cleanup.\n  for (const auto &I : llvm::reverse(Cleanups)) {\n    CGF.DeactivateCleanupBlock(I.Cleanup, I.IsActiveIP);\n    I.IsActiveIP->eraseFromParent();\n  }\n}\n\nstatic const Expr *maybeGetUnaryAddrOfOperand(const Expr *E) {\n  if (const UnaryOperator *uop = dyn_cast<UnaryOperator>(E->IgnoreParens()))\n    if (uop->getOpcode() == UO_AddrOf)\n      return uop->getSubExpr();\n  return nullptr;\n}\n\n/// Emit an argument that's being passed call-by-writeback.  That is,\n/// we are passing the address of an __autoreleased temporary; it\n/// might be copy-initialized with the current value of the given\n/// address, but it will definitely be copied out of after the call.\nstatic void emitWritebackArg(CodeGenFunction &CGF, CallArgList &args,\n                             const ObjCIndirectCopyRestoreExpr *CRE) {\n  LValue srcLV;\n\n  // Make an optimistic effort to emit the address as an l-value.\n  // This can fail if the argument expression is more complicated.\n  if (const Expr *lvExpr = maybeGetUnaryAddrOfOperand(CRE->getSubExpr())) {\n    srcLV = CGF.EmitLValue(lvExpr);\n\n  // Otherwise, just emit it as a scalar.\n  } else {\n    Address srcAddr = CGF.EmitPointerWithAlignment(CRE->getSubExpr());\n\n    QualType srcAddrType =\n      CRE->getSubExpr()->getType()->castAs<PointerType>()->getPointeeType();\n    srcLV = CGF.MakeAddrLValue(srcAddr, srcAddrType);\n  }\n  Address srcAddr = srcLV.getAddress(CGF);\n\n  // The dest and src types don't necessarily match in LLVM terms\n  // because of the crazy ObjC compatibility rules.\n\n  llvm::PointerType *destType =\n    cast<llvm::PointerType>(CGF.ConvertType(CRE->getType()));\n\n  // If the address is a constant null, just pass the appropriate null.\n  if (isProvablyNull(srcAddr.getPointer())) {\n    args.add(RValue::get(llvm::ConstantPointerNull::get(destType)),\n             CRE->getType());\n    return;\n  }\n\n  // Create the temporary.\n  Address temp = CGF.CreateTempAlloca(destType->getElementType(),\n                                      CGF.getPointerAlign(),\n                                      \"icr.temp\");\n  // Loading an l-value can introduce a cleanup if the l-value is __weak,\n  // and that cleanup will be conditional if we can't prove that the l-value\n  // isn't null, so we need to register a dominating point so that the cleanups\n  // system will make valid IR.\n  CodeGenFunction::ConditionalEvaluation condEval(CGF);\n\n  // Zero-initialize it if we're not doing a copy-initialization.\n  bool shouldCopy = CRE->shouldCopy();\n  if (!shouldCopy) {\n    llvm::Value *null =\n      llvm::ConstantPointerNull::get(\n        cast<llvm::PointerType>(destType->getElementType()));\n    CGF.Builder.CreateStore(null, temp);\n  }\n\n  llvm::BasicBlock *contBB = nullptr;\n  llvm::BasicBlock *originBB = nullptr;\n\n  // If the address is *not* known to be non-null, we need to switch.\n  llvm::Value *finalArgument;\n\n  bool provablyNonNull = llvm::isKnownNonZero(srcAddr.getPointer(),\n                                              CGF.CGM.getDataLayout());\n  if (provablyNonNull) {\n    finalArgument = temp.getPointer();\n  } else {\n    llvm::Value *isNull =\n      CGF.Builder.CreateIsNull(srcAddr.getPointer(), \"icr.isnull\");\n\n    finalArgument = CGF.Builder.CreateSelect(isNull,\n                                   llvm::ConstantPointerNull::get(destType),\n                                             temp.getPointer(), \"icr.argument\");\n\n    // If we need to copy, then the load has to be conditional, which\n    // means we need control flow.\n    if (shouldCopy) {\n      originBB = CGF.Builder.GetInsertBlock();\n      contBB = CGF.createBasicBlock(\"icr.cont\");\n      llvm::BasicBlock *copyBB = CGF.createBasicBlock(\"icr.copy\");\n      CGF.Builder.CreateCondBr(isNull, contBB, copyBB);\n      CGF.EmitBlock(copyBB);\n      condEval.begin(CGF);\n    }\n  }\n\n  llvm::Value *valueToUse = nullptr;\n\n  // Perform a copy if necessary.\n  if (shouldCopy) {\n    RValue srcRV = CGF.EmitLoadOfLValue(srcLV, SourceLocation());\n    assert(srcRV.isScalar());\n\n    llvm::Value *src = srcRV.getScalarVal();\n    src = CGF.Builder.CreateBitCast(src, destType->getElementType(),\n                                    \"icr.cast\");\n\n    // Use an ordinary store, not a store-to-lvalue.\n    CGF.Builder.CreateStore(src, temp);\n\n    // If optimization is enabled, and the value was held in a\n    // __strong variable, we need to tell the optimizer that this\n    // value has to stay alive until we're doing the store back.\n    // This is because the temporary is effectively unretained,\n    // and so otherwise we can violate the high-level semantics.\n    if (CGF.CGM.getCodeGenOpts().OptimizationLevel != 0 &&\n        srcLV.getObjCLifetime() == Qualifiers::OCL_Strong) {\n      valueToUse = src;\n    }\n  }\n\n  // Finish the control flow if we needed it.\n  if (shouldCopy && !provablyNonNull) {\n    llvm::BasicBlock *copyBB = CGF.Builder.GetInsertBlock();\n    CGF.EmitBlock(contBB);\n\n    // Make a phi for the value to intrinsically use.\n    if (valueToUse) {\n      llvm::PHINode *phiToUse = CGF.Builder.CreatePHI(valueToUse->getType(), 2,\n                                                      \"icr.to-use\");\n      phiToUse->addIncoming(valueToUse, copyBB);\n      phiToUse->addIncoming(llvm::UndefValue::get(valueToUse->getType()),\n                            originBB);\n      valueToUse = phiToUse;\n    }\n\n    condEval.end(CGF);\n  }\n\n  args.addWriteback(srcLV, temp, valueToUse);\n  args.add(RValue::get(finalArgument), CRE->getType());\n}\n\nvoid CallArgList::allocateArgumentMemory(CodeGenFunction &CGF) {\n  assert(!StackBase);\n\n  // Save the stack.\n  llvm::Function *F = CGF.CGM.getIntrinsic(llvm::Intrinsic::stacksave);\n  StackBase = CGF.Builder.CreateCall(F, {}, \"inalloca.save\");\n}\n\nvoid CallArgList::freeArgumentMemory(CodeGenFunction &CGF) const {\n  if (StackBase) {\n    // Restore the stack after the call.\n    llvm::Function *F = CGF.CGM.getIntrinsic(llvm::Intrinsic::stackrestore);\n    CGF.Builder.CreateCall(F, StackBase);\n  }\n}\n\nvoid CodeGenFunction::EmitNonNullArgCheck(RValue RV, QualType ArgType,\n                                          SourceLocation ArgLoc,\n                                          AbstractCallee AC,\n                                          unsigned ParmNum) {\n  if (!AC.getDecl() || !(SanOpts.has(SanitizerKind::NonnullAttribute) ||\n                         SanOpts.has(SanitizerKind::NullabilityArg)))\n    return;\n\n  // The param decl may be missing in a variadic function.\n  auto PVD = ParmNum < AC.getNumParams() ? AC.getParamDecl(ParmNum) : nullptr;\n  unsigned ArgNo = PVD ? PVD->getFunctionScopeIndex() : ParmNum;\n\n  // Prefer the nonnull attribute if it's present.\n  const NonNullAttr *NNAttr = nullptr;\n  if (SanOpts.has(SanitizerKind::NonnullAttribute))\n    NNAttr = getNonNullAttr(AC.getDecl(), PVD, ArgType, ArgNo);\n\n  bool CanCheckNullability = false;\n  if (SanOpts.has(SanitizerKind::NullabilityArg) && !NNAttr && PVD) {\n    auto Nullability = PVD->getType()->getNullability(getContext());\n    CanCheckNullability = Nullability &&\n                          *Nullability == NullabilityKind::NonNull &&\n                          PVD->getTypeSourceInfo();\n  }\n\n  if (!NNAttr && !CanCheckNullability)\n    return;\n\n  SourceLocation AttrLoc;\n  SanitizerMask CheckKind;\n  SanitizerHandler Handler;\n  if (NNAttr) {\n    AttrLoc = NNAttr->getLocation();\n    CheckKind = SanitizerKind::NonnullAttribute;\n    Handler = SanitizerHandler::NonnullArg;\n  } else {\n    AttrLoc = PVD->getTypeSourceInfo()->getTypeLoc().findNullabilityLoc();\n    CheckKind = SanitizerKind::NullabilityArg;\n    Handler = SanitizerHandler::NullabilityArg;\n  }\n\n  SanitizerScope SanScope(this);\n  llvm::Value *Cond = EmitNonNullRValueCheck(RV, ArgType);\n  llvm::Constant *StaticData[] = {\n      EmitCheckSourceLocation(ArgLoc), EmitCheckSourceLocation(AttrLoc),\n      llvm::ConstantInt::get(Int32Ty, ArgNo + 1),\n  };\n  EmitCheck(std::make_pair(Cond, CheckKind), Handler, StaticData, None);\n}\n\n// Check if the call is going to use the inalloca convention. This needs to\n// agree with CGFunctionInfo::usesInAlloca. The CGFunctionInfo is arranged\n// later, so we can't check it directly.\nstatic bool hasInAllocaArgs(CodeGenModule &CGM, CallingConv ExplicitCC,\n                            ArrayRef<QualType> ArgTypes) {\n  // The Swift calling convention doesn't go through the target-specific\n  // argument classification, so it never uses inalloca.\n  // TODO: Consider limiting inalloca use to only calling conventions supported\n  // by MSVC.\n  if (ExplicitCC == CC_Swift)\n    return false;\n  if (!CGM.getTarget().getCXXABI().isMicrosoft())\n    return false;\n  return llvm::any_of(ArgTypes, [&](QualType Ty) {\n    return isInAllocaArgument(CGM.getCXXABI(), Ty);\n  });\n}\n\n#ifndef NDEBUG\n// Determine whether the given argument is an Objective-C method\n// that may have type parameters in its signature.\nstatic bool isObjCMethodWithTypeParams(const ObjCMethodDecl *method) {\n  const DeclContext *dc = method->getDeclContext();\n  if (const ObjCInterfaceDecl *classDecl = dyn_cast<ObjCInterfaceDecl>(dc)) {\n    return classDecl->getTypeParamListAsWritten();\n  }\n\n  if (const ObjCCategoryDecl *catDecl = dyn_cast<ObjCCategoryDecl>(dc)) {\n    return catDecl->getTypeParamList();\n  }\n\n  return false;\n}\n#endif\n\n/// EmitCallArgs - Emit call arguments for a function.\nvoid CodeGenFunction::EmitCallArgs(\n    CallArgList &Args, PrototypeWrapper Prototype,\n    llvm::iterator_range<CallExpr::const_arg_iterator> ArgRange,\n    AbstractCallee AC, unsigned ParamsToSkip, EvaluationOrder Order) {\n  SmallVector<QualType, 16> ArgTypes;\n\n  assert((ParamsToSkip == 0 || Prototype.P) &&\n         \"Can't skip parameters if type info is not provided\");\n\n  // This variable only captures *explicitly* written conventions, not those\n  // applied by default via command line flags or target defaults, such as\n  // thiscall, aapcs, stdcall via -mrtd, etc. Computing that correctly would\n  // require knowing if this is a C++ instance method or being able to see\n  // unprototyped FunctionTypes.\n  CallingConv ExplicitCC = CC_C;\n\n  // First, if a prototype was provided, use those argument types.\n  bool IsVariadic = false;\n  if (Prototype.P) {\n    const auto *MD = Prototype.P.dyn_cast<const ObjCMethodDecl *>();\n    if (MD) {\n      IsVariadic = MD->isVariadic();\n      ExplicitCC = getCallingConventionForDecl(\n          MD, CGM.getTarget().getTriple().isOSWindows());\n      ArgTypes.assign(MD->param_type_begin() + ParamsToSkip,\n                      MD->param_type_end());\n    } else {\n      const auto *FPT = Prototype.P.get<const FunctionProtoType *>();\n      IsVariadic = FPT->isVariadic();\n      ExplicitCC = FPT->getExtInfo().getCC();\n      ArgTypes.assign(FPT->param_type_begin() + ParamsToSkip,\n                      FPT->param_type_end());\n    }\n\n#ifndef NDEBUG\n    // Check that the prototyped types match the argument expression types.\n    bool isGenericMethod = MD && isObjCMethodWithTypeParams(MD);\n    CallExpr::const_arg_iterator Arg = ArgRange.begin();\n    for (QualType Ty : ArgTypes) {\n      assert(Arg != ArgRange.end() && \"Running over edge of argument list!\");\n      assert(\n          (isGenericMethod || Ty->isVariablyModifiedType() ||\n           Ty.getNonReferenceType()->isObjCRetainableType() ||\n           getContext()\n                   .getCanonicalType(Ty.getNonReferenceType())\n                   .getTypePtr() ==\n               getContext().getCanonicalType((*Arg)->getType()).getTypePtr()) &&\n          \"type mismatch in call argument!\");\n      ++Arg;\n    }\n\n    // Either we've emitted all the call args, or we have a call to variadic\n    // function.\n    assert((Arg == ArgRange.end() || IsVariadic) &&\n           \"Extra arguments in non-variadic function!\");\n#endif\n  }\n\n  // If we still have any arguments, emit them using the type of the argument.\n  for (auto *A : llvm::make_range(std::next(ArgRange.begin(), ArgTypes.size()),\n                                  ArgRange.end()))\n    ArgTypes.push_back(IsVariadic ? getVarArgType(A) : A->getType());\n  assert((int)ArgTypes.size() == (ArgRange.end() - ArgRange.begin()));\n\n  // We must evaluate arguments from right to left in the MS C++ ABI,\n  // because arguments are destroyed left to right in the callee. As a special\n  // case, there are certain language constructs that require left-to-right\n  // evaluation, and in those cases we consider the evaluation order requirement\n  // to trump the \"destruction order is reverse construction order\" guarantee.\n  bool LeftToRight =\n      CGM.getTarget().getCXXABI().areArgsDestroyedLeftToRightInCallee()\n          ? Order == EvaluationOrder::ForceLeftToRight\n          : Order != EvaluationOrder::ForceRightToLeft;\n\n  auto MaybeEmitImplicitObjectSize = [&](unsigned I, const Expr *Arg,\n                                         RValue EmittedArg) {\n    if (!AC.hasFunctionDecl() || I >= AC.getNumParams())\n      return;\n    auto *PS = AC.getParamDecl(I)->getAttr<PassObjectSizeAttr>();\n    if (PS == nullptr)\n      return;\n\n    const auto &Context = getContext();\n    auto SizeTy = Context.getSizeType();\n    auto T = Builder.getIntNTy(Context.getTypeSize(SizeTy));\n    assert(EmittedArg.getScalarVal() && \"We emitted nothing for the arg?\");\n    llvm::Value *V = evaluateOrEmitBuiltinObjectSize(Arg, PS->getType(), T,\n                                                     EmittedArg.getScalarVal(),\n                                                     PS->isDynamic());\n    Args.add(RValue::get(V), SizeTy);\n    // If we're emitting args in reverse, be sure to do so with\n    // pass_object_size, as well.\n    if (!LeftToRight)\n      std::swap(Args.back(), *(&Args.back() - 1));\n  };\n\n  // Insert a stack save if we're going to need any inalloca args.\n  if (hasInAllocaArgs(CGM, ExplicitCC, ArgTypes)) {\n    assert(getTarget().getTriple().getArch() == llvm::Triple::x86 &&\n           \"inalloca only supported on x86\");\n    Args.allocateArgumentMemory(*this);\n  }\n\n  // Evaluate each argument in the appropriate order.\n  size_t CallArgsStart = Args.size();\n  for (unsigned I = 0, E = ArgTypes.size(); I != E; ++I) {\n    unsigned Idx = LeftToRight ? I : E - I - 1;\n    CallExpr::const_arg_iterator Arg = ArgRange.begin() + Idx;\n    unsigned InitialArgSize = Args.size();\n    // If *Arg is an ObjCIndirectCopyRestoreExpr, check that either the types of\n    // the argument and parameter match or the objc method is parameterized.\n    assert((!isa<ObjCIndirectCopyRestoreExpr>(*Arg) ||\n            getContext().hasSameUnqualifiedType((*Arg)->getType(),\n                                                ArgTypes[Idx]) ||\n            (isa<ObjCMethodDecl>(AC.getDecl()) &&\n             isObjCMethodWithTypeParams(cast<ObjCMethodDecl>(AC.getDecl())))) &&\n           \"Argument and parameter types don't match\");\n    EmitCallArg(Args, *Arg, ArgTypes[Idx]);\n    // In particular, we depend on it being the last arg in Args, and the\n    // objectsize bits depend on there only being one arg if !LeftToRight.\n    assert(InitialArgSize + 1 == Args.size() &&\n           \"The code below depends on only adding one arg per EmitCallArg\");\n    (void)InitialArgSize;\n    // Since pointer argument are never emitted as LValue, it is safe to emit\n    // non-null argument check for r-value only.\n    if (!Args.back().hasLValue()) {\n      RValue RVArg = Args.back().getKnownRValue();\n      EmitNonNullArgCheck(RVArg, ArgTypes[Idx], (*Arg)->getExprLoc(), AC,\n                          ParamsToSkip + Idx);\n      // @llvm.objectsize should never have side-effects and shouldn't need\n      // destruction/cleanups, so we can safely \"emit\" it after its arg,\n      // regardless of right-to-leftness\n      MaybeEmitImplicitObjectSize(Idx, *Arg, RVArg);\n    }\n  }\n\n  if (!LeftToRight) {\n    // Un-reverse the arguments we just evaluated so they match up with the LLVM\n    // IR function.\n    std::reverse(Args.begin() + CallArgsStart, Args.end());\n  }\n}\n\nnamespace {\n\nstruct DestroyUnpassedArg final : EHScopeStack::Cleanup {\n  DestroyUnpassedArg(Address Addr, QualType Ty)\n      : Addr(Addr), Ty(Ty) {}\n\n  Address Addr;\n  QualType Ty;\n\n  void Emit(CodeGenFunction &CGF, Flags flags) override {\n    QualType::DestructionKind DtorKind = Ty.isDestructedType();\n    if (DtorKind == QualType::DK_cxx_destructor) {\n      const CXXDestructorDecl *Dtor = Ty->getAsCXXRecordDecl()->getDestructor();\n      assert(!Dtor->isTrivial());\n      CGF.EmitCXXDestructorCall(Dtor, Dtor_Complete, /*for vbase*/ false,\n                                /*Delegating=*/false, Addr, Ty);\n    } else {\n      CGF.callCStructDestructor(CGF.MakeAddrLValue(Addr, Ty));\n    }\n  }\n};\n\nstruct DisableDebugLocationUpdates {\n  CodeGenFunction &CGF;\n  bool disabledDebugInfo;\n  DisableDebugLocationUpdates(CodeGenFunction &CGF, const Expr *E) : CGF(CGF) {\n    if ((disabledDebugInfo = isa<CXXDefaultArgExpr>(E) && CGF.getDebugInfo()))\n      CGF.disableDebugInfo();\n  }\n  ~DisableDebugLocationUpdates() {\n    if (disabledDebugInfo)\n      CGF.enableDebugInfo();\n  }\n};\n\n} // end anonymous namespace\n\nRValue CallArg::getRValue(CodeGenFunction &CGF) const {\n  if (!HasLV)\n    return RV;\n  LValue Copy = CGF.MakeAddrLValue(CGF.CreateMemTemp(Ty), Ty);\n  CGF.EmitAggregateCopy(Copy, LV, Ty, AggValueSlot::DoesNotOverlap,\n                        LV.isVolatile());\n  IsUsed = true;\n  return RValue::getAggregate(Copy.getAddress(CGF));\n}\n\nvoid CallArg::copyInto(CodeGenFunction &CGF, Address Addr) const {\n  LValue Dst = CGF.MakeAddrLValue(Addr, Ty);\n  if (!HasLV && RV.isScalar())\n    CGF.EmitStoreOfScalar(RV.getScalarVal(), Dst, /*isInit=*/true);\n  else if (!HasLV && RV.isComplex())\n    CGF.EmitStoreOfComplex(RV.getComplexVal(), Dst, /*init=*/true);\n  else {\n    auto Addr = HasLV ? LV.getAddress(CGF) : RV.getAggregateAddress();\n    LValue SrcLV = CGF.MakeAddrLValue(Addr, Ty);\n    // We assume that call args are never copied into subobjects.\n    CGF.EmitAggregateCopy(Dst, SrcLV, Ty, AggValueSlot::DoesNotOverlap,\n                          HasLV ? LV.isVolatileQualified()\n                                : RV.isVolatileQualified());\n  }\n  IsUsed = true;\n}\n\nvoid CodeGenFunction::EmitCallArg(CallArgList &args, const Expr *E,\n                                  QualType type) {\n  DisableDebugLocationUpdates Dis(*this, E);\n  if (const ObjCIndirectCopyRestoreExpr *CRE\n        = dyn_cast<ObjCIndirectCopyRestoreExpr>(E)) {\n    assert(getLangOpts().ObjCAutoRefCount);\n    return emitWritebackArg(*this, args, CRE);\n  }\n\n  assert(type->isReferenceType() == E->isGLValue() &&\n         \"reference binding to unmaterialized r-value!\");\n\n  if (E->isGLValue()) {\n    assert(E->getObjectKind() == OK_Ordinary);\n    return args.add(EmitReferenceBindingToExpr(E), type);\n  }\n\n  bool HasAggregateEvalKind = hasAggregateEvaluationKind(type);\n\n  // In the Microsoft C++ ABI, aggregate arguments are destructed by the callee.\n  // However, we still have to push an EH-only cleanup in case we unwind before\n  // we make it to the call.\n  if (HasAggregateEvalKind &&\n      type->castAs<RecordType>()->getDecl()->isParamDestroyedInCallee()) {\n    // If we're using inalloca, use the argument memory.  Otherwise, use a\n    // temporary.\n    AggValueSlot Slot;\n    if (args.isUsingInAlloca())\n      Slot = createPlaceholderSlot(*this, type);\n    else\n      Slot = CreateAggTemp(type, \"agg.tmp\");\n\n    bool DestroyedInCallee = true, NeedsEHCleanup = true;\n    if (const auto *RD = type->getAsCXXRecordDecl())\n      DestroyedInCallee = RD->hasNonTrivialDestructor();\n    else\n      NeedsEHCleanup = needsEHCleanup(type.isDestructedType());\n\n    if (DestroyedInCallee)\n      Slot.setExternallyDestructed();\n\n    EmitAggExpr(E, Slot);\n    RValue RV = Slot.asRValue();\n    args.add(RV, type);\n\n    if (DestroyedInCallee && NeedsEHCleanup) {\n      // Create a no-op GEP between the placeholder and the cleanup so we can\n      // RAUW it successfully.  It also serves as a marker of the first\n      // instruction where the cleanup is active.\n      pushFullExprCleanup<DestroyUnpassedArg>(EHCleanup, Slot.getAddress(),\n                                              type);\n      // This unreachable is a temporary marker which will be removed later.\n      llvm::Instruction *IsActive = Builder.CreateUnreachable();\n      args.addArgCleanupDeactivation(EHStack.getInnermostEHScope(), IsActive);\n    }\n    return;\n  }\n\n  if (HasAggregateEvalKind && isa<ImplicitCastExpr>(E) &&\n      cast<CastExpr>(E)->getCastKind() == CK_LValueToRValue) {\n    LValue L = EmitLValue(cast<CastExpr>(E)->getSubExpr());\n    assert(L.isSimple());\n    args.addUncopiedAggregate(L, type);\n    return;\n  }\n\n  args.add(EmitAnyExprToTemp(E), type);\n}\n\nQualType CodeGenFunction::getVarArgType(const Expr *Arg) {\n  // System headers on Windows define NULL to 0 instead of 0LL on Win64. MSVC\n  // implicitly widens null pointer constants that are arguments to varargs\n  // functions to pointer-sized ints.\n  if (!getTarget().getTriple().isOSWindows())\n    return Arg->getType();\n\n  if (Arg->getType()->isIntegerType() &&\n      getContext().getTypeSize(Arg->getType()) <\n          getContext().getTargetInfo().getPointerWidth(0) &&\n      Arg->isNullPointerConstant(getContext(),\n                                 Expr::NPC_ValueDependentIsNotNull)) {\n    return getContext().getIntPtrType();\n  }\n\n  return Arg->getType();\n}\n\n// In ObjC ARC mode with no ObjC ARC exception safety, tell the ARC\n// optimizer it can aggressively ignore unwind edges.\nvoid\nCodeGenFunction::AddObjCARCExceptionMetadata(llvm::Instruction *Inst) {\n  if (CGM.getCodeGenOpts().OptimizationLevel != 0 &&\n      !CGM.getCodeGenOpts().ObjCAutoRefCountExceptions)\n    Inst->setMetadata(\"clang.arc.no_objc_arc_exceptions\",\n                      CGM.getNoObjCARCExceptionsMetadata());\n}\n\n/// Emits a call to the given no-arguments nounwind runtime function.\nllvm::CallInst *\nCodeGenFunction::EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                         const llvm::Twine &name) {\n  return EmitNounwindRuntimeCall(callee, None, name);\n}\n\n/// Emits a call to the given nounwind runtime function.\nllvm::CallInst *\nCodeGenFunction::EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                         ArrayRef<llvm::Value *> args,\n                                         const llvm::Twine &name) {\n  llvm::CallInst *call = EmitRuntimeCall(callee, args, name);\n  call->setDoesNotThrow();\n  return call;\n}\n\n/// Emits a simple call (never an invoke) to the given no-arguments\n/// runtime function.\nllvm::CallInst *CodeGenFunction::EmitRuntimeCall(llvm::FunctionCallee callee,\n                                                 const llvm::Twine &name) {\n  return EmitRuntimeCall(callee, None, name);\n}\n\n// Calls which may throw must have operand bundles indicating which funclet\n// they are nested within.\nSmallVector<llvm::OperandBundleDef, 1>\nCodeGenFunction::getBundlesForFunclet(llvm::Value *Callee) {\n  SmallVector<llvm::OperandBundleDef, 1> BundleList;\n  // There is no need for a funclet operand bundle if we aren't inside a\n  // funclet.\n  if (!CurrentFuncletPad)\n    return BundleList;\n\n  // Skip intrinsics which cannot throw.\n  auto *CalleeFn = dyn_cast<llvm::Function>(Callee->stripPointerCasts());\n  if (CalleeFn && CalleeFn->isIntrinsic() && CalleeFn->doesNotThrow())\n    return BundleList;\n\n  BundleList.emplace_back(\"funclet\", CurrentFuncletPad);\n  return BundleList;\n}\n\n/// Emits a simple call (never an invoke) to the given runtime function.\nllvm::CallInst *CodeGenFunction::EmitRuntimeCall(llvm::FunctionCallee callee,\n                                                 ArrayRef<llvm::Value *> args,\n                                                 const llvm::Twine &name) {\n  llvm::CallInst *call = Builder.CreateCall(\n      callee, args, getBundlesForFunclet(callee.getCallee()), name);\n  call->setCallingConv(getRuntimeCC());\n  return call;\n}\n\n/// Emits a call or invoke to the given noreturn runtime function.\nvoid CodeGenFunction::EmitNoreturnRuntimeCallOrInvoke(\n    llvm::FunctionCallee callee, ArrayRef<llvm::Value *> args) {\n  SmallVector<llvm::OperandBundleDef, 1> BundleList =\n      getBundlesForFunclet(callee.getCallee());\n\n  if (getInvokeDest()) {\n    llvm::InvokeInst *invoke =\n      Builder.CreateInvoke(callee,\n                           getUnreachableBlock(),\n                           getInvokeDest(),\n                           args,\n                           BundleList);\n    invoke->setDoesNotReturn();\n    invoke->setCallingConv(getRuntimeCC());\n  } else {\n    llvm::CallInst *call = Builder.CreateCall(callee, args, BundleList);\n    call->setDoesNotReturn();\n    call->setCallingConv(getRuntimeCC());\n    Builder.CreateUnreachable();\n  }\n}\n\n/// Emits a call or invoke instruction to the given nullary runtime function.\nllvm::CallBase *\nCodeGenFunction::EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                         const Twine &name) {\n  return EmitRuntimeCallOrInvoke(callee, None, name);\n}\n\n/// Emits a call or invoke instruction to the given runtime function.\nllvm::CallBase *\nCodeGenFunction::EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                         ArrayRef<llvm::Value *> args,\n                                         const Twine &name) {\n  llvm::CallBase *call = EmitCallOrInvoke(callee, args, name);\n  call->setCallingConv(getRuntimeCC());\n  return call;\n}\n\n/// Emits a call or invoke instruction to the given function, depending\n/// on the current state of the EH stack.\nllvm::CallBase *CodeGenFunction::EmitCallOrInvoke(llvm::FunctionCallee Callee,\n                                                  ArrayRef<llvm::Value *> Args,\n                                                  const Twine &Name) {\n  llvm::BasicBlock *InvokeDest = getInvokeDest();\n  SmallVector<llvm::OperandBundleDef, 1> BundleList =\n      getBundlesForFunclet(Callee.getCallee());\n\n  llvm::CallBase *Inst;\n  if (!InvokeDest)\n    Inst = Builder.CreateCall(Callee, Args, BundleList, Name);\n  else {\n    llvm::BasicBlock *ContBB = createBasicBlock(\"invoke.cont\");\n    Inst = Builder.CreateInvoke(Callee, ContBB, InvokeDest, Args, BundleList,\n                                Name);\n    EmitBlock(ContBB);\n  }\n\n  // In ObjC ARC mode with no ObjC ARC exception safety, tell the ARC\n  // optimizer it can aggressively ignore unwind edges.\n  if (CGM.getLangOpts().ObjCAutoRefCount)\n    AddObjCARCExceptionMetadata(Inst);\n\n  return Inst;\n}\n\nvoid CodeGenFunction::deferPlaceholderReplacement(llvm::Instruction *Old,\n                                                  llvm::Value *New) {\n  DeferredReplacements.push_back(\n      std::make_pair(llvm::WeakTrackingVH(Old), New));\n}\n\nnamespace {\n\n/// Specify given \\p NewAlign as the alignment of return value attribute. If\n/// such attribute already exists, re-set it to the maximal one of two options.\nLLVM_NODISCARD llvm::AttributeList\nmaybeRaiseRetAlignmentAttribute(llvm::LLVMContext &Ctx,\n                                const llvm::AttributeList &Attrs,\n                                llvm::Align NewAlign) {\n  llvm::Align CurAlign = Attrs.getRetAlignment().valueOrOne();\n  if (CurAlign >= NewAlign)\n    return Attrs;\n  llvm::Attribute AlignAttr = llvm::Attribute::getWithAlignment(Ctx, NewAlign);\n  return Attrs\n      .removeAttribute(Ctx, llvm::AttributeList::ReturnIndex,\n                       llvm::Attribute::AttrKind::Alignment)\n      .addAttribute(Ctx, llvm::AttributeList::ReturnIndex, AlignAttr);\n}\n\ntemplate <typename AlignedAttrTy> class AbstractAssumeAlignedAttrEmitter {\nprotected:\n  CodeGenFunction &CGF;\n\n  /// We do nothing if this is, or becomes, nullptr.\n  const AlignedAttrTy *AA = nullptr;\n\n  llvm::Value *Alignment = nullptr;      // May or may not be a constant.\n  llvm::ConstantInt *OffsetCI = nullptr; // Constant, hopefully zero.\n\n  AbstractAssumeAlignedAttrEmitter(CodeGenFunction &CGF_, const Decl *FuncDecl)\n      : CGF(CGF_) {\n    if (!FuncDecl)\n      return;\n    AA = FuncDecl->getAttr<AlignedAttrTy>();\n  }\n\npublic:\n  /// If we can, materialize the alignment as an attribute on return value.\n  LLVM_NODISCARD llvm::AttributeList\n  TryEmitAsCallSiteAttribute(const llvm::AttributeList &Attrs) {\n    if (!AA || OffsetCI || CGF.SanOpts.has(SanitizerKind::Alignment))\n      return Attrs;\n    const auto *AlignmentCI = dyn_cast<llvm::ConstantInt>(Alignment);\n    if (!AlignmentCI)\n      return Attrs;\n    // We may legitimately have non-power-of-2 alignment here.\n    // If so, this is UB land, emit it via `@llvm.assume` instead.\n    if (!AlignmentCI->getValue().isPowerOf2())\n      return Attrs;\n    llvm::AttributeList NewAttrs = maybeRaiseRetAlignmentAttribute(\n        CGF.getLLVMContext(), Attrs,\n        llvm::Align(\n            AlignmentCI->getLimitedValue(llvm::Value::MaximumAlignment)));\n    AA = nullptr; // We're done. Disallow doing anything else.\n    return NewAttrs;\n  }\n\n  /// Emit alignment assumption.\n  /// This is a general fallback that we take if either there is an offset,\n  /// or the alignment is variable or we are sanitizing for alignment.\n  void EmitAsAnAssumption(SourceLocation Loc, QualType RetTy, RValue &Ret) {\n    if (!AA)\n      return;\n    CGF.emitAlignmentAssumption(Ret.getScalarVal(), RetTy, Loc,\n                                AA->getLocation(), Alignment, OffsetCI);\n    AA = nullptr; // We're done. Disallow doing anything else.\n  }\n};\n\n/// Helper data structure to emit `AssumeAlignedAttr`.\nclass AssumeAlignedAttrEmitter final\n    : public AbstractAssumeAlignedAttrEmitter<AssumeAlignedAttr> {\npublic:\n  AssumeAlignedAttrEmitter(CodeGenFunction &CGF_, const Decl *FuncDecl)\n      : AbstractAssumeAlignedAttrEmitter(CGF_, FuncDecl) {\n    if (!AA)\n      return;\n    // It is guaranteed that the alignment/offset are constants.\n    Alignment = cast<llvm::ConstantInt>(CGF.EmitScalarExpr(AA->getAlignment()));\n    if (Expr *Offset = AA->getOffset()) {\n      OffsetCI = cast<llvm::ConstantInt>(CGF.EmitScalarExpr(Offset));\n      if (OffsetCI->isNullValue()) // Canonicalize zero offset to no offset.\n        OffsetCI = nullptr;\n    }\n  }\n};\n\n/// Helper data structure to emit `AllocAlignAttr`.\nclass AllocAlignAttrEmitter final\n    : public AbstractAssumeAlignedAttrEmitter<AllocAlignAttr> {\npublic:\n  AllocAlignAttrEmitter(CodeGenFunction &CGF_, const Decl *FuncDecl,\n                        const CallArgList &CallArgs)\n      : AbstractAssumeAlignedAttrEmitter(CGF_, FuncDecl) {\n    if (!AA)\n      return;\n    // Alignment may or may not be a constant, and that is okay.\n    Alignment = CallArgs[AA->getParamIndex().getLLVMIndex()]\n                    .getRValue(CGF)\n                    .getScalarVal();\n  }\n};\n\n} // namespace\n\nRValue CodeGenFunction::EmitCall(const CGFunctionInfo &CallInfo,\n                                 const CGCallee &Callee,\n                                 ReturnValueSlot ReturnValue,\n                                 const CallArgList &CallArgs,\n                                 llvm::CallBase **callOrInvoke,\n                                 SourceLocation Loc) {\n  // FIXME: We no longer need the types from CallArgs; lift up and simplify.\n\n  assert(Callee.isOrdinary() || Callee.isVirtual());\n\n  // Handle struct-return functions by passing a pointer to the\n  // location that we would like to return into.\n  QualType RetTy = CallInfo.getReturnType();\n  const ABIArgInfo &RetAI = CallInfo.getReturnInfo();\n\n  llvm::FunctionType *IRFuncTy = getTypes().GetFunctionType(CallInfo);\n\n  const Decl *TargetDecl = Callee.getAbstractInfo().getCalleeDecl().getDecl();\n  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(TargetDecl)) {\n    // We can only guarantee that a function is called from the correct\n    // context/function based on the appropriate target attributes,\n    // so only check in the case where we have both always_inline and target\n    // since otherwise we could be making a conditional call after a check for\n    // the proper cpu features (and it won't cause code generation issues due to\n    // function based code generation).\n    if (TargetDecl->hasAttr<AlwaysInlineAttr>() &&\n        TargetDecl->hasAttr<TargetAttr>())\n      checkTargetFeatures(Loc, FD);\n\n    // Some architectures (such as x86-64) have the ABI changed based on\n    // attribute-target/features. Give them a chance to diagnose.\n    CGM.getTargetCodeGenInfo().checkFunctionCallABI(\n        CGM, Loc, dyn_cast_or_null<FunctionDecl>(CurCodeDecl), FD, CallArgs);\n  }\n\n#ifndef NDEBUG\n  if (!(CallInfo.isVariadic() && CallInfo.getArgStruct())) {\n    // For an inalloca varargs function, we don't expect CallInfo to match the\n    // function pointer's type, because the inalloca struct a will have extra\n    // fields in it for the varargs parameters.  Code later in this function\n    // bitcasts the function pointer to the type derived from CallInfo.\n    //\n    // In other cases, we assert that the types match up (until pointers stop\n    // having pointee types).\n    llvm::Type *TypeFromVal;\n    if (Callee.isVirtual())\n      TypeFromVal = Callee.getVirtualFunctionType();\n    else\n      TypeFromVal =\n          Callee.getFunctionPointer()->getType()->getPointerElementType();\n    assert(IRFuncTy == TypeFromVal);\n  }\n#endif\n\n  // 1. Set up the arguments.\n\n  // If we're using inalloca, insert the allocation after the stack save.\n  // FIXME: Do this earlier rather than hacking it in here!\n  Address ArgMemory = Address::invalid();\n  if (llvm::StructType *ArgStruct = CallInfo.getArgStruct()) {\n    const llvm::DataLayout &DL = CGM.getDataLayout();\n    llvm::Instruction *IP = CallArgs.getStackBase();\n    llvm::AllocaInst *AI;\n    if (IP) {\n      IP = IP->getNextNode();\n      AI = new llvm::AllocaInst(ArgStruct, DL.getAllocaAddrSpace(),\n                                \"argmem\", IP);\n    } else {\n      AI = CreateTempAlloca(ArgStruct, \"argmem\");\n    }\n    auto Align = CallInfo.getArgStructAlignment();\n    AI->setAlignment(Align.getAsAlign());\n    AI->setUsedWithInAlloca(true);\n    assert(AI->isUsedWithInAlloca() && !AI->isStaticAlloca());\n    ArgMemory = Address(AI, Align);\n  }\n\n  ClangToLLVMArgMapping IRFunctionArgs(CGM.getContext(), CallInfo);\n  SmallVector<llvm::Value *, 16> IRCallArgs(IRFunctionArgs.totalIRArgs());\n\n  // If the call returns a temporary with struct return, create a temporary\n  // alloca to hold the result, unless one is given to us.\n  Address SRetPtr = Address::invalid();\n  Address SRetAlloca = Address::invalid();\n  llvm::Value *UnusedReturnSizePtr = nullptr;\n  if (RetAI.isIndirect() || RetAI.isInAlloca() || RetAI.isCoerceAndExpand()) {\n    if (!ReturnValue.isNull()) {\n      SRetPtr = ReturnValue.getValue();\n    } else {\n      SRetPtr = CreateMemTemp(RetTy, \"tmp\", &SRetAlloca);\n      if (HaveInsertPoint() && ReturnValue.isUnused()) {\n        uint64_t size =\n            CGM.getDataLayout().getTypeAllocSize(ConvertTypeForMem(RetTy));\n        UnusedReturnSizePtr = EmitLifetimeStart(size, SRetAlloca.getPointer());\n      }\n    }\n    if (IRFunctionArgs.hasSRetArg()) {\n      IRCallArgs[IRFunctionArgs.getSRetArgNo()] = SRetPtr.getPointer();\n    } else if (RetAI.isInAlloca()) {\n      Address Addr =\n          Builder.CreateStructGEP(ArgMemory, RetAI.getInAllocaFieldIndex());\n      Builder.CreateStore(SRetPtr.getPointer(), Addr);\n    }\n  }\n\n  Address swiftErrorTemp = Address::invalid();\n  Address swiftErrorArg = Address::invalid();\n\n  // When passing arguments using temporary allocas, we need to add the\n  // appropriate lifetime markers. This vector keeps track of all the lifetime\n  // markers that need to be ended right after the call.\n  SmallVector<CallLifetimeEnd, 2> CallLifetimeEndAfterCall;\n\n  // Translate all of the arguments as necessary to match the IR lowering.\n  assert(CallInfo.arg_size() == CallArgs.size() &&\n         \"Mismatch between function signature & arguments.\");\n  unsigned ArgNo = 0;\n  CGFunctionInfo::const_arg_iterator info_it = CallInfo.arg_begin();\n  for (CallArgList::const_iterator I = CallArgs.begin(), E = CallArgs.end();\n       I != E; ++I, ++info_it, ++ArgNo) {\n    const ABIArgInfo &ArgInfo = info_it->info;\n\n    // Insert a padding argument to ensure proper alignment.\n    if (IRFunctionArgs.hasPaddingArg(ArgNo))\n      IRCallArgs[IRFunctionArgs.getPaddingArgNo(ArgNo)] =\n          llvm::UndefValue::get(ArgInfo.getPaddingType());\n\n    unsigned FirstIRArg, NumIRArgs;\n    std::tie(FirstIRArg, NumIRArgs) = IRFunctionArgs.getIRArgs(ArgNo);\n\n    switch (ArgInfo.getKind()) {\n    case ABIArgInfo::InAlloca: {\n      assert(NumIRArgs == 0);\n      assert(getTarget().getTriple().getArch() == llvm::Triple::x86);\n      if (I->isAggregate()) {\n        Address Addr = I->hasLValue()\n                           ? I->getKnownLValue().getAddress(*this)\n                           : I->getKnownRValue().getAggregateAddress();\n        llvm::Instruction *Placeholder =\n            cast<llvm::Instruction>(Addr.getPointer());\n\n        if (!ArgInfo.getInAllocaIndirect()) {\n          // Replace the placeholder with the appropriate argument slot GEP.\n          CGBuilderTy::InsertPoint IP = Builder.saveIP();\n          Builder.SetInsertPoint(Placeholder);\n          Addr = Builder.CreateStructGEP(ArgMemory,\n                                         ArgInfo.getInAllocaFieldIndex());\n          Builder.restoreIP(IP);\n        } else {\n          // For indirect things such as overaligned structs, replace the\n          // placeholder with a regular aggregate temporary alloca. Store the\n          // address of this alloca into the struct.\n          Addr = CreateMemTemp(info_it->type, \"inalloca.indirect.tmp\");\n          Address ArgSlot = Builder.CreateStructGEP(\n              ArgMemory, ArgInfo.getInAllocaFieldIndex());\n          Builder.CreateStore(Addr.getPointer(), ArgSlot);\n        }\n        deferPlaceholderReplacement(Placeholder, Addr.getPointer());\n      } else if (ArgInfo.getInAllocaIndirect()) {\n        // Make a temporary alloca and store the address of it into the argument\n        // struct.\n        Address Addr = CreateMemTempWithoutCast(\n            I->Ty, getContext().getTypeAlignInChars(I->Ty),\n            \"indirect-arg-temp\");\n        I->copyInto(*this, Addr);\n        Address ArgSlot =\n            Builder.CreateStructGEP(ArgMemory, ArgInfo.getInAllocaFieldIndex());\n        Builder.CreateStore(Addr.getPointer(), ArgSlot);\n      } else {\n        // Store the RValue into the argument struct.\n        Address Addr =\n            Builder.CreateStructGEP(ArgMemory, ArgInfo.getInAllocaFieldIndex());\n        unsigned AS = Addr.getType()->getPointerAddressSpace();\n        llvm::Type *MemType = ConvertTypeForMem(I->Ty)->getPointerTo(AS);\n        // There are some cases where a trivial bitcast is not avoidable.  The\n        // definition of a type later in a translation unit may change it's type\n        // from {}* to (%struct.foo*)*.\n        if (Addr.getType() != MemType)\n          Addr = Builder.CreateBitCast(Addr, MemType);\n        I->copyInto(*this, Addr);\n      }\n      break;\n    }\n\n    case ABIArgInfo::Indirect:\n    case ABIArgInfo::IndirectAliased: {\n      assert(NumIRArgs == 1);\n      if (!I->isAggregate()) {\n        // Make a temporary alloca to pass the argument.\n        Address Addr = CreateMemTempWithoutCast(\n            I->Ty, ArgInfo.getIndirectAlign(), \"indirect-arg-temp\");\n        IRCallArgs[FirstIRArg] = Addr.getPointer();\n\n        I->copyInto(*this, Addr);\n      } else {\n        // We want to avoid creating an unnecessary temporary+copy here;\n        // however, we need one in three cases:\n        // 1. If the argument is not byval, and we are required to copy the\n        //    source.  (This case doesn't occur on any common architecture.)\n        // 2. If the argument is byval, RV is not sufficiently aligned, and\n        //    we cannot force it to be sufficiently aligned.\n        // 3. If the argument is byval, but RV is not located in default\n        //    or alloca address space.\n        Address Addr = I->hasLValue()\n                           ? I->getKnownLValue().getAddress(*this)\n                           : I->getKnownRValue().getAggregateAddress();\n        llvm::Value *V = Addr.getPointer();\n        CharUnits Align = ArgInfo.getIndirectAlign();\n        const llvm::DataLayout *TD = &CGM.getDataLayout();\n\n        assert((FirstIRArg >= IRFuncTy->getNumParams() ||\n                IRFuncTy->getParamType(FirstIRArg)->getPointerAddressSpace() ==\n                    TD->getAllocaAddrSpace()) &&\n               \"indirect argument must be in alloca address space\");\n\n        bool NeedCopy = false;\n\n        if (Addr.getAlignment() < Align &&\n            llvm::getOrEnforceKnownAlignment(V, Align.getAsAlign(), *TD) <\n                Align.getAsAlign()) {\n          NeedCopy = true;\n        } else if (I->hasLValue()) {\n          auto LV = I->getKnownLValue();\n          auto AS = LV.getAddressSpace();\n\n          if (!ArgInfo.getIndirectByVal() ||\n              (LV.getAlignment() < getContext().getTypeAlignInChars(I->Ty))) {\n            NeedCopy = true;\n          }\n          if (!getLangOpts().OpenCL) {\n            if ((ArgInfo.getIndirectByVal() &&\n                (AS != LangAS::Default &&\n                 AS != CGM.getASTAllocaAddressSpace()))) {\n              NeedCopy = true;\n            }\n          }\n          // For OpenCL even if RV is located in default or alloca address space\n          // we don't want to perform address space cast for it.\n          else if ((ArgInfo.getIndirectByVal() &&\n                    Addr.getType()->getAddressSpace() != IRFuncTy->\n                      getParamType(FirstIRArg)->getPointerAddressSpace())) {\n            NeedCopy = true;\n          }\n        }\n\n        if (NeedCopy) {\n          // Create an aligned temporary, and copy to it.\n          Address AI = CreateMemTempWithoutCast(\n              I->Ty, ArgInfo.getIndirectAlign(), \"byval-temp\");\n          IRCallArgs[FirstIRArg] = AI.getPointer();\n\n          // Emit lifetime markers for the temporary alloca.\n          uint64_t ByvalTempElementSize =\n              CGM.getDataLayout().getTypeAllocSize(AI.getElementType());\n          llvm::Value *LifetimeSize =\n              EmitLifetimeStart(ByvalTempElementSize, AI.getPointer());\n\n          // Add cleanup code to emit the end lifetime marker after the call.\n          if (LifetimeSize) // In case we disabled lifetime markers.\n            CallLifetimeEndAfterCall.emplace_back(AI, LifetimeSize);\n\n          // Generate the copy.\n          I->copyInto(*this, AI);\n        } else {\n          // Skip the extra memcpy call.\n          auto *T = V->getType()->getPointerElementType()->getPointerTo(\n              CGM.getDataLayout().getAllocaAddrSpace());\n          IRCallArgs[FirstIRArg] = getTargetHooks().performAddrSpaceCast(\n              *this, V, LangAS::Default, CGM.getASTAllocaAddressSpace(), T,\n              true);\n        }\n      }\n      break;\n    }\n\n    case ABIArgInfo::Ignore:\n      assert(NumIRArgs == 0);\n      break;\n\n    case ABIArgInfo::Extend:\n    case ABIArgInfo::Direct: {\n      if (!isa<llvm::StructType>(ArgInfo.getCoerceToType()) &&\n          ArgInfo.getCoerceToType() == ConvertType(info_it->type) &&\n          ArgInfo.getDirectOffset() == 0) {\n        assert(NumIRArgs == 1);\n        llvm::Value *V;\n        if (!I->isAggregate())\n          V = I->getKnownRValue().getScalarVal();\n        else\n          V = Builder.CreateLoad(\n              I->hasLValue() ? I->getKnownLValue().getAddress(*this)\n                             : I->getKnownRValue().getAggregateAddress());\n\n        // Implement swifterror by copying into a new swifterror argument.\n        // We'll write back in the normal path out of the call.\n        if (CallInfo.getExtParameterInfo(ArgNo).getABI()\n              == ParameterABI::SwiftErrorResult) {\n          assert(!swiftErrorTemp.isValid() && \"multiple swifterror args\");\n\n          QualType pointeeTy = I->Ty->getPointeeType();\n          swiftErrorArg =\n            Address(V, getContext().getTypeAlignInChars(pointeeTy));\n\n          swiftErrorTemp =\n            CreateMemTemp(pointeeTy, getPointerAlign(), \"swifterror.temp\");\n          V = swiftErrorTemp.getPointer();\n          cast<llvm::AllocaInst>(V)->setSwiftError(true);\n\n          llvm::Value *errorValue = Builder.CreateLoad(swiftErrorArg);\n          Builder.CreateStore(errorValue, swiftErrorTemp);\n        }\n\n        // We might have to widen integers, but we should never truncate.\n        if (ArgInfo.getCoerceToType() != V->getType() &&\n            V->getType()->isIntegerTy())\n          V = Builder.CreateZExt(V, ArgInfo.getCoerceToType());\n\n        // If the argument doesn't match, perform a bitcast to coerce it.  This\n        // can happen due to trivial type mismatches.\n        if (FirstIRArg < IRFuncTy->getNumParams() &&\n            V->getType() != IRFuncTy->getParamType(FirstIRArg))\n          V = Builder.CreateBitCast(V, IRFuncTy->getParamType(FirstIRArg));\n\n        IRCallArgs[FirstIRArg] = V;\n        break;\n      }\n\n      // FIXME: Avoid the conversion through memory if possible.\n      Address Src = Address::invalid();\n      if (!I->isAggregate()) {\n        Src = CreateMemTemp(I->Ty, \"coerce\");\n        I->copyInto(*this, Src);\n      } else {\n        Src = I->hasLValue() ? I->getKnownLValue().getAddress(*this)\n                             : I->getKnownRValue().getAggregateAddress();\n      }\n\n      // If the value is offset in memory, apply the offset now.\n      Src = emitAddressAtOffset(*this, Src, ArgInfo);\n\n      // Fast-isel and the optimizer generally like scalar values better than\n      // FCAs, so we flatten them if this is safe to do for this argument.\n      llvm::StructType *STy =\n            dyn_cast<llvm::StructType>(ArgInfo.getCoerceToType());\n      if (STy && ArgInfo.isDirect() && ArgInfo.getCanBeFlattened()) {\n        llvm::Type *SrcTy = Src.getElementType();\n        uint64_t SrcSize = CGM.getDataLayout().getTypeAllocSize(SrcTy);\n        uint64_t DstSize = CGM.getDataLayout().getTypeAllocSize(STy);\n\n        // If the source type is smaller than the destination type of the\n        // coerce-to logic, copy the source value into a temp alloca the size\n        // of the destination type to allow loading all of it. The bits past\n        // the source value are left undef.\n        if (SrcSize < DstSize) {\n          Address TempAlloca\n            = CreateTempAlloca(STy, Src.getAlignment(),\n                               Src.getName() + \".coerce\");\n          Builder.CreateMemCpy(TempAlloca, Src, SrcSize);\n          Src = TempAlloca;\n        } else {\n          Src = Builder.CreateBitCast(Src,\n                                      STy->getPointerTo(Src.getAddressSpace()));\n        }\n\n        assert(NumIRArgs == STy->getNumElements());\n        for (unsigned i = 0, e = STy->getNumElements(); i != e; ++i) {\n          Address EltPtr = Builder.CreateStructGEP(Src, i);\n          llvm::Value *LI = Builder.CreateLoad(EltPtr);\n          IRCallArgs[FirstIRArg + i] = LI;\n        }\n      } else {\n        // In the simple case, just pass the coerced loaded value.\n        assert(NumIRArgs == 1);\n        llvm::Value *Load =\n            CreateCoercedLoad(Src, ArgInfo.getCoerceToType(), *this);\n\n        if (CallInfo.isCmseNSCall()) {\n          // For certain parameter types, clear padding bits, as they may reveal\n          // sensitive information.\n          // Small struct/union types are passed as integer arrays.\n          auto *ATy = dyn_cast<llvm::ArrayType>(Load->getType());\n          if (ATy != nullptr && isa<RecordType>(I->Ty.getCanonicalType()))\n            Load = EmitCMSEClearRecord(Load, ATy, I->Ty);\n        }\n        IRCallArgs[FirstIRArg] = Load;\n      }\n\n      break;\n    }\n\n    case ABIArgInfo::CoerceAndExpand: {\n      auto coercionType = ArgInfo.getCoerceAndExpandType();\n      auto layout = CGM.getDataLayout().getStructLayout(coercionType);\n\n      llvm::Value *tempSize = nullptr;\n      Address addr = Address::invalid();\n      Address AllocaAddr = Address::invalid();\n      if (I->isAggregate()) {\n        addr = I->hasLValue() ? I->getKnownLValue().getAddress(*this)\n                              : I->getKnownRValue().getAggregateAddress();\n\n      } else {\n        RValue RV = I->getKnownRValue();\n        assert(RV.isScalar()); // complex should always just be direct\n\n        llvm::Type *scalarType = RV.getScalarVal()->getType();\n        auto scalarSize = CGM.getDataLayout().getTypeAllocSize(scalarType);\n        auto scalarAlign = CGM.getDataLayout().getPrefTypeAlignment(scalarType);\n\n        // Materialize to a temporary.\n        addr = CreateTempAlloca(\n            RV.getScalarVal()->getType(),\n            CharUnits::fromQuantity(std::max(\n                (unsigned)layout->getAlignment().value(), scalarAlign)),\n            \"tmp\",\n            /*ArraySize=*/nullptr, &AllocaAddr);\n        tempSize = EmitLifetimeStart(scalarSize, AllocaAddr.getPointer());\n\n        Builder.CreateStore(RV.getScalarVal(), addr);\n      }\n\n      addr = Builder.CreateElementBitCast(addr, coercionType);\n\n      unsigned IRArgPos = FirstIRArg;\n      for (unsigned i = 0, e = coercionType->getNumElements(); i != e; ++i) {\n        llvm::Type *eltType = coercionType->getElementType(i);\n        if (ABIArgInfo::isPaddingForCoerceAndExpand(eltType)) continue;\n        Address eltAddr = Builder.CreateStructGEP(addr, i);\n        llvm::Value *elt = Builder.CreateLoad(eltAddr);\n        IRCallArgs[IRArgPos++] = elt;\n      }\n      assert(IRArgPos == FirstIRArg + NumIRArgs);\n\n      if (tempSize) {\n        EmitLifetimeEnd(tempSize, AllocaAddr.getPointer());\n      }\n\n      break;\n    }\n\n    case ABIArgInfo::Expand: {\n      unsigned IRArgPos = FirstIRArg;\n      ExpandTypeToArgs(I->Ty, *I, IRFuncTy, IRCallArgs, IRArgPos);\n      assert(IRArgPos == FirstIRArg + NumIRArgs);\n      break;\n    }\n    }\n  }\n\n  const CGCallee &ConcreteCallee = Callee.prepareConcreteCallee(*this);\n  llvm::Value *CalleePtr = ConcreteCallee.getFunctionPointer();\n\n  // If we're using inalloca, set up that argument.\n  if (ArgMemory.isValid()) {\n    llvm::Value *Arg = ArgMemory.getPointer();\n    if (CallInfo.isVariadic()) {\n      // When passing non-POD arguments by value to variadic functions, we will\n      // end up with a variadic prototype and an inalloca call site.  In such\n      // cases, we can't do any parameter mismatch checks.  Give up and bitcast\n      // the callee.\n      unsigned CalleeAS = CalleePtr->getType()->getPointerAddressSpace();\n      CalleePtr =\n          Builder.CreateBitCast(CalleePtr, IRFuncTy->getPointerTo(CalleeAS));\n    } else {\n      llvm::Type *LastParamTy =\n          IRFuncTy->getParamType(IRFuncTy->getNumParams() - 1);\n      if (Arg->getType() != LastParamTy) {\n#ifndef NDEBUG\n        // Assert that these structs have equivalent element types.\n        llvm::StructType *FullTy = CallInfo.getArgStruct();\n        llvm::StructType *DeclaredTy = cast<llvm::StructType>(\n            cast<llvm::PointerType>(LastParamTy)->getElementType());\n        assert(DeclaredTy->getNumElements() == FullTy->getNumElements());\n        for (llvm::StructType::element_iterator DI = DeclaredTy->element_begin(),\n                                                DE = DeclaredTy->element_end(),\n                                                FI = FullTy->element_begin();\n             DI != DE; ++DI, ++FI)\n          assert(*DI == *FI);\n#endif\n        Arg = Builder.CreateBitCast(Arg, LastParamTy);\n      }\n    }\n    assert(IRFunctionArgs.hasInallocaArg());\n    IRCallArgs[IRFunctionArgs.getInallocaArgNo()] = Arg;\n  }\n\n  // 2. Prepare the function pointer.\n\n  // If the callee is a bitcast of a non-variadic function to have a\n  // variadic function pointer type, check to see if we can remove the\n  // bitcast.  This comes up with unprototyped functions.\n  //\n  // This makes the IR nicer, but more importantly it ensures that we\n  // can inline the function at -O0 if it is marked always_inline.\n  auto simplifyVariadicCallee = [](llvm::FunctionType *CalleeFT,\n                                   llvm::Value *Ptr) -> llvm::Function * {\n    if (!CalleeFT->isVarArg())\n      return nullptr;\n\n    // Get underlying value if it's a bitcast\n    if (llvm::ConstantExpr *CE = dyn_cast<llvm::ConstantExpr>(Ptr)) {\n      if (CE->getOpcode() == llvm::Instruction::BitCast)\n        Ptr = CE->getOperand(0);\n    }\n\n    llvm::Function *OrigFn = dyn_cast<llvm::Function>(Ptr);\n    if (!OrigFn)\n      return nullptr;\n\n    llvm::FunctionType *OrigFT = OrigFn->getFunctionType();\n\n    // If the original type is variadic, or if any of the component types\n    // disagree, we cannot remove the cast.\n    if (OrigFT->isVarArg() ||\n        OrigFT->getNumParams() != CalleeFT->getNumParams() ||\n        OrigFT->getReturnType() != CalleeFT->getReturnType())\n      return nullptr;\n\n    for (unsigned i = 0, e = OrigFT->getNumParams(); i != e; ++i)\n      if (OrigFT->getParamType(i) != CalleeFT->getParamType(i))\n        return nullptr;\n\n    return OrigFn;\n  };\n\n  if (llvm::Function *OrigFn = simplifyVariadicCallee(IRFuncTy, CalleePtr)) {\n    CalleePtr = OrigFn;\n    IRFuncTy = OrigFn->getFunctionType();\n  }\n\n  // 3. Perform the actual call.\n\n  // Deactivate any cleanups that we're supposed to do immediately before\n  // the call.\n  if (!CallArgs.getCleanupsToDeactivate().empty())\n    deactivateArgCleanupsBeforeCall(*this, CallArgs);\n\n  // Assert that the arguments we computed match up.  The IR verifier\n  // will catch this, but this is a common enough source of problems\n  // during IRGen changes that it's way better for debugging to catch\n  // it ourselves here.\n#ifndef NDEBUG\n  assert(IRCallArgs.size() == IRFuncTy->getNumParams() || IRFuncTy->isVarArg());\n  for (unsigned i = 0; i < IRCallArgs.size(); ++i) {\n    // Inalloca argument can have different type.\n    if (IRFunctionArgs.hasInallocaArg() &&\n        i == IRFunctionArgs.getInallocaArgNo())\n      continue;\n    if (i < IRFuncTy->getNumParams())\n      assert(IRCallArgs[i]->getType() == IRFuncTy->getParamType(i));\n  }\n#endif\n\n  // Update the largest vector width if any arguments have vector types.\n  for (unsigned i = 0; i < IRCallArgs.size(); ++i) {\n    if (auto *VT = dyn_cast<llvm::VectorType>(IRCallArgs[i]->getType()))\n      LargestVectorWidth =\n          std::max((uint64_t)LargestVectorWidth,\n                   VT->getPrimitiveSizeInBits().getKnownMinSize());\n  }\n\n  // Compute the calling convention and attributes.\n  unsigned CallingConv;\n  llvm::AttributeList Attrs;\n  CGM.ConstructAttributeList(CalleePtr->getName(), CallInfo,\n                             Callee.getAbstractInfo(), Attrs, CallingConv,\n                             /*AttrOnCallSite=*/true);\n\n  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(CurFuncDecl))\n    if (FD->hasAttr<StrictFPAttr>())\n      // All calls within a strictfp function are marked strictfp\n      Attrs =\n        Attrs.addAttribute(getLLVMContext(), llvm::AttributeList::FunctionIndex,\n                           llvm::Attribute::StrictFP);\n\n  // Add call-site nomerge attribute if exists.\n  if (InNoMergeAttributedStmt)\n    Attrs =\n        Attrs.addAttribute(getLLVMContext(), llvm::AttributeList::FunctionIndex,\n                           llvm::Attribute::NoMerge);\n\n  // Apply some call-site-specific attributes.\n  // TODO: work this into building the attribute set.\n\n  // Apply always_inline to all calls within flatten functions.\n  // FIXME: should this really take priority over __try, below?\n  if (CurCodeDecl && CurCodeDecl->hasAttr<FlattenAttr>() &&\n      !(TargetDecl && TargetDecl->hasAttr<NoInlineAttr>())) {\n    Attrs =\n        Attrs.addAttribute(getLLVMContext(), llvm::AttributeList::FunctionIndex,\n                           llvm::Attribute::AlwaysInline);\n  }\n\n  // Disable inlining inside SEH __try blocks.\n  if (isSEHTryScope()) {\n    Attrs =\n        Attrs.addAttribute(getLLVMContext(), llvm::AttributeList::FunctionIndex,\n                           llvm::Attribute::NoInline);\n  }\n\n  // Decide whether to use a call or an invoke.\n  bool CannotThrow;\n  if (currentFunctionUsesSEHTry()) {\n    // SEH cares about asynchronous exceptions, so everything can \"throw.\"\n    CannotThrow = false;\n  } else if (isCleanupPadScope() &&\n             EHPersonality::get(*this).isMSVCXXPersonality()) {\n    // The MSVC++ personality will implicitly terminate the program if an\n    // exception is thrown during a cleanup outside of a try/catch.\n    // We don't need to model anything in IR to get this behavior.\n    CannotThrow = true;\n  } else {\n    // Otherwise, nounwind call sites will never throw.\n    CannotThrow = Attrs.hasFnAttribute(llvm::Attribute::NoUnwind);\n\n    if (auto *FPtr = dyn_cast<llvm::Function>(CalleePtr))\n      if (FPtr->hasFnAttribute(llvm::Attribute::NoUnwind))\n        CannotThrow = true;\n  }\n\n  // If we made a temporary, be sure to clean up after ourselves. Note that we\n  // can't depend on being inside of an ExprWithCleanups, so we need to manually\n  // pop this cleanup later on. Being eager about this is OK, since this\n  // temporary is 'invisible' outside of the callee.\n  if (UnusedReturnSizePtr)\n    pushFullExprCleanup<CallLifetimeEnd>(NormalEHLifetimeMarker, SRetAlloca,\n                                         UnusedReturnSizePtr);\n\n  llvm::BasicBlock *InvokeDest = CannotThrow ? nullptr : getInvokeDest();\n\n  SmallVector<llvm::OperandBundleDef, 1> BundleList =\n      getBundlesForFunclet(CalleePtr);\n\n  if (const FunctionDecl *FD = dyn_cast_or_null<FunctionDecl>(CurFuncDecl))\n    if (FD->hasAttr<StrictFPAttr>())\n      // All calls within a strictfp function are marked strictfp\n      Attrs =\n        Attrs.addAttribute(getLLVMContext(), llvm::AttributeList::FunctionIndex,\n                           llvm::Attribute::StrictFP);\n\n  AssumeAlignedAttrEmitter AssumeAlignedAttrEmitter(*this, TargetDecl);\n  Attrs = AssumeAlignedAttrEmitter.TryEmitAsCallSiteAttribute(Attrs);\n\n  AllocAlignAttrEmitter AllocAlignAttrEmitter(*this, TargetDecl, CallArgs);\n  Attrs = AllocAlignAttrEmitter.TryEmitAsCallSiteAttribute(Attrs);\n\n  // Emit the actual call/invoke instruction.\n  llvm::CallBase *CI;\n  if (!InvokeDest) {\n    CI = Builder.CreateCall(IRFuncTy, CalleePtr, IRCallArgs, BundleList);\n  } else {\n    llvm::BasicBlock *Cont = createBasicBlock(\"invoke.cont\");\n    CI = Builder.CreateInvoke(IRFuncTy, CalleePtr, Cont, InvokeDest, IRCallArgs,\n                              BundleList);\n    EmitBlock(Cont);\n  }\n  if (callOrInvoke)\n    *callOrInvoke = CI;\n\n  // If this is within a function that has the guard(nocf) attribute and is an\n  // indirect call, add the \"guard_nocf\" attribute to this call to indicate that\n  // Control Flow Guard checks should not be added, even if the call is inlined.\n  if (const auto *FD = dyn_cast_or_null<FunctionDecl>(CurFuncDecl)) {\n    if (const auto *A = FD->getAttr<CFGuardAttr>()) {\n      if (A->getGuard() == CFGuardAttr::GuardArg::nocf && !CI->getCalledFunction())\n        Attrs = Attrs.addAttribute(\n            getLLVMContext(), llvm::AttributeList::FunctionIndex, \"guard_nocf\");\n    }\n  }\n\n  // Apply the attributes and calling convention.\n  CI->setAttributes(Attrs);\n  CI->setCallingConv(static_cast<llvm::CallingConv::ID>(CallingConv));\n\n  // Apply various metadata.\n\n  if (!CI->getType()->isVoidTy())\n    CI->setName(\"call\");\n\n  // Update largest vector width from the return type.\n  if (auto *VT = dyn_cast<llvm::VectorType>(CI->getType()))\n    LargestVectorWidth =\n        std::max((uint64_t)LargestVectorWidth,\n                 VT->getPrimitiveSizeInBits().getKnownMinSize());\n\n  // Insert instrumentation or attach profile metadata at indirect call sites.\n  // For more details, see the comment before the definition of\n  // IPVK_IndirectCallTarget in InstrProfData.inc.\n  if (!CI->getCalledFunction())\n    PGO.valueProfile(Builder, llvm::IPVK_IndirectCallTarget,\n                     CI, CalleePtr);\n\n  // In ObjC ARC mode with no ObjC ARC exception safety, tell the ARC\n  // optimizer it can aggressively ignore unwind edges.\n  if (CGM.getLangOpts().ObjCAutoRefCount)\n    AddObjCARCExceptionMetadata(CI);\n\n  // Suppress tail calls if requested.\n  if (llvm::CallInst *Call = dyn_cast<llvm::CallInst>(CI)) {\n    if (TargetDecl && TargetDecl->hasAttr<NotTailCalledAttr>())\n      Call->setTailCallKind(llvm::CallInst::TCK_NoTail);\n  }\n\n  // Add metadata for calls to MSAllocator functions\n  if (getDebugInfo() && TargetDecl &&\n      TargetDecl->hasAttr<MSAllocatorAttr>())\n    getDebugInfo()->addHeapAllocSiteMetadata(CI, RetTy->getPointeeType(), Loc);\n\n  // 4. Finish the call.\n\n  // If the call doesn't return, finish the basic block and clear the\n  // insertion point; this allows the rest of IRGen to discard\n  // unreachable code.\n  if (CI->doesNotReturn()) {\n    if (UnusedReturnSizePtr)\n      PopCleanupBlock();\n\n    // Strip away the noreturn attribute to better diagnose unreachable UB.\n    if (SanOpts.has(SanitizerKind::Unreachable)) {\n      // Also remove from function since CallBase::hasFnAttr additionally checks\n      // attributes of the called function.\n      if (auto *F = CI->getCalledFunction())\n        F->removeFnAttr(llvm::Attribute::NoReturn);\n      CI->removeAttribute(llvm::AttributeList::FunctionIndex,\n                          llvm::Attribute::NoReturn);\n\n      // Avoid incompatibility with ASan which relies on the `noreturn`\n      // attribute to insert handler calls.\n      if (SanOpts.hasOneOf(SanitizerKind::Address |\n                           SanitizerKind::KernelAddress)) {\n        SanitizerScope SanScope(this);\n        llvm::IRBuilder<>::InsertPointGuard IPGuard(Builder);\n        Builder.SetInsertPoint(CI);\n        auto *FnType = llvm::FunctionType::get(CGM.VoidTy, /*isVarArg=*/false);\n        llvm::FunctionCallee Fn =\n            CGM.CreateRuntimeFunction(FnType, \"__asan_handle_no_return\");\n        EmitNounwindRuntimeCall(Fn);\n      }\n    }\n\n    EmitUnreachable(Loc);\n    Builder.ClearInsertionPoint();\n\n    // FIXME: For now, emit a dummy basic block because expr emitters in\n    // generally are not ready to handle emitting expressions at unreachable\n    // points.\n    EnsureInsertPoint();\n\n    // Return a reasonable RValue.\n    return GetUndefRValue(RetTy);\n  }\n\n  // Perform the swifterror writeback.\n  if (swiftErrorTemp.isValid()) {\n    llvm::Value *errorResult = Builder.CreateLoad(swiftErrorTemp);\n    Builder.CreateStore(errorResult, swiftErrorArg);\n  }\n\n  // Emit any call-associated writebacks immediately.  Arguably this\n  // should happen after any return-value munging.\n  if (CallArgs.hasWritebacks())\n    emitWritebacks(*this, CallArgs);\n\n  // The stack cleanup for inalloca arguments has to run out of the normal\n  // lexical order, so deactivate it and run it manually here.\n  CallArgs.freeArgumentMemory(*this);\n\n  // Extract the return value.\n  RValue Ret = [&] {\n    switch (RetAI.getKind()) {\n    case ABIArgInfo::CoerceAndExpand: {\n      auto coercionType = RetAI.getCoerceAndExpandType();\n\n      Address addr = SRetPtr;\n      addr = Builder.CreateElementBitCast(addr, coercionType);\n\n      assert(CI->getType() == RetAI.getUnpaddedCoerceAndExpandType());\n      bool requiresExtract = isa<llvm::StructType>(CI->getType());\n\n      unsigned unpaddedIndex = 0;\n      for (unsigned i = 0, e = coercionType->getNumElements(); i != e; ++i) {\n        llvm::Type *eltType = coercionType->getElementType(i);\n        if (ABIArgInfo::isPaddingForCoerceAndExpand(eltType)) continue;\n        Address eltAddr = Builder.CreateStructGEP(addr, i);\n        llvm::Value *elt = CI;\n        if (requiresExtract)\n          elt = Builder.CreateExtractValue(elt, unpaddedIndex++);\n        else\n          assert(unpaddedIndex == 0);\n        Builder.CreateStore(elt, eltAddr);\n      }\n      // FALLTHROUGH\n      LLVM_FALLTHROUGH;\n    }\n\n    case ABIArgInfo::InAlloca:\n    case ABIArgInfo::Indirect: {\n      RValue ret = convertTempToRValue(SRetPtr, RetTy, SourceLocation());\n      if (UnusedReturnSizePtr)\n        PopCleanupBlock();\n      return ret;\n    }\n\n    case ABIArgInfo::Ignore:\n      // If we are ignoring an argument that had a result, make sure to\n      // construct the appropriate return value for our caller.\n      return GetUndefRValue(RetTy);\n\n    case ABIArgInfo::Extend:\n    case ABIArgInfo::Direct: {\n      llvm::Type *RetIRTy = ConvertType(RetTy);\n      if (RetAI.getCoerceToType() == RetIRTy && RetAI.getDirectOffset() == 0) {\n        switch (getEvaluationKind(RetTy)) {\n        case TEK_Complex: {\n          llvm::Value *Real = Builder.CreateExtractValue(CI, 0);\n          llvm::Value *Imag = Builder.CreateExtractValue(CI, 1);\n          return RValue::getComplex(std::make_pair(Real, Imag));\n        }\n        case TEK_Aggregate: {\n          Address DestPtr = ReturnValue.getValue();\n          bool DestIsVolatile = ReturnValue.isVolatile();\n\n          if (!DestPtr.isValid()) {\n            DestPtr = CreateMemTemp(RetTy, \"agg.tmp\");\n            DestIsVolatile = false;\n          }\n          EmitAggregateStore(CI, DestPtr, DestIsVolatile);\n          return RValue::getAggregate(DestPtr);\n        }\n        case TEK_Scalar: {\n          // If the argument doesn't match, perform a bitcast to coerce it.  This\n          // can happen due to trivial type mismatches.\n          llvm::Value *V = CI;\n          if (V->getType() != RetIRTy)\n            V = Builder.CreateBitCast(V, RetIRTy);\n          return RValue::get(V);\n        }\n        }\n        llvm_unreachable(\"bad evaluation kind\");\n      }\n\n      Address DestPtr = ReturnValue.getValue();\n      bool DestIsVolatile = ReturnValue.isVolatile();\n\n      if (!DestPtr.isValid()) {\n        DestPtr = CreateMemTemp(RetTy, \"coerce\");\n        DestIsVolatile = false;\n      }\n\n      // If the value is offset in memory, apply the offset now.\n      Address StorePtr = emitAddressAtOffset(*this, DestPtr, RetAI);\n      CreateCoercedStore(CI, StorePtr, DestIsVolatile, *this);\n\n      return convertTempToRValue(DestPtr, RetTy, SourceLocation());\n    }\n\n    case ABIArgInfo::Expand:\n    case ABIArgInfo::IndirectAliased:\n      llvm_unreachable(\"Invalid ABI kind for return argument\");\n    }\n\n    llvm_unreachable(\"Unhandled ABIArgInfo::Kind\");\n  } ();\n\n  // Emit the assume_aligned check on the return value.\n  if (Ret.isScalar() && TargetDecl) {\n    AssumeAlignedAttrEmitter.EmitAsAnAssumption(Loc, RetTy, Ret);\n    AllocAlignAttrEmitter.EmitAsAnAssumption(Loc, RetTy, Ret);\n  }\n\n  // Explicitly call CallLifetimeEnd::Emit just to re-use the code even though\n  // we can't use the full cleanup mechanism.\n  for (CallLifetimeEnd &LifetimeEnd : CallLifetimeEndAfterCall)\n    LifetimeEnd.Emit(*this, /*Flags=*/{});\n\n  if (!ReturnValue.isExternallyDestructed() &&\n      RetTy.isDestructedType() == QualType::DK_nontrivial_c_struct)\n    pushDestroy(QualType::DK_nontrivial_c_struct, Ret.getAggregateAddress(),\n                RetTy);\n\n  return Ret;\n}\n\nCGCallee CGCallee::prepareConcreteCallee(CodeGenFunction &CGF) const {\n  if (isVirtual()) {\n    const CallExpr *CE = getVirtualCallExpr();\n    return CGF.CGM.getCXXABI().getVirtualFunctionPointer(\n        CGF, getVirtualMethodDecl(), getThisAddress(), getVirtualFunctionType(),\n        CE ? CE->getBeginLoc() : SourceLocation());\n  }\n\n  return *this;\n}\n\n/* VarArg handling */\n\nAddress CodeGenFunction::EmitVAArg(VAArgExpr *VE, Address &VAListAddr) {\n  VAListAddr = VE->isMicrosoftABI()\n                 ? EmitMSVAListRef(VE->getSubExpr())\n                 : EmitVAListRef(VE->getSubExpr());\n  QualType Ty = VE->getType();\n  if (VE->isMicrosoftABI())\n    return CGM.getTypes().getABIInfo().EmitMSVAArg(*this, VAListAddr, Ty);\n  return CGM.getTypes().getABIInfo().EmitVAArg(*this, VAListAddr, Ty);\n}\n"}}, "reports": [{"events": [{"location": {"col": 9, "file": 21, "line": 3652}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/Type.h", "reportHash": "912c0c107de9f8685289a15d5813f7ba", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 35, "line": 461}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/CodeGen/CGFunctionInfo.h", "reportHash": "2f322c1ce68365b0d75a27afcfcdd391", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 38, "line": 866}, "message": "destructor '~ConstantArrayExpansion' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "ec5e239d99b9f69363a30d746332c28c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 38, "line": 877}, "message": "destructor '~RecordExpansion' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "a88aa9ea0c14367dd0b538c2a09520d9", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 38, "line": 891}, "message": "destructor '~ComplexExpansion' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "b3f3cca951f77ab85ebeed8dc3faca81", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 38, "line": 900}, "message": "destructor '~NoExpansion' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "9467c3866f5b62ded6535cfb1883dec2", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 27, "file": 38, "line": 1886}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "5876abc656f755194a96a9429609a1ab", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 27, "file": 38, "line": 1886}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "bda420bc1034c48c727ecdb750521615", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 35, "file": 38, "line": 2169}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "13ae3f551b2d2ed3aa7a19842e0f5ade", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 35, "file": 38, "line": 2169}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "40444024547309a751fa4ada542c3806", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 38, "line": 3115}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "57e85ebe3a747d92fb7c4c709fc41343", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 26, "file": 38, "line": 3115}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "7dab65d97cc18c85db3e053e671d2934", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 38, "file": 38, "line": 4098}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "97e1c2cd8f9f76aebb6e1caaa02161ee", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 38, "file": 38, "line": 4098}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "80d6cbe0aae247abf791884c61ee2eb1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 33, "file": 38, "line": 5052}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "68c9878c7f82b42711aa3a35c06c8786", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 33, "file": 38, "line": 5052}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.cpp", "reportHash": "4c583c676b81979c045f976b9982912b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
