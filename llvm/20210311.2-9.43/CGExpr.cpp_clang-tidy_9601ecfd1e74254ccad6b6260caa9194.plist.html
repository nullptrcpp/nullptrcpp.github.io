<!DOCTYPE html>
<html>
  <head>
    <title>Plist HTML Viewer</title>

    <meta charset="UTF-8">

    <style type="text/css">
      .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.CodeMirror-lines{padding:4px 0}.CodeMirror pre{padding:0 4px}.CodeMirror-gutter-filler,.CodeMirror-scrollbar-filler{background-color:#fff}.CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.CodeMirror-guttermarker{color:#000}.CodeMirror-guttermarker-subtle{color:#999}.CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.cm-fat-cursor div.CodeMirror-cursors{z-index:1}.cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.cm-tab{display:inline-block;text-decoration:inherit}.CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:-20px;overflow:hidden}.CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.cm-s-default .cm-header{color:#00f}.cm-s-default .cm-quote{color:#090}.cm-negative{color:#d44}.cm-positive{color:#292}.cm-header,.cm-strong{font-weight:700}.cm-em{font-style:italic}.cm-link{text-decoration:underline}.cm-strikethrough{text-decoration:line-through}.cm-s-default .cm-keyword{color:#708}.cm-s-default .cm-atom{color:#219}.cm-s-default .cm-number{color:#164}.cm-s-default .cm-def{color:#00f}.cm-s-default .cm-variable-2{color:#05a}.cm-s-default .cm-type,.cm-s-default .cm-variable-3{color:#085}.cm-s-default .cm-comment{color:#a50}.cm-s-default .cm-string{color:#a11}.cm-s-default .cm-string-2{color:#f50}.cm-s-default .cm-meta{color:#555}.cm-s-default .cm-qualifier{color:#555}.cm-s-default .cm-builtin{color:#30a}.cm-s-default .cm-bracket{color:#997}.cm-s-default .cm-tag{color:#170}.cm-s-default .cm-attribute{color:#00c}.cm-s-default .cm-hr{color:#999}.cm-s-default .cm-link{color:#00c}.cm-s-default .cm-error{color:red}.cm-invalidchar{color:red}.CodeMirror-composing{border-bottom:2px solid}div.CodeMirror span.CodeMirror-matchingbracket{color:#0f0}div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#f22}.CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.CodeMirror-activeline-background{background:#e8f2ff}.CodeMirror{position:relative;overflow:hidden;background:#fff}.CodeMirror-scroll{overflow:scroll!important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:0;position:relative}.CodeMirror-sizer{position:relative;border-right:30px solid transparent}.CodeMirror-gutter-filler,.CodeMirror-hscrollbar,.CodeMirror-scrollbar-filler,.CodeMirror-vscrollbar{position:absolute;z-index:6;display:none}.CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.CodeMirror-scrollbar-filler{right:0;bottom:0}.CodeMirror-gutter-filler{left:0;bottom:0}.CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:0 0!important;border:none!important}.CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.CodeMirror-gutter-wrapper ::selection{background-color:transparent}.CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.CodeMirror-lines{cursor:text;min-height:1px}.CodeMirror pre{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:0 0;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.CodeMirror-wrap pre{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.CodeMirror-linewidget{position:relative;z-index:2;overflow:auto}.CodeMirror-rtl pre{direction:rtl}.CodeMirror-code{outline:0}.CodeMirror-gutter,.CodeMirror-gutters,.CodeMirror-linenumber,.CodeMirror-scroll,.CodeMirror-sizer{-moz-box-sizing:content-box;box-sizing:content-box}.CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.CodeMirror-cursor{position:absolute;pointer-events:none}.CodeMirror-measure pre{position:static}div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}div.CodeMirror-dragcursors{visibility:visible}.CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.CodeMirror-selected{background:#d9d9d9}.CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.CodeMirror-crosshair{cursor:crosshair}.CodeMirror-line::selection,.CodeMirror-line>span::selection,.CodeMirror-line>span>span::selection{background:#d7d4f0}.CodeMirror-line::-moz-selection,.CodeMirror-line>span::-moz-selection,.CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.cm-force-border{padding-right:.1px}@media print{.CodeMirror div.CodeMirror-cursors{visibility:hidden}}.cm-tab-wrap-hack:after{content:''}span.CodeMirror-selectedtext{background:0 0}
/*# sourceMappingURL=codemirror.min.css.map */

      .severity-low {
  background-color: #669603;
}

.severity-low:after {
  content : 'L';
}

.severity-unspecified {
  background-color: #666666;
}

.severity-unspecified:after {
  content : 'U';
}

.severity-style {
  background-color: #9932cc;
}

.severity-style:after {
  content : 'S';
}

.severity-medium {
  background-color: #a9d323;
  color: black;
}

.severity-medium:after {
  content : 'M';
}

.severity-high {
  background-color: #ffa800;
}

.severity-high:after {
  content : 'H';
}

.severity-critical {
  background-color: #e92625;
}

.severity-critical:after {
  content : 'C';
}

i[class*="severity-"] {
  line-height: normal;
  text-transform: capitalize;
  font-size: 0.8em;
  font-weight: bold;
  color: white;
  display: inline-block;
  width: 16px;
  height: 16px;
  text-align: center;
  font-family: sans-serif;
}

      html, body {
  width: 100%;
  height: 100%;
  padding: 0px;
  margin: 0px;
}

div.container {
  padding: 10px;
}

#content {
  height: 100%;
  display: block;
  overflow: hidden;
}

#content > div {
  margin: 10px;
  overflow: hidden;
  border: 1px solid #ddd;
  border-radius: 3px;
  overflow: hidden;
  height: 97%;
}

.button {
  background-color: #f1f1f1;
  text-decoration: none;
  display: inline-block;
  padding: 8px 16px;
  color: black;
  cursor: pointer;
}

.button:hover {
  background-color: #ddd;
  color: black;
}

.review-status {
  color: white;
  text-align: center;
}

.review-status-confirmed {
  background-color: #e92625;
}

.review-status-false-positive {
  background-color: grey;
}

.review-status-intentional {
  background-color: #669603;
}

      div.container {
  width: 100%;
  height: 100%;
  padding: 0px;
}

#editor-wrapper {
  margin: 10px;
}

#side-bar {
  float: left;
  width: 260px;
  margin: 0px;
}

#report-nav ul {
  list-style-type: none;
  padding: 0;
  margin: 0;
  overflow-y: auto;
  height: 100%;
}

#report-nav ul > li {
  padding: .4em;
  background-color: #fff;
  border-bottom: 1px solid rgba(0,0,0,.125);
  text-align: left;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

#report-nav ul > li.active {
  background-color: #427ea9;
  color: white;
}

#report-nav ul > li:hover {
  background-color: #427ea9;
  color: white;
  cursor: pointer;
}

#report-nav ul a {
  text-decoration: none;
}

#report-nav i[class*="severity-"] {
  margin-right: 5px;
}

.header {
  border-bottom: 1px solid lightgrey;
  font-family: monospace;
  padding: 10px;
  background-color: #fafbfc;
  border-bottom: 1px solid #e1e4e8;
  border-top-left-radius: 2px;
  border-top-right-radius: 2px;
}

#report-nav .header {
  font-weight: bold;
}

#editor-wrapper .header > div {
  padding-top: 2px;
}

#file-path,
#checker-name {
  color: #195ea2;
}

#review-status {
  padding: 0px 5px;
}

#file-path {
  font-family: monospace;
}

.check-msg {
  display: inline-block;
  padding: 3px 6px;
  margin: 1px;
  -webkit-border-radius: 5px;
  -moz-border-radius: 5px;
  border-radius: 5px;
}

.check-msg.info {
  color: #00546f;
  background-color: #bfdfe9;
  border: 1px solid #87a8b3;
}

.check-msg.error {
  background-color: #f2dede;
  color: #a94442;
  border: 1px solid #ebcccc;
}

.check-msg.macro {
  background-color: #d7dac2;
  color: #4f5c6d;
  border: 1px solid #d7dac2;
}

.check-msg.note {
  background-color: #d7d7d7;
  color: #4f5c6d;
  border: 1px solid #bfbfbf;
}

.check-msg.current {
  border: 2px dashed #3692ff;
}

.check-msg .tag {
  padding: 1px 5px;
  text-align: center;
  border-radius: 2px;
  margin-right: 5px;
  text-decoration: inherit;
}

.check-msg .tag.macro {
  background-color: #83876a;
  color: white;
  text-transform: capitalize;
}

.check-msg .tag.note {
  background-color: #9299a1;
  color: white;
  text-transform: capitalize;
}

.checker-enum {
  color: white;
  padding: 1px 5px;
  text-align: center;
  border-radius: 25px;
  margin-right: 5px;
  text-decoration: inherit;
}

.checker-enum.info {
  background-color: #427ea9;
}

.checker-enum.error {
  background-color: #a94442;
}

.arrow {
  border: solid black;
  border-width: 0 3px 3px 0;
  display: inline-block;
  padding: 3px;
  cursor: pointer;
  margin: 0px 5px;
}

.arrow:hover {
  border: solid #437ea8;
  border-width: 0 3px 3px 0;
}

.left-arrow {
  transform: rotate(135deg);
  -webkit-transform: rotate(135deg);
}

.right-arrow {
  transform: rotate(-45deg);
  -webkit-transform: rotate(-45deg);
}

    </style>

    <script type="text/javascript">
      function setNonCompatibleBrowserMessage() {
  document.body.innerHTML =
    '<h2 style="margin-left: 20px;">Your browser is not compatible with CodeChecker Viewer!</h2> \
     <p style="margin-left: 20px;">The version required for the following browsers are:</p> \
     <ul style="margin-left: 20px;"> \
     <li>Internet Explorer: version 9 or newer</li> \
     <li>Firefox: version 22.0 or newer</li> \
     </ul>';
}

// http://stackoverflow.com/questions/5916900/how-can-you-detect-the-version-of-a-browser
var browserVersion = (function(){
  var ua = navigator.userAgent, tem,
    M = ua.match(/(opera|chrome|safari|firefox|msie|trident(?=\/))\/?\s*(\d+)/i) || [];

  if (/trident/i.test(M[1])) {
    tem = /\brv[ :]+(\d+)/g.exec(ua) || [];
    return 'IE ' + (tem[1] || '');
  }

  if (M[1] === 'Chrome') {
    tem = ua.match(/\b(OPR|Edge)\/(\d+)/);
    if (tem != null) return tem.slice(1).join(' ').replace('OPR', 'Opera');
  }

  M = M[2] ? [M[1], M[2]] : [navigator.appName, navigator.appVersion, '-?'];
  if ((tem = ua.match(/version\/(\d+)/i)) != null) M.splice(1, 1, tem[1]);
    return M.join(' ');
})();

var pos = browserVersion.indexOf(' ');
var browser = browserVersion.substr(0, pos);
var version = parseInt(browserVersion.substr(pos + 1));

var browserCompatible
  = browser === 'Firefox'
  ? version >= 22
  : browser === 'IE'
  ? version >= 9
  : true;


      /* MIT License

Copyright (C) 2017 by Marijn Haverbeke <marijnh@gmail.com> and others

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
 */
      !function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):e.CodeMirror=t()}(this,function(){"use strict";function e(e){return new RegExp("(^|\\s)"+e+"(?:$|\\s)\\s*")}function t(e){for(var t=e.childNodes.length;t>0;--t)e.removeChild(e.firstChild);return e}function r(e,r){return t(e).appendChild(r)}function n(e,t,r,n){var i=document.createElement(e);if(r&&(i.className=r),n&&(i.style.cssText=n),"string"==typeof t)i.appendChild(document.createTextNode(t));else if(t)for(var o=0;o<t.length;++o)i.appendChild(t[o]);return i}function i(e,t,r,i){var o=n(e,t,r,i);return o.setAttribute("role","presentation"),o}function o(e,t){if(3==t.nodeType&&(t=t.parentNode),e.contains)return e.contains(t);do{if(11==t.nodeType&&(t=t.host),t==e)return!0}while(t=t.parentNode)}function l(){var e;try{e=document.activeElement}catch(t){e=document.body||null}for(;e&&e.shadowRoot&&e.shadowRoot.activeElement;)e=e.shadowRoot.activeElement;return e}function s(t,r){var n=t.className;e(r).test(n)||(t.className+=(n?" ":"")+r)}function a(t,r){for(var n=t.split(" "),i=0;i<n.length;i++)n[i]&&!e(n[i]).test(r)&&(r+=" "+n[i]);return r}function u(e){var t=Array.prototype.slice.call(arguments,1);return function(){return e.apply(null,t)}}function c(e,t,r){t||(t={});for(var n in e)!e.hasOwnProperty(n)||!1===r&&t.hasOwnProperty(n)||(t[n]=e[n]);return t}function f(e,t,r,n,i){null==t&&-1==(t=e.search(/[^\s\u00a0]/))&&(t=e.length);for(var o=n||0,l=i||0;;){var s=e.indexOf("\t",o);if(s<0||s>=t)return l+(t-o);l+=s-o,l+=r-l%r,o=s+1}}function h(e,t){for(var r=0;r<e.length;++r)if(e[r]==t)return r;return-1}function d(e,t,r){for(var n=0,i=0;;){var o=e.indexOf("\t",n);-1==o&&(o=e.length);var l=o-n;if(o==e.length||i+l>=t)return n+Math.min(l,t-i);if(i+=o-n,i+=r-i%r,n=o+1,i>=t)return n}}function p(e){for(;Kl.length<=e;)Kl.push(g(Kl)+" ");return Kl[e]}function g(e){return e[e.length-1]}function v(e,t){for(var r=[],n=0;n<e.length;n++)r[n]=t(e[n],n);return r}function m(e,t,r){for(var n=0,i=r(t);n<e.length&&r(e[n])<=i;)n++;e.splice(n,0,t)}function y(){}function b(e,t){var r;return Object.create?r=Object.create(e):(y.prototype=e,r=new y),t&&c(t,r),r}function w(e){return/\w/.test(e)||e>""&&(e.toUpperCase()!=e.toLowerCase()||jl.test(e))}function x(e,t){return t?!!(t.source.indexOf("\\w")>-1&&w(e))||t.test(e):w(e)}function C(e){for(var t in e)if(e.hasOwnProperty(t)&&e[t])return!1;return!0}function S(e){return e.charCodeAt(0)>=768&&Xl.test(e)}function L(e,t,r){for(;(r<0?t>0:t<e.length)&&S(e.charAt(t));)t+=r;return t}function k(e,t,r){for(var n=t>r?-1:1;;){if(t==r)return t;var i=(t+r)/2,o=n<0?Math.ceil(i):Math.floor(i);if(o==t)return e(o)?t:r;e(o)?r=o:t=o+n}}function T(e,t,r){var o=this;this.input=r,o.scrollbarFiller=n("div",null,"CodeMirror-scrollbar-filler"),o.scrollbarFiller.setAttribute("cm-not-content","true"),o.gutterFiller=n("div",null,"CodeMirror-gutter-filler"),o.gutterFiller.setAttribute("cm-not-content","true"),o.lineDiv=i("div",null,"CodeMirror-code"),o.selectionDiv=n("div",null,null,"position: relative; z-index: 1"),o.cursorDiv=n("div",null,"CodeMirror-cursors"),o.measure=n("div",null,"CodeMirror-measure"),o.lineMeasure=n("div",null,"CodeMirror-measure"),o.lineSpace=i("div",[o.measure,o.lineMeasure,o.selectionDiv,o.cursorDiv,o.lineDiv],null,"position: relative; outline: none");var l=i("div",[o.lineSpace],"CodeMirror-lines");o.mover=n("div",[l],null,"position: relative"),o.sizer=n("div",[o.mover],"CodeMirror-sizer"),o.sizerWidth=null,o.heightForcer=n("div",null,null,"position: absolute; height: "+Rl+"px; width: 1px;"),o.gutters=n("div",null,"CodeMirror-gutters"),o.lineGutter=null,o.scroller=n("div",[o.sizer,o.heightForcer,o.gutters],"CodeMirror-scroll"),o.scroller.setAttribute("tabIndex","-1"),o.wrapper=n("div",[o.scrollbarFiller,o.gutterFiller,o.scroller],"CodeMirror"),gl&&vl<8&&(o.gutters.style.zIndex=-1,o.scroller.style.paddingRight=0),ml||fl&&Tl||(o.scroller.draggable=!0),e&&(e.appendChild?e.appendChild(o.wrapper):e(o.wrapper)),o.viewFrom=o.viewTo=t.first,o.reportedViewFrom=o.reportedViewTo=t.first,o.view=[],o.renderedView=null,o.externalMeasured=null,o.viewOffset=0,o.lastWrapHeight=o.lastWrapWidth=0,o.updateLineNumbers=null,o.nativeBarWidth=o.barHeight=o.barWidth=0,o.scrollbarsClipped=!1,o.lineNumWidth=o.lineNumInnerWidth=o.lineNumChars=null,o.alignWidgets=!1,o.cachedCharWidth=o.cachedTextHeight=o.cachedPaddingH=null,o.maxLine=null,o.maxLineLength=0,o.maxLineChanged=!1,o.wheelDX=o.wheelDY=o.wheelStartX=o.wheelStartY=null,o.shift=!1,o.selForContextMenu=null,o.activeTouch=null,r.init(o)}function M(e,t){if((t-=e.first)<0||t>=e.size)throw new Error("There is no line "+(t+e.first)+" in the document.");for(var r=e;!r.lines;)for(var n=0;;++n){var i=r.children[n],o=i.chunkSize();if(t<o){r=i;break}t-=o}return r.lines[t]}function N(e,t,r){var n=[],i=t.line;return e.iter(t.line,r.line+1,function(e){var o=e.text;i==r.line&&(o=o.slice(0,r.ch)),i==t.line&&(o=o.slice(t.ch)),n.push(o),++i}),n}function O(e,t,r){var n=[];return e.iter(t,r,function(e){n.push(e.text)}),n}function A(e,t){var r=t-e.height;if(r)for(var n=e;n;n=n.parent)n.height+=r}function W(e){if(null==e.parent)return null;for(var t=e.parent,r=h(t.lines,e),n=t.parent;n;t=n,n=n.parent)for(var i=0;n.children[i]!=t;++i)r+=n.children[i].chunkSize();return r+t.first}function D(e,t){var r=e.first;e:do{for(var n=0;n<e.children.length;++n){var i=e.children[n],o=i.height;if(t<o){e=i;continue e}t-=o,r+=i.chunkSize()}return r}while(!e.lines);for(var l=0;l<e.lines.length;++l){var s=e.lines[l].height;if(t<s)break;t-=s}return r+l}function H(e,t){return t>=e.first&&t<e.first+e.size}function F(e,t){return String(e.lineNumberFormatter(t+e.firstLineNumber))}function E(e,t,r){if(void 0===r&&(r=null),!(this instanceof E))return new E(e,t,r);this.line=e,this.ch=t,this.sticky=r}function P(e,t){return e.line-t.line||e.ch-t.ch}function I(e,t){return e.sticky==t.sticky&&0==P(e,t)}function z(e){return E(e.line,e.ch)}function R(e,t){return P(e,t)<0?t:e}function B(e,t){return P(e,t)<0?e:t}function G(e,t){return Math.max(e.first,Math.min(t,e.first+e.size-1))}function U(e,t){if(t.line<e.first)return E(e.first,0);var r=e.first+e.size-1;return t.line>r?E(r,M(e,r).text.length):V(t,M(e,t.line).text.length)}function V(e,t){var r=e.ch;return null==r||r>t?E(e.line,t):r<0?E(e.line,0):e}function K(e,t){for(var r=[],n=0;n<t.length;n++)r[n]=U(e,t[n]);return r}function j(){Yl=!0}function X(){_l=!0}function Y(e,t,r){this.marker=e,this.from=t,this.to=r}function _(e,t){if(e)for(var r=0;r<e.length;++r){var n=e[r];if(n.marker==t)return n}}function $(e,t){for(var r,n=0;n<e.length;++n)e[n]!=t&&(r||(r=[])).push(e[n]);return r}function q(e,t){e.markedSpans=e.markedSpans?e.markedSpans.concat([t]):[t],t.marker.attachLine(e)}function Z(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t)||o.from==t&&"bookmark"==l.type&&(!r||!o.marker.insertLeft)){var s=null==o.to||(l.inclusiveRight?o.to>=t:o.to>t);(n||(n=[])).push(new Y(l,o.from,s?null:o.to))}}return n}function Q(e,t,r){var n;if(e)for(var i=0;i<e.length;++i){var o=e[i],l=o.marker;if(null==o.to||(l.inclusiveRight?o.to>=t:o.to>t)||o.from==t&&"bookmark"==l.type&&(!r||o.marker.insertLeft)){var s=null==o.from||(l.inclusiveLeft?o.from<=t:o.from<t);(n||(n=[])).push(new Y(l,s?null:o.from-t,null==o.to?null:o.to-t))}}return n}function J(e,t){if(t.full)return null;var r=H(e,t.from.line)&&M(e,t.from.line).markedSpans,n=H(e,t.to.line)&&M(e,t.to.line).markedSpans;if(!r&&!n)return null;var i=t.from.ch,o=t.to.ch,l=0==P(t.from,t.to),s=Z(r,i,l),a=Q(n,o,l),u=1==t.text.length,c=g(t.text).length+(u?i:0);if(s)for(var f=0;f<s.length;++f){var h=s[f];if(null==h.to){var d=_(a,h.marker);d?u&&(h.to=null==d.to?null:d.to+c):h.to=i}}if(a)for(var p=0;p<a.length;++p){var v=a[p];null!=v.to&&(v.to+=c),null==v.from?_(s,v.marker)||(v.from=c,u&&(s||(s=[])).push(v)):(v.from+=c,u&&(s||(s=[])).push(v))}s&&(s=ee(s)),a&&a!=s&&(a=ee(a));var m=[s];if(!u){var y,b=t.text.length-2;if(b>0&&s)for(var w=0;w<s.length;++w)null==s[w].to&&(y||(y=[])).push(new Y(s[w].marker,null,null));for(var x=0;x<b;++x)m.push(y);m.push(a)}return m}function ee(e){for(var t=0;t<e.length;++t){var r=e[t];null!=r.from&&r.from==r.to&&!1!==r.marker.clearWhenEmpty&&e.splice(t--,1)}return e.length?e:null}function te(e,t,r){var n=null;if(e.iter(t.line,r.line+1,function(e){if(e.markedSpans)for(var t=0;t<e.markedSpans.length;++t){var r=e.markedSpans[t].marker;!r.readOnly||n&&-1!=h(n,r)||(n||(n=[])).push(r)}}),!n)return null;for(var i=[{from:t,to:r}],o=0;o<n.length;++o)for(var l=n[o],s=l.find(0),a=0;a<i.length;++a){var u=i[a];if(!(P(u.to,s.from)<0||P(u.from,s.to)>0)){var c=[a,1],f=P(u.from,s.from),d=P(u.to,s.to);(f<0||!l.inclusiveLeft&&!f)&&c.push({from:u.from,to:s.from}),(d>0||!l.inclusiveRight&&!d)&&c.push({from:s.to,to:u.to}),i.splice.apply(i,c),a+=c.length-3}}return i}function re(e){var t=e.markedSpans;if(t){for(var r=0;r<t.length;++r)t[r].marker.detachLine(e);e.markedSpans=null}}function ne(e,t){if(t){for(var r=0;r<t.length;++r)t[r].marker.attachLine(e);e.markedSpans=t}}function ie(e){return e.inclusiveLeft?-1:0}function oe(e){return e.inclusiveRight?1:0}function le(e,t){var r=e.lines.length-t.lines.length;if(0!=r)return r;var n=e.find(),i=t.find(),o=P(n.from,i.from)||ie(e)-ie(t);if(o)return-o;var l=P(n.to,i.to)||oe(e)-oe(t);return l||t.id-e.id}function se(e,t){var r,n=_l&&e.markedSpans;if(n)for(var i=void 0,o=0;o<n.length;++o)(i=n[o]).marker.collapsed&&null==(t?i.from:i.to)&&(!r||le(r,i.marker)<0)&&(r=i.marker);return r}function ae(e){return se(e,!0)}function ue(e){return se(e,!1)}function ce(e,t,r,n,i){var o=M(e,t),l=_l&&o.markedSpans;if(l)for(var s=0;s<l.length;++s){var a=l[s];if(a.marker.collapsed){var u=a.marker.find(0),c=P(u.from,r)||ie(a.marker)-ie(i),f=P(u.to,n)||oe(a.marker)-oe(i);if(!(c>=0&&f<=0||c<=0&&f>=0)&&(c<=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.to,r)>=0:P(u.to,r)>0)||c>=0&&(a.marker.inclusiveRight&&i.inclusiveLeft?P(u.from,n)<=0:P(u.from,n)<0)))return!0}}}function fe(e){for(var t;t=ae(e);)e=t.find(-1,!0).line;return e}function he(e){for(var t;t=ue(e);)e=t.find(1,!0).line;return e}function de(e){for(var t,r;t=ue(e);)e=t.find(1,!0).line,(r||(r=[])).push(e);return r}function pe(e,t){var r=M(e,t),n=fe(r);return r==n?t:W(n)}function ge(e,t){if(t>e.lastLine())return t;var r,n=M(e,t);if(!ve(e,n))return t;for(;r=ue(n);)n=r.find(1,!0).line;return W(n)+1}function ve(e,t){var r=_l&&t.markedSpans;if(r)for(var n=void 0,i=0;i<r.length;++i)if((n=r[i]).marker.collapsed){if(null==n.from)return!0;if(!n.marker.widgetNode&&0==n.from&&n.marker.inclusiveLeft&&me(e,t,n))return!0}}function me(e,t,r){if(null==r.to){var n=r.marker.find(1,!0);return me(e,n.line,_(n.line.markedSpans,r.marker))}if(r.marker.inclusiveRight&&r.to==t.text.length)return!0;for(var i=void 0,o=0;o<t.markedSpans.length;++o)if((i=t.markedSpans[o]).marker.collapsed&&!i.marker.widgetNode&&i.from==r.to&&(null==i.to||i.to!=r.from)&&(i.marker.inclusiveLeft||r.marker.inclusiveRight)&&me(e,t,i))return!0}function ye(e){for(var t=0,r=(e=fe(e)).parent,n=0;n<r.lines.length;++n){var i=r.lines[n];if(i==e)break;t+=i.height}for(var o=r.parent;o;r=o,o=r.parent)for(var l=0;l<o.children.length;++l){var s=o.children[l];if(s==r)break;t+=s.height}return t}function be(e){if(0==e.height)return 0;for(var t,r=e.text.length,n=e;t=ae(n);){var i=t.find(0,!0);n=i.from.line,r+=i.from.ch-i.to.ch}for(n=e;t=ue(n);){var o=t.find(0,!0);r-=n.text.length-o.from.ch,r+=(n=o.to.line).text.length-o.to.ch}return r}function we(e){var t=e.display,r=e.doc;t.maxLine=M(r,r.first),t.maxLineLength=be(t.maxLine),t.maxLineChanged=!0,r.iter(function(e){var r=be(e);r>t.maxLineLength&&(t.maxLineLength=r,t.maxLine=e)})}function xe(e,t,r,n){if(!e)return n(t,r,"ltr",0);for(var i=!1,o=0;o<e.length;++o){var l=e[o];(l.from<r&&l.to>t||t==r&&l.to==t)&&(n(Math.max(l.from,t),Math.min(l.to,r),1==l.level?"rtl":"ltr",o),i=!0)}i||n(t,r,"ltr")}function Ce(e,t,r){var n;$l=null;for(var i=0;i<e.length;++i){var o=e[i];if(o.from<t&&o.to>t)return i;o.to==t&&(o.from!=o.to&&"before"==r?n=i:$l=i),o.from==t&&(o.from!=o.to&&"before"!=r?n=i:$l=i)}return null!=n?n:$l}function Se(e,t){var r=e.order;return null==r&&(r=e.order=ql(e.text,t)),r}function Le(e,t){return e._handlers&&e._handlers[t]||Zl}function ke(e,t,r){if(e.removeEventListener)e.removeEventListener(t,r,!1);else if(e.detachEvent)e.detachEvent("on"+t,r);else{var n=e._handlers,i=n&&n[t];if(i){var o=h(i,r);o>-1&&(n[t]=i.slice(0,o).concat(i.slice(o+1)))}}}function Te(e,t){var r=Le(e,t);if(r.length)for(var n=Array.prototype.slice.call(arguments,2),i=0;i<r.length;++i)r[i].apply(null,n)}function Me(e,t,r){return"string"==typeof t&&(t={type:t,preventDefault:function(){this.defaultPrevented=!0}}),Te(e,r||t.type,e,t),He(t)||t.codemirrorIgnore}function Ne(e){var t=e._handlers&&e._handlers.cursorActivity;if(t)for(var r=e.curOp.cursorActivityHandlers||(e.curOp.cursorActivityHandlers=[]),n=0;n<t.length;++n)-1==h(r,t[n])&&r.push(t[n])}function Oe(e,t){return Le(e,t).length>0}function Ae(e){e.prototype.on=function(e,t){Ql(this,e,t)},e.prototype.off=function(e,t){ke(this,e,t)}}function We(e){e.preventDefault?e.preventDefault():e.returnValue=!1}function De(e){e.stopPropagation?e.stopPropagation():e.cancelBubble=!0}function He(e){return null!=e.defaultPrevented?e.defaultPrevented:0==e.returnValue}function Fe(e){We(e),De(e)}function Ee(e){return e.target||e.srcElement}function Pe(e){var t=e.which;return null==t&&(1&e.button?t=1:2&e.button?t=3:4&e.button&&(t=2)),Ml&&e.ctrlKey&&1==t&&(t=3),t}function Ie(e){if(null==Il){var t=n("span","​");r(e,n("span",[t,document.createTextNode("x")])),0!=e.firstChild.offsetHeight&&(Il=t.offsetWidth<=1&&t.offsetHeight>2&&!(gl&&vl<8))}var i=Il?n("span","​"):n("span"," ",null,"display: inline-block; width: 1px; margin-right: -1px");return i.setAttribute("cm-text",""),i}function ze(e){if(null!=zl)return zl;var n=r(e,document.createTextNode("AخA")),i=Wl(n,0,1).getBoundingClientRect(),o=Wl(n,1,2).getBoundingClientRect();return t(e),!(!i||i.left==i.right)&&(zl=o.right-i.right<3)}function Re(e){if(null!=ns)return ns;var t=r(e,n("span","x")),i=t.getBoundingClientRect(),o=Wl(t,0,1).getBoundingClientRect();return ns=Math.abs(i.left-o.left)>1}function Be(e,t){arguments.length>2&&(t.dependencies=Array.prototype.slice.call(arguments,2)),is[e]=t}function Ge(e){if("string"==typeof e&&os.hasOwnProperty(e))e=os[e];else if(e&&"string"==typeof e.name&&os.hasOwnProperty(e.name)){var t=os[e.name];"string"==typeof t&&(t={name:t}),(e=b(t,e)).name=t.name}else{if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+xml$/.test(e))return Ge("application/xml");if("string"==typeof e&&/^[\w\-]+\/[\w\-]+\+json$/.test(e))return Ge("application/json")}return"string"==typeof e?{name:e}:e||{name:"null"}}function Ue(e,t){t=Ge(t);var r=is[t.name];if(!r)return Ue(e,"text/plain");var n=r(e,t);if(ls.hasOwnProperty(t.name)){var i=ls[t.name];for(var o in i)i.hasOwnProperty(o)&&(n.hasOwnProperty(o)&&(n["_"+o]=n[o]),n[o]=i[o])}if(n.name=t.name,t.helperType&&(n.helperType=t.helperType),t.modeProps)for(var l in t.modeProps)n[l]=t.modeProps[l];return n}function Ve(e,t){c(t,ls.hasOwnProperty(e)?ls[e]:ls[e]={})}function Ke(e,t){if(!0===t)return t;if(e.copyState)return e.copyState(t);var r={};for(var n in t){var i=t[n];i instanceof Array&&(i=i.concat([])),r[n]=i}return r}function je(e,t){for(var r;e.innerMode&&(r=e.innerMode(t))&&r.mode!=e;)t=r.state,e=r.mode;return r||{mode:e,state:t}}function Xe(e,t,r){return!e.startState||e.startState(t,r)}function Ye(e,t,r,n){var i=[e.state.modeGen],o={};tt(e,t.text,e.doc.mode,r,function(e,t){return i.push(e,t)},o,n);for(var l=r.state,s=0;s<e.state.overlays.length;++s)!function(n){var l=e.state.overlays[n],s=1,a=0;r.state=!0,tt(e,t.text,l.mode,r,function(e,t){for(var r=s;a<e;){var n=i[s];n>e&&i.splice(s,1,e,i[s+1],n),s+=2,a=Math.min(e,n)}if(t)if(l.opaque)i.splice(r,s-r,e,"overlay "+t),s=r+2;else for(;r<s;r+=2){var o=i[r+1];i[r+1]=(o?o+" ":"")+"overlay "+t}},o)}(s);return r.state=l,{styles:i,classes:o.bgClass||o.textClass?o:null}}function _e(e,t,r){if(!t.styles||t.styles[0]!=e.state.modeGen){var n=$e(e,W(t)),i=t.text.length>e.options.maxHighlightLength&&Ke(e.doc.mode,n.state),o=Ye(e,t,n);i&&(n.state=i),t.stateAfter=n.save(!i),t.styles=o.styles,o.classes?t.styleClasses=o.classes:t.styleClasses&&(t.styleClasses=null),r===e.doc.highlightFrontier&&(e.doc.modeFrontier=Math.max(e.doc.modeFrontier,++e.doc.highlightFrontier))}return t.styles}function $e(e,t,r){var n=e.doc,i=e.display;if(!n.mode.startState)return new us(n,!0,t);var o=rt(e,t,r),l=o>n.first&&M(n,o-1).stateAfter,s=l?us.fromSaved(n,l,o):new us(n,Xe(n.mode),o);return n.iter(o,t,function(r){qe(e,r.text,s);var n=s.line;r.stateAfter=n==t-1||n%5==0||n>=i.viewFrom&&n<i.viewTo?s.save():null,s.nextLine()}),r&&(n.modeFrontier=s.line),s}function qe(e,t,r,n){var i=e.doc.mode,o=new ss(t,e.options.tabSize,r);for(o.start=o.pos=n||0,""==t&&Ze(i,r.state);!o.eol();)Qe(i,o,r.state),o.start=o.pos}function Ze(e,t){if(e.blankLine)return e.blankLine(t);if(e.innerMode){var r=je(e,t);return r.mode.blankLine?r.mode.blankLine(r.state):void 0}}function Qe(e,t,r,n){for(var i=0;i<10;i++){n&&(n[0]=je(e,r).mode);var o=e.token(t,r);if(t.pos>t.start)return o}throw new Error("Mode "+e.name+" failed to advance stream.")}function Je(e,t,r,n){var i,o,l=e.doc,s=l.mode,a=M(l,(t=U(l,t)).line),u=$e(e,t.line,r),c=new ss(a.text,e.options.tabSize,u);for(n&&(o=[]);(n||c.pos<t.ch)&&!c.eol();)c.start=c.pos,i=Qe(s,c,u.state),n&&o.push(new cs(c,i,Ke(l.mode,u.state)));return n?o:new cs(c,i,u.state)}function et(e,t){if(e)for(;;){var r=e.match(/(?:^|\s+)line-(background-)?(\S+)/);if(!r)break;e=e.slice(0,r.index)+e.slice(r.index+r[0].length);var n=r[1]?"bgClass":"textClass";null==t[n]?t[n]=r[2]:new RegExp("(?:^|s)"+r[2]+"(?:$|s)").test(t[n])||(t[n]+=" "+r[2])}return e}function tt(e,t,r,n,i,o,l){var s=r.flattenSpans;null==s&&(s=e.options.flattenSpans);var a,u=0,c=null,f=new ss(t,e.options.tabSize,n),h=e.options.addModeClass&&[null];for(""==t&&et(Ze(r,n.state),o);!f.eol();){if(f.pos>e.options.maxHighlightLength?(s=!1,l&&qe(e,t,n,f.pos),f.pos=t.length,a=null):a=et(Qe(r,f,n.state,h),o),h){var d=h[0].name;d&&(a="m-"+(a?d+" "+a:d))}if(!s||c!=a){for(;u<f.start;)i(u=Math.min(f.start,u+5e3),c);c=a}f.start=f.pos}for(;u<f.pos;){var p=Math.min(f.pos,u+5e3);i(p,c),u=p}}function rt(e,t,r){for(var n,i,o=e.doc,l=r?-1:t-(e.doc.mode.innerMode?1e3:100),s=t;s>l;--s){if(s<=o.first)return o.first;var a=M(o,s-1),u=a.stateAfter;if(u&&(!r||s+(u instanceof as?u.lookAhead:0)<=o.modeFrontier))return s;var c=f(a.text,null,e.options.tabSize);(null==i||n>c)&&(i=s-1,n=c)}return i}function nt(e,t){if(e.modeFrontier=Math.min(e.modeFrontier,t),!(e.highlightFrontier<t-10)){for(var r=e.first,n=t-1;n>r;n--){var i=M(e,n).stateAfter;if(i&&(!(i instanceof as)||n+i.lookAhead<t)){r=n+1;break}}e.highlightFrontier=Math.min(e.highlightFrontier,r)}}function it(e,t,r,n){e.text=t,e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null),null!=e.order&&(e.order=null),re(e),ne(e,r);var i=n?n(e):1;i!=e.height&&A(e,i)}function ot(e){e.parent=null,re(e)}function lt(e,t){if(!e||/^\s*$/.test(e))return null;var r=t.addModeClass?ps:ds;return r[e]||(r[e]=e.replace(/\S+/g,"cm-$&"))}function st(e,t){var r=i("span",null,null,ml?"padding-right: .1px":null),n={pre:i("pre",[r],"CodeMirror-line"),content:r,col:0,pos:0,cm:e,trailingSpace:!1,splitSpaces:(gl||ml)&&e.getOption("lineWrapping")};t.measure={};for(var o=0;o<=(t.rest?t.rest.length:0);o++){var l=o?t.rest[o-1]:t.line,s=void 0;n.pos=0,n.addToken=ut,ze(e.display.measure)&&(s=Se(l,e.doc.direction))&&(n.addToken=ft(n.addToken,s)),n.map=[],dt(l,n,_e(e,l,t!=e.display.externalMeasured&&W(l))),l.styleClasses&&(l.styleClasses.bgClass&&(n.bgClass=a(l.styleClasses.bgClass,n.bgClass||"")),l.styleClasses.textClass&&(n.textClass=a(l.styleClasses.textClass,n.textClass||""))),0==n.map.length&&n.map.push(0,0,n.content.appendChild(Ie(e.display.measure))),0==o?(t.measure.map=n.map,t.measure.cache={}):((t.measure.maps||(t.measure.maps=[])).push(n.map),(t.measure.caches||(t.measure.caches=[])).push({}))}if(ml){var u=n.content.lastChild;(/\bcm-tab\b/.test(u.className)||u.querySelector&&u.querySelector(".cm-tab"))&&(n.content.className="cm-tab-wrap-hack")}return Te(e,"renderLine",e,t.line,n.pre),n.pre.className&&(n.textClass=a(n.pre.className,n.textClass||"")),n}function at(e){var t=n("span","•","cm-invalidchar");return t.title="\\u"+e.charCodeAt(0).toString(16),t.setAttribute("aria-label",t.title),t}function ut(e,t,r,i,o,l,s){if(t){var a,u=e.splitSpaces?ct(t,e.trailingSpace):t,c=e.cm.state.specialChars,f=!1;if(c.test(t)){a=document.createDocumentFragment();for(var h=0;;){c.lastIndex=h;var d=c.exec(t),g=d?d.index-h:t.length-h;if(g){var v=document.createTextNode(u.slice(h,h+g));gl&&vl<9?a.appendChild(n("span",[v])):a.appendChild(v),e.map.push(e.pos,e.pos+g,v),e.col+=g,e.pos+=g}if(!d)break;h+=g+1;var m=void 0;if("\t"==d[0]){var y=e.cm.options.tabSize,b=y-e.col%y;(m=a.appendChild(n("span",p(b),"cm-tab"))).setAttribute("role","presentation"),m.setAttribute("cm-text","\t"),e.col+=b}else"\r"==d[0]||"\n"==d[0]?((m=a.appendChild(n("span","\r"==d[0]?"␍":"␤","cm-invalidchar"))).setAttribute("cm-text",d[0]),e.col+=1):((m=e.cm.options.specialCharPlaceholder(d[0])).setAttribute("cm-text",d[0]),gl&&vl<9?a.appendChild(n("span",[m])):a.appendChild(m),e.col+=1);e.map.push(e.pos,e.pos+1,m),e.pos++}}else e.col+=t.length,a=document.createTextNode(u),e.map.push(e.pos,e.pos+t.length,a),gl&&vl<9&&(f=!0),e.pos+=t.length;if(e.trailingSpace=32==u.charCodeAt(t.length-1),r||i||o||f||s){var w=r||"";i&&(w+=i),o&&(w+=o);var x=n("span",[a],w,s);return l&&(x.title=l),e.content.appendChild(x)}e.content.appendChild(a)}}function ct(e,t){if(e.length>1&&!/  /.test(e))return e;for(var r=t,n="",i=0;i<e.length;i++){var o=e.charAt(i);" "!=o||!r||i!=e.length-1&&32!=e.charCodeAt(i+1)||(o=" "),n+=o,r=" "==o}return n}function ft(e,t){return function(r,n,i,o,l,s,a){i=i?i+" cm-force-border":"cm-force-border";for(var u=r.pos,c=u+n.length;;){for(var f=void 0,h=0;h<t.length&&!((f=t[h]).to>u&&f.from<=u);h++);if(f.to>=c)return e(r,n,i,o,l,s,a);e(r,n.slice(0,f.to-u),i,o,null,s,a),o=null,n=n.slice(f.to-u),u=f.to}}}function ht(e,t,r,n){var i=!n&&r.widgetNode;i&&e.map.push(e.pos,e.pos+t,i),!n&&e.cm.display.input.needsContentAttribute&&(i||(i=e.content.appendChild(document.createElement("span"))),i.setAttribute("cm-marker",r.id)),i&&(e.cm.display.input.setUneditable(i),e.content.appendChild(i)),e.pos+=t,e.trailingSpace=!1}function dt(e,t,r){var n=e.markedSpans,i=e.text,o=0;if(n)for(var l,s,a,u,c,f,h,d=i.length,p=0,g=1,v="",m=0;;){if(m==p){a=u=c=f=s="",h=null,m=1/0;for(var y=[],b=void 0,w=0;w<n.length;++w){var x=n[w],C=x.marker;"bookmark"==C.type&&x.from==p&&C.widgetNode?y.push(C):x.from<=p&&(null==x.to||x.to>p||C.collapsed&&x.to==p&&x.from==p)?(null!=x.to&&x.to!=p&&m>x.to&&(m=x.to,u=""),C.className&&(a+=" "+C.className),C.css&&(s=(s?s+";":"")+C.css),C.startStyle&&x.from==p&&(c+=" "+C.startStyle),C.endStyle&&x.to==m&&(b||(b=[])).push(C.endStyle,x.to),C.title&&!f&&(f=C.title),C.collapsed&&(!h||le(h.marker,C)<0)&&(h=x)):x.from>p&&m>x.from&&(m=x.from)}if(b)for(var S=0;S<b.length;S+=2)b[S+1]==m&&(u+=" "+b[S]);if(!h||h.from==p)for(var L=0;L<y.length;++L)ht(t,0,y[L]);if(h&&(h.from||0)==p){if(ht(t,(null==h.to?d+1:h.to)-p,h.marker,null==h.from),null==h.to)return;h.to==p&&(h=!1)}}if(p>=d)break;for(var k=Math.min(d,m);;){if(v){var T=p+v.length;if(!h){var M=T>k?v.slice(0,k-p):v;t.addToken(t,M,l?l+a:a,c,p+M.length==m?u:"",f,s)}if(T>=k){v=v.slice(k-p),p=k;break}p=T,c=""}v=i.slice(o,o=r[g++]),l=lt(r[g++],t.cm.options)}}else for(var N=1;N<r.length;N+=2)t.addToken(t,i.slice(o,o=r[N]),lt(r[N+1],t.cm.options))}function pt(e,t,r){this.line=t,this.rest=de(t),this.size=this.rest?W(g(this.rest))-r+1:1,this.node=this.text=null,this.hidden=ve(e,t)}function gt(e,t,r){for(var n,i=[],o=t;o<r;o=n){var l=new pt(e.doc,M(e.doc,o),o);n=o+l.size,i.push(l)}return i}function vt(e){gs?gs.ops.push(e):e.ownsGroup=gs={ops:[e],delayedCallbacks:[]}}function mt(e){var t=e.delayedCallbacks,r=0;do{for(;r<t.length;r++)t[r].call(null);for(var n=0;n<e.ops.length;n++){var i=e.ops[n];if(i.cursorActivityHandlers)for(;i.cursorActivityCalled<i.cursorActivityHandlers.length;)i.cursorActivityHandlers[i.cursorActivityCalled++].call(null,i.cm)}}while(r<t.length)}function yt(e,t){var r=e.ownsGroup;if(r)try{mt(r)}finally{gs=null,t(r)}}function bt(e,t){var r=Le(e,t);if(r.length){var n,i=Array.prototype.slice.call(arguments,2);gs?n=gs.delayedCallbacks:vs?n=vs:(n=vs=[],setTimeout(wt,0));for(var o=0;o<r.length;++o)!function(e){n.push(function(){return r[e].apply(null,i)})}(o)}}function wt(){var e=vs;vs=null;for(var t=0;t<e.length;++t)e[t]()}function xt(e,t,r,n){for(var i=0;i<t.changes.length;i++){var o=t.changes[i];"text"==o?kt(e,t):"gutter"==o?Mt(e,t,r,n):"class"==o?Tt(e,t):"widget"==o&&Nt(e,t,n)}t.changes=null}function Ct(e){return e.node==e.text&&(e.node=n("div",null,null,"position: relative"),e.text.parentNode&&e.text.parentNode.replaceChild(e.node,e.text),e.node.appendChild(e.text),gl&&vl<8&&(e.node.style.zIndex=2)),e.node}function St(e,t){var r=t.bgClass?t.bgClass+" "+(t.line.bgClass||""):t.line.bgClass;if(r&&(r+=" CodeMirror-linebackground"),t.background)r?t.background.className=r:(t.background.parentNode.removeChild(t.background),t.background=null);else if(r){var i=Ct(t);t.background=i.insertBefore(n("div",null,r),i.firstChild),e.display.input.setUneditable(t.background)}}function Lt(e,t){var r=e.display.externalMeasured;return r&&r.line==t.line?(e.display.externalMeasured=null,t.measure=r.measure,r.built):st(e,t)}function kt(e,t){var r=t.text.className,n=Lt(e,t);t.text==t.node&&(t.node=n.pre),t.text.parentNode.replaceChild(n.pre,t.text),t.text=n.pre,n.bgClass!=t.bgClass||n.textClass!=t.textClass?(t.bgClass=n.bgClass,t.textClass=n.textClass,Tt(e,t)):r&&(t.text.className=r)}function Tt(e,t){St(e,t),t.line.wrapClass?Ct(t).className=t.line.wrapClass:t.node!=t.text&&(t.node.className="");var r=t.textClass?t.textClass+" "+(t.line.textClass||""):t.line.textClass;t.text.className=r||""}function Mt(e,t,r,i){if(t.gutter&&(t.node.removeChild(t.gutter),t.gutter=null),t.gutterBackground&&(t.node.removeChild(t.gutterBackground),t.gutterBackground=null),t.line.gutterClass){var o=Ct(t);t.gutterBackground=n("div",null,"CodeMirror-gutter-background "+t.line.gutterClass,"left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px; width: "+i.gutterTotalWidth+"px"),e.display.input.setUneditable(t.gutterBackground),o.insertBefore(t.gutterBackground,t.text)}var l=t.line.gutterMarkers;if(e.options.lineNumbers||l){var s=Ct(t),a=t.gutter=n("div",null,"CodeMirror-gutter-wrapper","left: "+(e.options.fixedGutter?i.fixedPos:-i.gutterTotalWidth)+"px");if(e.display.input.setUneditable(a),s.insertBefore(a,t.text),t.line.gutterClass&&(a.className+=" "+t.line.gutterClass),!e.options.lineNumbers||l&&l["CodeMirror-linenumbers"]||(t.lineNumber=a.appendChild(n("div",F(e.options,r),"CodeMirror-linenumber CodeMirror-gutter-elt","left: "+i.gutterLeft["CodeMirror-linenumbers"]+"px; width: "+e.display.lineNumInnerWidth+"px"))),l)for(var u=0;u<e.options.gutters.length;++u){var c=e.options.gutters[u],f=l.hasOwnProperty(c)&&l[c];f&&a.appendChild(n("div",[f],"CodeMirror-gutter-elt","left: "+i.gutterLeft[c]+"px; width: "+i.gutterWidth[c]+"px"))}}}function Nt(e,t,r){t.alignable&&(t.alignable=null);for(var n=t.node.firstChild,i=void 0;n;n=i)i=n.nextSibling,"CodeMirror-linewidget"==n.className&&t.node.removeChild(n);At(e,t,r)}function Ot(e,t,r,n){var i=Lt(e,t);return t.text=t.node=i.pre,i.bgClass&&(t.bgClass=i.bgClass),i.textClass&&(t.textClass=i.textClass),Tt(e,t),Mt(e,t,r,n),At(e,t,n),t.node}function At(e,t,r){if(Wt(e,t.line,t,r,!0),t.rest)for(var n=0;n<t.rest.length;n++)Wt(e,t.rest[n],t,r,!1)}function Wt(e,t,r,i,o){if(t.widgets)for(var l=Ct(r),s=0,a=t.widgets;s<a.length;++s){var u=a[s],c=n("div",[u.node],"CodeMirror-linewidget");u.handleMouseEvents||c.setAttribute("cm-ignore-events","true"),Dt(u,c,r,i),e.display.input.setUneditable(c),o&&u.above?l.insertBefore(c,r.gutter||r.text):l.appendChild(c),bt(u,"redraw")}}function Dt(e,t,r,n){if(e.noHScroll){(r.alignable||(r.alignable=[])).push(t);var i=n.wrapperWidth;t.style.left=n.fixedPos+"px",e.coverGutter||(i-=n.gutterTotalWidth,t.style.paddingLeft=n.gutterTotalWidth+"px"),t.style.width=i+"px"}e.coverGutter&&(t.style.zIndex=5,t.style.position="relative",e.noHScroll||(t.style.marginLeft=-n.gutterTotalWidth+"px"))}function Ht(e){if(null!=e.height)return e.height;var t=e.doc.cm;if(!t)return 0;if(!o(document.body,e.node)){var i="position: relative;";e.coverGutter&&(i+="margin-left: -"+t.display.gutters.offsetWidth+"px;"),e.noHScroll&&(i+="width: "+t.display.wrapper.clientWidth+"px;"),r(t.display.measure,n("div",[e.node],null,i))}return e.height=e.node.parentNode.offsetHeight}function Ft(e,t){for(var r=Ee(t);r!=e.wrapper;r=r.parentNode)if(!r||1==r.nodeType&&"true"==r.getAttribute("cm-ignore-events")||r.parentNode==e.sizer&&r!=e.mover)return!0}function Et(e){return e.lineSpace.offsetTop}function Pt(e){return e.mover.offsetHeight-e.lineSpace.offsetHeight}function It(e){if(e.cachedPaddingH)return e.cachedPaddingH;var t=r(e.measure,n("pre","x")),i=window.getComputedStyle?window.getComputedStyle(t):t.currentStyle,o={left:parseInt(i.paddingLeft),right:parseInt(i.paddingRight)};return isNaN(o.left)||isNaN(o.right)||(e.cachedPaddingH=o),o}function zt(e){return Rl-e.display.nativeBarWidth}function Rt(e){return e.display.scroller.clientWidth-zt(e)-e.display.barWidth}function Bt(e){return e.display.scroller.clientHeight-zt(e)-e.display.barHeight}function Gt(e,t,r){var n=e.options.lineWrapping,i=n&&Rt(e);if(!t.measure.heights||n&&t.measure.width!=i){var o=t.measure.heights=[];if(n){t.measure.width=i;for(var l=t.text.firstChild.getClientRects(),s=0;s<l.length-1;s++){var a=l[s],u=l[s+1];Math.abs(a.bottom-u.bottom)>2&&o.push((a.bottom+u.top)/2-r.top)}}o.push(r.bottom-r.top)}}function Ut(e,t,r){if(e.line==t)return{map:e.measure.map,cache:e.measure.cache};for(var n=0;n<e.rest.length;n++)if(e.rest[n]==t)return{map:e.measure.maps[n],cache:e.measure.caches[n]};for(var i=0;i<e.rest.length;i++)if(W(e.rest[i])>r)return{map:e.measure.maps[i],cache:e.measure.caches[i],before:!0}}function Vt(e,t){var n=W(t=fe(t)),i=e.display.externalMeasured=new pt(e.doc,t,n);i.lineN=n;var o=i.built=st(e,i);return i.text=o.pre,r(e.display.lineMeasure,o.pre),i}function Kt(e,t,r,n){return Yt(e,Xt(e,t),r,n)}function jt(e,t){if(t>=e.display.viewFrom&&t<e.display.viewTo)return e.display.view[Lr(e,t)];var r=e.display.externalMeasured;return r&&t>=r.lineN&&t<r.lineN+r.size?r:void 0}function Xt(e,t){var r=W(t),n=jt(e,r);n&&!n.text?n=null:n&&n.changes&&(xt(e,n,r,br(e)),e.curOp.forceUpdate=!0),n||(n=Vt(e,t));var i=Ut(n,t,r);return{line:t,view:n,rect:null,map:i.map,cache:i.cache,before:i.before,hasHeights:!1}}function Yt(e,t,r,n,i){t.before&&(r=-1);var o,l=r+(n||"");return t.cache.hasOwnProperty(l)?o=t.cache[l]:(t.rect||(t.rect=t.view.text.getBoundingClientRect()),t.hasHeights||(Gt(e,t.view,t.rect),t.hasHeights=!0),(o=qt(e,t,r,n)).bogus||(t.cache[l]=o)),{left:o.left,right:o.right,top:i?o.rtop:o.top,bottom:i?o.rbottom:o.bottom}}function _t(e,t,r){for(var n,i,o,l,s,a,u=0;u<e.length;u+=3)if(s=e[u],a=e[u+1],t<s?(i=0,o=1,l="left"):t<a?o=(i=t-s)+1:(u==e.length-3||t==a&&e[u+3]>t)&&(i=(o=a-s)-1,t>=a&&(l="right")),null!=i){if(n=e[u+2],s==a&&r==(n.insertLeft?"left":"right")&&(l=r),"left"==r&&0==i)for(;u&&e[u-2]==e[u-3]&&e[u-1].insertLeft;)n=e[2+(u-=3)],l="left";if("right"==r&&i==a-s)for(;u<e.length-3&&e[u+3]==e[u+4]&&!e[u+5].insertLeft;)n=e[(u+=3)+2],l="right";break}return{node:n,start:i,end:o,collapse:l,coverStart:s,coverEnd:a}}function $t(e,t){var r=ms;if("left"==t)for(var n=0;n<e.length&&(r=e[n]).left==r.right;n++);else for(var i=e.length-1;i>=0&&(r=e[i]).left==r.right;i--);return r}function qt(e,t,r,n){var i,o=_t(t.map,r,n),l=o.node,s=o.start,a=o.end,u=o.collapse;if(3==l.nodeType){for(var c=0;c<4;c++){for(;s&&S(t.line.text.charAt(o.coverStart+s));)--s;for(;o.coverStart+a<o.coverEnd&&S(t.line.text.charAt(o.coverStart+a));)++a;if((i=gl&&vl<9&&0==s&&a==o.coverEnd-o.coverStart?l.parentNode.getBoundingClientRect():$t(Wl(l,s,a).getClientRects(),n)).left||i.right||0==s)break;a=s,s-=1,u="right"}gl&&vl<11&&(i=Zt(e.display.measure,i))}else{s>0&&(u=n="right");var f;i=e.options.lineWrapping&&(f=l.getClientRects()).length>1?f["right"==n?f.length-1:0]:l.getBoundingClientRect()}if(gl&&vl<9&&!s&&(!i||!i.left&&!i.right)){var h=l.parentNode.getClientRects()[0];i=h?{left:h.left,right:h.left+yr(e.display),top:h.top,bottom:h.bottom}:ms}for(var d=i.top-t.rect.top,p=i.bottom-t.rect.top,g=(d+p)/2,v=t.view.measure.heights,m=0;m<v.length-1&&!(g<v[m]);m++);var y=m?v[m-1]:0,b=v[m],w={left:("right"==u?i.right:i.left)-t.rect.left,right:("left"==u?i.left:i.right)-t.rect.left,top:y,bottom:b};return i.left||i.right||(w.bogus=!0),e.options.singleCursorHeightPerLine||(w.rtop=d,w.rbottom=p),w}function Zt(e,t){if(!window.screen||null==screen.logicalXDPI||screen.logicalXDPI==screen.deviceXDPI||!Re(e))return t;var r=screen.logicalXDPI/screen.deviceXDPI,n=screen.logicalYDPI/screen.deviceYDPI;return{left:t.left*r,right:t.right*r,top:t.top*n,bottom:t.bottom*n}}function Qt(e){if(e.measure&&(e.measure.cache={},e.measure.heights=null,e.rest))for(var t=0;t<e.rest.length;t++)e.measure.caches[t]={}}function Jt(e){e.display.externalMeasure=null,t(e.display.lineMeasure);for(var r=0;r<e.display.view.length;r++)Qt(e.display.view[r])}function er(e){Jt(e),e.display.cachedCharWidth=e.display.cachedTextHeight=e.display.cachedPaddingH=null,e.options.lineWrapping||(e.display.maxLineChanged=!0),e.display.lineNumChars=null}function tr(){return bl&&kl?-(document.body.getBoundingClientRect().left-parseInt(getComputedStyle(document.body).marginLeft)):window.pageXOffset||(document.documentElement||document.body).scrollLeft}function rr(){return bl&&kl?-(document.body.getBoundingClientRect().top-parseInt(getComputedStyle(document.body).marginTop)):window.pageYOffset||(document.documentElement||document.body).scrollTop}function nr(e){var t=0;if(e.widgets)for(var r=0;r<e.widgets.length;++r)e.widgets[r].above&&(t+=Ht(e.widgets[r]));return t}function ir(e,t,r,n,i){if(!i){var o=nr(t);r.top+=o,r.bottom+=o}if("line"==n)return r;n||(n="local");var l=ye(t);if("local"==n?l+=Et(e.display):l-=e.display.viewOffset,"page"==n||"window"==n){var s=e.display.lineSpace.getBoundingClientRect();l+=s.top+("window"==n?0:rr());var a=s.left+("window"==n?0:tr());r.left+=a,r.right+=a}return r.top+=l,r.bottom+=l,r}function or(e,t,r){if("div"==r)return t;var n=t.left,i=t.top;if("page"==r)n-=tr(),i-=rr();else if("local"==r||!r){var o=e.display.sizer.getBoundingClientRect();n+=o.left,i+=o.top}var l=e.display.lineSpace.getBoundingClientRect();return{left:n-l.left,top:i-l.top}}function lr(e,t,r,n,i){return n||(n=M(e.doc,t.line)),ir(e,n,Kt(e,n,t.ch,i),r)}function sr(e,t,r,n,i,o){function l(t,l){var s=Yt(e,i,t,l?"right":"left",o);return l?s.left=s.right:s.right=s.left,ir(e,n,s,r)}function s(e,t,r){var n=1==a[t].level;return l(r?e-1:e,n!=r)}n=n||M(e.doc,t.line),i||(i=Xt(e,n));var a=Se(n,e.doc.direction),u=t.ch,c=t.sticky;if(u>=n.text.length?(u=n.text.length,c="before"):u<=0&&(u=0,c="after"),!a)return l("before"==c?u-1:u,"before"==c);var f=Ce(a,u,c),h=$l,d=s(u,f,"before"==c);return null!=h&&(d.other=s(u,h,"before"!=c)),d}function ar(e,t){var r=0;t=U(e.doc,t),e.options.lineWrapping||(r=yr(e.display)*t.ch);var n=M(e.doc,t.line),i=ye(n)+Et(e.display);return{left:r,right:r,top:i,bottom:i+n.height}}function ur(e,t,r,n,i){var o=E(e,t,r);return o.xRel=i,n&&(o.outside=!0),o}function cr(e,t,r){var n=e.doc;if((r+=e.display.viewOffset)<0)return ur(n.first,0,null,!0,-1);var i=D(n,r),o=n.first+n.size-1;if(i>o)return ur(n.first+n.size-1,M(n,o).text.length,null,!0,1);t<0&&(t=0);for(var l=M(n,i);;){var s=pr(e,l,i,t,r),a=ue(l),u=a&&a.find(0,!0);if(!a||!(s.ch>u.from.ch||s.ch==u.from.ch&&s.xRel>0))return s;i=W(l=u.to.line)}}function fr(e,t,r,n){n-=nr(t);var i=t.text.length,o=k(function(t){return Yt(e,r,t-1).bottom<=n},i,0);return i=k(function(t){return Yt(e,r,t).top>n},o,i),{begin:o,end:i}}function hr(e,t,r,n){return r||(r=Xt(e,t)),fr(e,t,r,ir(e,t,Yt(e,r,n),"line").top)}function dr(e,t,r,n){return!(e.bottom<=r)&&(e.top>r||(n?e.left:e.right)>t)}function pr(e,t,r,n,i){i-=ye(t);var o=Xt(e,t),l=nr(t),s=0,a=t.text.length,u=!0,c=Se(t,e.doc.direction);if(c){var f=(e.options.lineWrapping?vr:gr)(e,t,r,o,c,n,i);s=(u=1!=f.level)?f.from:f.to-1,a=u?f.to:f.from-1}var h,d,p=null,g=null,v=k(function(t){var r=Yt(e,o,t);return r.top+=l,r.bottom+=l,!!dr(r,n,i,!1)&&(r.top<=i&&r.left<=n&&(p=t,g=r),!0)},s,a),m=!1;if(g){var y=n-g.left<g.right-n,b=y==u;v=p+(b?0:1),d=b?"after":"before",h=y?g.left:g.right}else{u||v!=a&&v!=s||v++,d=0==v?"after":v==t.text.length?"before":Yt(e,o,v-(u?1:0)).bottom+l<=i==u?"after":"before";var w=sr(e,E(r,v,d),"line",t,o);h=w.left,m=i<w.top||i>=w.bottom}return v=L(t.text,v,1),ur(r,v,d,m,n-h)}function gr(e,t,r,n,i,o,l){var s=k(function(s){var a=i[s],u=1!=a.level;return dr(sr(e,E(r,u?a.to:a.from,u?"before":"after"),"line",t,n),o,l,!0)},0,i.length-1),a=i[s];if(s>0){var u=1!=a.level,c=sr(e,E(r,u?a.from:a.to,u?"after":"before"),"line",t,n);dr(c,o,l,!0)&&c.top>l&&(a=i[s-1])}return a}function vr(e,t,r,n,i,o,l){for(var s=fr(e,t,n,l),a=s.begin,u=s.end,c=null,f=null,h=0;h<i.length;h++){var d=i[h];if(!(d.from>=u||d.to<=a)){var p=Yt(e,n,1!=d.level?Math.min(u,d.to)-1:Math.max(a,d.from)).right,g=p<o?o-p+1e9:p-o;(!c||f>g)&&(c=d,f=g)}}return c||(c=i[i.length-1]),c.from<a&&(c={from:a,to:c.to,level:c.level}),c.to>u&&(c={from:c.from,to:u,level:c.level}),c}function mr(e){if(null!=e.cachedTextHeight)return e.cachedTextHeight;if(null==hs){hs=n("pre");for(var i=0;i<49;++i)hs.appendChild(document.createTextNode("x")),hs.appendChild(n("br"));hs.appendChild(document.createTextNode("x"))}r(e.measure,hs);var o=hs.offsetHeight/50;return o>3&&(e.cachedTextHeight=o),t(e.measure),o||1}function yr(e){if(null!=e.cachedCharWidth)return e.cachedCharWidth;var t=n("span","xxxxxxxxxx"),i=n("pre",[t]);r(e.measure,i);var o=t.getBoundingClientRect(),l=(o.right-o.left)/10;return l>2&&(e.cachedCharWidth=l),l||10}function br(e){for(var t=e.display,r={},n={},i=t.gutters.clientLeft,o=t.gutters.firstChild,l=0;o;o=o.nextSibling,++l)r[e.options.gutters[l]]=o.offsetLeft+o.clientLeft+i,n[e.options.gutters[l]]=o.clientWidth;return{fixedPos:wr(t),gutterTotalWidth:t.gutters.offsetWidth,gutterLeft:r,gutterWidth:n,wrapperWidth:t.wrapper.clientWidth}}function wr(e){return e.scroller.getBoundingClientRect().left-e.sizer.getBoundingClientRect().left}function xr(e){var t=mr(e.display),r=e.options.lineWrapping,n=r&&Math.max(5,e.display.scroller.clientWidth/yr(e.display)-3);return function(i){if(ve(e.doc,i))return 0;var o=0;if(i.widgets)for(var l=0;l<i.widgets.length;l++)i.widgets[l].height&&(o+=i.widgets[l].height);return r?o+(Math.ceil(i.text.length/n)||1)*t:o+t}}function Cr(e){var t=e.doc,r=xr(e);t.iter(function(e){var t=r(e);t!=e.height&&A(e,t)})}function Sr(e,t,r,n){var i=e.display;if(!r&&"true"==Ee(t).getAttribute("cm-not-content"))return null;var o,l,s=i.lineSpace.getBoundingClientRect();try{o=t.clientX-s.left,l=t.clientY-s.top}catch(t){return null}var a,u=cr(e,o,l);if(n&&1==u.xRel&&(a=M(e.doc,u.line).text).length==u.ch){var c=f(a,a.length,e.options.tabSize)-a.length;u=E(u.line,Math.max(0,Math.round((o-It(e.display).left)/yr(e.display))-c))}return u}function Lr(e,t){if(t>=e.display.viewTo)return null;if((t-=e.display.viewFrom)<0)return null;for(var r=e.display.view,n=0;n<r.length;n++)if((t-=r[n].size)<0)return n}function kr(e){e.display.input.showSelection(e.display.input.prepareSelection())}function Tr(e,t){void 0===t&&(t=!0);for(var r=e.doc,n={},i=n.cursors=document.createDocumentFragment(),o=n.selection=document.createDocumentFragment(),l=0;l<r.sel.ranges.length;l++)if(t||l!=r.sel.primIndex){var s=r.sel.ranges[l];if(!(s.from().line>=e.display.viewTo||s.to().line<e.display.viewFrom)){var a=s.empty();(a||e.options.showCursorWhenSelecting)&&Mr(e,s.head,i),a||Or(e,s,o)}}return n}function Mr(e,t,r){var i=sr(e,t,"div",null,null,!e.options.singleCursorHeightPerLine),o=r.appendChild(n("div"," ","CodeMirror-cursor"));if(o.style.left=i.left+"px",o.style.top=i.top+"px",o.style.height=Math.max(0,i.bottom-i.top)*e.options.cursorHeight+"px",i.other){var l=r.appendChild(n("div"," ","CodeMirror-cursor CodeMirror-secondarycursor"));l.style.display="",l.style.left=i.other.left+"px",l.style.top=i.other.top+"px",l.style.height=.85*(i.other.bottom-i.other.top)+"px"}}function Nr(e,t){return e.top-t.top||e.left-t.left}function Or(e,t,r){function i(e,t,r,i){t<0&&(t=0),t=Math.round(t),i=Math.round(i),a.appendChild(n("div",null,"CodeMirror-selected","position: absolute; left: "+e+"px;\n                             top: "+t+"px; width: "+(null==r?f-e:r)+"px;\n                             height: "+(i-t)+"px"))}function o(t,r,n){function o(r,n){return lr(e,E(t,r),"div",u,n)}var l,a,u=M(s,t),h=u.text.length,d=Se(u,s.direction);return xe(d,r||0,null==n?h:n,function(t,s,p,g){var v=o(t,"ltr"==p?"left":"right"),m=o(s-1,"ltr"==p?"right":"left");if("ltr"==p){var y=null==r&&0==t?c:v.left,b=null==n&&s==h?f:m.right;m.top-v.top<=3?i(y,m.top,b-y,m.bottom):(i(y,v.top,null,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top),i(c,m.top,m.right,m.bottom))}else if(t<s){var w=null==r&&0==t?f:v.right,x=null==n&&s==h?c:m.left;if(m.top-v.top<=3)i(x,m.top,w-x,m.bottom);else{var C=c;if(g){var S=hr(e,u,null,t).end;C=o(S-(/\s/.test(u.text.charAt(S-1))?2:1),"left").left}i(C,v.top,w-C,v.bottom),v.bottom<m.top&&i(c,v.bottom,null,m.top);var L=null;d.length,L=o(hr(e,u,null,s).begin,"right").right-x,i(x,m.top,L,m.bottom)}}(!l||Nr(v,l)<0)&&(l=v),Nr(m,l)<0&&(l=m),(!a||Nr(v,a)<0)&&(a=v),Nr(m,a)<0&&(a=m)}),{start:l,end:a}}var l=e.display,s=e.doc,a=document.createDocumentFragment(),u=It(e.display),c=u.left,f=Math.max(l.sizerWidth,Rt(e)-l.sizer.offsetLeft)-u.right,h=t.from(),d=t.to();if(h.line==d.line)o(h.line,h.ch,d.ch);else{var p=M(s,h.line),g=M(s,d.line),v=fe(p)==fe(g),m=o(h.line,h.ch,v?p.text.length+1:null).end,y=o(d.line,v?0:null,d.ch).start;v&&(m.top<y.top-2?(i(m.right,m.top,null,m.bottom),i(c,y.top,y.left,y.bottom)):i(m.right,m.top,y.left-m.right,m.bottom)),m.bottom<y.top&&i(c,m.bottom,null,y.top)}r.appendChild(a)}function Ar(e){if(e.state.focused){var t=e.display;clearInterval(t.blinker);var r=!0;t.cursorDiv.style.visibility="",e.options.cursorBlinkRate>0?t.blinker=setInterval(function(){return t.cursorDiv.style.visibility=(r=!r)?"":"hidden"},e.options.cursorBlinkRate):e.options.cursorBlinkRate<0&&(t.cursorDiv.style.visibility="hidden")}}function Wr(e){e.state.focused||(e.display.input.focus(),Hr(e))}function Dr(e){e.state.delayingBlurEvent=!0,setTimeout(function(){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1,Fr(e))},100)}function Hr(e,t){e.state.delayingBlurEvent&&(e.state.delayingBlurEvent=!1),"nocursor"!=e.options.readOnly&&(e.state.focused||(Te(e,"focus",e,t),e.state.focused=!0,s(e.display.wrapper,"CodeMirror-focused"),e.curOp||e.display.selForContextMenu==e.doc.sel||(e.display.input.reset(),ml&&setTimeout(function(){return e.display.input.reset(!0)},20)),e.display.input.receivedFocus()),Ar(e))}function Fr(e,t){e.state.delayingBlurEvent||(e.state.focused&&(Te(e,"blur",e,t),e.state.focused=!1,Fl(e.display.wrapper,"CodeMirror-focused")),clearInterval(e.display.blinker),setTimeout(function(){e.state.focused||(e.display.shift=!1)},150))}function Er(e){for(var t=e.display,r=t.lineDiv.offsetTop,n=0;n<t.view.length;n++){var i=t.view[n],o=void 0;if(!i.hidden){if(gl&&vl<8){var l=i.node.offsetTop+i.node.offsetHeight;o=l-r,r=l}else{var s=i.node.getBoundingClientRect();o=s.bottom-s.top}var a=i.line.height-o;if(o<2&&(o=mr(t)),(a>.005||a<-.005)&&(A(i.line,o),Pr(i.line),i.rest))for(var u=0;u<i.rest.length;u++)Pr(i.rest[u])}}}function Pr(e){if(e.widgets)for(var t=0;t<e.widgets.length;++t)e.widgets[t].height=e.widgets[t].node.parentNode.offsetHeight}function Ir(e,t,r){var n=r&&null!=r.top?Math.max(0,r.top):e.scroller.scrollTop;n=Math.floor(n-Et(e));var i=r&&null!=r.bottom?r.bottom:n+e.wrapper.clientHeight,o=D(t,n),l=D(t,i);if(r&&r.ensure){var s=r.ensure.from.line,a=r.ensure.to.line;s<o?(o=s,l=D(t,ye(M(t,s))+e.wrapper.clientHeight)):Math.min(a,t.lastLine())>=l&&(o=D(t,ye(M(t,a))-e.wrapper.clientHeight),l=a)}return{from:o,to:Math.max(l,o+1)}}function zr(e){var t=e.display,r=t.view;if(t.alignWidgets||t.gutters.firstChild&&e.options.fixedGutter){for(var n=wr(t)-t.scroller.scrollLeft+e.doc.scrollLeft,i=t.gutters.offsetWidth,o=n+"px",l=0;l<r.length;l++)if(!r[l].hidden){e.options.fixedGutter&&(r[l].gutter&&(r[l].gutter.style.left=o),r[l].gutterBackground&&(r[l].gutterBackground.style.left=o));var s=r[l].alignable;if(s)for(var a=0;a<s.length;a++)s[a].style.left=o}e.options.fixedGutter&&(t.gutters.style.left=n+i+"px")}}function Rr(e){if(!e.options.lineNumbers)return!1;var t=e.doc,r=F(e.options,t.first+t.size-1),i=e.display;if(r.length!=i.lineNumChars){var o=i.measure.appendChild(n("div",[n("div",r)],"CodeMirror-linenumber CodeMirror-gutter-elt")),l=o.firstChild.offsetWidth,s=o.offsetWidth-l;return i.lineGutter.style.width="",i.lineNumInnerWidth=Math.max(l,i.lineGutter.offsetWidth-s)+1,i.lineNumWidth=i.lineNumInnerWidth+s,i.lineNumChars=i.lineNumInnerWidth?r.length:-1,i.lineGutter.style.width=i.lineNumWidth+"px",Wn(e),!0}return!1}function Br(e,t){if(!Me(e,"scrollCursorIntoView")){var r=e.display,i=r.sizer.getBoundingClientRect(),o=null;if(t.top+i.top<0?o=!0:t.bottom+i.top>(window.innerHeight||document.documentElement.clientHeight)&&(o=!1),null!=o&&!Sl){var l=n("div","​",null,"position: absolute;\n                         top: "+(t.top-r.viewOffset-Et(e.display))+"px;\n                         height: "+(t.bottom-t.top+zt(e)+r.barHeight)+"px;\n                         left: "+t.left+"px; width: "+Math.max(2,t.right-t.left)+"px;");e.display.lineSpace.appendChild(l),l.scrollIntoView(o),e.display.lineSpace.removeChild(l)}}}function Gr(e,t,r,n){null==n&&(n=0);var i;e.options.lineWrapping||t!=r||(r="before"==(t=t.ch?E(t.line,"before"==t.sticky?t.ch-1:t.ch,"after"):t).sticky?E(t.line,t.ch+1,"before"):t);for(var o=0;o<5;o++){var l=!1,s=sr(e,t),a=r&&r!=t?sr(e,r):s,u=Vr(e,i={left:Math.min(s.left,a.left),top:Math.min(s.top,a.top)-n,right:Math.max(s.left,a.left),bottom:Math.max(s.bottom,a.bottom)+n}),c=e.doc.scrollTop,f=e.doc.scrollLeft;if(null!=u.scrollTop&&(qr(e,u.scrollTop),Math.abs(e.doc.scrollTop-c)>1&&(l=!0)),null!=u.scrollLeft&&(Qr(e,u.scrollLeft),Math.abs(e.doc.scrollLeft-f)>1&&(l=!0)),!l)break}return i}function Ur(e,t){var r=Vr(e,t);null!=r.scrollTop&&qr(e,r.scrollTop),null!=r.scrollLeft&&Qr(e,r.scrollLeft)}function Vr(e,t){var r=e.display,n=mr(e.display);t.top<0&&(t.top=0);var i=e.curOp&&null!=e.curOp.scrollTop?e.curOp.scrollTop:r.scroller.scrollTop,o=Bt(e),l={};t.bottom-t.top>o&&(t.bottom=t.top+o);var s=e.doc.height+Pt(r),a=t.top<n,u=t.bottom>s-n;if(t.top<i)l.scrollTop=a?0:t.top;else if(t.bottom>i+o){var c=Math.min(t.top,(u?s:t.bottom)-o);c!=i&&(l.scrollTop=c)}var f=e.curOp&&null!=e.curOp.scrollLeft?e.curOp.scrollLeft:r.scroller.scrollLeft,h=Rt(e)-(e.options.fixedGutter?r.gutters.offsetWidth:0),d=t.right-t.left>h;return d&&(t.right=t.left+h),t.left<10?l.scrollLeft=0:t.left<f?l.scrollLeft=Math.max(0,t.left-(d?0:10)):t.right>h+f-3&&(l.scrollLeft=t.right+(d?0:10)-h),l}function Kr(e,t){null!=t&&(_r(e),e.curOp.scrollTop=(null==e.curOp.scrollTop?e.doc.scrollTop:e.curOp.scrollTop)+t)}function jr(e){_r(e);var t=e.getCursor();e.curOp.scrollToPos={from:t,to:t,margin:e.options.cursorScrollMargin}}function Xr(e,t,r){null==t&&null==r||_r(e),null!=t&&(e.curOp.scrollLeft=t),null!=r&&(e.curOp.scrollTop=r)}function Yr(e,t){_r(e),e.curOp.scrollToPos=t}function _r(e){var t=e.curOp.scrollToPos;t&&(e.curOp.scrollToPos=null,$r(e,ar(e,t.from),ar(e,t.to),t.margin))}function $r(e,t,r,n){var i=Vr(e,{left:Math.min(t.left,r.left),top:Math.min(t.top,r.top)-n,right:Math.max(t.right,r.right),bottom:Math.max(t.bottom,r.bottom)+n});Xr(e,i.scrollLeft,i.scrollTop)}function qr(e,t){Math.abs(e.doc.scrollTop-t)<2||(fl||On(e,{top:t}),Zr(e,t,!0),fl&&On(e),Cn(e,100))}function Zr(e,t,r){t=Math.min(e.display.scroller.scrollHeight-e.display.scroller.clientHeight,t),(e.display.scroller.scrollTop!=t||r)&&(e.doc.scrollTop=t,e.display.scrollbars.setScrollTop(t),e.display.scroller.scrollTop!=t&&(e.display.scroller.scrollTop=t))}function Qr(e,t,r,n){t=Math.min(t,e.display.scroller.scrollWidth-e.display.scroller.clientWidth),(r?t==e.doc.scrollLeft:Math.abs(e.doc.scrollLeft-t)<2)&&!n||(e.doc.scrollLeft=t,zr(e),e.display.scroller.scrollLeft!=t&&(e.display.scroller.scrollLeft=t),e.display.scrollbars.setScrollLeft(t))}function Jr(e){var t=e.display,r=t.gutters.offsetWidth,n=Math.round(e.doc.height+Pt(e.display));return{clientHeight:t.scroller.clientHeight,viewHeight:t.wrapper.clientHeight,scrollWidth:t.scroller.scrollWidth,clientWidth:t.scroller.clientWidth,viewWidth:t.wrapper.clientWidth,barLeft:e.options.fixedGutter?r:0,docHeight:n,scrollHeight:n+zt(e)+t.barHeight,nativeBarWidth:t.nativeBarWidth,gutterWidth:r}}function en(e,t){t||(t=Jr(e));var r=e.display.barWidth,n=e.display.barHeight;tn(e,t);for(var i=0;i<4&&r!=e.display.barWidth||n!=e.display.barHeight;i++)r!=e.display.barWidth&&e.options.lineWrapping&&Er(e),tn(e,Jr(e)),r=e.display.barWidth,n=e.display.barHeight}function tn(e,t){var r=e.display,n=r.scrollbars.update(t);r.sizer.style.paddingRight=(r.barWidth=n.right)+"px",r.sizer.style.paddingBottom=(r.barHeight=n.bottom)+"px",r.heightForcer.style.borderBottom=n.bottom+"px solid transparent",n.right&&n.bottom?(r.scrollbarFiller.style.display="block",r.scrollbarFiller.style.height=n.bottom+"px",r.scrollbarFiller.style.width=n.right+"px"):r.scrollbarFiller.style.display="",n.bottom&&e.options.coverGutterNextToScrollbar&&e.options.fixedGutter?(r.gutterFiller.style.display="block",r.gutterFiller.style.height=n.bottom+"px",r.gutterFiller.style.width=t.gutterWidth+"px"):r.gutterFiller.style.display=""}function rn(e){e.display.scrollbars&&(e.display.scrollbars.clear(),e.display.scrollbars.addClass&&Fl(e.display.wrapper,e.display.scrollbars.addClass)),e.display.scrollbars=new ws[e.options.scrollbarStyle](function(t){e.display.wrapper.insertBefore(t,e.display.scrollbarFiller),Ql(t,"mousedown",function(){e.state.focused&&setTimeout(function(){return e.display.input.focus()},0)}),t.setAttribute("cm-not-content","true")},function(t,r){"horizontal"==r?Qr(e,t):qr(e,t)},e),e.display.scrollbars.addClass&&s(e.display.wrapper,e.display.scrollbars.addClass)}function nn(e){e.curOp={cm:e,viewChanged:!1,startHeight:e.doc.height,forceUpdate:!1,updateInput:null,typing:!1,changeObjs:null,cursorActivityHandlers:null,cursorActivityCalled:0,selectionChanged:!1,updateMaxLine:!1,scrollLeft:null,scrollTop:null,scrollToPos:null,focus:!1,id:++xs},vt(e.curOp)}function on(e){yt(e.curOp,function(e){for(var t=0;t<e.ops.length;t++)e.ops[t].cm.curOp=null;ln(e)})}function ln(e){for(var t=e.ops,r=0;r<t.length;r++)sn(t[r]);for(var n=0;n<t.length;n++)an(t[n]);for(var i=0;i<t.length;i++)un(t[i]);for(var o=0;o<t.length;o++)cn(t[o]);for(var l=0;l<t.length;l++)fn(t[l])}function sn(e){var t=e.cm,r=t.display;Ln(t),e.updateMaxLine&&we(t),e.mustUpdate=e.viewChanged||e.forceUpdate||null!=e.scrollTop||e.scrollToPos&&(e.scrollToPos.from.line<r.viewFrom||e.scrollToPos.to.line>=r.viewTo)||r.maxLineChanged&&t.options.lineWrapping,e.update=e.mustUpdate&&new Cs(t,e.mustUpdate&&{top:e.scrollTop,ensure:e.scrollToPos},e.forceUpdate)}function an(e){e.updatedDisplay=e.mustUpdate&&Mn(e.cm,e.update)}function un(e){var t=e.cm,r=t.display;e.updatedDisplay&&Er(t),e.barMeasure=Jr(t),r.maxLineChanged&&!t.options.lineWrapping&&(e.adjustWidthTo=Kt(t,r.maxLine,r.maxLine.text.length).left+3,t.display.sizerWidth=e.adjustWidthTo,e.barMeasure.scrollWidth=Math.max(r.scroller.clientWidth,r.sizer.offsetLeft+e.adjustWidthTo+zt(t)+t.display.barWidth),e.maxScrollLeft=Math.max(0,r.sizer.offsetLeft+e.adjustWidthTo-Rt(t))),(e.updatedDisplay||e.selectionChanged)&&(e.preparedSelection=r.input.prepareSelection())}function cn(e){var t=e.cm;null!=e.adjustWidthTo&&(t.display.sizer.style.minWidth=e.adjustWidthTo+"px",e.maxScrollLeft<t.doc.scrollLeft&&Qr(t,Math.min(t.display.scroller.scrollLeft,e.maxScrollLeft),!0),t.display.maxLineChanged=!1);var r=e.focus&&e.focus==l();e.preparedSelection&&t.display.input.showSelection(e.preparedSelection,r),(e.updatedDisplay||e.startHeight!=t.doc.height)&&en(t,e.barMeasure),e.updatedDisplay&&Dn(t,e.barMeasure),e.selectionChanged&&Ar(t),t.state.focused&&e.updateInput&&t.display.input.reset(e.typing),r&&Wr(e.cm)}function fn(e){var t=e.cm,r=t.display,n=t.doc;e.updatedDisplay&&Nn(t,e.update),null==r.wheelStartX||null==e.scrollTop&&null==e.scrollLeft&&!e.scrollToPos||(r.wheelStartX=r.wheelStartY=null),null!=e.scrollTop&&Zr(t,e.scrollTop,e.forceScroll),null!=e.scrollLeft&&Qr(t,e.scrollLeft,!0,!0),e.scrollToPos&&Br(t,Gr(t,U(n,e.scrollToPos.from),U(n,e.scrollToPos.to),e.scrollToPos.margin));var i=e.maybeHiddenMarkers,o=e.maybeUnhiddenMarkers;if(i)for(var l=0;l<i.length;++l)i[l].lines.length||Te(i[l],"hide");if(o)for(var s=0;s<o.length;++s)o[s].lines.length&&Te(o[s],"unhide");r.wrapper.offsetHeight&&(n.scrollTop=t.display.scroller.scrollTop),e.changeObjs&&Te(t,"changes",t,e.changeObjs),e.update&&e.update.finish()}function hn(e,t){if(e.curOp)return t();nn(e);try{return t()}finally{on(e)}}function dn(e,t){return function(){if(e.curOp)return t.apply(e,arguments);nn(e);try{return t.apply(e,arguments)}finally{on(e)}}}function pn(e){return function(){if(this.curOp)return e.apply(this,arguments);nn(this);try{return e.apply(this,arguments)}finally{on(this)}}}function gn(e){return function(){var t=this.cm;if(!t||t.curOp)return e.apply(this,arguments);nn(t);try{return e.apply(this,arguments)}finally{on(t)}}}function vn(e,t,r,n){null==t&&(t=e.doc.first),null==r&&(r=e.doc.first+e.doc.size),n||(n=0);var i=e.display;if(n&&r<i.viewTo&&(null==i.updateLineNumbers||i.updateLineNumbers>t)&&(i.updateLineNumbers=t),e.curOp.viewChanged=!0,t>=i.viewTo)_l&&pe(e.doc,t)<i.viewTo&&yn(e);else if(r<=i.viewFrom)_l&&ge(e.doc,r+n)>i.viewFrom?yn(e):(i.viewFrom+=n,i.viewTo+=n);else if(t<=i.viewFrom&&r>=i.viewTo)yn(e);else if(t<=i.viewFrom){var o=bn(e,r,r+n,1);o?(i.view=i.view.slice(o.index),i.viewFrom=o.lineN,i.viewTo+=n):yn(e)}else if(r>=i.viewTo){var l=bn(e,t,t,-1);l?(i.view=i.view.slice(0,l.index),i.viewTo=l.lineN):yn(e)}else{var s=bn(e,t,t,-1),a=bn(e,r,r+n,1);s&&a?(i.view=i.view.slice(0,s.index).concat(gt(e,s.lineN,a.lineN)).concat(i.view.slice(a.index)),i.viewTo+=n):yn(e)}var u=i.externalMeasured;u&&(r<u.lineN?u.lineN+=n:t<u.lineN+u.size&&(i.externalMeasured=null))}function mn(e,t,r){e.curOp.viewChanged=!0;var n=e.display,i=e.display.externalMeasured;if(i&&t>=i.lineN&&t<i.lineN+i.size&&(n.externalMeasured=null),!(t<n.viewFrom||t>=n.viewTo)){var o=n.view[Lr(e,t)];if(null!=o.node){var l=o.changes||(o.changes=[]);-1==h(l,r)&&l.push(r)}}}function yn(e){e.display.viewFrom=e.display.viewTo=e.doc.first,e.display.view=[],e.display.viewOffset=0}function bn(e,t,r,n){var i,o=Lr(e,t),l=e.display.view;if(!_l||r==e.doc.first+e.doc.size)return{index:o,lineN:r};for(var s=e.display.viewFrom,a=0;a<o;a++)s+=l[a].size;if(s!=t){if(n>0){if(o==l.length-1)return null;i=s+l[o].size-t,o++}else i=s-t;t+=i,r+=i}for(;pe(e.doc,r)!=r;){if(o==(n<0?0:l.length-1))return null;r+=n*l[o-(n<0?1:0)].size,o+=n}return{index:o,lineN:r}}function wn(e,t,r){var n=e.display;0==n.view.length||t>=n.viewTo||r<=n.viewFrom?(n.view=gt(e,t,r),n.viewFrom=t):(n.viewFrom>t?n.view=gt(e,t,n.viewFrom).concat(n.view):n.viewFrom<t&&(n.view=n.view.slice(Lr(e,t))),n.viewFrom=t,n.viewTo<r?n.view=n.view.concat(gt(e,n.viewTo,r)):n.viewTo>r&&(n.view=n.view.slice(0,Lr(e,r)))),n.viewTo=r}function xn(e){for(var t=e.display.view,r=0,n=0;n<t.length;n++){var i=t[n];i.hidden||i.node&&!i.changes||++r}return r}function Cn(e,t){e.doc.highlightFrontier<e.display.viewTo&&e.state.highlight.set(t,u(Sn,e))}function Sn(e){var t=e.doc;if(!(t.highlightFrontier>=e.display.viewTo)){var r=+new Date+e.options.workTime,n=$e(e,t.highlightFrontier),i=[];t.iter(n.line,Math.min(t.first+t.size,e.display.viewTo+500),function(o){if(n.line>=e.display.viewFrom){var l=o.styles,s=o.text.length>e.options.maxHighlightLength?Ke(t.mode,n.state):null,a=Ye(e,o,n,!0);s&&(n.state=s),o.styles=a.styles;var u=o.styleClasses,c=a.classes;c?o.styleClasses=c:u&&(o.styleClasses=null);for(var f=!l||l.length!=o.styles.length||u!=c&&(!u||!c||u.bgClass!=c.bgClass||u.textClass!=c.textClass),h=0;!f&&h<l.length;++h)f=l[h]!=o.styles[h];f&&i.push(n.line),o.stateAfter=n.save(),n.nextLine()}else o.text.length<=e.options.maxHighlightLength&&qe(e,o.text,n),o.stateAfter=n.line%5==0?n.save():null,n.nextLine();if(+new Date>r)return Cn(e,e.options.workDelay),!0}),t.highlightFrontier=n.line,t.modeFrontier=Math.max(t.modeFrontier,n.line),i.length&&hn(e,function(){for(var t=0;t<i.length;t++)mn(e,i[t],"text")})}}function Ln(e){var t=e.display;!t.scrollbarsClipped&&t.scroller.offsetWidth&&(t.nativeBarWidth=t.scroller.offsetWidth-t.scroller.clientWidth,t.heightForcer.style.height=zt(e)+"px",t.sizer.style.marginBottom=-t.nativeBarWidth+"px",t.sizer.style.borderRightWidth=zt(e)+"px",t.scrollbarsClipped=!0)}function kn(e){if(e.hasFocus())return null;var t=l();if(!t||!o(e.display.lineDiv,t))return null;var r={activeElt:t};if(window.getSelection){var n=window.getSelection();n.anchorNode&&n.extend&&o(e.display.lineDiv,n.anchorNode)&&(r.anchorNode=n.anchorNode,r.anchorOffset=n.anchorOffset,r.focusNode=n.focusNode,r.focusOffset=n.focusOffset)}return r}function Tn(e){if(e&&e.activeElt&&e.activeElt!=l()&&(e.activeElt.focus(),e.anchorNode&&o(document.body,e.anchorNode)&&o(document.body,e.focusNode))){var t=window.getSelection(),r=document.createRange();r.setEnd(e.anchorNode,e.anchorOffset),r.collapse(!1),t.removeAllRanges(),t.addRange(r),t.extend(e.focusNode,e.focusOffset)}}function Mn(e,r){var n=e.display,i=e.doc;if(r.editorIsHidden)return yn(e),!1;if(!r.force&&r.visible.from>=n.viewFrom&&r.visible.to<=n.viewTo&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo)&&n.renderedView==n.view&&0==xn(e))return!1;Rr(e)&&(yn(e),r.dims=br(e));var o=i.first+i.size,l=Math.max(r.visible.from-e.options.viewportMargin,i.first),s=Math.min(o,r.visible.to+e.options.viewportMargin);n.viewFrom<l&&l-n.viewFrom<20&&(l=Math.max(i.first,n.viewFrom)),n.viewTo>s&&n.viewTo-s<20&&(s=Math.min(o,n.viewTo)),_l&&(l=pe(e.doc,l),s=ge(e.doc,s));var a=l!=n.viewFrom||s!=n.viewTo||n.lastWrapHeight!=r.wrapperHeight||n.lastWrapWidth!=r.wrapperWidth;wn(e,l,s),n.viewOffset=ye(M(e.doc,n.viewFrom)),e.display.mover.style.top=n.viewOffset+"px";var u=xn(e);if(!a&&0==u&&!r.force&&n.renderedView==n.view&&(null==n.updateLineNumbers||n.updateLineNumbers>=n.viewTo))return!1;var c=kn(e);return u>4&&(n.lineDiv.style.display="none"),An(e,n.updateLineNumbers,r.dims),u>4&&(n.lineDiv.style.display=""),n.renderedView=n.view,Tn(c),t(n.cursorDiv),t(n.selectionDiv),n.gutters.style.height=n.sizer.style.minHeight=0,a&&(n.lastWrapHeight=r.wrapperHeight,n.lastWrapWidth=r.wrapperWidth,Cn(e,400)),n.updateLineNumbers=null,!0}function Nn(e,t){for(var r=t.viewport,n=!0;(n&&e.options.lineWrapping&&t.oldDisplayWidth!=Rt(e)||(r&&null!=r.top&&(r={top:Math.min(e.doc.height+Pt(e.display)-Bt(e),r.top)}),t.visible=Ir(e.display,e.doc,r),!(t.visible.from>=e.display.viewFrom&&t.visible.to<=e.display.viewTo)))&&Mn(e,t);n=!1){Er(e);var i=Jr(e);kr(e),en(e,i),Dn(e,i),t.force=!1}t.signal(e,"update",e),e.display.viewFrom==e.display.reportedViewFrom&&e.display.viewTo==e.display.reportedViewTo||(t.signal(e,"viewportChange",e,e.display.viewFrom,e.display.viewTo),e.display.reportedViewFrom=e.display.viewFrom,e.display.reportedViewTo=e.display.viewTo)}function On(e,t){var r=new Cs(e,t);if(Mn(e,r)){Er(e),Nn(e,r);var n=Jr(e);kr(e),en(e,n),Dn(e,n),r.finish()}}function An(e,r,n){function i(t){var r=t.nextSibling;return ml&&Ml&&e.display.currentWheelTarget==t?t.style.display="none":t.parentNode.removeChild(t),r}for(var o=e.display,l=e.options.lineNumbers,s=o.lineDiv,a=s.firstChild,u=o.view,c=o.viewFrom,f=0;f<u.length;f++){var d=u[f];if(d.hidden);else if(d.node&&d.node.parentNode==s){for(;a!=d.node;)a=i(a);var p=l&&null!=r&&r<=c&&d.lineNumber;d.changes&&(h(d.changes,"gutter")>-1&&(p=!1),xt(e,d,c,n)),p&&(t(d.lineNumber),d.lineNumber.appendChild(document.createTextNode(F(e.options,c)))),a=d.node.nextSibling}else{var g=Ot(e,d,c,n);s.insertBefore(g,a)}c+=d.size}for(;a;)a=i(a)}function Wn(e){var t=e.display.gutters.offsetWidth;e.display.sizer.style.marginLeft=t+"px"}function Dn(e,t){e.display.sizer.style.minHeight=t.docHeight+"px",e.display.heightForcer.style.top=t.docHeight+"px",e.display.gutters.style.height=t.docHeight+e.display.barHeight+zt(e)+"px"}function Hn(e){var r=e.display.gutters,i=e.options.gutters;t(r);for(var o=0;o<i.length;++o){var l=i[o],s=r.appendChild(n("div",null,"CodeMirror-gutter "+l));"CodeMirror-linenumbers"==l&&(e.display.lineGutter=s,s.style.width=(e.display.lineNumWidth||1)+"px")}r.style.display=o?"":"none",Wn(e)}function Fn(e){var t=h(e.gutters,"CodeMirror-linenumbers");-1==t&&e.lineNumbers?e.gutters=e.gutters.concat(["CodeMirror-linenumbers"]):t>-1&&!e.lineNumbers&&(e.gutters=e.gutters.slice(0),e.gutters.splice(t,1))}function En(e){var t=e.wheelDeltaX,r=e.wheelDeltaY;return null==t&&e.detail&&e.axis==e.HORIZONTAL_AXIS&&(t=e.detail),null==r&&e.detail&&e.axis==e.VERTICAL_AXIS?r=e.detail:null==r&&(r=e.wheelDelta),{x:t,y:r}}function Pn(e){var t=En(e);return t.x*=Ls,t.y*=Ls,t}function In(e,t){var r=En(t),n=r.x,i=r.y,o=e.display,l=o.scroller,s=l.scrollWidth>l.clientWidth,a=l.scrollHeight>l.clientHeight;if(n&&s||i&&a){if(i&&Ml&&ml)e:for(var u=t.target,c=o.view;u!=l;u=u.parentNode)for(var f=0;f<c.length;f++)if(c[f].node==u){e.display.currentWheelTarget=u;break e}if(n&&!fl&&!wl&&null!=Ls)return i&&a&&qr(e,Math.max(0,l.scrollTop+i*Ls)),Qr(e,Math.max(0,l.scrollLeft+n*Ls)),(!i||i&&a)&&We(t),void(o.wheelStartX=null);if(i&&null!=Ls){var h=i*Ls,d=e.doc.scrollTop,p=d+o.wrapper.clientHeight;h<0?d=Math.max(0,d+h-50):p=Math.min(e.doc.height,p+h+50),On(e,{top:d,bottom:p})}Ss<20&&(null==o.wheelStartX?(o.wheelStartX=l.scrollLeft,o.wheelStartY=l.scrollTop,o.wheelDX=n,o.wheelDY=i,setTimeout(function(){if(null!=o.wheelStartX){var e=l.scrollLeft-o.wheelStartX,t=l.scrollTop-o.wheelStartY,r=t&&o.wheelDY&&t/o.wheelDY||e&&o.wheelDX&&e/o.wheelDX;o.wheelStartX=o.wheelStartY=null,r&&(Ls=(Ls*Ss+r)/(Ss+1),++Ss)}},200)):(o.wheelDX+=n,o.wheelDY+=i))}}function zn(e,t){var r=e[t];e.sort(function(e,t){return P(e.from(),t.from())}),t=h(e,r);for(var n=1;n<e.length;n++){var i=e[n],o=e[n-1];if(P(o.to(),i.from())>=0){var l=B(o.from(),i.from()),s=R(o.to(),i.to()),a=o.empty()?i.from()==i.head:o.from()==o.head;n<=t&&--t,e.splice(--n,2,new Ts(a?s:l,a?l:s))}}return new ks(e,t)}function Rn(e,t){return new ks([new Ts(e,t||e)],0)}function Bn(e){return e.text?E(e.from.line+e.text.length-1,g(e.text).length+(1==e.text.length?e.from.ch:0)):e.to}function Gn(e,t){if(P(e,t.from)<0)return e;if(P(e,t.to)<=0)return Bn(t);var r=e.line+t.text.length-(t.to.line-t.from.line)-1,n=e.ch;return e.line==t.to.line&&(n+=Bn(t).ch-t.to.ch),E(r,n)}function Un(e,t){for(var r=[],n=0;n<e.sel.ranges.length;n++){var i=e.sel.ranges[n];r.push(new Ts(Gn(i.anchor,t),Gn(i.head,t)))}return zn(r,e.sel.primIndex)}function Vn(e,t,r){return e.line==t.line?E(r.line,e.ch-t.ch+r.ch):E(r.line+(e.line-t.line),e.ch)}function Kn(e,t,r){for(var n=[],i=E(e.first,0),o=i,l=0;l<t.length;l++){var s=t[l],a=Vn(s.from,i,o),u=Vn(Bn(s),i,o);if(i=s.to,o=u,"around"==r){var c=e.sel.ranges[l],f=P(c.head,c.anchor)<0;n[l]=new Ts(f?u:a,f?a:u)}else n[l]=new Ts(a,a)}return new ks(n,e.sel.primIndex)}function jn(e){e.doc.mode=Ue(e.options,e.doc.modeOption),Xn(e)}function Xn(e){e.doc.iter(function(e){e.stateAfter&&(e.stateAfter=null),e.styles&&(e.styles=null)}),e.doc.modeFrontier=e.doc.highlightFrontier=e.doc.first,Cn(e,100),e.state.modeGen++,e.curOp&&vn(e)}function Yn(e,t){return 0==t.from.ch&&0==t.to.ch&&""==g(t.text)&&(!e.cm||e.cm.options.wholeLineUpdateBefore)}function _n(e,t,r,n){function i(e){return r?r[e]:null}function o(e,r,i){it(e,r,i,n),bt(e,"change",e,t)}function l(e,t){for(var r=[],o=e;o<t;++o)r.push(new fs(u[o],i(o),n));return r}var s=t.from,a=t.to,u=t.text,c=M(e,s.line),f=M(e,a.line),h=g(u),d=i(u.length-1),p=a.line-s.line;if(t.full)e.insert(0,l(0,u.length)),e.remove(u.length,e.size-u.length);else if(Yn(e,t)){var v=l(0,u.length-1);o(f,f.text,d),p&&e.remove(s.line,p),v.length&&e.insert(s.line,v)}else if(c==f)if(1==u.length)o(c,c.text.slice(0,s.ch)+h+c.text.slice(a.ch),d);else{var m=l(1,u.length-1);m.push(new fs(h+c.text.slice(a.ch),d,n)),o(c,c.text.slice(0,s.ch)+u[0],i(0)),e.insert(s.line+1,m)}else if(1==u.length)o(c,c.text.slice(0,s.ch)+u[0]+f.text.slice(a.ch),i(0)),e.remove(s.line+1,p);else{o(c,c.text.slice(0,s.ch)+u[0],i(0)),o(f,h+f.text.slice(a.ch),d);var y=l(1,u.length-1);p>1&&e.remove(s.line+1,p-1),e.insert(s.line+1,y)}bt(e,"change",e,t)}function $n(e,t,r){function n(e,i,o){if(e.linked)for(var l=0;l<e.linked.length;++l){var s=e.linked[l];if(s.doc!=i){var a=o&&s.sharedHist;r&&!a||(t(s.doc,a),n(s.doc,e,a))}}}n(e,null,!0)}function qn(e,t){if(t.cm)throw new Error("This document is already in use.");e.doc=t,t.cm=e,Cr(e),jn(e),Zn(e),e.options.lineWrapping||we(e),e.options.mode=t.modeOption,vn(e)}function Zn(e){("rtl"==e.doc.direction?s:Fl)(e.display.lineDiv,"CodeMirror-rtl")}function Qn(e){hn(e,function(){Zn(e),vn(e)})}function Jn(e){this.done=[],this.undone=[],this.undoDepth=1/0,this.lastModTime=this.lastSelTime=0,this.lastOp=this.lastSelOp=null,this.lastOrigin=this.lastSelOrigin=null,this.generation=this.maxGeneration=e||1}function ei(e,t){var r={from:z(t.from),to:Bn(t),text:N(e,t.from,t.to)};return si(e,r,t.from.line,t.to.line+1),$n(e,function(e){return si(e,r,t.from.line,t.to.line+1)},!0),r}function ti(e){for(;e.length&&g(e).ranges;)e.pop()}function ri(e,t){return t?(ti(e.done),g(e.done)):e.done.length&&!g(e.done).ranges?g(e.done):e.done.length>1&&!e.done[e.done.length-2].ranges?(e.done.pop(),g(e.done)):void 0}function ni(e,t,r,n){var i=e.history;i.undone.length=0;var o,l,s=+new Date;if((i.lastOp==n||i.lastOrigin==t.origin&&t.origin&&("+"==t.origin.charAt(0)&&e.cm&&i.lastModTime>s-e.cm.options.historyEventDelay||"*"==t.origin.charAt(0)))&&(o=ri(i,i.lastOp==n)))l=g(o.changes),0==P(t.from,t.to)&&0==P(t.from,l.to)?l.to=Bn(t):o.changes.push(ei(e,t));else{var a=g(i.done);for(a&&a.ranges||li(e.sel,i.done),o={changes:[ei(e,t)],generation:i.generation},i.done.push(o);i.done.length>i.undoDepth;)i.done.shift(),i.done[0].ranges||i.done.shift()}i.done.push(r),i.generation=++i.maxGeneration,i.lastModTime=i.lastSelTime=s,i.lastOp=i.lastSelOp=n,i.lastOrigin=i.lastSelOrigin=t.origin,l||Te(e,"historyAdded")}function ii(e,t,r,n){var i=t.charAt(0);return"*"==i||"+"==i&&r.ranges.length==n.ranges.length&&r.somethingSelected()==n.somethingSelected()&&new Date-e.history.lastSelTime<=(e.cm?e.cm.options.historyEventDelay:500)}function oi(e,t,r,n){var i=e.history,o=n&&n.origin;r==i.lastSelOp||o&&i.lastSelOrigin==o&&(i.lastModTime==i.lastSelTime&&i.lastOrigin==o||ii(e,o,g(i.done),t))?i.done[i.done.length-1]=t:li(t,i.done),i.lastSelTime=+new Date,i.lastSelOrigin=o,i.lastSelOp=r,n&&!1!==n.clearRedo&&ti(i.undone)}function li(e,t){var r=g(t);r&&r.ranges&&r.equals(e)||t.push(e)}function si(e,t,r,n){var i=t["spans_"+e.id],o=0;e.iter(Math.max(e.first,r),Math.min(e.first+e.size,n),function(r){r.markedSpans&&((i||(i=t["spans_"+e.id]={}))[o]=r.markedSpans),++o})}function ai(e){if(!e)return null;for(var t,r=0;r<e.length;++r)e[r].marker.explicitlyCleared?t||(t=e.slice(0,r)):t&&t.push(e[r]);return t?t.length?t:null:e}function ui(e,t){var r=t["spans_"+e.id];if(!r)return null;for(var n=[],i=0;i<t.text.length;++i)n.push(ai(r[i]));return n}function ci(e,t){var r=ui(e,t),n=J(e,t);if(!r)return n;if(!n)return r;for(var i=0;i<r.length;++i){var o=r[i],l=n[i];if(o&&l)e:for(var s=0;s<l.length;++s){for(var a=l[s],u=0;u<o.length;++u)if(o[u].marker==a.marker)continue e;o.push(a)}else l&&(r[i]=l)}return r}function fi(e,t,r){for(var n=[],i=0;i<e.length;++i){var o=e[i];if(o.ranges)n.push(r?ks.prototype.deepCopy.call(o):o);else{var l=o.changes,s=[];n.push({changes:s});for(var a=0;a<l.length;++a){var u=l[a],c=void 0;if(s.push({from:u.from,to:u.to,text:u.text}),t)for(var f in u)(c=f.match(/^spans_(\d+)$/))&&h(t,Number(c[1]))>-1&&(g(s)[f]=u[f],delete u[f])}}}return n}function hi(e,t,r,n){if(n){var i=e.anchor;if(r){var o=P(t,i)<0;o!=P(r,i)<0?(i=t,t=r):o!=P(t,r)<0&&(t=r)}return new Ts(i,t)}return new Ts(r||t,t)}function di(e,t,r,n,i){null==i&&(i=e.cm&&(e.cm.display.shift||e.extend)),bi(e,new ks([hi(e.sel.primary(),t,r,i)],0),n)}function pi(e,t,r){for(var n=[],i=e.cm&&(e.cm.display.shift||e.extend),o=0;o<e.sel.ranges.length;o++)n[o]=hi(e.sel.ranges[o],t[o],null,i);bi(e,zn(n,e.sel.primIndex),r)}function gi(e,t,r,n){var i=e.sel.ranges.slice(0);i[t]=r,bi(e,zn(i,e.sel.primIndex),n)}function vi(e,t,r,n){bi(e,Rn(t,r),n)}function mi(e,t,r){var n={ranges:t.ranges,update:function(t){var r=this;this.ranges=[];for(var n=0;n<t.length;n++)r.ranges[n]=new Ts(U(e,t[n].anchor),U(e,t[n].head))},origin:r&&r.origin};return Te(e,"beforeSelectionChange",e,n),e.cm&&Te(e.cm,"beforeSelectionChange",e.cm,n),n.ranges!=t.ranges?zn(n.ranges,n.ranges.length-1):t}function yi(e,t,r){var n=e.history.done,i=g(n);i&&i.ranges?(n[n.length-1]=t,wi(e,t,r)):bi(e,t,r)}function bi(e,t,r){wi(e,t,r),oi(e,e.sel,e.cm?e.cm.curOp.id:NaN,r)}function wi(e,t,r){(Oe(e,"beforeSelectionChange")||e.cm&&Oe(e.cm,"beforeSelectionChange"))&&(t=mi(e,t,r)),xi(e,Si(e,t,r&&r.bias||(P(t.primary().head,e.sel.primary().head)<0?-1:1),!0)),r&&!1===r.scroll||!e.cm||jr(e.cm)}function xi(e,t){t.equals(e.sel)||(e.sel=t,e.cm&&(e.cm.curOp.updateInput=e.cm.curOp.selectionChanged=!0,Ne(e.cm)),bt(e,"cursorActivity",e))}function Ci(e){xi(e,Si(e,e.sel,null,!1))}function Si(e,t,r,n){for(var i,o=0;o<t.ranges.length;o++){var l=t.ranges[o],s=t.ranges.length==e.sel.ranges.length&&e.sel.ranges[o],a=ki(e,l.anchor,s&&s.anchor,r,n),u=ki(e,l.head,s&&s.head,r,n);(i||a!=l.anchor||u!=l.head)&&(i||(i=t.ranges.slice(0,o)),i[o]=new Ts(a,u))}return i?zn(i,t.primIndex):t}function Li(e,t,r,n,i){var o=M(e,t.line);if(o.markedSpans)for(var l=0;l<o.markedSpans.length;++l){var s=o.markedSpans[l],a=s.marker;if((null==s.from||(a.inclusiveLeft?s.from<=t.ch:s.from<t.ch))&&(null==s.to||(a.inclusiveRight?s.to>=t.ch:s.to>t.ch))){if(i&&(Te(a,"beforeCursorEnter"),a.explicitlyCleared)){if(o.markedSpans){--l;continue}break}if(!a.atomic)continue;if(r){var u=a.find(n<0?1:-1),c=void 0;if((n<0?a.inclusiveRight:a.inclusiveLeft)&&(u=Ti(e,u,-n,u&&u.line==t.line?o:null)),u&&u.line==t.line&&(c=P(u,r))&&(n<0?c<0:c>0))return Li(e,u,t,n,i)}var f=a.find(n<0?-1:1);return(n<0?a.inclusiveLeft:a.inclusiveRight)&&(f=Ti(e,f,n,f.line==t.line?o:null)),f?Li(e,f,t,n,i):null}}return t}function ki(e,t,r,n,i){var o=n||1,l=Li(e,t,r,o,i)||!i&&Li(e,t,r,o,!0)||Li(e,t,r,-o,i)||!i&&Li(e,t,r,-o,!0);return l||(e.cantEdit=!0,E(e.first,0))}function Ti(e,t,r,n){return r<0&&0==t.ch?t.line>e.first?U(e,E(t.line-1)):null:r>0&&t.ch==(n||M(e,t.line)).text.length?t.line<e.first+e.size-1?E(t.line+1,0):null:new E(t.line,t.ch+r)}function Mi(e){e.setSelection(E(e.firstLine(),0),E(e.lastLine()),Gl)}function Ni(e,t,r){var n={canceled:!1,from:t.from,to:t.to,text:t.text,origin:t.origin,cancel:function(){return n.canceled=!0}};return r&&(n.update=function(t,r,i,o){t&&(n.from=U(e,t)),r&&(n.to=U(e,r)),i&&(n.text=i),void 0!==o&&(n.origin=o)}),Te(e,"beforeChange",e,n),e.cm&&Te(e.cm,"beforeChange",e.cm,n),n.canceled?null:{from:n.from,to:n.to,text:n.text,origin:n.origin}}function Oi(e,t,r){if(e.cm){if(!e.cm.curOp)return dn(e.cm,Oi)(e,t,r);if(e.cm.state.suppressEdits)return}if(!(Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"))||(t=Ni(e,t,!0))){var n=Yl&&!r&&te(e,t.from,t.to);if(n)for(var i=n.length-1;i>=0;--i)Ai(e,{from:n[i].from,to:n[i].to,text:i?[""]:t.text,origin:t.origin});else Ai(e,t)}}function Ai(e,t){if(1!=t.text.length||""!=t.text[0]||0!=P(t.from,t.to)){var r=Un(e,t);ni(e,t,r,e.cm?e.cm.curOp.id:NaN),Hi(e,t,r,J(e,t));var n=[];$n(e,function(e,r){r||-1!=h(n,e.history)||(zi(e.history,t),n.push(e.history)),Hi(e,t,null,J(e,t))})}}function Wi(e,t,r){if(!e.cm||!e.cm.state.suppressEdits||r){for(var n,i=e.history,o=e.sel,l="undo"==t?i.done:i.undone,s="undo"==t?i.undone:i.done,a=0;a<l.length&&(n=l[a],r?!n.ranges||n.equals(e.sel):n.ranges);a++);if(a!=l.length){for(i.lastOrigin=i.lastSelOrigin=null;(n=l.pop()).ranges;){if(li(n,s),r&&!n.equals(e.sel))return void bi(e,n,{clearRedo:!1});o=n}var u=[];li(o,s),s.push({changes:u,generation:i.generation}),i.generation=n.generation||++i.maxGeneration;for(var c=Oe(e,"beforeChange")||e.cm&&Oe(e.cm,"beforeChange"),f=n.changes.length-1;f>=0;--f){var d=function(r){var i=n.changes[r];if(i.origin=t,c&&!Ni(e,i,!1))return l.length=0,{};u.push(ei(e,i));var o=r?Un(e,i):g(l);Hi(e,i,o,ci(e,i)),!r&&e.cm&&e.cm.scrollIntoView({from:i.from,to:Bn(i)});var s=[];$n(e,function(e,t){t||-1!=h(s,e.history)||(zi(e.history,i),s.push(e.history)),Hi(e,i,null,ci(e,i))})}(f);if(d)return d.v}}}}function Di(e,t){if(0!=t&&(e.first+=t,e.sel=new ks(v(e.sel.ranges,function(e){return new Ts(E(e.anchor.line+t,e.anchor.ch),E(e.head.line+t,e.head.ch))}),e.sel.primIndex),e.cm)){vn(e.cm,e.first,e.first-t,t);for(var r=e.cm.display,n=r.viewFrom;n<r.viewTo;n++)mn(e.cm,n,"gutter")}}function Hi(e,t,r,n){if(e.cm&&!e.cm.curOp)return dn(e.cm,Hi)(e,t,r,n);if(t.to.line<e.first)Di(e,t.text.length-1-(t.to.line-t.from.line));else if(!(t.from.line>e.lastLine())){if(t.from.line<e.first){var i=t.text.length-1-(e.first-t.from.line);Di(e,i),t={from:E(e.first,0),to:E(t.to.line+i,t.to.ch),text:[g(t.text)],origin:t.origin}}var o=e.lastLine();t.to.line>o&&(t={from:t.from,to:E(o,M(e,o).text.length),text:[t.text[0]],origin:t.origin}),t.removed=N(e,t.from,t.to),r||(r=Un(e,t)),e.cm?Fi(e.cm,t,n):_n(e,t,n),wi(e,r,Gl)}}function Fi(e,t,r){var n=e.doc,i=e.display,o=t.from,l=t.to,s=!1,a=o.line;e.options.lineWrapping||(a=W(fe(M(n,o.line))),n.iter(a,l.line+1,function(e){if(e==i.maxLine)return s=!0,!0})),n.sel.contains(t.from,t.to)>-1&&Ne(e),_n(n,t,r,xr(e)),e.options.lineWrapping||(n.iter(a,o.line+t.text.length,function(e){var t=be(e);t>i.maxLineLength&&(i.maxLine=e,i.maxLineLength=t,i.maxLineChanged=!0,s=!1)}),s&&(e.curOp.updateMaxLine=!0)),nt(n,o.line),Cn(e,400);var u=t.text.length-(l.line-o.line)-1;t.full?vn(e):o.line!=l.line||1!=t.text.length||Yn(e.doc,t)?vn(e,o.line,l.line+1,u):mn(e,o.line,"text");var c=Oe(e,"changes"),f=Oe(e,"change");if(f||c){var h={from:o,to:l,text:t.text,removed:t.removed,origin:t.origin};f&&bt(e,"change",e,h),c&&(e.curOp.changeObjs||(e.curOp.changeObjs=[])).push(h)}e.display.selForContextMenu=null}function Ei(e,t,r,n,i){if(n||(n=r),P(n,r)<0){var o;r=(o=[n,r])[0],n=o[1]}"string"==typeof t&&(t=e.splitLines(t)),Oi(e,{from:r,to:n,text:t,origin:i})}function Pi(e,t,r,n){r<e.line?e.line+=n:t<e.line&&(e.line=t,e.ch=0)}function Ii(e,t,r,n){for(var i=0;i<e.length;++i){var o=e[i],l=!0;if(o.ranges){o.copied||((o=e[i]=o.deepCopy()).copied=!0);for(var s=0;s<o.ranges.length;s++)Pi(o.ranges[s].anchor,t,r,n),Pi(o.ranges[s].head,t,r,n)}else{for(var a=0;a<o.changes.length;++a){var u=o.changes[a];if(r<u.from.line)u.from=E(u.from.line+n,u.from.ch),u.to=E(u.to.line+n,u.to.ch);else if(t<=u.to.line){l=!1;break}}l||(e.splice(0,i+1),i=0)}}}function zi(e,t){var r=t.from.line,n=t.to.line,i=t.text.length-(n-r)-1;Ii(e.done,r,n,i),Ii(e.undone,r,n,i)}function Ri(e,t,r,n){var i=t,o=t;return"number"==typeof t?o=M(e,G(e,t)):i=W(t),null==i?null:(n(o,i)&&e.cm&&mn(e.cm,i,r),o)}function Bi(e){var t=this;this.lines=e,this.parent=null;for(var r=0,n=0;n<e.length;++n)e[n].parent=t,r+=e[n].height;this.height=r}function Gi(e){var t=this;this.children=e;for(var r=0,n=0,i=0;i<e.length;++i){var o=e[i];r+=o.chunkSize(),n+=o.height,o.parent=t}this.size=r,this.height=n,this.parent=null}function Ui(e,t,r){ye(t)<(e.curOp&&e.curOp.scrollTop||e.doc.scrollTop)&&Kr(e,r)}function Vi(e,t,r,n){var i=new Ms(e,r,n),o=e.cm;return o&&i.noHScroll&&(o.display.alignWidgets=!0),Ri(e,t,"widget",function(t){var r=t.widgets||(t.widgets=[]);if(null==i.insertAt?r.push(i):r.splice(Math.min(r.length-1,Math.max(0,i.insertAt)),0,i),i.line=t,o&&!ve(e,t)){var n=ye(t)<e.scrollTop;A(t,t.height+Ht(i)),n&&Kr(o,i.height),o.curOp.forceUpdate=!0}return!0}),bt(o,"lineWidgetAdded",o,i,"number"==typeof t?t:W(t)),i}function Ki(e,t,r,n,o){if(n&&n.shared)return ji(e,t,r,n,o);if(e.cm&&!e.cm.curOp)return dn(e.cm,Ki)(e,t,r,n,o);var l=new Os(e,o),s=P(t,r);if(n&&c(n,l,!1),s>0||0==s&&!1!==l.clearWhenEmpty)return l;if(l.replacedWith&&(l.collapsed=!0,l.widgetNode=i("span",[l.replacedWith],"CodeMirror-widget"),n.handleMouseEvents||l.widgetNode.setAttribute("cm-ignore-events","true"),n.insertLeft&&(l.widgetNode.insertLeft=!0)),l.collapsed){if(ce(e,t.line,t,r,l)||t.line!=r.line&&ce(e,r.line,t,r,l))throw new Error("Inserting collapsed marker partially overlapping an existing one");X()}l.addToHistory&&ni(e,{from:t,to:r,origin:"markText"},e.sel,NaN);var a,u=t.line,f=e.cm;if(e.iter(u,r.line+1,function(e){f&&l.collapsed&&!f.options.lineWrapping&&fe(e)==f.display.maxLine&&(a=!0),l.collapsed&&u!=t.line&&A(e,0),q(e,new Y(l,u==t.line?t.ch:null,u==r.line?r.ch:null)),++u}),l.collapsed&&e.iter(t.line,r.line+1,function(t){ve(e,t)&&A(t,0)}),l.clearOnEnter&&Ql(l,"beforeCursorEnter",function(){return l.clear()}),l.readOnly&&(j(),(e.history.done.length||e.history.undone.length)&&e.clearHistory()),l.collapsed&&(l.id=++Ns,l.atomic=!0),f){if(a&&(f.curOp.updateMaxLine=!0),l.collapsed)vn(f,t.line,r.line+1);else if(l.className||l.title||l.startStyle||l.endStyle||l.css)for(var h=t.line;h<=r.line;h++)mn(f,h,"text");l.atomic&&Ci(f.doc),bt(f,"markerAdded",f,l)}return l}function ji(e,t,r,n,i){(n=c(n)).shared=!1;var o=[Ki(e,t,r,n,i)],l=o[0],s=n.widgetNode;return $n(e,function(e){s&&(n.widgetNode=s.cloneNode(!0)),o.push(Ki(e,U(e,t),U(e,r),n,i));for(var a=0;a<e.linked.length;++a)if(e.linked[a].isParent)return;l=g(o)}),new As(o,l)}function Xi(e){return e.findMarks(E(e.first,0),e.clipPos(E(e.lastLine())),function(e){return e.parent})}function Yi(e,t){for(var r=0;r<t.length;r++){var n=t[r],i=n.find(),o=e.clipPos(i.from),l=e.clipPos(i.to);if(P(o,l)){var s=Ki(e,o,l,n.primary,n.primary.type);n.markers.push(s),s.parent=n}}}function _i(e){for(var t=0;t<e.length;t++)!function(t){var r=e[t],n=[r.primary.doc];$n(r.primary.doc,function(e){return n.push(e)});for(var i=0;i<r.markers.length;i++){var o=r.markers[i];-1==h(n,o.doc)&&(o.parent=null,r.markers.splice(i--,1))}}(t)}function $i(e){var t=this;if(Qi(t),!Me(t,e)&&!Ft(t.display,e)){We(e),gl&&(Hs=+new Date);var r=Sr(t,e,!0),n=e.dataTransfer.files;if(r&&!t.isReadOnly())if(n&&n.length&&window.FileReader&&window.File)for(var i=n.length,o=Array(i),l=0,s=0;s<i;++s)!function(e,n){if(!t.options.allowDropFileTypes||-1!=h(t.options.allowDropFileTypes,e.type)){var s=new FileReader;s.onload=dn(t,function(){var e=s.result;if(/[\x00-\x08\x0e-\x1f]{2}/.test(e)&&(e=""),o[n]=e,++l==i){var a={from:r=U(t.doc,r),to:r,text:t.doc.splitLines(o.join(t.doc.lineSeparator())),origin:"paste"};Oi(t.doc,a),yi(t.doc,Rn(r,Bn(a)))}}),s.readAsText(e)}}(n[s],s);else{if(t.state.draggingText&&t.doc.sel.contains(r)>-1)return t.state.draggingText(e),void setTimeout(function(){return t.display.input.focus()},20);try{var a=e.dataTransfer.getData("Text");if(a){var u;if(t.state.draggingText&&!t.state.draggingText.copy&&(u=t.listSelections()),wi(t.doc,Rn(r,r)),u)for(var c=0;c<u.length;++c)Ei(t.doc,"",u[c].anchor,u[c].head,"drag");t.replaceSelection(a,"around","paste"),t.display.input.focus()}}catch(e){}}}}function qi(e,t){if(gl&&(!e.state.draggingText||+new Date-Hs<100))Fe(t);else if(!Me(e,t)&&!Ft(e.display,t)&&(t.dataTransfer.setData("Text",e.getSelection()),t.dataTransfer.effectAllowed="copyMove",t.dataTransfer.setDragImage&&!xl)){var r=n("img",null,null,"position: fixed; left: 0; top: 0;");r.src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==",wl&&(r.width=r.height=1,e.display.wrapper.appendChild(r),r._top=r.offsetTop),t.dataTransfer.setDragImage(r,0,0),wl&&r.parentNode.removeChild(r)}}function Zi(e,t){var i=Sr(e,t);if(i){var o=document.createDocumentFragment();Mr(e,i,o),e.display.dragCursor||(e.display.dragCursor=n("div",null,"CodeMirror-cursors CodeMirror-dragcursors"),e.display.lineSpace.insertBefore(e.display.dragCursor,e.display.cursorDiv)),r(e.display.dragCursor,o)}}function Qi(e){e.display.dragCursor&&(e.display.lineSpace.removeChild(e.display.dragCursor),e.display.dragCursor=null)}function Ji(e){if(document.getElementsByClassName)for(var t=document.getElementsByClassName("CodeMirror"),r=0;r<t.length;r++){var n=t[r].CodeMirror;n&&e(n)}}function eo(){Fs||(to(),Fs=!0)}function to(){var e;Ql(window,"resize",function(){null==e&&(e=setTimeout(function(){e=null,Ji(ro)},100))}),Ql(window,"blur",function(){return Ji(Fr)})}function ro(e){var t=e.display;t.lastWrapHeight==t.wrapper.clientHeight&&t.lastWrapWidth==t.wrapper.clientWidth||(t.cachedCharWidth=t.cachedTextHeight=t.cachedPaddingH=null,t.scrollbarsClipped=!1,e.setSize())}function no(e){var t=e.split(/-(?!$)/);e=t[t.length-1];for(var r,n,i,o,l=0;l<t.length-1;l++){var s=t[l];if(/^(cmd|meta|m)$/i.test(s))o=!0;else if(/^a(lt)?$/i.test(s))r=!0;else if(/^(c|ctrl|control)$/i.test(s))n=!0;else{if(!/^s(hift)?$/i.test(s))throw new Error("Unrecognized modifier name: "+s);i=!0}}return r&&(e="Alt-"+e),n&&(e="Ctrl-"+e),o&&(e="Cmd-"+e),i&&(e="Shift-"+e),e}function io(e){var t={};for(var r in e)if(e.hasOwnProperty(r)){var n=e[r];if(/^(name|fallthrough|(de|at)tach)$/.test(r))continue;if("..."==n){delete e[r];continue}for(var i=v(r.split(" "),no),o=0;o<i.length;o++){var l=void 0,s=void 0;o==i.length-1?(s=i.join(" "),l=n):(s=i.slice(0,o+1).join(" "),l="...");var a=t[s];if(a){if(a!=l)throw new Error("Inconsistent bindings for "+s)}else t[s]=l}delete e[r]}for(var u in t)e[u]=t[u];return e}function oo(e,t,r,n){var i=(t=uo(t)).call?t.call(e,n):t[e];if(!1===i)return"nothing";if("..."===i)return"multi";if(null!=i&&r(i))return"handled";if(t.fallthrough){if("[object Array]"!=Object.prototype.toString.call(t.fallthrough))return oo(e,t.fallthrough,r,n);for(var o=0;o<t.fallthrough.length;o++){var l=oo(e,t.fallthrough[o],r,n);if(l)return l}}}function lo(e){var t="string"==typeof e?e:Es[e.keyCode];return"Ctrl"==t||"Alt"==t||"Shift"==t||"Mod"==t}function so(e,t,r){var n=e;return t.altKey&&"Alt"!=n&&(e="Alt-"+e),(Dl?t.metaKey:t.ctrlKey)&&"Ctrl"!=n&&(e="Ctrl-"+e),(Dl?t.ctrlKey:t.metaKey)&&"Cmd"!=n&&(e="Cmd-"+e),!r&&t.shiftKey&&"Shift"!=n&&(e="Shift-"+e),e}function ao(e,t){if(wl&&34==e.keyCode&&e.char)return!1;var r=Es[e.keyCode];return null!=r&&!e.altGraphKey&&so(r,e,t)}function uo(e){return"string"==typeof e?Rs[e]:e}function co(e,t){for(var r=e.doc.sel.ranges,n=[],i=0;i<r.length;i++){for(var o=t(r[i]);n.length&&P(o.from,g(n).to)<=0;){var l=n.pop();if(P(l.from,o.from)<0){o.from=l.from;break}}n.push(o)}hn(e,function(){for(var t=n.length-1;t>=0;t--)Ei(e.doc,"",n[t].from,n[t].to,"+delete");jr(e)})}function fo(e,t,r){var n=L(e.text,t+r,r);return n<0||n>e.text.length?null:n}function ho(e,t,r){var n=fo(e,t.ch,r);return null==n?null:new E(t.line,n,r<0?"after":"before")}function po(e,t,r,n,i){if(e){var o=Se(r,t.doc.direction);if(o){var l,s=i<0?g(o):o[0],a=i<0==(1==s.level)?"after":"before";if(s.level>0){var u=Xt(t,r);l=i<0?r.text.length-1:0;var c=Yt(t,u,l).top;l=k(function(e){return Yt(t,u,e).top==c},i<0==(1==s.level)?s.from:s.to-1,l),"before"==a&&(l=fo(r,l,1))}else l=i<0?s.to:s.from;return new E(n,l,a)}}return new E(n,i<0?r.text.length:0,i<0?"before":"after")}function go(e,t,r,n){var i=Se(t,e.doc.direction);if(!i)return ho(t,r,n);r.ch>=t.text.length?(r.ch=t.text.length,r.sticky="before"):r.ch<=0&&(r.ch=0,r.sticky="after");var o=Ce(i,r.ch,r.sticky),l=i[o];if("ltr"==e.doc.direction&&l.level%2==0&&(n>0?l.to>r.ch:l.from<r.ch))return ho(t,r,n);var s,a=function(e,r){return fo(t,e instanceof E?e.ch:e,r)},u=function(r){return e.options.lineWrapping?(s=s||Xt(e,t),hr(e,t,s,r)):{begin:0,end:t.text.length}},c=u("before"==r.sticky?a(r,-1):r.ch);if("rtl"==e.doc.direction||1==l.level){var f=1==l.level==n<0,h=a(r,f?1:-1);if(null!=h&&(f?h<=l.to&&h<=c.end:h>=l.from&&h>=c.begin)){var d=f?"before":"after";return new E(r.line,h,d)}}var p=function(e,t,n){for(var o=function(e,t){return t?new E(r.line,a(e,1),"before"):new E(r.line,e,"after")};e>=0&&e<i.length;e+=t){var l=i[e],s=t>0==(1!=l.level),u=s?n.begin:a(n.end,-1);if(l.from<=u&&u<l.to)return o(u,s);if(u=s?l.from:a(l.to,-1),n.begin<=u&&u<n.end)return o(u,s)}},g=p(o+n,n,c);if(g)return g;var v=n>0?c.end:a(c.begin,-1);return null==v||n>0&&v==t.text.length||!(g=p(n>0?0:i.length-1,n,u(v)))?null:g}function vo(e,t){var r=M(e.doc,t),n=fe(r);return n!=r&&(t=W(n)),po(!0,e,n,t,1)}function mo(e,t){var r=M(e.doc,t),n=he(r);return n!=r&&(t=W(n)),po(!0,e,r,t,-1)}function yo(e,t){var r=vo(e,t.line),n=M(e.doc,r.line),i=Se(n,e.doc.direction);if(!i||0==i[0].level){var o=Math.max(0,n.text.search(/\S/)),l=t.line==r.line&&t.ch<=o&&t.ch;return E(r.line,l?0:o,r.sticky)}return r}function bo(e,t,r){if("string"==typeof t&&!(t=Bs[t]))return!1;e.display.input.ensurePolled();var n=e.display.shift,i=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),r&&(e.display.shift=!1),i=t(e)!=Bl}finally{e.display.shift=n,e.state.suppressEdits=!1}return i}function wo(e,t,r){for(var n=0;n<e.state.keyMaps.length;n++){var i=oo(t,e.state.keyMaps[n],r,e);if(i)return i}return e.options.extraKeys&&oo(t,e.options.extraKeys,r,e)||oo(t,e.options.keyMap,r,e)}function xo(e,t,r,n){var i=e.state.keySeq;if(i){if(lo(t))return"handled";Gs.set(50,function(){e.state.keySeq==i&&(e.state.keySeq=null,e.display.input.reset())}),t=i+" "+t}var o=wo(e,t,n);return"multi"==o&&(e.state.keySeq=t),"handled"==o&&bt(e,"keyHandled",e,t,r),"handled"!=o&&"multi"!=o||(We(r),Ar(e)),i&&!o&&/\'$/.test(t)?(We(r),!0):!!o}function Co(e,t){var r=ao(t,!0);return!!r&&(t.shiftKey&&!e.state.keySeq?xo(e,"Shift-"+r,t,function(t){return bo(e,t,!0)})||xo(e,r,t,function(t){if("string"==typeof t?/^go[A-Z]/.test(t):t.motion)return bo(e,t)}):xo(e,r,t,function(t){return bo(e,t)}))}function So(e,t,r){return xo(e,"'"+r+"'",t,function(t){return bo(e,t,!0)})}function Lo(e){var t=this;if(t.curOp.focus=l(),!Me(t,e)){gl&&vl<11&&27==e.keyCode&&(e.returnValue=!1);var r=e.keyCode;t.display.shift=16==r||e.shiftKey;var n=Co(t,e);wl&&(Us=n?r:null,!n&&88==r&&!rs&&(Ml?e.metaKey:e.ctrlKey)&&t.replaceSelection("",null,"cut")),18!=r||/\bCodeMirror-crosshair\b/.test(t.display.lineDiv.className)||ko(t)}}function ko(e){function t(e){18!=e.keyCode&&e.altKey||(Fl(r,"CodeMirror-crosshair"),ke(document,"keyup",t),ke(document,"mouseover",t))}var r=e.display.lineDiv;s(r,"CodeMirror-crosshair"),Ql(document,"keyup",t),Ql(document,"mouseover",t)}function To(e){16==e.keyCode&&(this.doc.sel.shift=!1),Me(this,e)}function Mo(e){var t=this;if(!(Ft(t.display,e)||Me(t,e)||e.ctrlKey&&!e.altKey||Ml&&e.metaKey)){var r=e.keyCode,n=e.charCode;if(wl&&r==Us)return Us=null,void We(e);if(!wl||e.which&&!(e.which<10)||!Co(t,e)){var i=String.fromCharCode(null==n?r:n);"\b"!=i&&(So(t,e,i)||t.display.input.onKeyPress(e))}}}function No(e,t){var r=+new Date;return js&&js.compare(r,e,t)?(Ks=js=null,"triple"):Ks&&Ks.compare(r,e,t)?(js=new Vs(r,e,t),Ks=null,"double"):(Ks=new Vs(r,e,t),js=null,"single")}function Oo(e){var t=this,r=t.display;if(!(Me(t,e)||r.activeTouch&&r.input.supportsTouch()))if(r.input.ensurePolled(),r.shift=e.shiftKey,Ft(r,e))ml||(r.scroller.draggable=!1,setTimeout(function(){return r.scroller.draggable=!0},100));else if(!zo(t,e)){var n=Sr(t,e),i=Pe(e),o=n?No(n,i):"single";window.focus(),1==i&&t.state.selectingText&&t.state.selectingText(e),n&&Ao(t,i,n,o,e)||(1==i?n?Do(t,n,o,e):Ee(e)==r.scroller&&We(e):2==i?(n&&di(t.doc,n),setTimeout(function(){return r.input.focus()},20)):3==i&&(Hl?Ro(t,e):Dr(t)))}}function Ao(e,t,r,n,i){var o="Click";return"double"==n?o="Double"+o:"triple"==n&&(o="Triple"+o),o=(1==t?"Left":2==t?"Middle":"Right")+o,xo(e,so(o,i),i,function(t){if("string"==typeof t&&(t=Bs[t]),!t)return!1;var n=!1;try{e.isReadOnly()&&(e.state.suppressEdits=!0),n=t(e,r)!=Bl}finally{e.state.suppressEdits=!1}return n})}function Wo(e,t,r){var n=e.getOption("configureMouse"),i=n?n(e,t,r):{};if(null==i.unit){var o=Nl?r.shiftKey&&r.metaKey:r.altKey;i.unit=o?"rectangle":"single"==t?"char":"double"==t?"word":"line"}return(null==i.extend||e.doc.extend)&&(i.extend=e.doc.extend||r.shiftKey),null==i.addNew&&(i.addNew=Ml?r.metaKey:r.ctrlKey),null==i.moveOnDrag&&(i.moveOnDrag=!(Ml?r.altKey:r.ctrlKey)),i}function Do(e,t,r,n){gl?setTimeout(u(Wr,e),0):e.curOp.focus=l();var i,o=Wo(e,r,n),s=e.doc.sel;e.options.dragDrop&&Jl&&!e.isReadOnly()&&"single"==r&&(i=s.contains(t))>-1&&(P((i=s.ranges[i]).from(),t)<0||t.xRel>0)&&(P(i.to(),t)>0||t.xRel<0)?Ho(e,n,t,o):Eo(e,n,t,o)}function Ho(e,t,r,n){var i=e.display,o=!1,l=dn(e,function(t){ml&&(i.scroller.draggable=!1),e.state.draggingText=!1,ke(document,"mouseup",l),ke(document,"mousemove",s),ke(i.scroller,"dragstart",a),ke(i.scroller,"drop",l),o||(We(t),n.addNew||di(e.doc,r,null,null,n.extend),ml||gl&&9==vl?setTimeout(function(){document.body.focus(),i.input.focus()},20):i.input.focus())}),s=function(e){o=o||Math.abs(t.clientX-e.clientX)+Math.abs(t.clientY-e.clientY)>=10},a=function(){return o=!0};ml&&(i.scroller.draggable=!0),e.state.draggingText=l,l.copy=!n.moveOnDrag,i.scroller.dragDrop&&i.scroller.dragDrop(),Ql(document,"mouseup",l),Ql(document,"mousemove",s),Ql(i.scroller,"dragstart",a),Ql(i.scroller,"drop",l),Dr(e),setTimeout(function(){return i.input.focus()},20)}function Fo(e,t,r){if("char"==r)return new Ts(t,t);if("word"==r)return e.findWordAt(t);if("line"==r)return new Ts(E(t.line,0),U(e.doc,E(t.line+1,0)));var n=r(e,t);return new Ts(n.from,n.to)}function Eo(e,t,r,n){function i(t){if(0!=P(m,t))if(m=t,"rectangle"==n.unit){for(var i=[],o=e.options.tabSize,l=f(M(u,r.line).text,r.ch,o),s=f(M(u,t.line).text,t.ch,o),a=Math.min(l,s),g=Math.max(l,s),v=Math.min(r.line,t.line),y=Math.min(e.lastLine(),Math.max(r.line,t.line));v<=y;v++){var b=M(u,v).text,w=d(b,a,o);a==g?i.push(new Ts(E(v,w),E(v,w))):b.length>w&&i.push(new Ts(E(v,w),E(v,d(b,g,o))))}i.length||i.push(new Ts(r,r)),bi(u,zn(p.ranges.slice(0,h).concat(i),h),{origin:"*mouse",scroll:!1}),e.scrollIntoView(t)}else{var x,C=c,S=Fo(e,t,n.unit),L=C.anchor;P(S.anchor,L)>0?(x=S.head,L=B(C.from(),S.anchor)):(x=S.anchor,L=R(C.to(),S.head));var k=p.ranges.slice(0);k[h]=Po(e,new Ts(U(u,L),x)),bi(u,zn(k,h),Ul)}}function o(t){var r=++b,s=Sr(e,t,!0,"rectangle"==n.unit);if(s)if(0!=P(s,m)){e.curOp.focus=l(),i(s);var c=Ir(a,u);(s.line>=c.to||s.line<c.from)&&setTimeout(dn(e,function(){b==r&&o(t)}),150)}else{var f=t.clientY<y.top?-20:t.clientY>y.bottom?20:0;f&&setTimeout(dn(e,function(){b==r&&(a.scroller.scrollTop+=f,o(t))}),50)}}function s(t){e.state.selectingText=!1,b=1/0,We(t),a.input.focus(),ke(document,"mousemove",w),ke(document,"mouseup",x),u.history.lastSelOrigin=null}var a=e.display,u=e.doc;We(t);var c,h,p=u.sel,g=p.ranges;if(n.addNew&&!n.extend?(h=u.sel.contains(r),c=h>-1?g[h]:new Ts(r,r)):(c=u.sel.primary(),h=u.sel.primIndex),"rectangle"==n.unit)n.addNew||(c=new Ts(r,r)),r=Sr(e,t,!0,!0),h=-1;else{var v=Fo(e,r,n.unit);c=n.extend?hi(c,v.anchor,v.head,n.extend):v}n.addNew?-1==h?(h=g.length,bi(u,zn(g.concat([c]),h),{scroll:!1,origin:"*mouse"})):g.length>1&&g[h].empty()&&"char"==n.unit&&!n.extend?(bi(u,zn(g.slice(0,h).concat(g.slice(h+1)),0),{scroll:!1,origin:"*mouse"}),p=u.sel):gi(u,h,c,Ul):(h=0,bi(u,new ks([c],0),Ul),p=u.sel);var m=r,y=a.wrapper.getBoundingClientRect(),b=0,w=dn(e,function(e){Pe(e)?o(e):s(e)}),x=dn(e,s);e.state.selectingText=x,Ql(document,"mousemove",w),Ql(document,"mouseup",x)}function Po(e,t){var r=t.anchor,n=t.head,i=M(e.doc,r.line);if(0==P(r,n)&&r.sticky==n.sticky)return t;var o=Se(i);if(!o)return t;var l=Ce(o,r.ch,r.sticky),s=o[l];if(s.from!=r.ch&&s.to!=r.ch)return t;var a=l+(s.from==r.ch==(1!=s.level)?0:1);if(0==a||a==o.length)return t;var u;if(n.line!=r.line)u=(n.line-r.line)*("ltr"==e.doc.direction?1:-1)>0;else{var c=Ce(o,n.ch,n.sticky),f=c-l||(n.ch-r.ch)*(1==s.level?-1:1);u=c==a-1||c==a?f<0:f>0}var h=o[a+(u?-1:0)],d=u==(1==h.level),p=d?h.from:h.to,g=d?"after":"before";return r.ch==p&&r.sticky==g?t:new Ts(new E(r.line,p,g),n)}function Io(e,t,r,n){var i,o;if(t.touches)i=t.touches[0].clientX,o=t.touches[0].clientY;else try{i=t.clientX,o=t.clientY}catch(t){return!1}if(i>=Math.floor(e.display.gutters.getBoundingClientRect().right))return!1;n&&We(t);var l=e.display,s=l.lineDiv.getBoundingClientRect();if(o>s.bottom||!Oe(e,r))return He(t);o-=s.top-l.viewOffset;for(var a=0;a<e.options.gutters.length;++a){var u=l.gutters.childNodes[a];if(u&&u.getBoundingClientRect().right>=i)return Te(e,r,e,D(e.doc,o),e.options.gutters[a],t),He(t)}}function zo(e,t){return Io(e,t,"gutterClick",!0)}function Ro(e,t){Ft(e.display,t)||Bo(e,t)||Me(e,t,"contextmenu")||e.display.input.onContextMenu(t)}function Bo(e,t){return!!Oe(e,"gutterContextMenu")&&Io(e,t,"gutterContextMenu",!1)}function Go(e){e.display.wrapper.className=e.display.wrapper.className.replace(/\s*cm-s-\S+/g,"")+e.options.theme.replace(/(^|\s)\s*/g," cm-s-"),er(e)}function Uo(e){Hn(e),vn(e),zr(e)}function Vo(e,t,r){if(!t!=!(r&&r!=Xs)){var n=e.display.dragFunctions,i=t?Ql:ke;i(e.display.scroller,"dragstart",n.start),i(e.display.scroller,"dragenter",n.enter),i(e.display.scroller,"dragover",n.over),i(e.display.scroller,"dragleave",n.leave),i(e.display.scroller,"drop",n.drop)}}function Ko(e){e.options.lineWrapping?(s(e.display.wrapper,"CodeMirror-wrap"),e.display.sizer.style.minWidth="",e.display.sizerWidth=null):(Fl(e.display.wrapper,"CodeMirror-wrap"),we(e)),Cr(e),vn(e),er(e),setTimeout(function(){return en(e)},100)}function jo(e,t){var r=this;if(!(this instanceof jo))return new jo(e,t);this.options=t=t?c(t):{},c(Ys,t,!1),Fn(t);var n=t.value;"string"==typeof n&&(n=new Ds(n,t.mode,null,t.lineSeparator,t.direction)),this.doc=n;var i=new jo.inputStyles[t.inputStyle](this),o=this.display=new T(e,n,i);o.wrapper.CodeMirror=this,Hn(this),Go(this),t.lineWrapping&&(this.display.wrapper.className+=" CodeMirror-wrap"),rn(this),this.state={keyMaps:[],overlays:[],modeGen:0,overwrite:!1,delayingBlurEvent:!1,focused:!1,suppressEdits:!1,pasteIncoming:!1,cutIncoming:!1,selectingText:!1,draggingText:!1,highlight:new Pl,keySeq:null,specialChars:null},t.autofocus&&!Tl&&o.input.focus(),gl&&vl<11&&setTimeout(function(){return r.display.input.reset(!0)},20),Xo(this),eo(),nn(this),this.curOp.forceUpdate=!0,qn(this,n),t.autofocus&&!Tl||this.hasFocus()?setTimeout(u(Hr,this),20):Fr(this);for(var l in _s)_s.hasOwnProperty(l)&&_s[l](r,t[l],Xs);Rr(this),t.finishInit&&t.finishInit(this);for(var s=0;s<$s.length;++s)$s[s](r);on(this),ml&&t.lineWrapping&&"optimizelegibility"==getComputedStyle(o.lineDiv).textRendering&&(o.lineDiv.style.textRendering="auto")}function Xo(e){function t(){i.activeTouch&&(o=setTimeout(function(){return i.activeTouch=null},1e3),(l=i.activeTouch).end=+new Date)}function r(e){if(1!=e.touches.length)return!1;var t=e.touches[0];return t.radiusX<=1&&t.radiusY<=1}function n(e,t){if(null==t.left)return!0;var r=t.left-e.left,n=t.top-e.top;return r*r+n*n>400}var i=e.display;Ql(i.scroller,"mousedown",dn(e,Oo)),gl&&vl<11?Ql(i.scroller,"dblclick",dn(e,function(t){if(!Me(e,t)){var r=Sr(e,t);if(r&&!zo(e,t)&&!Ft(e.display,t)){We(t);var n=e.findWordAt(r);di(e.doc,n.anchor,n.head)}}})):Ql(i.scroller,"dblclick",function(t){return Me(e,t)||We(t)}),Hl||Ql(i.scroller,"contextmenu",function(t){return Ro(e,t)});var o,l={end:0};Ql(i.scroller,"touchstart",function(t){if(!Me(e,t)&&!r(t)&&!zo(e,t)){i.input.ensurePolled(),clearTimeout(o);var n=+new Date;i.activeTouch={start:n,moved:!1,prev:n-l.end<=300?l:null},1==t.touches.length&&(i.activeTouch.left=t.touches[0].pageX,i.activeTouch.top=t.touches[0].pageY)}}),Ql(i.scroller,"touchmove",function(){i.activeTouch&&(i.activeTouch.moved=!0)}),Ql(i.scroller,"touchend",function(r){var o=i.activeTouch;if(o&&!Ft(i,r)&&null!=o.left&&!o.moved&&new Date-o.start<300){var l,s=e.coordsChar(i.activeTouch,"page");l=!o.prev||n(o,o.prev)?new Ts(s,s):!o.prev.prev||n(o,o.prev.prev)?e.findWordAt(s):new Ts(E(s.line,0),U(e.doc,E(s.line+1,0))),e.setSelection(l.anchor,l.head),e.focus(),We(r)}t()}),Ql(i.scroller,"touchcancel",t),Ql(i.scroller,"scroll",function(){i.scroller.clientHeight&&(qr(e,i.scroller.scrollTop),Qr(e,i.scroller.scrollLeft,!0),Te(e,"scroll",e))}),Ql(i.scroller,"mousewheel",function(t){return In(e,t)}),Ql(i.scroller,"DOMMouseScroll",function(t){return In(e,t)}),Ql(i.wrapper,"scroll",function(){return i.wrapper.scrollTop=i.wrapper.scrollLeft=0}),i.dragFunctions={enter:function(t){Me(e,t)||Fe(t)},over:function(t){Me(e,t)||(Zi(e,t),Fe(t))},start:function(t){return qi(e,t)},drop:dn(e,$i),leave:function(t){Me(e,t)||Qi(e)}};var s=i.input.getField();Ql(s,"keyup",function(t){return To.call(e,t)}),Ql(s,"keydown",dn(e,Lo)),Ql(s,"keypress",dn(e,Mo)),Ql(s,"focus",function(t){return Hr(e,t)}),Ql(s,"blur",function(t){return Fr(e,t)})}function Yo(e,t,r,n){var i,o=e.doc;null==r&&(r="add"),"smart"==r&&(o.mode.indent?i=$e(e,t).state:r="prev");var l=e.options.tabSize,s=M(o,t),a=f(s.text,null,l);s.stateAfter&&(s.stateAfter=null);var u,c=s.text.match(/^\s*/)[0];if(n||/\S/.test(s.text)){if("smart"==r&&((u=o.mode.indent(i,s.text.slice(c.length),s.text))==Bl||u>150)){if(!n)return;r="prev"}}else u=0,r="not";"prev"==r?u=t>o.first?f(M(o,t-1).text,null,l):0:"add"==r?u=a+e.options.indentUnit:"subtract"==r?u=a-e.options.indentUnit:"number"==typeof r&&(u=a+r),u=Math.max(0,u);var h="",d=0;if(e.options.indentWithTabs)for(var g=Math.floor(u/l);g;--g)d+=l,h+="\t";if(d<u&&(h+=p(u-d)),h!=c)return Ei(o,h,E(t,0),E(t,c.length),"+input"),s.stateAfter=null,!0;for(var v=0;v<o.sel.ranges.length;v++){var m=o.sel.ranges[v];if(m.head.line==t&&m.head.ch<c.length){var y=E(t,c.length);gi(o,v,new Ts(y,y));break}}}function _o(e){qs=e}function $o(e,t,r,n,i){var o=e.doc;e.display.shift=!1,n||(n=o.sel);var l=e.state.pasteIncoming||"paste"==i,s=es(t),a=null;if(l&&n.ranges.length>1)if(qs&&qs.text.join("\n")==t){if(n.ranges.length%qs.text.length==0){a=[];for(var u=0;u<qs.text.length;u++)a.push(o.splitLines(qs.text[u]))}}else s.length==n.ranges.length&&e.options.pasteLinesPerSelection&&(a=v(s,function(e){return[e]}));for(var c,f=n.ranges.length-1;f>=0;f--){var h=n.ranges[f],d=h.from(),p=h.to();h.empty()&&(r&&r>0?d=E(d.line,d.ch-r):e.state.overwrite&&!l?p=E(p.line,Math.min(M(o,p.line).text.length,p.ch+g(s).length)):qs&&qs.lineWise&&qs.text.join("\n")==t&&(d=p=E(d.line,0))),c=e.curOp.updateInput;var m={from:d,to:p,text:a?a[f%a.length]:s,origin:i||(l?"paste":e.state.cutIncoming?"cut":"+input")};Oi(e.doc,m),bt(e,"inputRead",e,m)}t&&!l&&Zo(e,t),jr(e),e.curOp.updateInput=c,e.curOp.typing=!0,e.state.pasteIncoming=e.state.cutIncoming=!1}function qo(e,t){var r=e.clipboardData&&e.clipboardData.getData("Text");if(r)return e.preventDefault(),t.isReadOnly()||t.options.disableInput||hn(t,function(){return $o(t,r,0,null,"paste")}),!0}function Zo(e,t){if(e.options.electricChars&&e.options.smartIndent)for(var r=e.doc.sel,n=r.ranges.length-1;n>=0;n--){var i=r.ranges[n];if(!(i.head.ch>100||n&&r.ranges[n-1].head.line==i.head.line)){var o=e.getModeAt(i.head),l=!1;if(o.electricChars){for(var s=0;s<o.electricChars.length;s++)if(t.indexOf(o.electricChars.charAt(s))>-1){l=Yo(e,i.head.line,"smart");break}}else o.electricInput&&o.electricInput.test(M(e.doc,i.head.line).text.slice(0,i.head.ch))&&(l=Yo(e,i.head.line,"smart"));l&&bt(e,"electricInput",e,i.head.line)}}}function Qo(e){for(var t=[],r=[],n=0;n<e.doc.sel.ranges.length;n++){var i=e.doc.sel.ranges[n].head.line,o={anchor:E(i,0),head:E(i+1,0)};r.push(o),t.push(e.getRange(o.anchor,o.head))}return{text:t,ranges:r}}function Jo(e,t){e.setAttribute("autocorrect","off"),e.setAttribute("autocapitalize","off"),e.setAttribute("spellcheck",!!t)}function el(){var e=n("textarea",null,null,"position: absolute; bottom: -1em; padding: 0; width: 1px; height: 1em; outline: none"),t=n("div",[e],null,"overflow: hidden; position: relative; width: 3px; height: 0px;");return ml?e.style.width="1000px":e.setAttribute("wrap","off"),Ll&&(e.style.border="1px solid black"),Jo(e),t}function tl(e,t,r,n,i){function o(){var n=t.line+r;return!(n<e.first||n>=e.first+e.size)&&(t=new E(n,t.ch,t.sticky),u=M(e,n))}function l(n){var l;if(null==(l=i?go(e.cm,u,t,r):ho(u,t,r))){if(n||!o())return!1;t=po(i,e.cm,u,t.line,r)}else t=l;return!0}var s=t,a=r,u=M(e,t.line);if("char"==n)l();else if("column"==n)l(!0);else if("word"==n||"group"==n)for(var c=null,f="group"==n,h=e.cm&&e.cm.getHelper(t,"wordChars"),d=!0;!(r<0)||l(!d);d=!1){var p=u.text.charAt(t.ch)||"\n",g=x(p,h)?"w":f&&"\n"==p?"n":!f||/\s/.test(p)?null:"p";if(!f||d||g||(g="s"),c&&c!=g){r<0&&(r=1,l(),t.sticky="after");break}if(g&&(c=g),r>0&&!l(!d))break}var v=ki(e,t,s,a,!0);return I(s,v)&&(v.hitSide=!0),v}function rl(e,t,r,n){var i,o=e.doc,l=t.left;if("page"==n){var s=Math.min(e.display.wrapper.clientHeight,window.innerHeight||document.documentElement.clientHeight),a=Math.max(s-.5*mr(e.display),3);i=(r>0?t.bottom:t.top)+r*a}else"line"==n&&(i=r>0?t.bottom+3:t.top-3);for(var u;(u=cr(e,l,i)).outside;){if(r<0?i<=0:i>=o.height){u.hitSide=!0;break}i+=5*r}return u}function nl(e,t){var r=jt(e,t.line);if(!r||r.hidden)return null;var n=M(e.doc,t.line),i=Ut(r,n,t.line),o=Se(n,e.doc.direction),l="left";o&&(l=Ce(o,t.ch)%2?"right":"left");var s=_t(i.map,t.ch,l);return s.offset="right"==s.collapse?s.end:s.start,s}function il(e){for(var t=e;t;t=t.parentNode)if(/CodeMirror-gutter-wrapper/.test(t.className))return!0;return!1}function ol(e,t){return t&&(e.bad=!0),e}function ll(e,t,r,n,i){function o(e){return function(t){return t.id==e}}function l(){c&&(u+=f,c=!1)}function s(e){e&&(l(),u+=e)}function a(t){if(1==t.nodeType){var r=t.getAttribute("cm-text");if(null!=r)return void s(r||t.textContent.replace(/\u200b/g,""));var u,h=t.getAttribute("cm-marker");if(h){var d=e.findMarks(E(n,0),E(i+1,0),o(+h));return void(d.length&&(u=d[0].find(0))&&s(N(e.doc,u.from,u.to).join(f)))}if("false"==t.getAttribute("contenteditable"))return;var p=/^(pre|div|p)$/i.test(t.nodeName);p&&l();for(var g=0;g<t.childNodes.length;g++)a(t.childNodes[g]);p&&(c=!0)}else 3==t.nodeType&&s(t.nodeValue)}for(var u="",c=!1,f=e.doc.lineSeparator();a(t),t!=r;)t=t.nextSibling;return u}function sl(e,t,r){var n;if(t==e.display.lineDiv){if(!(n=e.display.lineDiv.childNodes[r]))return ol(e.clipPos(E(e.display.viewTo-1)),!0);t=null,r=0}else for(n=t;;n=n.parentNode){if(!n||n==e.display.lineDiv)return null;if(n.parentNode&&n.parentNode==e.display.lineDiv)break}for(var i=0;i<e.display.view.length;i++){var o=e.display.view[i];if(o.node==n)return al(o,t,r)}}function al(e,t,r){function n(t,r,n){for(var i=-1;i<(f?f.length:0);i++)for(var o=i<0?c.map:f[i],l=0;l<o.length;l+=3){var s=o[l+2];if(s==t||s==r){var a=W(i<0?e.line:e.rest[i]),u=o[l]+n;return(n<0||s!=t)&&(u=o[l+(n?1:0)]),E(a,u)}}}var i=e.text.firstChild,l=!1;if(!t||!o(i,t))return ol(E(W(e.line),0),!0);if(t==i&&(l=!0,t=i.childNodes[r],r=0,!t)){var s=e.rest?g(e.rest):e.line;return ol(E(W(s),s.text.length),l)}var a=3==t.nodeType?t:null,u=t;for(a||1!=t.childNodes.length||3!=t.firstChild.nodeType||(a=t.firstChild,r&&(r=a.nodeValue.length));u.parentNode!=i;)u=u.parentNode;var c=e.measure,f=c.maps,h=n(a,u,r);if(h)return ol(h,l);for(var d=u.nextSibling,p=a?a.nodeValue.length-r:0;d;d=d.nextSibling){if(h=n(d,d.firstChild,0))return ol(E(h.line,h.ch-p),l);p+=d.textContent.length}for(var v=u.previousSibling,m=r;v;v=v.previousSibling){if(h=n(v,v.firstChild,-1))return ol(E(h.line,h.ch+m),l);m+=v.textContent.length}}var ul=navigator.userAgent,cl=navigator.platform,fl=/gecko\/\d/i.test(ul),hl=/MSIE \d/.test(ul),dl=/Trident\/(?:[7-9]|\d{2,})\..*rv:(\d+)/.exec(ul),pl=/Edge\/(\d+)/.exec(ul),gl=hl||dl||pl,vl=gl&&(hl?document.documentMode||6:+(pl||dl)[1]),ml=!pl&&/WebKit\//.test(ul),yl=ml&&/Qt\/\d+\.\d+/.test(ul),bl=!pl&&/Chrome\//.test(ul),wl=/Opera\//.test(ul),xl=/Apple Computer/.test(navigator.vendor),Cl=/Mac OS X 1\d\D([8-9]|\d\d)\D/.test(ul),Sl=/PhantomJS/.test(ul),Ll=!pl&&/AppleWebKit/.test(ul)&&/Mobile\/\w+/.test(ul),kl=/Android/.test(ul),Tl=Ll||kl||/webOS|BlackBerry|Opera Mini|Opera Mobi|IEMobile/i.test(ul),Ml=Ll||/Mac/.test(cl),Nl=/\bCrOS\b/.test(ul),Ol=/win/i.test(cl),Al=wl&&ul.match(/Version\/(\d*\.\d*)/);Al&&(Al=Number(Al[1])),Al&&Al>=15&&(wl=!1,ml=!0);var Wl,Dl=Ml&&(yl||wl&&(null==Al||Al<12.11)),Hl=fl||gl&&vl>=9,Fl=function(t,r){var n=t.className,i=e(r).exec(n);if(i){var o=n.slice(i.index+i[0].length);t.className=n.slice(0,i.index)+(o?i[1]+o:"")}};Wl=document.createRange?function(e,t,r,n){var i=document.createRange();return i.setEnd(n||e,r),i.setStart(e,t),i}:function(e,t,r){var n=document.body.createTextRange();try{n.moveToElementText(e.parentNode)}catch(e){return n}return n.collapse(!0),n.moveEnd("character",r),n.moveStart("character",t),n};var El=function(e){e.select()};Ll?El=function(e){e.selectionStart=0,e.selectionEnd=e.value.length}:gl&&(El=function(e){try{e.select()}catch(e){}});var Pl=function(){this.id=null};Pl.prototype.set=function(e,t){clearTimeout(this.id),this.id=setTimeout(t,e)};var Il,zl,Rl=30,Bl={toString:function(){return"CodeMirror.Pass"}},Gl={scroll:!1},Ul={origin:"*mouse"},Vl={origin:"+move"},Kl=[""],jl=/[\u00df\u0587\u0590-\u05f4\u0600-\u06ff\u3040-\u309f\u30a0-\u30ff\u3400-\u4db5\u4e00-\u9fcc\uac00-\ud7af]/,Xl=/[\u0300-\u036f\u0483-\u0489\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065e\u0670\u06d6-\u06dc\u06de-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0900-\u0902\u093c\u0941-\u0948\u094d\u0951-\u0955\u0962\u0963\u0981\u09bc\u09be\u09c1-\u09c4\u09cd\u09d7\u09e2\u09e3\u0a01\u0a02\u0a3c\u0a41\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81\u0a82\u0abc\u0ac1-\u0ac5\u0ac7\u0ac8\u0acd\u0ae2\u0ae3\u0b01\u0b3c\u0b3e\u0b3f\u0b41-\u0b44\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe\u0bc0\u0bcd\u0bd7\u0c3e-\u0c40\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0cbc\u0cbf\u0cc2\u0cc6\u0ccc\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d3e\u0d41-\u0d44\u0d4d\u0d57\u0d62\u0d63\u0dca\u0dcf\u0dd2-\u0dd4\u0dd6\u0ddf\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f71-\u0f7e\u0f80-\u0f84\u0f86\u0f87\u0f90-\u0f97\u0f99-\u0fbc\u0fc6\u102d-\u1030\u1032-\u1037\u1039\u103a\u103d\u103e\u1058\u1059\u105e-\u1060\u1071-\u1074\u1082\u1085\u1086\u108d\u109d\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b7-\u17bd\u17c6\u17c9-\u17d3\u17dd\u180b-\u180d\u18a9\u1920-\u1922\u1927\u1928\u1932\u1939-\u193b\u1a17\u1a18\u1a56\u1a58-\u1a5e\u1a60\u1a62\u1a65-\u1a6c\u1a73-\u1a7c\u1a7f\u1b00-\u1b03\u1b34\u1b36-\u1b3a\u1b3c\u1b42\u1b6b-\u1b73\u1b80\u1b81\u1ba2-\u1ba5\u1ba8\u1ba9\u1c2c-\u1c33\u1c36\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce0\u1ce2-\u1ce8\u1ced\u1dc0-\u1de6\u1dfd-\u1dff\u200c\u200d\u20d0-\u20f0\u2cef-\u2cf1\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f-\ua672\ua67c\ua67d\ua6f0\ua6f1\ua802\ua806\ua80b\ua825\ua826\ua8c4\ua8e0-\ua8f1\ua926-\ua92d\ua947-\ua951\ua980-\ua982\ua9b3\ua9b6-\ua9b9\ua9bc\uaa29-\uaa2e\uaa31\uaa32\uaa35\uaa36\uaa43\uaa4c\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uabe5\uabe8\uabed\udc00-\udfff\ufb1e\ufe00-\ufe0f\ufe20-\ufe26\uff9e\uff9f]/,Yl=!1,_l=!1,$l=null,ql=function(){function e(e){return e<=247?r.charAt(e):1424<=e&&e<=1524?"R":1536<=e&&e<=1785?n.charAt(e-1536):1774<=e&&e<=2220?"r":8192<=e&&e<=8203?"w":8204==e?"b":"L"}function t(e,t,r){this.level=e,this.from=t,this.to=r}var r="bbbbbbbbbtstwsbbbbbbbbbbbbbbssstwNN%%%NNNNNN,N,N1111111111NNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNNNLLLLLLLLLLLLLLLLLLLLLLLLLLNNNNbbbbbbsbbbbbbbbbbbbbbbbbbbbbbbbbb,N%%%%NNNNLNNNNN%%11NLNNN1LNNNNNLLLLLLLLLLLLLLLLLLLLLLLNLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLN",n="nnnnnnNNr%%r,rNNmmmmmmmmmmmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmmmmmmmmmmmmmmmnnnnnnnnnn%nnrrrmrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrmmmmmmmnNmmmmmmrrmmNmmmmrr1111111111",i=/[\u0590-\u05f4\u0600-\u06ff\u0700-\u08ac]/,o=/[stwN]/,l=/[LRr]/,s=/[Lb1n]/,a=/[1n]/;return function(r,n){var u="ltr"==n?"L":"R";if(0==r.length||"ltr"==n&&!i.test(r))return!1;for(var c=r.length,f=[],h=0;h<c;++h)f.push(e(r.charCodeAt(h)));for(var d=0,p=u;d<c;++d){var v=f[d];"m"==v?f[d]=p:p=v}for(var m=0,y=u;m<c;++m){var b=f[m];"1"==b&&"r"==y?f[m]="n":l.test(b)&&(y=b,"r"==b&&(f[m]="R"))}for(var w=1,x=f[0];w<c-1;++w){var C=f[w];"+"==C&&"1"==x&&"1"==f[w+1]?f[w]="1":","!=C||x!=f[w+1]||"1"!=x&&"n"!=x||(f[w]=x),x=C}for(var S=0;S<c;++S){var L=f[S];if(","==L)f[S]="N";else if("%"==L){var k=void 0;for(k=S+1;k<c&&"%"==f[k];++k);for(var T=S&&"!"==f[S-1]||k<c&&"1"==f[k]?"1":"N",M=S;M<k;++M)f[M]=T;S=k-1}}for(var N=0,O=u;N<c;++N){var A=f[N];"L"==O&&"1"==A?f[N]="L":l.test(A)&&(O=A)}for(var W=0;W<c;++W)if(o.test(f[W])){var D=void 0;for(D=W+1;D<c&&o.test(f[D]);++D);for(var H="L"==(W?f[W-1]:u),F=H==("L"==(D<c?f[D]:u))?H?"L":"R":u,E=W;E<D;++E)f[E]=F;W=D-1}for(var P,I=[],z=0;z<c;)if(s.test(f[z])){var R=z;for(++z;z<c&&s.test(f[z]);++z);I.push(new t(0,R,z))}else{var B=z,G=I.length;for(++z;z<c&&"L"!=f[z];++z);for(var U=B;U<z;)if(a.test(f[U])){B<U&&I.splice(G,0,new t(1,B,U));var V=U;for(++U;U<z&&a.test(f[U]);++U);I.splice(G,0,new t(2,V,U)),B=U}else++U;B<z&&I.splice(G,0,new t(1,B,z))}return 1==I[0].level&&(P=r.match(/^\s+/))&&(I[0].from=P[0].length,I.unshift(new t(0,0,P[0].length))),1==g(I).level&&(P=r.match(/\s+$/))&&(g(I).to-=P[0].length,I.push(new t(0,c-P[0].length,c))),"rtl"==n?I.reverse():I}}(),Zl=[],Ql=function(e,t,r){if(e.addEventListener)e.addEventListener(t,r,!1);else if(e.attachEvent)e.attachEvent("on"+t,r);else{var n=e._handlers||(e._handlers={});n[t]=(n[t]||Zl).concat(r)}},Jl=function(){if(gl&&vl<9)return!1;var e=n("div");return"draggable"in e||"dragDrop"in e}(),es=3!="\n\nb".split(/\n/).length?function(e){for(var t=0,r=[],n=e.length;t<=n;){var i=e.indexOf("\n",t);-1==i&&(i=e.length);var o=e.slice(t,"\r"==e.charAt(i-1)?i-1:i),l=o.indexOf("\r");-1!=l?(r.push(o.slice(0,l)),t+=l+1):(r.push(o),t=i+1)}return r}:function(e){return e.split(/\r\n?|\n/)},ts=window.getSelection?function(e){try{return e.selectionStart!=e.selectionEnd}catch(e){return!1}}:function(e){var t;try{t=e.ownerDocument.selection.createRange()}catch(e){}return!(!t||t.parentElement()!=e)&&0!=t.compareEndPoints("StartToEnd",t)},rs=function(){var e=n("div");return"oncopy"in e||(e.setAttribute("oncopy","return;"),"function"==typeof e.oncopy)}(),ns=null,is={},os={},ls={},ss=function(e,t,r){this.pos=this.start=0,this.string=e,this.tabSize=t||8,this.lastColumnPos=this.lastColumnValue=0,this.lineStart=0,this.lineOracle=r};ss.prototype.eol=function(){return this.pos>=this.string.length},ss.prototype.sol=function(){return this.pos==this.lineStart},ss.prototype.peek=function(){return this.string.charAt(this.pos)||void 0},ss.prototype.next=function(){if(this.pos<this.string.length)return this.string.charAt(this.pos++)},ss.prototype.eat=function(e){var t=this.string.charAt(this.pos);if("string"==typeof e?t==e:t&&(e.test?e.test(t):e(t)))return++this.pos,t},ss.prototype.eatWhile=function(e){for(var t=this.pos;this.eat(e););return this.pos>t},ss.prototype.eatSpace=function(){for(var e=this,t=this.pos;/[\s\u00a0]/.test(this.string.charAt(this.pos));)++e.pos;return this.pos>t},ss.prototype.skipToEnd=function(){this.pos=this.string.length},ss.prototype.skipTo=function(e){var t=this.string.indexOf(e,this.pos);if(t>-1)return this.pos=t,!0},ss.prototype.backUp=function(e){this.pos-=e},ss.prototype.column=function(){return this.lastColumnPos<this.start&&(this.lastColumnValue=f(this.string,this.start,this.tabSize,this.lastColumnPos,this.lastColumnValue),this.lastColumnPos=this.start),this.lastColumnValue-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.indentation=function(){return f(this.string,null,this.tabSize)-(this.lineStart?f(this.string,this.lineStart,this.tabSize):0)},ss.prototype.match=function(e,t,r){if("string"!=typeof e){var n=this.string.slice(this.pos).match(e);return n&&n.index>0?null:(n&&!1!==t&&(this.pos+=n[0].length),n)}var i=function(e){return r?e.toLowerCase():e};if(i(this.string.substr(this.pos,e.length))==i(e))return!1!==t&&(this.pos+=e.length),!0},ss.prototype.current=function(){return this.string.slice(this.start,this.pos)},ss.prototype.hideFirstChars=function(e,t){this.lineStart+=e;try{return t()}finally{this.lineStart-=e}},ss.prototype.lookAhead=function(e){var t=this.lineOracle;return t&&t.lookAhead(e)};var as=function(e,t){this.state=e,this.lookAhead=t},us=function(e,t,r,n){this.state=t,this.doc=e,this.line=r,this.maxLookAhead=n||0};us.prototype.lookAhead=function(e){var t=this.doc.getLine(this.line+e);return null!=t&&e>this.maxLookAhead&&(this.maxLookAhead=e),t},us.prototype.nextLine=function(){this.line++,this.maxLookAhead>0&&this.maxLookAhead--},us.fromSaved=function(e,t,r){return t instanceof as?new us(e,Ke(e.mode,t.state),r,t.lookAhead):new us(e,Ke(e.mode,t),r)},us.prototype.save=function(e){var t=!1!==e?Ke(this.doc.mode,this.state):this.state;return this.maxLookAhead>0?new as(t,this.maxLookAhead):t};var cs=function(e,t,r){this.start=e.start,this.end=e.pos,this.string=e.current(),this.type=t||null,this.state=r},fs=function(e,t,r){this.text=e,ne(this,t),this.height=r?r(this):1};fs.prototype.lineNo=function(){return W(this)},Ae(fs);var hs,ds={},ps={},gs=null,vs=null,ms={left:0,right:0,top:0,bottom:0},ys=function(e,t,r){this.cm=r;var i=this.vert=n("div",[n("div",null,null,"min-width: 1px")],"CodeMirror-vscrollbar"),o=this.horiz=n("div",[n("div",null,null,"height: 100%; min-height: 1px")],"CodeMirror-hscrollbar");e(i),e(o),Ql(i,"scroll",function(){i.clientHeight&&t(i.scrollTop,"vertical")}),Ql(o,"scroll",function(){o.clientWidth&&t(o.scrollLeft,"horizontal")}),this.checkedZeroWidth=!1,gl&&vl<8&&(this.horiz.style.minHeight=this.vert.style.minWidth="18px")};ys.prototype.update=function(e){var t=e.scrollWidth>e.clientWidth+1,r=e.scrollHeight>e.clientHeight+1,n=e.nativeBarWidth;if(r){this.vert.style.display="block",this.vert.style.bottom=t?n+"px":"0";var i=e.viewHeight-(t?n:0);this.vert.firstChild.style.height=Math.max(0,e.scrollHeight-e.clientHeight+i)+"px"}else this.vert.style.display="",this.vert.firstChild.style.height="0";if(t){this.horiz.style.display="block",this.horiz.style.right=r?n+"px":"0",this.horiz.style.left=e.barLeft+"px";var o=e.viewWidth-e.barLeft-(r?n:0);this.horiz.firstChild.style.width=Math.max(0,e.scrollWidth-e.clientWidth+o)+"px"}else this.horiz.style.display="",this.horiz.firstChild.style.width="0";return!this.checkedZeroWidth&&e.clientHeight>0&&(0==n&&this.zeroWidthHack(),this.checkedZeroWidth=!0),{right:r?n:0,bottom:t?n:0}},ys.prototype.setScrollLeft=function(e){this.horiz.scrollLeft!=e&&(this.horiz.scrollLeft=e),this.disableHoriz&&this.enableZeroWidthBar(this.horiz,this.disableHoriz,"horiz")},ys.prototype.setScrollTop=function(e){this.vert.scrollTop!=e&&(this.vert.scrollTop=e),this.disableVert&&this.enableZeroWidthBar(this.vert,this.disableVert,"vert")},ys.prototype.zeroWidthHack=function(){var e=Ml&&!Cl?"12px":"18px";this.horiz.style.height=this.vert.style.width=e,this.horiz.style.pointerEvents=this.vert.style.pointerEvents="none",this.disableHoriz=new Pl,this.disableVert=new Pl},ys.prototype.enableZeroWidthBar=function(e,t,r){function n(){var i=e.getBoundingClientRect();("vert"==r?document.elementFromPoint(i.right-1,(i.top+i.bottom)/2):document.elementFromPoint((i.right+i.left)/2,i.bottom-1))!=e?e.style.pointerEvents="none":t.set(1e3,n)}e.style.pointerEvents="auto",t.set(1e3,n)},ys.prototype.clear=function(){var e=this.horiz.parentNode;e.removeChild(this.horiz),e.removeChild(this.vert)};var bs=function(){};bs.prototype.update=function(){return{bottom:0,right:0}},bs.prototype.setScrollLeft=function(){},bs.prototype.setScrollTop=function(){},bs.prototype.clear=function(){};var ws={native:ys,null:bs},xs=0,Cs=function(e,t,r){var n=e.display;this.viewport=t,this.visible=Ir(n,e.doc,t),this.editorIsHidden=!n.wrapper.offsetWidth,this.wrapperHeight=n.wrapper.clientHeight,this.wrapperWidth=n.wrapper.clientWidth,this.oldDisplayWidth=Rt(e),this.force=r,this.dims=br(e),this.events=[]};Cs.prototype.signal=function(e,t){Oe(e,t)&&this.events.push(arguments)},Cs.prototype.finish=function(){for(var e=this,t=0;t<this.events.length;t++)Te.apply(null,e.events[t])};var Ss=0,Ls=null;gl?Ls=-.53:fl?Ls=15:bl?Ls=-.7:xl&&(Ls=-1/3);var ks=function(e,t){this.ranges=e,this.primIndex=t};ks.prototype.primary=function(){return this.ranges[this.primIndex]},ks.prototype.equals=function(e){var t=this;if(e==this)return!0;if(e.primIndex!=this.primIndex||e.ranges.length!=this.ranges.length)return!1;for(var r=0;r<this.ranges.length;r++){var n=t.ranges[r],i=e.ranges[r];if(!I(n.anchor,i.anchor)||!I(n.head,i.head))return!1}return!0},ks.prototype.deepCopy=function(){for(var e=this,t=[],r=0;r<this.ranges.length;r++)t[r]=new Ts(z(e.ranges[r].anchor),z(e.ranges[r].head));return new ks(t,this.primIndex)},ks.prototype.somethingSelected=function(){for(var e=this,t=0;t<this.ranges.length;t++)if(!e.ranges[t].empty())return!0;return!1},ks.prototype.contains=function(e,t){var r=this;t||(t=e);for(var n=0;n<this.ranges.length;n++){var i=r.ranges[n];if(P(t,i.from())>=0&&P(e,i.to())<=0)return n}return-1};var Ts=function(e,t){this.anchor=e,this.head=t};Ts.prototype.from=function(){return B(this.anchor,this.head)},Ts.prototype.to=function(){return R(this.anchor,this.head)},Ts.prototype.empty=function(){return this.head.line==this.anchor.line&&this.head.ch==this.anchor.ch},Bi.prototype={chunkSize:function(){return this.lines.length},removeInner:function(e,t){for(var r=this,n=e,i=e+t;n<i;++n){var o=r.lines[n];r.height-=o.height,ot(o),bt(o,"delete")}this.lines.splice(e,t)},collapse:function(e){e.push.apply(e,this.lines)},insertInner:function(e,t,r){var n=this;this.height+=r,this.lines=this.lines.slice(0,e).concat(t).concat(this.lines.slice(e));for(var i=0;i<t.length;++i)t[i].parent=n},iterN:function(e,t,r){for(var n=this,i=e+t;e<i;++e)if(r(n.lines[e]))return!0}},Gi.prototype={chunkSize:function(){return this.size},removeInner:function(e,t){var r=this;this.size-=t;for(var n=0;n<this.children.length;++n){var i=r.children[n],o=i.chunkSize();if(e<o){var l=Math.min(t,o-e),s=i.height;if(i.removeInner(e,l),r.height-=s-i.height,o==l&&(r.children.splice(n--,1),i.parent=null),0==(t-=l))break;e=0}else e-=o}if(this.size-t<25&&(this.children.length>1||!(this.children[0]instanceof Bi))){var a=[];this.collapse(a),this.children=[new Bi(a)],this.children[0].parent=this}},collapse:function(e){for(var t=this,r=0;r<this.children.length;++r)t.children[r].collapse(e)},insertInner:function(e,t,r){var n=this;this.size+=t.length,this.height+=r;for(var i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<=l){if(o.insertInner(e,t,r),o.lines&&o.lines.length>50){for(var s=o.lines.length%25+25,a=s;a<o.lines.length;){var u=new Bi(o.lines.slice(a,a+=25));o.height-=u.height,n.children.splice(++i,0,u),u.parent=n}o.lines=o.lines.slice(0,s),n.maybeSpill()}break}e-=l}},maybeSpill:function(){if(!(this.children.length<=10)){var e=this;do{var t=new Gi(e.children.splice(e.children.length-5,5));if(e.parent){e.size-=t.size,e.height-=t.height;var r=h(e.parent.children,e);e.parent.children.splice(r+1,0,t)}else{var n=new Gi(e.children);n.parent=e,e.children=[n,t],e=n}t.parent=e.parent}while(e.children.length>10);e.parent.maybeSpill()}},iterN:function(e,t,r){for(var n=this,i=0;i<this.children.length;++i){var o=n.children[i],l=o.chunkSize();if(e<l){var s=Math.min(t,l-e);if(o.iterN(e,s,r))return!0;if(0==(t-=s))break;e=0}else e-=l}}};var Ms=function(e,t,r){var n=this;if(r)for(var i in r)r.hasOwnProperty(i)&&(n[i]=r[i]);this.doc=e,this.node=t};Ms.prototype.clear=function(){var e=this,t=this.doc.cm,r=this.line.widgets,n=this.line,i=W(n);if(null!=i&&r){for(var o=0;o<r.length;++o)r[o]==e&&r.splice(o--,1);r.length||(n.widgets=null);var l=Ht(this);A(n,Math.max(0,n.height-l)),t&&(hn(t,function(){Ui(t,n,-l),mn(t,i,"widget")}),bt(t,"lineWidgetCleared",t,this,i))}},Ms.prototype.changed=function(){var e=this,t=this.height,r=this.doc.cm,n=this.line;this.height=null;var i=Ht(this)-t;i&&(A(n,n.height+i),r&&hn(r,function(){r.curOp.forceUpdate=!0,Ui(r,n,i),bt(r,"lineWidgetChanged",r,e,W(n))}))},Ae(Ms);var Ns=0,Os=function(e,t){this.lines=[],this.type=t,this.doc=e,this.id=++Ns};Os.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){var t=this.doc.cm,r=t&&!t.curOp;if(r&&nn(t),Oe(this,"clear")){var n=this.find();n&&bt(this,"clear",n.from,n.to)}for(var i=null,o=null,l=0;l<this.lines.length;++l){var s=e.lines[l],a=_(s.markedSpans,e);t&&!e.collapsed?mn(t,W(s),"text"):t&&(null!=a.to&&(o=W(s)),null!=a.from&&(i=W(s))),s.markedSpans=$(s.markedSpans,a),null==a.from&&e.collapsed&&!ve(e.doc,s)&&t&&A(s,mr(t.display))}if(t&&this.collapsed&&!t.options.lineWrapping)for(var u=0;u<this.lines.length;++u){var c=fe(e.lines[u]),f=be(c);f>t.display.maxLineLength&&(t.display.maxLine=c,t.display.maxLineLength=f,t.display.maxLineChanged=!0)}null!=i&&t&&this.collapsed&&vn(t,i,o+1),this.lines.length=0,this.explicitlyCleared=!0,this.atomic&&this.doc.cantEdit&&(this.doc.cantEdit=!1,t&&Ci(t.doc)),t&&bt(t,"markerCleared",t,this,i,o),r&&on(t),this.parent&&this.parent.clear()}},Os.prototype.find=function(e,t){var r=this;null==e&&"bookmark"==this.type&&(e=1);for(var n,i,o=0;o<this.lines.length;++o){var l=r.lines[o],s=_(l.markedSpans,r);if(null!=s.from&&(n=E(t?l:W(l),s.from),-1==e))return n;if(null!=s.to&&(i=E(t?l:W(l),s.to),1==e))return i}return n&&{from:n,to:i}},Os.prototype.changed=function(){var e=this,t=this.find(-1,!0),r=this,n=this.doc.cm;t&&n&&hn(n,function(){var i=t.line,o=W(t.line),l=jt(n,o);if(l&&(Qt(l),n.curOp.selectionChanged=n.curOp.forceUpdate=!0),n.curOp.updateMaxLine=!0,!ve(r.doc,i)&&null!=r.height){var s=r.height;r.height=null;var a=Ht(r)-s;a&&A(i,i.height+a)}bt(n,"markerChanged",n,e)})},Os.prototype.attachLine=function(e){if(!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;t.maybeHiddenMarkers&&-1!=h(t.maybeHiddenMarkers,this)||(t.maybeUnhiddenMarkers||(t.maybeUnhiddenMarkers=[])).push(this)}this.lines.push(e)},Os.prototype.detachLine=function(e){if(this.lines.splice(h(this.lines,e),1),!this.lines.length&&this.doc.cm){var t=this.doc.cm.curOp;(t.maybeHiddenMarkers||(t.maybeHiddenMarkers=[])).push(this)}},Ae(Os);var As=function(e,t){var r=this;this.markers=e,this.primary=t;for(var n=0;n<e.length;++n)e[n].parent=r};As.prototype.clear=function(){var e=this;if(!this.explicitlyCleared){this.explicitlyCleared=!0;for(var t=0;t<this.markers.length;++t)e.markers[t].clear();bt(this,"clear")}},As.prototype.find=function(e,t){return this.primary.find(e,t)},Ae(As);var Ws=0,Ds=function(e,t,r,n,i){if(!(this instanceof Ds))return new Ds(e,t,r,n,i);null==r&&(r=0),Gi.call(this,[new Bi([new fs("",null)])]),this.first=r,this.scrollTop=this.scrollLeft=0,this.cantEdit=!1,this.cleanGeneration=1,this.modeFrontier=this.highlightFrontier=r;var o=E(r,0);this.sel=Rn(o),this.history=new Jn(null),this.id=++Ws,this.modeOption=t,this.lineSep=n,this.direction="rtl"==i?"rtl":"ltr",this.extend=!1,"string"==typeof e&&(e=this.splitLines(e)),_n(this,{from:o,to:o,text:e}),bi(this,Rn(o),Gl)};Ds.prototype=b(Gi.prototype,{constructor:Ds,iter:function(e,t,r){r?this.iterN(e-this.first,t-e,r):this.iterN(this.first,this.first+this.size,e)},insert:function(e,t){for(var r=0,n=0;n<t.length;++n)r+=t[n].height;this.insertInner(e-this.first,t,r)},remove:function(e,t){this.removeInner(e-this.first,t)},getValue:function(e){var t=O(this,this.first,this.first+this.size);return!1===e?t:t.join(e||this.lineSeparator())},setValue:gn(function(e){var t=E(this.first,0),r=this.first+this.size-1;Oi(this,{from:t,to:E(r,M(this,r).text.length),text:this.splitLines(e),origin:"setValue",full:!0},!0),this.cm&&Xr(this.cm,0,0),bi(this,Rn(t),Gl)}),replaceRange:function(e,t,r,n){Ei(this,e,t=U(this,t),r=r?U(this,r):t,n)},getRange:function(e,t,r){var n=N(this,U(this,e),U(this,t));return!1===r?n:n.join(r||this.lineSeparator())},getLine:function(e){var t=this.getLineHandle(e);return t&&t.text},getLineHandle:function(e){if(H(this,e))return M(this,e)},getLineNumber:function(e){return W(e)},getLineHandleVisualStart:function(e){return"number"==typeof e&&(e=M(this,e)),fe(e)},lineCount:function(){return this.size},firstLine:function(){return this.first},lastLine:function(){return this.first+this.size-1},clipPos:function(e){return U(this,e)},getCursor:function(e){var t=this.sel.primary();return null==e||"head"==e?t.head:"anchor"==e?t.anchor:"end"==e||"to"==e||!1===e?t.to():t.from()},listSelections:function(){return this.sel.ranges},somethingSelected:function(){return this.sel.somethingSelected()},setCursor:gn(function(e,t,r){vi(this,U(this,"number"==typeof e?E(e,t||0):e),null,r)}),setSelection:gn(function(e,t,r){vi(this,U(this,e),U(this,t||e),r)}),extendSelection:gn(function(e,t,r){di(this,U(this,e),t&&U(this,t),r)}),extendSelections:gn(function(e,t){pi(this,K(this,e),t)}),extendSelectionsBy:gn(function(e,t){pi(this,K(this,v(this.sel.ranges,e)),t)}),setSelections:gn(function(e,t,r){var n=this;if(e.length){for(var i=[],o=0;o<e.length;o++)i[o]=new Ts(U(n,e[o].anchor),U(n,e[o].head));null==t&&(t=Math.min(e.length-1,this.sel.primIndex)),bi(this,zn(i,t),r)}}),addSelection:gn(function(e,t,r){var n=this.sel.ranges.slice(0);n.push(new Ts(U(this,e),U(this,t||e))),bi(this,zn(n,n.length-1),r)}),getSelection:function(e){for(var t,r=this,n=this.sel.ranges,i=0;i<n.length;i++){var o=N(r,n[i].from(),n[i].to());t=t?t.concat(o):o}return!1===e?t:t.join(e||this.lineSeparator())},getSelections:function(e){for(var t=this,r=[],n=this.sel.ranges,i=0;i<n.length;i++){var o=N(t,n[i].from(),n[i].to());!1!==e&&(o=o.join(e||t.lineSeparator())),r[i]=o}return r},replaceSelection:function(e,t,r){for(var n=[],i=0;i<this.sel.ranges.length;i++)n[i]=e;this.replaceSelections(n,t,r||"+input")},replaceSelections:gn(function(e,t,r){for(var n=this,i=[],o=this.sel,l=0;l<o.ranges.length;l++){var s=o.ranges[l];i[l]={from:s.from(),to:s.to(),text:n.splitLines(e[l]),origin:r}}for(var a=t&&"end"!=t&&Kn(this,i,t),u=i.length-1;u>=0;u--)Oi(n,i[u]);a?yi(this,a):this.cm&&jr(this.cm)}),undo:gn(function(){Wi(this,"undo")}),redo:gn(function(){Wi(this,"redo")}),undoSelection:gn(function(){Wi(this,"undo",!0)}),redoSelection:gn(function(){Wi(this,"redo",!0)}),setExtending:function(e){this.extend=e},getExtending:function(){return this.extend},historySize:function(){for(var e=this.history,t=0,r=0,n=0;n<e.done.length;n++)e.done[n].ranges||++t;for(var i=0;i<e.undone.length;i++)e.undone[i].ranges||++r;return{undo:t,redo:r}},clearHistory:function(){this.history=new Jn(this.history.maxGeneration)},markClean:function(){this.cleanGeneration=this.changeGeneration(!0)},changeGeneration:function(e){return e&&(this.history.lastOp=this.history.lastSelOp=this.history.lastOrigin=null),this.history.generation},isClean:function(e){return this.history.generation==(e||this.cleanGeneration)},getHistory:function(){return{done:fi(this.history.done),undone:fi(this.history.undone)}},setHistory:function(e){var t=this.history=new Jn(this.history.maxGeneration);t.done=fi(e.done.slice(0),null,!0),t.undone=fi(e.undone.slice(0),null,!0)},setGutterMarker:gn(function(e,t,r){return Ri(this,e,"gutter",function(e){var n=e.gutterMarkers||(e.gutterMarkers={});return n[t]=r,!r&&C(n)&&(e.gutterMarkers=null),!0})}),clearGutter:gn(function(e){var t=this;this.iter(function(r){r.gutterMarkers&&r.gutterMarkers[e]&&Ri(t,r,"gutter",function(){return r.gutterMarkers[e]=null,C(r.gutterMarkers)&&(r.gutterMarkers=null),!0})})}),lineInfo:function(e){var t;if("number"==typeof e){if(!H(this,e))return null;if(t=e,!(e=M(this,e)))return null}else if(null==(t=W(e)))return null;return{line:t,handle:e,text:e.text,gutterMarkers:e.gutterMarkers,textClass:e.textClass,bgClass:e.bgClass,wrapClass:e.wrapClass,widgets:e.widgets}},addLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass";if(t[i]){if(e(n).test(t[i]))return!1;t[i]+=" "+n}else t[i]=n;return!0})}),removeLineClass:gn(function(t,r,n){return Ri(this,t,"gutter"==r?"gutter":"class",function(t){var i="text"==r?"textClass":"background"==r?"bgClass":"gutter"==r?"gutterClass":"wrapClass",o=t[i];if(!o)return!1;if(null==n)t[i]=null;else{var l=o.match(e(n));if(!l)return!1;var s=l.index+l[0].length;t[i]=o.slice(0,l.index)+(l.index&&s!=o.length?" ":"")+o.slice(s)||null}return!0})}),addLineWidget:gn(function(e,t,r){return Vi(this,e,t,r)}),removeLineWidget:function(e){e.clear()},markText:function(e,t,r){return Ki(this,U(this,e),U(this,t),r,r&&r.type||"range")},setBookmark:function(e,t){var r={replacedWith:t&&(null==t.nodeType?t.widget:t),insertLeft:t&&t.insertLeft,clearWhenEmpty:!1,shared:t&&t.shared,handleMouseEvents:t&&t.handleMouseEvents};return e=U(this,e),Ki(this,e,e,r,"bookmark")},findMarksAt:function(e){var t=[],r=M(this,(e=U(this,e)).line).markedSpans;if(r)for(var n=0;n<r.length;++n){var i=r[n];(null==i.from||i.from<=e.ch)&&(null==i.to||i.to>=e.ch)&&t.push(i.marker.parent||i.marker)}return t},findMarks:function(e,t,r){e=U(this,e),t=U(this,t);var n=[],i=e.line;return this.iter(e.line,t.line+1,function(o){var l=o.markedSpans;if(l)for(var s=0;s<l.length;s++){var a=l[s];null!=a.to&&i==e.line&&e.ch>=a.to||null==a.from&&i!=e.line||null!=a.from&&i==t.line&&a.from>=t.ch||r&&!r(a.marker)||n.push(a.marker.parent||a.marker)}++i}),n},getAllMarks:function(){var e=[];return this.iter(function(t){var r=t.markedSpans;if(r)for(var n=0;n<r.length;++n)null!=r[n].from&&e.push(r[n].marker)}),e},posFromIndex:function(e){var t,r=this.first,n=this.lineSeparator().length;return this.iter(function(i){var o=i.text.length+n;if(o>e)return t=e,!0;e-=o,++r}),U(this,E(r,t))},indexFromPos:function(e){var t=(e=U(this,e)).ch;if(e.line<this.first||e.ch<0)return 0;var r=this.lineSeparator().length;return this.iter(this.first,e.line,function(e){t+=e.text.length+r}),t},copy:function(e){var t=new Ds(O(this,this.first,this.first+this.size),this.modeOption,this.first,this.lineSep,this.direction);return t.scrollTop=this.scrollTop,t.scrollLeft=this.scrollLeft,t.sel=this.sel,t.extend=!1,e&&(t.history.undoDepth=this.history.undoDepth,t.setHistory(this.getHistory())),t},linkedDoc:function(e){e||(e={});var t=this.first,r=this.first+this.size;null!=e.from&&e.from>t&&(t=e.from),null!=e.to&&e.to<r&&(r=e.to);var n=new Ds(O(this,t,r),e.mode||this.modeOption,t,this.lineSep,this.direction);return e.sharedHist&&(n.history=this.history),(this.linked||(this.linked=[])).push({doc:n,sharedHist:e.sharedHist}),n.linked=[{doc:this,isParent:!0,sharedHist:e.sharedHist}],Yi(n,Xi(this)),n},unlinkDoc:function(e){var t=this;if(e instanceof jo&&(e=e.doc),this.linked)for(var r=0;r<this.linked.length;++r)if(t.linked[r].doc==e){t.linked.splice(r,1),e.unlinkDoc(t),_i(Xi(t));break}if(e.history==this.history){var n=[e.id];$n(e,function(e){return n.push(e.id)},!0),e.history=new Jn(null),e.history.done=fi(this.history.done,n),e.history.undone=fi(this.history.undone,n)}},iterLinkedDocs:function(e){$n(this,e)},getMode:function(){return this.mode},getEditor:function(){return this.cm},splitLines:function(e){return this.lineSep?e.split(this.lineSep):es(e)},lineSeparator:function(){return this.lineSep||"\n"},setDirection:gn(function(e){"rtl"!=e&&(e="ltr"),e!=this.direction&&(this.direction=e,this.iter(function(e){return e.order=null}),this.cm&&Qn(this.cm))})}),Ds.prototype.eachLine=Ds.prototype.iter;for(var Hs=0,Fs=!1,Es={3:"Enter",8:"Backspace",9:"Tab",13:"Enter",16:"Shift",17:"Ctrl",18:"Alt",19:"Pause",20:"CapsLock",27:"Esc",32:"Space",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"Left",38:"Up",39:"Right",40:"Down",44:"PrintScrn",45:"Insert",46:"Delete",59:";",61:"=",91:"Mod",92:"Mod",93:"Mod",106:"*",107:"=",109:"-",110:".",111:"/",127:"Delete",173:"-",186:";",187:"=",188:",",189:"-",190:".",191:"/",192:"`",219:"[",220:"\\",221:"]",222:"'",63232:"Up",63233:"Down",63234:"Left",63235:"Right",63272:"Delete",63273:"Home",63275:"End",63276:"PageUp",63277:"PageDown",63302:"Insert"},Ps=0;Ps<10;Ps++)Es[Ps+48]=Es[Ps+96]=String(Ps);for(var Is=65;Is<=90;Is++)Es[Is]=String.fromCharCode(Is);for(var zs=1;zs<=12;zs++)Es[zs+111]=Es[zs+63235]="F"+zs;var Rs={};Rs.basic={Left:"goCharLeft",Right:"goCharRight",Up:"goLineUp",Down:"goLineDown",End:"goLineEnd",Home:"goLineStartSmart",PageUp:"goPageUp",PageDown:"goPageDown",Delete:"delCharAfter",Backspace:"delCharBefore","Shift-Backspace":"delCharBefore",Tab:"defaultTab","Shift-Tab":"indentAuto",Enter:"newlineAndIndent",Insert:"toggleOverwrite",Esc:"singleSelection"},Rs.pcDefault={"Ctrl-A":"selectAll","Ctrl-D":"deleteLine","Ctrl-Z":"undo","Shift-Ctrl-Z":"redo","Ctrl-Y":"redo","Ctrl-Home":"goDocStart","Ctrl-End":"goDocEnd","Ctrl-Up":"goLineUp","Ctrl-Down":"goLineDown","Ctrl-Left":"goGroupLeft","Ctrl-Right":"goGroupRight","Alt-Left":"goLineStart","Alt-Right":"goLineEnd","Ctrl-Backspace":"delGroupBefore","Ctrl-Delete":"delGroupAfter","Ctrl-S":"save","Ctrl-F":"find","Ctrl-G":"findNext","Shift-Ctrl-G":"findPrev","Shift-Ctrl-F":"replace","Shift-Ctrl-R":"replaceAll","Ctrl-[":"indentLess","Ctrl-]":"indentMore","Ctrl-U":"undoSelection","Shift-Ctrl-U":"redoSelection","Alt-U":"redoSelection",fallthrough:"basic"},Rs.emacsy={"Ctrl-F":"goCharRight","Ctrl-B":"goCharLeft","Ctrl-P":"goLineUp","Ctrl-N":"goLineDown","Alt-F":"goWordRight","Alt-B":"goWordLeft","Ctrl-A":"goLineStart","Ctrl-E":"goLineEnd","Ctrl-V":"goPageDown","Shift-Ctrl-V":"goPageUp","Ctrl-D":"delCharAfter","Ctrl-H":"delCharBefore","Alt-D":"delWordAfter","Alt-Backspace":"delWordBefore","Ctrl-K":"killLine","Ctrl-T":"transposeChars","Ctrl-O":"openLine"},Rs.macDefault={"Cmd-A":"selectAll","Cmd-D":"deleteLine","Cmd-Z":"undo","Shift-Cmd-Z":"redo","Cmd-Y":"redo","Cmd-Home":"goDocStart","Cmd-Up":"goDocStart","Cmd-End":"goDocEnd","Cmd-Down":"goDocEnd","Alt-Left":"goGroupLeft","Alt-Right":"goGroupRight","Cmd-Left":"goLineLeft","Cmd-Right":"goLineRight","Alt-Backspace":"delGroupBefore","Ctrl-Alt-Backspace":"delGroupAfter","Alt-Delete":"delGroupAfter","Cmd-S":"save","Cmd-F":"find","Cmd-G":"findNext","Shift-Cmd-G":"findPrev","Cmd-Alt-F":"replace","Shift-Cmd-Alt-F":"replaceAll","Cmd-[":"indentLess","Cmd-]":"indentMore","Cmd-Backspace":"delWrappedLineLeft","Cmd-Delete":"delWrappedLineRight","Cmd-U":"undoSelection","Shift-Cmd-U":"redoSelection","Ctrl-Up":"goDocStart","Ctrl-Down":"goDocEnd",fallthrough:["basic","emacsy"]},Rs.default=Ml?Rs.macDefault:Rs.pcDefault;var Bs={selectAll:Mi,singleSelection:function(e){return e.setSelection(e.getCursor("anchor"),e.getCursor("head"),Gl)},killLine:function(e){return co(e,function(t){if(t.empty()){var r=M(e.doc,t.head.line).text.length;return t.head.ch==r&&t.head.line<e.lastLine()?{from:t.head,to:E(t.head.line+1,0)}:{from:t.head,to:E(t.head.line,r)}}return{from:t.from(),to:t.to()}})},deleteLine:function(e){return co(e,function(t){return{from:E(t.from().line,0),to:U(e.doc,E(t.to().line+1,0))}})},delLineLeft:function(e){return co(e,function(e){return{from:E(e.from().line,0),to:e.from()}})},delWrappedLineLeft:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5;return{from:e.coordsChar({left:0,top:r},"div"),to:t.from()}})},delWrappedLineRight:function(e){return co(e,function(t){var r=e.charCoords(t.head,"div").top+5,n=e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div");return{from:t.from(),to:n}})},undo:function(e){return e.undo()},redo:function(e){return e.redo()},undoSelection:function(e){return e.undoSelection()},redoSelection:function(e){return e.redoSelection()},goDocStart:function(e){return e.extendSelection(E(e.firstLine(),0))},goDocEnd:function(e){return e.extendSelection(E(e.lastLine()))},goLineStart:function(e){return e.extendSelectionsBy(function(t){return vo(e,t.head.line)},{origin:"+move",bias:1})},goLineStartSmart:function(e){return e.extendSelectionsBy(function(t){return yo(e,t.head)},{origin:"+move",bias:1})},goLineEnd:function(e){return e.extendSelectionsBy(function(t){return mo(e,t.head.line)},{origin:"+move",bias:-1})},goLineRight:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:e.display.lineDiv.offsetWidth+100,top:r},"div")},Vl)},goLineLeft:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5;return e.coordsChar({left:0,top:r},"div")},Vl)},goLineLeftSmart:function(e){return e.extendSelectionsBy(function(t){var r=e.cursorCoords(t.head,"div").top+5,n=e.coordsChar({left:0,top:r},"div");return n.ch<e.getLine(n.line).search(/\S/)?yo(e,t.head):n},Vl)},goLineUp:function(e){return e.moveV(-1,"line")},goLineDown:function(e){return e.moveV(1,"line")},goPageUp:function(e){return e.moveV(-1,"page")},goPageDown:function(e){return e.moveV(1,"page")},goCharLeft:function(e){return e.moveH(-1,"char")},goCharRight:function(e){return e.moveH(1,"char")},goColumnLeft:function(e){return e.moveH(-1,"column")},goColumnRight:function(e){return e.moveH(1,"column")},goWordLeft:function(e){return e.moveH(-1,"word")},goGroupRight:function(e){return e.moveH(1,"group")},goGroupLeft:function(e){return e.moveH(-1,"group")},goWordRight:function(e){return e.moveH(1,"word")},delCharBefore:function(e){return e.deleteH(-1,"char")},delCharAfter:function(e){return e.deleteH(1,"char")},delWordBefore:function(e){return e.deleteH(-1,"word")},delWordAfter:function(e){return e.deleteH(1,"word")},delGroupBefore:function(e){return e.deleteH(-1,"group")},delGroupAfter:function(e){return e.deleteH(1,"group")},indentAuto:function(e){return e.indentSelection("smart")},indentMore:function(e){return e.indentSelection("add")},indentLess:function(e){return e.indentSelection("subtract")},insertTab:function(e){return e.replaceSelection("\t")},insertSoftTab:function(e){for(var t=[],r=e.listSelections(),n=e.options.tabSize,i=0;i<r.length;i++){var o=r[i].from(),l=f(e.getLine(o.line),o.ch,n);t.push(p(n-l%n))}e.replaceSelections(t)},defaultTab:function(e){e.somethingSelected()?e.indentSelection("add"):e.execCommand("insertTab")},transposeChars:function(e){return hn(e,function(){for(var t=e.listSelections(),r=[],n=0;n<t.length;n++)if(t[n].empty()){var i=t[n].head,o=M(e.doc,i.line).text;if(o)if(i.ch==o.length&&(i=new E(i.line,i.ch-1)),i.ch>0)i=new E(i.line,i.ch+1),e.replaceRange(o.charAt(i.ch-1)+o.charAt(i.ch-2),E(i.line,i.ch-2),i,"+transpose");else if(i.line>e.doc.first){var l=M(e.doc,i.line-1).text;l&&(i=new E(i.line,1),e.replaceRange(o.charAt(0)+e.doc.lineSeparator()+l.charAt(l.length-1),E(i.line-1,l.length-1),i,"+transpose"))}r.push(new Ts(i,i))}e.setSelections(r)})},newlineAndIndent:function(e){return hn(e,function(){for(var t=e.listSelections(),r=t.length-1;r>=0;r--)e.replaceRange(e.doc.lineSeparator(),t[r].anchor,t[r].head,"+input");t=e.listSelections();for(var n=0;n<t.length;n++)e.indentLine(t[n].from().line,null,!0);jr(e)})},openLine:function(e){return e.replaceSelection("\n","start")},toggleOverwrite:function(e){return e.toggleOverwrite()}},Gs=new Pl,Us=null,Vs=function(e,t,r){this.time=e,this.pos=t,this.button=r};Vs.prototype.compare=function(e,t,r){return this.time+400>e&&0==P(t,this.pos)&&r==this.button};var Ks,js,Xs={toString:function(){return"CodeMirror.Init"}},Ys={},_s={};jo.defaults=Ys,jo.optionHandlers=_s;var $s=[];jo.defineInitHook=function(e){return $s.push(e)};var qs=null,Zs=function(e){this.cm=e,this.lastAnchorNode=this.lastAnchorOffset=this.lastFocusNode=this.lastFocusOffset=null,this.polling=new Pl,this.composing=null,this.gracePeriod=!1,this.readDOMTimeout=null};Zs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()}),"cut"==e.type&&i.replaceSelection("",null,"cut");else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type&&i.operation(function(){i.setSelections(t.ranges,0,Gl),i.replaceSelection("",null,"cut")})}if(e.clipboardData){e.clipboardData.clearData();var r=qs.text.join("\n");if(e.clipboardData.setData("Text",r),e.clipboardData.getData("Text")==r)return void e.preventDefault()}var l=el(),s=l.firstChild;i.display.lineSpace.insertBefore(l,i.display.lineSpace.firstChild),s.value=qs.text.join("\n");var a=document.activeElement;El(s),setTimeout(function(){i.display.lineSpace.removeChild(l),a.focus(),a==o&&n.showPrimarySelection()},50)}}var r=this,n=this,i=n.cm,o=n.div=e.lineDiv;Jo(o,i.options.spellcheck),Ql(o,"paste",function(e){Me(i,e)||qo(e,i)||vl<=11&&setTimeout(dn(i,function(){return r.updateFromDOM()}),20)}),Ql(o,"compositionstart",function(e){r.composing={data:e.data,done:!1}}),Ql(o,"compositionupdate",function(e){r.composing||(r.composing={data:e.data,done:!1})}),Ql(o,"compositionend",function(e){r.composing&&(e.data!=r.composing.data&&r.readFromDOMSoon(),r.composing.done=!0)}),Ql(o,"touchstart",function(){return n.forceCompositionEnd()}),Ql(o,"input",function(){r.composing||r.readFromDOMSoon()}),Ql(o,"copy",t),Ql(o,"cut",t)},Zs.prototype.prepareSelection=function(){var e=Tr(this.cm,!1);return e.focus=this.cm.state.focused,e},Zs.prototype.showSelection=function(e,t){e&&this.cm.display.view.length&&((e.focus||t)&&this.showPrimarySelection(),this.showMultipleSelections(e))},Zs.prototype.showPrimarySelection=function(){var e=window.getSelection(),t=this.cm,r=t.doc.sel.primary(),n=r.from(),i=r.to();if(t.display.viewTo==t.display.viewFrom||n.line>=t.display.viewTo||i.line<t.display.viewFrom)e.removeAllRanges();else{var o=sl(t,e.anchorNode,e.anchorOffset),l=sl(t,e.focusNode,e.focusOffset);if(!o||o.bad||!l||l.bad||0!=P(B(o,l),n)||0!=P(R(o,l),i)){var s=t.display.view,a=n.line>=t.display.viewFrom&&nl(t,n)||{node:s[0].measure.map[2],offset:0},u=i.line<t.display.viewTo&&nl(t,i);if(!u){var c=s[s.length-1].measure,f=c.maps?c.maps[c.maps.length-1]:c.map;u={node:f[f.length-1],offset:f[f.length-2]-f[f.length-3]}}if(a&&u){var h,d=e.rangeCount&&e.getRangeAt(0);try{h=Wl(a.node,a.offset,u.offset,u.node)}catch(e){}h&&(!fl&&t.state.focused?(e.collapse(a.node,a.offset),h.collapsed||(e.removeAllRanges(),e.addRange(h))):(e.removeAllRanges(),e.addRange(h)),d&&null==e.anchorNode?e.addRange(d):fl&&this.startGracePeriod()),this.rememberSelection()}else e.removeAllRanges()}}},Zs.prototype.startGracePeriod=function(){var e=this;clearTimeout(this.gracePeriod),this.gracePeriod=setTimeout(function(){e.gracePeriod=!1,e.selectionChanged()&&e.cm.operation(function(){return e.cm.curOp.selectionChanged=!0})},20)},Zs.prototype.showMultipleSelections=function(e){r(this.cm.display.cursorDiv,e.cursors),r(this.cm.display.selectionDiv,e.selection)},Zs.prototype.rememberSelection=function(){var e=window.getSelection();this.lastAnchorNode=e.anchorNode,this.lastAnchorOffset=e.anchorOffset,this.lastFocusNode=e.focusNode,this.lastFocusOffset=e.focusOffset},Zs.prototype.selectionInEditor=function(){var e=window.getSelection();if(!e.rangeCount)return!1;var t=e.getRangeAt(0).commonAncestorContainer;return o(this.div,t)},Zs.prototype.focus=function(){"nocursor"!=this.cm.options.readOnly&&(this.selectionInEditor()||this.showSelection(this.prepareSelection(),!0),this.div.focus())},Zs.prototype.blur=function(){this.div.blur()},Zs.prototype.getField=function(){return this.div},Zs.prototype.supportsTouch=function(){return!0},Zs.prototype.receivedFocus=function(){function e(){t.cm.state.focused&&(t.pollSelection(),t.polling.set(t.cm.options.pollInterval,e))}var t=this;this.selectionInEditor()?this.pollSelection():hn(this.cm,function(){return t.cm.curOp.selectionChanged=!0}),this.polling.set(this.cm.options.pollInterval,e)},Zs.prototype.selectionChanged=function(){var e=window.getSelection();return e.anchorNode!=this.lastAnchorNode||e.anchorOffset!=this.lastAnchorOffset||e.focusNode!=this.lastFocusNode||e.focusOffset!=this.lastFocusOffset},Zs.prototype.pollSelection=function(){if(null==this.readDOMTimeout&&!this.gracePeriod&&this.selectionChanged()){var e=window.getSelection(),t=this.cm;if(kl&&bl&&this.cm.options.gutters.length&&il(e.anchorNode))return this.cm.triggerOnKeyDown({type:"keydown",keyCode:8,preventDefault:Math.abs}),this.blur(),void this.focus();if(!this.composing){this.rememberSelection();var r=sl(t,e.anchorNode,e.anchorOffset),n=sl(t,e.focusNode,e.focusOffset);r&&n&&hn(t,function(){bi(t.doc,Rn(r,n),Gl),(r.bad||n.bad)&&(t.curOp.selectionChanged=!0)})}}},Zs.prototype.pollContent=function(){null!=this.readDOMTimeout&&(clearTimeout(this.readDOMTimeout),this.readDOMTimeout=null);var e=this.cm,t=e.display,r=e.doc.sel.primary(),n=r.from(),i=r.to();if(0==n.ch&&n.line>e.firstLine()&&(n=E(n.line-1,M(e.doc,n.line-1).length)),i.ch==M(e.doc,i.line).text.length&&i.line<e.lastLine()&&(i=E(i.line+1,0)),n.line<t.viewFrom||i.line>t.viewTo-1)return!1;var o,l,s;n.line==t.viewFrom||0==(o=Lr(e,n.line))?(l=W(t.view[0].line),s=t.view[0].node):(l=W(t.view[o].line),s=t.view[o-1].node.nextSibling);var a,u,c=Lr(e,i.line);if(c==t.view.length-1?(a=t.viewTo-1,u=t.lineDiv.lastChild):(a=W(t.view[c+1].line)-1,u=t.view[c+1].node.previousSibling),!s)return!1;for(var f=e.doc.splitLines(ll(e,s,u,l,a)),h=N(e.doc,E(l,0),E(a,M(e.doc,a).text.length));f.length>1&&h.length>1;)if(g(f)==g(h))f.pop(),h.pop(),a--;else{if(f[0]!=h[0])break;f.shift(),h.shift(),l++}for(var d=0,p=0,v=f[0],m=h[0],y=Math.min(v.length,m.length);d<y&&v.charCodeAt(d)==m.charCodeAt(d);)++d;for(var b=g(f),w=g(h),x=Math.min(b.length-(1==f.length?d:0),w.length-(1==h.length?d:0));p<x&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)++p;if(1==f.length&&1==h.length&&l==n.line)for(;d&&d>n.ch&&b.charCodeAt(b.length-p-1)==w.charCodeAt(w.length-p-1);)d--,p++;f[f.length-1]=b.slice(0,b.length-p).replace(/^\u200b+/,""),f[0]=f[0].slice(d).replace(/\u200b+$/,"");var C=E(l,d),S=E(a,h.length?g(h).length-p:0);return f.length>1||f[0]||P(C,S)?(Ei(e.doc,f,C,S,"+input"),!0):void 0},Zs.prototype.ensurePolled=function(){this.forceCompositionEnd()},Zs.prototype.reset=function(){this.forceCompositionEnd()},Zs.prototype.forceCompositionEnd=function(){this.composing&&(clearTimeout(this.readDOMTimeout),this.composing=null,this.updateFromDOM(),this.div.blur(),this.div.focus())},Zs.prototype.readFromDOMSoon=function(){var e=this;null==this.readDOMTimeout&&(this.readDOMTimeout=setTimeout(function(){if(e.readDOMTimeout=null,e.composing){if(!e.composing.done)return;e.composing=null}e.updateFromDOM()},80))},Zs.prototype.updateFromDOM=function(){var e=this;!this.cm.isReadOnly()&&this.pollContent()||hn(this.cm,function(){return vn(e.cm)})},Zs.prototype.setUneditable=function(e){e.contentEditable="false"},Zs.prototype.onKeyPress=function(e){0!=e.charCode&&(e.preventDefault(),this.cm.isReadOnly()||dn(this.cm,$o)(this.cm,String.fromCharCode(null==e.charCode?e.keyCode:e.charCode),0))},Zs.prototype.readOnlyChanged=function(e){this.div.contentEditable=String("nocursor"!=e)},Zs.prototype.onContextMenu=function(){},Zs.prototype.resetPosition=function(){},Zs.prototype.needsContentAttribute=!0;var Qs=function(e){this.cm=e,this.prevInput="",this.pollingFast=!1,this.polling=new Pl,this.hasSelection=!1,this.composing=null};Qs.prototype.init=function(e){function t(e){if(!Me(i,e)){if(i.somethingSelected())_o({lineWise:!1,text:i.getSelections()});else{if(!i.options.lineWiseCopyCut)return;var t=Qo(i);_o({lineWise:!0,text:t.text}),"cut"==e.type?i.setSelections(t.ranges,null,Gl):(n.prevInput="",l.value=t.text.join("\n"),El(l))}"cut"==e.type&&(i.state.cutIncoming=!0)}}var r=this,n=this,i=this.cm,o=this.wrapper=el(),l=this.textarea=o.firstChild;e.wrapper.insertBefore(o,e.wrapper.firstChild),Ll&&(l.style.width="0px"),Ql(l,"input",function(){gl&&vl>=9&&r.hasSelection&&(r.hasSelection=null),n.poll()}),Ql(l,"paste",function(e){Me(i,e)||qo(e,i)||(i.state.pasteIncoming=!0,n.fastPoll())}),Ql(l,"cut",t),Ql(l,"copy",t),Ql(e.scroller,"paste",function(t){Ft(e,t)||Me(i,t)||(i.state.pasteIncoming=!0,n.focus())}),Ql(e.lineSpace,"selectstart",function(t){Ft(e,t)||We(t)}),Ql(l,"compositionstart",function(){var e=i.getCursor("from");n.composing&&n.composing.range.clear(),n.composing={start:e,range:i.markText(e,i.getCursor("to"),{className:"CodeMirror-composing"})}}),Ql(l,"compositionend",function(){n.composing&&(n.poll(),n.composing.range.clear(),n.composing=null)})},Qs.prototype.prepareSelection=function(){var e=this.cm,t=e.display,r=e.doc,n=Tr(e);if(e.options.moveInputWithCursor){var i=sr(e,r.sel.primary().head,"div"),o=t.wrapper.getBoundingClientRect(),l=t.lineDiv.getBoundingClientRect();n.teTop=Math.max(0,Math.min(t.wrapper.clientHeight-10,i.top+l.top-o.top)),n.teLeft=Math.max(0,Math.min(t.wrapper.clientWidth-10,i.left+l.left-o.left))}return n},Qs.prototype.showSelection=function(e){var t=this.cm.display;r(t.cursorDiv,e.cursors),r(t.selectionDiv,e.selection),null!=e.teTop&&(this.wrapper.style.top=e.teTop+"px",this.wrapper.style.left=e.teLeft+"px")},Qs.prototype.reset=function(e){if(!this.contextMenuPending&&!this.composing){var t=this.cm;if(t.somethingSelected()){this.prevInput="";var r=t.getSelection();this.textarea.value=r,t.state.focused&&El(this.textarea),gl&&vl>=9&&(this.hasSelection=r)}else e||(this.prevInput=this.textarea.value="",gl&&vl>=9&&(this.hasSelection=null))}},Qs.prototype.getField=function(){return this.textarea},Qs.prototype.supportsTouch=function(){return!1},Qs.prototype.focus=function(){if("nocursor"!=this.cm.options.readOnly&&(!Tl||l()!=this.textarea))try{this.textarea.focus()}catch(e){}},Qs.prototype.blur=function(){this.textarea.blur()},Qs.prototype.resetPosition=function(){this.wrapper.style.top=this.wrapper.style.left=0},Qs.prototype.receivedFocus=function(){this.slowPoll()},Qs.prototype.slowPoll=function(){var e=this;this.pollingFast||this.polling.set(this.cm.options.pollInterval,function(){e.poll(),e.cm.state.focused&&e.slowPoll()})},Qs.prototype.fastPoll=function(){function e(){r.poll()||t?(r.pollingFast=!1,r.slowPoll()):(t=!0,r.polling.set(60,e))}var t=!1,r=this;r.pollingFast=!0,r.polling.set(20,e)},Qs.prototype.poll=function(){var e=this,t=this.cm,r=this.textarea,n=this.prevInput;if(this.contextMenuPending||!t.state.focused||ts(r)&&!n&&!this.composing||t.isReadOnly()||t.options.disableInput||t.state.keySeq)return!1;var i=r.value;if(i==n&&!t.somethingSelected())return!1;if(gl&&vl>=9&&this.hasSelection===i||Ml&&/[\uf700-\uf7ff]/.test(i))return t.display.input.reset(),!1;if(t.doc.sel==t.display.selForContextMenu){var o=i.charCodeAt(0);if(8203!=o||n||(n="​"),8666==o)return this.reset(),this.cm.execCommand("undo")}for(var l=0,s=Math.min(n.length,i.length);l<s&&n.charCodeAt(l)==i.charCodeAt(l);)++l;return hn(t,function(){$o(t,i.slice(l),n.length-l,null,e.composing?"*compose":null),i.length>1e3||i.indexOf("\n")>-1?r.value=e.prevInput="":e.prevInput=i,e.composing&&(e.composing.range.clear(),e.composing.range=t.markText(e.composing.start,t.getCursor("to"),{className:"CodeMirror-composing"}))}),!0},Qs.prototype.ensurePolled=function(){this.pollingFast&&this.poll()&&(this.pollingFast=!1)},Qs.prototype.onKeyPress=function(){gl&&vl>=9&&(this.hasSelection=null),this.fastPoll()},Qs.prototype.onContextMenu=function(e){function t(){if(null!=l.selectionStart){var e=i.somethingSelected(),t="​"+(e?l.value:"");l.value="⇚",l.value=t,n.prevInput=e?"":"​",l.selectionStart=1,l.selectionEnd=t.length,o.selForContextMenu=i.doc.sel}}function r(){if(n.contextMenuPending=!1,n.wrapper.style.cssText=c,l.style.cssText=u,gl&&vl<9&&o.scrollbars.setScrollTop(o.scroller.scrollTop=a),null!=l.selectionStart){(!gl||gl&&vl<9)&&t();var e=0,r=function(){o.selForContextMenu==i.doc.sel&&0==l.selectionStart&&l.selectionEnd>0&&"​"==n.prevInput?dn(i,Mi)(i):e++<10?o.detectingSelectAll=setTimeout(r,500):(o.selForContextMenu=null,o.input.reset())};o.detectingSelectAll=setTimeout(r,200)}}var n=this,i=n.cm,o=i.display,l=n.textarea,s=Sr(i,e),a=o.scroller.scrollTop;if(s&&!wl){i.options.resetSelectionOnContextMenu&&-1==i.doc.sel.contains(s)&&dn(i,bi)(i.doc,Rn(s),Gl);var u=l.style.cssText,c=n.wrapper.style.cssText;n.wrapper.style.cssText="position: absolute";var f=n.wrapper.getBoundingClientRect();l.style.cssText="position: absolute; width: 30px; height: 30px;\n      top: "+(e.clientY-f.top-5)+"px; left: "+(e.clientX-f.left-5)+"px;\n      z-index: 1000; background: "+(gl?"rgba(255, 255, 255, .05)":"transparent")+";\n      outline: none; border-width: 0; outline: none; overflow: hidden; opacity: .05; filter: alpha(opacity=5);";var h;if(ml&&(h=window.scrollY),o.input.focus(),ml&&window.scrollTo(null,h),o.input.reset(),i.somethingSelected()||(l.value=n.prevInput=" "),n.contextMenuPending=!0,o.selForContextMenu=i.doc.sel,clearTimeout(o.detectingSelectAll),gl&&vl>=9&&t(),Hl){Fe(e);var d=function(){ke(window,"mouseup",d),setTimeout(r,20)};Ql(window,"mouseup",d)}else setTimeout(r,50)}},Qs.prototype.readOnlyChanged=function(e){e||this.reset(),this.textarea.disabled="nocursor"==e},Qs.prototype.setUneditable=function(){},Qs.prototype.needsContentAttribute=!1,function(e){function t(t,n,i,o){e.defaults[t]=n,i&&(r[t]=o?function(e,t,r){r!=Xs&&i(e,t,r)}:i)}var r=e.optionHandlers;e.defineOption=t,e.Init=Xs,t("value","",function(e,t){return e.setValue(t)},!0),t("mode",null,function(e,t){e.doc.modeOption=t,jn(e)},!0),t("indentUnit",2,jn,!0),t("indentWithTabs",!1),t("smartIndent",!0),t("tabSize",4,function(e){Xn(e),er(e),vn(e)},!0),t("lineSeparator",null,function(e,t){if(e.doc.lineSep=t,t){var r=[],n=e.doc.first;e.doc.iter(function(e){for(var i=0;;){var o=e.text.indexOf(t,i);if(-1==o)break;i=o+t.length,r.push(E(n,o))}n++});for(var i=r.length-1;i>=0;i--)Ei(e.doc,t,r[i],E(r[i].line,r[i].ch+t.length))}}),t("specialChars",/[\u0000-\u001f\u007f-\u009f\u00ad\u061c\u200b-\u200f\u2028\u2029\ufeff]/g,function(e,t,r){e.state.specialChars=new RegExp(t.source+(t.test("\t")?"":"|\t"),"g"),r!=Xs&&e.refresh()}),t("specialCharPlaceholder",at,function(e){return e.refresh()},!0),t("electricChars",!0),t("inputStyle",Tl?"contenteditable":"textarea",function(){throw new Error("inputStyle can not (yet) be changed in a running editor")},!0),t("spellcheck",!1,function(e,t){return e.getInputField().spellcheck=t},!0),t("rtlMoveVisually",!Ol),t("wholeLineUpdateBefore",!0),t("theme","default",function(e){Go(e),Uo(e)},!0),t("keyMap","default",function(e,t,r){var n=uo(t),i=r!=Xs&&uo(r);i&&i.detach&&i.detach(e,n),n.attach&&n.attach(e,i||null)}),t("extraKeys",null),t("configureMouse",null),t("lineWrapping",!1,Ko,!0),t("gutters",[],function(e){Fn(e.options),Uo(e)},!0),t("fixedGutter",!0,function(e,t){e.display.gutters.style.left=t?wr(e.display)+"px":"0",e.refresh()},!0),t("coverGutterNextToScrollbar",!1,function(e){return en(e)},!0),t("scrollbarStyle","native",function(e){rn(e),en(e),e.display.scrollbars.setScrollTop(e.doc.scrollTop),e.display.scrollbars.setScrollLeft(e.doc.scrollLeft)},!0),t("lineNumbers",!1,function(e){Fn(e.options),Uo(e)},!0),t("firstLineNumber",1,Uo,!0),t("lineNumberFormatter",function(e){return e},Uo,!0),t("showCursorWhenSelecting",!1,kr,!0),t("resetSelectionOnContextMenu",!0),t("lineWiseCopyCut",!0),t("pasteLinesPerSelection",!0),t("readOnly",!1,function(e,t){"nocursor"==t&&(Fr(e),e.display.input.blur()),e.display.input.readOnlyChanged(t)}),t("disableInput",!1,function(e,t){t||e.display.input.reset()},!0),t("dragDrop",!0,Vo),t("allowDropFileTypes",null),t("cursorBlinkRate",530),t("cursorScrollMargin",0),t("cursorHeight",1,kr,!0),t("singleCursorHeightPerLine",!0,kr,!0),t("workTime",100),t("workDelay",100),t("flattenSpans",!0,Xn,!0),t("addModeClass",!1,Xn,!0),t("pollInterval",100),t("undoDepth",200,function(e,t){return e.doc.history.undoDepth=t}),t("historyEventDelay",1250),t("viewportMargin",10,function(e){return e.refresh()},!0),t("maxHighlightLength",1e4,Xn,!0),t("moveInputWithCursor",!0,function(e,t){t||e.display.input.resetPosition()}),t("tabindex",null,function(e,t){return e.display.input.getField().tabIndex=t||""}),t("autofocus",null),t("direction","ltr",function(e,t){return e.doc.setDirection(t)},!0)}(jo),function(e){var t=e.optionHandlers,r=e.helpers={};e.prototype={constructor:e,focus:function(){window.focus(),this.display.input.focus()},setOption:function(e,r){var n=this.options,i=n[e];n[e]==r&&"mode"!=e||(n[e]=r,t.hasOwnProperty(e)&&dn(this,t[e])(this,r,i),Te(this,"optionChange",this,e))},getOption:function(e){return this.options[e]},getDoc:function(){return this.doc},addKeyMap:function(e,t){this.state.keyMaps[t?"push":"unshift"](uo(e))},removeKeyMap:function(e){for(var t=this.state.keyMaps,r=0;r<t.length;++r)if(t[r]==e||t[r].name==e)return t.splice(r,1),!0},addOverlay:pn(function(t,r){var n=t.token?t:e.getMode(this.options,t);if(n.startState)throw new Error("Overlays may not be stateful.");m(this.state.overlays,{mode:n,modeSpec:t,opaque:r&&r.opaque,priority:r&&r.priority||0},function(e){return e.priority}),this.state.modeGen++,vn(this)}),removeOverlay:pn(function(e){for(var t=this,r=this.state.overlays,n=0;n<r.length;++n){var i=r[n].modeSpec;if(i==e||"string"==typeof e&&i.name==e)return r.splice(n,1),t.state.modeGen++,void vn(t)}}),indentLine:pn(function(e,t,r){"string"!=typeof t&&"number"!=typeof t&&(t=null==t?this.options.smartIndent?"smart":"prev":t?"add":"subtract"),H(this.doc,e)&&Yo(this,e,t,r)}),indentSelection:pn(function(e){for(var t=this,r=this.doc.sel.ranges,n=-1,i=0;i<r.length;i++){var o=r[i];if(o.empty())o.head.line>n&&(Yo(t,o.head.line,e,!0),n=o.head.line,i==t.doc.sel.primIndex&&jr(t));else{var l=o.from(),s=o.to(),a=Math.max(n,l.line);n=Math.min(t.lastLine(),s.line-(s.ch?0:1))+1;for(var u=a;u<n;++u)Yo(t,u,e);var c=t.doc.sel.ranges;0==l.ch&&r.length==c.length&&c[i].from().ch>0&&gi(t.doc,i,new Ts(l,c[i].to()),Gl)}}}),getTokenAt:function(e,t){return Je(this,e,t)},getLineTokens:function(e,t){return Je(this,E(e),t,!0)},getTokenTypeAt:function(e){e=U(this.doc,e);var t,r=_e(this,M(this.doc,e.line)),n=0,i=(r.length-1)/2,o=e.ch;if(0==o)t=r[2];else for(;;){var l=n+i>>1;if((l?r[2*l-1]:0)>=o)i=l;else{if(!(r[2*l+1]<o)){t=r[2*l+2];break}n=l+1}}var s=t?t.indexOf("overlay "):-1;return s<0?t:0==s?null:t.slice(0,s-1)},getModeAt:function(t){var r=this.doc.mode;return r.innerMode?e.innerMode(r,this.getTokenAt(t).state).mode:r},getHelper:function(e,t){return this.getHelpers(e,t)[0]},getHelpers:function(e,t){var n=this,i=[];if(!r.hasOwnProperty(t))return i;var o=r[t],l=this.getModeAt(e);if("string"==typeof l[t])o[l[t]]&&i.push(o[l[t]]);else if(l[t])for(var s=0;s<l[t].length;s++){var a=o[l[t][s]];a&&i.push(a)}else l.helperType&&o[l.helperType]?i.push(o[l.helperType]):o[l.name]&&i.push(o[l.name]);for(var u=0;u<o._global.length;u++){var c=o._global[u];c.pred(l,n)&&-1==h(i,c.val)&&i.push(c.val)}return i},getStateAfter:function(e,t){var r=this.doc;return e=G(r,null==e?r.first+r.size-1:e),$e(this,e+1,t).state},cursorCoords:function(e,t){var r,n=this.doc.sel.primary();return r=null==e?n.head:"object"==typeof e?U(this.doc,e):e?n.from():n.to(),sr(this,r,t||"page")},charCoords:function(e,t){return lr(this,U(this.doc,e),t||"page")},coordsChar:function(e,t){return e=or(this,e,t||"page"),cr(this,e.left,e.top)},lineAtHeight:function(e,t){return e=or(this,{top:e,left:0},t||"page").top,D(this.doc,e+this.display.viewOffset)},heightAtLine:function(e,t,r){var n,i=!1;if("number"==typeof e){var o=this.doc.first+this.doc.size-1;e<this.doc.first?e=this.doc.first:e>o&&(e=o,i=!0),n=M(this.doc,e)}else n=e;return ir(this,n,{top:0,left:0},t||"page",r||i).top+(i?this.doc.height-ye(n):0)},defaultTextHeight:function(){return mr(this.display)},defaultCharWidth:function(){return yr(this.display)},getViewport:function(){return{from:this.display.viewFrom,to:this.display.viewTo}},addWidget:function(e,t,r,n,i){var o=this.display,l=(e=sr(this,U(this.doc,e))).bottom,s=e.left;if(t.style.position="absolute",t.setAttribute("cm-ignore-events","true"),this.display.input.setUneditable(t),o.sizer.appendChild(t),"over"==n)l=e.top;else if("above"==n||"near"==n){var a=Math.max(o.wrapper.clientHeight,this.doc.height),u=Math.max(o.sizer.clientWidth,o.lineSpace.clientWidth);("above"==n||e.bottom+t.offsetHeight>a)&&e.top>t.offsetHeight?l=e.top-t.offsetHeight:e.bottom+t.offsetHeight<=a&&(l=e.bottom),s+t.offsetWidth>u&&(s=u-t.offsetWidth)}t.style.top=l+"px",t.style.left=t.style.right="","right"==i?(s=o.sizer.clientWidth-t.offsetWidth,t.style.right="0px"):("left"==i?s=0:"middle"==i&&(s=(o.sizer.clientWidth-t.offsetWidth)/2),t.style.left=s+"px"),r&&Ur(this,{left:s,top:l,right:s+t.offsetWidth,bottom:l+t.offsetHeight})},triggerOnKeyDown:pn(Lo),triggerOnKeyPress:pn(Mo),triggerOnKeyUp:To,triggerOnMouseDown:pn(Oo),execCommand:function(e){if(Bs.hasOwnProperty(e))return Bs[e].call(null,this)},triggerElectric:pn(function(e){Zo(this,e)}),findPosH:function(e,t,r,n){var i=this,o=1;t<0&&(o=-1,t=-t);for(var l=U(this.doc,e),s=0;s<t&&!(l=tl(i.doc,l,o,r,n)).hitSide;++s);return l},moveH:pn(function(e,t){var r=this;this.extendSelectionsBy(function(n){return r.display.shift||r.doc.extend||n.empty()?tl(r.doc,n.head,e,t,r.options.rtlMoveVisually):e<0?n.from():n.to()},Vl)}),deleteH:pn(function(e,t){var r=this.doc.sel,n=this.doc;r.somethingSelected()?n.replaceSelection("",null,"+delete"):co(this,function(r){var i=tl(n,r.head,e,t,!1);return e<0?{from:i,to:r.head}:{from:r.head,to:i}})}),findPosV:function(e,t,r,n){var i=this,o=1,l=n;t<0&&(o=-1,t=-t);for(var s=U(this.doc,e),a=0;a<t;++a){var u=sr(i,s,"div");if(null==l?l=u.left:u.left=l,(s=rl(i,u,o,r)).hitSide)break}return s},moveV:pn(function(e,t){var r=this,n=this.doc,i=[],o=!this.display.shift&&!n.extend&&n.sel.somethingSelected();if(n.extendSelectionsBy(function(l){if(o)return e<0?l.from():l.to();var s=sr(r,l.head,"div");null!=l.goalColumn&&(s.left=l.goalColumn),i.push(s.left);var a=rl(r,s,e,t);return"page"==t&&l==n.sel.primary()&&Kr(r,lr(r,a,"div").top-s.top),a},Vl),i.length)for(var l=0;l<n.sel.ranges.length;l++)n.sel.ranges[l].goalColumn=i[l]}),findWordAt:function(e){var t=M(this.doc,e.line).text,r=e.ch,n=e.ch;if(t){var i=this.getHelper(e,"wordChars");"before"!=e.sticky&&n!=t.length||!r?++n:--r;for(var o=t.charAt(r),l=x(o,i)?function(e){return x(e,i)}:/\s/.test(o)?function(e){return/\s/.test(e)}:function(e){return!/\s/.test(e)&&!x(e)};r>0&&l(t.charAt(r-1));)--r;for(;n<t.length&&l(t.charAt(n));)++n}return new Ts(E(e.line,r),E(e.line,n))},toggleOverwrite:function(e){null!=e&&e==this.state.overwrite||((this.state.overwrite=!this.state.overwrite)?s(this.display.cursorDiv,"CodeMirror-overwrite"):Fl(this.display.cursorDiv,"CodeMirror-overwrite"),Te(this,"overwriteToggle",this,this.state.overwrite))},hasFocus:function(){return this.display.input.getField()==l()},isReadOnly:function(){return!(!this.options.readOnly&&!this.doc.cantEdit)},scrollTo:pn(function(e,t){Xr(this,e,t)}),getScrollInfo:function(){var e=this.display.scroller;return{left:e.scrollLeft,top:e.scrollTop,height:e.scrollHeight-zt(this)-this.display.barHeight,width:e.scrollWidth-zt(this)-this.display.barWidth,clientHeight:Bt(this),clientWidth:Rt(this)}},scrollIntoView:pn(function(e,t){null==e?(e={from:this.doc.sel.primary().head,to:null},null==t&&(t=this.options.cursorScrollMargin)):"number"==typeof e?e={from:E(e,0),to:null}:null==e.from&&(e={from:e,to:null}),e.to||(e.to=e.from),e.margin=t||0,null!=e.from.line?Yr(this,e):$r(this,e.from,e.to,e.margin)}),setSize:pn(function(e,t){var r=this,n=function(e){return"number"==typeof e||/^\d+$/.test(String(e))?e+"px":e};null!=e&&(this.display.wrapper.style.width=n(e)),null!=t&&(this.display.wrapper.style.height=n(t)),this.options.lineWrapping&&Jt(this);var i=this.display.viewFrom;this.doc.iter(i,this.display.viewTo,function(e){if(e.widgets)for(var t=0;t<e.widgets.length;t++)if(e.widgets[t].noHScroll){mn(r,i,"widget");break}++i}),this.curOp.forceUpdate=!0,Te(this,"refresh",this)}),operation:function(e){return hn(this,e)},startOperation:function(){return nn(this)},endOperation:function(){return on(this)},refresh:pn(function(){var e=this.display.cachedTextHeight;vn(this),this.curOp.forceUpdate=!0,er(this),Xr(this,this.doc.scrollLeft,this.doc.scrollTop),Wn(this),(null==e||Math.abs(e-mr(this.display))>.5)&&Cr(this),Te(this,"refresh",this)}),swapDoc:pn(function(e){var t=this.doc;return t.cm=null,qn(this,e),er(this),this.display.input.reset(),Xr(this,e.scrollLeft,e.scrollTop),this.curOp.forceScroll=!0,bt(this,"swapDoc",this,t),t}),getInputField:function(){return this.display.input.getField()},getWrapperElement:function(){return this.display.wrapper},getScrollerElement:function(){return this.display.scroller},getGutterElement:function(){return this.display.gutters}},Ae(e),e.registerHelper=function(t,n,i){r.hasOwnProperty(t)||(r[t]=e[t]={_global:[]}),r[t][n]=i},e.registerGlobalHelper=function(t,n,i,o){e.registerHelper(t,n,o),r[t]._global.push({pred:i,val:o})}}(jo);var Js="iter insert remove copy getEditor constructor".split(" ");for(var ea in Ds.prototype)Ds.prototype.hasOwnProperty(ea)&&h(Js,ea)<0&&(jo.prototype[ea]=function(e){return function(){return e.apply(this.doc,arguments)}}(Ds.prototype[ea]));return Ae(Ds),jo.inputStyles={textarea:Qs,contenteditable:Zs},jo.defineMode=function(e){jo.defaults.mode||"null"==e||(jo.defaults.mode=e),Be.apply(this,arguments)},jo.defineMIME=function(e,t){os[e]=t},jo.defineMode("null",function(){return{token:function(e){return e.skipToEnd()}}}),jo.defineMIME("text/plain","null"),jo.defineExtension=function(e,t){jo.prototype[e]=t},jo.defineDocExtension=function(e,t){Ds.prototype[e]=t},jo.fromTextArea=function(e,t){function r(){e.value=a.getValue()}if(t=t?c(t):{},t.value=e.value,!t.tabindex&&e.tabIndex&&(t.tabindex=e.tabIndex),!t.placeholder&&e.placeholder&&(t.placeholder=e.placeholder),null==t.autofocus){var n=l();t.autofocus=n==e||null!=e.getAttribute("autofocus")&&n==document.body}var i;if(e.form&&(Ql(e.form,"submit",r),!t.leaveSubmitMethodAlone)){var o=e.form;i=o.submit;try{var s=o.submit=function(){r(),o.submit=i,o.submit(),o.submit=s}}catch(e){}}t.finishInit=function(t){t.save=r,t.getTextArea=function(){return e},t.toTextArea=function(){t.toTextArea=isNaN,r(),e.parentNode.removeChild(t.getWrapperElement()),e.style.display="",e.form&&(ke(e.form,"submit",r),"function"==typeof e.form.submit&&(e.form.submit=i))}},e.style.display="none";var a=jo(function(t){return e.parentNode.insertBefore(t,e.nextSibling)},t);return a},function(e){e.off=ke,e.on=Ql,e.wheelEventPixels=Pn,e.Doc=Ds,e.splitLines=es,e.countColumn=f,e.findColumn=d,e.isWordChar=w,e.Pass=Bl,e.signal=Te,e.Line=fs,e.changeEnd=Bn,e.scrollbarModel=ws,e.Pos=E,e.cmpPos=P,e.modes=is,e.mimeModes=os,e.resolveMode=Ge,e.getMode=Ue,e.modeExtensions=ls,e.extendMode=Ve,e.copyState=Ke,e.startState=Xe,e.innerMode=je,e.commands=Bs,e.keyMap=Rs,e.keyName=ao,e.isModifierKey=lo,e.lookupKey=oo,e.normalizeKeyMap=io,e.StringStream=ss,e.SharedTextMarker=As,e.TextMarker=Os,e.LineWidget=Ms,e.e_preventDefault=We,e.e_stopPropagation=De,e.e_stop=Fe,e.addClass=s,e.contains=o,e.rmClass=Fl,e.keyNames=Es}(jo),jo.version="5.30.0",jo});
      !function(e){"object"==typeof exports&&"object"==typeof module?e(require("../../lib/codemirror")):"function"==typeof define&&define.amd?define(["../../lib/codemirror"],e):e(CodeMirror)}(function(e){"use strict";function t(e,t,n,r,o,a){this.indented=e,this.column=t,this.type=n,this.info=r,this.align=o,this.prev=a}function n(e,n,r,o){var a=e.indented;return e.context&&"statement"==e.context.type&&"statement"!=r&&(a=e.context.indented),e.context=new t(a,n,r,o,null,e.context)}function r(e){var t=e.context.type;return")"!=t&&"]"!=t&&"}"!=t||(e.indented=e.context.indented),e.context=e.context.prev}function o(e,t,n){return"variable"==t.prevToken||"type"==t.prevToken||(!!/\S(?:[^- ]>|[*\]])\s*$|\*$/.test(e.string.slice(0,n))||(!(!t.typeAtEndOfLine||e.column()!=e.indentation())||void 0))}function a(e){for(;;){if(!e||"top"==e.type)return!0;if("}"==e.type&&"namespace"!=e.prev.info)return!1;e=e.prev}}function i(e){for(var t={},n=e.split(" "),r=0;r<n.length;++r)t[n[r]]=!0;return t}function l(e,t){return"function"==typeof e?e(t):e.propertyIsEnumerable(t)}function s(e,t){if(!t.startOfLine)return!1;for(var n,r=null;n=e.peek();){if("\\"==n&&e.match(/^.$/)){r=s;break}if("/"==n&&e.match(/^\/[\/\*]/,!1))break;e.next()}return t.tokenize=r,"meta"}function c(e,t){return"type"==t.prevToken&&"type"}function u(e){return e.eatWhile(/[\w\.']/),"number"}function d(e,t){if(e.backUp(1),e.match(/(R|u8R|uR|UR|LR)/)){var n=e.match(/"([^\s\\()]{0,16})\(/);return!!n&&(t.cpp11RawStringDelim=n[1],t.tokenize=m,m(e,t))}return e.match(/(u8|u|U|L)/)?!!e.match(/["']/,!1)&&"string":(e.next(),!1)}function f(e){var t=/(\w+)::~?(\w+)$/.exec(e);return t&&t[1]==t[2]}function p(e,t){for(var n;null!=(n=e.next());)if('"'==n&&!e.eat('"')){t.tokenize=null;break}return"string"}function m(e,t){var n=t.cpp11RawStringDelim.replace(/[^\w\s]/g,"\\$&");return e.match(new RegExp(".*?\\)"+n+'"'))?t.tokenize=null:e.skipToEnd(),"string"}function h(t,n){function r(e){if(e)for(var t in e)e.hasOwnProperty(t)&&o.push(t)}"string"==typeof t&&(t=[t]);var o=[];r(n.keywords),r(n.types),r(n.builtin),r(n.atoms),o.length&&(n.helperType=t[0],e.registerHelper("hintWords",t[0],o));for(var a=0;a<t.length;++a)e.defineMIME(t[a],n)}function g(e,t){for(var n=!1;!e.eol();){if(!n&&e.match('"""')){t.tokenize=null;break}n="\\"==e.next()&&!n}return"string"}function y(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!e&&!o&&t.match('"')){a=!0;break}if(e&&t.match('"""')){a=!0;break}r=t.next(),!o&&"$"==r&&t.match("{")&&t.skipTo("}"),o=!o&&"\\"==r&&!e}return!a&&e||(n.tokenize=null),"string"}}function x(e){return function(t,n){for(var r,o=!1,a=!1;!t.eol();){if(!o&&t.match('"')&&("single"==e||t.match('""'))){a=!0;break}if(!o&&t.match("``")){w=x(e),a=!0;break}r=t.next(),o="single"==e&&!o&&"\\"==r}return a&&(n.tokenize=null),"string"}}e.defineMode("clike",function(i,s){function c(e,t){var n=e.next();if(S[n]){var r=S[n](e,t);if(!1!==r)return r}if('"'==n||"'"==n)return t.tokenize=u(n),t.tokenize(e,t);if(D.test(n))return p=n,null;if(L.test(n)){if(e.backUp(1),e.match(I))return"number";e.next()}if("/"==n){if(e.eat("*"))return t.tokenize=d,d(e,t);if(e.eat("/"))return e.skipToEnd(),"comment"}if(F.test(n)){for(;!e.match(/^\/[\/*]/,!1)&&e.eat(F););return"operator"}if(e.eatWhile(z),P)for(;e.match(P);)e.eatWhile(z);var o=e.current();return l(x,o)?(l(w,o)&&(p="newstatement"),l(v,o)&&(m=!0),"keyword"):l(b,o)?"type":l(k,o)?(l(w,o)&&(p="newstatement"),"builtin"):l(_,o)?"atom":"variable"}function u(e){return function(t,n){for(var r,o=!1,a=!1;null!=(r=t.next());){if(r==e&&!o){a=!0;break}o=!o&&"\\"==r}return(a||!o&&!C)&&(n.tokenize=null),"string"}}function d(e,t){for(var n,r=!1;n=e.next();){if("/"==n&&r){t.tokenize=null;break}r="*"==n}return"comment"}function f(e,t){s.typeFirstDefinitions&&e.eol()&&a(t.context)&&(t.typeAtEndOfLine=o(e,t,e.pos))}var p,m,h=i.indentUnit,g=s.statementIndentUnit||h,y=s.dontAlignCalls,x=s.keywords||{},b=s.types||{},k=s.builtin||{},w=s.blockKeywords||{},v=s.defKeywords||{},_=s.atoms||{},S=s.hooks||{},C=s.multiLineStrings,T=!1!==s.indentStatements,M=!1!==s.indentSwitch,P=s.namespaceSeparator,D=s.isPunctuationChar||/[\[\]{}\(\),;\:\.]/,L=s.numberStart||/[\d\.]/,I=s.number||/^(?:0x[a-f\d]+|0b[01]+|(?:\d+\.?\d*|\.\d+)(?:e[-+]?\d+)?)(u|ll?|l|f)?/i,F=s.isOperatorChar||/[+\-*&%=<>!?|\/]/,z=s.isIdentifierChar||/[\w\$_\xa1-\uffff]/;return{startState:function(e){return{tokenize:null,context:new t((e||0)-h,0,"top",null,!1),indented:0,startOfLine:!0,prevToken:null}},token:function(e,t){var i=t.context;if(e.sol()&&(null==i.align&&(i.align=!1),t.indented=e.indentation(),t.startOfLine=!0),e.eatSpace())return f(e,t),null;p=m=null;var l=(t.tokenize||c)(e,t);if("comment"==l||"meta"==l)return l;if(null==i.align&&(i.align=!0),";"==p||":"==p||","==p&&e.match(/^\s*(?:\/\/.*)?$/,!1))for(;"statement"==t.context.type;)r(t);else if("{"==p)n(t,e.column(),"}");else if("["==p)n(t,e.column(),"]");else if("("==p)n(t,e.column(),")");else if("}"==p){for(;"statement"==i.type;)i=r(t);for("}"==i.type&&(i=r(t));"statement"==i.type;)i=r(t)}else p==i.type?r(t):T&&(("}"==i.type||"top"==i.type)&&";"!=p||"statement"==i.type&&"newstatement"==p)&&n(t,e.column(),"statement",e.current());if("variable"==l&&("def"==t.prevToken||s.typeFirstDefinitions&&o(e,t,e.start)&&a(t.context)&&e.match(/^\s*\(/,!1))&&(l="def"),S.token){var u=S.token(e,t,l);void 0!==u&&(l=u)}return"def"==l&&!1===s.styleDefs&&(l="variable"),t.startOfLine=!1,t.prevToken=m?"def":l||p,f(e,t),l},indent:function(t,n){if(t.tokenize!=c&&null!=t.tokenize||t.typeAtEndOfLine)return e.Pass;var r=t.context,o=n&&n.charAt(0);if("statement"==r.type&&"}"==o&&(r=r.prev),s.dontIndentStatements)for(;"statement"==r.type&&s.dontIndentStatements.test(r.info);)r=r.prev;if(S.indent){var a=S.indent(t,r,n);if("number"==typeof a)return a}var i=o==r.type,l=r.prev&&"switch"==r.prev.info;if(s.allmanIndentation&&/[{(]/.test(o)){for(;"top"!=r.type&&"}"!=r.type;)r=r.prev;return r.indented}return"statement"==r.type?r.indented+("{"==o?0:g):!r.align||y&&")"==r.type?")"!=r.type||i?r.indented+(i?0:h)+(i||!l||/^(?:case|default)\b/.test(n)?0:h):r.indented+g:r.column+(i?0:1)},electricInput:M?/^\s*(?:case .*?:|default:|\{\}?|\})$/:/^\s*[{}]$/,blockCommentStart:"/*",blockCommentEnd:"*/",lineComment:"//",fold:"brace"}});var b="auto if break case register continue return default do sizeof static else struct switch extern typedef union for goto while enum const volatile",k="int long char short double float unsigned signed void size_t ptrdiff_t";h(["text/x-csrc","text/x-c","text/x-chdr"],{name:"clike",keywords:i(b),types:i(k+" bool _Complex _Bool float_t double_t intptr_t intmax_t int8_t int16_t int32_t int64_t uintptr_t uintmax_t uint8_t uint16_t uint32_t uint64_t"),blockKeywords:i("case do else for if switch while struct"),defKeywords:i("struct"),typeFirstDefinitions:!0,atoms:i("null true false"),hooks:{"#":s,"*":c},modeProps:{fold:["brace","include"]}}),h(["text/x-c++src","text/x-c++hdr"],{name:"clike",keywords:i(b+" asm dynamic_cast namespace reinterpret_cast try explicit new static_cast typeid catch operator template typename class friend private this using const_cast inline public throw virtual delete mutable protected alignas alignof constexpr decltype nullptr noexcept thread_local final static_assert override"),types:i(k+" bool wchar_t"),blockKeywords:i("catch class do else finally for if struct switch try while"),defKeywords:i("class namespace struct enum union"),typeFirstDefinitions:!0,atoms:i("true false null"),dontIndentStatements:/^template$/,isIdentifierChar:/[\w\$_~\xa1-\uffff]/,hooks:{"#":s,"*":c,u:d,U:d,L:d,R:d,0:u,1:u,2:u,3:u,4:u,5:u,6:u,7:u,8:u,9:u,token:function(e,t,n){if("variable"==n&&"("==e.peek()&&(";"==t.prevToken||null==t.prevToken||"}"==t.prevToken)&&f(e.current()))return"def"}},namespaceSeparator:"::",modeProps:{fold:["brace","include"]}}),h("text/x-java",{name:"clike",keywords:i("abstract assert break case catch class const continue default do else enum extends final finally float for goto if implements import instanceof interface native new package private protected public return static strictfp super switch synchronized this throw throws transient try volatile while @interface"),types:i("byte short int long float double boolean char void Boolean Byte Character Double Float Integer Long Number Object Short String StringBuffer StringBuilder Void"),blockKeywords:i("catch class do else finally for if switch try while"),defKeywords:i("class interface package enum @interface"),typeFirstDefinitions:!0,atoms:i("true false null"),number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,hooks:{"@":function(e){return!e.match("interface",!1)&&(e.eatWhile(/[\w\$_]/),"meta")}},modeProps:{fold:["brace","import"]}}),h("text/x-csharp",{name:"clike",keywords:i("abstract as async await base break case catch checked class const continue default delegate do else enum event explicit extern finally fixed for foreach goto if implicit in interface internal is lock namespace new operator out override params private protected public readonly ref return sealed sizeof stackalloc static struct switch this throw try typeof unchecked unsafe using virtual void volatile while add alias ascending descending dynamic from get global group into join let orderby partial remove select set value var yield"),types:i("Action Boolean Byte Char DateTime DateTimeOffset Decimal Double Func Guid Int16 Int32 Int64 Object SByte Single String Task TimeSpan UInt16 UInt32 UInt64 bool byte char decimal double short int long object sbyte float string ushort uint ulong"),blockKeywords:i("catch class do else finally for foreach if struct switch try while"),defKeywords:i("class interface namespace struct var"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"@":function(e,t){return e.eat('"')?(t.tokenize=p,p(e,t)):(e.eatWhile(/[\w\$_]/),"meta")}}}),h("text/x-scala",{name:"clike",keywords:i("abstract case catch class def do else extends final finally for forSome if implicit import lazy match new null object override package private protected return sealed super this throw trait try type val var while with yield _ assert assume require print println printf readLine readBoolean readByte readShort readChar readInt readLong readFloat readDouble"),types:i("AnyVal App Application Array BufferedIterator BigDecimal BigInt Char Console Either Enumeration Equiv Error Exception Fractional Function IndexedSeq Int Integral Iterable Iterator List Map Numeric Nil NotNull Option Ordered Ordering PartialFunction PartialOrdering Product Proxy Range Responder Seq Serializable Set Specializable Stream StringBuilder StringContext Symbol Throwable Traversable TraversableOnce Tuple Unit Vector Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),multiLineStrings:!0,blockKeywords:i("catch class enum do else finally for forSome if match switch try while"),defKeywords:i("class enum def object package trait type val var"),atoms:i("true false null"),indentStatements:!1,indentSwitch:!1,isOperatorChar:/[+\-*&%=<>!?|\/#:@]/,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return!!e.match('""')&&(t.tokenize=g,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},"=":function(e,n){var r=n.context;return!("}"!=r.type||!r.align||!e.eat(">"))&&(n.context=new t(r.indented,r.column,r.type,r.info,null,r.prev),"operator")}},modeProps:{closeBrackets:{triples:'"'}}}),h("text/x-kotlin",{name:"clike",keywords:i("package as typealias class interface this super val var fun for is in This throw return break continue object if else while do try when !in !is as? file import where by get set abstract enum open inner override private public internal protected catch finally out final vararg reified dynamic companion constructor init sealed field property receiver param sparam lateinit data inline noinline tailrec external annotation crossinline const operator infix suspend"),types:i("Boolean Byte Character CharSequence Class ClassLoader Cloneable Comparable Compiler Double Exception Float Integer Long Math Number Object Package Pair Process Runtime Runnable SecurityManager Short StackTraceElement StrictMath String StringBuffer System Thread ThreadGroup ThreadLocal Throwable Triple Void"),intendSwitch:!1,indentStatements:!1,multiLineStrings:!0,number:/^(?:0x[a-f\d_]+|0b[01_]+|(?:[\d_]+\.?\d*|\.\d+)(?:e[-+]?[\d_]+)?)(u|ll?|l|f)?/i,blockKeywords:i("catch class do else finally for if where try while enum"),defKeywords:i("class val var object package interface fun"),atoms:i("true false null this"),hooks:{'"':function(e,t){return t.tokenize=y(e.match('""')),t.tokenize(e,t)}},modeProps:{closeBrackets:{triples:'"'}}}),h(["x-shader/x-vertex","x-shader/x-fragment"],{name:"clike",keywords:i("sampler1D sampler2D sampler3D samplerCube sampler1DShadow sampler2DShadow const attribute uniform varying break continue discard return for while do if else struct in out inout"),types:i("float int bool void vec2 vec3 vec4 ivec2 ivec3 ivec4 bvec2 bvec3 bvec4 mat2 mat3 mat4"),blockKeywords:i("for while do if else struct"),builtin:i("radians degrees sin cos tan asin acos atan pow exp log exp2 sqrt inversesqrt abs sign floor ceil fract mod min max clamp mix step smoothstep length distance dot cross normalize ftransform faceforward reflect refract matrixCompMult lessThan lessThanEqual greaterThan greaterThanEqual equal notEqual any all not texture1D texture1DProj texture1DLod texture1DProjLod texture2D texture2DProj texture2DLod texture2DProjLod texture3D texture3DProj texture3DLod texture3DProjLod textureCube textureCubeLod shadow1D shadow2D shadow1DProj shadow2DProj shadow1DLod shadow2DLod shadow1DProjLod shadow2DProjLod dFdx dFdy fwidth noise1 noise2 noise3 noise4"),atoms:i("true false gl_FragColor gl_SecondaryColor gl_Normal gl_Vertex gl_MultiTexCoord0 gl_MultiTexCoord1 gl_MultiTexCoord2 gl_MultiTexCoord3 gl_MultiTexCoord4 gl_MultiTexCoord5 gl_MultiTexCoord6 gl_MultiTexCoord7 gl_FogCoord gl_PointCoord gl_Position gl_PointSize gl_ClipVertex gl_FrontColor gl_BackColor gl_FrontSecondaryColor gl_BackSecondaryColor gl_TexCoord gl_FogFragCoord gl_FragCoord gl_FrontFacing gl_FragData gl_FragDepth gl_ModelViewMatrix gl_ProjectionMatrix gl_ModelViewProjectionMatrix gl_TextureMatrix gl_NormalMatrix gl_ModelViewMatrixInverse gl_ProjectionMatrixInverse gl_ModelViewProjectionMatrixInverse gl_TexureMatrixTranspose gl_ModelViewMatrixInverseTranspose gl_ProjectionMatrixInverseTranspose gl_ModelViewProjectionMatrixInverseTranspose gl_TextureMatrixInverseTranspose gl_NormalScale gl_DepthRange gl_ClipPlane gl_Point gl_FrontMaterial gl_BackMaterial gl_LightSource gl_LightModel gl_FrontLightModelProduct gl_BackLightModelProduct gl_TextureColor gl_EyePlaneS gl_EyePlaneT gl_EyePlaneR gl_EyePlaneQ gl_FogParameters gl_MaxLights gl_MaxClipPlanes gl_MaxTextureUnits gl_MaxTextureCoords gl_MaxVertexAttribs gl_MaxVertexUniformComponents gl_MaxVaryingFloats gl_MaxVertexTextureImageUnits gl_MaxTextureImageUnits gl_MaxFragmentUniformComponents gl_MaxCombineTextureImageUnits gl_MaxDrawBuffers"),indentSwitch:!1,hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-nesc",{name:"clike",keywords:i(b+"as atomic async call command component components configuration event generic implementation includes interface module new norace nx_struct nx_union post provides signal task uses abstract extends"),types:i(k),blockKeywords:i("case do else for if switch while struct"),atoms:i("null true false"),hooks:{"#":s},modeProps:{fold:["brace","include"]}}),h("text/x-objectivec",{name:"clike",keywords:i(b+"inline restrict _Bool _Complex _Imaginary BOOL Class bycopy byref id IMP in inout nil oneway out Protocol SEL self super atomic nonatomic retain copy readwrite readonly"),types:i(k),atoms:i("YES NO NULL NILL ON OFF true false"),hooks:{"@":function(e){return e.eatWhile(/[\w\$]/),"keyword"},"#":s,indent:function(e,t,n){if("statement"==t.type&&/^@\w/.test(n))return t.indented}},modeProps:{fold:"brace"}}),h("text/x-squirrel",{name:"clike",keywords:i("base break clone continue const default delete enum extends function in class foreach local resume return this throw typeof yield constructor instanceof static"),types:i(k),blockKeywords:i("case catch class else for foreach if switch try while"),defKeywords:i("function local class"),typeFirstDefinitions:!0,atoms:i("true false null"),hooks:{"#":s},modeProps:{fold:["brace","include"]}});var w=null;h("text/x-ceylon",{name:"clike",keywords:i("abstracts alias assembly assert assign break case catch class continue dynamic else exists extends finally for function given if import in interface is let module new nonempty object of out outer package return satisfies super switch then this throw try value void while"),types:function(e){var t=e.charAt(0);return t===t.toUpperCase()&&t!==t.toLowerCase()},blockKeywords:i("case catch class dynamic else finally for function if interface module new object switch try while"),defKeywords:i("class dynamic function interface module object package value"),builtin:i("abstract actual aliased annotation by default deprecated doc final formal late license native optional sealed see serializable shared suppressWarnings tagged throws variable"),isPunctuationChar:/[\[\]{}\(\),;\:\.`]/,isOperatorChar:/[+\-*&%=<>!?|^~:\/]/,numberStart:/[\d#$]/,number:/^(?:#[\da-fA-F_]+|\$[01_]+|[\d_]+[kMGTPmunpf]?|[\d_]+\.[\d_]+(?:[eE][-+]?\d+|[kMGTPmunpf]|)|)/i,multiLineStrings:!0,typeFirstDefinitions:!0,atoms:i("true false null larger smaller equal empty finished"),indentSwitch:!1,styleDefs:!1,hooks:{"@":function(e){return e.eatWhile(/[\w\$_]/),"meta"},'"':function(e,t){return t.tokenize=x(e.match('""')?"triple":"single"),t.tokenize(e,t)},"`":function(e,t){return!(!w||!e.match("`"))&&(t.tokenize=w,w=null,t.tokenize(e,t))},"'":function(e){return e.eatWhile(/[\w\$_\xa1-\uffff]/),"atom"},token:function(e,t,n){if(("variable"==n||"type"==n)&&"."==t.prevToken)return"variable-2"}},modeProps:{fold:["brace","import"],closeBrackets:{triples:'"'}}})});
      // -------------------------------------------------------------------------
//  Part of the CodeChecker project, under the Apache License v2.0 with
//  LLVM Exceptions. See LICENSE for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// -------------------------------------------------------------------------

var BugViewer = {
  _files : [],
  _reports : [],
  _lineWidgets : [],
  _navigationMenuItems : [],
  _sourceFileData : null,
  _currentReport : null,
  _lastBugEvent  : null,

  init : function (files, reports) {
    this._files = files;
    this._reports = reports;

    this.initEscapeChars();
  },

  initEscapeChars : function () {
    this.escapeChars = {
      ' ' : 'nbsp',
      '<' : 'lt',
      '>' : 'gt',
      '"' : 'quot',
      '&' : 'amp'
    };

    var regexString = '[';
    for (var key in this.escapeChars) {
      regexString += key;
    }
    regexString += ']';

    this.escapeRegExp = new RegExp( regexString, 'g');
  },

  escapeHTML : function (str) {
    var that = this;

    return str.replace(this.escapeRegExp, function (m) {
      return '&' + that.escapeChars[m] + ';';
    });
  },

  initByUrl : function () {
    if (!this._reports) return;

    var state = {};
    window.location.hash.substr(1).split('&').forEach(function (s) {
      var parts = s.split('=');
      state[parts[0]] = parts[1];
    });

    for (var key in this._reports) {
      var report = this._reports[key];
      if (report.reportHash === state['reportHash']) {
        this.navigate(report);
        return;
      }
    }

    this.navigate(this._reports[0]);
  },

  create : function () {
    this._content = document.getElementById('editor-wrapper');
    this._filepath = document.getElementById('file-path');
    this._checkerName = document.getElementById('checker-name');
    this._reviewStatusWrapper =
      document.getElementById('review-status-wrapper');
    this._reviewStatus = document.getElementById('review-status');
    this._editor = document.getElementById('editor');

    this._codeMirror = CodeMirror(this._editor, {
      mode: 'text/x-c++src',
      matchBrackets : true,
      lineNumbers : true,
      readOnly : true,
      foldGutter : true,
      extraKeys : {},
      viewportMargin : 100
    });

    this._createNavigationMenu();
  },

  navigate : function (report, item) {
    if (!item) {
      var items = this._navigationMenuItems.filter(function (navItem) {
        return navItem.report.reportHash === report.reportHash;
      });

      if (!items.length) return;

      item = items[0].widget;
    }

    this._selectedReport.classList.remove('active');
    this._selectedReport = item;
    this._selectedReport.classList.add('active');
    this.setReport(report);
  },

  _createNavigationMenu : function () {
    var that = this;

    var nav = document.getElementById('report-nav');
    var list = document.createElement('ul');
    this._reports.forEach(function (report) {
      var events = report['events'];
      var lastBugEvent = events[events.length - 1];
      var item = document.createElement('li');

      var severity = document.createElement('i');
      severity.className = 'severity-' + report.severity.toLowerCase();

      item.appendChild(severity);
      item.appendChild(document.createTextNode(lastBugEvent.message));

      item.addEventListener('click', function () {
        that.navigate(report, item);
      })
      list.appendChild(item);
      that._navigationMenuItems.push({ report : report, widget : item });
    });

    if (!this._selectedReport && list.childNodes.length) {
      this._selectedReport = list.childNodes[0];
      this._selectedReport.classList.add('active');
    }

    nav.appendChild(list);
  },

  setReport : function (report) {
    this._currentReport = report;
    var events = report['events'];
    var lastBugEvent = events[events.length - 1];
    this.setCurrentBugEvent(lastBugEvent, events.length - 1);
    this.setCheckerName(report.checkerName);
    this.setReviewStatus(report.reviewStatus);

    window.location.hash = '#reportHash=' + report.reportHash;
  },

  setCurrentBugEvent : function (event, idx) {
    this._currentBugEvent = event;
    this.setSourceFileData(this._files[event.location.file]);
    this.drawBugPath();

    this.jumpTo(event.location.line, 0);
    this.highlightBugEvent(event, idx);
  },

  highlightBugEvent : function (event, idx) {
    this._lineWidgets.forEach(function (widget) {
      var lineIdx = widget.node.getAttribute('idx');
      if (parseInt(lineIdx) === idx) {
        widget.node.classList.add('current');
      }
    });
  },

  setCheckerName : function (checkerName) {
    this._checkerName.innerHTML = checkerName;
  },

  setReviewStatus : function (status) {
    if (status) {
      var className =
        'review-status-' + status.toLowerCase().split(' ').join('-');
      this._reviewStatus.className = "review-status " + className;

      this._reviewStatus.innerHTML = status;
      this._reviewStatusWrapper.style.display = 'block';
    } else {
      this._reviewStatusWrapper.style.display = 'none';
    }
  },

  setSourceFileData : function (file) {
    if (this._sourceFileData && file.id === this._sourceFileData.id) {
      return;
    }

    this._sourceFileData = file;
    this._filepath.innerHTML = file.path;
    this._codeMirror.doc.setValue(file.content);
    this._refresh();
  },

  _refresh : function () {
    var that = this;
    setTimeout(function () {
      var fullHeight = parseInt(that._content.clientHeight);
      var headerHeight = that._filepath.clientHeight;

      that._codeMirror.setSize('auto', fullHeight - headerHeight);
      that._codeMirror.refresh();
    }, 200);
  },

  clearBubbles : function () {
    this._lineWidgets.forEach(function (widget) { widget.clear(); });
    this._lineWidgets = [];
  },

  getMessage : function (event, kind) {
    if (kind === 'macro') {
      var name = 'macro expansion' + (event.name ? ': ' + event.name : '');

      return '<span class="tag macro">' + name + '</span>'
        + this.escapeHTML(event.expansion).replace(/(?:\r\n|\r|\n)/g, '<br>');
    } else if (kind === 'note') {
      return '<span class="tag note">note</span>'
        +  this.escapeHTML(event.message).replace(/(?:\r\n|\r|\n)/g, '<br>');
    }
  },

  addExtraPathEvents : function (events, kind) {
    var that = this;

    if (!events) {
      return;
    }

    events.forEach(function (event) {
      if (event.location.file !== that._currentBugEvent.location.file) {
        return;
      }

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + kind);

      var msg = document.createElement('span');
      msg.innerHTML = that.getMessage(event, kind);
      element.appendChild(msg);

      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  drawBugPath : function () {
    var that = this;

    this.clearBubbles();

    this.addExtraPathEvents(this._currentReport.macros, 'macro');
    this.addExtraPathEvents(this._currentReport.notes, 'note');

    // Processing bug path events.
    var currentEvents = this._currentReport.events;
    currentEvents.forEach(function (event, step) {
      if (event.location.file !== that._currentBugEvent.location.file)
        return;

      var left =
        that._codeMirror.defaultCharWidth() * event.location.col + 'px';
      var type = step === currentEvents.length - 1 ? 'error' : 'info';

      var element = document.createElement('div');
      element.setAttribute('style', 'margin-left: ' + left);
      element.setAttribute('class', 'check-msg ' + type);
      element.setAttribute('idx', step);

      var enumeration = document.createElement('span');
      enumeration.setAttribute('class', 'checker-enum ' + type);
      enumeration.innerHTML = step + 1;

      if (currentEvents.length > 1)
        element.appendChild(enumeration);

      var prevBugEvent = step - 1;
      if (step > 0) {
        var prevBug = document.createElement('span');
        prevBug.setAttribute('class', 'arrow left-arrow');
        prevBug.addEventListener('click', function () {
          var event = currentEvents[prevBugEvent];
          that.setCurrentBugEvent(event, prevBugEvent);
        });
        element.appendChild(prevBug);
      }

      var msg = document.createElement('span');
      msg.innerHTML = that.escapeHTML(event.message)
        .replace(/(?:\r\n|\r|\n)/g, '<br>');

      element.appendChild(msg);

      var nextBugEvent = step + 1;
      if (nextBugEvent < currentEvents.length) {
        var nextBug = document.createElement('span');
        nextBug.setAttribute('class', 'arrow right-arrow');
        nextBug.addEventListener('click', function () {
          var event = currentEvents[nextBugEvent];
          that.setCurrentBugEvent(event, nextBugEvent);
        });
        element.appendChild(nextBug);
      }


      that._lineWidgets.push(that._codeMirror.addLineWidget(
        event.location.line - 1, element));
    });
  },

  jumpTo : function (line, column) {
    var that = this;

    setTimeout(function () {
      var selPosPixel
        = that._codeMirror.charCoords({ line : line, ch : column }, 'local');
      var editorSize = {
        width  : that._editor.clientWidth,
        height : that._editor.clientHeight
      };

      that._codeMirror.scrollIntoView({
        top    : selPosPixel.top - 100,
        bottom : selPosPixel.top + editorSize.height - 150,
        left   : selPosPixel.left < editorSize.width - 100
               ? 0
               : selPosPixel.left - 50,
        right  : selPosPixel.left < editorSize.width - 100
               ? 10
               : selPosPixel.left + editorSize.width - 100
      });
    }, 0);
  }
}


      var data = {"files": {"1": {"id": 1, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/ASTContext.h", "content": "//===- ASTContext.h - Context to hold long-lived AST nodes ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n/// \\file\n/// Defines the clang::ASTContext interface.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_ASTCONTEXT_H\n#define LLVM_CLANG_AST_ASTCONTEXT_H\n\n#include \"clang/AST/ASTContextAllocate.h\"\n#include \"clang/AST/ASTFwd.h\"\n#include \"clang/AST/CanonicalType.h\"\n#include \"clang/AST/CommentCommandTraits.h\"\n#include \"clang/AST/ComparisonCategories.h\"\n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/DeclBase.h\"\n#include \"clang/AST/DeclarationName.h\"\n#include \"clang/AST/ExternalASTSource.h\"\n#include \"clang/AST/NestedNameSpecifier.h\"\n#include \"clang/AST/PrettyPrinter.h\"\n#include \"clang/AST/RawCommentList.h\"\n#include \"clang/AST/TemplateName.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/AddressSpaces.h\"\n#include \"clang/Basic/AttrKinds.h\"\n#include \"clang/Basic/IdentifierTable.h\"\n#include \"clang/Basic/LLVM.h\"\n#include \"clang/Basic/LangOptions.h\"\n#include \"clang/Basic/Linkage.h\"\n#include \"clang/Basic/NoSanitizeList.h\"\n#include \"clang/Basic/OperatorKinds.h\"\n#include \"clang/Basic/PartialDiagnostic.h\"\n#include \"clang/Basic/ProfileList.h\"\n#include \"clang/Basic/SourceLocation.h\"\n#include \"clang/Basic/Specifiers.h\"\n#include \"clang/Basic/XRayLists.h\"\n#include \"llvm/ADT/APSInt.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/DenseSet.h\"\n#include \"llvm/ADT/FoldingSet.h\"\n#include \"llvm/ADT/IntrusiveRefCntPtr.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/None.h\"\n#include \"llvm/ADT/Optional.h\"\n#include \"llvm/ADT/PointerIntPair.h\"\n#include \"llvm/ADT/PointerUnion.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/ADT/StringMap.h\"\n#include \"llvm/ADT/StringRef.h\"\n#include \"llvm/ADT/TinyPtrVector.h\"\n#include \"llvm/ADT/Triple.h\"\n#include \"llvm/ADT/iterator_range.h\"\n#include \"llvm/Support/AlignOf.h\"\n#include \"llvm/Support/Allocator.h\"\n#include \"llvm/Support/Casting.h\"\n#include \"llvm/Support/Compiler.h\"\n#include \"llvm/Support/TypeSize.h\"\n#include <cassert>\n#include <cstddef>\n#include <cstdint>\n#include <iterator>\n#include <memory>\n#include <string>\n#include <type_traits>\n#include <utility>\n#include <vector>\n\nnamespace llvm {\n\nclass APFixedPoint;\nclass FixedPointSemantics;\nstruct fltSemantics;\ntemplate <typename T, unsigned N> class SmallPtrSet;\n\n} // namespace llvm\n\nnamespace clang {\n\nclass APValue;\nclass ASTMutationListener;\nclass ASTRecordLayout;\nclass AtomicExpr;\nclass BlockExpr;\nclass BuiltinTemplateDecl;\nclass CharUnits;\nclass ConceptDecl;\nclass CXXABI;\nclass CXXConstructorDecl;\nclass CXXMethodDecl;\nclass CXXRecordDecl;\nclass DiagnosticsEngine;\nclass ParentMapContext;\nclass DynTypedNode;\nclass DynTypedNodeList;\nclass Expr;\nclass GlobalDecl;\nclass MangleContext;\nclass MangleNumberingContext;\nclass MaterializeTemporaryExpr;\nclass MemberSpecializationInfo;\nclass Module;\nstruct MSGuidDeclParts;\nclass ObjCCategoryDecl;\nclass ObjCCategoryImplDecl;\nclass ObjCContainerDecl;\nclass ObjCImplDecl;\nclass ObjCImplementationDecl;\nclass ObjCInterfaceDecl;\nclass ObjCIvarDecl;\nclass ObjCMethodDecl;\nclass ObjCPropertyDecl;\nclass ObjCPropertyImplDecl;\nclass ObjCProtocolDecl;\nclass ObjCTypeParamDecl;\nclass OMPTraitInfo;\nstruct ParsedTargetAttr;\nclass Preprocessor;\nclass Stmt;\nclass StoredDeclsMap;\nclass TargetAttr;\nclass TargetInfo;\nclass TemplateDecl;\nclass TemplateParameterList;\nclass TemplateTemplateParmDecl;\nclass TemplateTypeParmDecl;\nclass UnresolvedSetIterator;\nclass UsingShadowDecl;\nclass VarTemplateDecl;\nclass VTableContextBase;\nstruct BlockVarCopyInit;\n\nnamespace Builtin {\n\nclass Context;\n\n} // namespace Builtin\n\nenum BuiltinTemplateKind : int;\nenum OpenCLTypeKind : uint8_t;\n\nnamespace comments {\n\nclass FullComment;\n\n} // namespace comments\n\nnamespace interp {\n\nclass Context;\n\n} // namespace interp\n\nnamespace serialization {\ntemplate <class> class AbstractTypeReader;\n} // namespace serialization\n\nstruct TypeInfo {\n  uint64_t Width = 0;\n  unsigned Align = 0;\n  bool AlignIsRequired : 1;\n\n  TypeInfo() : AlignIsRequired(false) {}\n  TypeInfo(uint64_t Width, unsigned Align, bool AlignIsRequired)\n      : Width(Width), Align(Align), AlignIsRequired(AlignIsRequired) {}\n};\n\nstruct TypeInfoChars {\n  CharUnits Width;\n  CharUnits Align;\n  bool AlignIsRequired : 1;\n\n  TypeInfoChars() : AlignIsRequired(false) {}\n  TypeInfoChars(CharUnits Width, CharUnits Align, bool AlignIsRequired)\n      : Width(Width), Align(Align), AlignIsRequired(AlignIsRequired) {}\n};\n\n/// Holds long-lived AST nodes (such as types and decls) that can be\n/// referred to throughout the semantic analysis of a file.\nclass ASTContext : public RefCountedBase<ASTContext> {\n  friend class NestedNameSpecifier;\n\n  mutable SmallVector<Type *, 0> Types;\n  mutable llvm::FoldingSet<ExtQuals> ExtQualNodes;\n  mutable llvm::FoldingSet<ComplexType> ComplexTypes;\n  mutable llvm::FoldingSet<PointerType> PointerTypes;\n  mutable llvm::FoldingSet<AdjustedType> AdjustedTypes;\n  mutable llvm::FoldingSet<BlockPointerType> BlockPointerTypes;\n  mutable llvm::FoldingSet<LValueReferenceType> LValueReferenceTypes;\n  mutable llvm::FoldingSet<RValueReferenceType> RValueReferenceTypes;\n  mutable llvm::FoldingSet<MemberPointerType> MemberPointerTypes;\n  mutable llvm::ContextualFoldingSet<ConstantArrayType, ASTContext &>\n      ConstantArrayTypes;\n  mutable llvm::FoldingSet<IncompleteArrayType> IncompleteArrayTypes;\n  mutable std::vector<VariableArrayType*> VariableArrayTypes;\n  mutable llvm::FoldingSet<DependentSizedArrayType> DependentSizedArrayTypes;\n  mutable llvm::FoldingSet<DependentSizedExtVectorType>\n    DependentSizedExtVectorTypes;\n  mutable llvm::FoldingSet<DependentAddressSpaceType>\n      DependentAddressSpaceTypes;\n  mutable llvm::FoldingSet<VectorType> VectorTypes;\n  mutable llvm::FoldingSet<DependentVectorType> DependentVectorTypes;\n  mutable llvm::FoldingSet<ConstantMatrixType> MatrixTypes;\n  mutable llvm::FoldingSet<DependentSizedMatrixType> DependentSizedMatrixTypes;\n  mutable llvm::FoldingSet<FunctionNoProtoType> FunctionNoProtoTypes;\n  mutable llvm::ContextualFoldingSet<FunctionProtoType, ASTContext&>\n    FunctionProtoTypes;\n  mutable llvm::FoldingSet<DependentTypeOfExprType> DependentTypeOfExprTypes;\n  mutable llvm::FoldingSet<DependentDecltypeType> DependentDecltypeTypes;\n  mutable llvm::FoldingSet<TemplateTypeParmType> TemplateTypeParmTypes;\n  mutable llvm::FoldingSet<ObjCTypeParamType> ObjCTypeParamTypes;\n  mutable llvm::FoldingSet<SubstTemplateTypeParmType>\n    SubstTemplateTypeParmTypes;\n  mutable llvm::FoldingSet<SubstTemplateTypeParmPackType>\n    SubstTemplateTypeParmPackTypes;\n  mutable llvm::ContextualFoldingSet<TemplateSpecializationType, ASTContext&>\n    TemplateSpecializationTypes;\n  mutable llvm::FoldingSet<ParenType> ParenTypes;\n  mutable llvm::FoldingSet<ElaboratedType> ElaboratedTypes;\n  mutable llvm::FoldingSet<DependentNameType> DependentNameTypes;\n  mutable llvm::ContextualFoldingSet<DependentTemplateSpecializationType,\n                                     ASTContext&>\n    DependentTemplateSpecializationTypes;\n  llvm::FoldingSet<PackExpansionType> PackExpansionTypes;\n  mutable llvm::FoldingSet<ObjCObjectTypeImpl> ObjCObjectTypes;\n  mutable llvm::FoldingSet<ObjCObjectPointerType> ObjCObjectPointerTypes;\n  mutable llvm::FoldingSet<DependentUnaryTransformType>\n    DependentUnaryTransformTypes;\n  mutable llvm::ContextualFoldingSet<AutoType, ASTContext&> AutoTypes;\n  mutable llvm::FoldingSet<DeducedTemplateSpecializationType>\n    DeducedTemplateSpecializationTypes;\n  mutable llvm::FoldingSet<AtomicType> AtomicTypes;\n  llvm::FoldingSet<AttributedType> AttributedTypes;\n  mutable llvm::FoldingSet<PipeType> PipeTypes;\n  mutable llvm::FoldingSet<ExtIntType> ExtIntTypes;\n  mutable llvm::FoldingSet<DependentExtIntType> DependentExtIntTypes;\n\n  mutable llvm::FoldingSet<QualifiedTemplateName> QualifiedTemplateNames;\n  mutable llvm::FoldingSet<DependentTemplateName> DependentTemplateNames;\n  mutable llvm::FoldingSet<SubstTemplateTemplateParmStorage>\n    SubstTemplateTemplateParms;\n  mutable llvm::ContextualFoldingSet<SubstTemplateTemplateParmPackStorage,\n                                     ASTContext&>\n    SubstTemplateTemplateParmPacks;\n\n  /// The set of nested name specifiers.\n  ///\n  /// This set is managed by the NestedNameSpecifier class.\n  mutable llvm::FoldingSet<NestedNameSpecifier> NestedNameSpecifiers;\n  mutable NestedNameSpecifier *GlobalNestedNameSpecifier = nullptr;\n\n  /// A cache mapping from RecordDecls to ASTRecordLayouts.\n  ///\n  /// This is lazily created.  This is intentionally not serialized.\n  mutable llvm::DenseMap<const RecordDecl*, const ASTRecordLayout*>\n    ASTRecordLayouts;\n  mutable llvm::DenseMap<const ObjCContainerDecl*, const ASTRecordLayout*>\n    ObjCLayouts;\n\n  /// A cache from types to size and alignment information.\n  using TypeInfoMap = llvm::DenseMap<const Type *, struct TypeInfo>;\n  mutable TypeInfoMap MemoizedTypeInfo;\n\n  /// A cache from types to unadjusted alignment information. Only ARM and\n  /// AArch64 targets need this information, keeping it separate prevents\n  /// imposing overhead on TypeInfo size.\n  using UnadjustedAlignMap = llvm::DenseMap<const Type *, unsigned>;\n  mutable UnadjustedAlignMap MemoizedUnadjustedAlign;\n\n  /// A cache mapping from CXXRecordDecls to key functions.\n  llvm::DenseMap<const CXXRecordDecl*, LazyDeclPtr> KeyFunctions;\n\n  /// Mapping from ObjCContainers to their ObjCImplementations.\n  llvm::DenseMap<ObjCContainerDecl*, ObjCImplDecl*> ObjCImpls;\n\n  /// Mapping from ObjCMethod to its duplicate declaration in the same\n  /// interface.\n  llvm::DenseMap<const ObjCMethodDecl*,const ObjCMethodDecl*> ObjCMethodRedecls;\n\n  /// Mapping from __block VarDecls to BlockVarCopyInit.\n  llvm::DenseMap<const VarDecl *, BlockVarCopyInit> BlockVarCopyInits;\n\n  /// Mapping from GUIDs to the corresponding MSGuidDecl.\n  mutable llvm::FoldingSet<MSGuidDecl> MSGuidDecls;\n\n  /// Mapping from APValues to the corresponding TemplateParamObjects.\n  mutable llvm::FoldingSet<TemplateParamObjectDecl> TemplateParamObjectDecls;\n\n  /// A cache mapping a string value to a StringLiteral object with the same\n  /// value.\n  ///\n  /// This is lazily created.  This is intentionally not serialized.\n  mutable llvm::StringMap<StringLiteral *> StringLiteralCache;\n\n  /// MD5 hash of CUID. It is calculated when first used and cached by this\n  /// data member.\n  mutable std::string CUIDHash;\n\n  /// Representation of a \"canonical\" template template parameter that\n  /// is used in canonical template names.\n  class CanonicalTemplateTemplateParm : public llvm::FoldingSetNode {\n    TemplateTemplateParmDecl *Parm;\n\n  public:\n    CanonicalTemplateTemplateParm(TemplateTemplateParmDecl *Parm)\n        : Parm(Parm) {}\n\n    TemplateTemplateParmDecl *getParam() const { return Parm; }\n\n    void Profile(llvm::FoldingSetNodeID &ID, const ASTContext &C) {\n      Profile(ID, C, Parm);\n    }\n\n    static void Profile(llvm::FoldingSetNodeID &ID,\n                        const ASTContext &C,\n                        TemplateTemplateParmDecl *Parm);\n  };\n  mutable llvm::ContextualFoldingSet<CanonicalTemplateTemplateParm,\n                                     const ASTContext&>\n    CanonTemplateTemplateParms;\n\n  TemplateTemplateParmDecl *\n    getCanonicalTemplateTemplateParmDecl(TemplateTemplateParmDecl *TTP) const;\n\n  /// The typedef for the __int128_t type.\n  mutable TypedefDecl *Int128Decl = nullptr;\n\n  /// The typedef for the __uint128_t type.\n  mutable TypedefDecl *UInt128Decl = nullptr;\n\n  /// The typedef for the target specific predefined\n  /// __builtin_va_list type.\n  mutable TypedefDecl *BuiltinVaListDecl = nullptr;\n\n  /// The typedef for the predefined \\c __builtin_ms_va_list type.\n  mutable TypedefDecl *BuiltinMSVaListDecl = nullptr;\n\n  /// The typedef for the predefined \\c id type.\n  mutable TypedefDecl *ObjCIdDecl = nullptr;\n\n  /// The typedef for the predefined \\c SEL type.\n  mutable TypedefDecl *ObjCSelDecl = nullptr;\n\n  /// The typedef for the predefined \\c Class type.\n  mutable TypedefDecl *ObjCClassDecl = nullptr;\n\n  /// The typedef for the predefined \\c Protocol class in Objective-C.\n  mutable ObjCInterfaceDecl *ObjCProtocolClassDecl = nullptr;\n\n  /// The typedef for the predefined 'BOOL' type.\n  mutable TypedefDecl *BOOLDecl = nullptr;\n\n  // Typedefs which may be provided defining the structure of Objective-C\n  // pseudo-builtins\n  QualType ObjCIdRedefinitionType;\n  QualType ObjCClassRedefinitionType;\n  QualType ObjCSelRedefinitionType;\n\n  /// The identifier 'bool'.\n  mutable IdentifierInfo *BoolName = nullptr;\n\n  /// The identifier 'NSObject'.\n  mutable IdentifierInfo *NSObjectName = nullptr;\n\n  /// The identifier 'NSCopying'.\n  IdentifierInfo *NSCopyingName = nullptr;\n\n  /// The identifier '__make_integer_seq'.\n  mutable IdentifierInfo *MakeIntegerSeqName = nullptr;\n\n  /// The identifier '__type_pack_element'.\n  mutable IdentifierInfo *TypePackElementName = nullptr;\n\n  QualType ObjCConstantStringType;\n  mutable RecordDecl *CFConstantStringTagDecl = nullptr;\n  mutable TypedefDecl *CFConstantStringTypeDecl = nullptr;\n\n  mutable QualType ObjCSuperType;\n\n  QualType ObjCNSStringType;\n\n  /// The typedef declaration for the Objective-C \"instancetype\" type.\n  TypedefDecl *ObjCInstanceTypeDecl = nullptr;\n\n  /// The type for the C FILE type.\n  TypeDecl *FILEDecl = nullptr;\n\n  /// The type for the C jmp_buf type.\n  TypeDecl *jmp_bufDecl = nullptr;\n\n  /// The type for the C sigjmp_buf type.\n  TypeDecl *sigjmp_bufDecl = nullptr;\n\n  /// The type for the C ucontext_t type.\n  TypeDecl *ucontext_tDecl = nullptr;\n\n  /// Type for the Block descriptor for Blocks CodeGen.\n  ///\n  /// Since this is only used for generation of debug info, it is not\n  /// serialized.\n  mutable RecordDecl *BlockDescriptorType = nullptr;\n\n  /// Type for the Block descriptor for Blocks CodeGen.\n  ///\n  /// Since this is only used for generation of debug info, it is not\n  /// serialized.\n  mutable RecordDecl *BlockDescriptorExtendedType = nullptr;\n\n  /// Declaration for the CUDA cudaConfigureCall function.\n  FunctionDecl *cudaConfigureCallDecl = nullptr;\n\n  /// Keeps track of all declaration attributes.\n  ///\n  /// Since so few decls have attrs, we keep them in a hash map instead of\n  /// wasting space in the Decl class.\n  llvm::DenseMap<const Decl*, AttrVec*> DeclAttrs;\n\n  /// A mapping from non-redeclarable declarations in modules that were\n  /// merged with other declarations to the canonical declaration that they were\n  /// merged into.\n  llvm::DenseMap<Decl*, Decl*> MergedDecls;\n\n  /// A mapping from a defining declaration to a list of modules (other\n  /// than the owning module of the declaration) that contain merged\n  /// definitions of that entity.\n  llvm::DenseMap<NamedDecl*, llvm::TinyPtrVector<Module*>> MergedDefModules;\n\n  /// Initializers for a module, in order. Each Decl will be either\n  /// something that has a semantic effect on startup (such as a variable with\n  /// a non-constant initializer), or an ImportDecl (which recursively triggers\n  /// initialization of another module).\n  struct PerModuleInitializers {\n    llvm::SmallVector<Decl*, 4> Initializers;\n    llvm::SmallVector<uint32_t, 4> LazyInitializers;\n\n    void resolve(ASTContext &Ctx);\n  };\n  llvm::DenseMap<Module*, PerModuleInitializers*> ModuleInitializers;\n\n  ASTContext &this_() { return *this; }\n\npublic:\n  /// A type synonym for the TemplateOrInstantiation mapping.\n  using TemplateOrSpecializationInfo =\n      llvm::PointerUnion<VarTemplateDecl *, MemberSpecializationInfo *>;\n\nprivate:\n  friend class ASTDeclReader;\n  friend class ASTReader;\n  friend class ASTWriter;\n  template <class> friend class serialization::AbstractTypeReader;\n  friend class CXXRecordDecl;\n\n  /// A mapping to contain the template or declaration that\n  /// a variable declaration describes or was instantiated from,\n  /// respectively.\n  ///\n  /// For non-templates, this value will be NULL. For variable\n  /// declarations that describe a variable template, this will be a\n  /// pointer to a VarTemplateDecl. For static data members\n  /// of class template specializations, this will be the\n  /// MemberSpecializationInfo referring to the member variable that was\n  /// instantiated or specialized. Thus, the mapping will keep track of\n  /// the static data member templates from which static data members of\n  /// class template specializations were instantiated.\n  ///\n  /// Given the following example:\n  ///\n  /// \\code\n  /// template<typename T>\n  /// struct X {\n  ///   static T value;\n  /// };\n  ///\n  /// template<typename T>\n  ///   T X<T>::value = T(17);\n  ///\n  /// int *x = &X<int>::value;\n  /// \\endcode\n  ///\n  /// This mapping will contain an entry that maps from the VarDecl for\n  /// X<int>::value to the corresponding VarDecl for X<T>::value (within the\n  /// class template X) and will be marked TSK_ImplicitInstantiation.\n  llvm::DenseMap<const VarDecl *, TemplateOrSpecializationInfo>\n  TemplateOrInstantiation;\n\n  /// Keeps track of the declaration from which a using declaration was\n  /// created during instantiation.\n  ///\n  /// The source and target declarations are always a UsingDecl, an\n  /// UnresolvedUsingValueDecl, or an UnresolvedUsingTypenameDecl.\n  ///\n  /// For example:\n  /// \\code\n  /// template<typename T>\n  /// struct A {\n  ///   void f();\n  /// };\n  ///\n  /// template<typename T>\n  /// struct B : A<T> {\n  ///   using A<T>::f;\n  /// };\n  ///\n  /// template struct B<int>;\n  /// \\endcode\n  ///\n  /// This mapping will contain an entry that maps from the UsingDecl in\n  /// B<int> to the UnresolvedUsingDecl in B<T>.\n  llvm::DenseMap<NamedDecl *, NamedDecl *> InstantiatedFromUsingDecl;\n\n  llvm::DenseMap<UsingShadowDecl*, UsingShadowDecl*>\n    InstantiatedFromUsingShadowDecl;\n\n  llvm::DenseMap<FieldDecl *, FieldDecl *> InstantiatedFromUnnamedFieldDecl;\n\n  /// Mapping that stores the methods overridden by a given C++\n  /// member function.\n  ///\n  /// Since most C++ member functions aren't virtual and therefore\n  /// don't override anything, we store the overridden functions in\n  /// this map on the side rather than within the CXXMethodDecl structure.\n  using CXXMethodVector = llvm::TinyPtrVector<const CXXMethodDecl *>;\n  llvm::DenseMap<const CXXMethodDecl *, CXXMethodVector> OverriddenMethods;\n\n  /// Mapping from each declaration context to its corresponding\n  /// mangling numbering context (used for constructs like lambdas which\n  /// need to be consistently numbered for the mangler).\n  llvm::DenseMap<const DeclContext *, std::unique_ptr<MangleNumberingContext>>\n      MangleNumberingContexts;\n  llvm::DenseMap<const Decl *, std::unique_ptr<MangleNumberingContext>>\n      ExtraMangleNumberingContexts;\n\n  /// Side-table of mangling numbers for declarations which rarely\n  /// need them (like static local vars).\n  llvm::MapVector<const NamedDecl *, unsigned> MangleNumbers;\n  llvm::MapVector<const VarDecl *, unsigned> StaticLocalNumbers;\n  /// Mapping the associated device lambda mangling number if present.\n  mutable llvm::DenseMap<const CXXRecordDecl *, unsigned>\n      DeviceLambdaManglingNumbers;\n\n  /// Mapping that stores parameterIndex values for ParmVarDecls when\n  /// that value exceeds the bitfield size of ParmVarDeclBits.ParameterIndex.\n  using ParameterIndexTable = llvm::DenseMap<const VarDecl *, unsigned>;\n  ParameterIndexTable ParamIndices;\n\n  ImportDecl *FirstLocalImport = nullptr;\n  ImportDecl *LastLocalImport = nullptr;\n\n  TranslationUnitDecl *TUDecl;\n  mutable ExternCContextDecl *ExternCContext = nullptr;\n  mutable BuiltinTemplateDecl *MakeIntegerSeqDecl = nullptr;\n  mutable BuiltinTemplateDecl *TypePackElementDecl = nullptr;\n\n  /// The associated SourceManager object.\n  SourceManager &SourceMgr;\n\n  /// The language options used to create the AST associated with\n  ///  this ASTContext object.\n  LangOptions &LangOpts;\n\n  /// NoSanitizeList object that is used by sanitizers to decide which\n  /// entities should not be instrumented.\n  std::unique_ptr<NoSanitizeList> NoSanitizeL;\n\n  /// Function filtering mechanism to determine whether a given function\n  /// should be imbued with the XRay \"always\" or \"never\" attributes.\n  std::unique_ptr<XRayFunctionFilter> XRayFilter;\n\n  /// ProfileList object that is used by the profile instrumentation\n  /// to decide which entities should be instrumented.\n  std::unique_ptr<ProfileList> ProfList;\n\n  /// The allocator used to create AST objects.\n  ///\n  /// AST objects are never destructed; rather, all memory associated with the\n  /// AST objects will be released when the ASTContext itself is destroyed.\n  mutable llvm::BumpPtrAllocator BumpAlloc;\n\n  /// Allocator for partial diagnostics.\n  PartialDiagnostic::DiagStorageAllocator DiagAllocator;\n\n  /// The current C++ ABI.\n  std::unique_ptr<CXXABI> ABI;\n  CXXABI *createCXXABI(const TargetInfo &T);\n\n  /// The logical -> physical address space map.\n  const LangASMap *AddrSpaceMap = nullptr;\n\n  /// Address space map mangling must be used with language specific\n  /// address spaces (e.g. OpenCL/CUDA)\n  bool AddrSpaceMapMangling;\n\n  const TargetInfo *Target = nullptr;\n  const TargetInfo *AuxTarget = nullptr;\n  clang::PrintingPolicy PrintingPolicy;\n  std::unique_ptr<interp::Context> InterpContext;\n  std::unique_ptr<ParentMapContext> ParentMapCtx;\n\npublic:\n  IdentifierTable &Idents;\n  SelectorTable &Selectors;\n  Builtin::Context &BuiltinInfo;\n  mutable DeclarationNameTable DeclarationNames;\n  IntrusiveRefCntPtr<ExternalASTSource> ExternalSource;\n  ASTMutationListener *Listener = nullptr;\n\n  /// Returns the clang bytecode interpreter context.\n  interp::Context &getInterpContext();\n\n  /// Returns the dynamic AST node parent map context.\n  ParentMapContext &getParentMapContext();\n\n  // A traversal scope limits the parts of the AST visible to certain analyses.\n  // RecursiveASTVisitor::TraverseAST will only visit reachable nodes, and\n  // getParents() will only observe reachable parent edges.\n  //\n  // The scope is defined by a set of \"top-level\" declarations.\n  // Initially, it is the entire TU: {getTranslationUnitDecl()}.\n  // Changing the scope clears the parent cache, which is expensive to rebuild.\n  std::vector<Decl *> getTraversalScope() const { return TraversalScope; }\n  void setTraversalScope(const std::vector<Decl *> &);\n\n  /// Forwards to get node parents from the ParentMapContext. New callers should\n  /// use ParentMapContext::getParents() directly.\n  template <typename NodeT> DynTypedNodeList getParents(const NodeT &Node);\n\n  const clang::PrintingPolicy &getPrintingPolicy() const {\n    return PrintingPolicy;\n  }\n\n  void setPrintingPolicy(const clang::PrintingPolicy &Policy) {\n    PrintingPolicy = Policy;\n  }\n\n  SourceManager& getSourceManager() { return SourceMgr; }\n  const SourceManager& getSourceManager() const { return SourceMgr; }\n\n  llvm::BumpPtrAllocator &getAllocator() const {\n    return BumpAlloc;\n  }\n\n  void *Allocate(size_t Size, unsigned Align = 8) const {\n    return BumpAlloc.Allocate(Size, Align);\n  }\n  template <typename T> T *Allocate(size_t Num = 1) const {\n    return static_cast<T *>(Allocate(Num * sizeof(T), alignof(T)));\n  }\n  void Deallocate(void *Ptr) const {}\n\n  /// Return the total amount of physical memory allocated for representing\n  /// AST nodes and type information.\n  size_t getASTAllocatedMemory() const {\n    return BumpAlloc.getTotalMemory();\n  }\n\n  /// Return the total memory used for various side tables.\n  size_t getSideTableAllocatedMemory() const;\n\n  PartialDiagnostic::DiagStorageAllocator &getDiagAllocator() {\n    return DiagAllocator;\n  }\n\n  const TargetInfo &getTargetInfo() const { return *Target; }\n  const TargetInfo *getAuxTargetInfo() const { return AuxTarget; }\n\n  /// getIntTypeForBitwidth -\n  /// sets integer QualTy according to specified details:\n  /// bitwidth, signed/unsigned.\n  /// Returns empty type if there is no appropriate target types.\n  QualType getIntTypeForBitwidth(unsigned DestWidth,\n                                 unsigned Signed) const;\n\n  /// getRealTypeForBitwidth -\n  /// sets floating point QualTy according to specified bitwidth.\n  /// Returns empty type if there is no appropriate target types.\n  QualType getRealTypeForBitwidth(unsigned DestWidth, bool ExplicitIEEE) const;\n\n  bool AtomicUsesUnsupportedLibcall(const AtomicExpr *E) const;\n\n  const LangOptions& getLangOpts() const { return LangOpts; }\n\n  // If this condition is false, typo correction must be performed eagerly\n  // rather than delayed in many places, as it makes use of dependent types.\n  // the condition is false for clang's C-only codepath, as it doesn't support\n  // dependent types yet.\n  bool isDependenceAllowed() const {\n    return LangOpts.CPlusPlus || LangOpts.RecoveryAST;\n  }\n\n  const NoSanitizeList &getNoSanitizeList() const { return *NoSanitizeL; }\n\n  const XRayFunctionFilter &getXRayFilter() const {\n    return *XRayFilter;\n  }\n\n  const ProfileList &getProfileList() const { return *ProfList; }\n\n  DiagnosticsEngine &getDiagnostics() const;\n\n  FullSourceLoc getFullLoc(SourceLocation Loc) const {\n    return FullSourceLoc(Loc,SourceMgr);\n  }\n\n  /// All comments in this translation unit.\n  RawCommentList Comments;\n\n  /// True if comments are already loaded from ExternalASTSource.\n  mutable bool CommentsLoaded = false;\n\n  /// Mapping from declaration to directly attached comment.\n  ///\n  /// Raw comments are owned by Comments list.  This mapping is populated\n  /// lazily.\n  mutable llvm::DenseMap<const Decl *, const RawComment *> DeclRawComments;\n\n  /// Mapping from canonical declaration to the first redeclaration in chain\n  /// that has a comment attached.\n  ///\n  /// Raw comments are owned by Comments list.  This mapping is populated\n  /// lazily.\n  mutable llvm::DenseMap<const Decl *, const Decl *> RedeclChainComments;\n\n  /// Keeps track of redeclaration chains that don't have any comment attached.\n  /// Mapping from canonical declaration to redeclaration chain that has no\n  /// comments attached to any redeclaration. Specifically it's mapping to\n  /// the last redeclaration we've checked.\n  ///\n  /// Shall not contain declarations that have comments attached to any\n  /// redeclaration in their chain.\n  mutable llvm::DenseMap<const Decl *, const Decl *> CommentlessRedeclChains;\n\n  /// Mapping from declarations to parsed comments attached to any\n  /// redeclaration.\n  mutable llvm::DenseMap<const Decl *, comments::FullComment *> ParsedComments;\n\n  /// Attaches \\p Comment to \\p OriginalD and to its redeclaration chain\n  /// and removes the redeclaration chain from the set of commentless chains.\n  ///\n  /// Don't do anything if a comment has already been attached to \\p OriginalD\n  /// or its redeclaration chain.\n  void cacheRawCommentForDecl(const Decl &OriginalD,\n                              const RawComment &Comment) const;\n\n  /// \\returns searches \\p CommentsInFile for doc comment for \\p D.\n  ///\n  /// \\p RepresentativeLocForDecl is used as a location for searching doc\n  /// comments. \\p CommentsInFile is a mapping offset -> comment of files in the\n  /// same file where \\p RepresentativeLocForDecl is.\n  RawComment *getRawCommentForDeclNoCacheImpl(\n      const Decl *D, const SourceLocation RepresentativeLocForDecl,\n      const std::map<unsigned, RawComment *> &CommentsInFile) const;\n\n  /// Return the documentation comment attached to a given declaration,\n  /// without looking into cache.\n  RawComment *getRawCommentForDeclNoCache(const Decl *D) const;\n\npublic:\n  void addComment(const RawComment &RC);\n\n  /// Return the documentation comment attached to a given declaration.\n  /// Returns nullptr if no comment is attached.\n  ///\n  /// \\param OriginalDecl if not nullptr, is set to declaration AST node that\n  /// had the comment, if the comment we found comes from a redeclaration.\n  const RawComment *\n  getRawCommentForAnyRedecl(const Decl *D,\n                            const Decl **OriginalDecl = nullptr) const;\n\n  /// Searches existing comments for doc comments that should be attached to \\p\n  /// Decls. If any doc comment is found, it is parsed.\n  ///\n  /// Requirement: All \\p Decls are in the same file.\n  ///\n  /// If the last comment in the file is already attached we assume\n  /// there are not comments left to be attached to \\p Decls.\n  void attachCommentsToJustParsedDecls(ArrayRef<Decl *> Decls,\n                                       const Preprocessor *PP);\n\n  /// Return parsed documentation comment attached to a given declaration.\n  /// Returns nullptr if no comment is attached.\n  ///\n  /// \\param PP the Preprocessor used with this TU.  Could be nullptr if\n  /// preprocessor is not available.\n  comments::FullComment *getCommentForDecl(const Decl *D,\n                                           const Preprocessor *PP) const;\n\n  /// Return parsed documentation comment attached to a given declaration.\n  /// Returns nullptr if no comment is attached. Does not look at any\n  /// redeclarations of the declaration.\n  comments::FullComment *getLocalCommentForDeclUncached(const Decl *D) const;\n\n  comments::FullComment *cloneFullComment(comments::FullComment *FC,\n                                         const Decl *D) const;\n\nprivate:\n  mutable comments::CommandTraits CommentCommandTraits;\n\n  /// Iterator that visits import declarations.\n  class import_iterator {\n    ImportDecl *Import = nullptr;\n\n  public:\n    using value_type = ImportDecl *;\n    using reference = ImportDecl *;\n    using pointer = ImportDecl *;\n    using difference_type = int;\n    using iterator_category = std::forward_iterator_tag;\n\n    import_iterator() = default;\n    explicit import_iterator(ImportDecl *Import) : Import(Import) {}\n\n    reference operator*() const { return Import; }\n    pointer operator->() const { return Import; }\n\n    import_iterator &operator++() {\n      Import = ASTContext::getNextLocalImport(Import);\n      return *this;\n    }\n\n    import_iterator operator++(int) {\n      import_iterator Other(*this);\n      ++(*this);\n      return Other;\n    }\n\n    friend bool operator==(import_iterator X, import_iterator Y) {\n      return X.Import == Y.Import;\n    }\n\n    friend bool operator!=(import_iterator X, import_iterator Y) {\n      return X.Import != Y.Import;\n    }\n  };\n\npublic:\n  comments::CommandTraits &getCommentCommandTraits() const {\n    return CommentCommandTraits;\n  }\n\n  /// Retrieve the attributes for the given declaration.\n  AttrVec& getDeclAttrs(const Decl *D);\n\n  /// Erase the attributes corresponding to the given declaration.\n  void eraseDeclAttrs(const Decl *D);\n\n  /// If this variable is an instantiated static data member of a\n  /// class template specialization, returns the templated static data member\n  /// from which it was instantiated.\n  // FIXME: Remove ?\n  MemberSpecializationInfo *getInstantiatedFromStaticDataMember(\n                                                           const VarDecl *Var);\n\n  TemplateOrSpecializationInfo\n  getTemplateOrSpecializationInfo(const VarDecl *Var);\n\n  /// Note that the static data member \\p Inst is an instantiation of\n  /// the static data member template \\p Tmpl of a class template.\n  void setInstantiatedFromStaticDataMember(VarDecl *Inst, VarDecl *Tmpl,\n                                           TemplateSpecializationKind TSK,\n                        SourceLocation PointOfInstantiation = SourceLocation());\n\n  void setTemplateOrSpecializationInfo(VarDecl *Inst,\n                                       TemplateOrSpecializationInfo TSI);\n\n  /// If the given using decl \\p Inst is an instantiation of a\n  /// (possibly unresolved) using decl from a template instantiation,\n  /// return it.\n  NamedDecl *getInstantiatedFromUsingDecl(NamedDecl *Inst);\n\n  /// Remember that the using decl \\p Inst is an instantiation\n  /// of the using decl \\p Pattern of a class template.\n  void setInstantiatedFromUsingDecl(NamedDecl *Inst, NamedDecl *Pattern);\n\n  void setInstantiatedFromUsingShadowDecl(UsingShadowDecl *Inst,\n                                          UsingShadowDecl *Pattern);\n  UsingShadowDecl *getInstantiatedFromUsingShadowDecl(UsingShadowDecl *Inst);\n\n  FieldDecl *getInstantiatedFromUnnamedFieldDecl(FieldDecl *Field);\n\n  void setInstantiatedFromUnnamedFieldDecl(FieldDecl *Inst, FieldDecl *Tmpl);\n\n  // Access to the set of methods overridden by the given C++ method.\n  using overridden_cxx_method_iterator = CXXMethodVector::const_iterator;\n  overridden_cxx_method_iterator\n  overridden_methods_begin(const CXXMethodDecl *Method) const;\n\n  overridden_cxx_method_iterator\n  overridden_methods_end(const CXXMethodDecl *Method) const;\n\n  unsigned overridden_methods_size(const CXXMethodDecl *Method) const;\n\n  using overridden_method_range =\n      llvm::iterator_range<overridden_cxx_method_iterator>;\n\n  overridden_method_range overridden_methods(const CXXMethodDecl *Method) const;\n\n  /// Note that the given C++ \\p Method overrides the given \\p\n  /// Overridden method.\n  void addOverriddenMethod(const CXXMethodDecl *Method,\n                           const CXXMethodDecl *Overridden);\n\n  /// Return C++ or ObjC overridden methods for the given \\p Method.\n  ///\n  /// An ObjC method is considered to override any method in the class's\n  /// base classes, its protocols, or its categories' protocols, that has\n  /// the same selector and is of the same kind (class or instance).\n  /// A method in an implementation is not considered as overriding the same\n  /// method in the interface or its categories.\n  void getOverriddenMethods(\n                        const NamedDecl *Method,\n                        SmallVectorImpl<const NamedDecl *> &Overridden) const;\n\n  /// Notify the AST context that a new import declaration has been\n  /// parsed or implicitly created within this translation unit.\n  void addedLocalImportDecl(ImportDecl *Import);\n\n  static ImportDecl *getNextLocalImport(ImportDecl *Import) {\n    return Import->getNextLocalImport();\n  }\n\n  using import_range = llvm::iterator_range<import_iterator>;\n\n  import_range local_imports() const {\n    return import_range(import_iterator(FirstLocalImport), import_iterator());\n  }\n\n  Decl *getPrimaryMergedDecl(Decl *D) {\n    Decl *Result = MergedDecls.lookup(D);\n    return Result ? Result : D;\n  }\n  void setPrimaryMergedDecl(Decl *D, Decl *Primary) {\n    MergedDecls[D] = Primary;\n  }\n\n  /// Note that the definition \\p ND has been merged into module \\p M,\n  /// and should be visible whenever \\p M is visible.\n  void mergeDefinitionIntoModule(NamedDecl *ND, Module *M,\n                                 bool NotifyListeners = true);\n\n  /// Clean up the merged definition list. Call this if you might have\n  /// added duplicates into the list.\n  void deduplicateMergedDefinitonsFor(NamedDecl *ND);\n\n  /// Get the additional modules in which the definition \\p Def has\n  /// been merged.\n  ArrayRef<Module*> getModulesWithMergedDefinition(const NamedDecl *Def);\n\n  /// Add a declaration to the list of declarations that are initialized\n  /// for a module. This will typically be a global variable (with internal\n  /// linkage) that runs module initializers, such as the iostream initializer,\n  /// or an ImportDecl nominating another module that has initializers.\n  void addModuleInitializer(Module *M, Decl *Init);\n\n  void addLazyModuleInitializers(Module *M, ArrayRef<uint32_t> IDs);\n\n  /// Get the initializations to perform when importing a module, if any.\n  ArrayRef<Decl*> getModuleInitializers(Module *M);\n\n  TranslationUnitDecl *getTranslationUnitDecl() const { return TUDecl; }\n\n  ExternCContextDecl *getExternCContextDecl() const;\n  BuiltinTemplateDecl *getMakeIntegerSeqDecl() const;\n  BuiltinTemplateDecl *getTypePackElementDecl() const;\n\n  // Builtin Types.\n  CanQualType VoidTy;\n  CanQualType BoolTy;\n  CanQualType CharTy;\n  CanQualType WCharTy;  // [C++ 3.9.1p5].\n  CanQualType WideCharTy; // Same as WCharTy in C++, integer type in C99.\n  CanQualType WIntTy;   // [C99 7.24.1], integer type unchanged by default promotions.\n  CanQualType Char8Ty;  // [C++20 proposal]\n  CanQualType Char16Ty; // [C++0x 3.9.1p5], integer type in C99.\n  CanQualType Char32Ty; // [C++0x 3.9.1p5], integer type in C99.\n  CanQualType SignedCharTy, ShortTy, IntTy, LongTy, LongLongTy, Int128Ty;\n  CanQualType UnsignedCharTy, UnsignedShortTy, UnsignedIntTy, UnsignedLongTy;\n  CanQualType UnsignedLongLongTy, UnsignedInt128Ty;\n  CanQualType FloatTy, DoubleTy, LongDoubleTy, Float128Ty;\n  CanQualType ShortAccumTy, AccumTy,\n      LongAccumTy;  // ISO/IEC JTC1 SC22 WG14 N1169 Extension\n  CanQualType UnsignedShortAccumTy, UnsignedAccumTy, UnsignedLongAccumTy;\n  CanQualType ShortFractTy, FractTy, LongFractTy;\n  CanQualType UnsignedShortFractTy, UnsignedFractTy, UnsignedLongFractTy;\n  CanQualType SatShortAccumTy, SatAccumTy, SatLongAccumTy;\n  CanQualType SatUnsignedShortAccumTy, SatUnsignedAccumTy,\n      SatUnsignedLongAccumTy;\n  CanQualType SatShortFractTy, SatFractTy, SatLongFractTy;\n  CanQualType SatUnsignedShortFractTy, SatUnsignedFractTy,\n      SatUnsignedLongFractTy;\n  CanQualType HalfTy; // [OpenCL 6.1.1.1], ARM NEON\n  CanQualType BFloat16Ty;\n  CanQualType Float16Ty; // C11 extension ISO/IEC TS 18661-3\n  CanQualType FloatComplexTy, DoubleComplexTy, LongDoubleComplexTy;\n  CanQualType Float128ComplexTy;\n  CanQualType VoidPtrTy, NullPtrTy;\n  CanQualType DependentTy, OverloadTy, BoundMemberTy, UnknownAnyTy;\n  CanQualType BuiltinFnTy;\n  CanQualType PseudoObjectTy, ARCUnbridgedCastTy;\n  CanQualType ObjCBuiltinIdTy, ObjCBuiltinClassTy, ObjCBuiltinSelTy;\n  CanQualType ObjCBuiltinBoolTy;\n#define IMAGE_TYPE(ImgType, Id, SingletonId, Access, Suffix) \\\n  CanQualType SingletonId;\n#include \"clang/Basic/OpenCLImageTypes.def\"\n  CanQualType OCLSamplerTy, OCLEventTy, OCLClkEventTy;\n  CanQualType OCLQueueTy, OCLReserveIDTy;\n  CanQualType IncompleteMatrixIdxTy;\n  CanQualType OMPArraySectionTy, OMPArrayShapingTy, OMPIteratorTy;\n#define EXT_OPAQUE_TYPE(ExtType, Id, Ext) \\\n  CanQualType Id##Ty;\n#include \"clang/Basic/OpenCLExtensionTypes.def\"\n#define SVE_TYPE(Name, Id, SingletonId) \\\n  CanQualType SingletonId;\n#include \"clang/Basic/AArch64SVEACLETypes.def\"\n#define PPC_VECTOR_TYPE(Name, Id, Size) \\\n  CanQualType Id##Ty;\n#include \"clang/Basic/PPCTypes.def\"\n#define RVV_TYPE(Name, Id, SingletonId) \\\n  CanQualType SingletonId;\n#include \"clang/Basic/RISCVVTypes.def\"\n\n  // Types for deductions in C++0x [stmt.ranged]'s desugaring. Built on demand.\n  mutable QualType AutoDeductTy;     // Deduction against 'auto'.\n  mutable QualType AutoRRefDeductTy; // Deduction against 'auto &&'.\n\n  // Decl used to help define __builtin_va_list for some targets.\n  // The decl is built when constructing 'BuiltinVaListDecl'.\n  mutable Decl *VaListTagDecl = nullptr;\n\n  // Implicitly-declared type 'struct _GUID'.\n  mutable TagDecl *MSGuidTagDecl = nullptr;\n\n  /// Keep track of CUDA/HIP static device variables referenced by host code.\n  llvm::DenseSet<const VarDecl *> CUDAStaticDeviceVarReferencedByHost;\n\n  ASTContext(LangOptions &LOpts, SourceManager &SM, IdentifierTable &idents,\n             SelectorTable &sels, Builtin::Context &builtins);\n  ASTContext(const ASTContext &) = delete;\n  ASTContext &operator=(const ASTContext &) = delete;\n  ~ASTContext();\n\n  /// Attach an external AST source to the AST context.\n  ///\n  /// The external AST source provides the ability to load parts of\n  /// the abstract syntax tree as needed from some external storage,\n  /// e.g., a precompiled header.\n  void setExternalSource(IntrusiveRefCntPtr<ExternalASTSource> Source);\n\n  /// Retrieve a pointer to the external AST source associated\n  /// with this AST context, if any.\n  ExternalASTSource *getExternalSource() const {\n    return ExternalSource.get();\n  }\n\n  /// Attach an AST mutation listener to the AST context.\n  ///\n  /// The AST mutation listener provides the ability to track modifications to\n  /// the abstract syntax tree entities committed after they were initially\n  /// created.\n  void setASTMutationListener(ASTMutationListener *Listener) {\n    this->Listener = Listener;\n  }\n\n  /// Retrieve a pointer to the AST mutation listener associated\n  /// with this AST context, if any.\n  ASTMutationListener *getASTMutationListener() const { return Listener; }\n\n  void PrintStats() const;\n  const SmallVectorImpl<Type *>& getTypes() const { return Types; }\n\n  BuiltinTemplateDecl *buildBuiltinTemplateDecl(BuiltinTemplateKind BTK,\n                                                const IdentifierInfo *II) const;\n\n  /// Create a new implicit TU-level CXXRecordDecl or RecordDecl\n  /// declaration.\n  RecordDecl *buildImplicitRecord(StringRef Name,\n                                  RecordDecl::TagKind TK = TTK_Struct) const;\n\n  /// Create a new implicit TU-level typedef declaration.\n  TypedefDecl *buildImplicitTypedef(QualType T, StringRef Name) const;\n\n  /// Retrieve the declaration for the 128-bit signed integer type.\n  TypedefDecl *getInt128Decl() const;\n\n  /// Retrieve the declaration for the 128-bit unsigned integer type.\n  TypedefDecl *getUInt128Decl() const;\n\n  //===--------------------------------------------------------------------===//\n  //                           Type Constructors\n  //===--------------------------------------------------------------------===//\n\nprivate:\n  /// Return a type with extended qualifiers.\n  QualType getExtQualType(const Type *Base, Qualifiers Quals) const;\n\n  QualType getTypeDeclTypeSlow(const TypeDecl *Decl) const;\n\n  QualType getPipeType(QualType T, bool ReadOnly) const;\n\npublic:\n  /// Return the uniqued reference to the type for an address space\n  /// qualified type with the specified type and address space.\n  ///\n  /// The resulting type has a union of the qualifiers from T and the address\n  /// space. If T already has an address space specifier, it is silently\n  /// replaced.\n  QualType getAddrSpaceQualType(QualType T, LangAS AddressSpace) const;\n\n  /// Remove any existing address space on the type and returns the type\n  /// with qualifiers intact (or that's the idea anyway)\n  ///\n  /// The return type should be T with all prior qualifiers minus the address\n  /// space.\n  QualType removeAddrSpaceQualType(QualType T) const;\n\n  /// Apply Objective-C protocol qualifiers to the given type.\n  /// \\param allowOnPointerType specifies if we can apply protocol\n  /// qualifiers on ObjCObjectPointerType. It can be set to true when\n  /// constructing the canonical type of a Objective-C type parameter.\n  QualType applyObjCProtocolQualifiers(QualType type,\n      ArrayRef<ObjCProtocolDecl *> protocols, bool &hasError,\n      bool allowOnPointerType = false) const;\n\n  /// Return the uniqued reference to the type for an Objective-C\n  /// gc-qualified type.\n  ///\n  /// The resulting type has a union of the qualifiers from T and the gc\n  /// attribute.\n  QualType getObjCGCQualType(QualType T, Qualifiers::GC gcAttr) const;\n\n  /// Remove the existing address space on the type if it is a pointer size\n  /// address space and return the type with qualifiers intact.\n  QualType removePtrSizeAddrSpace(QualType T) const;\n\n  /// Return the uniqued reference to the type for a \\c restrict\n  /// qualified type.\n  ///\n  /// The resulting type has a union of the qualifiers from \\p T and\n  /// \\c restrict.\n  QualType getRestrictType(QualType T) const {\n    return T.withFastQualifiers(Qualifiers::Restrict);\n  }\n\n  /// Return the uniqued reference to the type for a \\c volatile\n  /// qualified type.\n  ///\n  /// The resulting type has a union of the qualifiers from \\p T and\n  /// \\c volatile.\n  QualType getVolatileType(QualType T) const {\n    return T.withFastQualifiers(Qualifiers::Volatile);\n  }\n\n  /// Return the uniqued reference to the type for a \\c const\n  /// qualified type.\n  ///\n  /// The resulting type has a union of the qualifiers from \\p T and \\c const.\n  ///\n  /// It can be reasonably expected that this will always be equivalent to\n  /// calling T.withConst().\n  QualType getConstType(QualType T) const { return T.withConst(); }\n\n  /// Change the ExtInfo on a function type.\n  const FunctionType *adjustFunctionType(const FunctionType *Fn,\n                                         FunctionType::ExtInfo EInfo);\n\n  /// Adjust the given function result type.\n  CanQualType getCanonicalFunctionResultType(QualType ResultType) const;\n\n  /// Change the result type of a function type once it is deduced.\n  void adjustDeducedFunctionResultType(FunctionDecl *FD, QualType ResultType);\n\n  /// Get a function type and produce the equivalent function type with the\n  /// specified exception specification. Type sugar that can be present on a\n  /// declaration of a function with an exception specification is permitted\n  /// and preserved. Other type sugar (for instance, typedefs) is not.\n  QualType getFunctionTypeWithExceptionSpec(\n      QualType Orig, const FunctionProtoType::ExceptionSpecInfo &ESI);\n\n  /// Determine whether two function types are the same, ignoring\n  /// exception specifications in cases where they're part of the type.\n  bool hasSameFunctionTypeIgnoringExceptionSpec(QualType T, QualType U);\n\n  /// Change the exception specification on a function once it is\n  /// delay-parsed, instantiated, or computed.\n  void adjustExceptionSpec(FunctionDecl *FD,\n                           const FunctionProtoType::ExceptionSpecInfo &ESI,\n                           bool AsWritten = false);\n\n  /// Get a function type and produce the equivalent function type where\n  /// pointer size address spaces in the return type and parameter tyeps are\n  /// replaced with the default address space.\n  QualType getFunctionTypeWithoutPtrSizes(QualType T);\n\n  /// Determine whether two function types are the same, ignoring pointer sizes\n  /// in the return type and parameter types.\n  bool hasSameFunctionTypeIgnoringPtrSizes(QualType T, QualType U);\n\n  /// Return the uniqued reference to the type for a complex\n  /// number with the specified element type.\n  QualType getComplexType(QualType T) const;\n  CanQualType getComplexType(CanQualType T) const {\n    return CanQualType::CreateUnsafe(getComplexType((QualType) T));\n  }\n\n  /// Return the uniqued reference to the type for a pointer to\n  /// the specified type.\n  QualType getPointerType(QualType T) const;\n  CanQualType getPointerType(CanQualType T) const {\n    return CanQualType::CreateUnsafe(getPointerType((QualType) T));\n  }\n\n  /// Return the uniqued reference to a type adjusted from the original\n  /// type to a new type.\n  QualType getAdjustedType(QualType Orig, QualType New) const;\n  CanQualType getAdjustedType(CanQualType Orig, CanQualType New) const {\n    return CanQualType::CreateUnsafe(\n        getAdjustedType((QualType)Orig, (QualType)New));\n  }\n\n  /// Return the uniqued reference to the decayed version of the given\n  /// type.  Can only be called on array and function types which decay to\n  /// pointer types.\n  QualType getDecayedType(QualType T) const;\n  CanQualType getDecayedType(CanQualType T) const {\n    return CanQualType::CreateUnsafe(getDecayedType((QualType) T));\n  }\n\n  /// Return the uniqued reference to the atomic type for the specified\n  /// type.\n  QualType getAtomicType(QualType T) const;\n\n  /// Return the uniqued reference to the type for a block of the\n  /// specified type.\n  QualType getBlockPointerType(QualType T) const;\n\n  /// Gets the struct used to keep track of the descriptor for pointer to\n  /// blocks.\n  QualType getBlockDescriptorType() const;\n\n  /// Return a read_only pipe type for the specified type.\n  QualType getReadPipeType(QualType T) const;\n\n  /// Return a write_only pipe type for the specified type.\n  QualType getWritePipeType(QualType T) const;\n\n  /// Return an extended integer type with the specified signedness and bit\n  /// count.\n  QualType getExtIntType(bool Unsigned, unsigned NumBits) const;\n\n  /// Return a dependent extended integer type with the specified signedness and\n  /// bit count.\n  QualType getDependentExtIntType(bool Unsigned, Expr *BitsExpr) const;\n\n  /// Gets the struct used to keep track of the extended descriptor for\n  /// pointer to blocks.\n  QualType getBlockDescriptorExtendedType() const;\n\n  /// Map an AST Type to an OpenCLTypeKind enum value.\n  OpenCLTypeKind getOpenCLTypeKind(const Type *T) const;\n\n  /// Get address space for OpenCL type.\n  LangAS getOpenCLTypeAddrSpace(const Type *T) const;\n\n  void setcudaConfigureCallDecl(FunctionDecl *FD) {\n    cudaConfigureCallDecl = FD;\n  }\n\n  FunctionDecl *getcudaConfigureCallDecl() {\n    return cudaConfigureCallDecl;\n  }\n\n  /// Returns true iff we need copy/dispose helpers for the given type.\n  bool BlockRequiresCopying(QualType Ty, const VarDecl *D);\n\n  /// Returns true, if given type has a known lifetime. HasByrefExtendedLayout\n  /// is set to false in this case. If HasByrefExtendedLayout returns true,\n  /// byref variable has extended lifetime.\n  bool getByrefLifetime(QualType Ty,\n                        Qualifiers::ObjCLifetime &Lifetime,\n                        bool &HasByrefExtendedLayout) const;\n\n  /// Return the uniqued reference to the type for an lvalue reference\n  /// to the specified type.\n  QualType getLValueReferenceType(QualType T, bool SpelledAsLValue = true)\n    const;\n\n  /// Return the uniqued reference to the type for an rvalue reference\n  /// to the specified type.\n  QualType getRValueReferenceType(QualType T) const;\n\n  /// Return the uniqued reference to the type for a member pointer to\n  /// the specified type in the specified class.\n  ///\n  /// The class \\p Cls is a \\c Type because it could be a dependent name.\n  QualType getMemberPointerType(QualType T, const Type *Cls) const;\n\n  /// Return a non-unique reference to the type for a variable array of\n  /// the specified element type.\n  QualType getVariableArrayType(QualType EltTy, Expr *NumElts,\n                                ArrayType::ArraySizeModifier ASM,\n                                unsigned IndexTypeQuals,\n                                SourceRange Brackets) const;\n\n  /// Return a non-unique reference to the type for a dependently-sized\n  /// array of the specified element type.\n  ///\n  /// FIXME: We will need these to be uniqued, or at least comparable, at some\n  /// point.\n  QualType getDependentSizedArrayType(QualType EltTy, Expr *NumElts,\n                                      ArrayType::ArraySizeModifier ASM,\n                                      unsigned IndexTypeQuals,\n                                      SourceRange Brackets) const;\n\n  /// Return a unique reference to the type for an incomplete array of\n  /// the specified element type.\n  QualType getIncompleteArrayType(QualType EltTy,\n                                  ArrayType::ArraySizeModifier ASM,\n                                  unsigned IndexTypeQuals) const;\n\n  /// Return the unique reference to the type for a constant array of\n  /// the specified element type.\n  QualType getConstantArrayType(QualType EltTy, const llvm::APInt &ArySize,\n                                const Expr *SizeExpr,\n                                ArrayType::ArraySizeModifier ASM,\n                                unsigned IndexTypeQuals) const;\n\n  /// Return a type for a constant array for a string literal of the\n  /// specified element type and length.\n  QualType getStringLiteralArrayType(QualType EltTy, unsigned Length) const;\n\n  /// Returns a vla type where known sizes are replaced with [*].\n  QualType getVariableArrayDecayedType(QualType Ty) const;\n\n  // Convenience struct to return information about a builtin vector type.\n  struct BuiltinVectorTypeInfo {\n    QualType ElementType;\n    llvm::ElementCount EC;\n    unsigned NumVectors;\n    BuiltinVectorTypeInfo(QualType ElementType, llvm::ElementCount EC,\n                          unsigned NumVectors)\n        : ElementType(ElementType), EC(EC), NumVectors(NumVectors) {}\n  };\n\n  /// Returns the element type, element count and number of vectors\n  /// (in case of tuple) for a builtin vector type.\n  BuiltinVectorTypeInfo\n  getBuiltinVectorTypeInfo(const BuiltinType *VecTy) const;\n\n  /// Return the unique reference to a scalable vector type of the specified\n  /// element type and scalable number of elements.\n  ///\n  /// \\pre \\p EltTy must be a built-in type.\n  QualType getScalableVectorType(QualType EltTy, unsigned NumElts) const;\n\n  /// Return the unique reference to a vector type of the specified\n  /// element type and size.\n  ///\n  /// \\pre \\p VectorType must be a built-in type.\n  QualType getVectorType(QualType VectorType, unsigned NumElts,\n                         VectorType::VectorKind VecKind) const;\n  /// Return the unique reference to the type for a dependently sized vector of\n  /// the specified element type.\n  QualType getDependentVectorType(QualType VectorType, Expr *SizeExpr,\n                                  SourceLocation AttrLoc,\n                                  VectorType::VectorKind VecKind) const;\n\n  /// Return the unique reference to an extended vector type\n  /// of the specified element type and size.\n  ///\n  /// \\pre \\p VectorType must be a built-in type.\n  QualType getExtVectorType(QualType VectorType, unsigned NumElts) const;\n\n  /// \\pre Return a non-unique reference to the type for a dependently-sized\n  /// vector of the specified element type.\n  ///\n  /// FIXME: We will need these to be uniqued, or at least comparable, at some\n  /// point.\n  QualType getDependentSizedExtVectorType(QualType VectorType,\n                                          Expr *SizeExpr,\n                                          SourceLocation AttrLoc) const;\n\n  /// Return the unique reference to the matrix type of the specified element\n  /// type and size\n  ///\n  /// \\pre \\p ElementType must be a valid matrix element type (see\n  /// MatrixType::isValidElementType).\n  QualType getConstantMatrixType(QualType ElementType, unsigned NumRows,\n                                 unsigned NumColumns) const;\n\n  /// Return the unique reference to the matrix type of the specified element\n  /// type and size\n  QualType getDependentSizedMatrixType(QualType ElementType, Expr *RowExpr,\n                                       Expr *ColumnExpr,\n                                       SourceLocation AttrLoc) const;\n\n  QualType getDependentAddressSpaceType(QualType PointeeType,\n                                        Expr *AddrSpaceExpr,\n                                        SourceLocation AttrLoc) const;\n\n  /// Return a K&R style C function type like 'int()'.\n  QualType getFunctionNoProtoType(QualType ResultTy,\n                                  const FunctionType::ExtInfo &Info) const;\n\n  QualType getFunctionNoProtoType(QualType ResultTy) const {\n    return getFunctionNoProtoType(ResultTy, FunctionType::ExtInfo());\n  }\n\n  /// Return a normal function type with a typed argument list.\n  QualType getFunctionType(QualType ResultTy, ArrayRef<QualType> Args,\n                           const FunctionProtoType::ExtProtoInfo &EPI) const {\n    return getFunctionTypeInternal(ResultTy, Args, EPI, false);\n  }\n\n  QualType adjustStringLiteralBaseType(QualType StrLTy) const;\n\nprivate:\n  /// Return a normal function type with a typed argument list.\n  QualType getFunctionTypeInternal(QualType ResultTy, ArrayRef<QualType> Args,\n                                   const FunctionProtoType::ExtProtoInfo &EPI,\n                                   bool OnlyWantCanonical) const;\n\npublic:\n  /// Return the unique reference to the type for the specified type\n  /// declaration.\n  QualType getTypeDeclType(const TypeDecl *Decl,\n                           const TypeDecl *PrevDecl = nullptr) const {\n    assert(Decl && \"Passed null for Decl param\");\n    if (Decl->TypeForDecl) return QualType(Decl->TypeForDecl, 0);\n\n    if (PrevDecl) {\n      assert(PrevDecl->TypeForDecl && \"previous decl has no TypeForDecl\");\n      Decl->TypeForDecl = PrevDecl->TypeForDecl;\n      return QualType(PrevDecl->TypeForDecl, 0);\n    }\n\n    return getTypeDeclTypeSlow(Decl);\n  }\n\n  /// Return the unique reference to the type for the specified\n  /// typedef-name decl.\n  QualType getTypedefType(const TypedefNameDecl *Decl,\n                          QualType Underlying = QualType()) const;\n\n  QualType getRecordType(const RecordDecl *Decl) const;\n\n  QualType getEnumType(const EnumDecl *Decl) const;\n\n  QualType getInjectedClassNameType(CXXRecordDecl *Decl, QualType TST) const;\n\n  QualType getAttributedType(attr::Kind attrKind,\n                             QualType modifiedType,\n                             QualType equivalentType);\n\n  QualType getSubstTemplateTypeParmType(const TemplateTypeParmType *Replaced,\n                                        QualType Replacement) const;\n  QualType getSubstTemplateTypeParmPackType(\n                                          const TemplateTypeParmType *Replaced,\n                                            const TemplateArgument &ArgPack);\n\n  QualType\n  getTemplateTypeParmType(unsigned Depth, unsigned Index,\n                          bool ParameterPack,\n                          TemplateTypeParmDecl *ParmDecl = nullptr) const;\n\n  QualType getTemplateSpecializationType(TemplateName T,\n                                         ArrayRef<TemplateArgument> Args,\n                                         QualType Canon = QualType()) const;\n\n  QualType\n  getCanonicalTemplateSpecializationType(TemplateName T,\n                                         ArrayRef<TemplateArgument> Args) const;\n\n  QualType getTemplateSpecializationType(TemplateName T,\n                                         const TemplateArgumentListInfo &Args,\n                                         QualType Canon = QualType()) const;\n\n  TypeSourceInfo *\n  getTemplateSpecializationTypeInfo(TemplateName T, SourceLocation TLoc,\n                                    const TemplateArgumentListInfo &Args,\n                                    QualType Canon = QualType()) const;\n\n  QualType getParenType(QualType NamedType) const;\n\n  QualType getMacroQualifiedType(QualType UnderlyingTy,\n                                 const IdentifierInfo *MacroII) const;\n\n  QualType getElaboratedType(ElaboratedTypeKeyword Keyword,\n                             NestedNameSpecifier *NNS, QualType NamedType,\n                             TagDecl *OwnedTagDecl = nullptr) const;\n  QualType getDependentNameType(ElaboratedTypeKeyword Keyword,\n                                NestedNameSpecifier *NNS,\n                                const IdentifierInfo *Name,\n                                QualType Canon = QualType()) const;\n\n  QualType getDependentTemplateSpecializationType(ElaboratedTypeKeyword Keyword,\n                                                  NestedNameSpecifier *NNS,\n                                                  const IdentifierInfo *Name,\n                                    const TemplateArgumentListInfo &Args) const;\n  QualType getDependentTemplateSpecializationType(\n      ElaboratedTypeKeyword Keyword, NestedNameSpecifier *NNS,\n      const IdentifierInfo *Name, ArrayRef<TemplateArgument> Args) const;\n\n  TemplateArgument getInjectedTemplateArg(NamedDecl *ParamDecl);\n\n  /// Get a template argument list with one argument per template parameter\n  /// in a template parameter list, such as for the injected class name of\n  /// a class template.\n  void getInjectedTemplateArgs(const TemplateParameterList *Params,\n                               SmallVectorImpl<TemplateArgument> &Args);\n\n  /// Form a pack expansion type with the given pattern.\n  /// \\param NumExpansions The number of expansions for the pack, if known.\n  /// \\param ExpectPackInType If \\c false, we should not expect \\p Pattern to\n  ///        contain an unexpanded pack. This only makes sense if the pack\n  ///        expansion is used in a context where the arity is inferred from\n  ///        elsewhere, such as if the pattern contains a placeholder type or\n  ///        if this is the canonical type of another pack expansion type.\n  QualType getPackExpansionType(QualType Pattern,\n                                Optional<unsigned> NumExpansions,\n                                bool ExpectPackInType = true);\n\n  QualType getObjCInterfaceType(const ObjCInterfaceDecl *Decl,\n                                ObjCInterfaceDecl *PrevDecl = nullptr) const;\n\n  /// Legacy interface: cannot provide type arguments or __kindof.\n  QualType getObjCObjectType(QualType Base,\n                             ObjCProtocolDecl * const *Protocols,\n                             unsigned NumProtocols) const;\n\n  QualType getObjCObjectType(QualType Base,\n                             ArrayRef<QualType> typeArgs,\n                             ArrayRef<ObjCProtocolDecl *> protocols,\n                             bool isKindOf) const;\n\n  QualType getObjCTypeParamType(const ObjCTypeParamDecl *Decl,\n                                ArrayRef<ObjCProtocolDecl *> protocols) const;\n  void adjustObjCTypeParamBoundType(const ObjCTypeParamDecl *Orig,\n                                    ObjCTypeParamDecl *New) const;\n\n  bool ObjCObjectAdoptsQTypeProtocols(QualType QT, ObjCInterfaceDecl *Decl);\n\n  /// QIdProtocolsAdoptObjCObjectProtocols - Checks that protocols in\n  /// QT's qualified-id protocol list adopt all protocols in IDecl's list\n  /// of protocols.\n  bool QIdProtocolsAdoptObjCObjectProtocols(QualType QT,\n                                            ObjCInterfaceDecl *IDecl);\n\n  /// Return a ObjCObjectPointerType type for the given ObjCObjectType.\n  QualType getObjCObjectPointerType(QualType OIT) const;\n\n  /// GCC extension.\n  QualType getTypeOfExprType(Expr *e) const;\n  QualType getTypeOfType(QualType t) const;\n\n  /// C++11 decltype.\n  QualType getDecltypeType(Expr *e, QualType UnderlyingType) const;\n\n  /// Unary type transforms\n  QualType getUnaryTransformType(QualType BaseType, QualType UnderlyingType,\n                                 UnaryTransformType::UTTKind UKind) const;\n\n  /// C++11 deduced auto type.\n  QualType getAutoType(QualType DeducedType, AutoTypeKeyword Keyword,\n                       bool IsDependent, bool IsPack = false,\n                       ConceptDecl *TypeConstraintConcept = nullptr,\n                       ArrayRef<TemplateArgument> TypeConstraintArgs ={}) const;\n\n  /// C++11 deduction pattern for 'auto' type.\n  QualType getAutoDeductType() const;\n\n  /// C++11 deduction pattern for 'auto &&' type.\n  QualType getAutoRRefDeductType() const;\n\n  /// C++17 deduced class template specialization type.\n  QualType getDeducedTemplateSpecializationType(TemplateName Template,\n                                                QualType DeducedType,\n                                                bool IsDependent) const;\n\n  /// Return the unique reference to the type for the specified TagDecl\n  /// (struct/union/class/enum) decl.\n  QualType getTagDeclType(const TagDecl *Decl) const;\n\n  /// Return the unique type for \"size_t\" (C99 7.17), defined in\n  /// <stddef.h>.\n  ///\n  /// The sizeof operator requires this (C99 6.5.3.4p4).\n  CanQualType getSizeType() const;\n\n  /// Return the unique signed counterpart of\n  /// the integer type corresponding to size_t.\n  CanQualType getSignedSizeType() const;\n\n  /// Return the unique type for \"intmax_t\" (C99 7.18.1.5), defined in\n  /// <stdint.h>.\n  CanQualType getIntMaxType() const;\n\n  /// Return the unique type for \"uintmax_t\" (C99 7.18.1.5), defined in\n  /// <stdint.h>.\n  CanQualType getUIntMaxType() const;\n\n  /// Return the unique wchar_t type available in C++ (and available as\n  /// __wchar_t as a Microsoft extension).\n  QualType getWCharType() const { return WCharTy; }\n\n  /// Return the type of wide characters. In C++, this returns the\n  /// unique wchar_t type. In C99, this returns a type compatible with the type\n  /// defined in <stddef.h> as defined by the target.\n  QualType getWideCharType() const { return WideCharTy; }\n\n  /// Return the type of \"signed wchar_t\".\n  ///\n  /// Used when in C++, as a GCC extension.\n  QualType getSignedWCharType() const;\n\n  /// Return the type of \"unsigned wchar_t\".\n  ///\n  /// Used when in C++, as a GCC extension.\n  QualType getUnsignedWCharType() const;\n\n  /// In C99, this returns a type compatible with the type\n  /// defined in <stddef.h> as defined by the target.\n  QualType getWIntType() const { return WIntTy; }\n\n  /// Return a type compatible with \"intptr_t\" (C99 7.18.1.4),\n  /// as defined by the target.\n  QualType getIntPtrType() const;\n\n  /// Return a type compatible with \"uintptr_t\" (C99 7.18.1.4),\n  /// as defined by the target.\n  QualType getUIntPtrType() const;\n\n  /// Return the unique type for \"ptrdiff_t\" (C99 7.17) defined in\n  /// <stddef.h>. Pointer - pointer requires this (C99 6.5.6p9).\n  QualType getPointerDiffType() const;\n\n  /// Return the unique unsigned counterpart of \"ptrdiff_t\"\n  /// integer type. The standard (C11 7.21.6.1p7) refers to this type\n  /// in the definition of %tu format specifier.\n  QualType getUnsignedPointerDiffType() const;\n\n  /// Return the unique type for \"pid_t\" defined in\n  /// <sys/types.h>. We need this to compute the correct type for vfork().\n  QualType getProcessIDType() const;\n\n  /// Return the C structure type used to represent constant CFStrings.\n  QualType getCFConstantStringType() const;\n\n  /// Returns the C struct type for objc_super\n  QualType getObjCSuperType() const;\n  void setObjCSuperType(QualType ST) { ObjCSuperType = ST; }\n\n  /// Get the structure type used to representation CFStrings, or NULL\n  /// if it hasn't yet been built.\n  QualType getRawCFConstantStringType() const {\n    if (CFConstantStringTypeDecl)\n      return getTypedefType(CFConstantStringTypeDecl);\n    return QualType();\n  }\n  void setCFConstantStringType(QualType T);\n  TypedefDecl *getCFConstantStringDecl() const;\n  RecordDecl *getCFConstantStringTagDecl() const;\n\n  // This setter/getter represents the ObjC type for an NSConstantString.\n  void setObjCConstantStringInterface(ObjCInterfaceDecl *Decl);\n  QualType getObjCConstantStringInterface() const {\n    return ObjCConstantStringType;\n  }\n\n  QualType getObjCNSStringType() const {\n    return ObjCNSStringType;\n  }\n\n  void setObjCNSStringType(QualType T) {\n    ObjCNSStringType = T;\n  }\n\n  /// Retrieve the type that \\c id has been defined to, which may be\n  /// different from the built-in \\c id if \\c id has been typedef'd.\n  QualType getObjCIdRedefinitionType() const {\n    if (ObjCIdRedefinitionType.isNull())\n      return getObjCIdType();\n    return ObjCIdRedefinitionType;\n  }\n\n  /// Set the user-written type that redefines \\c id.\n  void setObjCIdRedefinitionType(QualType RedefType) {\n    ObjCIdRedefinitionType = RedefType;\n  }\n\n  /// Retrieve the type that \\c Class has been defined to, which may be\n  /// different from the built-in \\c Class if \\c Class has been typedef'd.\n  QualType getObjCClassRedefinitionType() const {\n    if (ObjCClassRedefinitionType.isNull())\n      return getObjCClassType();\n    return ObjCClassRedefinitionType;\n  }\n\n  /// Set the user-written type that redefines 'SEL'.\n  void setObjCClassRedefinitionType(QualType RedefType) {\n    ObjCClassRedefinitionType = RedefType;\n  }\n\n  /// Retrieve the type that 'SEL' has been defined to, which may be\n  /// different from the built-in 'SEL' if 'SEL' has been typedef'd.\n  QualType getObjCSelRedefinitionType() const {\n    if (ObjCSelRedefinitionType.isNull())\n      return getObjCSelType();\n    return ObjCSelRedefinitionType;\n  }\n\n  /// Set the user-written type that redefines 'SEL'.\n  void setObjCSelRedefinitionType(QualType RedefType) {\n    ObjCSelRedefinitionType = RedefType;\n  }\n\n  /// Retrieve the identifier 'NSObject'.\n  IdentifierInfo *getNSObjectName() const {\n    if (!NSObjectName) {\n      NSObjectName = &Idents.get(\"NSObject\");\n    }\n\n    return NSObjectName;\n  }\n\n  /// Retrieve the identifier 'NSCopying'.\n  IdentifierInfo *getNSCopyingName() {\n    if (!NSCopyingName) {\n      NSCopyingName = &Idents.get(\"NSCopying\");\n    }\n\n    return NSCopyingName;\n  }\n\n  CanQualType getNSUIntegerType() const;\n\n  CanQualType getNSIntegerType() const;\n\n  /// Retrieve the identifier 'bool'.\n  IdentifierInfo *getBoolName() const {\n    if (!BoolName)\n      BoolName = &Idents.get(\"bool\");\n    return BoolName;\n  }\n\n  IdentifierInfo *getMakeIntegerSeqName() const {\n    if (!MakeIntegerSeqName)\n      MakeIntegerSeqName = &Idents.get(\"__make_integer_seq\");\n    return MakeIntegerSeqName;\n  }\n\n  IdentifierInfo *getTypePackElementName() const {\n    if (!TypePackElementName)\n      TypePackElementName = &Idents.get(\"__type_pack_element\");\n    return TypePackElementName;\n  }\n\n  /// Retrieve the Objective-C \"instancetype\" type, if already known;\n  /// otherwise, returns a NULL type;\n  QualType getObjCInstanceType() {\n    return getTypeDeclType(getObjCInstanceTypeDecl());\n  }\n\n  /// Retrieve the typedef declaration corresponding to the Objective-C\n  /// \"instancetype\" type.\n  TypedefDecl *getObjCInstanceTypeDecl();\n\n  /// Set the type for the C FILE type.\n  void setFILEDecl(TypeDecl *FILEDecl) { this->FILEDecl = FILEDecl; }\n\n  /// Retrieve the C FILE type.\n  QualType getFILEType() const {\n    if (FILEDecl)\n      return getTypeDeclType(FILEDecl);\n    return QualType();\n  }\n\n  /// Set the type for the C jmp_buf type.\n  void setjmp_bufDecl(TypeDecl *jmp_bufDecl) {\n    this->jmp_bufDecl = jmp_bufDecl;\n  }\n\n  /// Retrieve the C jmp_buf type.\n  QualType getjmp_bufType() const {\n    if (jmp_bufDecl)\n      return getTypeDeclType(jmp_bufDecl);\n    return QualType();\n  }\n\n  /// Set the type for the C sigjmp_buf type.\n  void setsigjmp_bufDecl(TypeDecl *sigjmp_bufDecl) {\n    this->sigjmp_bufDecl = sigjmp_bufDecl;\n  }\n\n  /// Retrieve the C sigjmp_buf type.\n  QualType getsigjmp_bufType() const {\n    if (sigjmp_bufDecl)\n      return getTypeDeclType(sigjmp_bufDecl);\n    return QualType();\n  }\n\n  /// Set the type for the C ucontext_t type.\n  void setucontext_tDecl(TypeDecl *ucontext_tDecl) {\n    this->ucontext_tDecl = ucontext_tDecl;\n  }\n\n  /// Retrieve the C ucontext_t type.\n  QualType getucontext_tType() const {\n    if (ucontext_tDecl)\n      return getTypeDeclType(ucontext_tDecl);\n    return QualType();\n  }\n\n  /// The result type of logical operations, '<', '>', '!=', etc.\n  QualType getLogicalOperationType() const {\n    return getLangOpts().CPlusPlus ? BoolTy : IntTy;\n  }\n\n  /// Emit the Objective-CC type encoding for the given type \\p T into\n  /// \\p S.\n  ///\n  /// If \\p Field is specified then record field names are also encoded.\n  void getObjCEncodingForType(QualType T, std::string &S,\n                              const FieldDecl *Field=nullptr,\n                              QualType *NotEncodedT=nullptr) const;\n\n  /// Emit the Objective-C property type encoding for the given\n  /// type \\p T into \\p S.\n  void getObjCEncodingForPropertyType(QualType T, std::string &S) const;\n\n  void getLegacyIntegralTypeEncoding(QualType &t) const;\n\n  /// Put the string version of the type qualifiers \\p QT into \\p S.\n  void getObjCEncodingForTypeQualifier(Decl::ObjCDeclQualifier QT,\n                                       std::string &S) const;\n\n  /// Emit the encoded type for the function \\p Decl into \\p S.\n  ///\n  /// This is in the same format as Objective-C method encodings.\n  ///\n  /// \\returns true if an error occurred (e.g., because one of the parameter\n  /// types is incomplete), false otherwise.\n  std::string getObjCEncodingForFunctionDecl(const FunctionDecl *Decl) const;\n\n  /// Emit the encoded type for the method declaration \\p Decl into\n  /// \\p S.\n  std::string getObjCEncodingForMethodDecl(const ObjCMethodDecl *Decl,\n                                           bool Extended = false) const;\n\n  /// Return the encoded type for this block declaration.\n  std::string getObjCEncodingForBlock(const BlockExpr *blockExpr) const;\n\n  /// getObjCEncodingForPropertyDecl - Return the encoded type for\n  /// this method declaration. If non-NULL, Container must be either\n  /// an ObjCCategoryImplDecl or ObjCImplementationDecl; it should\n  /// only be NULL when getting encodings for protocol properties.\n  std::string getObjCEncodingForPropertyDecl(const ObjCPropertyDecl *PD,\n                                             const Decl *Container) const;\n\n  bool ProtocolCompatibleWithProtocol(ObjCProtocolDecl *lProto,\n                                      ObjCProtocolDecl *rProto) const;\n\n  ObjCPropertyImplDecl *getObjCPropertyImplDeclForPropertyDecl(\n                                                  const ObjCPropertyDecl *PD,\n                                                  const Decl *Container) const;\n\n  /// Return the size of type \\p T for Objective-C encoding purpose,\n  /// in characters.\n  CharUnits getObjCEncodingTypeSize(QualType T) const;\n\n  /// Retrieve the typedef corresponding to the predefined \\c id type\n  /// in Objective-C.\n  TypedefDecl *getObjCIdDecl() const;\n\n  /// Represents the Objective-CC \\c id type.\n  ///\n  /// This is set up lazily, by Sema.  \\c id is always a (typedef for a)\n  /// pointer type, a pointer to a struct.\n  QualType getObjCIdType() const {\n    return getTypeDeclType(getObjCIdDecl());\n  }\n\n  /// Retrieve the typedef corresponding to the predefined 'SEL' type\n  /// in Objective-C.\n  TypedefDecl *getObjCSelDecl() const;\n\n  /// Retrieve the type that corresponds to the predefined Objective-C\n  /// 'SEL' type.\n  QualType getObjCSelType() const {\n    return getTypeDeclType(getObjCSelDecl());\n  }\n\n  /// Retrieve the typedef declaration corresponding to the predefined\n  /// Objective-C 'Class' type.\n  TypedefDecl *getObjCClassDecl() const;\n\n  /// Represents the Objective-C \\c Class type.\n  ///\n  /// This is set up lazily, by Sema.  \\c Class is always a (typedef for a)\n  /// pointer type, a pointer to a struct.\n  QualType getObjCClassType() const {\n    return getTypeDeclType(getObjCClassDecl());\n  }\n\n  /// Retrieve the Objective-C class declaration corresponding to\n  /// the predefined \\c Protocol class.\n  ObjCInterfaceDecl *getObjCProtocolDecl() const;\n\n  /// Retrieve declaration of 'BOOL' typedef\n  TypedefDecl *getBOOLDecl() const {\n    return BOOLDecl;\n  }\n\n  /// Save declaration of 'BOOL' typedef\n  void setBOOLDecl(TypedefDecl *TD) {\n    BOOLDecl = TD;\n  }\n\n  /// type of 'BOOL' type.\n  QualType getBOOLType() const {\n    return getTypeDeclType(getBOOLDecl());\n  }\n\n  /// Retrieve the type of the Objective-C \\c Protocol class.\n  QualType getObjCProtoType() const {\n    return getObjCInterfaceType(getObjCProtocolDecl());\n  }\n\n  /// Retrieve the C type declaration corresponding to the predefined\n  /// \\c __builtin_va_list type.\n  TypedefDecl *getBuiltinVaListDecl() const;\n\n  /// Retrieve the type of the \\c __builtin_va_list type.\n  QualType getBuiltinVaListType() const {\n    return getTypeDeclType(getBuiltinVaListDecl());\n  }\n\n  /// Retrieve the C type declaration corresponding to the predefined\n  /// \\c __va_list_tag type used to help define the \\c __builtin_va_list type\n  /// for some targets.\n  Decl *getVaListTagDecl() const;\n\n  /// Retrieve the C type declaration corresponding to the predefined\n  /// \\c __builtin_ms_va_list type.\n  TypedefDecl *getBuiltinMSVaListDecl() const;\n\n  /// Retrieve the type of the \\c __builtin_ms_va_list type.\n  QualType getBuiltinMSVaListType() const {\n    return getTypeDeclType(getBuiltinMSVaListDecl());\n  }\n\n  /// Retrieve the implicitly-predeclared 'struct _GUID' declaration.\n  TagDecl *getMSGuidTagDecl() const { return MSGuidTagDecl; }\n\n  /// Retrieve the implicitly-predeclared 'struct _GUID' type.\n  QualType getMSGuidType() const {\n    assert(MSGuidTagDecl && \"asked for GUID type but MS extensions disabled\");\n    return getTagDeclType(MSGuidTagDecl);\n  }\n\n  /// Return whether a declaration to a builtin is allowed to be\n  /// overloaded/redeclared.\n  bool canBuiltinBeRedeclared(const FunctionDecl *) const;\n\n  /// Return a type with additional \\c const, \\c volatile, or\n  /// \\c restrict qualifiers.\n  QualType getCVRQualifiedType(QualType T, unsigned CVR) const {\n    return getQualifiedType(T, Qualifiers::fromCVRMask(CVR));\n  }\n\n  /// Un-split a SplitQualType.\n  QualType getQualifiedType(SplitQualType split) const {\n    return getQualifiedType(split.Ty, split.Quals);\n  }\n\n  /// Return a type with additional qualifiers.\n  QualType getQualifiedType(QualType T, Qualifiers Qs) const {\n    if (!Qs.hasNonFastQualifiers())\n      return T.withFastQualifiers(Qs.getFastQualifiers());\n    QualifierCollector Qc(Qs);\n    const Type *Ptr = Qc.strip(T);\n    return getExtQualType(Ptr, Qc);\n  }\n\n  /// Return a type with additional qualifiers.\n  QualType getQualifiedType(const Type *T, Qualifiers Qs) const {\n    if (!Qs.hasNonFastQualifiers())\n      return QualType(T, Qs.getFastQualifiers());\n    return getExtQualType(T, Qs);\n  }\n\n  /// Return a type with the given lifetime qualifier.\n  ///\n  /// \\pre Neither type.ObjCLifetime() nor \\p lifetime may be \\c OCL_None.\n  QualType getLifetimeQualifiedType(QualType type,\n                                    Qualifiers::ObjCLifetime lifetime) {\n    assert(type.getObjCLifetime() == Qualifiers::OCL_None);\n    assert(lifetime != Qualifiers::OCL_None);\n\n    Qualifiers qs;\n    qs.addObjCLifetime(lifetime);\n    return getQualifiedType(type, qs);\n  }\n\n  /// getUnqualifiedObjCPointerType - Returns version of\n  /// Objective-C pointer type with lifetime qualifier removed.\n  QualType getUnqualifiedObjCPointerType(QualType type) const {\n    if (!type.getTypePtr()->isObjCObjectPointerType() ||\n        !type.getQualifiers().hasObjCLifetime())\n      return type;\n    Qualifiers Qs = type.getQualifiers();\n    Qs.removeObjCLifetime();\n    return getQualifiedType(type.getUnqualifiedType(), Qs);\n  }\n\n  unsigned char getFixedPointScale(QualType Ty) const;\n  unsigned char getFixedPointIBits(QualType Ty) const;\n  llvm::FixedPointSemantics getFixedPointSemantics(QualType Ty) const;\n  llvm::APFixedPoint getFixedPointMax(QualType Ty) const;\n  llvm::APFixedPoint getFixedPointMin(QualType Ty) const;\n\n  DeclarationNameInfo getNameForTemplate(TemplateName Name,\n                                         SourceLocation NameLoc) const;\n\n  TemplateName getOverloadedTemplateName(UnresolvedSetIterator Begin,\n                                         UnresolvedSetIterator End) const;\n  TemplateName getAssumedTemplateName(DeclarationName Name) const;\n\n  TemplateName getQualifiedTemplateName(NestedNameSpecifier *NNS,\n                                        bool TemplateKeyword,\n                                        TemplateDecl *Template) const;\n\n  TemplateName getDependentTemplateName(NestedNameSpecifier *NNS,\n                                        const IdentifierInfo *Name) const;\n  TemplateName getDependentTemplateName(NestedNameSpecifier *NNS,\n                                        OverloadedOperatorKind Operator) const;\n  TemplateName getSubstTemplateTemplateParm(TemplateTemplateParmDecl *param,\n                                            TemplateName replacement) const;\n  TemplateName getSubstTemplateTemplateParmPack(TemplateTemplateParmDecl *Param,\n                                        const TemplateArgument &ArgPack) const;\n\n  enum GetBuiltinTypeError {\n    /// No error\n    GE_None,\n\n    /// Missing a type\n    GE_Missing_type,\n\n    /// Missing a type from <stdio.h>\n    GE_Missing_stdio,\n\n    /// Missing a type from <setjmp.h>\n    GE_Missing_setjmp,\n\n    /// Missing a type from <ucontext.h>\n    GE_Missing_ucontext\n  };\n\n  QualType DecodeTypeStr(const char *&Str, const ASTContext &Context,\n                         ASTContext::GetBuiltinTypeError &Error,\n                         bool &RequireICE, bool AllowTypeModifiers) const;\n\n  /// Return the type for the specified builtin.\n  ///\n  /// If \\p IntegerConstantArgs is non-null, it is filled in with a bitmask of\n  /// arguments to the builtin that are required to be integer constant\n  /// expressions.\n  QualType GetBuiltinType(unsigned ID, GetBuiltinTypeError &Error,\n                          unsigned *IntegerConstantArgs = nullptr) const;\n\n  /// Types and expressions required to build C++2a three-way comparisons\n  /// using operator<=>, including the values return by builtin <=> operators.\n  ComparisonCategories CompCategories;\n\nprivate:\n  CanQualType getFromTargetType(unsigned Type) const;\n  TypeInfo getTypeInfoImpl(const Type *T) const;\n\n  //===--------------------------------------------------------------------===//\n  //                         Type Predicates.\n  //===--------------------------------------------------------------------===//\n\npublic:\n  /// Return one of the GCNone, Weak or Strong Objective-C garbage\n  /// collection attributes.\n  Qualifiers::GC getObjCGCAttrKind(QualType Ty) const;\n\n  /// Return true if the given vector types are of the same unqualified\n  /// type or if they are equivalent to the same GCC vector type.\n  ///\n  /// \\note This ignores whether they are target-specific (AltiVec or Neon)\n  /// types.\n  bool areCompatibleVectorTypes(QualType FirstVec, QualType SecondVec);\n\n  /// Return true if the given types are an SVE builtin and a VectorType that\n  /// is a fixed-length representation of the SVE builtin for a specific\n  /// vector-length.\n  bool areCompatibleSveTypes(QualType FirstType, QualType SecondType);\n\n  /// Return true if the given vector types are lax-compatible SVE vector types,\n  /// false otherwise.\n  bool areLaxCompatibleSveTypes(QualType FirstType, QualType SecondType);\n\n  /// Return true if the type has been explicitly qualified with ObjC ownership.\n  /// A type may be implicitly qualified with ownership under ObjC ARC, and in\n  /// some cases the compiler treats these differently.\n  bool hasDirectOwnershipQualifier(QualType Ty) const;\n\n  /// Return true if this is an \\c NSObject object with its \\c NSObject\n  /// attribute set.\n  static bool isObjCNSObjectType(QualType Ty) {\n    return Ty->isObjCNSObjectType();\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                         Type Sizing and Analysis\n  //===--------------------------------------------------------------------===//\n\n  /// Return the APFloat 'semantics' for the specified scalar floating\n  /// point type.\n  const llvm::fltSemantics &getFloatTypeSemantics(QualType T) const;\n\n  /// Get the size and alignment of the specified complete type in bits.\n  TypeInfo getTypeInfo(const Type *T) const;\n  TypeInfo getTypeInfo(QualType T) const { return getTypeInfo(T.getTypePtr()); }\n\n  /// Get default simd alignment of the specified complete type in bits.\n  unsigned getOpenMPDefaultSimdAlign(QualType T) const;\n\n  /// Return the size of the specified (complete) type \\p T, in bits.\n  uint64_t getTypeSize(QualType T) const { return getTypeInfo(T).Width; }\n  uint64_t getTypeSize(const Type *T) const { return getTypeInfo(T).Width; }\n\n  /// Return the size of the character type, in bits.\n  uint64_t getCharWidth() const {\n    return getTypeSize(CharTy);\n  }\n\n  /// Convert a size in bits to a size in characters.\n  CharUnits toCharUnitsFromBits(int64_t BitSize) const;\n\n  /// Convert a size in characters to a size in bits.\n  int64_t toBits(CharUnits CharSize) const;\n\n  /// Return the size of the specified (complete) type \\p T, in\n  /// characters.\n  CharUnits getTypeSizeInChars(QualType T) const;\n  CharUnits getTypeSizeInChars(const Type *T) const;\n\n  Optional<CharUnits> getTypeSizeInCharsIfKnown(QualType Ty) const {\n    if (Ty->isIncompleteType() || Ty->isDependentType())\n      return None;\n    return getTypeSizeInChars(Ty);\n  }\n\n  Optional<CharUnits> getTypeSizeInCharsIfKnown(const Type *Ty) const {\n    return getTypeSizeInCharsIfKnown(QualType(Ty, 0));\n  }\n\n  /// Return the ABI-specified alignment of a (complete) type \\p T, in\n  /// bits.\n  unsigned getTypeAlign(QualType T) const { return getTypeInfo(T).Align; }\n  unsigned getTypeAlign(const Type *T) const { return getTypeInfo(T).Align; }\n\n  /// Return the ABI-specified natural alignment of a (complete) type \\p T,\n  /// before alignment adjustments, in bits.\n  ///\n  /// This alignment is curently used only by ARM and AArch64 when passing\n  /// arguments of a composite type.\n  unsigned getTypeUnadjustedAlign(QualType T) const {\n    return getTypeUnadjustedAlign(T.getTypePtr());\n  }\n  unsigned getTypeUnadjustedAlign(const Type *T) const;\n\n  /// Return the alignment of a type, in bits, or 0 if\n  /// the type is incomplete and we cannot determine the alignment (for\n  /// example, from alignment attributes). The returned alignment is the\n  /// Preferred alignment if NeedsPreferredAlignment is true, otherwise is the\n  /// ABI alignment.\n  unsigned getTypeAlignIfKnown(QualType T,\n                               bool NeedsPreferredAlignment = false) const;\n\n  /// Return the ABI-specified alignment of a (complete) type \\p T, in\n  /// characters.\n  CharUnits getTypeAlignInChars(QualType T) const;\n  CharUnits getTypeAlignInChars(const Type *T) const;\n\n  /// Return the PreferredAlignment of a (complete) type \\p T, in\n  /// characters.\n  CharUnits getPreferredTypeAlignInChars(QualType T) const {\n    return toCharUnitsFromBits(getPreferredTypeAlign(T));\n  }\n\n  /// getTypeUnadjustedAlignInChars - Return the ABI-specified alignment of a type,\n  /// in characters, before alignment adjustments. This method does not work on\n  /// incomplete types.\n  CharUnits getTypeUnadjustedAlignInChars(QualType T) const;\n  CharUnits getTypeUnadjustedAlignInChars(const Type *T) const;\n\n  // getTypeInfoDataSizeInChars - Return the size of a type, in chars. If the\n  // type is a record, its data size is returned.\n  TypeInfoChars getTypeInfoDataSizeInChars(QualType T) const;\n\n  TypeInfoChars getTypeInfoInChars(const Type *T) const;\n  TypeInfoChars getTypeInfoInChars(QualType T) const;\n\n  /// Determine if the alignment the type has was required using an\n  /// alignment attribute.\n  bool isAlignmentRequired(const Type *T) const;\n  bool isAlignmentRequired(QualType T) const;\n\n  /// Return the \"preferred\" alignment of the specified type \\p T for\n  /// the current target, in bits.\n  ///\n  /// This can be different than the ABI alignment in cases where it is\n  /// beneficial for performance or backwards compatibility preserving to\n  /// overalign a data type. (Note: despite the name, the preferred alignment\n  /// is ABI-impacting, and not an optimization.)\n  unsigned getPreferredTypeAlign(QualType T) const {\n    return getPreferredTypeAlign(T.getTypePtr());\n  }\n  unsigned getPreferredTypeAlign(const Type *T) const;\n\n  /// Return the default alignment for __attribute__((aligned)) on\n  /// this target, to be used if no alignment value is specified.\n  unsigned getTargetDefaultAlignForAttributeAligned() const;\n\n  /// Return the alignment in bits that should be given to a\n  /// global variable with type \\p T.\n  unsigned getAlignOfGlobalVar(QualType T) const;\n\n  /// Return the alignment in characters that should be given to a\n  /// global variable with type \\p T.\n  CharUnits getAlignOfGlobalVarInChars(QualType T) const;\n\n  /// Return a conservative estimate of the alignment of the specified\n  /// decl \\p D.\n  ///\n  /// \\pre \\p D must not be a bitfield type, as bitfields do not have a valid\n  /// alignment.\n  ///\n  /// If \\p ForAlignof, references are treated like their underlying type\n  /// and  large arrays don't get any special treatment. If not \\p ForAlignof\n  /// it computes the value expected by CodeGen: references are treated like\n  /// pointers and large arrays get extra alignment.\n  CharUnits getDeclAlign(const Decl *D, bool ForAlignof = false) const;\n\n  /// Return the alignment (in bytes) of the thrown exception object. This is\n  /// only meaningful for targets that allocate C++ exceptions in a system\n  /// runtime, such as those using the Itanium C++ ABI.\n  CharUnits getExnObjectAlignment() const;\n\n  /// Get or compute information about the layout of the specified\n  /// record (struct/union/class) \\p D, which indicates its size and field\n  /// position information.\n  const ASTRecordLayout &getASTRecordLayout(const RecordDecl *D) const;\n\n  /// Get or compute information about the layout of the specified\n  /// Objective-C interface.\n  const ASTRecordLayout &getASTObjCInterfaceLayout(const ObjCInterfaceDecl *D)\n    const;\n\n  void DumpRecordLayout(const RecordDecl *RD, raw_ostream &OS,\n                        bool Simple = false) const;\n\n  /// Get or compute information about the layout of the specified\n  /// Objective-C implementation.\n  ///\n  /// This may differ from the interface if synthesized ivars are present.\n  const ASTRecordLayout &\n  getASTObjCImplementationLayout(const ObjCImplementationDecl *D) const;\n\n  /// Get our current best idea for the key function of the\n  /// given record decl, or nullptr if there isn't one.\n  ///\n  /// The key function is, according to the Itanium C++ ABI section 5.2.3:\n  ///   ...the first non-pure virtual function that is not inline at the\n  ///   point of class definition.\n  ///\n  /// Other ABIs use the same idea.  However, the ARM C++ ABI ignores\n  /// virtual functions that are defined 'inline', which means that\n  /// the result of this computation can change.\n  const CXXMethodDecl *getCurrentKeyFunction(const CXXRecordDecl *RD);\n\n  /// Observe that the given method cannot be a key function.\n  /// Checks the key-function cache for the method's class and clears it\n  /// if matches the given declaration.\n  ///\n  /// This is used in ABIs where out-of-line definitions marked\n  /// inline are not considered to be key functions.\n  ///\n  /// \\param method should be the declaration from the class definition\n  void setNonKeyFunction(const CXXMethodDecl *method);\n\n  /// Loading virtual member pointers using the virtual inheritance model\n  /// always results in an adjustment using the vbtable even if the index is\n  /// zero.\n  ///\n  /// This is usually OK because the first slot in the vbtable points\n  /// backwards to the top of the MDC.  However, the MDC might be reusing a\n  /// vbptr from an nv-base.  In this case, the first slot in the vbtable\n  /// points to the start of the nv-base which introduced the vbptr and *not*\n  /// the MDC.  Modify the NonVirtualBaseAdjustment to account for this.\n  CharUnits getOffsetOfBaseWithVBPtr(const CXXRecordDecl *RD) const;\n\n  /// Get the offset of a FieldDecl or IndirectFieldDecl, in bits.\n  uint64_t getFieldOffset(const ValueDecl *FD) const;\n\n  /// Get the offset of an ObjCIvarDecl in bits.\n  uint64_t lookupFieldBitOffset(const ObjCInterfaceDecl *OID,\n                                const ObjCImplementationDecl *ID,\n                                const ObjCIvarDecl *Ivar) const;\n\n  /// Find the 'this' offset for the member path in a pointer-to-member\n  /// APValue.\n  CharUnits getMemberPointerPathAdjustment(const APValue &MP) const;\n\n  bool isNearlyEmpty(const CXXRecordDecl *RD) const;\n\n  VTableContextBase *getVTableContext();\n\n  /// If \\p T is null pointer, assume the target in ASTContext.\n  MangleContext *createMangleContext(const TargetInfo *T = nullptr);\n\n  void DeepCollectObjCIvars(const ObjCInterfaceDecl *OI, bool leafClass,\n                            SmallVectorImpl<const ObjCIvarDecl*> &Ivars) const;\n\n  unsigned CountNonClassIvars(const ObjCInterfaceDecl *OI) const;\n  void CollectInheritedProtocols(const Decl *CDecl,\n                          llvm::SmallPtrSet<ObjCProtocolDecl*, 8> &Protocols);\n\n  /// Return true if the specified type has unique object representations\n  /// according to (C++17 [meta.unary.prop]p9)\n  bool hasUniqueObjectRepresentations(QualType Ty) const;\n\n  //===--------------------------------------------------------------------===//\n  //                            Type Operators\n  //===--------------------------------------------------------------------===//\n\n  /// Return the canonical (structural) type corresponding to the\n  /// specified potentially non-canonical type \\p T.\n  ///\n  /// The non-canonical version of a type may have many \"decorated\" versions of\n  /// types.  Decorators can include typedefs, 'typeof' operators, etc. The\n  /// returned type is guaranteed to be free of any of these, allowing two\n  /// canonical types to be compared for exact equality with a simple pointer\n  /// comparison.\n  CanQualType getCanonicalType(QualType T) const {\n    return CanQualType::CreateUnsafe(T.getCanonicalType());\n  }\n\n  const Type *getCanonicalType(const Type *T) const {\n    return T->getCanonicalTypeInternal().getTypePtr();\n  }\n\n  /// Return the canonical parameter type corresponding to the specific\n  /// potentially non-canonical one.\n  ///\n  /// Qualifiers are stripped off, functions are turned into function\n  /// pointers, and arrays decay one level into pointers.\n  CanQualType getCanonicalParamType(QualType T) const;\n\n  /// Determine whether the given types \\p T1 and \\p T2 are equivalent.\n  bool hasSameType(QualType T1, QualType T2) const {\n    return getCanonicalType(T1) == getCanonicalType(T2);\n  }\n  bool hasSameType(const Type *T1, const Type *T2) const {\n    return getCanonicalType(T1) == getCanonicalType(T2);\n  }\n\n  /// Return this type as a completely-unqualified array type,\n  /// capturing the qualifiers in \\p Quals.\n  ///\n  /// This will remove the minimal amount of sugaring from the types, similar\n  /// to the behavior of QualType::getUnqualifiedType().\n  ///\n  /// \\param T is the qualified type, which may be an ArrayType\n  ///\n  /// \\param Quals will receive the full set of qualifiers that were\n  /// applied to the array.\n  ///\n  /// \\returns if this is an array type, the completely unqualified array type\n  /// that corresponds to it. Otherwise, returns T.getUnqualifiedType().\n  QualType getUnqualifiedArrayType(QualType T, Qualifiers &Quals);\n\n  /// Determine whether the given types are equivalent after\n  /// cvr-qualifiers have been removed.\n  bool hasSameUnqualifiedType(QualType T1, QualType T2) const {\n    return getCanonicalType(T1).getTypePtr() ==\n           getCanonicalType(T2).getTypePtr();\n  }\n\n  bool hasSameNullabilityTypeQualifier(QualType SubT, QualType SuperT,\n                                       bool IsParam) const {\n    auto SubTnullability = SubT->getNullability(*this);\n    auto SuperTnullability = SuperT->getNullability(*this);\n    if (SubTnullability.hasValue() == SuperTnullability.hasValue()) {\n      // Neither has nullability; return true\n      if (!SubTnullability)\n        return true;\n      // Both have nullability qualifier.\n      if (*SubTnullability == *SuperTnullability ||\n          *SubTnullability == NullabilityKind::Unspecified ||\n          *SuperTnullability == NullabilityKind::Unspecified)\n        return true;\n\n      if (IsParam) {\n        // Ok for the superclass method parameter to be \"nonnull\" and the subclass\n        // method parameter to be \"nullable\"\n        return (*SuperTnullability == NullabilityKind::NonNull &&\n                *SubTnullability == NullabilityKind::Nullable);\n      }\n      // For the return type, it's okay for the superclass method to specify\n      // \"nullable\" and the subclass method specify \"nonnull\"\n      return (*SuperTnullability == NullabilityKind::Nullable &&\n              *SubTnullability == NullabilityKind::NonNull);\n    }\n    return true;\n  }\n\n  bool ObjCMethodsAreEqual(const ObjCMethodDecl *MethodDecl,\n                           const ObjCMethodDecl *MethodImp);\n\n  bool UnwrapSimilarTypes(QualType &T1, QualType &T2);\n  bool UnwrapSimilarArrayTypes(QualType &T1, QualType &T2);\n\n  /// Determine if two types are similar, according to the C++ rules. That is,\n  /// determine if they are the same other than qualifiers on the initial\n  /// sequence of pointer / pointer-to-member / array (and in Clang, object\n  /// pointer) types and their element types.\n  ///\n  /// Clang offers a number of qualifiers in addition to the C++ qualifiers;\n  /// those qualifiers are also ignored in the 'similarity' check.\n  bool hasSimilarType(QualType T1, QualType T2);\n\n  /// Determine if two types are similar, ignoring only CVR qualifiers.\n  bool hasCvrSimilarType(QualType T1, QualType T2);\n\n  /// Retrieves the \"canonical\" nested name specifier for a\n  /// given nested name specifier.\n  ///\n  /// The canonical nested name specifier is a nested name specifier\n  /// that uniquely identifies a type or namespace within the type\n  /// system. For example, given:\n  ///\n  /// \\code\n  /// namespace N {\n  ///   struct S {\n  ///     template<typename T> struct X { typename T* type; };\n  ///   };\n  /// }\n  ///\n  /// template<typename T> struct Y {\n  ///   typename N::S::X<T>::type member;\n  /// };\n  /// \\endcode\n  ///\n  /// Here, the nested-name-specifier for N::S::X<T>:: will be\n  /// S::X<template-param-0-0>, since 'S' and 'X' are uniquely defined\n  /// by declarations in the type system and the canonical type for\n  /// the template type parameter 'T' is template-param-0-0.\n  NestedNameSpecifier *\n  getCanonicalNestedNameSpecifier(NestedNameSpecifier *NNS) const;\n\n  /// Retrieves the default calling convention for the current target.\n  CallingConv getDefaultCallingConvention(bool IsVariadic,\n                                          bool IsCXXMethod,\n                                          bool IsBuiltin = false) const;\n\n  /// Retrieves the \"canonical\" template name that refers to a\n  /// given template.\n  ///\n  /// The canonical template name is the simplest expression that can\n  /// be used to refer to a given template. For most templates, this\n  /// expression is just the template declaration itself. For example,\n  /// the template std::vector can be referred to via a variety of\n  /// names---std::vector, \\::std::vector, vector (if vector is in\n  /// scope), etc.---but all of these names map down to the same\n  /// TemplateDecl, which is used to form the canonical template name.\n  ///\n  /// Dependent template names are more interesting. Here, the\n  /// template name could be something like T::template apply or\n  /// std::allocator<T>::template rebind, where the nested name\n  /// specifier itself is dependent. In this case, the canonical\n  /// template name uses the shortest form of the dependent\n  /// nested-name-specifier, which itself contains all canonical\n  /// types, values, and templates.\n  TemplateName getCanonicalTemplateName(TemplateName Name) const;\n\n  /// Determine whether the given template names refer to the same\n  /// template.\n  bool hasSameTemplateName(TemplateName X, TemplateName Y);\n\n  /// Retrieve the \"canonical\" template argument.\n  ///\n  /// The canonical template argument is the simplest template argument\n  /// (which may be a type, value, expression, or declaration) that\n  /// expresses the value of the argument.\n  TemplateArgument getCanonicalTemplateArgument(const TemplateArgument &Arg)\n    const;\n\n  /// Type Query functions.  If the type is an instance of the specified class,\n  /// return the Type pointer for the underlying maximally pretty type.  This\n  /// is a member of ASTContext because this may need to do some amount of\n  /// canonicalization, e.g. to move type qualifiers into the element type.\n  const ArrayType *getAsArrayType(QualType T) const;\n  const ConstantArrayType *getAsConstantArrayType(QualType T) const {\n    return dyn_cast_or_null<ConstantArrayType>(getAsArrayType(T));\n  }\n  const VariableArrayType *getAsVariableArrayType(QualType T) const {\n    return dyn_cast_or_null<VariableArrayType>(getAsArrayType(T));\n  }\n  const IncompleteArrayType *getAsIncompleteArrayType(QualType T) const {\n    return dyn_cast_or_null<IncompleteArrayType>(getAsArrayType(T));\n  }\n  const DependentSizedArrayType *getAsDependentSizedArrayType(QualType T)\n    const {\n    return dyn_cast_or_null<DependentSizedArrayType>(getAsArrayType(T));\n  }\n\n  /// Return the innermost element type of an array type.\n  ///\n  /// For example, will return \"int\" for int[m][n]\n  QualType getBaseElementType(const ArrayType *VAT) const;\n\n  /// Return the innermost element type of a type (which needn't\n  /// actually be an array type).\n  QualType getBaseElementType(QualType QT) const;\n\n  /// Return number of constant array elements.\n  uint64_t getConstantArrayElementCount(const ConstantArrayType *CA) const;\n\n  /// Perform adjustment on the parameter type of a function.\n  ///\n  /// This routine adjusts the given parameter type @p T to the actual\n  /// parameter type used by semantic analysis (C99 6.7.5.3p[7,8],\n  /// C++ [dcl.fct]p3). The adjusted parameter type is returned.\n  QualType getAdjustedParameterType(QualType T) const;\n\n  /// Retrieve the parameter type as adjusted for use in the signature\n  /// of a function, decaying array and function types and removing top-level\n  /// cv-qualifiers.\n  QualType getSignatureParameterType(QualType T) const;\n\n  QualType getExceptionObjectType(QualType T) const;\n\n  /// Return the properly qualified result of decaying the specified\n  /// array type to a pointer.\n  ///\n  /// This operation is non-trivial when handling typedefs etc.  The canonical\n  /// type of \\p T must be an array type, this returns a pointer to a properly\n  /// qualified element of the array.\n  ///\n  /// See C99 6.7.5.3p7 and C99 6.3.2.1p3.\n  QualType getArrayDecayedType(QualType T) const;\n\n  /// Return the type that \\p PromotableType will promote to: C99\n  /// 6.3.1.1p2, assuming that \\p PromotableType is a promotable integer type.\n  QualType getPromotedIntegerType(QualType PromotableType) const;\n\n  /// Recurses in pointer/array types until it finds an Objective-C\n  /// retainable type and returns its ownership.\n  Qualifiers::ObjCLifetime getInnerObjCOwnership(QualType T) const;\n\n  /// Whether this is a promotable bitfield reference according\n  /// to C99 6.3.1.1p2, bullet 2 (and GCC extensions).\n  ///\n  /// \\returns the type this bit-field will promote to, or NULL if no\n  /// promotion occurs.\n  QualType isPromotableBitField(Expr *E) const;\n\n  /// Return the highest ranked integer type, see C99 6.3.1.8p1.\n  ///\n  /// If \\p LHS > \\p RHS, returns 1.  If \\p LHS == \\p RHS, returns 0.  If\n  /// \\p LHS < \\p RHS, return -1.\n  int getIntegerTypeOrder(QualType LHS, QualType RHS) const;\n\n  /// Compare the rank of the two specified floating point types,\n  /// ignoring the domain of the type (i.e. 'double' == '_Complex double').\n  ///\n  /// If \\p LHS > \\p RHS, returns 1.  If \\p LHS == \\p RHS, returns 0.  If\n  /// \\p LHS < \\p RHS, return -1.\n  int getFloatingTypeOrder(QualType LHS, QualType RHS) const;\n\n  /// Compare the rank of two floating point types as above, but compare equal\n  /// if both types have the same floating-point semantics on the target (i.e.\n  /// long double and double on AArch64 will return 0).\n  int getFloatingTypeSemanticOrder(QualType LHS, QualType RHS) const;\n\n  /// Return a real floating point or a complex type (based on\n  /// \\p typeDomain/\\p typeSize).\n  ///\n  /// \\param typeDomain a real floating point or complex type.\n  /// \\param typeSize a real floating point or complex type.\n  QualType getFloatingTypeOfSizeWithinDomain(QualType typeSize,\n                                             QualType typeDomain) const;\n\n  unsigned getTargetAddressSpace(QualType T) const {\n    return getTargetAddressSpace(T.getQualifiers());\n  }\n\n  unsigned getTargetAddressSpace(Qualifiers Q) const {\n    return getTargetAddressSpace(Q.getAddressSpace());\n  }\n\n  unsigned getTargetAddressSpace(LangAS AS) const;\n\n  LangAS getLangASForBuiltinAddressSpace(unsigned AS) const;\n\n  /// Get target-dependent integer value for null pointer which is used for\n  /// constant folding.\n  uint64_t getTargetNullPointerValue(QualType QT) const;\n\n  bool addressSpaceMapManglingFor(LangAS AS) const {\n    return AddrSpaceMapMangling || isTargetAddressSpace(AS);\n  }\n\nprivate:\n  // Helper for integer ordering\n  unsigned getIntegerRank(const Type *T) const;\n\npublic:\n  //===--------------------------------------------------------------------===//\n  //                    Type Compatibility Predicates\n  //===--------------------------------------------------------------------===//\n\n  /// Compatibility predicates used to check assignment expressions.\n  bool typesAreCompatible(QualType T1, QualType T2,\n                          bool CompareUnqualified = false); // C99 6.2.7p1\n\n  bool propertyTypesAreCompatible(QualType, QualType);\n  bool typesAreBlockPointerCompatible(QualType, QualType);\n\n  bool isObjCIdType(QualType T) const {\n    return T == getObjCIdType();\n  }\n\n  bool isObjCClassType(QualType T) const {\n    return T == getObjCClassType();\n  }\n\n  bool isObjCSelType(QualType T) const {\n    return T == getObjCSelType();\n  }\n\n  bool ObjCQualifiedIdTypesAreCompatible(const ObjCObjectPointerType *LHS,\n                                         const ObjCObjectPointerType *RHS,\n                                         bool ForCompare);\n\n  bool ObjCQualifiedClassTypesAreCompatible(const ObjCObjectPointerType *LHS,\n                                            const ObjCObjectPointerType *RHS);\n\n  // Check the safety of assignment from LHS to RHS\n  bool canAssignObjCInterfaces(const ObjCObjectPointerType *LHSOPT,\n                               const ObjCObjectPointerType *RHSOPT);\n  bool canAssignObjCInterfaces(const ObjCObjectType *LHS,\n                               const ObjCObjectType *RHS);\n  bool canAssignObjCInterfacesInBlockPointer(\n                                          const ObjCObjectPointerType *LHSOPT,\n                                          const ObjCObjectPointerType *RHSOPT,\n                                          bool BlockReturnType);\n  bool areComparableObjCPointerTypes(QualType LHS, QualType RHS);\n  QualType areCommonBaseCompatible(const ObjCObjectPointerType *LHSOPT,\n                                   const ObjCObjectPointerType *RHSOPT);\n  bool canBindObjCObjectType(QualType To, QualType From);\n\n  // Functions for calculating composite types\n  QualType mergeTypes(QualType, QualType, bool OfBlockPointer=false,\n                      bool Unqualified = false, bool BlockReturnType = false);\n  QualType mergeFunctionTypes(QualType, QualType, bool OfBlockPointer=false,\n                              bool Unqualified = false, bool AllowCXX = false);\n  QualType mergeFunctionParameterTypes(QualType, QualType,\n                                       bool OfBlockPointer = false,\n                                       bool Unqualified = false);\n  QualType mergeTransparentUnionType(QualType, QualType,\n                                     bool OfBlockPointer=false,\n                                     bool Unqualified = false);\n\n  QualType mergeObjCGCQualifiers(QualType, QualType);\n\n  /// This function merges the ExtParameterInfo lists of two functions. It\n  /// returns true if the lists are compatible. The merged list is returned in\n  /// NewParamInfos.\n  ///\n  /// \\param FirstFnType The type of the first function.\n  ///\n  /// \\param SecondFnType The type of the second function.\n  ///\n  /// \\param CanUseFirst This flag is set to true if the first function's\n  /// ExtParameterInfo list can be used as the composite list of\n  /// ExtParameterInfo.\n  ///\n  /// \\param CanUseSecond This flag is set to true if the second function's\n  /// ExtParameterInfo list can be used as the composite list of\n  /// ExtParameterInfo.\n  ///\n  /// \\param NewParamInfos The composite list of ExtParameterInfo. The list is\n  /// empty if none of the flags are set.\n  ///\n  bool mergeExtParameterInfo(\n      const FunctionProtoType *FirstFnType,\n      const FunctionProtoType *SecondFnType,\n      bool &CanUseFirst, bool &CanUseSecond,\n      SmallVectorImpl<FunctionProtoType::ExtParameterInfo> &NewParamInfos);\n\n  void ResetObjCLayout(const ObjCContainerDecl *CD);\n\n  //===--------------------------------------------------------------------===//\n  //                    Integer Predicates\n  //===--------------------------------------------------------------------===//\n\n  // The width of an integer, as defined in C99 6.2.6.2. This is the number\n  // of bits in an integer type excluding any padding bits.\n  unsigned getIntWidth(QualType T) const;\n\n  // Per C99 6.2.5p6, for every signed integer type, there is a corresponding\n  // unsigned integer type.  This method takes a signed type, and returns the\n  // corresponding unsigned integer type.\n  // With the introduction of fixed point types in ISO N1169, this method also\n  // accepts fixed point types and returns the corresponding unsigned type for\n  // a given fixed point type.\n  QualType getCorrespondingUnsignedType(QualType T) const;\n\n  // Per ISO N1169, this method accepts fixed point types and returns the\n  // corresponding saturated type for a given fixed point type.\n  QualType getCorrespondingSaturatedType(QualType Ty) const;\n\n  // This method accepts fixed point types and returns the corresponding signed\n  // type. Unlike getCorrespondingUnsignedType(), this only accepts unsigned\n  // fixed point types because there are unsigned integer types like bool and\n  // char8_t that don't have signed equivalents.\n  QualType getCorrespondingSignedFixedPointType(QualType Ty) const;\n\n  //===--------------------------------------------------------------------===//\n  //                    Integer Values\n  //===--------------------------------------------------------------------===//\n\n  /// Make an APSInt of the appropriate width and signedness for the\n  /// given \\p Value and integer \\p Type.\n  llvm::APSInt MakeIntValue(uint64_t Value, QualType Type) const {\n    // If Type is a signed integer type larger than 64 bits, we need to be sure\n    // to sign extend Res appropriately.\n    llvm::APSInt Res(64, !Type->isSignedIntegerOrEnumerationType());\n    Res = Value;\n    unsigned Width = getIntWidth(Type);\n    if (Width != Res.getBitWidth())\n      return Res.extOrTrunc(Width);\n    return Res;\n  }\n\n  bool isSentinelNullExpr(const Expr *E);\n\n  /// Get the implementation of the ObjCInterfaceDecl \\p D, or nullptr if\n  /// none exists.\n  ObjCImplementationDecl *getObjCImplementation(ObjCInterfaceDecl *D);\n\n  /// Get the implementation of the ObjCCategoryDecl \\p D, or nullptr if\n  /// none exists.\n  ObjCCategoryImplDecl *getObjCImplementation(ObjCCategoryDecl *D);\n\n  /// Return true if there is at least one \\@implementation in the TU.\n  bool AnyObjCImplementation() {\n    return !ObjCImpls.empty();\n  }\n\n  /// Set the implementation of ObjCInterfaceDecl.\n  void setObjCImplementation(ObjCInterfaceDecl *IFaceD,\n                             ObjCImplementationDecl *ImplD);\n\n  /// Set the implementation of ObjCCategoryDecl.\n  void setObjCImplementation(ObjCCategoryDecl *CatD,\n                             ObjCCategoryImplDecl *ImplD);\n\n  /// Get the duplicate declaration of a ObjCMethod in the same\n  /// interface, or null if none exists.\n  const ObjCMethodDecl *\n  getObjCMethodRedeclaration(const ObjCMethodDecl *MD) const;\n\n  void setObjCMethodRedeclaration(const ObjCMethodDecl *MD,\n                                  const ObjCMethodDecl *Redecl);\n\n  /// Returns the Objective-C interface that \\p ND belongs to if it is\n  /// an Objective-C method/property/ivar etc. that is part of an interface,\n  /// otherwise returns null.\n  const ObjCInterfaceDecl *getObjContainingInterface(const NamedDecl *ND) const;\n\n  /// Set the copy initialization expression of a block var decl. \\p CanThrow\n  /// indicates whether the copy expression can throw or not.\n  void setBlockVarCopyInit(const VarDecl* VD, Expr *CopyExpr, bool CanThrow);\n\n  /// Get the copy initialization expression of the VarDecl \\p VD, or\n  /// nullptr if none exists.\n  BlockVarCopyInit getBlockVarCopyInit(const VarDecl* VD) const;\n\n  /// Allocate an uninitialized TypeSourceInfo.\n  ///\n  /// The caller should initialize the memory held by TypeSourceInfo using\n  /// the TypeLoc wrappers.\n  ///\n  /// \\param T the type that will be the basis for type source info. This type\n  /// should refer to how the declarator was written in source code, not to\n  /// what type semantic analysis resolved the declarator to.\n  ///\n  /// \\param Size the size of the type info to create, or 0 if the size\n  /// should be calculated based on the type.\n  TypeSourceInfo *CreateTypeSourceInfo(QualType T, unsigned Size = 0) const;\n\n  /// Allocate a TypeSourceInfo where all locations have been\n  /// initialized to a given location, which defaults to the empty\n  /// location.\n  TypeSourceInfo *\n  getTrivialTypeSourceInfo(QualType T,\n                           SourceLocation Loc = SourceLocation()) const;\n\n  /// Add a deallocation callback that will be invoked when the\n  /// ASTContext is destroyed.\n  ///\n  /// \\param Callback A callback function that will be invoked on destruction.\n  ///\n  /// \\param Data Pointer data that will be provided to the callback function\n  /// when it is called.\n  void AddDeallocation(void (*Callback)(void *), void *Data) const;\n\n  /// If T isn't trivially destructible, calls AddDeallocation to register it\n  /// for destruction.\n  template <typename T> void addDestruction(T *Ptr) const {\n    if (!std::is_trivially_destructible<T>::value) {\n      auto DestroyPtr = [](void *V) { static_cast<T *>(V)->~T(); };\n      AddDeallocation(DestroyPtr, Ptr);\n    }\n  }\n\n  GVALinkage GetGVALinkageForFunction(const FunctionDecl *FD) const;\n  GVALinkage GetGVALinkageForVariable(const VarDecl *VD);\n\n  /// Determines if the decl can be CodeGen'ed or deserialized from PCH\n  /// lazily, only when used; this is only relevant for function or file scoped\n  /// var definitions.\n  ///\n  /// \\returns true if the function/var must be CodeGen'ed/deserialized even if\n  /// it is not used.\n  bool DeclMustBeEmitted(const Decl *D);\n\n  /// Visits all versions of a multiversioned function with the passed\n  /// predicate.\n  void forEachMultiversionedFunctionVersion(\n      const FunctionDecl *FD,\n      llvm::function_ref<void(FunctionDecl *)> Pred) const;\n\n  const CXXConstructorDecl *\n  getCopyConstructorForExceptionObject(CXXRecordDecl *RD);\n\n  void addCopyConstructorForExceptionObject(CXXRecordDecl *RD,\n                                            CXXConstructorDecl *CD);\n\n  void addTypedefNameForUnnamedTagDecl(TagDecl *TD, TypedefNameDecl *TND);\n\n  TypedefNameDecl *getTypedefNameForUnnamedTagDecl(const TagDecl *TD);\n\n  void addDeclaratorForUnnamedTagDecl(TagDecl *TD, DeclaratorDecl *DD);\n\n  DeclaratorDecl *getDeclaratorForUnnamedTagDecl(const TagDecl *TD);\n\n  void setManglingNumber(const NamedDecl *ND, unsigned Number);\n  unsigned getManglingNumber(const NamedDecl *ND) const;\n\n  void setStaticLocalNumber(const VarDecl *VD, unsigned Number);\n  unsigned getStaticLocalNumber(const VarDecl *VD) const;\n\n  /// Retrieve the context for computing mangling numbers in the given\n  /// DeclContext.\n  MangleNumberingContext &getManglingNumberContext(const DeclContext *DC);\n  enum NeedExtraManglingDecl_t { NeedExtraManglingDecl };\n  MangleNumberingContext &getManglingNumberContext(NeedExtraManglingDecl_t,\n                                                   const Decl *D);\n\n  std::unique_ptr<MangleNumberingContext> createMangleNumberingContext() const;\n\n  /// Used by ParmVarDecl to store on the side the\n  /// index of the parameter when it exceeds the size of the normal bitfield.\n  void setParameterIndex(const ParmVarDecl *D, unsigned index);\n\n  /// Used by ParmVarDecl to retrieve on the side the\n  /// index of the parameter when it exceeds the size of the normal bitfield.\n  unsigned getParameterIndex(const ParmVarDecl *D) const;\n\n  /// Return a string representing the human readable name for the specified\n  /// function declaration or file name. Used by SourceLocExpr and\n  /// PredefinedExpr to cache evaluated results.\n  StringLiteral *getPredefinedStringLiteralFromCache(StringRef Key) const;\n\n  /// Return a declaration for the global GUID object representing the given\n  /// GUID value.\n  MSGuidDecl *getMSGuidDecl(MSGuidDeclParts Parts) const;\n\n  /// Return the template parameter object of the given type with the given\n  /// value.\n  TemplateParamObjectDecl *getTemplateParamObjectDecl(QualType T,\n                                                      const APValue &V) const;\n\n  /// Parses the target attributes passed in, and returns only the ones that are\n  /// valid feature names.\n  ParsedTargetAttr filterFunctionTargetAttrs(const TargetAttr *TD) const;\n\n  void getFunctionFeatureMap(llvm::StringMap<bool> &FeatureMap,\n                             const FunctionDecl *) const;\n  void getFunctionFeatureMap(llvm::StringMap<bool> &FeatureMap,\n                             GlobalDecl GD) const;\n\n  //===--------------------------------------------------------------------===//\n  //                    Statistics\n  //===--------------------------------------------------------------------===//\n\n  /// The number of implicitly-declared default constructors.\n  unsigned NumImplicitDefaultConstructors = 0;\n\n  /// The number of implicitly-declared default constructors for\n  /// which declarations were built.\n  unsigned NumImplicitDefaultConstructorsDeclared = 0;\n\n  /// The number of implicitly-declared copy constructors.\n  unsigned NumImplicitCopyConstructors = 0;\n\n  /// The number of implicitly-declared copy constructors for\n  /// which declarations were built.\n  unsigned NumImplicitCopyConstructorsDeclared = 0;\n\n  /// The number of implicitly-declared move constructors.\n  unsigned NumImplicitMoveConstructors = 0;\n\n  /// The number of implicitly-declared move constructors for\n  /// which declarations were built.\n  unsigned NumImplicitMoveConstructorsDeclared = 0;\n\n  /// The number of implicitly-declared copy assignment operators.\n  unsigned NumImplicitCopyAssignmentOperators = 0;\n\n  /// The number of implicitly-declared copy assignment operators for\n  /// which declarations were built.\n  unsigned NumImplicitCopyAssignmentOperatorsDeclared = 0;\n\n  /// The number of implicitly-declared move assignment operators.\n  unsigned NumImplicitMoveAssignmentOperators = 0;\n\n  /// The number of implicitly-declared move assignment operators for\n  /// which declarations were built.\n  unsigned NumImplicitMoveAssignmentOperatorsDeclared = 0;\n\n  /// The number of implicitly-declared destructors.\n  unsigned NumImplicitDestructors = 0;\n\n  /// The number of implicitly-declared destructors for which\n  /// declarations were built.\n  unsigned NumImplicitDestructorsDeclared = 0;\n\npublic:\n  /// Initialize built-in types.\n  ///\n  /// This routine may only be invoked once for a given ASTContext object.\n  /// It is normally invoked after ASTContext construction.\n  ///\n  /// \\param Target The target\n  void InitBuiltinTypes(const TargetInfo &Target,\n                        const TargetInfo *AuxTarget = nullptr);\n\nprivate:\n  void InitBuiltinType(CanQualType &R, BuiltinType::Kind K);\n\n  class ObjCEncOptions {\n    unsigned Bits;\n\n    ObjCEncOptions(unsigned Bits) : Bits(Bits) {}\n\n  public:\n    ObjCEncOptions() : Bits(0) {}\n    ObjCEncOptions(const ObjCEncOptions &RHS) : Bits(RHS.Bits) {}\n\n#define OPT_LIST(V)                                                            \\\n  V(ExpandPointedToStructures, 0)                                              \\\n  V(ExpandStructures, 1)                                                       \\\n  V(IsOutermostType, 2)                                                        \\\n  V(EncodingProperty, 3)                                                       \\\n  V(IsStructField, 4)                                                          \\\n  V(EncodeBlockParameters, 5)                                                  \\\n  V(EncodeClassNames, 6)                                                       \\\n\n#define V(N,I) ObjCEncOptions& set##N() { Bits |= 1 << I; return *this; }\nOPT_LIST(V)\n#undef V\n\n#define V(N,I) bool N() const { return Bits & 1 << I; }\nOPT_LIST(V)\n#undef V\n\n#undef OPT_LIST\n\n    LLVM_NODISCARD ObjCEncOptions keepingOnly(ObjCEncOptions Mask) const {\n      return Bits & Mask.Bits;\n    }\n\n    LLVM_NODISCARD ObjCEncOptions forComponentType() const {\n      ObjCEncOptions Mask = ObjCEncOptions()\n                                .setIsOutermostType()\n                                .setIsStructField();\n      return Bits & ~Mask.Bits;\n    }\n  };\n\n  // Return the Objective-C type encoding for a given type.\n  void getObjCEncodingForTypeImpl(QualType t, std::string &S,\n                                  ObjCEncOptions Options,\n                                  const FieldDecl *Field,\n                                  QualType *NotEncodedT = nullptr) const;\n\n  // Adds the encoding of the structure's members.\n  void getObjCEncodingForStructureImpl(RecordDecl *RD, std::string &S,\n                                       const FieldDecl *Field,\n                                       bool includeVBases = true,\n                                       QualType *NotEncodedT=nullptr) const;\n\npublic:\n  // Adds the encoding of a method parameter or return type.\n  void getObjCEncodingForMethodParameter(Decl::ObjCDeclQualifier QT,\n                                         QualType T, std::string& S,\n                                         bool Extended) const;\n\n  /// Returns true if this is an inline-initialized static data member\n  /// which is treated as a definition for MSVC compatibility.\n  bool isMSStaticDataMemberInlineDefinition(const VarDecl *VD) const;\n\n  enum class InlineVariableDefinitionKind {\n    /// Not an inline variable.\n    None,\n\n    /// Weak definition of inline variable.\n    Weak,\n\n    /// Weak for now, might become strong later in this TU.\n    WeakUnknown,\n\n    /// Strong definition.\n    Strong\n  };\n\n  /// Determine whether a definition of this inline variable should\n  /// be treated as a weak or strong definition. For compatibility with\n  /// C++14 and before, for a constexpr static data member, if there is an\n  /// out-of-line declaration of the member, we may promote it from weak to\n  /// strong.\n  InlineVariableDefinitionKind\n  getInlineVariableDefinitionKind(const VarDecl *VD) const;\n\nprivate:\n  friend class DeclarationNameTable;\n  friend class DeclContext;\n\n  const ASTRecordLayout &\n  getObjCLayout(const ObjCInterfaceDecl *D,\n                const ObjCImplementationDecl *Impl) const;\n\n  /// A set of deallocations that should be performed when the\n  /// ASTContext is destroyed.\n  // FIXME: We really should have a better mechanism in the ASTContext to\n  // manage running destructors for types which do variable sized allocation\n  // within the AST. In some places we thread the AST bump pointer allocator\n  // into the datastructures which avoids this mess during deallocation but is\n  // wasteful of memory, and here we require a lot of error prone book keeping\n  // in order to track and run destructors while we're tearing things down.\n  using DeallocationFunctionsAndArguments =\n      llvm::SmallVector<std::pair<void (*)(void *), void *>, 16>;\n  mutable DeallocationFunctionsAndArguments Deallocations;\n\n  // FIXME: This currently contains the set of StoredDeclMaps used\n  // by DeclContext objects.  This probably should not be in ASTContext,\n  // but we include it here so that ASTContext can quickly deallocate them.\n  llvm::PointerIntPair<StoredDeclsMap *, 1> LastSDM;\n\n  std::vector<Decl *> TraversalScope;\n\n  std::unique_ptr<VTableContextBase> VTContext;\n\n  void ReleaseDeclContextMaps();\n\npublic:\n  enum PragmaSectionFlag : unsigned {\n    PSF_None = 0,\n    PSF_Read = 0x1,\n    PSF_Write = 0x2,\n    PSF_Execute = 0x4,\n    PSF_Implicit = 0x8,\n    PSF_ZeroInit = 0x10,\n    PSF_Invalid = 0x80000000U,\n  };\n\n  struct SectionInfo {\n    NamedDecl *Decl;\n    SourceLocation PragmaSectionLocation;\n    int SectionFlags;\n\n    SectionInfo() = default;\n    SectionInfo(NamedDecl *Decl, SourceLocation PragmaSectionLocation,\n                int SectionFlags)\n        : Decl(Decl), PragmaSectionLocation(PragmaSectionLocation),\n          SectionFlags(SectionFlags) {}\n  };\n\n  llvm::StringMap<SectionInfo> SectionInfos;\n\n  /// Return a new OMPTraitInfo object owned by this context.\n  OMPTraitInfo &getNewOMPTraitInfo();\n\n  /// Whether a C++ static variable may be externalized.\n  bool mayExternalizeStaticVar(const Decl *D) const;\n\n  /// Whether a C++ static variable should be externalized.\n  bool shouldExternalizeStaticVar(const Decl *D) const;\n\n  StringRef getCUIDHash() const;\n\nprivate:\n  /// All OMPTraitInfo objects live in this collection, one per\n  /// `pragma omp [begin] declare variant` directive.\n  SmallVector<std::unique_ptr<OMPTraitInfo>, 4> OMPTraitInfoVector;\n};\n\n/// Insertion operator for diagnostics.\nconst StreamingDiagnostic &operator<<(const StreamingDiagnostic &DB,\n                                      const ASTContext::SectionInfo &Section);\n\n/// Utility function for constructing a nullary selector.\ninline Selector GetNullarySelector(StringRef name, ASTContext &Ctx) {\n  IdentifierInfo* II = &Ctx.Idents.get(name);\n  return Ctx.Selectors.getSelector(0, &II);\n}\n\n/// Utility function for constructing an unary selector.\ninline Selector GetUnarySelector(StringRef name, ASTContext &Ctx) {\n  IdentifierInfo* II = &Ctx.Idents.get(name);\n  return Ctx.Selectors.getSelector(1, &II);\n}\n\n} // namespace clang\n\n// operator new and delete aren't allowed inside namespaces.\n\n/// Placement new for using the ASTContext's allocator.\n///\n/// This placement form of operator new uses the ASTContext's allocator for\n/// obtaining memory.\n///\n/// IMPORTANT: These are also declared in clang/AST/ASTContextAllocate.h!\n/// Any changes here need to also be made there.\n///\n/// We intentionally avoid using a nothrow specification here so that the calls\n/// to this operator will not perform a null check on the result -- the\n/// underlying allocator never returns null pointers.\n///\n/// Usage looks like this (assuming there's an ASTContext 'Context' in scope):\n/// @code\n/// // Default alignment (8)\n/// IntegerLiteral *Ex = new (Context) IntegerLiteral(arguments);\n/// // Specific alignment\n/// IntegerLiteral *Ex2 = new (Context, 4) IntegerLiteral(arguments);\n/// @endcode\n/// Memory allocated through this placement new operator does not need to be\n/// explicitly freed, as ASTContext will free all of this memory when it gets\n/// destroyed. Please note that you cannot use delete on the pointer.\n///\n/// @param Bytes The number of bytes to allocate. Calculated by the compiler.\n/// @param C The ASTContext that provides the allocator.\n/// @param Alignment The alignment of the allocated memory (if the underlying\n///                  allocator supports it).\n/// @return The allocated memory. Could be nullptr.\ninline void *operator new(size_t Bytes, const clang::ASTContext &C,\n                          size_t Alignment /* = 8 */) {\n  return C.Allocate(Bytes, Alignment);\n}\n\n/// Placement delete companion to the new above.\n///\n/// This operator is just a companion to the new above. There is no way of\n/// invoking it directly; see the new operator for more details. This operator\n/// is called implicitly by the compiler if a placement new expression using\n/// the ASTContext throws in the object constructor.\ninline void operator delete(void *Ptr, const clang::ASTContext &C, size_t) {\n  C.Deallocate(Ptr);\n}\n\n/// This placement form of operator new[] uses the ASTContext's allocator for\n/// obtaining memory.\n///\n/// We intentionally avoid using a nothrow specification here so that the calls\n/// to this operator will not perform a null check on the result -- the\n/// underlying allocator never returns null pointers.\n///\n/// Usage looks like this (assuming there's an ASTContext 'Context' in scope):\n/// @code\n/// // Default alignment (8)\n/// char *data = new (Context) char[10];\n/// // Specific alignment\n/// char *data = new (Context, 4) char[10];\n/// @endcode\n/// Memory allocated through this placement new[] operator does not need to be\n/// explicitly freed, as ASTContext will free all of this memory when it gets\n/// destroyed. Please note that you cannot use delete on the pointer.\n///\n/// @param Bytes The number of bytes to allocate. Calculated by the compiler.\n/// @param C The ASTContext that provides the allocator.\n/// @param Alignment The alignment of the allocated memory (if the underlying\n///                  allocator supports it).\n/// @return The allocated memory. Could be nullptr.\ninline void *operator new[](size_t Bytes, const clang::ASTContext& C,\n                            size_t Alignment /* = 8 */) {\n  return C.Allocate(Bytes, Alignment);\n}\n\n/// Placement delete[] companion to the new[] above.\n///\n/// This operator is just a companion to the new[] above. There is no way of\n/// invoking it directly; see the new[] operator for more details. This operator\n/// is called implicitly by the compiler if a placement new[] expression using\n/// the ASTContext throws in the object constructor.\ninline void operator delete[](void *Ptr, const clang::ASTContext &C, size_t) {\n  C.Deallocate(Ptr);\n}\n\n/// Create the representation of a LazyGenerationalUpdatePtr.\ntemplate <typename Owner, typename T,\n          void (clang::ExternalASTSource::*Update)(Owner)>\ntypename clang::LazyGenerationalUpdatePtr<Owner, T, Update>::ValueType\n    clang::LazyGenerationalUpdatePtr<Owner, T, Update>::makeValue(\n        const clang::ASTContext &Ctx, T Value) {\n  // Note, this is implemented here so that ExternalASTSource.h doesn't need to\n  // include ASTContext.h. We explicitly instantiate it for all relevant types\n  // in ASTContext.cpp.\n  if (auto *Source = Ctx.getExternalSource())\n    return new (Ctx) LazyData(Source, Value);\n  return Value;\n}\n\n#endif // LLVM_CLANG_AST_ASTCONTEXT_H\n"}, "21": {"id": 21, "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/NSAPI.h", "content": "//===--- NSAPI.h - NSFoundation APIs ----------------------------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_AST_NSAPI_H\n#define LLVM_CLANG_AST_NSAPI_H\n\n#include \"clang/Basic/IdentifierTable.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/Optional.h\"\n\nnamespace clang {\n  class ASTContext;\n  class ObjCInterfaceDecl;\n  class QualType;\n  class Expr;\n\n// Provides info and caches identifiers/selectors for NSFoundation API.\nclass NSAPI {\npublic:\n  explicit NSAPI(ASTContext &Ctx);\n\n  ASTContext &getASTContext() const { return Ctx; }\n\n  enum NSClassIdKindKind {\n    ClassId_NSObject,\n    ClassId_NSString,\n    ClassId_NSArray,\n    ClassId_NSMutableArray,\n    ClassId_NSDictionary,\n    ClassId_NSMutableDictionary,\n    ClassId_NSNumber,\n    ClassId_NSMutableSet,\n    ClassId_NSMutableOrderedSet,\n    ClassId_NSValue\n  };\n  static const unsigned NumClassIds = 10;\n\n  enum NSStringMethodKind {\n    NSStr_stringWithString,\n    NSStr_stringWithUTF8String,\n    NSStr_stringWithCStringEncoding,\n    NSStr_stringWithCString,\n    NSStr_initWithString,\n    NSStr_initWithUTF8String\n  };\n  static const unsigned NumNSStringMethods = 6;\n\n  IdentifierInfo *getNSClassId(NSClassIdKindKind K) const;\n\n  /// The Objective-C NSString selectors.\n  Selector getNSStringSelector(NSStringMethodKind MK) const;\n\n  /// Returns true if the expression \\param E is a reference of\n  /// \"NSUTF8StringEncoding\" enum constant.\n  bool isNSUTF8StringEncodingConstant(const Expr *E) const {\n    return isObjCEnumerator(E, \"NSUTF8StringEncoding\", NSUTF8StringEncodingId);\n  }\n\n  /// Returns true if the expression \\param E is a reference of\n  /// \"NSASCIIStringEncoding\" enum constant.\n  bool isNSASCIIStringEncodingConstant(const Expr *E) const {\n    return isObjCEnumerator(E, \"NSASCIIStringEncoding\",NSASCIIStringEncodingId);\n  }\n\n  /// Enumerates the NSArray/NSMutableArray methods used to generate\n  /// literals and to apply some checks.\n  enum NSArrayMethodKind {\n    NSArr_array,\n    NSArr_arrayWithArray,\n    NSArr_arrayWithObject,\n    NSArr_arrayWithObjects,\n    NSArr_arrayWithObjectsCount,\n    NSArr_initWithArray,\n    NSArr_initWithObjects,\n    NSArr_objectAtIndex,\n    NSMutableArr_replaceObjectAtIndex,\n    NSMutableArr_addObject,\n    NSMutableArr_insertObjectAtIndex,\n    NSMutableArr_setObjectAtIndexedSubscript\n  };\n  static const unsigned NumNSArrayMethods = 12;\n\n  /// The Objective-C NSArray selectors.\n  Selector getNSArraySelector(NSArrayMethodKind MK) const;\n\n  /// Return NSArrayMethodKind if \\p Sel is such a selector.\n  Optional<NSArrayMethodKind> getNSArrayMethodKind(Selector Sel);\n\n  /// Enumerates the NSDictionary/NSMutableDictionary methods used\n  /// to generate literals and to apply some checks.\n  enum NSDictionaryMethodKind {\n    NSDict_dictionary,\n    NSDict_dictionaryWithDictionary,\n    NSDict_dictionaryWithObjectForKey,\n    NSDict_dictionaryWithObjectsForKeys,\n    NSDict_dictionaryWithObjectsForKeysCount,\n    NSDict_dictionaryWithObjectsAndKeys,\n    NSDict_initWithDictionary,\n    NSDict_initWithObjectsAndKeys,\n    NSDict_initWithObjectsForKeys,\n    NSDict_objectForKey,\n    NSMutableDict_setObjectForKey,\n    NSMutableDict_setObjectForKeyedSubscript,\n    NSMutableDict_setValueForKey\n  };\n  static const unsigned NumNSDictionaryMethods = 13;\n\n  /// The Objective-C NSDictionary selectors.\n  Selector getNSDictionarySelector(NSDictionaryMethodKind MK) const;\n\n  /// Return NSDictionaryMethodKind if \\p Sel is such a selector.\n  Optional<NSDictionaryMethodKind> getNSDictionaryMethodKind(Selector Sel);\n\n  /// Enumerates the NSMutableSet/NSOrderedSet methods used\n  /// to apply some checks.\n  enum NSSetMethodKind {\n    NSMutableSet_addObject,\n    NSOrderedSet_insertObjectAtIndex,\n    NSOrderedSet_setObjectAtIndex,\n    NSOrderedSet_setObjectAtIndexedSubscript,\n    NSOrderedSet_replaceObjectAtIndexWithObject\n  };\n  static const unsigned NumNSSetMethods = 5;\n\n  /// The Objective-C NSSet selectors.\n  Selector getNSSetSelector(NSSetMethodKind MK) const;\n\n  /// Return NSSetMethodKind if \\p Sel is such a selector.\n  Optional<NSSetMethodKind> getNSSetMethodKind(Selector Sel);\n\n  /// Returns selector for \"objectForKeyedSubscript:\".\n  Selector getObjectForKeyedSubscriptSelector() const {\n    return getOrInitSelector(StringRef(\"objectForKeyedSubscript\"),\n                             objectForKeyedSubscriptSel);\n  }\n\n  /// Returns selector for \"objectAtIndexedSubscript:\".\n  Selector getObjectAtIndexedSubscriptSelector() const {\n    return getOrInitSelector(StringRef(\"objectAtIndexedSubscript\"),\n                             objectAtIndexedSubscriptSel);\n  }\n\n  /// Returns selector for \"setObject:forKeyedSubscript\".\n  Selector getSetObjectForKeyedSubscriptSelector() const {\n    StringRef Ids[] = { \"setObject\", \"forKeyedSubscript\" };\n    return getOrInitSelector(Ids, setObjectForKeyedSubscriptSel);\n  }\n\n  /// Returns selector for \"setObject:atIndexedSubscript\".\n  Selector getSetObjectAtIndexedSubscriptSelector() const {\n    StringRef Ids[] = { \"setObject\", \"atIndexedSubscript\" };\n    return getOrInitSelector(Ids, setObjectAtIndexedSubscriptSel);\n  }\n\n  /// Returns selector for \"isEqual:\".\n  Selector getIsEqualSelector() const {\n    return getOrInitSelector(StringRef(\"isEqual\"), isEqualSel);\n  }\n\n  Selector getNewSelector() const {\n    return getOrInitNullarySelector(\"new\", NewSel);\n  }\n\n  Selector getInitSelector() const {\n    return getOrInitNullarySelector(\"init\", InitSel);\n  }\n\n  /// Enumerates the NSNumber methods used to generate literals.\n  enum NSNumberLiteralMethodKind {\n    NSNumberWithChar,\n    NSNumberWithUnsignedChar,\n    NSNumberWithShort,\n    NSNumberWithUnsignedShort,\n    NSNumberWithInt,\n    NSNumberWithUnsignedInt,\n    NSNumberWithLong,\n    NSNumberWithUnsignedLong,\n    NSNumberWithLongLong,\n    NSNumberWithUnsignedLongLong,\n    NSNumberWithFloat,\n    NSNumberWithDouble,\n    NSNumberWithBool,\n    NSNumberWithInteger,\n    NSNumberWithUnsignedInteger\n  };\n  static const unsigned NumNSNumberLiteralMethods = 15;\n\n  /// The Objective-C NSNumber selectors used to create NSNumber literals.\n  /// \\param Instance if true it will return the selector for the init* method\n  /// otherwise it will return the selector for the number* method.\n  Selector getNSNumberLiteralSelector(NSNumberLiteralMethodKind MK,\n                                      bool Instance) const;\n\n  bool isNSNumberLiteralSelector(NSNumberLiteralMethodKind MK,\n                                 Selector Sel) const {\n    return Sel == getNSNumberLiteralSelector(MK, false) ||\n           Sel == getNSNumberLiteralSelector(MK, true);\n  }\n\n  /// Return NSNumberLiteralMethodKind if \\p Sel is such a selector.\n  Optional<NSNumberLiteralMethodKind>\n      getNSNumberLiteralMethodKind(Selector Sel) const;\n\n  /// Determine the appropriate NSNumber factory method kind for a\n  /// literal of the given type.\n  Optional<NSNumberLiteralMethodKind>\n      getNSNumberFactoryMethodKind(QualType T) const;\n\n  /// Returns true if \\param T is a typedef of \"BOOL\" in objective-c.\n  bool isObjCBOOLType(QualType T) const;\n  /// Returns true if \\param T is a typedef of \"NSInteger\" in objective-c.\n  bool isObjCNSIntegerType(QualType T) const;\n  /// Returns true if \\param T is a typedef of \"NSUInteger\" in objective-c.\n  bool isObjCNSUIntegerType(QualType T) const;\n  /// Returns one of NSIntegral typedef names if \\param T is a typedef\n  /// of that name in objective-c.\n  StringRef GetNSIntegralKind(QualType T) const;\n\n  /// Returns \\c true if \\p Id is currently defined as a macro.\n  bool isMacroDefined(StringRef Id) const;\n\n  /// Returns \\c true if \\p InterfaceDecl is subclass of \\p NSClassKind\n  bool isSubclassOfNSClass(ObjCInterfaceDecl *InterfaceDecl,\n                           NSClassIdKindKind NSClassKind) const;\n\nprivate:\n  bool isObjCTypedef(QualType T, StringRef name, IdentifierInfo *&II) const;\n  bool isObjCEnumerator(const Expr *E,\n                        StringRef name, IdentifierInfo *&II) const;\n  Selector getOrInitSelector(ArrayRef<StringRef> Ids, Selector &Sel) const;\n  Selector getOrInitNullarySelector(StringRef Id, Selector &Sel) const;\n\n  ASTContext &Ctx;\n\n  mutable IdentifierInfo *ClassIds[NumClassIds];\n\n  mutable Selector NSStringSelectors[NumNSStringMethods];\n\n  /// The selectors for Objective-C NSArray methods.\n  mutable Selector NSArraySelectors[NumNSArrayMethods];\n\n  /// The selectors for Objective-C NSDictionary methods.\n  mutable Selector NSDictionarySelectors[NumNSDictionaryMethods];\n\n  /// The selectors for Objective-C NSSet methods.\n  mutable Selector NSSetSelectors[NumNSSetMethods];\n\n  /// The Objective-C NSNumber selectors used to create NSNumber literals.\n  mutable Selector NSNumberClassSelectors[NumNSNumberLiteralMethods];\n  mutable Selector NSNumberInstanceSelectors[NumNSNumberLiteralMethods];\n\n  mutable Selector objectForKeyedSubscriptSel, objectAtIndexedSubscriptSel,\n                   setObjectForKeyedSubscriptSel,setObjectAtIndexedSubscriptSel,\n                   isEqualSel, InitSel, NewSel;\n\n  mutable IdentifierInfo *BOOLId, *NSIntegerId, *NSUIntegerId;\n  mutable IdentifierInfo *NSASCIIStringEncodingId, *NSUTF8StringEncodingId;\n};\n\n}  // end namespace clang\n\n#endif // LLVM_CLANG_AST_NSAPI_H\n"}, "50": {"id": 50, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "content": "//===----- CGCall.h - Encapsulate calling convention details ----*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// These classes wrap the information about a call or function\n// definition used to handle ABI compliancy.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGCALL_H\n#define LLVM_CLANG_LIB_CODEGEN_CGCALL_H\n\n#include \"CGValue.h\"\n#include \"EHScopeStack.h\"\n#include \"clang/AST/ASTFwd.h\"\n#include \"clang/AST/CanonicalType.h\"\n#include \"clang/AST/GlobalDecl.h\"\n#include \"clang/AST/Type.h\"\n#include \"llvm/IR/Value.h\"\n\n// FIXME: Restructure so we don't have to expose so much stuff.\n#include \"ABIInfo.h\"\n\nnamespace llvm {\nclass AttributeList;\nclass Function;\nclass Type;\nclass Value;\n} // namespace llvm\n\nnamespace clang {\nclass ASTContext;\nclass Decl;\nclass FunctionDecl;\nclass ObjCMethodDecl;\nclass VarDecl;\n\nnamespace CodeGen {\n\n/// Abstract information about a function or function prototype.\nclass CGCalleeInfo {\n  /// The function prototype of the callee.\n  const FunctionProtoType *CalleeProtoTy;\n  /// The function declaration of the callee.\n  GlobalDecl CalleeDecl;\n\npublic:\n  explicit CGCalleeInfo() : CalleeProtoTy(nullptr), CalleeDecl() {}\n  CGCalleeInfo(const FunctionProtoType *calleeProtoTy, GlobalDecl calleeDecl)\n      : CalleeProtoTy(calleeProtoTy), CalleeDecl(calleeDecl) {}\n  CGCalleeInfo(const FunctionProtoType *calleeProtoTy)\n      : CalleeProtoTy(calleeProtoTy), CalleeDecl() {}\n  CGCalleeInfo(GlobalDecl calleeDecl)\n      : CalleeProtoTy(nullptr), CalleeDecl(calleeDecl) {}\n\n  const FunctionProtoType *getCalleeFunctionProtoType() const {\n    return CalleeProtoTy;\n  }\n  const GlobalDecl getCalleeDecl() const { return CalleeDecl; }\n};\n\n/// All available information about a concrete callee.\nclass CGCallee {\n  enum class SpecialKind : uintptr_t {\n    Invalid,\n    Builtin,\n    PseudoDestructor,\n    Virtual,\n\n    Last = Virtual\n  };\n\n  struct BuiltinInfoStorage {\n    const FunctionDecl *Decl;\n    unsigned ID;\n  };\n  struct PseudoDestructorInfoStorage {\n    const CXXPseudoDestructorExpr *Expr;\n  };\n  struct VirtualInfoStorage {\n    const CallExpr *CE;\n    GlobalDecl MD;\n    Address Addr;\n    llvm::FunctionType *FTy;\n  };\n\n  SpecialKind KindOrFunctionPointer;\n  union {\n    CGCalleeInfo AbstractInfo;\n    BuiltinInfoStorage BuiltinInfo;\n    PseudoDestructorInfoStorage PseudoDestructorInfo;\n    VirtualInfoStorage VirtualInfo;\n  };\n\n  explicit CGCallee(SpecialKind kind) : KindOrFunctionPointer(kind) {}\n\n  CGCallee(const FunctionDecl *builtinDecl, unsigned builtinID)\n      : KindOrFunctionPointer(SpecialKind::Builtin) {\n    BuiltinInfo.Decl = builtinDecl;\n    BuiltinInfo.ID = builtinID;\n  }\n\npublic:\n  CGCallee() : KindOrFunctionPointer(SpecialKind::Invalid) {}\n\n  /// Construct a callee.  Call this constructor directly when this\n  /// isn't a direct call.\n  CGCallee(const CGCalleeInfo &abstractInfo, llvm::Value *functionPtr)\n      : KindOrFunctionPointer(\n            SpecialKind(reinterpret_cast<uintptr_t>(functionPtr))) {\n    AbstractInfo = abstractInfo;\n    assert(functionPtr && \"configuring callee without function pointer\");\n    assert(functionPtr->getType()->isPointerTy());\n    assert(functionPtr->getType()->getPointerElementType()->isFunctionTy());\n  }\n\n  static CGCallee forBuiltin(unsigned builtinID,\n                             const FunctionDecl *builtinDecl) {\n    CGCallee result(SpecialKind::Builtin);\n    result.BuiltinInfo.Decl = builtinDecl;\n    result.BuiltinInfo.ID = builtinID;\n    return result;\n  }\n\n  static CGCallee forPseudoDestructor(const CXXPseudoDestructorExpr *E) {\n    CGCallee result(SpecialKind::PseudoDestructor);\n    result.PseudoDestructorInfo.Expr = E;\n    return result;\n  }\n\n  static CGCallee forDirect(llvm::Constant *functionPtr,\n                            const CGCalleeInfo &abstractInfo = CGCalleeInfo()) {\n    return CGCallee(abstractInfo, functionPtr);\n  }\n\n  static CGCallee forDirect(llvm::FunctionCallee functionPtr,\n                            const CGCalleeInfo &abstractInfo = CGCalleeInfo()) {\n    return CGCallee(abstractInfo, functionPtr.getCallee());\n  }\n\n  static CGCallee forVirtual(const CallExpr *CE, GlobalDecl MD, Address Addr,\n                             llvm::FunctionType *FTy) {\n    CGCallee result(SpecialKind::Virtual);\n    result.VirtualInfo.CE = CE;\n    result.VirtualInfo.MD = MD;\n    result.VirtualInfo.Addr = Addr;\n    result.VirtualInfo.FTy = FTy;\n    return result;\n  }\n\n  bool isBuiltin() const {\n    return KindOrFunctionPointer == SpecialKind::Builtin;\n  }\n  const FunctionDecl *getBuiltinDecl() const {\n    assert(isBuiltin());\n    return BuiltinInfo.Decl;\n  }\n  unsigned getBuiltinID() const {\n    assert(isBuiltin());\n    return BuiltinInfo.ID;\n  }\n\n  bool isPseudoDestructor() const {\n    return KindOrFunctionPointer == SpecialKind::PseudoDestructor;\n  }\n  const CXXPseudoDestructorExpr *getPseudoDestructorExpr() const {\n    assert(isPseudoDestructor());\n    return PseudoDestructorInfo.Expr;\n  }\n\n  bool isOrdinary() const {\n    return uintptr_t(KindOrFunctionPointer) > uintptr_t(SpecialKind::Last);\n  }\n  CGCalleeInfo getAbstractInfo() const {\n    if (isVirtual())\n      return VirtualInfo.MD;\n    assert(isOrdinary());\n    return AbstractInfo;\n  }\n  llvm::Value *getFunctionPointer() const {\n    assert(isOrdinary());\n    return reinterpret_cast<llvm::Value *>(uintptr_t(KindOrFunctionPointer));\n  }\n  void setFunctionPointer(llvm::Value *functionPtr) {\n    assert(isOrdinary());\n    KindOrFunctionPointer =\n        SpecialKind(reinterpret_cast<uintptr_t>(functionPtr));\n  }\n\n  bool isVirtual() const {\n    return KindOrFunctionPointer == SpecialKind::Virtual;\n  }\n  const CallExpr *getVirtualCallExpr() const {\n    assert(isVirtual());\n    return VirtualInfo.CE;\n  }\n  GlobalDecl getVirtualMethodDecl() const {\n    assert(isVirtual());\n    return VirtualInfo.MD;\n  }\n  Address getThisAddress() const {\n    assert(isVirtual());\n    return VirtualInfo.Addr;\n  }\n  llvm::FunctionType *getVirtualFunctionType() const {\n    assert(isVirtual());\n    return VirtualInfo.FTy;\n  }\n\n  /// If this is a delayed callee computation of some sort, prepare\n  /// a concrete callee.\n  CGCallee prepareConcreteCallee(CodeGenFunction &CGF) const;\n};\n\nstruct CallArg {\nprivate:\n  union {\n    RValue RV;\n    LValue LV; /// The argument is semantically a load from this l-value.\n  };\n  bool HasLV;\n\n  /// A data-flow flag to make sure getRValue and/or copyInto are not\n  /// called twice for duplicated IR emission.\n  mutable bool IsUsed;\n\npublic:\n  QualType Ty;\n  CallArg(RValue rv, QualType ty)\n      : RV(rv), HasLV(false), IsUsed(false), Ty(ty) {}\n  CallArg(LValue lv, QualType ty)\n      : LV(lv), HasLV(true), IsUsed(false), Ty(ty) {}\n  bool hasLValue() const { return HasLV; }\n  QualType getType() const { return Ty; }\n\n  /// \\returns an independent RValue. If the CallArg contains an LValue,\n  /// a temporary copy is returned.\n  RValue getRValue(CodeGenFunction &CGF) const;\n\n  LValue getKnownLValue() const {\n    assert(HasLV && !IsUsed);\n    return LV;\n  }\n  RValue getKnownRValue() const {\n    assert(!HasLV && !IsUsed);\n    return RV;\n  }\n  void setRValue(RValue _RV) {\n    assert(!HasLV);\n    RV = _RV;\n  }\n\n  bool isAggregate() const { return HasLV || RV.isAggregate(); }\n\n  void copyInto(CodeGenFunction &CGF, Address A) const;\n};\n\n/// CallArgList - Type for representing both the value and type of\n/// arguments in a call.\nclass CallArgList : public SmallVector<CallArg, 8> {\npublic:\n  CallArgList() : StackBase(nullptr) {}\n\n  struct Writeback {\n    /// The original argument.  Note that the argument l-value\n    /// is potentially null.\n    LValue Source;\n\n    /// The temporary alloca.\n    Address Temporary;\n\n    /// A value to \"use\" after the writeback, or null.\n    llvm::Value *ToUse;\n  };\n\n  struct CallArgCleanup {\n    EHScopeStack::stable_iterator Cleanup;\n\n    /// The \"is active\" insertion point.  This instruction is temporary and\n    /// will be removed after insertion.\n    llvm::Instruction *IsActiveIP;\n  };\n\n  void add(RValue rvalue, QualType type) { push_back(CallArg(rvalue, type)); }\n\n  void addUncopiedAggregate(LValue LV, QualType type) {\n    push_back(CallArg(LV, type));\n  }\n\n  /// Add all the arguments from another CallArgList to this one. After doing\n  /// this, the old CallArgList retains its list of arguments, but must not\n  /// be used to emit a call.\n  void addFrom(const CallArgList &other) {\n    insert(end(), other.begin(), other.end());\n    Writebacks.insert(Writebacks.end(), other.Writebacks.begin(),\n                      other.Writebacks.end());\n    CleanupsToDeactivate.insert(CleanupsToDeactivate.end(),\n                                other.CleanupsToDeactivate.begin(),\n                                other.CleanupsToDeactivate.end());\n    assert(!(StackBase && other.StackBase) && \"can't merge stackbases\");\n    if (!StackBase)\n      StackBase = other.StackBase;\n  }\n\n  void addWriteback(LValue srcLV, Address temporary, llvm::Value *toUse) {\n    Writeback writeback = {srcLV, temporary, toUse};\n    Writebacks.push_back(writeback);\n  }\n\n  bool hasWritebacks() const { return !Writebacks.empty(); }\n\n  typedef llvm::iterator_range<SmallVectorImpl<Writeback>::const_iterator>\n      writeback_const_range;\n\n  writeback_const_range writebacks() const {\n    return writeback_const_range(Writebacks.begin(), Writebacks.end());\n  }\n\n  void addArgCleanupDeactivation(EHScopeStack::stable_iterator Cleanup,\n                                 llvm::Instruction *IsActiveIP) {\n    CallArgCleanup ArgCleanup;\n    ArgCleanup.Cleanup = Cleanup;\n    ArgCleanup.IsActiveIP = IsActiveIP;\n    CleanupsToDeactivate.push_back(ArgCleanup);\n  }\n\n  ArrayRef<CallArgCleanup> getCleanupsToDeactivate() const {\n    return CleanupsToDeactivate;\n  }\n\n  void allocateArgumentMemory(CodeGenFunction &CGF);\n  llvm::Instruction *getStackBase() const { return StackBase; }\n  void freeArgumentMemory(CodeGenFunction &CGF) const;\n\n  /// Returns if we're using an inalloca struct to pass arguments in\n  /// memory.\n  bool isUsingInAlloca() const { return StackBase; }\n\nprivate:\n  SmallVector<Writeback, 1> Writebacks;\n\n  /// Deactivate these cleanups immediately before making the call.  This\n  /// is used to cleanup objects that are owned by the callee once the call\n  /// occurs.\n  SmallVector<CallArgCleanup, 1> CleanupsToDeactivate;\n\n  /// The stacksave call.  It dominates all of the argument evaluation.\n  llvm::CallInst *StackBase;\n};\n\n/// FunctionArgList - Type for representing both the decl and type\n/// of parameters to a function. The decl must be either a\n/// ParmVarDecl or ImplicitParamDecl.\nclass FunctionArgList : public SmallVector<const VarDecl *, 16> {};\n\n/// ReturnValueSlot - Contains the address where the return value of a\n/// function can be stored, and whether the address is volatile or not.\nclass ReturnValueSlot {\n  Address Addr = Address::invalid();\n\n  // Return value slot flags\n  unsigned IsVolatile : 1;\n  unsigned IsUnused : 1;\n  unsigned IsExternallyDestructed : 1;\n\npublic:\n  ReturnValueSlot()\n      : IsVolatile(false), IsUnused(false), IsExternallyDestructed(false) {}\n  ReturnValueSlot(Address Addr, bool IsVolatile, bool IsUnused = false,\n                  bool IsExternallyDestructed = false)\n      : Addr(Addr), IsVolatile(IsVolatile), IsUnused(IsUnused),\n        IsExternallyDestructed(IsExternallyDestructed) {}\n\n  bool isNull() const { return !Addr.isValid(); }\n  bool isVolatile() const { return IsVolatile; }\n  Address getValue() const { return Addr; }\n  bool isUnused() const { return IsUnused; }\n  bool isExternallyDestructed() const { return IsExternallyDestructed; }\n};\n\n} // end namespace CodeGen\n} // end namespace clang\n\n#endif\n"}, "51": {"id": 51, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCleanup.h", "content": "//===-- CGCleanup.h - Classes for cleanups IR generation --------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// These classes support the generation of LLVM IR for cleanups.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGCLEANUP_H\n#define LLVM_CLANG_LIB_CODEGEN_CGCLEANUP_H\n\n#include \"EHScopeStack.h\"\n\n#include \"Address.h\"\n#include \"llvm/ADT/SmallPtrSet.h\"\n#include \"llvm/ADT/SmallVector.h\"\n\nnamespace llvm {\nclass BasicBlock;\nclass Value;\nclass ConstantInt;\nclass AllocaInst;\n}\n\nnamespace clang {\nclass FunctionDecl;\nnamespace CodeGen {\nclass CodeGenModule;\nclass CodeGenFunction;\n\n/// The MS C++ ABI needs a pointer to RTTI data plus some flags to describe the\n/// type of a catch handler, so we use this wrapper.\nstruct CatchTypeInfo {\n  llvm::Constant *RTTI;\n  unsigned Flags;\n};\n\n/// A protected scope for zero-cost EH handling.\nclass EHScope {\n  llvm::BasicBlock *CachedLandingPad;\n  llvm::BasicBlock *CachedEHDispatchBlock;\n\n  EHScopeStack::stable_iterator EnclosingEHScope;\n\n  class CommonBitFields {\n    friend class EHScope;\n    unsigned Kind : 3;\n  };\n  enum { NumCommonBits = 3 };\n\nprotected:\n  class CatchBitFields {\n    friend class EHCatchScope;\n    unsigned : NumCommonBits;\n\n    unsigned NumHandlers : 32 - NumCommonBits;\n  };\n\n  class CleanupBitFields {\n    friend class EHCleanupScope;\n    unsigned : NumCommonBits;\n\n    /// Whether this cleanup needs to be run along normal edges.\n    unsigned IsNormalCleanup : 1;\n\n    /// Whether this cleanup needs to be run along exception edges.\n    unsigned IsEHCleanup : 1;\n\n    /// Whether this cleanup is currently active.\n    unsigned IsActive : 1;\n\n    /// Whether this cleanup is a lifetime marker\n    unsigned IsLifetimeMarker : 1;\n\n    /// Whether the normal cleanup should test the activation flag.\n    unsigned TestFlagInNormalCleanup : 1;\n\n    /// Whether the EH cleanup should test the activation flag.\n    unsigned TestFlagInEHCleanup : 1;\n\n    /// The amount of extra storage needed by the Cleanup.\n    /// Always a multiple of the scope-stack alignment.\n    unsigned CleanupSize : 12;\n  };\n\n  class FilterBitFields {\n    friend class EHFilterScope;\n    unsigned : NumCommonBits;\n\n    unsigned NumFilters : 32 - NumCommonBits;\n  };\n\n  union {\n    CommonBitFields CommonBits;\n    CatchBitFields CatchBits;\n    CleanupBitFields CleanupBits;\n    FilterBitFields FilterBits;\n  };\n\npublic:\n  enum Kind { Cleanup, Catch, Terminate, Filter };\n\n  EHScope(Kind kind, EHScopeStack::stable_iterator enclosingEHScope)\n    : CachedLandingPad(nullptr), CachedEHDispatchBlock(nullptr),\n      EnclosingEHScope(enclosingEHScope) {\n    CommonBits.Kind = kind;\n  }\n\n  Kind getKind() const { return static_cast<Kind>(CommonBits.Kind); }\n\n  llvm::BasicBlock *getCachedLandingPad() const {\n    return CachedLandingPad;\n  }\n\n  void setCachedLandingPad(llvm::BasicBlock *block) {\n    CachedLandingPad = block;\n  }\n\n  llvm::BasicBlock *getCachedEHDispatchBlock() const {\n    return CachedEHDispatchBlock;\n  }\n\n  void setCachedEHDispatchBlock(llvm::BasicBlock *block) {\n    CachedEHDispatchBlock = block;\n  }\n\n  bool hasEHBranches() const {\n    if (llvm::BasicBlock *block = getCachedEHDispatchBlock())\n      return !block->use_empty();\n    return false;\n  }\n\n  EHScopeStack::stable_iterator getEnclosingEHScope() const {\n    return EnclosingEHScope;\n  }\n};\n\n/// A scope which attempts to handle some, possibly all, types of\n/// exceptions.\n///\n/// Objective C \\@finally blocks are represented using a cleanup scope\n/// after the catch scope.\nclass EHCatchScope : public EHScope {\n  // In effect, we have a flexible array member\n  //   Handler Handlers[0];\n  // But that's only standard in C99, not C++, so we have to do\n  // annoying pointer arithmetic instead.\n\npublic:\n  struct Handler {\n    /// A type info value, or null (C++ null, not an LLVM null pointer)\n    /// for a catch-all.\n    CatchTypeInfo Type;\n\n    /// The catch handler for this type.\n    llvm::BasicBlock *Block;\n\n    bool isCatchAll() const { return Type.RTTI == nullptr; }\n  };\n\nprivate:\n  friend class EHScopeStack;\n\n  Handler *getHandlers() {\n    return reinterpret_cast<Handler*>(this+1);\n  }\n\n  const Handler *getHandlers() const {\n    return reinterpret_cast<const Handler*>(this+1);\n  }\n\npublic:\n  static size_t getSizeForNumHandlers(unsigned N) {\n    return sizeof(EHCatchScope) + N * sizeof(Handler);\n  }\n\n  EHCatchScope(unsigned numHandlers,\n               EHScopeStack::stable_iterator enclosingEHScope)\n    : EHScope(Catch, enclosingEHScope) {\n    CatchBits.NumHandlers = numHandlers;\n    assert(CatchBits.NumHandlers == numHandlers && \"NumHandlers overflow?\");\n  }\n\n  unsigned getNumHandlers() const {\n    return CatchBits.NumHandlers;\n  }\n\n  void setCatchAllHandler(unsigned I, llvm::BasicBlock *Block) {\n    setHandler(I, CatchTypeInfo{nullptr, 0}, Block);\n  }\n\n  void setHandler(unsigned I, llvm::Constant *Type, llvm::BasicBlock *Block) {\n    assert(I < getNumHandlers());\n    getHandlers()[I].Type = CatchTypeInfo{Type, 0};\n    getHandlers()[I].Block = Block;\n  }\n\n  void setHandler(unsigned I, CatchTypeInfo Type, llvm::BasicBlock *Block) {\n    assert(I < getNumHandlers());\n    getHandlers()[I].Type = Type;\n    getHandlers()[I].Block = Block;\n  }\n\n  const Handler &getHandler(unsigned I) const {\n    assert(I < getNumHandlers());\n    return getHandlers()[I];\n  }\n\n  // Clear all handler blocks.\n  // FIXME: it's better to always call clearHandlerBlocks in DTOR and have a\n  // 'takeHandler' or some such function which removes ownership from the\n  // EHCatchScope object if the handlers should live longer than EHCatchScope.\n  void clearHandlerBlocks() {\n    for (unsigned I = 0, N = getNumHandlers(); I != N; ++I)\n      delete getHandler(I).Block;\n  }\n\n  typedef const Handler *iterator;\n  iterator begin() const { return getHandlers(); }\n  iterator end() const { return getHandlers() + getNumHandlers(); }\n\n  static bool classof(const EHScope *Scope) {\n    return Scope->getKind() == Catch;\n  }\n};\n\n/// A cleanup scope which generates the cleanup blocks lazily.\nclass alignas(8) EHCleanupScope : public EHScope {\n  /// The nearest normal cleanup scope enclosing this one.\n  EHScopeStack::stable_iterator EnclosingNormal;\n\n  /// The nearest EH scope enclosing this one.\n  EHScopeStack::stable_iterator EnclosingEH;\n\n  /// The dual entry/exit block along the normal edge.  This is lazily\n  /// created if needed before the cleanup is popped.\n  llvm::BasicBlock *NormalBlock;\n\n  /// An optional i1 variable indicating whether this cleanup has been\n  /// activated yet.\n  llvm::AllocaInst *ActiveFlag;\n\n  /// Extra information required for cleanups that have resolved\n  /// branches through them.  This has to be allocated on the side\n  /// because everything on the cleanup stack has be trivially\n  /// movable.\n  struct ExtInfo {\n    /// The destinations of normal branch-afters and branch-throughs.\n    llvm::SmallPtrSet<llvm::BasicBlock*, 4> Branches;\n\n    /// Normal branch-afters.\n    SmallVector<std::pair<llvm::BasicBlock*,llvm::ConstantInt*>, 4>\n      BranchAfters;\n  };\n  mutable struct ExtInfo *ExtInfo;\n\n  /// The number of fixups required by enclosing scopes (not including\n  /// this one).  If this is the top cleanup scope, all the fixups\n  /// from this index onwards belong to this scope.\n  unsigned FixupDepth;\n\n  struct ExtInfo &getExtInfo() {\n    if (!ExtInfo) ExtInfo = new struct ExtInfo();\n    return *ExtInfo;\n  }\n\n  const struct ExtInfo &getExtInfo() const {\n    if (!ExtInfo) ExtInfo = new struct ExtInfo();\n    return *ExtInfo;\n  }\n\npublic:\n  /// Gets the size required for a lazy cleanup scope with the given\n  /// cleanup-data requirements.\n  static size_t getSizeForCleanupSize(size_t Size) {\n    return sizeof(EHCleanupScope) + Size;\n  }\n\n  size_t getAllocatedSize() const {\n    return sizeof(EHCleanupScope) + CleanupBits.CleanupSize;\n  }\n\n  EHCleanupScope(bool isNormal, bool isEH, unsigned cleanupSize,\n                 unsigned fixupDepth,\n                 EHScopeStack::stable_iterator enclosingNormal,\n                 EHScopeStack::stable_iterator enclosingEH)\n      : EHScope(EHScope::Cleanup, enclosingEH),\n        EnclosingNormal(enclosingNormal), NormalBlock(nullptr),\n        ActiveFlag(nullptr), ExtInfo(nullptr), FixupDepth(fixupDepth) {\n    CleanupBits.IsNormalCleanup = isNormal;\n    CleanupBits.IsEHCleanup = isEH;\n    CleanupBits.IsActive = true;\n    CleanupBits.IsLifetimeMarker = false;\n    CleanupBits.TestFlagInNormalCleanup = false;\n    CleanupBits.TestFlagInEHCleanup = false;\n    CleanupBits.CleanupSize = cleanupSize;\n\n    assert(CleanupBits.CleanupSize == cleanupSize && \"cleanup size overflow\");\n  }\n\n  void Destroy() {\n    delete ExtInfo;\n  }\n  // Objects of EHCleanupScope are not destructed. Use Destroy().\n  ~EHCleanupScope() = delete;\n\n  bool isNormalCleanup() const { return CleanupBits.IsNormalCleanup; }\n  llvm::BasicBlock *getNormalBlock() const { return NormalBlock; }\n  void setNormalBlock(llvm::BasicBlock *BB) { NormalBlock = BB; }\n\n  bool isEHCleanup() const { return CleanupBits.IsEHCleanup; }\n\n  bool isActive() const { return CleanupBits.IsActive; }\n  void setActive(bool A) { CleanupBits.IsActive = A; }\n\n  bool isLifetimeMarker() const { return CleanupBits.IsLifetimeMarker; }\n  void setLifetimeMarker() { CleanupBits.IsLifetimeMarker = true; }\n\n  bool hasActiveFlag() const { return ActiveFlag != nullptr; }\n  Address getActiveFlag() const {\n    return Address(ActiveFlag, CharUnits::One());\n  }\n  void setActiveFlag(Address Var) {\n    assert(Var.getAlignment().isOne());\n    ActiveFlag = cast<llvm::AllocaInst>(Var.getPointer());\n  }\n\n  void setTestFlagInNormalCleanup() {\n    CleanupBits.TestFlagInNormalCleanup = true;\n  }\n  bool shouldTestFlagInNormalCleanup() const {\n    return CleanupBits.TestFlagInNormalCleanup;\n  }\n\n  void setTestFlagInEHCleanup() {\n    CleanupBits.TestFlagInEHCleanup = true;\n  }\n  bool shouldTestFlagInEHCleanup() const {\n    return CleanupBits.TestFlagInEHCleanup;\n  }\n\n  unsigned getFixupDepth() const { return FixupDepth; }\n  EHScopeStack::stable_iterator getEnclosingNormalCleanup() const {\n    return EnclosingNormal;\n  }\n\n  size_t getCleanupSize() const { return CleanupBits.CleanupSize; }\n  void *getCleanupBuffer() { return this + 1; }\n\n  EHScopeStack::Cleanup *getCleanup() {\n    return reinterpret_cast<EHScopeStack::Cleanup*>(getCleanupBuffer());\n  }\n\n  /// True if this cleanup scope has any branch-afters or branch-throughs.\n  bool hasBranches() const { return ExtInfo && !ExtInfo->Branches.empty(); }\n\n  /// Add a branch-after to this cleanup scope.  A branch-after is a\n  /// branch from a point protected by this (normal) cleanup to a\n  /// point in the normal cleanup scope immediately containing it.\n  /// For example,\n  ///   for (;;) { A a; break; }\n  /// contains a branch-after.\n  ///\n  /// Branch-afters each have their own destination out of the\n  /// cleanup, guaranteed distinct from anything else threaded through\n  /// it.  Therefore branch-afters usually force a switch after the\n  /// cleanup.\n  void addBranchAfter(llvm::ConstantInt *Index,\n                      llvm::BasicBlock *Block) {\n    struct ExtInfo &ExtInfo = getExtInfo();\n    if (ExtInfo.Branches.insert(Block).second)\n      ExtInfo.BranchAfters.push_back(std::make_pair(Block, Index));\n  }\n\n  /// Return the number of unique branch-afters on this scope.\n  unsigned getNumBranchAfters() const {\n    return ExtInfo ? ExtInfo->BranchAfters.size() : 0;\n  }\n\n  llvm::BasicBlock *getBranchAfterBlock(unsigned I) const {\n    assert(I < getNumBranchAfters());\n    return ExtInfo->BranchAfters[I].first;\n  }\n\n  llvm::ConstantInt *getBranchAfterIndex(unsigned I) const {\n    assert(I < getNumBranchAfters());\n    return ExtInfo->BranchAfters[I].second;\n  }\n\n  /// Add a branch-through to this cleanup scope.  A branch-through is\n  /// a branch from a scope protected by this (normal) cleanup to an\n  /// enclosing scope other than the immediately-enclosing normal\n  /// cleanup scope.\n  ///\n  /// In the following example, the branch through B's scope is a\n  /// branch-through, while the branch through A's scope is a\n  /// branch-after:\n  ///   for (;;) { A a; B b; break; }\n  ///\n  /// All branch-throughs have a common destination out of the\n  /// cleanup, one possibly shared with the fall-through.  Therefore\n  /// branch-throughs usually don't force a switch after the cleanup.\n  ///\n  /// \\return true if the branch-through was new to this scope\n  bool addBranchThrough(llvm::BasicBlock *Block) {\n    return getExtInfo().Branches.insert(Block).second;\n  }\n\n  /// Determines if this cleanup scope has any branch throughs.\n  bool hasBranchThroughs() const {\n    if (!ExtInfo) return false;\n    return (ExtInfo->BranchAfters.size() != ExtInfo->Branches.size());\n  }\n\n  static bool classof(const EHScope *Scope) {\n    return (Scope->getKind() == Cleanup);\n  }\n};\n// NOTE: there's a bunch of different data classes tacked on after an\n// EHCleanupScope. It is asserted (in EHScopeStack::pushCleanup*) that\n// they don't require greater alignment than ScopeStackAlignment. So,\n// EHCleanupScope ought to have alignment equal to that -- not more\n// (would be misaligned by the stack allocator), and not less (would\n// break the appended classes).\nstatic_assert(alignof(EHCleanupScope) == EHScopeStack::ScopeStackAlignment,\n              \"EHCleanupScope expected alignment\");\n\n/// An exceptions scope which filters exceptions thrown through it.\n/// Only exceptions matching the filter types will be permitted to be\n/// thrown.\n///\n/// This is used to implement C++ exception specifications.\nclass EHFilterScope : public EHScope {\n  // Essentially ends in a flexible array member:\n  // llvm::Value *FilterTypes[0];\n\n  llvm::Value **getFilters() {\n    return reinterpret_cast<llvm::Value**>(this+1);\n  }\n\n  llvm::Value * const *getFilters() const {\n    return reinterpret_cast<llvm::Value* const *>(this+1);\n  }\n\npublic:\n  EHFilterScope(unsigned numFilters)\n    : EHScope(Filter, EHScopeStack::stable_end()) {\n    FilterBits.NumFilters = numFilters;\n    assert(FilterBits.NumFilters == numFilters && \"NumFilters overflow\");\n  }\n\n  static size_t getSizeForNumFilters(unsigned numFilters) {\n    return sizeof(EHFilterScope) + numFilters * sizeof(llvm::Value*);\n  }\n\n  unsigned getNumFilters() const { return FilterBits.NumFilters; }\n\n  void setFilter(unsigned i, llvm::Value *filterValue) {\n    assert(i < getNumFilters());\n    getFilters()[i] = filterValue;\n  }\n\n  llvm::Value *getFilter(unsigned i) const {\n    assert(i < getNumFilters());\n    return getFilters()[i];\n  }\n\n  static bool classof(const EHScope *scope) {\n    return scope->getKind() == Filter;\n  }\n};\n\n/// An exceptions scope which calls std::terminate if any exception\n/// reaches it.\nclass EHTerminateScope : public EHScope {\npublic:\n  EHTerminateScope(EHScopeStack::stable_iterator enclosingEHScope)\n    : EHScope(Terminate, enclosingEHScope) {}\n  static size_t getSize() { return sizeof(EHTerminateScope); }\n\n  static bool classof(const EHScope *scope) {\n    return scope->getKind() == Terminate;\n  }\n};\n\n/// A non-stable pointer into the scope stack.\nclass EHScopeStack::iterator {\n  char *Ptr;\n\n  friend class EHScopeStack;\n  explicit iterator(char *Ptr) : Ptr(Ptr) {}\n\npublic:\n  iterator() : Ptr(nullptr) {}\n\n  EHScope *get() const {\n    return reinterpret_cast<EHScope*>(Ptr);\n  }\n\n  EHScope *operator->() const { return get(); }\n  EHScope &operator*() const { return *get(); }\n\n  iterator &operator++() {\n    size_t Size;\n    switch (get()->getKind()) {\n    case EHScope::Catch:\n      Size = EHCatchScope::getSizeForNumHandlers(\n          static_cast<const EHCatchScope *>(get())->getNumHandlers());\n      break;\n\n    case EHScope::Filter:\n      Size = EHFilterScope::getSizeForNumFilters(\n          static_cast<const EHFilterScope *>(get())->getNumFilters());\n      break;\n\n    case EHScope::Cleanup:\n      Size = static_cast<const EHCleanupScope *>(get())->getAllocatedSize();\n      break;\n\n    case EHScope::Terminate:\n      Size = EHTerminateScope::getSize();\n      break;\n    }\n    Ptr += llvm::alignTo(Size, ScopeStackAlignment);\n    return *this;\n  }\n\n  iterator next() {\n    iterator copy = *this;\n    ++copy;\n    return copy;\n  }\n\n  iterator operator++(int) {\n    iterator copy = *this;\n    operator++();\n    return copy;\n  }\n\n  bool encloses(iterator other) const { return Ptr >= other.Ptr; }\n  bool strictlyEncloses(iterator other) const { return Ptr > other.Ptr; }\n\n  bool operator==(iterator other) const { return Ptr == other.Ptr; }\n  bool operator!=(iterator other) const { return Ptr != other.Ptr; }\n};\n\ninline EHScopeStack::iterator EHScopeStack::begin() const {\n  return iterator(StartOfData);\n}\n\ninline EHScopeStack::iterator EHScopeStack::end() const {\n  return iterator(EndOfBuffer);\n}\n\ninline void EHScopeStack::popCatch() {\n  assert(!empty() && \"popping exception stack when not empty\");\n\n  EHCatchScope &scope = cast<EHCatchScope>(*begin());\n  InnermostEHScope = scope.getEnclosingEHScope();\n  deallocate(EHCatchScope::getSizeForNumHandlers(scope.getNumHandlers()));\n}\n\ninline void EHScopeStack::popTerminate() {\n  assert(!empty() && \"popping exception stack when not empty\");\n\n  EHTerminateScope &scope = cast<EHTerminateScope>(*begin());\n  InnermostEHScope = scope.getEnclosingEHScope();\n  deallocate(EHTerminateScope::getSize());\n}\n\ninline EHScopeStack::iterator EHScopeStack::find(stable_iterator sp) const {\n  assert(sp.isValid() && \"finding invalid savepoint\");\n  assert(sp.Size <= stable_begin().Size && \"finding savepoint after pop\");\n  return iterator(EndOfBuffer - sp.Size);\n}\n\ninline EHScopeStack::stable_iterator\nEHScopeStack::stabilize(iterator ir) const {\n  assert(StartOfData <= ir.Ptr && ir.Ptr <= EndOfBuffer);\n  return stable_iterator(EndOfBuffer - ir.Ptr);\n}\n\n/// The exceptions personality for a function.\nstruct EHPersonality {\n  const char *PersonalityFn;\n\n  // If this is non-null, this personality requires a non-standard\n  // function for rethrowing an exception after a catchall cleanup.\n  // This function must have prototype void(void*).\n  const char *CatchallRethrowFn;\n\n  static const EHPersonality &get(CodeGenModule &CGM, const FunctionDecl *FD);\n  static const EHPersonality &get(CodeGenFunction &CGF);\n\n  static const EHPersonality GNU_C;\n  static const EHPersonality GNU_C_SJLJ;\n  static const EHPersonality GNU_C_SEH;\n  static const EHPersonality GNU_ObjC;\n  static const EHPersonality GNU_ObjC_SJLJ;\n  static const EHPersonality GNU_ObjC_SEH;\n  static const EHPersonality GNUstep_ObjC;\n  static const EHPersonality GNU_ObjCXX;\n  static const EHPersonality NeXT_ObjC;\n  static const EHPersonality GNU_CPlusPlus;\n  static const EHPersonality GNU_CPlusPlus_SJLJ;\n  static const EHPersonality GNU_CPlusPlus_SEH;\n  static const EHPersonality MSVC_except_handler;\n  static const EHPersonality MSVC_C_specific_handler;\n  static const EHPersonality MSVC_CxxFrameHandler3;\n  static const EHPersonality GNU_Wasm_CPlusPlus;\n  static const EHPersonality XL_CPlusPlus;\n\n  /// Does this personality use landingpads or the family of pad instructions\n  /// designed to form funclets?\n  bool usesFuncletPads() const {\n    return isMSVCPersonality() || isWasmPersonality();\n  }\n\n  bool isMSVCPersonality() const {\n    return this == &MSVC_except_handler || this == &MSVC_C_specific_handler ||\n           this == &MSVC_CxxFrameHandler3;\n  }\n\n  bool isWasmPersonality() const { return this == &GNU_Wasm_CPlusPlus; }\n\n  bool isMSVCXXPersonality() const { return this == &MSVC_CxxFrameHandler3; }\n};\n}\n}\n\n#endif\n"}, "52": {"id": 52, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGExpr.cpp", "content": "//===--- CGExpr.cpp - Emit LLVM Code from Expressions ---------------------===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This contains code to emit Expr nodes as LLVM code.\n//\n//===----------------------------------------------------------------------===//\n\n#include \"CGCUDARuntime.h\"\n#include \"CGCXXABI.h\"\n#include \"CGCall.h\"\n#include \"CGCleanup.h\"\n#include \"CGDebugInfo.h\"\n#include \"CGObjCRuntime.h\"\n#include \"CGOpenMPRuntime.h\"\n#include \"CGRecordLayout.h\"\n#include \"CodeGenFunction.h\"\n#include \"CodeGenModule.h\"\n#include \"ConstantEmitter.h\"\n#include \"TargetInfo.h\"\n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Attr.h\"\n#include \"clang/AST/DeclObjC.h\"\n#include \"clang/AST/NSAPI.h\"\n#include \"clang/Basic/Builtins.h\"\n#include \"clang/Basic/CodeGenOptions.h\"\n#include \"clang/Basic/SourceManager.h\"\n#include \"llvm/ADT/Hashing.h\"\n#include \"llvm/ADT/StringExtras.h\"\n#include \"llvm/IR/DataLayout.h\"\n#include \"llvm/IR/Intrinsics.h\"\n#include \"llvm/IR/LLVMContext.h\"\n#include \"llvm/IR/MDBuilder.h\"\n#include \"llvm/Support/ConvertUTF.h\"\n#include \"llvm/Support/MathExtras.h\"\n#include \"llvm/Support/Path.h\"\n#include \"llvm/Transforms/Utils/SanitizerStats.h\"\n\n#include <string>\n\nusing namespace clang;\nusing namespace CodeGen;\n\n//===--------------------------------------------------------------------===//\n//                        Miscellaneous Helper Methods\n//===--------------------------------------------------------------------===//\n\nllvm::Value *CodeGenFunction::EmitCastToVoidPtr(llvm::Value *value) {\n  unsigned addressSpace =\n      cast<llvm::PointerType>(value->getType())->getAddressSpace();\n\n  llvm::PointerType *destType = Int8PtrTy;\n  if (addressSpace)\n    destType = llvm::Type::getInt8PtrTy(getLLVMContext(), addressSpace);\n\n  if (value->getType() == destType) return value;\n  return Builder.CreateBitCast(value, destType);\n}\n\n/// CreateTempAlloca - This creates a alloca and inserts it into the entry\n/// block.\nAddress CodeGenFunction::CreateTempAllocaWithoutCast(llvm::Type *Ty,\n                                                     CharUnits Align,\n                                                     const Twine &Name,\n                                                     llvm::Value *ArraySize) {\n  auto Alloca = CreateTempAlloca(Ty, Name, ArraySize);\n  Alloca->setAlignment(Align.getAsAlign());\n  return Address(Alloca, Align);\n}\n\n/// CreateTempAlloca - This creates a alloca and inserts it into the entry\n/// block. The alloca is casted to default address space if necessary.\nAddress CodeGenFunction::CreateTempAlloca(llvm::Type *Ty, CharUnits Align,\n                                          const Twine &Name,\n                                          llvm::Value *ArraySize,\n                                          Address *AllocaAddr) {\n  auto Alloca = CreateTempAllocaWithoutCast(Ty, Align, Name, ArraySize);\n  if (AllocaAddr)\n    *AllocaAddr = Alloca;\n  llvm::Value *V = Alloca.getPointer();\n  // Alloca always returns a pointer in alloca address space, which may\n  // be different from the type defined by the language. For example,\n  // in C++ the auto variables are in the default address space. Therefore\n  // cast alloca to the default address space when necessary.\n  if (getASTAllocaAddressSpace() != LangAS::Default) {\n    auto DestAddrSpace = getContext().getTargetAddressSpace(LangAS::Default);\n    llvm::IRBuilderBase::InsertPointGuard IPG(Builder);\n    // When ArraySize is nullptr, alloca is inserted at AllocaInsertPt,\n    // otherwise alloca is inserted at the current insertion point of the\n    // builder.\n    if (!ArraySize)\n      Builder.SetInsertPoint(AllocaInsertPt);\n    V = getTargetHooks().performAddrSpaceCast(\n        *this, V, getASTAllocaAddressSpace(), LangAS::Default,\n        Ty->getPointerTo(DestAddrSpace), /*non-null*/ true);\n  }\n\n  return Address(V, Align);\n}\n\n/// CreateTempAlloca - This creates an alloca and inserts it into the entry\n/// block if \\p ArraySize is nullptr, otherwise inserts it at the current\n/// insertion point of the builder.\nllvm::AllocaInst *CodeGenFunction::CreateTempAlloca(llvm::Type *Ty,\n                                                    const Twine &Name,\n                                                    llvm::Value *ArraySize) {\n  if (ArraySize)\n    return Builder.CreateAlloca(Ty, ArraySize, Name);\n  return new llvm::AllocaInst(Ty, CGM.getDataLayout().getAllocaAddrSpace(),\n                              ArraySize, Name, AllocaInsertPt);\n}\n\n/// CreateDefaultAlignTempAlloca - This creates an alloca with the\n/// default alignment of the corresponding LLVM type, which is *not*\n/// guaranteed to be related in any way to the expected alignment of\n/// an AST type that might have been lowered to Ty.\nAddress CodeGenFunction::CreateDefaultAlignTempAlloca(llvm::Type *Ty,\n                                                      const Twine &Name) {\n  CharUnits Align =\n    CharUnits::fromQuantity(CGM.getDataLayout().getABITypeAlignment(Ty));\n  return CreateTempAlloca(Ty, Align, Name);\n}\n\nvoid CodeGenFunction::InitTempAlloca(Address Var, llvm::Value *Init) {\n  auto *Alloca = Var.getPointer();\n  assert(isa<llvm::AllocaInst>(Alloca) ||\n         (isa<llvm::AddrSpaceCastInst>(Alloca) &&\n          isa<llvm::AllocaInst>(\n              cast<llvm::AddrSpaceCastInst>(Alloca)->getPointerOperand())));\n\n  auto *Store = new llvm::StoreInst(Init, Alloca, /*volatile*/ false,\n                                    Var.getAlignment().getAsAlign());\n  llvm::BasicBlock *Block = AllocaInsertPt->getParent();\n  Block->getInstList().insertAfter(AllocaInsertPt->getIterator(), Store);\n}\n\nAddress CodeGenFunction::CreateIRTemp(QualType Ty, const Twine &Name) {\n  CharUnits Align = getContext().getTypeAlignInChars(Ty);\n  return CreateTempAlloca(ConvertType(Ty), Align, Name);\n}\n\nAddress CodeGenFunction::CreateMemTemp(QualType Ty, const Twine &Name,\n                                       Address *Alloca) {\n  // FIXME: Should we prefer the preferred type alignment here?\n  return CreateMemTemp(Ty, getContext().getTypeAlignInChars(Ty), Name, Alloca);\n}\n\nAddress CodeGenFunction::CreateMemTemp(QualType Ty, CharUnits Align,\n                                       const Twine &Name, Address *Alloca) {\n  Address Result = CreateTempAlloca(ConvertTypeForMem(Ty), Align, Name,\n                                    /*ArraySize=*/nullptr, Alloca);\n\n  if (Ty->isConstantMatrixType()) {\n    auto *ArrayTy = cast<llvm::ArrayType>(Result.getType()->getElementType());\n    auto *VectorTy = llvm::FixedVectorType::get(ArrayTy->getElementType(),\n                                                ArrayTy->getNumElements());\n\n    Result = Address(\n        Builder.CreateBitCast(Result.getPointer(), VectorTy->getPointerTo()),\n        Result.getAlignment());\n  }\n  return Result;\n}\n\nAddress CodeGenFunction::CreateMemTempWithoutCast(QualType Ty, CharUnits Align,\n                                                  const Twine &Name) {\n  return CreateTempAllocaWithoutCast(ConvertTypeForMem(Ty), Align, Name);\n}\n\nAddress CodeGenFunction::CreateMemTempWithoutCast(QualType Ty,\n                                                  const Twine &Name) {\n  return CreateMemTempWithoutCast(Ty, getContext().getTypeAlignInChars(Ty),\n                                  Name);\n}\n\n/// EvaluateExprAsBool - Perform the usual unary conversions on the specified\n/// expression and compare the result against zero, returning an Int1Ty value.\nllvm::Value *CodeGenFunction::EvaluateExprAsBool(const Expr *E) {\n  PGO.setCurrentStmt(E);\n  if (const MemberPointerType *MPT = E->getType()->getAs<MemberPointerType>()) {\n    llvm::Value *MemPtr = EmitScalarExpr(E);\n    return CGM.getCXXABI().EmitMemberPointerIsNotNull(*this, MemPtr, MPT);\n  }\n\n  QualType BoolTy = getContext().BoolTy;\n  SourceLocation Loc = E->getExprLoc();\n  CGFPOptionsRAII FPOptsRAII(*this, E);\n  if (!E->getType()->isAnyComplexType())\n    return EmitScalarConversion(EmitScalarExpr(E), E->getType(), BoolTy, Loc);\n\n  return EmitComplexToScalarConversion(EmitComplexExpr(E), E->getType(), BoolTy,\n                                       Loc);\n}\n\n/// EmitIgnoredExpr - Emit code to compute the specified expression,\n/// ignoring the result.\nvoid CodeGenFunction::EmitIgnoredExpr(const Expr *E) {\n  if (E->isRValue())\n    return (void) EmitAnyExpr(E, AggValueSlot::ignored(), true);\n\n  // Just emit it as an l-value and drop the result.\n  EmitLValue(E);\n}\n\n/// EmitAnyExpr - Emit code to compute the specified expression which\n/// can have any type.  The result is returned as an RValue struct.\n/// If this is an aggregate expression, AggSlot indicates where the\n/// result should be returned.\nRValue CodeGenFunction::EmitAnyExpr(const Expr *E,\n                                    AggValueSlot aggSlot,\n                                    bool ignoreResult) {\n  switch (getEvaluationKind(E->getType())) {\n  case TEK_Scalar:\n    return RValue::get(EmitScalarExpr(E, ignoreResult));\n  case TEK_Complex:\n    return RValue::getComplex(EmitComplexExpr(E, ignoreResult, ignoreResult));\n  case TEK_Aggregate:\n    if (!ignoreResult && aggSlot.isIgnored())\n      aggSlot = CreateAggTemp(E->getType(), \"agg-temp\");\n    EmitAggExpr(E, aggSlot);\n    return aggSlot.asRValue();\n  }\n  llvm_unreachable(\"bad evaluation kind\");\n}\n\n/// EmitAnyExprToTemp - Similar to EmitAnyExpr(), however, the result will\n/// always be accessible even if no aggregate location is provided.\nRValue CodeGenFunction::EmitAnyExprToTemp(const Expr *E) {\n  AggValueSlot AggSlot = AggValueSlot::ignored();\n\n  if (hasAggregateEvaluationKind(E->getType()))\n    AggSlot = CreateAggTemp(E->getType(), \"agg.tmp\");\n  return EmitAnyExpr(E, AggSlot);\n}\n\n/// EmitAnyExprToMem - Evaluate an expression into a given memory\n/// location.\nvoid CodeGenFunction::EmitAnyExprToMem(const Expr *E,\n                                       Address Location,\n                                       Qualifiers Quals,\n                                       bool IsInit) {\n  // FIXME: This function should take an LValue as an argument.\n  switch (getEvaluationKind(E->getType())) {\n  case TEK_Complex:\n    EmitComplexExprIntoLValue(E, MakeAddrLValue(Location, E->getType()),\n                              /*isInit*/ false);\n    return;\n\n  case TEK_Aggregate: {\n    EmitAggExpr(E, AggValueSlot::forAddr(Location, Quals,\n                                         AggValueSlot::IsDestructed_t(IsInit),\n                                         AggValueSlot::DoesNotNeedGCBarriers,\n                                         AggValueSlot::IsAliased_t(!IsInit),\n                                         AggValueSlot::MayOverlap));\n    return;\n  }\n\n  case TEK_Scalar: {\n    RValue RV = RValue::get(EmitScalarExpr(E, /*Ignore*/ false));\n    LValue LV = MakeAddrLValue(Location, E->getType());\n    EmitStoreThroughLValue(RV, LV);\n    return;\n  }\n  }\n  llvm_unreachable(\"bad evaluation kind\");\n}\n\nstatic void\npushTemporaryCleanup(CodeGenFunction &CGF, const MaterializeTemporaryExpr *M,\n                     const Expr *E, Address ReferenceTemporary) {\n  // Objective-C++ ARC:\n  //   If we are binding a reference to a temporary that has ownership, we\n  //   need to perform retain/release operations on the temporary.\n  //\n  // FIXME: This should be looking at E, not M.\n  if (auto Lifetime = M->getType().getObjCLifetime()) {\n    switch (Lifetime) {\n    case Qualifiers::OCL_None:\n    case Qualifiers::OCL_ExplicitNone:\n      // Carry on to normal cleanup handling.\n      break;\n\n    case Qualifiers::OCL_Autoreleasing:\n      // Nothing to do; cleaned up by an autorelease pool.\n      return;\n\n    case Qualifiers::OCL_Strong:\n    case Qualifiers::OCL_Weak:\n      switch (StorageDuration Duration = M->getStorageDuration()) {\n      case SD_Static:\n        // Note: we intentionally do not register a cleanup to release\n        // the object on program termination.\n        return;\n\n      case SD_Thread:\n        // FIXME: We should probably register a cleanup in this case.\n        return;\n\n      case SD_Automatic:\n      case SD_FullExpression:\n        CodeGenFunction::Destroyer *Destroy;\n        CleanupKind CleanupKind;\n        if (Lifetime == Qualifiers::OCL_Strong) {\n          const ValueDecl *VD = M->getExtendingDecl();\n          bool Precise =\n              VD && isa<VarDecl>(VD) && VD->hasAttr<ObjCPreciseLifetimeAttr>();\n          CleanupKind = CGF.getARCCleanupKind();\n          Destroy = Precise ? &CodeGenFunction::destroyARCStrongPrecise\n                            : &CodeGenFunction::destroyARCStrongImprecise;\n        } else {\n          // __weak objects always get EH cleanups; otherwise, exceptions\n          // could cause really nasty crashes instead of mere leaks.\n          CleanupKind = NormalAndEHCleanup;\n          Destroy = &CodeGenFunction::destroyARCWeak;\n        }\n        if (Duration == SD_FullExpression)\n          CGF.pushDestroy(CleanupKind, ReferenceTemporary,\n                          M->getType(), *Destroy,\n                          CleanupKind & EHCleanup);\n        else\n          CGF.pushLifetimeExtendedDestroy(CleanupKind, ReferenceTemporary,\n                                          M->getType(),\n                                          *Destroy, CleanupKind & EHCleanup);\n        return;\n\n      case SD_Dynamic:\n        llvm_unreachable(\"temporary cannot have dynamic storage duration\");\n      }\n      llvm_unreachable(\"unknown storage duration\");\n    }\n  }\n\n  CXXDestructorDecl *ReferenceTemporaryDtor = nullptr;\n  if (const RecordType *RT =\n          E->getType()->getBaseElementTypeUnsafe()->getAs<RecordType>()) {\n    // Get the destructor for the reference temporary.\n    auto *ClassDecl = cast<CXXRecordDecl>(RT->getDecl());\n    if (!ClassDecl->hasTrivialDestructor())\n      ReferenceTemporaryDtor = ClassDecl->getDestructor();\n  }\n\n  if (!ReferenceTemporaryDtor)\n    return;\n\n  // Call the destructor for the temporary.\n  switch (M->getStorageDuration()) {\n  case SD_Static:\n  case SD_Thread: {\n    llvm::FunctionCallee CleanupFn;\n    llvm::Constant *CleanupArg;\n    if (E->getType()->isArrayType()) {\n      CleanupFn = CodeGenFunction(CGF.CGM).generateDestroyHelper(\n          ReferenceTemporary, E->getType(),\n          CodeGenFunction::destroyCXXObject, CGF.getLangOpts().Exceptions,\n          dyn_cast_or_null<VarDecl>(M->getExtendingDecl()));\n      CleanupArg = llvm::Constant::getNullValue(CGF.Int8PtrTy);\n    } else {\n      CleanupFn = CGF.CGM.getAddrAndTypeOfCXXStructor(\n          GlobalDecl(ReferenceTemporaryDtor, Dtor_Complete));\n      CleanupArg = cast<llvm::Constant>(ReferenceTemporary.getPointer());\n    }\n    CGF.CGM.getCXXABI().registerGlobalDtor(\n        CGF, *cast<VarDecl>(M->getExtendingDecl()), CleanupFn, CleanupArg);\n    break;\n  }\n\n  case SD_FullExpression:\n    CGF.pushDestroy(NormalAndEHCleanup, ReferenceTemporary, E->getType(),\n                    CodeGenFunction::destroyCXXObject,\n                    CGF.getLangOpts().Exceptions);\n    break;\n\n  case SD_Automatic:\n    CGF.pushLifetimeExtendedDestroy(NormalAndEHCleanup,\n                                    ReferenceTemporary, E->getType(),\n                                    CodeGenFunction::destroyCXXObject,\n                                    CGF.getLangOpts().Exceptions);\n    break;\n\n  case SD_Dynamic:\n    llvm_unreachable(\"temporary cannot have dynamic storage duration\");\n  }\n}\n\nstatic Address createReferenceTemporary(CodeGenFunction &CGF,\n                                        const MaterializeTemporaryExpr *M,\n                                        const Expr *Inner,\n                                        Address *Alloca = nullptr) {\n  auto &TCG = CGF.getTargetHooks();\n  switch (M->getStorageDuration()) {\n  case SD_FullExpression:\n  case SD_Automatic: {\n    // If we have a constant temporary array or record try to promote it into a\n    // constant global under the same rules a normal constant would've been\n    // promoted. This is easier on the optimizer and generally emits fewer\n    // instructions.\n    QualType Ty = Inner->getType();\n    if (CGF.CGM.getCodeGenOpts().MergeAllConstants &&\n        (Ty->isArrayType() || Ty->isRecordType()) &&\n        CGF.CGM.isTypeConstant(Ty, true))\n      if (auto Init = ConstantEmitter(CGF).tryEmitAbstract(Inner, Ty)) {\n        if (auto AddrSpace = CGF.getTarget().getConstantAddressSpace()) {\n          auto AS = AddrSpace.getValue();\n          auto *GV = new llvm::GlobalVariable(\n              CGF.CGM.getModule(), Init->getType(), /*isConstant=*/true,\n              llvm::GlobalValue::PrivateLinkage, Init, \".ref.tmp\", nullptr,\n              llvm::GlobalValue::NotThreadLocal,\n              CGF.getContext().getTargetAddressSpace(AS));\n          CharUnits alignment = CGF.getContext().getTypeAlignInChars(Ty);\n          GV->setAlignment(alignment.getAsAlign());\n          llvm::Constant *C = GV;\n          if (AS != LangAS::Default)\n            C = TCG.performAddrSpaceCast(\n                CGF.CGM, GV, AS, LangAS::Default,\n                GV->getValueType()->getPointerTo(\n                    CGF.getContext().getTargetAddressSpace(LangAS::Default)));\n          // FIXME: Should we put the new global into a COMDAT?\n          return Address(C, alignment);\n        }\n      }\n    return CGF.CreateMemTemp(Ty, \"ref.tmp\", Alloca);\n  }\n  case SD_Thread:\n  case SD_Static:\n    return CGF.CGM.GetAddrOfGlobalTemporary(M, Inner);\n\n  case SD_Dynamic:\n    llvm_unreachable(\"temporary can't have dynamic storage duration\");\n  }\n  llvm_unreachable(\"unknown storage duration\");\n}\n\n/// Helper method to check if the underlying ABI is AAPCS\nstatic bool isAAPCS(const TargetInfo &TargetInfo) {\n  return TargetInfo.getABI().startswith(\"aapcs\");\n}\n\nLValue CodeGenFunction::\nEmitMaterializeTemporaryExpr(const MaterializeTemporaryExpr *M) {\n  const Expr *E = M->getSubExpr();\n\n  assert((!M->getExtendingDecl() || !isa<VarDecl>(M->getExtendingDecl()) ||\n          !cast<VarDecl>(M->getExtendingDecl())->isARCPseudoStrong()) &&\n         \"Reference should never be pseudo-strong!\");\n\n  // FIXME: ideally this would use EmitAnyExprToMem, however, we cannot do so\n  // as that will cause the lifetime adjustment to be lost for ARC\n  auto ownership = M->getType().getObjCLifetime();\n  if (ownership != Qualifiers::OCL_None &&\n      ownership != Qualifiers::OCL_ExplicitNone) {\n    Address Object = createReferenceTemporary(*this, M, E);\n    if (auto *Var = dyn_cast<llvm::GlobalVariable>(Object.getPointer())) {\n      Object = Address(llvm::ConstantExpr::getBitCast(Var,\n                           ConvertTypeForMem(E->getType())\n                             ->getPointerTo(Object.getAddressSpace())),\n                       Object.getAlignment());\n\n      // createReferenceTemporary will promote the temporary to a global with a\n      // constant initializer if it can.  It can only do this to a value of\n      // ARC-manageable type if the value is global and therefore \"immune\" to\n      // ref-counting operations.  Therefore we have no need to emit either a\n      // dynamic initialization or a cleanup and we can just return the address\n      // of the temporary.\n      if (Var->hasInitializer())\n        return MakeAddrLValue(Object, M->getType(), AlignmentSource::Decl);\n\n      Var->setInitializer(CGM.EmitNullConstant(E->getType()));\n    }\n    LValue RefTempDst = MakeAddrLValue(Object, M->getType(),\n                                       AlignmentSource::Decl);\n\n    switch (getEvaluationKind(E->getType())) {\n    default: llvm_unreachable(\"expected scalar or aggregate expression\");\n    case TEK_Scalar:\n      EmitScalarInit(E, M->getExtendingDecl(), RefTempDst, false);\n      break;\n    case TEK_Aggregate: {\n      EmitAggExpr(E, AggValueSlot::forAddr(Object,\n                                           E->getType().getQualifiers(),\n                                           AggValueSlot::IsDestructed,\n                                           AggValueSlot::DoesNotNeedGCBarriers,\n                                           AggValueSlot::IsNotAliased,\n                                           AggValueSlot::DoesNotOverlap));\n      break;\n    }\n    }\n\n    pushTemporaryCleanup(*this, M, E, Object);\n    return RefTempDst;\n  }\n\n  SmallVector<const Expr *, 2> CommaLHSs;\n  SmallVector<SubobjectAdjustment, 2> Adjustments;\n  E = E->skipRValueSubobjectAdjustments(CommaLHSs, Adjustments);\n\n  for (const auto &Ignored : CommaLHSs)\n    EmitIgnoredExpr(Ignored);\n\n  if (const auto *opaque = dyn_cast<OpaqueValueExpr>(E)) {\n    if (opaque->getType()->isRecordType()) {\n      assert(Adjustments.empty());\n      return EmitOpaqueValueLValue(opaque);\n    }\n  }\n\n  // Create and initialize the reference temporary.\n  Address Alloca = Address::invalid();\n  Address Object = createReferenceTemporary(*this, M, E, &Alloca);\n  if (auto *Var = dyn_cast<llvm::GlobalVariable>(\n          Object.getPointer()->stripPointerCasts())) {\n    Object = Address(llvm::ConstantExpr::getBitCast(\n                         cast<llvm::Constant>(Object.getPointer()),\n                         ConvertTypeForMem(E->getType())->getPointerTo()),\n                     Object.getAlignment());\n    // If the temporary is a global and has a constant initializer or is a\n    // constant temporary that we promoted to a global, we may have already\n    // initialized it.\n    if (!Var->hasInitializer()) {\n      Var->setInitializer(CGM.EmitNullConstant(E->getType()));\n      EmitAnyExprToMem(E, Object, Qualifiers(), /*IsInit*/true);\n    }\n  } else {\n    switch (M->getStorageDuration()) {\n    case SD_Automatic:\n      if (auto *Size = EmitLifetimeStart(\n              CGM.getDataLayout().getTypeAllocSize(Alloca.getElementType()),\n              Alloca.getPointer())) {\n        pushCleanupAfterFullExpr<CallLifetimeEnd>(NormalEHLifetimeMarker,\n                                                  Alloca, Size);\n      }\n      break;\n\n    case SD_FullExpression: {\n      if (!ShouldEmitLifetimeMarkers)\n        break;\n\n      // Avoid creating a conditional cleanup just to hold an llvm.lifetime.end\n      // marker. Instead, start the lifetime of a conditional temporary earlier\n      // so that it's unconditional. Don't do this with sanitizers which need\n      // more precise lifetime marks.\n      ConditionalEvaluation *OldConditional = nullptr;\n      CGBuilderTy::InsertPoint OldIP;\n      if (isInConditionalBranch() && !E->getType().isDestructedType() &&\n          !SanOpts.has(SanitizerKind::HWAddress) &&\n          !SanOpts.has(SanitizerKind::Memory) &&\n          !CGM.getCodeGenOpts().SanitizeAddressUseAfterScope) {\n        OldConditional = OutermostConditional;\n        OutermostConditional = nullptr;\n\n        OldIP = Builder.saveIP();\n        llvm::BasicBlock *Block = OldConditional->getStartingBlock();\n        Builder.restoreIP(CGBuilderTy::InsertPoint(\n            Block, llvm::BasicBlock::iterator(Block->back())));\n      }\n\n      if (auto *Size = EmitLifetimeStart(\n              CGM.getDataLayout().getTypeAllocSize(Alloca.getElementType()),\n              Alloca.getPointer())) {\n        pushFullExprCleanup<CallLifetimeEnd>(NormalEHLifetimeMarker, Alloca,\n                                             Size);\n      }\n\n      if (OldConditional) {\n        OutermostConditional = OldConditional;\n        Builder.restoreIP(OldIP);\n      }\n      break;\n    }\n\n    default:\n      break;\n    }\n    EmitAnyExprToMem(E, Object, Qualifiers(), /*IsInit*/true);\n  }\n  pushTemporaryCleanup(*this, M, E, Object);\n\n  // Perform derived-to-base casts and/or field accesses, to get from the\n  // temporary object we created (and, potentially, for which we extended\n  // the lifetime) to the subobject we're binding the reference to.\n  for (unsigned I = Adjustments.size(); I != 0; --I) {\n    SubobjectAdjustment &Adjustment = Adjustments[I-1];\n    switch (Adjustment.Kind) {\n    case SubobjectAdjustment::DerivedToBaseAdjustment:\n      Object =\n          GetAddressOfBaseClass(Object, Adjustment.DerivedToBase.DerivedClass,\n                                Adjustment.DerivedToBase.BasePath->path_begin(),\n                                Adjustment.DerivedToBase.BasePath->path_end(),\n                                /*NullCheckValue=*/ false, E->getExprLoc());\n      break;\n\n    case SubobjectAdjustment::FieldAdjustment: {\n      LValue LV = MakeAddrLValue(Object, E->getType(), AlignmentSource::Decl);\n      LV = EmitLValueForField(LV, Adjustment.Field);\n      assert(LV.isSimple() &&\n             \"materialized temporary field is not a simple lvalue\");\n      Object = LV.getAddress(*this);\n      break;\n    }\n\n    case SubobjectAdjustment::MemberPointerAdjustment: {\n      llvm::Value *Ptr = EmitScalarExpr(Adjustment.Ptr.RHS);\n      Object = EmitCXXMemberDataPointerAddress(E, Object, Ptr,\n                                               Adjustment.Ptr.MPT);\n      break;\n    }\n    }\n  }\n\n  return MakeAddrLValue(Object, M->getType(), AlignmentSource::Decl);\n}\n\nRValue\nCodeGenFunction::EmitReferenceBindingToExpr(const Expr *E) {\n  // Emit the expression as an lvalue.\n  LValue LV = EmitLValue(E);\n  assert(LV.isSimple());\n  llvm::Value *Value = LV.getPointer(*this);\n\n  if (sanitizePerformTypeCheck() && !E->getType()->isFunctionType()) {\n    // C++11 [dcl.ref]p5 (as amended by core issue 453):\n    //   If a glvalue to which a reference is directly bound designates neither\n    //   an existing object or function of an appropriate type nor a region of\n    //   storage of suitable size and alignment to contain an object of the\n    //   reference's type, the behavior is undefined.\n    QualType Ty = E->getType();\n    EmitTypeCheck(TCK_ReferenceBinding, E->getExprLoc(), Value, Ty);\n  }\n\n  return RValue::get(Value);\n}\n\n\n/// getAccessedFieldNo - Given an encoded value and a result number, return the\n/// input field number being accessed.\nunsigned CodeGenFunction::getAccessedFieldNo(unsigned Idx,\n                                             const llvm::Constant *Elts) {\n  return cast<llvm::ConstantInt>(Elts->getAggregateElement(Idx))\n      ->getZExtValue();\n}\n\n/// Emit the hash_16_bytes function from include/llvm/ADT/Hashing.h.\nstatic llvm::Value *emitHash16Bytes(CGBuilderTy &Builder, llvm::Value *Low,\n                                    llvm::Value *High) {\n  llvm::Value *KMul = Builder.getInt64(0x9ddfea08eb382d69ULL);\n  llvm::Value *K47 = Builder.getInt64(47);\n  llvm::Value *A0 = Builder.CreateMul(Builder.CreateXor(Low, High), KMul);\n  llvm::Value *A1 = Builder.CreateXor(Builder.CreateLShr(A0, K47), A0);\n  llvm::Value *B0 = Builder.CreateMul(Builder.CreateXor(High, A1), KMul);\n  llvm::Value *B1 = Builder.CreateXor(Builder.CreateLShr(B0, K47), B0);\n  return Builder.CreateMul(B1, KMul);\n}\n\nbool CodeGenFunction::isNullPointerAllowed(TypeCheckKind TCK) {\n  return TCK == TCK_DowncastPointer || TCK == TCK_Upcast ||\n         TCK == TCK_UpcastToVirtualBase || TCK == TCK_DynamicOperation;\n}\n\nbool CodeGenFunction::isVptrCheckRequired(TypeCheckKind TCK, QualType Ty) {\n  CXXRecordDecl *RD = Ty->getAsCXXRecordDecl();\n  return (RD && RD->hasDefinition() && RD->isDynamicClass()) &&\n         (TCK == TCK_MemberAccess || TCK == TCK_MemberCall ||\n          TCK == TCK_DowncastPointer || TCK == TCK_DowncastReference ||\n          TCK == TCK_UpcastToVirtualBase || TCK == TCK_DynamicOperation);\n}\n\nbool CodeGenFunction::sanitizePerformTypeCheck() const {\n  return SanOpts.has(SanitizerKind::Null) |\n         SanOpts.has(SanitizerKind::Alignment) |\n         SanOpts.has(SanitizerKind::ObjectSize) |\n         SanOpts.has(SanitizerKind::Vptr);\n}\n\nvoid CodeGenFunction::EmitTypeCheck(TypeCheckKind TCK, SourceLocation Loc,\n                                    llvm::Value *Ptr, QualType Ty,\n                                    CharUnits Alignment,\n                                    SanitizerSet SkippedChecks,\n                                    llvm::Value *ArraySize) {\n  if (!sanitizePerformTypeCheck())\n    return;\n\n  // Don't check pointers outside the default address space. The null check\n  // isn't correct, the object-size check isn't supported by LLVM, and we can't\n  // communicate the addresses to the runtime handler for the vptr check.\n  if (Ptr->getType()->getPointerAddressSpace())\n    return;\n\n  // Don't check pointers to volatile data. The behavior here is implementation-\n  // defined.\n  if (Ty.isVolatileQualified())\n    return;\n\n  SanitizerScope SanScope(this);\n\n  SmallVector<std::pair<llvm::Value *, SanitizerMask>, 3> Checks;\n  llvm::BasicBlock *Done = nullptr;\n\n  // Quickly determine whether we have a pointer to an alloca. It's possible\n  // to skip null checks, and some alignment checks, for these pointers. This\n  // can reduce compile-time significantly.\n  auto PtrToAlloca = dyn_cast<llvm::AllocaInst>(Ptr->stripPointerCasts());\n\n  llvm::Value *True = llvm::ConstantInt::getTrue(getLLVMContext());\n  llvm::Value *IsNonNull = nullptr;\n  bool IsGuaranteedNonNull =\n      SkippedChecks.has(SanitizerKind::Null) || PtrToAlloca;\n  bool AllowNullPointers = isNullPointerAllowed(TCK);\n  if ((SanOpts.has(SanitizerKind::Null) || AllowNullPointers) &&\n      !IsGuaranteedNonNull) {\n    // The glvalue must not be an empty glvalue.\n    IsNonNull = Builder.CreateIsNotNull(Ptr);\n\n    // The IR builder can constant-fold the null check if the pointer points to\n    // a constant.\n    IsGuaranteedNonNull = IsNonNull == True;\n\n    // Skip the null check if the pointer is known to be non-null.\n    if (!IsGuaranteedNonNull) {\n      if (AllowNullPointers) {\n        // When performing pointer casts, it's OK if the value is null.\n        // Skip the remaining checks in that case.\n        Done = createBasicBlock(\"null\");\n        llvm::BasicBlock *Rest = createBasicBlock(\"not.null\");\n        Builder.CreateCondBr(IsNonNull, Rest, Done);\n        EmitBlock(Rest);\n      } else {\n        Checks.push_back(std::make_pair(IsNonNull, SanitizerKind::Null));\n      }\n    }\n  }\n\n  if (SanOpts.has(SanitizerKind::ObjectSize) &&\n      !SkippedChecks.has(SanitizerKind::ObjectSize) &&\n      !Ty->isIncompleteType()) {\n    uint64_t TySize = CGM.getMinimumObjectSize(Ty).getQuantity();\n    llvm::Value *Size = llvm::ConstantInt::get(IntPtrTy, TySize);\n    if (ArraySize)\n      Size = Builder.CreateMul(Size, ArraySize);\n\n    // Degenerate case: new X[0] does not need an objectsize check.\n    llvm::Constant *ConstantSize = dyn_cast<llvm::Constant>(Size);\n    if (!ConstantSize || !ConstantSize->isNullValue()) {\n      // The glvalue must refer to a large enough storage region.\n      // FIXME: If Address Sanitizer is enabled, insert dynamic instrumentation\n      //        to check this.\n      // FIXME: Get object address space\n      llvm::Type *Tys[2] = { IntPtrTy, Int8PtrTy };\n      llvm::Function *F = CGM.getIntrinsic(llvm::Intrinsic::objectsize, Tys);\n      llvm::Value *Min = Builder.getFalse();\n      llvm::Value *NullIsUnknown = Builder.getFalse();\n      llvm::Value *Dynamic = Builder.getFalse();\n      llvm::Value *CastAddr = Builder.CreateBitCast(Ptr, Int8PtrTy);\n      llvm::Value *LargeEnough = Builder.CreateICmpUGE(\n          Builder.CreateCall(F, {CastAddr, Min, NullIsUnknown, Dynamic}), Size);\n      Checks.push_back(std::make_pair(LargeEnough, SanitizerKind::ObjectSize));\n    }\n  }\n\n  uint64_t AlignVal = 0;\n  llvm::Value *PtrAsInt = nullptr;\n\n  if (SanOpts.has(SanitizerKind::Alignment) &&\n      !SkippedChecks.has(SanitizerKind::Alignment)) {\n    AlignVal = Alignment.getQuantity();\n    if (!Ty->isIncompleteType() && !AlignVal)\n      AlignVal = CGM.getNaturalTypeAlignment(Ty, nullptr, nullptr,\n                                             /*ForPointeeType=*/true)\n                     .getQuantity();\n\n    // The glvalue must be suitably aligned.\n    if (AlignVal > 1 &&\n        (!PtrToAlloca || PtrToAlloca->getAlignment() < AlignVal)) {\n      PtrAsInt = Builder.CreatePtrToInt(Ptr, IntPtrTy);\n      llvm::Value *Align = Builder.CreateAnd(\n          PtrAsInt, llvm::ConstantInt::get(IntPtrTy, AlignVal - 1));\n      llvm::Value *Aligned =\n          Builder.CreateICmpEQ(Align, llvm::ConstantInt::get(IntPtrTy, 0));\n      if (Aligned != True)\n        Checks.push_back(std::make_pair(Aligned, SanitizerKind::Alignment));\n    }\n  }\n\n  if (Checks.size() > 0) {\n    // Make sure we're not losing information. Alignment needs to be a power of\n    // 2\n    assert(!AlignVal || (uint64_t)1 << llvm::Log2_64(AlignVal) == AlignVal);\n    llvm::Constant *StaticData[] = {\n        EmitCheckSourceLocation(Loc), EmitCheckTypeDescriptor(Ty),\n        llvm::ConstantInt::get(Int8Ty, AlignVal ? llvm::Log2_64(AlignVal) : 1),\n        llvm::ConstantInt::get(Int8Ty, TCK)};\n    EmitCheck(Checks, SanitizerHandler::TypeMismatch, StaticData,\n              PtrAsInt ? PtrAsInt : Ptr);\n  }\n\n  // If possible, check that the vptr indicates that there is a subobject of\n  // type Ty at offset zero within this object.\n  //\n  // C++11 [basic.life]p5,6:\n  //   [For storage which does not refer to an object within its lifetime]\n  //   The program has undefined behavior if:\n  //    -- the [pointer or glvalue] is used to access a non-static data member\n  //       or call a non-static member function\n  if (SanOpts.has(SanitizerKind::Vptr) &&\n      !SkippedChecks.has(SanitizerKind::Vptr) && isVptrCheckRequired(TCK, Ty)) {\n    // Ensure that the pointer is non-null before loading it. If there is no\n    // compile-time guarantee, reuse the run-time null check or emit a new one.\n    if (!IsGuaranteedNonNull) {\n      if (!IsNonNull)\n        IsNonNull = Builder.CreateIsNotNull(Ptr);\n      if (!Done)\n        Done = createBasicBlock(\"vptr.null\");\n      llvm::BasicBlock *VptrNotNull = createBasicBlock(\"vptr.not.null\");\n      Builder.CreateCondBr(IsNonNull, VptrNotNull, Done);\n      EmitBlock(VptrNotNull);\n    }\n\n    // Compute a hash of the mangled name of the type.\n    //\n    // FIXME: This is not guaranteed to be deterministic! Move to a\n    //        fingerprinting mechanism once LLVM provides one. For the time\n    //        being the implementation happens to be deterministic.\n    SmallString<64> MangledName;\n    llvm::raw_svector_ostream Out(MangledName);\n    CGM.getCXXABI().getMangleContext().mangleCXXRTTI(Ty.getUnqualifiedType(),\n                                                     Out);\n\n    // Contained in NoSanitizeList based on the mangled type.\n    if (!CGM.getContext().getNoSanitizeList().containsType(SanitizerKind::Vptr,\n                                                           Out.str())) {\n      llvm::hash_code TypeHash = hash_value(Out.str());\n\n      // Load the vptr, and compute hash_16_bytes(TypeHash, vptr).\n      llvm::Value *Low = llvm::ConstantInt::get(Int64Ty, TypeHash);\n      llvm::Type *VPtrTy = llvm::PointerType::get(IntPtrTy, 0);\n      Address VPtrAddr(Builder.CreateBitCast(Ptr, VPtrTy), getPointerAlign());\n      llvm::Value *VPtrVal = Builder.CreateLoad(VPtrAddr);\n      llvm::Value *High = Builder.CreateZExt(VPtrVal, Int64Ty);\n\n      llvm::Value *Hash = emitHash16Bytes(Builder, Low, High);\n      Hash = Builder.CreateTrunc(Hash, IntPtrTy);\n\n      // Look the hash up in our cache.\n      const int CacheSize = 128;\n      llvm::Type *HashTable = llvm::ArrayType::get(IntPtrTy, CacheSize);\n      llvm::Value *Cache = CGM.CreateRuntimeVariable(HashTable,\n                                                     \"__ubsan_vptr_type_cache\");\n      llvm::Value *Slot = Builder.CreateAnd(Hash,\n                                            llvm::ConstantInt::get(IntPtrTy,\n                                                                   CacheSize-1));\n      llvm::Value *Indices[] = { Builder.getInt32(0), Slot };\n      llvm::Value *CacheVal =\n          Builder.CreateAlignedLoad(IntPtrTy,\n                                    Builder.CreateInBoundsGEP(Cache, Indices),\n                                    getPointerAlign());\n\n      // If the hash isn't in the cache, call a runtime handler to perform the\n      // hard work of checking whether the vptr is for an object of the right\n      // type. This will either fill in the cache and return, or produce a\n      // diagnostic.\n      llvm::Value *EqualHash = Builder.CreateICmpEQ(CacheVal, Hash);\n      llvm::Constant *StaticData[] = {\n        EmitCheckSourceLocation(Loc),\n        EmitCheckTypeDescriptor(Ty),\n        CGM.GetAddrOfRTTIDescriptor(Ty.getUnqualifiedType()),\n        llvm::ConstantInt::get(Int8Ty, TCK)\n      };\n      llvm::Value *DynamicData[] = { Ptr, Hash };\n      EmitCheck(std::make_pair(EqualHash, SanitizerKind::Vptr),\n                SanitizerHandler::DynamicTypeCacheMiss, StaticData,\n                DynamicData);\n    }\n  }\n\n  if (Done) {\n    Builder.CreateBr(Done);\n    EmitBlock(Done);\n  }\n}\n\n/// Determine whether this expression refers to a flexible array member in a\n/// struct. We disable array bounds checks for such members.\nstatic bool isFlexibleArrayMemberExpr(const Expr *E) {\n  // For compatibility with existing code, we treat arrays of length 0 or\n  // 1 as flexible array members.\n  // FIXME: This is inconsistent with the warning code in SemaChecking. Unify\n  // the two mechanisms.\n  const ArrayType *AT = E->getType()->castAsArrayTypeUnsafe();\n  if (const auto *CAT = dyn_cast<ConstantArrayType>(AT)) {\n    // FIXME: Sema doesn't treat [1] as a flexible array member if the bound\n    // was produced by macro expansion.\n    if (CAT->getSize().ugt(1))\n      return false;\n  } else if (!isa<IncompleteArrayType>(AT))\n    return false;\n\n  E = E->IgnoreParens();\n\n  // A flexible array member must be the last member in the class.\n  if (const auto *ME = dyn_cast<MemberExpr>(E)) {\n    // FIXME: If the base type of the member expr is not FD->getParent(),\n    // this should not be treated as a flexible array member access.\n    if (const auto *FD = dyn_cast<FieldDecl>(ME->getMemberDecl())) {\n      // FIXME: Sema doesn't treat a T[1] union member as a flexible array\n      // member, only a T[0] or T[] member gets that treatment.\n      if (FD->getParent()->isUnion())\n        return true;\n      RecordDecl::field_iterator FI(\n          DeclContext::decl_iterator(const_cast<FieldDecl *>(FD)));\n      return ++FI == FD->getParent()->field_end();\n    }\n  } else if (const auto *IRE = dyn_cast<ObjCIvarRefExpr>(E)) {\n    return IRE->getDecl()->getNextIvar() == nullptr;\n  }\n\n  return false;\n}\n\nllvm::Value *CodeGenFunction::LoadPassedObjectSize(const Expr *E,\n                                                   QualType EltTy) {\n  ASTContext &C = getContext();\n  uint64_t EltSize = C.getTypeSizeInChars(EltTy).getQuantity();\n  if (!EltSize)\n    return nullptr;\n\n  auto *ArrayDeclRef = dyn_cast<DeclRefExpr>(E->IgnoreParenImpCasts());\n  if (!ArrayDeclRef)\n    return nullptr;\n\n  auto *ParamDecl = dyn_cast<ParmVarDecl>(ArrayDeclRef->getDecl());\n  if (!ParamDecl)\n    return nullptr;\n\n  auto *POSAttr = ParamDecl->getAttr<PassObjectSizeAttr>();\n  if (!POSAttr)\n    return nullptr;\n\n  // Don't load the size if it's a lower bound.\n  int POSType = POSAttr->getType();\n  if (POSType != 0 && POSType != 1)\n    return nullptr;\n\n  // Find the implicit size parameter.\n  auto PassedSizeIt = SizeArguments.find(ParamDecl);\n  if (PassedSizeIt == SizeArguments.end())\n    return nullptr;\n\n  const ImplicitParamDecl *PassedSizeDecl = PassedSizeIt->second;\n  assert(LocalDeclMap.count(PassedSizeDecl) && \"Passed size not loadable\");\n  Address AddrOfSize = LocalDeclMap.find(PassedSizeDecl)->second;\n  llvm::Value *SizeInBytes = EmitLoadOfScalar(AddrOfSize, /*Volatile=*/false,\n                                              C.getSizeType(), E->getExprLoc());\n  llvm::Value *SizeOfElement =\n      llvm::ConstantInt::get(SizeInBytes->getType(), EltSize);\n  return Builder.CreateUDiv(SizeInBytes, SizeOfElement);\n}\n\n/// If Base is known to point to the start of an array, return the length of\n/// that array. Return 0 if the length cannot be determined.\nstatic llvm::Value *getArrayIndexingBound(\n    CodeGenFunction &CGF, const Expr *Base, QualType &IndexedType) {\n  // For the vector indexing extension, the bound is the number of elements.\n  if (const VectorType *VT = Base->getType()->getAs<VectorType>()) {\n    IndexedType = Base->getType();\n    return CGF.Builder.getInt32(VT->getNumElements());\n  }\n\n  Base = Base->IgnoreParens();\n\n  if (const auto *CE = dyn_cast<CastExpr>(Base)) {\n    if (CE->getCastKind() == CK_ArrayToPointerDecay &&\n        !isFlexibleArrayMemberExpr(CE->getSubExpr())) {\n      IndexedType = CE->getSubExpr()->getType();\n      const ArrayType *AT = IndexedType->castAsArrayTypeUnsafe();\n      if (const auto *CAT = dyn_cast<ConstantArrayType>(AT))\n        return CGF.Builder.getInt(CAT->getSize());\n      else if (const auto *VAT = dyn_cast<VariableArrayType>(AT))\n        return CGF.getVLASize(VAT).NumElts;\n      // Ignore pass_object_size here. It's not applicable on decayed pointers.\n    }\n  }\n\n  QualType EltTy{Base->getType()->getPointeeOrArrayElementType(), 0};\n  if (llvm::Value *POS = CGF.LoadPassedObjectSize(Base, EltTy)) {\n    IndexedType = Base->getType();\n    return POS;\n  }\n\n  return nullptr;\n}\n\nvoid CodeGenFunction::EmitBoundsCheck(const Expr *E, const Expr *Base,\n                                      llvm::Value *Index, QualType IndexType,\n                                      bool Accessed) {\n  assert(SanOpts.has(SanitizerKind::ArrayBounds) &&\n         \"should not be called unless adding bounds checks\");\n  SanitizerScope SanScope(this);\n\n  QualType IndexedType;\n  llvm::Value *Bound = getArrayIndexingBound(*this, Base, IndexedType);\n  if (!Bound)\n    return;\n\n  bool IndexSigned = IndexType->isSignedIntegerOrEnumerationType();\n  llvm::Value *IndexVal = Builder.CreateIntCast(Index, SizeTy, IndexSigned);\n  llvm::Value *BoundVal = Builder.CreateIntCast(Bound, SizeTy, false);\n\n  llvm::Constant *StaticData[] = {\n    EmitCheckSourceLocation(E->getExprLoc()),\n    EmitCheckTypeDescriptor(IndexedType),\n    EmitCheckTypeDescriptor(IndexType)\n  };\n  llvm::Value *Check = Accessed ? Builder.CreateICmpULT(IndexVal, BoundVal)\n                                : Builder.CreateICmpULE(IndexVal, BoundVal);\n  EmitCheck(std::make_pair(Check, SanitizerKind::ArrayBounds),\n            SanitizerHandler::OutOfBounds, StaticData, Index);\n}\n\n\nCodeGenFunction::ComplexPairTy CodeGenFunction::\nEmitComplexPrePostIncDec(const UnaryOperator *E, LValue LV,\n                         bool isInc, bool isPre) {\n  ComplexPairTy InVal = EmitLoadOfComplex(LV, E->getExprLoc());\n\n  llvm::Value *NextVal;\n  if (isa<llvm::IntegerType>(InVal.first->getType())) {\n    uint64_t AmountVal = isInc ? 1 : -1;\n    NextVal = llvm::ConstantInt::get(InVal.first->getType(), AmountVal, true);\n\n    // Add the inc/dec to the real part.\n    NextVal = Builder.CreateAdd(InVal.first, NextVal, isInc ? \"inc\" : \"dec\");\n  } else {\n    QualType ElemTy = E->getType()->castAs<ComplexType>()->getElementType();\n    llvm::APFloat FVal(getContext().getFloatTypeSemantics(ElemTy), 1);\n    if (!isInc)\n      FVal.changeSign();\n    NextVal = llvm::ConstantFP::get(getLLVMContext(), FVal);\n\n    // Add the inc/dec to the real part.\n    NextVal = Builder.CreateFAdd(InVal.first, NextVal, isInc ? \"inc\" : \"dec\");\n  }\n\n  ComplexPairTy IncVal(NextVal, InVal.second);\n\n  // Store the updated result through the lvalue.\n  EmitStoreOfComplex(IncVal, LV, /*init*/ false);\n  if (getLangOpts().OpenMP)\n    CGM.getOpenMPRuntime().checkAndEmitLastprivateConditional(*this,\n                                                              E->getSubExpr());\n\n  // If this is a postinc, return the value read from memory, otherwise use the\n  // updated value.\n  return isPre ? IncVal : InVal;\n}\n\nvoid CodeGenModule::EmitExplicitCastExprType(const ExplicitCastExpr *E,\n                                             CodeGenFunction *CGF) {\n  // Bind VLAs in the cast type.\n  if (CGF && E->getType()->isVariablyModifiedType())\n    CGF->EmitVariablyModifiedType(E->getType());\n\n  if (CGDebugInfo *DI = getModuleDebugInfo())\n    DI->EmitExplicitCastType(E->getType());\n}\n\n//===----------------------------------------------------------------------===//\n//                         LValue Expression Emission\n//===----------------------------------------------------------------------===//\n\n/// EmitPointerWithAlignment - Given an expression of pointer type, try to\n/// derive a more accurate bound on the alignment of the pointer.\nAddress CodeGenFunction::EmitPointerWithAlignment(const Expr *E,\n                                                  LValueBaseInfo *BaseInfo,\n                                                  TBAAAccessInfo *TBAAInfo) {\n  // We allow this with ObjC object pointers because of fragile ABIs.\n  assert(E->getType()->isPointerType() ||\n         E->getType()->isObjCObjectPointerType());\n  E = E->IgnoreParens();\n\n  // Casts:\n  if (const CastExpr *CE = dyn_cast<CastExpr>(E)) {\n    if (const auto *ECE = dyn_cast<ExplicitCastExpr>(CE))\n      CGM.EmitExplicitCastExprType(ECE, this);\n\n    switch (CE->getCastKind()) {\n    // Non-converting casts (but not C's implicit conversion from void*).\n    case CK_BitCast:\n    case CK_NoOp:\n    case CK_AddressSpaceConversion:\n      if (auto PtrTy = CE->getSubExpr()->getType()->getAs<PointerType>()) {\n        if (PtrTy->getPointeeType()->isVoidType())\n          break;\n\n        LValueBaseInfo InnerBaseInfo;\n        TBAAAccessInfo InnerTBAAInfo;\n        Address Addr = EmitPointerWithAlignment(CE->getSubExpr(),\n                                                &InnerBaseInfo,\n                                                &InnerTBAAInfo);\n        if (BaseInfo) *BaseInfo = InnerBaseInfo;\n        if (TBAAInfo) *TBAAInfo = InnerTBAAInfo;\n\n        if (isa<ExplicitCastExpr>(CE)) {\n          LValueBaseInfo TargetTypeBaseInfo;\n          TBAAAccessInfo TargetTypeTBAAInfo;\n          CharUnits Align = CGM.getNaturalPointeeTypeAlignment(\n              E->getType(), &TargetTypeBaseInfo, &TargetTypeTBAAInfo);\n          if (TBAAInfo)\n            *TBAAInfo = CGM.mergeTBAAInfoForCast(*TBAAInfo,\n                                                 TargetTypeTBAAInfo);\n          // If the source l-value is opaque, honor the alignment of the\n          // casted-to type.\n          if (InnerBaseInfo.getAlignmentSource() != AlignmentSource::Decl) {\n            if (BaseInfo)\n              BaseInfo->mergeForCast(TargetTypeBaseInfo);\n            Addr = Address(Addr.getPointer(), Align);\n          }\n        }\n\n        if (SanOpts.has(SanitizerKind::CFIUnrelatedCast) &&\n            CE->getCastKind() == CK_BitCast) {\n          if (auto PT = E->getType()->getAs<PointerType>())\n            EmitVTablePtrCheckForCast(PT->getPointeeType(), Addr.getPointer(),\n                                      /*MayBeNull=*/true,\n                                      CodeGenFunction::CFITCK_UnrelatedCast,\n                                      CE->getBeginLoc());\n        }\n        return CE->getCastKind() != CK_AddressSpaceConversion\n                   ? Builder.CreateBitCast(Addr, ConvertType(E->getType()))\n                   : Builder.CreateAddrSpaceCast(Addr,\n                                                 ConvertType(E->getType()));\n      }\n      break;\n\n    // Array-to-pointer decay.\n    case CK_ArrayToPointerDecay:\n      return EmitArrayToPointerDecay(CE->getSubExpr(), BaseInfo, TBAAInfo);\n\n    // Derived-to-base conversions.\n    case CK_UncheckedDerivedToBase:\n    case CK_DerivedToBase: {\n      // TODO: Support accesses to members of base classes in TBAA. For now, we\n      // conservatively pretend that the complete object is of the base class\n      // type.\n      if (TBAAInfo)\n        *TBAAInfo = CGM.getTBAAAccessInfo(E->getType());\n      Address Addr = EmitPointerWithAlignment(CE->getSubExpr(), BaseInfo);\n      auto Derived = CE->getSubExpr()->getType()->getPointeeCXXRecordDecl();\n      return GetAddressOfBaseClass(Addr, Derived,\n                                   CE->path_begin(), CE->path_end(),\n                                   ShouldNullCheckClassCastValue(CE),\n                                   CE->getExprLoc());\n    }\n\n    // TODO: Is there any reason to treat base-to-derived conversions\n    // specially?\n    default:\n      break;\n    }\n  }\n\n  // Unary &.\n  if (const UnaryOperator *UO = dyn_cast<UnaryOperator>(E)) {\n    if (UO->getOpcode() == UO_AddrOf) {\n      LValue LV = EmitLValue(UO->getSubExpr());\n      if (BaseInfo) *BaseInfo = LV.getBaseInfo();\n      if (TBAAInfo) *TBAAInfo = LV.getTBAAInfo();\n      return LV.getAddress(*this);\n    }\n  }\n\n  // TODO: conditional operators, comma.\n\n  // Otherwise, use the alignment of the type.\n  CharUnits Align =\n      CGM.getNaturalPointeeTypeAlignment(E->getType(), BaseInfo, TBAAInfo);\n  return Address(EmitScalarExpr(E), Align);\n}\n\nllvm::Value *CodeGenFunction::EmitNonNullRValueCheck(RValue RV, QualType T) {\n  llvm::Value *V = RV.getScalarVal();\n  if (auto MPT = T->getAs<MemberPointerType>())\n    return CGM.getCXXABI().EmitMemberPointerIsNotNull(*this, V, MPT);\n  return Builder.CreateICmpNE(V, llvm::Constant::getNullValue(V->getType()));\n}\n\nRValue CodeGenFunction::GetUndefRValue(QualType Ty) {\n  if (Ty->isVoidType())\n    return RValue::get(nullptr);\n\n  switch (getEvaluationKind(Ty)) {\n  case TEK_Complex: {\n    llvm::Type *EltTy =\n      ConvertType(Ty->castAs<ComplexType>()->getElementType());\n    llvm::Value *U = llvm::UndefValue::get(EltTy);\n    return RValue::getComplex(std::make_pair(U, U));\n  }\n\n  // If this is a use of an undefined aggregate type, the aggregate must have an\n  // identifiable address.  Just because the contents of the value are undefined\n  // doesn't mean that the address can't be taken and compared.\n  case TEK_Aggregate: {\n    Address DestPtr = CreateMemTemp(Ty, \"undef.agg.tmp\");\n    return RValue::getAggregate(DestPtr);\n  }\n\n  case TEK_Scalar:\n    return RValue::get(llvm::UndefValue::get(ConvertType(Ty)));\n  }\n  llvm_unreachable(\"bad evaluation kind\");\n}\n\nRValue CodeGenFunction::EmitUnsupportedRValue(const Expr *E,\n                                              const char *Name) {\n  ErrorUnsupported(E, Name);\n  return GetUndefRValue(E->getType());\n}\n\nLValue CodeGenFunction::EmitUnsupportedLValue(const Expr *E,\n                                              const char *Name) {\n  ErrorUnsupported(E, Name);\n  llvm::Type *Ty = llvm::PointerType::getUnqual(ConvertType(E->getType()));\n  return MakeAddrLValue(Address(llvm::UndefValue::get(Ty), CharUnits::One()),\n                        E->getType());\n}\n\nbool CodeGenFunction::IsWrappedCXXThis(const Expr *Obj) {\n  const Expr *Base = Obj;\n  while (!isa<CXXThisExpr>(Base)) {\n    // The result of a dynamic_cast can be null.\n    if (isa<CXXDynamicCastExpr>(Base))\n      return false;\n\n    if (const auto *CE = dyn_cast<CastExpr>(Base)) {\n      Base = CE->getSubExpr();\n    } else if (const auto *PE = dyn_cast<ParenExpr>(Base)) {\n      Base = PE->getSubExpr();\n    } else if (const auto *UO = dyn_cast<UnaryOperator>(Base)) {\n      if (UO->getOpcode() == UO_Extension)\n        Base = UO->getSubExpr();\n      else\n        return false;\n    } else {\n      return false;\n    }\n  }\n  return true;\n}\n\nLValue CodeGenFunction::EmitCheckedLValue(const Expr *E, TypeCheckKind TCK) {\n  LValue LV;\n  if (SanOpts.has(SanitizerKind::ArrayBounds) && isa<ArraySubscriptExpr>(E))\n    LV = EmitArraySubscriptExpr(cast<ArraySubscriptExpr>(E), /*Accessed*/true);\n  else\n    LV = EmitLValue(E);\n  if (!isa<DeclRefExpr>(E) && !LV.isBitField() && LV.isSimple()) {\n    SanitizerSet SkippedChecks;\n    if (const auto *ME = dyn_cast<MemberExpr>(E)) {\n      bool IsBaseCXXThis = IsWrappedCXXThis(ME->getBase());\n      if (IsBaseCXXThis)\n        SkippedChecks.set(SanitizerKind::Alignment, true);\n      if (IsBaseCXXThis || isa<DeclRefExpr>(ME->getBase()))\n        SkippedChecks.set(SanitizerKind::Null, true);\n    }\n    EmitTypeCheck(TCK, E->getExprLoc(), LV.getPointer(*this), E->getType(),\n                  LV.getAlignment(), SkippedChecks);\n  }\n  return LV;\n}\n\n/// EmitLValue - Emit code to compute a designator that specifies the location\n/// of the expression.\n///\n/// This can return one of two things: a simple address or a bitfield reference.\n/// In either case, the LLVM Value* in the LValue structure is guaranteed to be\n/// an LLVM pointer type.\n///\n/// If this returns a bitfield reference, nothing about the pointee type of the\n/// LLVM value is known: For example, it may not be a pointer to an integer.\n///\n/// If this returns a normal address, and if the lvalue's C type is fixed size,\n/// this method guarantees that the returned pointer type will point to an LLVM\n/// type of the same size of the lvalue's type.  If the lvalue has a variable\n/// length type, this is not possible.\n///\nLValue CodeGenFunction::EmitLValue(const Expr *E) {\n  ApplyDebugLocation DL(*this, E);\n  switch (E->getStmtClass()) {\n  default: return EmitUnsupportedLValue(E, \"l-value expression\");\n\n  case Expr::ObjCPropertyRefExprClass:\n    llvm_unreachable(\"cannot emit a property reference directly\");\n\n  case Expr::ObjCSelectorExprClass:\n    return EmitObjCSelectorLValue(cast<ObjCSelectorExpr>(E));\n  case Expr::ObjCIsaExprClass:\n    return EmitObjCIsaExpr(cast<ObjCIsaExpr>(E));\n  case Expr::BinaryOperatorClass:\n    return EmitBinaryOperatorLValue(cast<BinaryOperator>(E));\n  case Expr::CompoundAssignOperatorClass: {\n    QualType Ty = E->getType();\n    if (const AtomicType *AT = Ty->getAs<AtomicType>())\n      Ty = AT->getValueType();\n    if (!Ty->isAnyComplexType())\n      return EmitCompoundAssignmentLValue(cast<CompoundAssignOperator>(E));\n    return EmitComplexCompoundAssignmentLValue(cast<CompoundAssignOperator>(E));\n  }\n  case Expr::CallExprClass:\n  case Expr::CXXMemberCallExprClass:\n  case Expr::CXXOperatorCallExprClass:\n  case Expr::UserDefinedLiteralClass:\n    return EmitCallExprLValue(cast<CallExpr>(E));\n  case Expr::CXXRewrittenBinaryOperatorClass:\n    return EmitLValue(cast<CXXRewrittenBinaryOperator>(E)->getSemanticForm());\n  case Expr::VAArgExprClass:\n    return EmitVAArgExprLValue(cast<VAArgExpr>(E));\n  case Expr::DeclRefExprClass:\n    return EmitDeclRefLValue(cast<DeclRefExpr>(E));\n  case Expr::ConstantExprClass: {\n    const ConstantExpr *CE = cast<ConstantExpr>(E);\n    if (llvm::Value *Result = ConstantEmitter(*this).tryEmitConstantExpr(CE)) {\n      QualType RetType = cast<CallExpr>(CE->getSubExpr()->IgnoreImplicit())\n                             ->getCallReturnType(getContext());\n      return MakeNaturalAlignAddrLValue(Result, RetType);\n    }\n    return EmitLValue(cast<ConstantExpr>(E)->getSubExpr());\n  }\n  case Expr::ParenExprClass:\n    return EmitLValue(cast<ParenExpr>(E)->getSubExpr());\n  case Expr::GenericSelectionExprClass:\n    return EmitLValue(cast<GenericSelectionExpr>(E)->getResultExpr());\n  case Expr::PredefinedExprClass:\n    return EmitPredefinedLValue(cast<PredefinedExpr>(E));\n  case Expr::StringLiteralClass:\n    return EmitStringLiteralLValue(cast<StringLiteral>(E));\n  case Expr::ObjCEncodeExprClass:\n    return EmitObjCEncodeExprLValue(cast<ObjCEncodeExpr>(E));\n  case Expr::PseudoObjectExprClass:\n    return EmitPseudoObjectLValue(cast<PseudoObjectExpr>(E));\n  case Expr::InitListExprClass:\n    return EmitInitListLValue(cast<InitListExpr>(E));\n  case Expr::CXXTemporaryObjectExprClass:\n  case Expr::CXXConstructExprClass:\n    return EmitCXXConstructLValue(cast<CXXConstructExpr>(E));\n  case Expr::CXXBindTemporaryExprClass:\n    return EmitCXXBindTemporaryLValue(cast<CXXBindTemporaryExpr>(E));\n  case Expr::CXXUuidofExprClass:\n    return EmitCXXUuidofLValue(cast<CXXUuidofExpr>(E));\n  case Expr::LambdaExprClass:\n    return EmitAggExprToLValue(E);\n\n  case Expr::ExprWithCleanupsClass: {\n    const auto *cleanups = cast<ExprWithCleanups>(E);\n    RunCleanupsScope Scope(*this);\n    LValue LV = EmitLValue(cleanups->getSubExpr());\n    if (LV.isSimple()) {\n      // Defend against branches out of gnu statement expressions surrounded by\n      // cleanups.\n      llvm::Value *V = LV.getPointer(*this);\n      Scope.ForceCleanup({&V});\n      return LValue::MakeAddr(Address(V, LV.getAlignment()), LV.getType(),\n                              getContext(), LV.getBaseInfo(), LV.getTBAAInfo());\n    }\n    // FIXME: Is it possible to create an ExprWithCleanups that produces a\n    // bitfield lvalue or some other non-simple lvalue?\n    return LV;\n  }\n\n  case Expr::CXXDefaultArgExprClass: {\n    auto *DAE = cast<CXXDefaultArgExpr>(E);\n    CXXDefaultArgExprScope Scope(*this, DAE);\n    return EmitLValue(DAE->getExpr());\n  }\n  case Expr::CXXDefaultInitExprClass: {\n    auto *DIE = cast<CXXDefaultInitExpr>(E);\n    CXXDefaultInitExprScope Scope(*this, DIE);\n    return EmitLValue(DIE->getExpr());\n  }\n  case Expr::CXXTypeidExprClass:\n    return EmitCXXTypeidLValue(cast<CXXTypeidExpr>(E));\n\n  case Expr::ObjCMessageExprClass:\n    return EmitObjCMessageExprLValue(cast<ObjCMessageExpr>(E));\n  case Expr::ObjCIvarRefExprClass:\n    return EmitObjCIvarRefLValue(cast<ObjCIvarRefExpr>(E));\n  case Expr::StmtExprClass:\n    return EmitStmtExprLValue(cast<StmtExpr>(E));\n  case Expr::UnaryOperatorClass:\n    return EmitUnaryOpLValue(cast<UnaryOperator>(E));\n  case Expr::ArraySubscriptExprClass:\n    return EmitArraySubscriptExpr(cast<ArraySubscriptExpr>(E));\n  case Expr::MatrixSubscriptExprClass:\n    return EmitMatrixSubscriptExpr(cast<MatrixSubscriptExpr>(E));\n  case Expr::OMPArraySectionExprClass:\n    return EmitOMPArraySectionExpr(cast<OMPArraySectionExpr>(E));\n  case Expr::ExtVectorElementExprClass:\n    return EmitExtVectorElementExpr(cast<ExtVectorElementExpr>(E));\n  case Expr::MemberExprClass:\n    return EmitMemberExpr(cast<MemberExpr>(E));\n  case Expr::CompoundLiteralExprClass:\n    return EmitCompoundLiteralLValue(cast<CompoundLiteralExpr>(E));\n  case Expr::ConditionalOperatorClass:\n    return EmitConditionalOperatorLValue(cast<ConditionalOperator>(E));\n  case Expr::BinaryConditionalOperatorClass:\n    return EmitConditionalOperatorLValue(cast<BinaryConditionalOperator>(E));\n  case Expr::ChooseExprClass:\n    return EmitLValue(cast<ChooseExpr>(E)->getChosenSubExpr());\n  case Expr::OpaqueValueExprClass:\n    return EmitOpaqueValueLValue(cast<OpaqueValueExpr>(E));\n  case Expr::SubstNonTypeTemplateParmExprClass:\n    return EmitLValue(cast<SubstNonTypeTemplateParmExpr>(E)->getReplacement());\n  case Expr::ImplicitCastExprClass:\n  case Expr::CStyleCastExprClass:\n  case Expr::CXXFunctionalCastExprClass:\n  case Expr::CXXStaticCastExprClass:\n  case Expr::CXXDynamicCastExprClass:\n  case Expr::CXXReinterpretCastExprClass:\n  case Expr::CXXConstCastExprClass:\n  case Expr::CXXAddrspaceCastExprClass:\n  case Expr::ObjCBridgedCastExprClass:\n    return EmitCastLValue(cast<CastExpr>(E));\n\n  case Expr::MaterializeTemporaryExprClass:\n    return EmitMaterializeTemporaryExpr(cast<MaterializeTemporaryExpr>(E));\n\n  case Expr::CoawaitExprClass:\n    return EmitCoawaitLValue(cast<CoawaitExpr>(E));\n  case Expr::CoyieldExprClass:\n    return EmitCoyieldLValue(cast<CoyieldExpr>(E));\n  }\n}\n\n/// Given an object of the given canonical type, can we safely copy a\n/// value out of it based on its initializer?\nstatic bool isConstantEmittableObjectType(QualType type) {\n  assert(type.isCanonical());\n  assert(!type->isReferenceType());\n\n  // Must be const-qualified but non-volatile.\n  Qualifiers qs = type.getLocalQualifiers();\n  if (!qs.hasConst() || qs.hasVolatile()) return false;\n\n  // Otherwise, all object types satisfy this except C++ classes with\n  // mutable subobjects or non-trivial copy/destroy behavior.\n  if (const auto *RT = dyn_cast<RecordType>(type))\n    if (const auto *RD = dyn_cast<CXXRecordDecl>(RT->getDecl()))\n      if (RD->hasMutableFields() || !RD->isTrivial())\n        return false;\n\n  return true;\n}\n\n/// Can we constant-emit a load of a reference to a variable of the\n/// given type?  This is different from predicates like\n/// Decl::mightBeUsableInConstantExpressions because we do want it to apply\n/// in situations that don't necessarily satisfy the language's rules\n/// for this (e.g. C++'s ODR-use rules).  For example, we want to able\n/// to do this with const float variables even if those variables\n/// aren't marked 'constexpr'.\nenum ConstantEmissionKind {\n  CEK_None,\n  CEK_AsReferenceOnly,\n  CEK_AsValueOrReference,\n  CEK_AsValueOnly\n};\nstatic ConstantEmissionKind checkVarTypeForConstantEmission(QualType type) {\n  type = type.getCanonicalType();\n  if (const auto *ref = dyn_cast<ReferenceType>(type)) {\n    if (isConstantEmittableObjectType(ref->getPointeeType()))\n      return CEK_AsValueOrReference;\n    return CEK_AsReferenceOnly;\n  }\n  if (isConstantEmittableObjectType(type))\n    return CEK_AsValueOnly;\n  return CEK_None;\n}\n\n/// Try to emit a reference to the given value without producing it as\n/// an l-value.  This is just an optimization, but it avoids us needing\n/// to emit global copies of variables if they're named without triggering\n/// a formal use in a context where we can't emit a direct reference to them,\n/// for instance if a block or lambda or a member of a local class uses a\n/// const int variable or constexpr variable from an enclosing function.\nCodeGenFunction::ConstantEmission\nCodeGenFunction::tryEmitAsConstant(DeclRefExpr *refExpr) {\n  ValueDecl *value = refExpr->getDecl();\n\n  // The value needs to be an enum constant or a constant variable.\n  ConstantEmissionKind CEK;\n  if (isa<ParmVarDecl>(value)) {\n    CEK = CEK_None;\n  } else if (auto *var = dyn_cast<VarDecl>(value)) {\n    CEK = checkVarTypeForConstantEmission(var->getType());\n  } else if (isa<EnumConstantDecl>(value)) {\n    CEK = CEK_AsValueOnly;\n  } else {\n    CEK = CEK_None;\n  }\n  if (CEK == CEK_None) return ConstantEmission();\n\n  Expr::EvalResult result;\n  bool resultIsReference;\n  QualType resultType;\n\n  // It's best to evaluate all the way as an r-value if that's permitted.\n  if (CEK != CEK_AsReferenceOnly &&\n      refExpr->EvaluateAsRValue(result, getContext())) {\n    resultIsReference = false;\n    resultType = refExpr->getType();\n\n  // Otherwise, try to evaluate as an l-value.\n  } else if (CEK != CEK_AsValueOnly &&\n             refExpr->EvaluateAsLValue(result, getContext())) {\n    resultIsReference = true;\n    resultType = value->getType();\n\n  // Failure.\n  } else {\n    return ConstantEmission();\n  }\n\n  // In any case, if the initializer has side-effects, abandon ship.\n  if (result.HasSideEffects)\n    return ConstantEmission();\n\n  // In CUDA/HIP device compilation, a lambda may capture a reference variable\n  // referencing a global host variable by copy. In this case the lambda should\n  // make a copy of the value of the global host variable. The DRE of the\n  // captured reference variable cannot be emitted as load from the host\n  // global variable as compile time constant, since the host variable is not\n  // accessible on device. The DRE of the captured reference variable has to be\n  // loaded from captures.\n  if (CGM.getLangOpts().CUDAIsDevice && result.Val.isLValue() &&\n      refExpr->refersToEnclosingVariableOrCapture()) {\n    auto *MD = dyn_cast_or_null<CXXMethodDecl>(CurCodeDecl);\n    if (MD && MD->getParent()->isLambda() &&\n        MD->getOverloadedOperator() == OO_Call) {\n      const APValue::LValueBase &base = result.Val.getLValueBase();\n      if (const ValueDecl *D = base.dyn_cast<const ValueDecl *>()) {\n        if (const VarDecl *VD = dyn_cast<const VarDecl>(D)) {\n          if (!VD->hasAttr<CUDADeviceAttr>()) {\n            return ConstantEmission();\n          }\n        }\n      }\n    }\n  }\n\n  // Emit as a constant.\n  auto C = ConstantEmitter(*this).emitAbstract(refExpr->getLocation(),\n                                               result.Val, resultType);\n\n  // Make sure we emit a debug reference to the global variable.\n  // This should probably fire even for\n  if (isa<VarDecl>(value)) {\n    if (!getContext().DeclMustBeEmitted(cast<VarDecl>(value)))\n      EmitDeclRefExprDbgValue(refExpr, result.Val);\n  } else {\n    assert(isa<EnumConstantDecl>(value));\n    EmitDeclRefExprDbgValue(refExpr, result.Val);\n  }\n\n  // If we emitted a reference constant, we need to dereference that.\n  if (resultIsReference)\n    return ConstantEmission::forReference(C);\n\n  return ConstantEmission::forValue(C);\n}\n\nstatic DeclRefExpr *tryToConvertMemberExprToDeclRefExpr(CodeGenFunction &CGF,\n                                                        const MemberExpr *ME) {\n  if (auto *VD = dyn_cast<VarDecl>(ME->getMemberDecl())) {\n    // Try to emit static variable member expressions as DREs.\n    return DeclRefExpr::Create(\n        CGF.getContext(), NestedNameSpecifierLoc(), SourceLocation(), VD,\n        /*RefersToEnclosingVariableOrCapture=*/false, ME->getExprLoc(),\n        ME->getType(), ME->getValueKind(), nullptr, nullptr, ME->isNonOdrUse());\n  }\n  return nullptr;\n}\n\nCodeGenFunction::ConstantEmission\nCodeGenFunction::tryEmitAsConstant(const MemberExpr *ME) {\n  if (DeclRefExpr *DRE = tryToConvertMemberExprToDeclRefExpr(*this, ME))\n    return tryEmitAsConstant(DRE);\n  return ConstantEmission();\n}\n\nllvm::Value *CodeGenFunction::emitScalarConstant(\n    const CodeGenFunction::ConstantEmission &Constant, Expr *E) {\n  assert(Constant && \"not a constant\");\n  if (Constant.isReference())\n    return EmitLoadOfLValue(Constant.getReferenceLValue(*this, E),\n                            E->getExprLoc())\n        .getScalarVal();\n  return Constant.getValue();\n}\n\nllvm::Value *CodeGenFunction::EmitLoadOfScalar(LValue lvalue,\n                                               SourceLocation Loc) {\n  return EmitLoadOfScalar(lvalue.getAddress(*this), lvalue.isVolatile(),\n                          lvalue.getType(), Loc, lvalue.getBaseInfo(),\n                          lvalue.getTBAAInfo(), lvalue.isNontemporal());\n}\n\nstatic bool hasBooleanRepresentation(QualType Ty) {\n  if (Ty->isBooleanType())\n    return true;\n\n  if (const EnumType *ET = Ty->getAs<EnumType>())\n    return ET->getDecl()->getIntegerType()->isBooleanType();\n\n  if (const AtomicType *AT = Ty->getAs<AtomicType>())\n    return hasBooleanRepresentation(AT->getValueType());\n\n  return false;\n}\n\nstatic bool getRangeForType(CodeGenFunction &CGF, QualType Ty,\n                            llvm::APInt &Min, llvm::APInt &End,\n                            bool StrictEnums, bool IsBool) {\n  const EnumType *ET = Ty->getAs<EnumType>();\n  bool IsRegularCPlusPlusEnum = CGF.getLangOpts().CPlusPlus && StrictEnums &&\n                                ET && !ET->getDecl()->isFixed();\n  if (!IsBool && !IsRegularCPlusPlusEnum)\n    return false;\n\n  if (IsBool) {\n    Min = llvm::APInt(CGF.getContext().getTypeSize(Ty), 0);\n    End = llvm::APInt(CGF.getContext().getTypeSize(Ty), 2);\n  } else {\n    const EnumDecl *ED = ET->getDecl();\n    llvm::Type *LTy = CGF.ConvertTypeForMem(ED->getIntegerType());\n    unsigned Bitwidth = LTy->getScalarSizeInBits();\n    unsigned NumNegativeBits = ED->getNumNegativeBits();\n    unsigned NumPositiveBits = ED->getNumPositiveBits();\n\n    if (NumNegativeBits) {\n      unsigned NumBits = std::max(NumNegativeBits, NumPositiveBits + 1);\n      assert(NumBits <= Bitwidth);\n      End = llvm::APInt(Bitwidth, 1) << (NumBits - 1);\n      Min = -End;\n    } else {\n      assert(NumPositiveBits <= Bitwidth);\n      End = llvm::APInt(Bitwidth, 1) << NumPositiveBits;\n      Min = llvm::APInt(Bitwidth, 0);\n    }\n  }\n  return true;\n}\n\nllvm::MDNode *CodeGenFunction::getRangeForLoadFromType(QualType Ty) {\n  llvm::APInt Min, End;\n  if (!getRangeForType(*this, Ty, Min, End, CGM.getCodeGenOpts().StrictEnums,\n                       hasBooleanRepresentation(Ty)))\n    return nullptr;\n\n  llvm::MDBuilder MDHelper(getLLVMContext());\n  return MDHelper.createRange(Min, End);\n}\n\nbool CodeGenFunction::EmitScalarRangeCheck(llvm::Value *Value, QualType Ty,\n                                           SourceLocation Loc) {\n  bool HasBoolCheck = SanOpts.has(SanitizerKind::Bool);\n  bool HasEnumCheck = SanOpts.has(SanitizerKind::Enum);\n  if (!HasBoolCheck && !HasEnumCheck)\n    return false;\n\n  bool IsBool = hasBooleanRepresentation(Ty) ||\n                NSAPI(CGM.getContext()).isObjCBOOLType(Ty);\n  bool NeedsBoolCheck = HasBoolCheck && IsBool;\n  bool NeedsEnumCheck = HasEnumCheck && Ty->getAs<EnumType>();\n  if (!NeedsBoolCheck && !NeedsEnumCheck)\n    return false;\n\n  // Single-bit booleans don't need to be checked. Special-case this to avoid\n  // a bit width mismatch when handling bitfield values. This is handled by\n  // EmitFromMemory for the non-bitfield case.\n  if (IsBool &&\n      cast<llvm::IntegerType>(Value->getType())->getBitWidth() == 1)\n    return false;\n\n  llvm::APInt Min, End;\n  if (!getRangeForType(*this, Ty, Min, End, /*StrictEnums=*/true, IsBool))\n    return true;\n\n  auto &Ctx = getLLVMContext();\n  SanitizerScope SanScope(this);\n  llvm::Value *Check;\n  --End;\n  if (!Min) {\n    Check = Builder.CreateICmpULE(Value, llvm::ConstantInt::get(Ctx, End));\n  } else {\n    llvm::Value *Upper =\n        Builder.CreateICmpSLE(Value, llvm::ConstantInt::get(Ctx, End));\n    llvm::Value *Lower =\n        Builder.CreateICmpSGE(Value, llvm::ConstantInt::get(Ctx, Min));\n    Check = Builder.CreateAnd(Upper, Lower);\n  }\n  llvm::Constant *StaticArgs[] = {EmitCheckSourceLocation(Loc),\n                                  EmitCheckTypeDescriptor(Ty)};\n  SanitizerMask Kind =\n      NeedsEnumCheck ? SanitizerKind::Enum : SanitizerKind::Bool;\n  EmitCheck(std::make_pair(Check, Kind), SanitizerHandler::LoadInvalidValue,\n            StaticArgs, EmitCheckValue(Value));\n  return true;\n}\n\nllvm::Value *CodeGenFunction::EmitLoadOfScalar(Address Addr, bool Volatile,\n                                               QualType Ty,\n                                               SourceLocation Loc,\n                                               LValueBaseInfo BaseInfo,\n                                               TBAAAccessInfo TBAAInfo,\n                                               bool isNontemporal) {\n  if (!CGM.getCodeGenOpts().PreserveVec3Type) {\n    // For better performance, handle vector loads differently.\n    if (Ty->isVectorType()) {\n      const llvm::Type *EltTy = Addr.getElementType();\n\n      const auto *VTy = cast<llvm::FixedVectorType>(EltTy);\n\n      // Handle vectors of size 3 like size 4 for better performance.\n      if (VTy->getNumElements() == 3) {\n\n        // Bitcast to vec4 type.\n        auto *vec4Ty = llvm::FixedVectorType::get(VTy->getElementType(), 4);\n        Address Cast = Builder.CreateElementBitCast(Addr, vec4Ty, \"castToVec4\");\n        // Now load value.\n        llvm::Value *V = Builder.CreateLoad(Cast, Volatile, \"loadVec4\");\n\n        // Shuffle vector to get vec3.\n        V = Builder.CreateShuffleVector(V, ArrayRef<int>{0, 1, 2},\n                                        \"extractVec\");\n        return EmitFromMemory(V, Ty);\n      }\n    }\n  }\n\n  // Atomic operations have to be done on integral types.\n  LValue AtomicLValue =\n      LValue::MakeAddr(Addr, Ty, getContext(), BaseInfo, TBAAInfo);\n  if (Ty->isAtomicType() || LValueIsSuitableForInlineAtomic(AtomicLValue)) {\n    return EmitAtomicLoad(AtomicLValue, Loc).getScalarVal();\n  }\n\n  llvm::LoadInst *Load = Builder.CreateLoad(Addr, Volatile);\n  if (isNontemporal) {\n    llvm::MDNode *Node = llvm::MDNode::get(\n        Load->getContext(), llvm::ConstantAsMetadata::get(Builder.getInt32(1)));\n    Load->setMetadata(CGM.getModule().getMDKindID(\"nontemporal\"), Node);\n  }\n\n  CGM.DecorateInstructionWithTBAA(Load, TBAAInfo);\n\n  if (EmitScalarRangeCheck(Load, Ty, Loc)) {\n    // In order to prevent the optimizer from throwing away the check, don't\n    // attach range metadata to the load.\n  } else if (CGM.getCodeGenOpts().OptimizationLevel > 0)\n    if (llvm::MDNode *RangeInfo = getRangeForLoadFromType(Ty))\n      Load->setMetadata(llvm::LLVMContext::MD_range, RangeInfo);\n\n  return EmitFromMemory(Load, Ty);\n}\n\nllvm::Value *CodeGenFunction::EmitToMemory(llvm::Value *Value, QualType Ty) {\n  // Bool has a different representation in memory than in registers.\n  if (hasBooleanRepresentation(Ty)) {\n    // This should really always be an i1, but sometimes it's already\n    // an i8, and it's awkward to track those cases down.\n    if (Value->getType()->isIntegerTy(1))\n      return Builder.CreateZExt(Value, ConvertTypeForMem(Ty), \"frombool\");\n    assert(Value->getType()->isIntegerTy(getContext().getTypeSize(Ty)) &&\n           \"wrong value rep of bool\");\n  }\n\n  return Value;\n}\n\nllvm::Value *CodeGenFunction::EmitFromMemory(llvm::Value *Value, QualType Ty) {\n  // Bool has a different representation in memory than in registers.\n  if (hasBooleanRepresentation(Ty)) {\n    assert(Value->getType()->isIntegerTy(getContext().getTypeSize(Ty)) &&\n           \"wrong value rep of bool\");\n    return Builder.CreateTrunc(Value, Builder.getInt1Ty(), \"tobool\");\n  }\n\n  return Value;\n}\n\n// Convert the pointer of \\p Addr to a pointer to a vector (the value type of\n// MatrixType), if it points to a array (the memory type of MatrixType).\nstatic Address MaybeConvertMatrixAddress(Address Addr, CodeGenFunction &CGF,\n                                         bool IsVector = true) {\n  auto *ArrayTy = dyn_cast<llvm::ArrayType>(\n      cast<llvm::PointerType>(Addr.getPointer()->getType())->getElementType());\n  if (ArrayTy && IsVector) {\n    auto *VectorTy = llvm::FixedVectorType::get(ArrayTy->getElementType(),\n                                                ArrayTy->getNumElements());\n\n    return Address(CGF.Builder.CreateElementBitCast(Addr, VectorTy));\n  }\n  auto *VectorTy = dyn_cast<llvm::VectorType>(\n      cast<llvm::PointerType>(Addr.getPointer()->getType())->getElementType());\n  if (VectorTy && !IsVector) {\n    auto *ArrayTy = llvm::ArrayType::get(\n        VectorTy->getElementType(),\n        cast<llvm::FixedVectorType>(VectorTy)->getNumElements());\n\n    return Address(CGF.Builder.CreateElementBitCast(Addr, ArrayTy));\n  }\n\n  return Addr;\n}\n\n// Emit a store of a matrix LValue. This may require casting the original\n// pointer to memory address (ArrayType) to a pointer to the value type\n// (VectorType).\nstatic void EmitStoreOfMatrixScalar(llvm::Value *value, LValue lvalue,\n                                    bool isInit, CodeGenFunction &CGF) {\n  Address Addr = MaybeConvertMatrixAddress(lvalue.getAddress(CGF), CGF,\n                                           value->getType()->isVectorTy());\n  CGF.EmitStoreOfScalar(value, Addr, lvalue.isVolatile(), lvalue.getType(),\n                        lvalue.getBaseInfo(), lvalue.getTBAAInfo(), isInit,\n                        lvalue.isNontemporal());\n}\n\nvoid CodeGenFunction::EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                                        bool Volatile, QualType Ty,\n                                        LValueBaseInfo BaseInfo,\n                                        TBAAAccessInfo TBAAInfo,\n                                        bool isInit, bool isNontemporal) {\n  if (!CGM.getCodeGenOpts().PreserveVec3Type) {\n    // Handle vectors differently to get better performance.\n    if (Ty->isVectorType()) {\n      llvm::Type *SrcTy = Value->getType();\n      auto *VecTy = dyn_cast<llvm::VectorType>(SrcTy);\n      // Handle vec3 special.\n      if (VecTy && cast<llvm::FixedVectorType>(VecTy)->getNumElements() == 3) {\n        // Our source is a vec3, do a shuffle vector to make it a vec4.\n        Value = Builder.CreateShuffleVector(Value, ArrayRef<int>{0, 1, 2, -1},\n                                            \"extractVec\");\n        SrcTy = llvm::FixedVectorType::get(VecTy->getElementType(), 4);\n      }\n      if (Addr.getElementType() != SrcTy) {\n        Addr = Builder.CreateElementBitCast(Addr, SrcTy, \"storetmp\");\n      }\n    }\n  }\n\n  Value = EmitToMemory(Value, Ty);\n\n  LValue AtomicLValue =\n      LValue::MakeAddr(Addr, Ty, getContext(), BaseInfo, TBAAInfo);\n  if (Ty->isAtomicType() ||\n      (!isInit && LValueIsSuitableForInlineAtomic(AtomicLValue))) {\n    EmitAtomicStore(RValue::get(Value), AtomicLValue, isInit);\n    return;\n  }\n\n  llvm::StoreInst *Store = Builder.CreateStore(Value, Addr, Volatile);\n  if (isNontemporal) {\n    llvm::MDNode *Node =\n        llvm::MDNode::get(Store->getContext(),\n                          llvm::ConstantAsMetadata::get(Builder.getInt32(1)));\n    Store->setMetadata(CGM.getModule().getMDKindID(\"nontemporal\"), Node);\n  }\n\n  CGM.DecorateInstructionWithTBAA(Store, TBAAInfo);\n}\n\nvoid CodeGenFunction::EmitStoreOfScalar(llvm::Value *value, LValue lvalue,\n                                        bool isInit) {\n  if (lvalue.getType()->isConstantMatrixType()) {\n    EmitStoreOfMatrixScalar(value, lvalue, isInit, *this);\n    return;\n  }\n\n  EmitStoreOfScalar(value, lvalue.getAddress(*this), lvalue.isVolatile(),\n                    lvalue.getType(), lvalue.getBaseInfo(),\n                    lvalue.getTBAAInfo(), isInit, lvalue.isNontemporal());\n}\n\n// Emit a load of a LValue of matrix type. This may require casting the pointer\n// to memory address (ArrayType) to a pointer to the value type (VectorType).\nstatic RValue EmitLoadOfMatrixLValue(LValue LV, SourceLocation Loc,\n                                     CodeGenFunction &CGF) {\n  assert(LV.getType()->isConstantMatrixType());\n  Address Addr = MaybeConvertMatrixAddress(LV.getAddress(CGF), CGF);\n  LV.setAddress(Addr);\n  return RValue::get(CGF.EmitLoadOfScalar(LV, Loc));\n}\n\n/// EmitLoadOfLValue - Given an expression that represents a value lvalue, this\n/// method emits the address of the lvalue, then loads the result as an rvalue,\n/// returning the rvalue.\nRValue CodeGenFunction::EmitLoadOfLValue(LValue LV, SourceLocation Loc) {\n  if (LV.isObjCWeak()) {\n    // load of a __weak object.\n    Address AddrWeakObj = LV.getAddress(*this);\n    return RValue::get(CGM.getObjCRuntime().EmitObjCWeakRead(*this,\n                                                             AddrWeakObj));\n  }\n  if (LV.getQuals().getObjCLifetime() == Qualifiers::OCL_Weak) {\n    // In MRC mode, we do a load+autorelease.\n    if (!getLangOpts().ObjCAutoRefCount) {\n      return RValue::get(EmitARCLoadWeak(LV.getAddress(*this)));\n    }\n\n    // In ARC mode, we load retained and then consume the value.\n    llvm::Value *Object = EmitARCLoadWeakRetained(LV.getAddress(*this));\n    Object = EmitObjCConsumeObject(LV.getType(), Object);\n    return RValue::get(Object);\n  }\n\n  if (LV.isSimple()) {\n    assert(!LV.getType()->isFunctionType());\n\n    if (LV.getType()->isConstantMatrixType())\n      return EmitLoadOfMatrixLValue(LV, Loc, *this);\n\n    // Everything needs a load.\n    return RValue::get(EmitLoadOfScalar(LV, Loc));\n  }\n\n  if (LV.isVectorElt()) {\n    llvm::LoadInst *Load = Builder.CreateLoad(LV.getVectorAddress(),\n                                              LV.isVolatileQualified());\n    return RValue::get(Builder.CreateExtractElement(Load, LV.getVectorIdx(),\n                                                    \"vecext\"));\n  }\n\n  // If this is a reference to a subset of the elements of a vector, either\n  // shuffle the input or extract/insert them as appropriate.\n  if (LV.isExtVectorElt()) {\n    return EmitLoadOfExtVectorElementLValue(LV);\n  }\n\n  // Global Register variables always invoke intrinsics\n  if (LV.isGlobalReg())\n    return EmitLoadOfGlobalRegLValue(LV);\n\n  if (LV.isMatrixElt()) {\n    llvm::LoadInst *Load =\n        Builder.CreateLoad(LV.getMatrixAddress(), LV.isVolatileQualified());\n    return RValue::get(\n        Builder.CreateExtractElement(Load, LV.getMatrixIdx(), \"matrixext\"));\n  }\n\n  assert(LV.isBitField() && \"Unknown LValue type!\");\n  return EmitLoadOfBitfieldLValue(LV, Loc);\n}\n\nRValue CodeGenFunction::EmitLoadOfBitfieldLValue(LValue LV,\n                                                 SourceLocation Loc) {\n  const CGBitFieldInfo &Info = LV.getBitFieldInfo();\n\n  // Get the output type.\n  llvm::Type *ResLTy = ConvertType(LV.getType());\n\n  Address Ptr = LV.getBitFieldAddress();\n  llvm::Value *Val =\n      Builder.CreateLoad(Ptr, LV.isVolatileQualified(), \"bf.load\");\n\n  bool UseVolatile = LV.isVolatileQualified() &&\n                     Info.VolatileStorageSize != 0 && isAAPCS(CGM.getTarget());\n  const unsigned Offset = UseVolatile ? Info.VolatileOffset : Info.Offset;\n  const unsigned StorageSize =\n      UseVolatile ? Info.VolatileStorageSize : Info.StorageSize;\n  if (Info.IsSigned) {\n    assert(static_cast<unsigned>(Offset + Info.Size) <= StorageSize);\n    unsigned HighBits = StorageSize - Offset - Info.Size;\n    if (HighBits)\n      Val = Builder.CreateShl(Val, HighBits, \"bf.shl\");\n    if (Offset + HighBits)\n      Val = Builder.CreateAShr(Val, Offset + HighBits, \"bf.ashr\");\n  } else {\n    if (Offset)\n      Val = Builder.CreateLShr(Val, Offset, \"bf.lshr\");\n    if (static_cast<unsigned>(Offset) + Info.Size < StorageSize)\n      Val = Builder.CreateAnd(\n          Val, llvm::APInt::getLowBitsSet(StorageSize, Info.Size), \"bf.clear\");\n  }\n  Val = Builder.CreateIntCast(Val, ResLTy, Info.IsSigned, \"bf.cast\");\n  EmitScalarRangeCheck(Val, LV.getType(), Loc);\n  return RValue::get(Val);\n}\n\n// If this is a reference to a subset of the elements of a vector, create an\n// appropriate shufflevector.\nRValue CodeGenFunction::EmitLoadOfExtVectorElementLValue(LValue LV) {\n  llvm::Value *Vec = Builder.CreateLoad(LV.getExtVectorAddress(),\n                                        LV.isVolatileQualified());\n\n  const llvm::Constant *Elts = LV.getExtVectorElts();\n\n  // If the result of the expression is a non-vector type, we must be extracting\n  // a single element.  Just codegen as an extractelement.\n  const VectorType *ExprVT = LV.getType()->getAs<VectorType>();\n  if (!ExprVT) {\n    unsigned InIdx = getAccessedFieldNo(0, Elts);\n    llvm::Value *Elt = llvm::ConstantInt::get(SizeTy, InIdx);\n    return RValue::get(Builder.CreateExtractElement(Vec, Elt));\n  }\n\n  // Always use shuffle vector to try to retain the original program structure\n  unsigned NumResultElts = ExprVT->getNumElements();\n\n  SmallVector<int, 4> Mask;\n  for (unsigned i = 0; i != NumResultElts; ++i)\n    Mask.push_back(getAccessedFieldNo(i, Elts));\n\n  Vec = Builder.CreateShuffleVector(Vec, Mask);\n  return RValue::get(Vec);\n}\n\n/// Generates lvalue for partial ext_vector access.\nAddress CodeGenFunction::EmitExtVectorElementLValue(LValue LV) {\n  Address VectorAddress = LV.getExtVectorAddress();\n  QualType EQT = LV.getType()->castAs<VectorType>()->getElementType();\n  llvm::Type *VectorElementTy = CGM.getTypes().ConvertType(EQT);\n\n  Address CastToPointerElement =\n    Builder.CreateElementBitCast(VectorAddress, VectorElementTy,\n                                 \"conv.ptr.element\");\n\n  const llvm::Constant *Elts = LV.getExtVectorElts();\n  unsigned ix = getAccessedFieldNo(0, Elts);\n\n  Address VectorBasePtrPlusIx =\n    Builder.CreateConstInBoundsGEP(CastToPointerElement, ix,\n                                   \"vector.elt\");\n\n  return VectorBasePtrPlusIx;\n}\n\n/// Load of global gamed gegisters are always calls to intrinsics.\nRValue CodeGenFunction::EmitLoadOfGlobalRegLValue(LValue LV) {\n  assert((LV.getType()->isIntegerType() || LV.getType()->isPointerType()) &&\n         \"Bad type for register variable\");\n  llvm::MDNode *RegName = cast<llvm::MDNode>(\n      cast<llvm::MetadataAsValue>(LV.getGlobalReg())->getMetadata());\n\n  // We accept integer and pointer types only\n  llvm::Type *OrigTy = CGM.getTypes().ConvertType(LV.getType());\n  llvm::Type *Ty = OrigTy;\n  if (OrigTy->isPointerTy())\n    Ty = CGM.getTypes().getDataLayout().getIntPtrType(OrigTy);\n  llvm::Type *Types[] = { Ty };\n\n  llvm::Function *F = CGM.getIntrinsic(llvm::Intrinsic::read_register, Types);\n  llvm::Value *Call = Builder.CreateCall(\n      F, llvm::MetadataAsValue::get(Ty->getContext(), RegName));\n  if (OrigTy->isPointerTy())\n    Call = Builder.CreateIntToPtr(Call, OrigTy);\n  return RValue::get(Call);\n}\n\n/// EmitStoreThroughLValue - Store the specified rvalue into the specified\n/// lvalue, where both are guaranteed to the have the same type, and that type\n/// is 'Ty'.\nvoid CodeGenFunction::EmitStoreThroughLValue(RValue Src, LValue Dst,\n                                             bool isInit) {\n  if (!Dst.isSimple()) {\n    if (Dst.isVectorElt()) {\n      // Read/modify/write the vector, inserting the new element.\n      llvm::Value *Vec = Builder.CreateLoad(Dst.getVectorAddress(),\n                                            Dst.isVolatileQualified());\n      Vec = Builder.CreateInsertElement(Vec, Src.getScalarVal(),\n                                        Dst.getVectorIdx(), \"vecins\");\n      Builder.CreateStore(Vec, Dst.getVectorAddress(),\n                          Dst.isVolatileQualified());\n      return;\n    }\n\n    // If this is an update of extended vector elements, insert them as\n    // appropriate.\n    if (Dst.isExtVectorElt())\n      return EmitStoreThroughExtVectorComponentLValue(Src, Dst);\n\n    if (Dst.isGlobalReg())\n      return EmitStoreThroughGlobalRegLValue(Src, Dst);\n\n    if (Dst.isMatrixElt()) {\n      llvm::Value *Vec = Builder.CreateLoad(Dst.getMatrixAddress());\n      Vec = Builder.CreateInsertElement(Vec, Src.getScalarVal(),\n                                        Dst.getMatrixIdx(), \"matins\");\n      Builder.CreateStore(Vec, Dst.getMatrixAddress(),\n                          Dst.isVolatileQualified());\n      return;\n    }\n\n    assert(Dst.isBitField() && \"Unknown LValue type\");\n    return EmitStoreThroughBitfieldLValue(Src, Dst);\n  }\n\n  // There's special magic for assigning into an ARC-qualified l-value.\n  if (Qualifiers::ObjCLifetime Lifetime = Dst.getQuals().getObjCLifetime()) {\n    switch (Lifetime) {\n    case Qualifiers::OCL_None:\n      llvm_unreachable(\"present but none\");\n\n    case Qualifiers::OCL_ExplicitNone:\n      // nothing special\n      break;\n\n    case Qualifiers::OCL_Strong:\n      if (isInit) {\n        Src = RValue::get(EmitARCRetain(Dst.getType(), Src.getScalarVal()));\n        break;\n      }\n      EmitARCStoreStrong(Dst, Src.getScalarVal(), /*ignore*/ true);\n      return;\n\n    case Qualifiers::OCL_Weak:\n      if (isInit)\n        // Initialize and then skip the primitive store.\n        EmitARCInitWeak(Dst.getAddress(*this), Src.getScalarVal());\n      else\n        EmitARCStoreWeak(Dst.getAddress(*this), Src.getScalarVal(),\n                         /*ignore*/ true);\n      return;\n\n    case Qualifiers::OCL_Autoreleasing:\n      Src = RValue::get(EmitObjCExtendObjectLifetime(Dst.getType(),\n                                                     Src.getScalarVal()));\n      // fall into the normal path\n      break;\n    }\n  }\n\n  if (Dst.isObjCWeak() && !Dst.isNonGC()) {\n    // load of a __weak object.\n    Address LvalueDst = Dst.getAddress(*this);\n    llvm::Value *src = Src.getScalarVal();\n     CGM.getObjCRuntime().EmitObjCWeakAssign(*this, src, LvalueDst);\n    return;\n  }\n\n  if (Dst.isObjCStrong() && !Dst.isNonGC()) {\n    // load of a __strong object.\n    Address LvalueDst = Dst.getAddress(*this);\n    llvm::Value *src = Src.getScalarVal();\n    if (Dst.isObjCIvar()) {\n      assert(Dst.getBaseIvarExp() && \"BaseIvarExp is NULL\");\n      llvm::Type *ResultType = IntPtrTy;\n      Address dst = EmitPointerWithAlignment(Dst.getBaseIvarExp());\n      llvm::Value *RHS = dst.getPointer();\n      RHS = Builder.CreatePtrToInt(RHS, ResultType, \"sub.ptr.rhs.cast\");\n      llvm::Value *LHS =\n        Builder.CreatePtrToInt(LvalueDst.getPointer(), ResultType,\n                               \"sub.ptr.lhs.cast\");\n      llvm::Value *BytesBetween = Builder.CreateSub(LHS, RHS, \"ivar.offset\");\n      CGM.getObjCRuntime().EmitObjCIvarAssign(*this, src, dst,\n                                              BytesBetween);\n    } else if (Dst.isGlobalObjCRef()) {\n      CGM.getObjCRuntime().EmitObjCGlobalAssign(*this, src, LvalueDst,\n                                                Dst.isThreadLocalRef());\n    }\n    else\n      CGM.getObjCRuntime().EmitObjCStrongCastAssign(*this, src, LvalueDst);\n    return;\n  }\n\n  assert(Src.isScalar() && \"Can't emit an agg store with this method\");\n  EmitStoreOfScalar(Src.getScalarVal(), Dst, isInit);\n}\n\nvoid CodeGenFunction::EmitStoreThroughBitfieldLValue(RValue Src, LValue Dst,\n                                                     llvm::Value **Result) {\n  const CGBitFieldInfo &Info = Dst.getBitFieldInfo();\n  llvm::Type *ResLTy = ConvertTypeForMem(Dst.getType());\n  Address Ptr = Dst.getBitFieldAddress();\n\n  // Get the source value, truncated to the width of the bit-field.\n  llvm::Value *SrcVal = Src.getScalarVal();\n\n  // Cast the source to the storage type and shift it into place.\n  SrcVal = Builder.CreateIntCast(SrcVal, Ptr.getElementType(),\n                                 /*isSigned=*/false);\n  llvm::Value *MaskedVal = SrcVal;\n\n  const bool UseVolatile =\n      CGM.getCodeGenOpts().AAPCSBitfieldWidth && Dst.isVolatileQualified() &&\n      Info.VolatileStorageSize != 0 && isAAPCS(CGM.getTarget());\n  const unsigned StorageSize =\n      UseVolatile ? Info.VolatileStorageSize : Info.StorageSize;\n  const unsigned Offset = UseVolatile ? Info.VolatileOffset : Info.Offset;\n  // See if there are other bits in the bitfield's storage we'll need to load\n  // and mask together with source before storing.\n  if (StorageSize != Info.Size) {\n    assert(StorageSize > Info.Size && \"Invalid bitfield size.\");\n    llvm::Value *Val =\n        Builder.CreateLoad(Ptr, Dst.isVolatileQualified(), \"bf.load\");\n\n    // Mask the source value as needed.\n    if (!hasBooleanRepresentation(Dst.getType()))\n      SrcVal = Builder.CreateAnd(\n          SrcVal, llvm::APInt::getLowBitsSet(StorageSize, Info.Size),\n          \"bf.value\");\n    MaskedVal = SrcVal;\n    if (Offset)\n      SrcVal = Builder.CreateShl(SrcVal, Offset, \"bf.shl\");\n\n    // Mask out the original value.\n    Val = Builder.CreateAnd(\n        Val, ~llvm::APInt::getBitsSet(StorageSize, Offset, Offset + Info.Size),\n        \"bf.clear\");\n\n    // Or together the unchanged values and the source value.\n    SrcVal = Builder.CreateOr(Val, SrcVal, \"bf.set\");\n  } else {\n    assert(Offset == 0);\n    // According to the AACPS:\n    // When a volatile bit-field is written, and its container does not overlap\n    // with any non-bit-field member, its container must be read exactly once\n    // and written exactly once using the access width appropriate to the type\n    // of the container. The two accesses are not atomic.\n    if (Dst.isVolatileQualified() && isAAPCS(CGM.getTarget()) &&\n        CGM.getCodeGenOpts().ForceAAPCSBitfieldLoad)\n      Builder.CreateLoad(Ptr, true, \"bf.load\");\n  }\n\n  // Write the new value back out.\n  Builder.CreateStore(SrcVal, Ptr, Dst.isVolatileQualified());\n\n  // Return the new value of the bit-field, if requested.\n  if (Result) {\n    llvm::Value *ResultVal = MaskedVal;\n\n    // Sign extend the value if needed.\n    if (Info.IsSigned) {\n      assert(Info.Size <= StorageSize);\n      unsigned HighBits = StorageSize - Info.Size;\n      if (HighBits) {\n        ResultVal = Builder.CreateShl(ResultVal, HighBits, \"bf.result.shl\");\n        ResultVal = Builder.CreateAShr(ResultVal, HighBits, \"bf.result.ashr\");\n      }\n    }\n\n    ResultVal = Builder.CreateIntCast(ResultVal, ResLTy, Info.IsSigned,\n                                      \"bf.result.cast\");\n    *Result = EmitFromMemory(ResultVal, Dst.getType());\n  }\n}\n\nvoid CodeGenFunction::EmitStoreThroughExtVectorComponentLValue(RValue Src,\n                                                               LValue Dst) {\n  // This access turns into a read/modify/write of the vector.  Load the input\n  // value now.\n  llvm::Value *Vec = Builder.CreateLoad(Dst.getExtVectorAddress(),\n                                        Dst.isVolatileQualified());\n  const llvm::Constant *Elts = Dst.getExtVectorElts();\n\n  llvm::Value *SrcVal = Src.getScalarVal();\n\n  if (const VectorType *VTy = Dst.getType()->getAs<VectorType>()) {\n    unsigned NumSrcElts = VTy->getNumElements();\n    unsigned NumDstElts =\n        cast<llvm::FixedVectorType>(Vec->getType())->getNumElements();\n    if (NumDstElts == NumSrcElts) {\n      // Use shuffle vector is the src and destination are the same number of\n      // elements and restore the vector mask since it is on the side it will be\n      // stored.\n      SmallVector<int, 4> Mask(NumDstElts);\n      for (unsigned i = 0; i != NumSrcElts; ++i)\n        Mask[getAccessedFieldNo(i, Elts)] = i;\n\n      Vec = Builder.CreateShuffleVector(SrcVal, Mask);\n    } else if (NumDstElts > NumSrcElts) {\n      // Extended the source vector to the same length and then shuffle it\n      // into the destination.\n      // FIXME: since we're shuffling with undef, can we just use the indices\n      //        into that?  This could be simpler.\n      SmallVector<int, 4> ExtMask;\n      for (unsigned i = 0; i != NumSrcElts; ++i)\n        ExtMask.push_back(i);\n      ExtMask.resize(NumDstElts, -1);\n      llvm::Value *ExtSrcVal = Builder.CreateShuffleVector(SrcVal, ExtMask);\n      // build identity\n      SmallVector<int, 4> Mask;\n      for (unsigned i = 0; i != NumDstElts; ++i)\n        Mask.push_back(i);\n\n      // When the vector size is odd and .odd or .hi is used, the last element\n      // of the Elts constant array will be one past the size of the vector.\n      // Ignore the last element here, if it is greater than the mask size.\n      if (getAccessedFieldNo(NumSrcElts - 1, Elts) == Mask.size())\n        NumSrcElts--;\n\n      // modify when what gets shuffled in\n      for (unsigned i = 0; i != NumSrcElts; ++i)\n        Mask[getAccessedFieldNo(i, Elts)] = i + NumDstElts;\n      Vec = Builder.CreateShuffleVector(Vec, ExtSrcVal, Mask);\n    } else {\n      // We should never shorten the vector\n      llvm_unreachable(\"unexpected shorten vector length\");\n    }\n  } else {\n    // If the Src is a scalar (not a vector) it must be updating one element.\n    unsigned InIdx = getAccessedFieldNo(0, Elts);\n    llvm::Value *Elt = llvm::ConstantInt::get(SizeTy, InIdx);\n    Vec = Builder.CreateInsertElement(Vec, SrcVal, Elt);\n  }\n\n  Builder.CreateStore(Vec, Dst.getExtVectorAddress(),\n                      Dst.isVolatileQualified());\n}\n\n/// Store of global named registers are always calls to intrinsics.\nvoid CodeGenFunction::EmitStoreThroughGlobalRegLValue(RValue Src, LValue Dst) {\n  assert((Dst.getType()->isIntegerType() || Dst.getType()->isPointerType()) &&\n         \"Bad type for register variable\");\n  llvm::MDNode *RegName = cast<llvm::MDNode>(\n      cast<llvm::MetadataAsValue>(Dst.getGlobalReg())->getMetadata());\n  assert(RegName && \"Register LValue is not metadata\");\n\n  // We accept integer and pointer types only\n  llvm::Type *OrigTy = CGM.getTypes().ConvertType(Dst.getType());\n  llvm::Type *Ty = OrigTy;\n  if (OrigTy->isPointerTy())\n    Ty = CGM.getTypes().getDataLayout().getIntPtrType(OrigTy);\n  llvm::Type *Types[] = { Ty };\n\n  llvm::Function *F = CGM.getIntrinsic(llvm::Intrinsic::write_register, Types);\n  llvm::Value *Value = Src.getScalarVal();\n  if (OrigTy->isPointerTy())\n    Value = Builder.CreatePtrToInt(Value, Ty);\n  Builder.CreateCall(\n      F, {llvm::MetadataAsValue::get(Ty->getContext(), RegName), Value});\n}\n\n// setObjCGCLValueClass - sets class of the lvalue for the purpose of\n// generating write-barries API. It is currently a global, ivar,\n// or neither.\nstatic void setObjCGCLValueClass(const ASTContext &Ctx, const Expr *E,\n                                 LValue &LV,\n                                 bool IsMemberAccess=false) {\n  if (Ctx.getLangOpts().getGC() == LangOptions::NonGC)\n    return;\n\n  if (isa<ObjCIvarRefExpr>(E)) {\n    QualType ExpTy = E->getType();\n    if (IsMemberAccess && ExpTy->isPointerType()) {\n      // If ivar is a structure pointer, assigning to field of\n      // this struct follows gcc's behavior and makes it a non-ivar\n      // writer-barrier conservatively.\n      ExpTy = ExpTy->castAs<PointerType>()->getPointeeType();\n      if (ExpTy->isRecordType()) {\n        LV.setObjCIvar(false);\n        return;\n      }\n    }\n    LV.setObjCIvar(true);\n    auto *Exp = cast<ObjCIvarRefExpr>(const_cast<Expr *>(E));\n    LV.setBaseIvarExp(Exp->getBase());\n    LV.setObjCArray(E->getType()->isArrayType());\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<DeclRefExpr>(E)) {\n    if (const auto *VD = dyn_cast<VarDecl>(Exp->getDecl())) {\n      if (VD->hasGlobalStorage()) {\n        LV.setGlobalObjCRef(true);\n        LV.setThreadLocalRef(VD->getTLSKind() != VarDecl::TLS_None);\n      }\n    }\n    LV.setObjCArray(E->getType()->isArrayType());\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<UnaryOperator>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getSubExpr(), LV, IsMemberAccess);\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<ParenExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getSubExpr(), LV, IsMemberAccess);\n    if (LV.isObjCIvar()) {\n      // If cast is to a structure pointer, follow gcc's behavior and make it\n      // a non-ivar write-barrier.\n      QualType ExpTy = E->getType();\n      if (ExpTy->isPointerType())\n        ExpTy = ExpTy->castAs<PointerType>()->getPointeeType();\n      if (ExpTy->isRecordType())\n        LV.setObjCIvar(false);\n    }\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<GenericSelectionExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getResultExpr(), LV);\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<ImplicitCastExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getSubExpr(), LV, IsMemberAccess);\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<CStyleCastExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getSubExpr(), LV, IsMemberAccess);\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<ObjCBridgedCastExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getSubExpr(), LV, IsMemberAccess);\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<ArraySubscriptExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getBase(), LV);\n    if (LV.isObjCIvar() && !LV.isObjCArray())\n      // Using array syntax to assigning to what an ivar points to is not\n      // same as assigning to the ivar itself. {id *Names;} Names[i] = 0;\n      LV.setObjCIvar(false);\n    else if (LV.isGlobalObjCRef() && !LV.isObjCArray())\n      // Using array syntax to assigning to what global points to is not\n      // same as assigning to the global itself. {id *G;} G[i] = 0;\n      LV.setGlobalObjCRef(false);\n    return;\n  }\n\n  if (const auto *Exp = dyn_cast<MemberExpr>(E)) {\n    setObjCGCLValueClass(Ctx, Exp->getBase(), LV, true);\n    // We don't know if member is an 'ivar', but this flag is looked at\n    // only in the context of LV.isObjCIvar().\n    LV.setObjCArray(E->getType()->isArrayType());\n    return;\n  }\n}\n\nstatic llvm::Value *\nEmitBitCastOfLValueToProperType(CodeGenFunction &CGF,\n                                llvm::Value *V, llvm::Type *IRType,\n                                StringRef Name = StringRef()) {\n  unsigned AS = cast<llvm::PointerType>(V->getType())->getAddressSpace();\n  return CGF.Builder.CreateBitCast(V, IRType->getPointerTo(AS), Name);\n}\n\nstatic LValue EmitThreadPrivateVarDeclLValue(\n    CodeGenFunction &CGF, const VarDecl *VD, QualType T, Address Addr,\n    llvm::Type *RealVarTy, SourceLocation Loc) {\n  if (CGF.CGM.getLangOpts().OpenMPIRBuilder)\n    Addr = CodeGenFunction::OMPBuilderCBHelpers::getAddrOfThreadPrivate(\n        CGF, VD, Addr, Loc);\n  else\n    Addr =\n        CGF.CGM.getOpenMPRuntime().getAddrOfThreadPrivate(CGF, VD, Addr, Loc);\n\n  Addr = CGF.Builder.CreateElementBitCast(Addr, RealVarTy);\n  return CGF.MakeAddrLValue(Addr, T, AlignmentSource::Decl);\n}\n\nstatic Address emitDeclTargetVarDeclLValue(CodeGenFunction &CGF,\n                                           const VarDecl *VD, QualType T) {\n  llvm::Optional<OMPDeclareTargetDeclAttr::MapTypeTy> Res =\n      OMPDeclareTargetDeclAttr::isDeclareTargetDeclaration(VD);\n  // Return an invalid address if variable is MT_To and unified\n  // memory is not enabled. For all other cases: MT_Link and\n  // MT_To with unified memory, return a valid address.\n  if (!Res || (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n               !CGF.CGM.getOpenMPRuntime().hasRequiresUnifiedSharedMemory()))\n    return Address::invalid();\n  assert(((*Res == OMPDeclareTargetDeclAttr::MT_Link) ||\n          (*Res == OMPDeclareTargetDeclAttr::MT_To &&\n           CGF.CGM.getOpenMPRuntime().hasRequiresUnifiedSharedMemory())) &&\n         \"Expected link clause OR to clause with unified memory enabled.\");\n  QualType PtrTy = CGF.getContext().getPointerType(VD->getType());\n  Address Addr = CGF.CGM.getOpenMPRuntime().getAddrOfDeclareTargetVar(VD);\n  return CGF.EmitLoadOfPointer(Addr, PtrTy->castAs<PointerType>());\n}\n\nAddress\nCodeGenFunction::EmitLoadOfReference(LValue RefLVal,\n                                     LValueBaseInfo *PointeeBaseInfo,\n                                     TBAAAccessInfo *PointeeTBAAInfo) {\n  llvm::LoadInst *Load =\n      Builder.CreateLoad(RefLVal.getAddress(*this), RefLVal.isVolatile());\n  CGM.DecorateInstructionWithTBAA(Load, RefLVal.getTBAAInfo());\n\n  CharUnits Align = CGM.getNaturalTypeAlignment(\n      RefLVal.getType()->getPointeeType(), PointeeBaseInfo, PointeeTBAAInfo,\n      /* forPointeeType= */ true);\n  return Address(Load, Align);\n}\n\nLValue CodeGenFunction::EmitLoadOfReferenceLValue(LValue RefLVal) {\n  LValueBaseInfo PointeeBaseInfo;\n  TBAAAccessInfo PointeeTBAAInfo;\n  Address PointeeAddr = EmitLoadOfReference(RefLVal, &PointeeBaseInfo,\n                                            &PointeeTBAAInfo);\n  return MakeAddrLValue(PointeeAddr, RefLVal.getType()->getPointeeType(),\n                        PointeeBaseInfo, PointeeTBAAInfo);\n}\n\nAddress CodeGenFunction::EmitLoadOfPointer(Address Ptr,\n                                           const PointerType *PtrTy,\n                                           LValueBaseInfo *BaseInfo,\n                                           TBAAAccessInfo *TBAAInfo) {\n  llvm::Value *Addr = Builder.CreateLoad(Ptr);\n  return Address(Addr, CGM.getNaturalTypeAlignment(PtrTy->getPointeeType(),\n                                                   BaseInfo, TBAAInfo,\n                                                   /*forPointeeType=*/true));\n}\n\nLValue CodeGenFunction::EmitLoadOfPointerLValue(Address PtrAddr,\n                                                const PointerType *PtrTy) {\n  LValueBaseInfo BaseInfo;\n  TBAAAccessInfo TBAAInfo;\n  Address Addr = EmitLoadOfPointer(PtrAddr, PtrTy, &BaseInfo, &TBAAInfo);\n  return MakeAddrLValue(Addr, PtrTy->getPointeeType(), BaseInfo, TBAAInfo);\n}\n\nstatic LValue EmitGlobalVarDeclLValue(CodeGenFunction &CGF,\n                                      const Expr *E, const VarDecl *VD) {\n  QualType T = E->getType();\n\n  // If it's thread_local, emit a call to its wrapper function instead.\n  if (VD->getTLSKind() == VarDecl::TLS_Dynamic &&\n      CGF.CGM.getCXXABI().usesThreadWrapperFunction(VD))\n    return CGF.CGM.getCXXABI().EmitThreadLocalVarDeclLValue(CGF, VD, T);\n  // Check if the variable is marked as declare target with link clause in\n  // device codegen.\n  if (CGF.getLangOpts().OpenMPIsDevice) {\n    Address Addr = emitDeclTargetVarDeclLValue(CGF, VD, T);\n    if (Addr.isValid())\n      return CGF.MakeAddrLValue(Addr, T, AlignmentSource::Decl);\n  }\n\n  llvm::Value *V = CGF.CGM.GetAddrOfGlobalVar(VD);\n  llvm::Type *RealVarTy = CGF.getTypes().ConvertTypeForMem(VD->getType());\n  V = EmitBitCastOfLValueToProperType(CGF, V, RealVarTy);\n  CharUnits Alignment = CGF.getContext().getDeclAlign(VD);\n  Address Addr(V, Alignment);\n  // Emit reference to the private copy of the variable if it is an OpenMP\n  // threadprivate variable.\n  if (CGF.getLangOpts().OpenMP && !CGF.getLangOpts().OpenMPSimd &&\n      VD->hasAttr<OMPThreadPrivateDeclAttr>()) {\n    return EmitThreadPrivateVarDeclLValue(CGF, VD, T, Addr, RealVarTy,\n                                          E->getExprLoc());\n  }\n  LValue LV = VD->getType()->isReferenceType() ?\n      CGF.EmitLoadOfReferenceLValue(Addr, VD->getType(),\n                                    AlignmentSource::Decl) :\n      CGF.MakeAddrLValue(Addr, T, AlignmentSource::Decl);\n  setObjCGCLValueClass(CGF.getContext(), E, LV);\n  return LV;\n}\n\nstatic llvm::Constant *EmitFunctionDeclPointer(CodeGenModule &CGM,\n                                               GlobalDecl GD) {\n  const FunctionDecl *FD = cast<FunctionDecl>(GD.getDecl());\n  if (FD->hasAttr<WeakRefAttr>()) {\n    ConstantAddress aliasee = CGM.GetWeakRefReference(FD);\n    return aliasee.getPointer();\n  }\n\n  llvm::Constant *V = CGM.GetAddrOfFunction(GD);\n  if (!FD->hasPrototype()) {\n    if (const FunctionProtoType *Proto =\n            FD->getType()->getAs<FunctionProtoType>()) {\n      // Ugly case: for a K&R-style definition, the type of the definition\n      // isn't the same as the type of a use.  Correct for this with a\n      // bitcast.\n      QualType NoProtoType =\n          CGM.getContext().getFunctionNoProtoType(Proto->getReturnType());\n      NoProtoType = CGM.getContext().getPointerType(NoProtoType);\n      V = llvm::ConstantExpr::getBitCast(V,\n                                      CGM.getTypes().ConvertType(NoProtoType));\n    }\n  }\n  return V;\n}\n\nstatic LValue EmitFunctionDeclLValue(CodeGenFunction &CGF, const Expr *E,\n                                     GlobalDecl GD) {\n  const FunctionDecl *FD = cast<FunctionDecl>(GD.getDecl());\n  llvm::Value *V = EmitFunctionDeclPointer(CGF.CGM, GD);\n  CharUnits Alignment = CGF.getContext().getDeclAlign(FD);\n  return CGF.MakeAddrLValue(V, E->getType(), Alignment,\n                            AlignmentSource::Decl);\n}\n\nstatic LValue EmitCapturedFieldLValue(CodeGenFunction &CGF, const FieldDecl *FD,\n                                      llvm::Value *ThisValue) {\n  QualType TagType = CGF.getContext().getTagDeclType(FD->getParent());\n  LValue LV = CGF.MakeNaturalAlignAddrLValue(ThisValue, TagType);\n  return CGF.EmitLValueForField(LV, FD);\n}\n\n/// Named Registers are named metadata pointing to the register name\n/// which will be read from/written to as an argument to the intrinsic\n/// @llvm.read/write_register.\n/// So far, only the name is being passed down, but other options such as\n/// register type, allocation type or even optimization options could be\n/// passed down via the metadata node.\nstatic LValue EmitGlobalNamedRegister(const VarDecl *VD, CodeGenModule &CGM) {\n  SmallString<64> Name(\"llvm.named.register.\");\n  AsmLabelAttr *Asm = VD->getAttr<AsmLabelAttr>();\n  assert(Asm->getLabel().size() < 64-Name.size() &&\n      \"Register name too big\");\n  Name.append(Asm->getLabel());\n  llvm::NamedMDNode *M =\n    CGM.getModule().getOrInsertNamedMetadata(Name);\n  if (M->getNumOperands() == 0) {\n    llvm::MDString *Str = llvm::MDString::get(CGM.getLLVMContext(),\n                                              Asm->getLabel());\n    llvm::Metadata *Ops[] = {Str};\n    M->addOperand(llvm::MDNode::get(CGM.getLLVMContext(), Ops));\n  }\n\n  CharUnits Alignment = CGM.getContext().getDeclAlign(VD);\n\n  llvm::Value *Ptr =\n    llvm::MetadataAsValue::get(CGM.getLLVMContext(), M->getOperand(0));\n  return LValue::MakeGlobalReg(Address(Ptr, Alignment), VD->getType());\n}\n\n/// Determine whether we can emit a reference to \\p VD from the current\n/// context, despite not necessarily having seen an odr-use of the variable in\n/// this context.\nstatic bool canEmitSpuriousReferenceToVariable(CodeGenFunction &CGF,\n                                               const DeclRefExpr *E,\n                                               const VarDecl *VD,\n                                               bool IsConstant) {\n  // For a variable declared in an enclosing scope, do not emit a spurious\n  // reference even if we have a capture, as that will emit an unwarranted\n  // reference to our capture state, and will likely generate worse code than\n  // emitting a local copy.\n  if (E->refersToEnclosingVariableOrCapture())\n    return false;\n\n  // For a local declaration declared in this function, we can always reference\n  // it even if we don't have an odr-use.\n  if (VD->hasLocalStorage()) {\n    return VD->getDeclContext() ==\n           dyn_cast_or_null<DeclContext>(CGF.CurCodeDecl);\n  }\n\n  // For a global declaration, we can emit a reference to it if we know\n  // for sure that we are able to emit a definition of it.\n  VD = VD->getDefinition(CGF.getContext());\n  if (!VD)\n    return false;\n\n  // Don't emit a spurious reference if it might be to a variable that only\n  // exists on a different device / target.\n  // FIXME: This is unnecessarily broad. Check whether this would actually be a\n  // cross-target reference.\n  if (CGF.getLangOpts().OpenMP || CGF.getLangOpts().CUDA ||\n      CGF.getLangOpts().OpenCL) {\n    return false;\n  }\n\n  // We can emit a spurious reference only if the linkage implies that we'll\n  // be emitting a non-interposable symbol that will be retained until link\n  // time.\n  switch (CGF.CGM.getLLVMLinkageVarDefinition(VD, IsConstant)) {\n  case llvm::GlobalValue::ExternalLinkage:\n  case llvm::GlobalValue::LinkOnceODRLinkage:\n  case llvm::GlobalValue::WeakODRLinkage:\n  case llvm::GlobalValue::InternalLinkage:\n  case llvm::GlobalValue::PrivateLinkage:\n    return true;\n  default:\n    return false;\n  }\n}\n\nLValue CodeGenFunction::EmitDeclRefLValue(const DeclRefExpr *E) {\n  const NamedDecl *ND = E->getDecl();\n  QualType T = E->getType();\n\n  assert(E->isNonOdrUse() != NOUR_Unevaluated &&\n         \"should not emit an unevaluated operand\");\n\n  if (const auto *VD = dyn_cast<VarDecl>(ND)) {\n    // Global Named registers access via intrinsics only\n    if (VD->getStorageClass() == SC_Register &&\n        VD->hasAttr<AsmLabelAttr>() && !VD->isLocalVarDecl())\n      return EmitGlobalNamedRegister(VD, CGM);\n\n    // If this DeclRefExpr does not constitute an odr-use of the variable,\n    // we're not permitted to emit a reference to it in general, and it might\n    // not be captured if capture would be necessary for a use. Emit the\n    // constant value directly instead.\n    if (E->isNonOdrUse() == NOUR_Constant &&\n        (VD->getType()->isReferenceType() ||\n         !canEmitSpuriousReferenceToVariable(*this, E, VD, true))) {\n      VD->getAnyInitializer(VD);\n      llvm::Constant *Val = ConstantEmitter(*this).emitAbstract(\n          E->getLocation(), *VD->evaluateValue(), VD->getType());\n      assert(Val && \"failed to emit constant expression\");\n\n      Address Addr = Address::invalid();\n      if (!VD->getType()->isReferenceType()) {\n        // Spill the constant value to a global.\n        Addr = CGM.createUnnamedGlobalFrom(*VD, Val,\n                                           getContext().getDeclAlign(VD));\n        llvm::Type *VarTy = getTypes().ConvertTypeForMem(VD->getType());\n        auto *PTy = llvm::PointerType::get(\n            VarTy, getContext().getTargetAddressSpace(VD->getType()));\n        if (PTy != Addr.getType())\n          Addr = Builder.CreatePointerBitCastOrAddrSpaceCast(Addr, PTy);\n      } else {\n        // Should we be using the alignment of the constant pointer we emitted?\n        CharUnits Alignment =\n            CGM.getNaturalTypeAlignment(E->getType(),\n                                        /* BaseInfo= */ nullptr,\n                                        /* TBAAInfo= */ nullptr,\n                                        /* forPointeeType= */ true);\n        Addr = Address(Val, Alignment);\n      }\n      return MakeAddrLValue(Addr, T, AlignmentSource::Decl);\n    }\n\n    // FIXME: Handle other kinds of non-odr-use DeclRefExprs.\n\n    // Check for captured variables.\n    if (E->refersToEnclosingVariableOrCapture()) {\n      VD = VD->getCanonicalDecl();\n      if (auto *FD = LambdaCaptureFields.lookup(VD))\n        return EmitCapturedFieldLValue(*this, FD, CXXABIThisValue);\n      if (CapturedStmtInfo) {\n        auto I = LocalDeclMap.find(VD);\n        if (I != LocalDeclMap.end()) {\n          LValue CapLVal;\n          if (VD->getType()->isReferenceType())\n            CapLVal = EmitLoadOfReferenceLValue(I->second, VD->getType(),\n                                                AlignmentSource::Decl);\n          else\n            CapLVal = MakeAddrLValue(I->second, T);\n          // Mark lvalue as nontemporal if the variable is marked as nontemporal\n          // in simd context.\n          if (getLangOpts().OpenMP &&\n              CGM.getOpenMPRuntime().isNontemporalDecl(VD))\n            CapLVal.setNontemporal(/*Value=*/true);\n          return CapLVal;\n        }\n        LValue CapLVal =\n            EmitCapturedFieldLValue(*this, CapturedStmtInfo->lookup(VD),\n                                    CapturedStmtInfo->getContextValue());\n        CapLVal = MakeAddrLValue(\n            Address(CapLVal.getPointer(*this), getContext().getDeclAlign(VD)),\n            CapLVal.getType(), LValueBaseInfo(AlignmentSource::Decl),\n            CapLVal.getTBAAInfo());\n        // Mark lvalue as nontemporal if the variable is marked as nontemporal\n        // in simd context.\n        if (getLangOpts().OpenMP &&\n            CGM.getOpenMPRuntime().isNontemporalDecl(VD))\n          CapLVal.setNontemporal(/*Value=*/true);\n        return CapLVal;\n      }\n\n      assert(isa<BlockDecl>(CurCodeDecl));\n      Address addr = GetAddrOfBlockDecl(VD);\n      return MakeAddrLValue(addr, T, AlignmentSource::Decl);\n    }\n  }\n\n  // FIXME: We should be able to assert this for FunctionDecls as well!\n  // FIXME: We should be able to assert this for all DeclRefExprs, not just\n  // those with a valid source location.\n  assert((ND->isUsed(false) || !isa<VarDecl>(ND) || E->isNonOdrUse() ||\n          !E->getLocation().isValid()) &&\n         \"Should not use decl without marking it used!\");\n\n  if (ND->hasAttr<WeakRefAttr>()) {\n    const auto *VD = cast<ValueDecl>(ND);\n    ConstantAddress Aliasee = CGM.GetWeakRefReference(VD);\n    return MakeAddrLValue(Aliasee, T, AlignmentSource::Decl);\n  }\n\n  if (const auto *VD = dyn_cast<VarDecl>(ND)) {\n    // Check if this is a global variable.\n    if (VD->hasLinkage() || VD->isStaticDataMember())\n      return EmitGlobalVarDeclLValue(*this, E, VD);\n\n    Address addr = Address::invalid();\n\n    // The variable should generally be present in the local decl map.\n    auto iter = LocalDeclMap.find(VD);\n    if (iter != LocalDeclMap.end()) {\n      addr = iter->second;\n\n    // Otherwise, it might be static local we haven't emitted yet for\n    // some reason; most likely, because it's in an outer function.\n    } else if (VD->isStaticLocal()) {\n      addr = Address(CGM.getOrCreateStaticVarDecl(\n          *VD, CGM.getLLVMLinkageVarDefinition(VD, /*IsConstant=*/false)),\n                     getContext().getDeclAlign(VD));\n\n    // No other cases for now.\n    } else {\n      llvm_unreachable(\"DeclRefExpr for Decl not entered in LocalDeclMap?\");\n    }\n\n\n    // Check for OpenMP threadprivate variables.\n    if (getLangOpts().OpenMP && !getLangOpts().OpenMPSimd &&\n        VD->hasAttr<OMPThreadPrivateDeclAttr>()) {\n      return EmitThreadPrivateVarDeclLValue(\n          *this, VD, T, addr, getTypes().ConvertTypeForMem(VD->getType()),\n          E->getExprLoc());\n    }\n\n    // Drill into block byref variables.\n    bool isBlockByref = VD->isEscapingByref();\n    if (isBlockByref) {\n      addr = emitBlockByrefAddress(addr, VD);\n    }\n\n    // Drill into reference types.\n    LValue LV = VD->getType()->isReferenceType() ?\n        EmitLoadOfReferenceLValue(addr, VD->getType(), AlignmentSource::Decl) :\n        MakeAddrLValue(addr, T, AlignmentSource::Decl);\n\n    bool isLocalStorage = VD->hasLocalStorage();\n\n    bool NonGCable = isLocalStorage &&\n                     !VD->getType()->isReferenceType() &&\n                     !isBlockByref;\n    if (NonGCable) {\n      LV.getQuals().removeObjCGCAttr();\n      LV.setNonGC(true);\n    }\n\n    bool isImpreciseLifetime =\n      (isLocalStorage && !VD->hasAttr<ObjCPreciseLifetimeAttr>());\n    if (isImpreciseLifetime)\n      LV.setARCPreciseLifetime(ARCImpreciseLifetime);\n    setObjCGCLValueClass(getContext(), E, LV);\n    return LV;\n  }\n\n  if (const auto *FD = dyn_cast<FunctionDecl>(ND))\n    return EmitFunctionDeclLValue(*this, E, FD);\n\n  // FIXME: While we're emitting a binding from an enclosing scope, all other\n  // DeclRefExprs we see should be implicitly treated as if they also refer to\n  // an enclosing scope.\n  if (const auto *BD = dyn_cast<BindingDecl>(ND))\n    return EmitLValue(BD->getBinding());\n\n  // We can form DeclRefExprs naming GUID declarations when reconstituting\n  // non-type template parameters into expressions.\n  if (const auto *GD = dyn_cast<MSGuidDecl>(ND))\n    return MakeAddrLValue(CGM.GetAddrOfMSGuidDecl(GD), T,\n                          AlignmentSource::Decl);\n\n  if (const auto *TPO = dyn_cast<TemplateParamObjectDecl>(ND))\n    return MakeAddrLValue(CGM.GetAddrOfTemplateParamObject(TPO), T,\n                          AlignmentSource::Decl);\n\n  llvm_unreachable(\"Unhandled DeclRefExpr\");\n}\n\nLValue CodeGenFunction::EmitUnaryOpLValue(const UnaryOperator *E) {\n  // __extension__ doesn't affect lvalue-ness.\n  if (E->getOpcode() == UO_Extension)\n    return EmitLValue(E->getSubExpr());\n\n  QualType ExprTy = getContext().getCanonicalType(E->getSubExpr()->getType());\n  switch (E->getOpcode()) {\n  default: llvm_unreachable(\"Unknown unary operator lvalue!\");\n  case UO_Deref: {\n    QualType T = E->getSubExpr()->getType()->getPointeeType();\n    assert(!T.isNull() && \"CodeGenFunction::EmitUnaryOpLValue: Illegal type\");\n\n    LValueBaseInfo BaseInfo;\n    TBAAAccessInfo TBAAInfo;\n    Address Addr = EmitPointerWithAlignment(E->getSubExpr(), &BaseInfo,\n                                            &TBAAInfo);\n    LValue LV = MakeAddrLValue(Addr, T, BaseInfo, TBAAInfo);\n    LV.getQuals().setAddressSpace(ExprTy.getAddressSpace());\n\n    // We should not generate __weak write barrier on indirect reference\n    // of a pointer to object; as in void foo (__weak id *param); *param = 0;\n    // But, we continue to generate __strong write barrier on indirect write\n    // into a pointer to object.\n    if (getLangOpts().ObjC &&\n        getLangOpts().getGC() != LangOptions::NonGC &&\n        LV.isObjCWeak())\n      LV.setNonGC(!E->isOBJCGCCandidate(getContext()));\n    return LV;\n  }\n  case UO_Real:\n  case UO_Imag: {\n    LValue LV = EmitLValue(E->getSubExpr());\n    assert(LV.isSimple() && \"real/imag on non-ordinary l-value\");\n\n    // __real is valid on scalars.  This is a faster way of testing that.\n    // __imag can only produce an rvalue on scalars.\n    if (E->getOpcode() == UO_Real &&\n        !LV.getAddress(*this).getElementType()->isStructTy()) {\n      assert(E->getSubExpr()->getType()->isArithmeticType());\n      return LV;\n    }\n\n    QualType T = ExprTy->castAs<ComplexType>()->getElementType();\n\n    Address Component =\n        (E->getOpcode() == UO_Real\n             ? emitAddrOfRealComponent(LV.getAddress(*this), LV.getType())\n             : emitAddrOfImagComponent(LV.getAddress(*this), LV.getType()));\n    LValue ElemLV = MakeAddrLValue(Component, T, LV.getBaseInfo(),\n                                   CGM.getTBAAInfoForSubobject(LV, T));\n    ElemLV.getQuals().addQualifiers(LV.getQuals());\n    return ElemLV;\n  }\n  case UO_PreInc:\n  case UO_PreDec: {\n    LValue LV = EmitLValue(E->getSubExpr());\n    bool isInc = E->getOpcode() == UO_PreInc;\n\n    if (E->getType()->isAnyComplexType())\n      EmitComplexPrePostIncDec(E, LV, isInc, true/*isPre*/);\n    else\n      EmitScalarPrePostIncDec(E, LV, isInc, true/*isPre*/);\n    return LV;\n  }\n  }\n}\n\nLValue CodeGenFunction::EmitStringLiteralLValue(const StringLiteral *E) {\n  return MakeAddrLValue(CGM.GetAddrOfConstantStringFromLiteral(E),\n                        E->getType(), AlignmentSource::Decl);\n}\n\nLValue CodeGenFunction::EmitObjCEncodeExprLValue(const ObjCEncodeExpr *E) {\n  return MakeAddrLValue(CGM.GetAddrOfConstantStringFromObjCEncode(E),\n                        E->getType(), AlignmentSource::Decl);\n}\n\nLValue CodeGenFunction::EmitPredefinedLValue(const PredefinedExpr *E) {\n  auto SL = E->getFunctionName();\n  assert(SL != nullptr && \"No StringLiteral name in PredefinedExpr\");\n  StringRef FnName = CurFn->getName();\n  if (FnName.startswith(\"\\01\"))\n    FnName = FnName.substr(1);\n  StringRef NameItems[] = {\n      PredefinedExpr::getIdentKindName(E->getIdentKind()), FnName};\n  std::string GVName = llvm::join(NameItems, NameItems + 2, \".\");\n  if (auto *BD = dyn_cast_or_null<BlockDecl>(CurCodeDecl)) {\n    std::string Name = std::string(SL->getString());\n    if (!Name.empty()) {\n      unsigned Discriminator =\n          CGM.getCXXABI().getMangleContext().getBlockId(BD, true);\n      if (Discriminator)\n        Name += \"_\" + Twine(Discriminator + 1).str();\n      auto C = CGM.GetAddrOfConstantCString(Name, GVName.c_str());\n      return MakeAddrLValue(C, E->getType(), AlignmentSource::Decl);\n    } else {\n      auto C =\n          CGM.GetAddrOfConstantCString(std::string(FnName), GVName.c_str());\n      return MakeAddrLValue(C, E->getType(), AlignmentSource::Decl);\n    }\n  }\n  auto C = CGM.GetAddrOfConstantStringFromLiteral(SL, GVName);\n  return MakeAddrLValue(C, E->getType(), AlignmentSource::Decl);\n}\n\n/// Emit a type description suitable for use by a runtime sanitizer library. The\n/// format of a type descriptor is\n///\n/// \\code\n///   { i16 TypeKind, i16 TypeInfo }\n/// \\endcode\n///\n/// followed by an array of i8 containing the type name. TypeKind is 0 for an\n/// integer, 1 for a floating point value, and -1 for anything else.\nllvm::Constant *CodeGenFunction::EmitCheckTypeDescriptor(QualType T) {\n  // Only emit each type's descriptor once.\n  if (llvm::Constant *C = CGM.getTypeDescriptorFromMap(T))\n    return C;\n\n  uint16_t TypeKind = -1;\n  uint16_t TypeInfo = 0;\n\n  if (T->isIntegerType()) {\n    TypeKind = 0;\n    TypeInfo = (llvm::Log2_32(getContext().getTypeSize(T)) << 1) |\n               (T->isSignedIntegerType() ? 1 : 0);\n  } else if (T->isFloatingType()) {\n    TypeKind = 1;\n    TypeInfo = getContext().getTypeSize(T);\n  }\n\n  // Format the type name as if for a diagnostic, including quotes and\n  // optionally an 'aka'.\n  SmallString<32> Buffer;\n  CGM.getDiags().ConvertArgToString(DiagnosticsEngine::ak_qualtype,\n                                    (intptr_t)T.getAsOpaquePtr(),\n                                    StringRef(), StringRef(), None, Buffer,\n                                    None);\n\n  llvm::Constant *Components[] = {\n    Builder.getInt16(TypeKind), Builder.getInt16(TypeInfo),\n    llvm::ConstantDataArray::getString(getLLVMContext(), Buffer)\n  };\n  llvm::Constant *Descriptor = llvm::ConstantStruct::getAnon(Components);\n\n  auto *GV = new llvm::GlobalVariable(\n      CGM.getModule(), Descriptor->getType(),\n      /*isConstant=*/true, llvm::GlobalVariable::PrivateLinkage, Descriptor);\n  GV->setUnnamedAddr(llvm::GlobalValue::UnnamedAddr::Global);\n  CGM.getSanitizerMetadata()->disableSanitizerForGlobal(GV);\n\n  // Remember the descriptor for this type.\n  CGM.setTypeDescriptorInMap(T, GV);\n\n  return GV;\n}\n\nllvm::Value *CodeGenFunction::EmitCheckValue(llvm::Value *V) {\n  llvm::Type *TargetTy = IntPtrTy;\n\n  if (V->getType() == TargetTy)\n    return V;\n\n  // Floating-point types which fit into intptr_t are bitcast to integers\n  // and then passed directly (after zero-extension, if necessary).\n  if (V->getType()->isFloatingPointTy()) {\n    unsigned Bits = V->getType()->getPrimitiveSizeInBits().getFixedSize();\n    if (Bits <= TargetTy->getIntegerBitWidth())\n      V = Builder.CreateBitCast(V, llvm::Type::getIntNTy(getLLVMContext(),\n                                                         Bits));\n  }\n\n  // Integers which fit in intptr_t are zero-extended and passed directly.\n  if (V->getType()->isIntegerTy() &&\n      V->getType()->getIntegerBitWidth() <= TargetTy->getIntegerBitWidth())\n    return Builder.CreateZExt(V, TargetTy);\n\n  // Pointers are passed directly, everything else is passed by address.\n  if (!V->getType()->isPointerTy()) {\n    Address Ptr = CreateDefaultAlignTempAlloca(V->getType());\n    Builder.CreateStore(V, Ptr);\n    V = Ptr.getPointer();\n  }\n  return Builder.CreatePtrToInt(V, TargetTy);\n}\n\n/// Emit a representation of a SourceLocation for passing to a handler\n/// in a sanitizer runtime library. The format for this data is:\n/// \\code\n///   struct SourceLocation {\n///     const char *Filename;\n///     int32_t Line, Column;\n///   };\n/// \\endcode\n/// For an invalid SourceLocation, the Filename pointer is null.\nllvm::Constant *CodeGenFunction::EmitCheckSourceLocation(SourceLocation Loc) {\n  llvm::Constant *Filename;\n  int Line, Column;\n\n  PresumedLoc PLoc = getContext().getSourceManager().getPresumedLoc(Loc);\n  if (PLoc.isValid()) {\n    StringRef FilenameString = PLoc.getFilename();\n\n    int PathComponentsToStrip =\n        CGM.getCodeGenOpts().EmitCheckPathComponentsToStrip;\n    if (PathComponentsToStrip < 0) {\n      assert(PathComponentsToStrip != INT_MIN);\n      int PathComponentsToKeep = -PathComponentsToStrip;\n      auto I = llvm::sys::path::rbegin(FilenameString);\n      auto E = llvm::sys::path::rend(FilenameString);\n      while (I != E && --PathComponentsToKeep)\n        ++I;\n\n      FilenameString = FilenameString.substr(I - E);\n    } else if (PathComponentsToStrip > 0) {\n      auto I = llvm::sys::path::begin(FilenameString);\n      auto E = llvm::sys::path::end(FilenameString);\n      while (I != E && PathComponentsToStrip--)\n        ++I;\n\n      if (I != E)\n        FilenameString =\n            FilenameString.substr(I - llvm::sys::path::begin(FilenameString));\n      else\n        FilenameString = llvm::sys::path::filename(FilenameString);\n    }\n\n    auto FilenameGV =\n        CGM.GetAddrOfConstantCString(std::string(FilenameString), \".src\");\n    CGM.getSanitizerMetadata()->disableSanitizerForGlobal(\n                          cast<llvm::GlobalVariable>(FilenameGV.getPointer()));\n    Filename = FilenameGV.getPointer();\n    Line = PLoc.getLine();\n    Column = PLoc.getColumn();\n  } else {\n    Filename = llvm::Constant::getNullValue(Int8PtrTy);\n    Line = Column = 0;\n  }\n\n  llvm::Constant *Data[] = {Filename, Builder.getInt32(Line),\n                            Builder.getInt32(Column)};\n\n  return llvm::ConstantStruct::getAnon(Data);\n}\n\nnamespace {\n/// Specify under what conditions this check can be recovered\nenum class CheckRecoverableKind {\n  /// Always terminate program execution if this check fails.\n  Unrecoverable,\n  /// Check supports recovering, runtime has both fatal (noreturn) and\n  /// non-fatal handlers for this check.\n  Recoverable,\n  /// Runtime conditionally aborts, always need to support recovery.\n  AlwaysRecoverable\n};\n}\n\nstatic CheckRecoverableKind getRecoverableKind(SanitizerMask Kind) {\n  assert(Kind.countPopulation() == 1);\n  if (Kind == SanitizerKind::Function || Kind == SanitizerKind::Vptr)\n    return CheckRecoverableKind::AlwaysRecoverable;\n  else if (Kind == SanitizerKind::Return || Kind == SanitizerKind::Unreachable)\n    return CheckRecoverableKind::Unrecoverable;\n  else\n    return CheckRecoverableKind::Recoverable;\n}\n\nnamespace {\nstruct SanitizerHandlerInfo {\n  char const *const Name;\n  unsigned Version;\n};\n}\n\nconst SanitizerHandlerInfo SanitizerHandlers[] = {\n#define SANITIZER_CHECK(Enum, Name, Version) {#Name, Version},\n    LIST_SANITIZER_CHECKS\n#undef SANITIZER_CHECK\n};\n\nstatic void emitCheckHandlerCall(CodeGenFunction &CGF,\n                                 llvm::FunctionType *FnType,\n                                 ArrayRef<llvm::Value *> FnArgs,\n                                 SanitizerHandler CheckHandler,\n                                 CheckRecoverableKind RecoverKind, bool IsFatal,\n                                 llvm::BasicBlock *ContBB) {\n  assert(IsFatal || RecoverKind != CheckRecoverableKind::Unrecoverable);\n  Optional<ApplyDebugLocation> DL;\n  if (!CGF.Builder.getCurrentDebugLocation()) {\n    // Ensure that the call has at least an artificial debug location.\n    DL.emplace(CGF, SourceLocation());\n  }\n  bool NeedsAbortSuffix =\n      IsFatal && RecoverKind != CheckRecoverableKind::Unrecoverable;\n  bool MinimalRuntime = CGF.CGM.getCodeGenOpts().SanitizeMinimalRuntime;\n  const SanitizerHandlerInfo &CheckInfo = SanitizerHandlers[CheckHandler];\n  const StringRef CheckName = CheckInfo.Name;\n  std::string FnName = \"__ubsan_handle_\" + CheckName.str();\n  if (CheckInfo.Version && !MinimalRuntime)\n    FnName += \"_v\" + llvm::utostr(CheckInfo.Version);\n  if (MinimalRuntime)\n    FnName += \"_minimal\";\n  if (NeedsAbortSuffix)\n    FnName += \"_abort\";\n  bool MayReturn =\n      !IsFatal || RecoverKind == CheckRecoverableKind::AlwaysRecoverable;\n\n  llvm::AttrBuilder B;\n  if (!MayReturn) {\n    B.addAttribute(llvm::Attribute::NoReturn)\n        .addAttribute(llvm::Attribute::NoUnwind);\n  }\n  B.addAttribute(llvm::Attribute::UWTable);\n\n  llvm::FunctionCallee Fn = CGF.CGM.CreateRuntimeFunction(\n      FnType, FnName,\n      llvm::AttributeList::get(CGF.getLLVMContext(),\n                               llvm::AttributeList::FunctionIndex, B),\n      /*Local=*/true);\n  llvm::CallInst *HandlerCall = CGF.EmitNounwindRuntimeCall(Fn, FnArgs);\n  if (!MayReturn) {\n    HandlerCall->setDoesNotReturn();\n    CGF.Builder.CreateUnreachable();\n  } else {\n    CGF.Builder.CreateBr(ContBB);\n  }\n}\n\nvoid CodeGenFunction::EmitCheck(\n    ArrayRef<std::pair<llvm::Value *, SanitizerMask>> Checked,\n    SanitizerHandler CheckHandler, ArrayRef<llvm::Constant *> StaticArgs,\n    ArrayRef<llvm::Value *> DynamicArgs) {\n  assert(IsSanitizerScope);\n  assert(Checked.size() > 0);\n  assert(CheckHandler >= 0 &&\n         size_t(CheckHandler) < llvm::array_lengthof(SanitizerHandlers));\n  const StringRef CheckName = SanitizerHandlers[CheckHandler].Name;\n\n  llvm::Value *FatalCond = nullptr;\n  llvm::Value *RecoverableCond = nullptr;\n  llvm::Value *TrapCond = nullptr;\n  for (int i = 0, n = Checked.size(); i < n; ++i) {\n    llvm::Value *Check = Checked[i].first;\n    // -fsanitize-trap= overrides -fsanitize-recover=.\n    llvm::Value *&Cond =\n        CGM.getCodeGenOpts().SanitizeTrap.has(Checked[i].second)\n            ? TrapCond\n            : CGM.getCodeGenOpts().SanitizeRecover.has(Checked[i].second)\n                  ? RecoverableCond\n                  : FatalCond;\n    Cond = Cond ? Builder.CreateAnd(Cond, Check) : Check;\n  }\n\n  if (TrapCond)\n    EmitTrapCheck(TrapCond, CheckHandler);\n  if (!FatalCond && !RecoverableCond)\n    return;\n\n  llvm::Value *JointCond;\n  if (FatalCond && RecoverableCond)\n    JointCond = Builder.CreateAnd(FatalCond, RecoverableCond);\n  else\n    JointCond = FatalCond ? FatalCond : RecoverableCond;\n  assert(JointCond);\n\n  CheckRecoverableKind RecoverKind = getRecoverableKind(Checked[0].second);\n  assert(SanOpts.has(Checked[0].second));\n#ifndef NDEBUG\n  for (int i = 1, n = Checked.size(); i < n; ++i) {\n    assert(RecoverKind == getRecoverableKind(Checked[i].second) &&\n           \"All recoverable kinds in a single check must be same!\");\n    assert(SanOpts.has(Checked[i].second));\n  }\n#endif\n\n  llvm::BasicBlock *Cont = createBasicBlock(\"cont\");\n  llvm::BasicBlock *Handlers = createBasicBlock(\"handler.\" + CheckName);\n  llvm::Instruction *Branch = Builder.CreateCondBr(JointCond, Cont, Handlers);\n  // Give hint that we very much don't expect to execute the handler\n  // Value chosen to match UR_NONTAKEN_WEIGHT, see BranchProbabilityInfo.cpp\n  llvm::MDBuilder MDHelper(getLLVMContext());\n  llvm::MDNode *Node = MDHelper.createBranchWeights((1U << 20) - 1, 1);\n  Branch->setMetadata(llvm::LLVMContext::MD_prof, Node);\n  EmitBlock(Handlers);\n\n  // Handler functions take an i8* pointing to the (handler-specific) static\n  // information block, followed by a sequence of intptr_t arguments\n  // representing operand values.\n  SmallVector<llvm::Value *, 4> Args;\n  SmallVector<llvm::Type *, 4> ArgTypes;\n  if (!CGM.getCodeGenOpts().SanitizeMinimalRuntime) {\n    Args.reserve(DynamicArgs.size() + 1);\n    ArgTypes.reserve(DynamicArgs.size() + 1);\n\n    // Emit handler arguments and create handler function type.\n    if (!StaticArgs.empty()) {\n      llvm::Constant *Info = llvm::ConstantStruct::getAnon(StaticArgs);\n      auto *InfoPtr =\n          new llvm::GlobalVariable(CGM.getModule(), Info->getType(), false,\n                                   llvm::GlobalVariable::PrivateLinkage, Info);\n      InfoPtr->setUnnamedAddr(llvm::GlobalValue::UnnamedAddr::Global);\n      CGM.getSanitizerMetadata()->disableSanitizerForGlobal(InfoPtr);\n      Args.push_back(Builder.CreateBitCast(InfoPtr, Int8PtrTy));\n      ArgTypes.push_back(Int8PtrTy);\n    }\n\n    for (size_t i = 0, n = DynamicArgs.size(); i != n; ++i) {\n      Args.push_back(EmitCheckValue(DynamicArgs[i]));\n      ArgTypes.push_back(IntPtrTy);\n    }\n  }\n\n  llvm::FunctionType *FnType =\n    llvm::FunctionType::get(CGM.VoidTy, ArgTypes, false);\n\n  if (!FatalCond || !RecoverableCond) {\n    // Simple case: we need to generate a single handler call, either\n    // fatal, or non-fatal.\n    emitCheckHandlerCall(*this, FnType, Args, CheckHandler, RecoverKind,\n                         (FatalCond != nullptr), Cont);\n  } else {\n    // Emit two handler calls: first one for set of unrecoverable checks,\n    // another one for recoverable.\n    llvm::BasicBlock *NonFatalHandlerBB =\n        createBasicBlock(\"non_fatal.\" + CheckName);\n    llvm::BasicBlock *FatalHandlerBB = createBasicBlock(\"fatal.\" + CheckName);\n    Builder.CreateCondBr(FatalCond, NonFatalHandlerBB, FatalHandlerBB);\n    EmitBlock(FatalHandlerBB);\n    emitCheckHandlerCall(*this, FnType, Args, CheckHandler, RecoverKind, true,\n                         NonFatalHandlerBB);\n    EmitBlock(NonFatalHandlerBB);\n    emitCheckHandlerCall(*this, FnType, Args, CheckHandler, RecoverKind, false,\n                         Cont);\n  }\n\n  EmitBlock(Cont);\n}\n\nvoid CodeGenFunction::EmitCfiSlowPathCheck(\n    SanitizerMask Kind, llvm::Value *Cond, llvm::ConstantInt *TypeId,\n    llvm::Value *Ptr, ArrayRef<llvm::Constant *> StaticArgs) {\n  llvm::BasicBlock *Cont = createBasicBlock(\"cfi.cont\");\n\n  llvm::BasicBlock *CheckBB = createBasicBlock(\"cfi.slowpath\");\n  llvm::BranchInst *BI = Builder.CreateCondBr(Cond, Cont, CheckBB);\n\n  llvm::MDBuilder MDHelper(getLLVMContext());\n  llvm::MDNode *Node = MDHelper.createBranchWeights((1U << 20) - 1, 1);\n  BI->setMetadata(llvm::LLVMContext::MD_prof, Node);\n\n  EmitBlock(CheckBB);\n\n  bool WithDiag = !CGM.getCodeGenOpts().SanitizeTrap.has(Kind);\n\n  llvm::CallInst *CheckCall;\n  llvm::FunctionCallee SlowPathFn;\n  if (WithDiag) {\n    llvm::Constant *Info = llvm::ConstantStruct::getAnon(StaticArgs);\n    auto *InfoPtr =\n        new llvm::GlobalVariable(CGM.getModule(), Info->getType(), false,\n                                 llvm::GlobalVariable::PrivateLinkage, Info);\n    InfoPtr->setUnnamedAddr(llvm::GlobalValue::UnnamedAddr::Global);\n    CGM.getSanitizerMetadata()->disableSanitizerForGlobal(InfoPtr);\n\n    SlowPathFn = CGM.getModule().getOrInsertFunction(\n        \"__cfi_slowpath_diag\",\n        llvm::FunctionType::get(VoidTy, {Int64Ty, Int8PtrTy, Int8PtrTy},\n                                false));\n    CheckCall = Builder.CreateCall(\n        SlowPathFn, {TypeId, Ptr, Builder.CreateBitCast(InfoPtr, Int8PtrTy)});\n  } else {\n    SlowPathFn = CGM.getModule().getOrInsertFunction(\n        \"__cfi_slowpath\",\n        llvm::FunctionType::get(VoidTy, {Int64Ty, Int8PtrTy}, false));\n    CheckCall = Builder.CreateCall(SlowPathFn, {TypeId, Ptr});\n  }\n\n  CGM.setDSOLocal(\n      cast<llvm::GlobalValue>(SlowPathFn.getCallee()->stripPointerCasts()));\n  CheckCall->setDoesNotThrow();\n\n  EmitBlock(Cont);\n}\n\n// Emit a stub for __cfi_check function so that the linker knows about this\n// symbol in LTO mode.\nvoid CodeGenFunction::EmitCfiCheckStub() {\n  llvm::Module *M = &CGM.getModule();\n  auto &Ctx = M->getContext();\n  llvm::Function *F = llvm::Function::Create(\n      llvm::FunctionType::get(VoidTy, {Int64Ty, Int8PtrTy, Int8PtrTy}, false),\n      llvm::GlobalValue::WeakAnyLinkage, \"__cfi_check\", M);\n  CGM.setDSOLocal(F);\n  llvm::BasicBlock *BB = llvm::BasicBlock::Create(Ctx, \"entry\", F);\n  // FIXME: consider emitting an intrinsic call like\n  // call void @llvm.cfi_check(i64 %0, i8* %1, i8* %2)\n  // which can be lowered in CrossDSOCFI pass to the actual contents of\n  // __cfi_check. This would allow inlining of __cfi_check calls.\n  llvm::CallInst::Create(\n      llvm::Intrinsic::getDeclaration(M, llvm::Intrinsic::trap), \"\", BB);\n  llvm::ReturnInst::Create(Ctx, nullptr, BB);\n}\n\n// This function is basically a switch over the CFI failure kind, which is\n// extracted from CFICheckFailData (1st function argument). Each case is either\n// llvm.trap or a call to one of the two runtime handlers, based on\n// -fsanitize-trap and -fsanitize-recover settings.  Default case (invalid\n// failure kind) traps, but this should really never happen.  CFICheckFailData\n// can be nullptr if the calling module has -fsanitize-trap behavior for this\n// check kind; in this case __cfi_check_fail traps as well.\nvoid CodeGenFunction::EmitCfiCheckFail() {\n  SanitizerScope SanScope(this);\n  FunctionArgList Args;\n  ImplicitParamDecl ArgData(getContext(), getContext().VoidPtrTy,\n                            ImplicitParamDecl::Other);\n  ImplicitParamDecl ArgAddr(getContext(), getContext().VoidPtrTy,\n                            ImplicitParamDecl::Other);\n  Args.push_back(&ArgData);\n  Args.push_back(&ArgAddr);\n\n  const CGFunctionInfo &FI =\n    CGM.getTypes().arrangeBuiltinFunctionDeclaration(getContext().VoidTy, Args);\n\n  llvm::Function *F = llvm::Function::Create(\n      llvm::FunctionType::get(VoidTy, {VoidPtrTy, VoidPtrTy}, false),\n      llvm::GlobalValue::WeakODRLinkage, \"__cfi_check_fail\", &CGM.getModule());\n\n  CGM.SetLLVMFunctionAttributes(GlobalDecl(), FI, F);\n  CGM.SetLLVMFunctionAttributesForDefinition(nullptr, F);\n  F->setVisibility(llvm::GlobalValue::HiddenVisibility);\n\n  StartFunction(GlobalDecl(), CGM.getContext().VoidTy, F, FI, Args,\n                SourceLocation());\n\n  // This function is not affected by NoSanitizeList. This function does\n  // not have a source location, but \"src:*\" would still apply. Revert any\n  // changes to SanOpts made in StartFunction.\n  SanOpts = CGM.getLangOpts().Sanitize;\n\n  llvm::Value *Data =\n      EmitLoadOfScalar(GetAddrOfLocalVar(&ArgData), /*Volatile=*/false,\n                       CGM.getContext().VoidPtrTy, ArgData.getLocation());\n  llvm::Value *Addr =\n      EmitLoadOfScalar(GetAddrOfLocalVar(&ArgAddr), /*Volatile=*/false,\n                       CGM.getContext().VoidPtrTy, ArgAddr.getLocation());\n\n  // Data == nullptr means the calling module has trap behaviour for this check.\n  llvm::Value *DataIsNotNullPtr =\n      Builder.CreateICmpNE(Data, llvm::ConstantPointerNull::get(Int8PtrTy));\n  EmitTrapCheck(DataIsNotNullPtr, SanitizerHandler::CFICheckFail);\n\n  llvm::StructType *SourceLocationTy =\n      llvm::StructType::get(VoidPtrTy, Int32Ty, Int32Ty);\n  llvm::StructType *CfiCheckFailDataTy =\n      llvm::StructType::get(Int8Ty, SourceLocationTy, VoidPtrTy);\n\n  llvm::Value *V = Builder.CreateConstGEP2_32(\n      CfiCheckFailDataTy,\n      Builder.CreatePointerCast(Data, CfiCheckFailDataTy->getPointerTo(0)), 0,\n      0);\n  Address CheckKindAddr(V, getIntAlign());\n  llvm::Value *CheckKind = Builder.CreateLoad(CheckKindAddr);\n\n  llvm::Value *AllVtables = llvm::MetadataAsValue::get(\n      CGM.getLLVMContext(),\n      llvm::MDString::get(CGM.getLLVMContext(), \"all-vtables\"));\n  llvm::Value *ValidVtable = Builder.CreateZExt(\n      Builder.CreateCall(CGM.getIntrinsic(llvm::Intrinsic::type_test),\n                         {Addr, AllVtables}),\n      IntPtrTy);\n\n  const std::pair<int, SanitizerMask> CheckKinds[] = {\n      {CFITCK_VCall, SanitizerKind::CFIVCall},\n      {CFITCK_NVCall, SanitizerKind::CFINVCall},\n      {CFITCK_DerivedCast, SanitizerKind::CFIDerivedCast},\n      {CFITCK_UnrelatedCast, SanitizerKind::CFIUnrelatedCast},\n      {CFITCK_ICall, SanitizerKind::CFIICall}};\n\n  SmallVector<std::pair<llvm::Value *, SanitizerMask>, 5> Checks;\n  for (auto CheckKindMaskPair : CheckKinds) {\n    int Kind = CheckKindMaskPair.first;\n    SanitizerMask Mask = CheckKindMaskPair.second;\n    llvm::Value *Cond =\n        Builder.CreateICmpNE(CheckKind, llvm::ConstantInt::get(Int8Ty, Kind));\n    if (CGM.getLangOpts().Sanitize.has(Mask))\n      EmitCheck(std::make_pair(Cond, Mask), SanitizerHandler::CFICheckFail, {},\n                {Data, Addr, ValidVtable});\n    else\n      EmitTrapCheck(Cond, SanitizerHandler::CFICheckFail);\n  }\n\n  FinishFunction();\n  // The only reference to this function will be created during LTO link.\n  // Make sure it survives until then.\n  CGM.addUsedGlobal(F);\n}\n\nvoid CodeGenFunction::EmitUnreachable(SourceLocation Loc) {\n  if (SanOpts.has(SanitizerKind::Unreachable)) {\n    SanitizerScope SanScope(this);\n    EmitCheck(std::make_pair(static_cast<llvm::Value *>(Builder.getFalse()),\n                             SanitizerKind::Unreachable),\n              SanitizerHandler::BuiltinUnreachable,\n              EmitCheckSourceLocation(Loc), None);\n  }\n  Builder.CreateUnreachable();\n}\n\nvoid CodeGenFunction::EmitTrapCheck(llvm::Value *Checked,\n                                    SanitizerHandler CheckHandlerID) {\n  llvm::BasicBlock *Cont = createBasicBlock(\"cont\");\n\n  // If we're optimizing, collapse all calls to trap down to just one per\n  // check-type per function to save on code size.\n  if (TrapBBs.size() <= CheckHandlerID)\n    TrapBBs.resize(CheckHandlerID + 1);\n  llvm::BasicBlock *&TrapBB = TrapBBs[CheckHandlerID];\n\n  if (!CGM.getCodeGenOpts().OptimizationLevel || !TrapBB) {\n    TrapBB = createBasicBlock(\"trap\");\n    Builder.CreateCondBr(Checked, Cont, TrapBB);\n    EmitBlock(TrapBB);\n\n    llvm::CallInst *TrapCall =\n        Builder.CreateCall(CGM.getIntrinsic(llvm::Intrinsic::ubsantrap),\n                           llvm::ConstantInt::get(CGM.Int8Ty, CheckHandlerID));\n\n    if (!CGM.getCodeGenOpts().TrapFuncName.empty()) {\n      auto A = llvm::Attribute::get(getLLVMContext(), \"trap-func-name\",\n                                    CGM.getCodeGenOpts().TrapFuncName);\n      TrapCall->addAttribute(llvm::AttributeList::FunctionIndex, A);\n    }\n    TrapCall->setDoesNotReturn();\n    TrapCall->setDoesNotThrow();\n    Builder.CreateUnreachable();\n  } else {\n    auto Call = TrapBB->begin();\n    assert(isa<llvm::CallInst>(Call) && \"Expected call in trap BB\");\n\n    Call->applyMergedLocation(Call->getDebugLoc(),\n                              Builder.getCurrentDebugLocation());\n    Builder.CreateCondBr(Checked, Cont, TrapBB);\n  }\n\n  EmitBlock(Cont);\n}\n\nllvm::CallInst *CodeGenFunction::EmitTrapCall(llvm::Intrinsic::ID IntrID) {\n  llvm::CallInst *TrapCall =\n      Builder.CreateCall(CGM.getIntrinsic(IntrID));\n\n  if (!CGM.getCodeGenOpts().TrapFuncName.empty()) {\n    auto A = llvm::Attribute::get(getLLVMContext(), \"trap-func-name\",\n                                  CGM.getCodeGenOpts().TrapFuncName);\n    TrapCall->addAttribute(llvm::AttributeList::FunctionIndex, A);\n  }\n\n  return TrapCall;\n}\n\nAddress CodeGenFunction::EmitArrayToPointerDecay(const Expr *E,\n                                                 LValueBaseInfo *BaseInfo,\n                                                 TBAAAccessInfo *TBAAInfo) {\n  assert(E->getType()->isArrayType() &&\n         \"Array to pointer decay must have array source type!\");\n\n  // Expressions of array type can't be bitfields or vector elements.\n  LValue LV = EmitLValue(E);\n  Address Addr = LV.getAddress(*this);\n\n  // If the array type was an incomplete type, we need to make sure\n  // the decay ends up being the right type.\n  llvm::Type *NewTy = ConvertType(E->getType());\n  Addr = Builder.CreateElementBitCast(Addr, NewTy);\n\n  // Note that VLA pointers are always decayed, so we don't need to do\n  // anything here.\n  if (!E->getType()->isVariableArrayType()) {\n    assert(isa<llvm::ArrayType>(Addr.getElementType()) &&\n           \"Expected pointer to array\");\n    Addr = Builder.CreateConstArrayGEP(Addr, 0, \"arraydecay\");\n  }\n\n  // The result of this decay conversion points to an array element within the\n  // base lvalue. However, since TBAA currently does not support representing\n  // accesses to elements of member arrays, we conservatively represent accesses\n  // to the pointee object as if it had no any base lvalue specified.\n  // TODO: Support TBAA for member arrays.\n  QualType EltType = E->getType()->castAsArrayTypeUnsafe()->getElementType();\n  if (BaseInfo) *BaseInfo = LV.getBaseInfo();\n  if (TBAAInfo) *TBAAInfo = CGM.getTBAAAccessInfo(EltType);\n\n  return Builder.CreateElementBitCast(Addr, ConvertTypeForMem(EltType));\n}\n\n/// isSimpleArrayDecayOperand - If the specified expr is a simple decay from an\n/// array to pointer, return the array subexpression.\nstatic const Expr *isSimpleArrayDecayOperand(const Expr *E) {\n  // If this isn't just an array->pointer decay, bail out.\n  const auto *CE = dyn_cast<CastExpr>(E);\n  if (!CE || CE->getCastKind() != CK_ArrayToPointerDecay)\n    return nullptr;\n\n  // If this is a decay from variable width array, bail out.\n  const Expr *SubExpr = CE->getSubExpr();\n  if (SubExpr->getType()->isVariableArrayType())\n    return nullptr;\n\n  return SubExpr;\n}\n\nstatic llvm::Value *emitArraySubscriptGEP(CodeGenFunction &CGF,\n                                          llvm::Value *ptr,\n                                          ArrayRef<llvm::Value*> indices,\n                                          bool inbounds,\n                                          bool signedIndices,\n                                          SourceLocation loc,\n                                    const llvm::Twine &name = \"arrayidx\") {\n  if (inbounds) {\n    return CGF.EmitCheckedInBoundsGEP(ptr, indices, signedIndices,\n                                      CodeGenFunction::NotSubtraction, loc,\n                                      name);\n  } else {\n    return CGF.Builder.CreateGEP(ptr, indices, name);\n  }\n}\n\nstatic CharUnits getArrayElementAlign(CharUnits arrayAlign,\n                                      llvm::Value *idx,\n                                      CharUnits eltSize) {\n  // If we have a constant index, we can use the exact offset of the\n  // element we're accessing.\n  if (auto constantIdx = dyn_cast<llvm::ConstantInt>(idx)) {\n    CharUnits offset = constantIdx->getZExtValue() * eltSize;\n    return arrayAlign.alignmentAtOffset(offset);\n\n  // Otherwise, use the worst-case alignment for any element.\n  } else {\n    return arrayAlign.alignmentOfArrayElement(eltSize);\n  }\n}\n\nstatic QualType getFixedSizeElementType(const ASTContext &ctx,\n                                        const VariableArrayType *vla) {\n  QualType eltType;\n  do {\n    eltType = vla->getElementType();\n  } while ((vla = ctx.getAsVariableArrayType(eltType)));\n  return eltType;\n}\n\n/// Given an array base, check whether its member access belongs to a record\n/// with preserve_access_index attribute or not.\nstatic bool IsPreserveAIArrayBase(CodeGenFunction &CGF, const Expr *ArrayBase) {\n  if (!ArrayBase || !CGF.getDebugInfo())\n    return false;\n\n  // Only support base as either a MemberExpr or DeclRefExpr.\n  // DeclRefExpr to cover cases like:\n  //    struct s { int a; int b[10]; };\n  //    struct s *p;\n  //    p[1].a\n  // p[1] will generate a DeclRefExpr and p[1].a is a MemberExpr.\n  // p->b[5] is a MemberExpr example.\n  const Expr *E = ArrayBase->IgnoreImpCasts();\n  if (const auto *ME = dyn_cast<MemberExpr>(E))\n    return ME->getMemberDecl()->hasAttr<BPFPreserveAccessIndexAttr>();\n\n  if (const auto *DRE = dyn_cast<DeclRefExpr>(E)) {\n    const auto *VarDef = dyn_cast<VarDecl>(DRE->getDecl());\n    if (!VarDef)\n      return false;\n\n    const auto *PtrT = VarDef->getType()->getAs<PointerType>();\n    if (!PtrT)\n      return false;\n\n    const auto *PointeeT = PtrT->getPointeeType()\n                             ->getUnqualifiedDesugaredType();\n    if (const auto *RecT = dyn_cast<RecordType>(PointeeT))\n      return RecT->getDecl()->hasAttr<BPFPreserveAccessIndexAttr>();\n    return false;\n  }\n\n  return false;\n}\n\nstatic Address emitArraySubscriptGEP(CodeGenFunction &CGF, Address addr,\n                                     ArrayRef<llvm::Value *> indices,\n                                     QualType eltType, bool inbounds,\n                                     bool signedIndices, SourceLocation loc,\n                                     QualType *arrayType = nullptr,\n                                     const Expr *Base = nullptr,\n                                     const llvm::Twine &name = \"arrayidx\") {\n  // All the indices except that last must be zero.\n#ifndef NDEBUG\n  for (auto idx : indices.drop_back())\n    assert(isa<llvm::ConstantInt>(idx) &&\n           cast<llvm::ConstantInt>(idx)->isZero());\n#endif\n\n  // Determine the element size of the statically-sized base.  This is\n  // the thing that the indices are expressed in terms of.\n  if (auto vla = CGF.getContext().getAsVariableArrayType(eltType)) {\n    eltType = getFixedSizeElementType(CGF.getContext(), vla);\n  }\n\n  // We can use that to compute the best alignment of the element.\n  CharUnits eltSize = CGF.getContext().getTypeSizeInChars(eltType);\n  CharUnits eltAlign =\n    getArrayElementAlign(addr.getAlignment(), indices.back(), eltSize);\n\n  llvm::Value *eltPtr;\n  auto LastIndex = dyn_cast<llvm::ConstantInt>(indices.back());\n  if (!LastIndex ||\n      (!CGF.IsInPreservedAIRegion && !IsPreserveAIArrayBase(CGF, Base))) {\n    eltPtr = emitArraySubscriptGEP(\n        CGF, addr.getPointer(), indices, inbounds, signedIndices,\n        loc, name);\n  } else {\n    // Remember the original array subscript for bpf target\n    unsigned idx = LastIndex->getZExtValue();\n    llvm::DIType *DbgInfo = nullptr;\n    if (arrayType)\n      DbgInfo = CGF.getDebugInfo()->getOrCreateStandaloneType(*arrayType, loc);\n    eltPtr = CGF.Builder.CreatePreserveArrayAccessIndex(addr.getElementType(),\n                                                        addr.getPointer(),\n                                                        indices.size() - 1,\n                                                        idx, DbgInfo);\n  }\n\n  return Address(eltPtr, eltAlign);\n}\n\nLValue CodeGenFunction::EmitArraySubscriptExpr(const ArraySubscriptExpr *E,\n                                               bool Accessed) {\n  // The index must always be an integer, which is not an aggregate.  Emit it\n  // in lexical order (this complexity is, sadly, required by C++17).\n  llvm::Value *IdxPre =\n      (E->getLHS() == E->getIdx()) ? EmitScalarExpr(E->getIdx()) : nullptr;\n  bool SignedIndices = false;\n  auto EmitIdxAfterBase = [&, IdxPre](bool Promote) -> llvm::Value * {\n    auto *Idx = IdxPre;\n    if (E->getLHS() != E->getIdx()) {\n      assert(E->getRHS() == E->getIdx() && \"index was neither LHS nor RHS\");\n      Idx = EmitScalarExpr(E->getIdx());\n    }\n\n    QualType IdxTy = E->getIdx()->getType();\n    bool IdxSigned = IdxTy->isSignedIntegerOrEnumerationType();\n    SignedIndices |= IdxSigned;\n\n    if (SanOpts.has(SanitizerKind::ArrayBounds))\n      EmitBoundsCheck(E, E->getBase(), Idx, IdxTy, Accessed);\n\n    // Extend or truncate the index type to 32 or 64-bits.\n    if (Promote && Idx->getType() != IntPtrTy)\n      Idx = Builder.CreateIntCast(Idx, IntPtrTy, IdxSigned, \"idxprom\");\n\n    return Idx;\n  };\n  IdxPre = nullptr;\n\n  // If the base is a vector type, then we are forming a vector element lvalue\n  // with this subscript.\n  if (E->getBase()->getType()->isVectorType() &&\n      !isa<ExtVectorElementExpr>(E->getBase())) {\n    // Emit the vector as an lvalue to get its address.\n    LValue LHS = EmitLValue(E->getBase());\n    auto *Idx = EmitIdxAfterBase(/*Promote*/false);\n    assert(LHS.isSimple() && \"Can only subscript lvalue vectors here!\");\n    return LValue::MakeVectorElt(LHS.getAddress(*this), Idx,\n                                 E->getBase()->getType(), LHS.getBaseInfo(),\n                                 TBAAAccessInfo());\n  }\n\n  // All the other cases basically behave like simple offsetting.\n\n  // Handle the extvector case we ignored above.\n  if (isa<ExtVectorElementExpr>(E->getBase())) {\n    LValue LV = EmitLValue(E->getBase());\n    auto *Idx = EmitIdxAfterBase(/*Promote*/true);\n    Address Addr = EmitExtVectorElementLValue(LV);\n\n    QualType EltType = LV.getType()->castAs<VectorType>()->getElementType();\n    Addr = emitArraySubscriptGEP(*this, Addr, Idx, EltType, /*inbounds*/ true,\n                                 SignedIndices, E->getExprLoc());\n    return MakeAddrLValue(Addr, EltType, LV.getBaseInfo(),\n                          CGM.getTBAAInfoForSubobject(LV, EltType));\n  }\n\n  LValueBaseInfo EltBaseInfo;\n  TBAAAccessInfo EltTBAAInfo;\n  Address Addr = Address::invalid();\n  if (const VariableArrayType *vla =\n           getContext().getAsVariableArrayType(E->getType())) {\n    // The base must be a pointer, which is not an aggregate.  Emit\n    // it.  It needs to be emitted first in case it's what captures\n    // the VLA bounds.\n    Addr = EmitPointerWithAlignment(E->getBase(), &EltBaseInfo, &EltTBAAInfo);\n    auto *Idx = EmitIdxAfterBase(/*Promote*/true);\n\n    // The element count here is the total number of non-VLA elements.\n    llvm::Value *numElements = getVLASize(vla).NumElts;\n\n    // Effectively, the multiply by the VLA size is part of the GEP.\n    // GEP indexes are signed, and scaling an index isn't permitted to\n    // signed-overflow, so we use the same semantics for our explicit\n    // multiply.  We suppress this if overflow is not undefined behavior.\n    if (getLangOpts().isSignedOverflowDefined()) {\n      Idx = Builder.CreateMul(Idx, numElements);\n    } else {\n      Idx = Builder.CreateNSWMul(Idx, numElements);\n    }\n\n    Addr = emitArraySubscriptGEP(*this, Addr, Idx, vla->getElementType(),\n                                 !getLangOpts().isSignedOverflowDefined(),\n                                 SignedIndices, E->getExprLoc());\n\n  } else if (const ObjCObjectType *OIT = E->getType()->getAs<ObjCObjectType>()){\n    // Indexing over an interface, as in \"NSString *P; P[4];\"\n\n    // Emit the base pointer.\n    Addr = EmitPointerWithAlignment(E->getBase(), &EltBaseInfo, &EltTBAAInfo);\n    auto *Idx = EmitIdxAfterBase(/*Promote*/true);\n\n    CharUnits InterfaceSize = getContext().getTypeSizeInChars(OIT);\n    llvm::Value *InterfaceSizeVal =\n        llvm::ConstantInt::get(Idx->getType(), InterfaceSize.getQuantity());\n\n    llvm::Value *ScaledIdx = Builder.CreateMul(Idx, InterfaceSizeVal);\n\n    // We don't necessarily build correct LLVM struct types for ObjC\n    // interfaces, so we can't rely on GEP to do this scaling\n    // correctly, so we need to cast to i8*.  FIXME: is this actually\n    // true?  A lot of other things in the fragile ABI would break...\n    llvm::Type *OrigBaseTy = Addr.getType();\n    Addr = Builder.CreateElementBitCast(Addr, Int8Ty);\n\n    // Do the GEP.\n    CharUnits EltAlign =\n      getArrayElementAlign(Addr.getAlignment(), Idx, InterfaceSize);\n    llvm::Value *EltPtr =\n        emitArraySubscriptGEP(*this, Addr.getPointer(), ScaledIdx, false,\n                              SignedIndices, E->getExprLoc());\n    Addr = Address(EltPtr, EltAlign);\n\n    // Cast back.\n    Addr = Builder.CreateBitCast(Addr, OrigBaseTy);\n  } else if (const Expr *Array = isSimpleArrayDecayOperand(E->getBase())) {\n    // If this is A[i] where A is an array, the frontend will have decayed the\n    // base to be a ArrayToPointerDecay implicit cast.  While correct, it is\n    // inefficient at -O0 to emit a \"gep A, 0, 0\" when codegen'ing it, then a\n    // \"gep x, i\" here.  Emit one \"gep A, 0, i\".\n    assert(Array->getType()->isArrayType() &&\n           \"Array to pointer decay must have array source type!\");\n    LValue ArrayLV;\n    // For simple multidimensional array indexing, set the 'accessed' flag for\n    // better bounds-checking of the base expression.\n    if (const auto *ASE = dyn_cast<ArraySubscriptExpr>(Array))\n      ArrayLV = EmitArraySubscriptExpr(ASE, /*Accessed*/ true);\n    else\n      ArrayLV = EmitLValue(Array);\n    auto *Idx = EmitIdxAfterBase(/*Promote*/true);\n\n    // Propagate the alignment from the array itself to the result.\n    QualType arrayType = Array->getType();\n    Addr = emitArraySubscriptGEP(\n        *this, ArrayLV.getAddress(*this), {CGM.getSize(CharUnits::Zero()), Idx},\n        E->getType(), !getLangOpts().isSignedOverflowDefined(), SignedIndices,\n        E->getExprLoc(), &arrayType, E->getBase());\n    EltBaseInfo = ArrayLV.getBaseInfo();\n    EltTBAAInfo = CGM.getTBAAInfoForSubobject(ArrayLV, E->getType());\n  } else {\n    // The base must be a pointer; emit it with an estimate of its alignment.\n    Addr = EmitPointerWithAlignment(E->getBase(), &EltBaseInfo, &EltTBAAInfo);\n    auto *Idx = EmitIdxAfterBase(/*Promote*/true);\n    QualType ptrType = E->getBase()->getType();\n    Addr = emitArraySubscriptGEP(*this, Addr, Idx, E->getType(),\n                                 !getLangOpts().isSignedOverflowDefined(),\n                                 SignedIndices, E->getExprLoc(), &ptrType,\n                                 E->getBase());\n  }\n\n  LValue LV = MakeAddrLValue(Addr, E->getType(), EltBaseInfo, EltTBAAInfo);\n\n  if (getLangOpts().ObjC &&\n      getLangOpts().getGC() != LangOptions::NonGC) {\n    LV.setNonGC(!E->isOBJCGCCandidate(getContext()));\n    setObjCGCLValueClass(getContext(), E, LV);\n  }\n  return LV;\n}\n\nLValue CodeGenFunction::EmitMatrixSubscriptExpr(const MatrixSubscriptExpr *E) {\n  assert(\n      !E->isIncomplete() &&\n      \"incomplete matrix subscript expressions should be rejected during Sema\");\n  LValue Base = EmitLValue(E->getBase());\n  llvm::Value *RowIdx = EmitScalarExpr(E->getRowIdx());\n  llvm::Value *ColIdx = EmitScalarExpr(E->getColumnIdx());\n  llvm::Value *NumRows = Builder.getIntN(\n      RowIdx->getType()->getScalarSizeInBits(),\n      E->getBase()->getType()->castAs<ConstantMatrixType>()->getNumRows());\n  llvm::Value *FinalIdx =\n      Builder.CreateAdd(Builder.CreateMul(ColIdx, NumRows), RowIdx);\n  return LValue::MakeMatrixElt(\n      MaybeConvertMatrixAddress(Base.getAddress(*this), *this), FinalIdx,\n      E->getBase()->getType(), Base.getBaseInfo(), TBAAAccessInfo());\n}\n\nstatic Address emitOMPArraySectionBase(CodeGenFunction &CGF, const Expr *Base,\n                                       LValueBaseInfo &BaseInfo,\n                                       TBAAAccessInfo &TBAAInfo,\n                                       QualType BaseTy, QualType ElTy,\n                                       bool IsLowerBound) {\n  LValue BaseLVal;\n  if (auto *ASE = dyn_cast<OMPArraySectionExpr>(Base->IgnoreParenImpCasts())) {\n    BaseLVal = CGF.EmitOMPArraySectionExpr(ASE, IsLowerBound);\n    if (BaseTy->isArrayType()) {\n      Address Addr = BaseLVal.getAddress(CGF);\n      BaseInfo = BaseLVal.getBaseInfo();\n\n      // If the array type was an incomplete type, we need to make sure\n      // the decay ends up being the right type.\n      llvm::Type *NewTy = CGF.ConvertType(BaseTy);\n      Addr = CGF.Builder.CreateElementBitCast(Addr, NewTy);\n\n      // Note that VLA pointers are always decayed, so we don't need to do\n      // anything here.\n      if (!BaseTy->isVariableArrayType()) {\n        assert(isa<llvm::ArrayType>(Addr.getElementType()) &&\n               \"Expected pointer to array\");\n        Addr = CGF.Builder.CreateConstArrayGEP(Addr, 0, \"arraydecay\");\n      }\n\n      return CGF.Builder.CreateElementBitCast(Addr,\n                                              CGF.ConvertTypeForMem(ElTy));\n    }\n    LValueBaseInfo TypeBaseInfo;\n    TBAAAccessInfo TypeTBAAInfo;\n    CharUnits Align =\n        CGF.CGM.getNaturalTypeAlignment(ElTy, &TypeBaseInfo, &TypeTBAAInfo);\n    BaseInfo.mergeForCast(TypeBaseInfo);\n    TBAAInfo = CGF.CGM.mergeTBAAInfoForCast(TBAAInfo, TypeTBAAInfo);\n    return Address(CGF.Builder.CreateLoad(BaseLVal.getAddress(CGF)), Align);\n  }\n  return CGF.EmitPointerWithAlignment(Base, &BaseInfo, &TBAAInfo);\n}\n\nLValue CodeGenFunction::EmitOMPArraySectionExpr(const OMPArraySectionExpr *E,\n                                                bool IsLowerBound) {\n  QualType BaseTy = OMPArraySectionExpr::getBaseOriginalType(E->getBase());\n  QualType ResultExprTy;\n  if (auto *AT = getContext().getAsArrayType(BaseTy))\n    ResultExprTy = AT->getElementType();\n  else\n    ResultExprTy = BaseTy->getPointeeType();\n  llvm::Value *Idx = nullptr;\n  if (IsLowerBound || E->getColonLocFirst().isInvalid()) {\n    // Requesting lower bound or upper bound, but without provided length and\n    // without ':' symbol for the default length -> length = 1.\n    // Idx = LowerBound ?: 0;\n    if (auto *LowerBound = E->getLowerBound()) {\n      Idx = Builder.CreateIntCast(\n          EmitScalarExpr(LowerBound), IntPtrTy,\n          LowerBound->getType()->hasSignedIntegerRepresentation());\n    } else\n      Idx = llvm::ConstantInt::getNullValue(IntPtrTy);\n  } else {\n    // Try to emit length or lower bound as constant. If this is possible, 1\n    // is subtracted from constant length or lower bound. Otherwise, emit LLVM\n    // IR (LB + Len) - 1.\n    auto &C = CGM.getContext();\n    auto *Length = E->getLength();\n    llvm::APSInt ConstLength;\n    if (Length) {\n      // Idx = LowerBound + Length - 1;\n      if (Optional<llvm::APSInt> CL = Length->getIntegerConstantExpr(C)) {\n        ConstLength = CL->zextOrTrunc(PointerWidthInBits);\n        Length = nullptr;\n      }\n      auto *LowerBound = E->getLowerBound();\n      llvm::APSInt ConstLowerBound(PointerWidthInBits, /*isUnsigned=*/false);\n      if (LowerBound) {\n        if (Optional<llvm::APSInt> LB = LowerBound->getIntegerConstantExpr(C)) {\n          ConstLowerBound = LB->zextOrTrunc(PointerWidthInBits);\n          LowerBound = nullptr;\n        }\n      }\n      if (!Length)\n        --ConstLength;\n      else if (!LowerBound)\n        --ConstLowerBound;\n\n      if (Length || LowerBound) {\n        auto *LowerBoundVal =\n            LowerBound\n                ? Builder.CreateIntCast(\n                      EmitScalarExpr(LowerBound), IntPtrTy,\n                      LowerBound->getType()->hasSignedIntegerRepresentation())\n                : llvm::ConstantInt::get(IntPtrTy, ConstLowerBound);\n        auto *LengthVal =\n            Length\n                ? Builder.CreateIntCast(\n                      EmitScalarExpr(Length), IntPtrTy,\n                      Length->getType()->hasSignedIntegerRepresentation())\n                : llvm::ConstantInt::get(IntPtrTy, ConstLength);\n        Idx = Builder.CreateAdd(LowerBoundVal, LengthVal, \"lb_add_len\",\n                                /*HasNUW=*/false,\n                                !getLangOpts().isSignedOverflowDefined());\n        if (Length && LowerBound) {\n          Idx = Builder.CreateSub(\n              Idx, llvm::ConstantInt::get(IntPtrTy, /*V=*/1), \"idx_sub_1\",\n              /*HasNUW=*/false, !getLangOpts().isSignedOverflowDefined());\n        }\n      } else\n        Idx = llvm::ConstantInt::get(IntPtrTy, ConstLength + ConstLowerBound);\n    } else {\n      // Idx = ArraySize - 1;\n      QualType ArrayTy = BaseTy->isPointerType()\n                             ? E->getBase()->IgnoreParenImpCasts()->getType()\n                             : BaseTy;\n      if (auto *VAT = C.getAsVariableArrayType(ArrayTy)) {\n        Length = VAT->getSizeExpr();\n        if (Optional<llvm::APSInt> L = Length->getIntegerConstantExpr(C)) {\n          ConstLength = *L;\n          Length = nullptr;\n        }\n      } else {\n        auto *CAT = C.getAsConstantArrayType(ArrayTy);\n        ConstLength = CAT->getSize();\n      }\n      if (Length) {\n        auto *LengthVal = Builder.CreateIntCast(\n            EmitScalarExpr(Length), IntPtrTy,\n            Length->getType()->hasSignedIntegerRepresentation());\n        Idx = Builder.CreateSub(\n            LengthVal, llvm::ConstantInt::get(IntPtrTy, /*V=*/1), \"len_sub_1\",\n            /*HasNUW=*/false, !getLangOpts().isSignedOverflowDefined());\n      } else {\n        ConstLength = ConstLength.zextOrTrunc(PointerWidthInBits);\n        --ConstLength;\n        Idx = llvm::ConstantInt::get(IntPtrTy, ConstLength);\n      }\n    }\n  }\n  assert(Idx);\n\n  Address EltPtr = Address::invalid();\n  LValueBaseInfo BaseInfo;\n  TBAAAccessInfo TBAAInfo;\n  if (auto *VLA = getContext().getAsVariableArrayType(ResultExprTy)) {\n    // The base must be a pointer, which is not an aggregate.  Emit\n    // it.  It needs to be emitted first in case it's what captures\n    // the VLA bounds.\n    Address Base =\n        emitOMPArraySectionBase(*this, E->getBase(), BaseInfo, TBAAInfo,\n                                BaseTy, VLA->getElementType(), IsLowerBound);\n    // The element count here is the total number of non-VLA elements.\n    llvm::Value *NumElements = getVLASize(VLA).NumElts;\n\n    // Effectively, the multiply by the VLA size is part of the GEP.\n    // GEP indexes are signed, and scaling an index isn't permitted to\n    // signed-overflow, so we use the same semantics for our explicit\n    // multiply.  We suppress this if overflow is not undefined behavior.\n    if (getLangOpts().isSignedOverflowDefined())\n      Idx = Builder.CreateMul(Idx, NumElements);\n    else\n      Idx = Builder.CreateNSWMul(Idx, NumElements);\n    EltPtr = emitArraySubscriptGEP(*this, Base, Idx, VLA->getElementType(),\n                                   !getLangOpts().isSignedOverflowDefined(),\n                                   /*signedIndices=*/false, E->getExprLoc());\n  } else if (const Expr *Array = isSimpleArrayDecayOperand(E->getBase())) {\n    // If this is A[i] where A is an array, the frontend will have decayed the\n    // base to be a ArrayToPointerDecay implicit cast.  While correct, it is\n    // inefficient at -O0 to emit a \"gep A, 0, 0\" when codegen'ing it, then a\n    // \"gep x, i\" here.  Emit one \"gep A, 0, i\".\n    assert(Array->getType()->isArrayType() &&\n           \"Array to pointer decay must have array source type!\");\n    LValue ArrayLV;\n    // For simple multidimensional array indexing, set the 'accessed' flag for\n    // better bounds-checking of the base expression.\n    if (const auto *ASE = dyn_cast<ArraySubscriptExpr>(Array))\n      ArrayLV = EmitArraySubscriptExpr(ASE, /*Accessed*/ true);\n    else\n      ArrayLV = EmitLValue(Array);\n\n    // Propagate the alignment from the array itself to the result.\n    EltPtr = emitArraySubscriptGEP(\n        *this, ArrayLV.getAddress(*this), {CGM.getSize(CharUnits::Zero()), Idx},\n        ResultExprTy, !getLangOpts().isSignedOverflowDefined(),\n        /*signedIndices=*/false, E->getExprLoc());\n    BaseInfo = ArrayLV.getBaseInfo();\n    TBAAInfo = CGM.getTBAAInfoForSubobject(ArrayLV, ResultExprTy);\n  } else {\n    Address Base = emitOMPArraySectionBase(*this, E->getBase(), BaseInfo,\n                                           TBAAInfo, BaseTy, ResultExprTy,\n                                           IsLowerBound);\n    EltPtr = emitArraySubscriptGEP(*this, Base, Idx, ResultExprTy,\n                                   !getLangOpts().isSignedOverflowDefined(),\n                                   /*signedIndices=*/false, E->getExprLoc());\n  }\n\n  return MakeAddrLValue(EltPtr, ResultExprTy, BaseInfo, TBAAInfo);\n}\n\nLValue CodeGenFunction::\nEmitExtVectorElementExpr(const ExtVectorElementExpr *E) {\n  // Emit the base vector as an l-value.\n  LValue Base;\n\n  // ExtVectorElementExpr's base can either be a vector or pointer to vector.\n  if (E->isArrow()) {\n    // If it is a pointer to a vector, emit the address and form an lvalue with\n    // it.\n    LValueBaseInfo BaseInfo;\n    TBAAAccessInfo TBAAInfo;\n    Address Ptr = EmitPointerWithAlignment(E->getBase(), &BaseInfo, &TBAAInfo);\n    const auto *PT = E->getBase()->getType()->castAs<PointerType>();\n    Base = MakeAddrLValue(Ptr, PT->getPointeeType(), BaseInfo, TBAAInfo);\n    Base.getQuals().removeObjCGCAttr();\n  } else if (E->getBase()->isGLValue()) {\n    // Otherwise, if the base is an lvalue ( as in the case of foo.x.x),\n    // emit the base as an lvalue.\n    assert(E->getBase()->getType()->isVectorType());\n    Base = EmitLValue(E->getBase());\n  } else {\n    // Otherwise, the base is a normal rvalue (as in (V+V).x), emit it as such.\n    assert(E->getBase()->getType()->isVectorType() &&\n           \"Result must be a vector\");\n    llvm::Value *Vec = EmitScalarExpr(E->getBase());\n\n    // Store the vector to memory (because LValue wants an address).\n    Address VecMem = CreateMemTemp(E->getBase()->getType());\n    Builder.CreateStore(Vec, VecMem);\n    Base = MakeAddrLValue(VecMem, E->getBase()->getType(),\n                          AlignmentSource::Decl);\n  }\n\n  QualType type =\n    E->getType().withCVRQualifiers(Base.getQuals().getCVRQualifiers());\n\n  // Encode the element access list into a vector of unsigned indices.\n  SmallVector<uint32_t, 4> Indices;\n  E->getEncodedElementAccess(Indices);\n\n  if (Base.isSimple()) {\n    llvm::Constant *CV =\n        llvm::ConstantDataVector::get(getLLVMContext(), Indices);\n    return LValue::MakeExtVectorElt(Base.getAddress(*this), CV, type,\n                                    Base.getBaseInfo(), TBAAAccessInfo());\n  }\n  assert(Base.isExtVectorElt() && \"Can only subscript lvalue vec elts here!\");\n\n  llvm::Constant *BaseElts = Base.getExtVectorElts();\n  SmallVector<llvm::Constant *, 4> CElts;\n\n  for (unsigned i = 0, e = Indices.size(); i != e; ++i)\n    CElts.push_back(BaseElts->getAggregateElement(Indices[i]));\n  llvm::Constant *CV = llvm::ConstantVector::get(CElts);\n  return LValue::MakeExtVectorElt(Base.getExtVectorAddress(), CV, type,\n                                  Base.getBaseInfo(), TBAAAccessInfo());\n}\n\nLValue CodeGenFunction::EmitMemberExpr(const MemberExpr *E) {\n  if (DeclRefExpr *DRE = tryToConvertMemberExprToDeclRefExpr(*this, E)) {\n    EmitIgnoredExpr(E->getBase());\n    return EmitDeclRefLValue(DRE);\n  }\n\n  Expr *BaseExpr = E->getBase();\n  // If this is s.x, emit s as an lvalue.  If it is s->x, emit s as a scalar.\n  LValue BaseLV;\n  if (E->isArrow()) {\n    LValueBaseInfo BaseInfo;\n    TBAAAccessInfo TBAAInfo;\n    Address Addr = EmitPointerWithAlignment(BaseExpr, &BaseInfo, &TBAAInfo);\n    QualType PtrTy = BaseExpr->getType()->getPointeeType();\n    SanitizerSet SkippedChecks;\n    bool IsBaseCXXThis = IsWrappedCXXThis(BaseExpr);\n    if (IsBaseCXXThis)\n      SkippedChecks.set(SanitizerKind::Alignment, true);\n    if (IsBaseCXXThis || isa<DeclRefExpr>(BaseExpr))\n      SkippedChecks.set(SanitizerKind::Null, true);\n    EmitTypeCheck(TCK_MemberAccess, E->getExprLoc(), Addr.getPointer(), PtrTy,\n                  /*Alignment=*/CharUnits::Zero(), SkippedChecks);\n    BaseLV = MakeAddrLValue(Addr, PtrTy, BaseInfo, TBAAInfo);\n  } else\n    BaseLV = EmitCheckedLValue(BaseExpr, TCK_MemberAccess);\n\n  NamedDecl *ND = E->getMemberDecl();\n  if (auto *Field = dyn_cast<FieldDecl>(ND)) {\n    LValue LV = EmitLValueForField(BaseLV, Field);\n    setObjCGCLValueClass(getContext(), E, LV);\n    if (getLangOpts().OpenMP) {\n      // If the member was explicitly marked as nontemporal, mark it as\n      // nontemporal. If the base lvalue is marked as nontemporal, mark access\n      // to children as nontemporal too.\n      if ((IsWrappedCXXThis(BaseExpr) &&\n           CGM.getOpenMPRuntime().isNontemporalDecl(Field)) ||\n          BaseLV.isNontemporal())\n        LV.setNontemporal(/*Value=*/true);\n    }\n    return LV;\n  }\n\n  if (const auto *FD = dyn_cast<FunctionDecl>(ND))\n    return EmitFunctionDeclLValue(*this, E, FD);\n\n  llvm_unreachable(\"Unhandled member declaration!\");\n}\n\n/// Given that we are currently emitting a lambda, emit an l-value for\n/// one of its members.\nLValue CodeGenFunction::EmitLValueForLambdaField(const FieldDecl *Field) {\n  assert(cast<CXXMethodDecl>(CurCodeDecl)->getParent()->isLambda());\n  assert(cast<CXXMethodDecl>(CurCodeDecl)->getParent() == Field->getParent());\n  QualType LambdaTagType =\n    getContext().getTagDeclType(Field->getParent());\n  LValue LambdaLV = MakeNaturalAlignAddrLValue(CXXABIThisValue, LambdaTagType);\n  return EmitLValueForField(LambdaLV, Field);\n}\n\n/// Get the field index in the debug info. The debug info structure/union\n/// will ignore the unnamed bitfields.\nunsigned CodeGenFunction::getDebugInfoFIndex(const RecordDecl *Rec,\n                                             unsigned FieldIndex) {\n  unsigned I = 0, Skipped = 0;\n\n  for (auto F : Rec->getDefinition()->fields()) {\n    if (I == FieldIndex)\n      break;\n    if (F->isUnnamedBitfield())\n      Skipped++;\n    I++;\n  }\n\n  return FieldIndex - Skipped;\n}\n\n/// Get the address of a zero-sized field within a record. The resulting\n/// address doesn't necessarily have the right type.\nstatic Address emitAddrOfZeroSizeField(CodeGenFunction &CGF, Address Base,\n                                       const FieldDecl *Field) {\n  CharUnits Offset = CGF.getContext().toCharUnitsFromBits(\n      CGF.getContext().getFieldOffset(Field));\n  if (Offset.isZero())\n    return Base;\n  Base = CGF.Builder.CreateElementBitCast(Base, CGF.Int8Ty);\n  return CGF.Builder.CreateConstInBoundsByteGEP(Base, Offset);\n}\n\n/// Drill down to the storage of a field without walking into\n/// reference types.\n///\n/// The resulting address doesn't necessarily have the right type.\nstatic Address emitAddrOfFieldStorage(CodeGenFunction &CGF, Address base,\n                                      const FieldDecl *field) {\n  if (field->isZeroSize(CGF.getContext()))\n    return emitAddrOfZeroSizeField(CGF, base, field);\n\n  const RecordDecl *rec = field->getParent();\n\n  unsigned idx =\n    CGF.CGM.getTypes().getCGRecordLayout(rec).getLLVMFieldNo(field);\n\n  return CGF.Builder.CreateStructGEP(base, idx, field->getName());\n}\n\nstatic Address emitPreserveStructAccess(CodeGenFunction &CGF, LValue base,\n                                        Address addr, const FieldDecl *field) {\n  const RecordDecl *rec = field->getParent();\n  llvm::DIType *DbgInfo = CGF.getDebugInfo()->getOrCreateStandaloneType(\n      base.getType(), rec->getLocation());\n\n  unsigned idx =\n      CGF.CGM.getTypes().getCGRecordLayout(rec).getLLVMFieldNo(field);\n\n  return CGF.Builder.CreatePreserveStructAccessIndex(\n      addr, idx, CGF.getDebugInfoFIndex(rec, field->getFieldIndex()), DbgInfo);\n}\n\nstatic bool hasAnyVptr(const QualType Type, const ASTContext &Context) {\n  const auto *RD = Type.getTypePtr()->getAsCXXRecordDecl();\n  if (!RD)\n    return false;\n\n  if (RD->isDynamicClass())\n    return true;\n\n  for (const auto &Base : RD->bases())\n    if (hasAnyVptr(Base.getType(), Context))\n      return true;\n\n  for (const FieldDecl *Field : RD->fields())\n    if (hasAnyVptr(Field->getType(), Context))\n      return true;\n\n  return false;\n}\n\nLValue CodeGenFunction::EmitLValueForField(LValue base,\n                                           const FieldDecl *field) {\n  LValueBaseInfo BaseInfo = base.getBaseInfo();\n\n  if (field->isBitField()) {\n    const CGRecordLayout &RL =\n        CGM.getTypes().getCGRecordLayout(field->getParent());\n    const CGBitFieldInfo &Info = RL.getBitFieldInfo(field);\n    const bool UseVolatile = isAAPCS(CGM.getTarget()) &&\n                             CGM.getCodeGenOpts().AAPCSBitfieldWidth &&\n                             Info.VolatileStorageSize != 0 &&\n                             field->getType()\n                                 .withCVRQualifiers(base.getVRQualifiers())\n                                 .isVolatileQualified();\n    Address Addr = base.getAddress(*this);\n    unsigned Idx = RL.getLLVMFieldNo(field);\n    const RecordDecl *rec = field->getParent();\n    if (!UseVolatile) {\n      if (!IsInPreservedAIRegion &&\n          (!getDebugInfo() || !rec->hasAttr<BPFPreserveAccessIndexAttr>())) {\n        if (Idx != 0)\n          // For structs, we GEP to the field that the record layout suggests.\n          Addr = Builder.CreateStructGEP(Addr, Idx, field->getName());\n      } else {\n        llvm::DIType *DbgInfo = getDebugInfo()->getOrCreateRecordType(\n            getContext().getRecordType(rec), rec->getLocation());\n        Addr = Builder.CreatePreserveStructAccessIndex(\n            Addr, Idx, getDebugInfoFIndex(rec, field->getFieldIndex()),\n            DbgInfo);\n      }\n    }\n    const unsigned SS =\n        UseVolatile ? Info.VolatileStorageSize : Info.StorageSize;\n    // Get the access type.\n    llvm::Type *FieldIntTy = llvm::Type::getIntNTy(getLLVMContext(), SS);\n    if (Addr.getElementType() != FieldIntTy)\n      Addr = Builder.CreateElementBitCast(Addr, FieldIntTy);\n    if (UseVolatile) {\n      const unsigned VolatileOffset = Info.VolatileStorageOffset.getQuantity();\n      if (VolatileOffset)\n        Addr = Builder.CreateConstInBoundsGEP(Addr, VolatileOffset);\n    }\n\n    QualType fieldType =\n        field->getType().withCVRQualifiers(base.getVRQualifiers());\n    // TODO: Support TBAA for bit fields.\n    LValueBaseInfo FieldBaseInfo(BaseInfo.getAlignmentSource());\n    return LValue::MakeBitfield(Addr, Info, fieldType, FieldBaseInfo,\n                                TBAAAccessInfo());\n  }\n\n  // Fields of may-alias structures are may-alias themselves.\n  // FIXME: this should get propagated down through anonymous structs\n  // and unions.\n  QualType FieldType = field->getType();\n  const RecordDecl *rec = field->getParent();\n  AlignmentSource BaseAlignSource = BaseInfo.getAlignmentSource();\n  LValueBaseInfo FieldBaseInfo(getFieldAlignmentSource(BaseAlignSource));\n  TBAAAccessInfo FieldTBAAInfo;\n  if (base.getTBAAInfo().isMayAlias() ||\n          rec->hasAttr<MayAliasAttr>() || FieldType->isVectorType()) {\n    FieldTBAAInfo = TBAAAccessInfo::getMayAliasInfo();\n  } else if (rec->isUnion()) {\n    // TODO: Support TBAA for unions.\n    FieldTBAAInfo = TBAAAccessInfo::getMayAliasInfo();\n  } else {\n    // If no base type been assigned for the base access, then try to generate\n    // one for this base lvalue.\n    FieldTBAAInfo = base.getTBAAInfo();\n    if (!FieldTBAAInfo.BaseType) {\n        FieldTBAAInfo.BaseType = CGM.getTBAABaseTypeInfo(base.getType());\n        assert(!FieldTBAAInfo.Offset &&\n               \"Nonzero offset for an access with no base type!\");\n    }\n\n    // Adjust offset to be relative to the base type.\n    const ASTRecordLayout &Layout =\n        getContext().getASTRecordLayout(field->getParent());\n    unsigned CharWidth = getContext().getCharWidth();\n    if (FieldTBAAInfo.BaseType)\n      FieldTBAAInfo.Offset +=\n          Layout.getFieldOffset(field->getFieldIndex()) / CharWidth;\n\n    // Update the final access type and size.\n    FieldTBAAInfo.AccessType = CGM.getTBAATypeInfo(FieldType);\n    FieldTBAAInfo.Size =\n        getContext().getTypeSizeInChars(FieldType).getQuantity();\n  }\n\n  Address addr = base.getAddress(*this);\n  if (auto *ClassDef = dyn_cast<CXXRecordDecl>(rec)) {\n    if (CGM.getCodeGenOpts().StrictVTablePointers &&\n        ClassDef->isDynamicClass()) {\n      // Getting to any field of dynamic object requires stripping dynamic\n      // information provided by invariant.group.  This is because accessing\n      // fields may leak the real address of dynamic object, which could result\n      // in miscompilation when leaked pointer would be compared.\n      auto *stripped = Builder.CreateStripInvariantGroup(addr.getPointer());\n      addr = Address(stripped, addr.getAlignment());\n    }\n  }\n\n  unsigned RecordCVR = base.getVRQualifiers();\n  if (rec->isUnion()) {\n    // For unions, there is no pointer adjustment.\n    if (CGM.getCodeGenOpts().StrictVTablePointers &&\n        hasAnyVptr(FieldType, getContext()))\n      // Because unions can easily skip invariant.barriers, we need to add\n      // a barrier every time CXXRecord field with vptr is referenced.\n      addr = Address(Builder.CreateLaunderInvariantGroup(addr.getPointer()),\n                     addr.getAlignment());\n\n    if (IsInPreservedAIRegion ||\n        (getDebugInfo() && rec->hasAttr<BPFPreserveAccessIndexAttr>())) {\n      // Remember the original union field index\n      llvm::DIType *DbgInfo = getDebugInfo()->getOrCreateStandaloneType(base.getType(),\n          rec->getLocation());\n      addr = Address(\n          Builder.CreatePreserveUnionAccessIndex(\n              addr.getPointer(), getDebugInfoFIndex(rec, field->getFieldIndex()), DbgInfo),\n          addr.getAlignment());\n    }\n\n    if (FieldType->isReferenceType())\n      addr = Builder.CreateElementBitCast(\n          addr, CGM.getTypes().ConvertTypeForMem(FieldType), field->getName());\n  } else {\n    if (!IsInPreservedAIRegion &&\n        (!getDebugInfo() || !rec->hasAttr<BPFPreserveAccessIndexAttr>()))\n      // For structs, we GEP to the field that the record layout suggests.\n      addr = emitAddrOfFieldStorage(*this, addr, field);\n    else\n      // Remember the original struct field index\n      addr = emitPreserveStructAccess(*this, base, addr, field);\n  }\n\n  // If this is a reference field, load the reference right now.\n  if (FieldType->isReferenceType()) {\n    LValue RefLVal =\n        MakeAddrLValue(addr, FieldType, FieldBaseInfo, FieldTBAAInfo);\n    if (RecordCVR & Qualifiers::Volatile)\n      RefLVal.getQuals().addVolatile();\n    addr = EmitLoadOfReference(RefLVal, &FieldBaseInfo, &FieldTBAAInfo);\n\n    // Qualifiers on the struct don't apply to the referencee.\n    RecordCVR = 0;\n    FieldType = FieldType->getPointeeType();\n  }\n\n  // Make sure that the address is pointing to the right type.  This is critical\n  // for both unions and structs.  A union needs a bitcast, a struct element\n  // will need a bitcast if the LLVM type laid out doesn't match the desired\n  // type.\n  addr = Builder.CreateElementBitCast(\n      addr, CGM.getTypes().ConvertTypeForMem(FieldType), field->getName());\n\n  if (field->hasAttr<AnnotateAttr>())\n    addr = EmitFieldAnnotations(field, addr);\n\n  LValue LV = MakeAddrLValue(addr, FieldType, FieldBaseInfo, FieldTBAAInfo);\n  LV.getQuals().addCVRQualifiers(RecordCVR);\n\n  // __weak attribute on a field is ignored.\n  if (LV.getQuals().getObjCGCAttr() == Qualifiers::Weak)\n    LV.getQuals().removeObjCGCAttr();\n\n  return LV;\n}\n\nLValue\nCodeGenFunction::EmitLValueForFieldInitialization(LValue Base,\n                                                  const FieldDecl *Field) {\n  QualType FieldType = Field->getType();\n\n  if (!FieldType->isReferenceType())\n    return EmitLValueForField(Base, Field);\n\n  Address V = emitAddrOfFieldStorage(*this, Base.getAddress(*this), Field);\n\n  // Make sure that the address is pointing to the right type.\n  llvm::Type *llvmType = ConvertTypeForMem(FieldType);\n  V = Builder.CreateElementBitCast(V, llvmType, Field->getName());\n\n  // TODO: Generate TBAA information that describes this access as a structure\n  // member access and not just an access to an object of the field's type. This\n  // should be similar to what we do in EmitLValueForField().\n  LValueBaseInfo BaseInfo = Base.getBaseInfo();\n  AlignmentSource FieldAlignSource = BaseInfo.getAlignmentSource();\n  LValueBaseInfo FieldBaseInfo(getFieldAlignmentSource(FieldAlignSource));\n  return MakeAddrLValue(V, FieldType, FieldBaseInfo,\n                        CGM.getTBAAInfoForSubobject(Base, FieldType));\n}\n\nLValue CodeGenFunction::EmitCompoundLiteralLValue(const CompoundLiteralExpr *E){\n  if (E->isFileScope()) {\n    ConstantAddress GlobalPtr = CGM.GetAddrOfConstantCompoundLiteral(E);\n    return MakeAddrLValue(GlobalPtr, E->getType(), AlignmentSource::Decl);\n  }\n  if (E->getType()->isVariablyModifiedType())\n    // make sure to emit the VLA size.\n    EmitVariablyModifiedType(E->getType());\n\n  Address DeclPtr = CreateMemTemp(E->getType(), \".compoundliteral\");\n  const Expr *InitExpr = E->getInitializer();\n  LValue Result = MakeAddrLValue(DeclPtr, E->getType(), AlignmentSource::Decl);\n\n  EmitAnyExprToMem(InitExpr, DeclPtr, E->getType().getQualifiers(),\n                   /*Init*/ true);\n\n  // Block-scope compound literals are destroyed at the end of the enclosing\n  // scope in C.\n  if (!getLangOpts().CPlusPlus)\n    if (QualType::DestructionKind DtorKind = E->getType().isDestructedType())\n      pushLifetimeExtendedDestroy(getCleanupKind(DtorKind), DeclPtr,\n                                  E->getType(), getDestroyer(DtorKind),\n                                  DtorKind & EHCleanup);\n\n  return Result;\n}\n\nLValue CodeGenFunction::EmitInitListLValue(const InitListExpr *E) {\n  if (!E->isGLValue())\n    // Initializing an aggregate temporary in C++11: T{...}.\n    return EmitAggExprToLValue(E);\n\n  // An lvalue initializer list must be initializing a reference.\n  assert(E->isTransparent() && \"non-transparent glvalue init list\");\n  return EmitLValue(E->getInit(0));\n}\n\n/// Emit the operand of a glvalue conditional operator. This is either a glvalue\n/// or a (possibly-parenthesized) throw-expression. If this is a throw, no\n/// LValue is returned and the current block has been terminated.\nstatic Optional<LValue> EmitLValueOrThrowExpression(CodeGenFunction &CGF,\n                                                    const Expr *Operand) {\n  if (auto *ThrowExpr = dyn_cast<CXXThrowExpr>(Operand->IgnoreParens())) {\n    CGF.EmitCXXThrowExpr(ThrowExpr, /*KeepInsertionPoint*/false);\n    return None;\n  }\n\n  return CGF.EmitLValue(Operand);\n}\n\nLValue CodeGenFunction::\nEmitConditionalOperatorLValue(const AbstractConditionalOperator *expr) {\n  if (!expr->isGLValue()) {\n    // ?: here should be an aggregate.\n    assert(hasAggregateEvaluationKind(expr->getType()) &&\n           \"Unexpected conditional operator!\");\n    return EmitAggExprToLValue(expr);\n  }\n\n  OpaqueValueMapping binding(*this, expr);\n\n  const Expr *condExpr = expr->getCond();\n  bool CondExprBool;\n  if (ConstantFoldsToSimpleInteger(condExpr, CondExprBool)) {\n    const Expr *live = expr->getTrueExpr(), *dead = expr->getFalseExpr();\n    if (!CondExprBool) std::swap(live, dead);\n\n    if (!ContainsLabel(dead)) {\n      // If the true case is live, we need to track its region.\n      if (CondExprBool)\n        incrementProfileCounter(expr);\n      // If a throw expression we emit it and return an undefined lvalue\n      // because it can't be used.\n      if (auto *ThrowExpr = dyn_cast<CXXThrowExpr>(live->IgnoreParens())) {\n        EmitCXXThrowExpr(ThrowExpr);\n        llvm::Type *Ty =\n            llvm::PointerType::getUnqual(ConvertType(dead->getType()));\n        return MakeAddrLValue(\n            Address(llvm::UndefValue::get(Ty), CharUnits::One()),\n            dead->getType());\n      }\n      return EmitLValue(live);\n    }\n  }\n\n  llvm::BasicBlock *lhsBlock = createBasicBlock(\"cond.true\");\n  llvm::BasicBlock *rhsBlock = createBasicBlock(\"cond.false\");\n  llvm::BasicBlock *contBlock = createBasicBlock(\"cond.end\");\n\n  ConditionalEvaluation eval(*this);\n  EmitBranchOnBoolExpr(condExpr, lhsBlock, rhsBlock, getProfileCount(expr));\n\n  // Any temporaries created here are conditional.\n  EmitBlock(lhsBlock);\n  incrementProfileCounter(expr);\n  eval.begin(*this);\n  Optional<LValue> lhs =\n      EmitLValueOrThrowExpression(*this, expr->getTrueExpr());\n  eval.end(*this);\n\n  if (lhs && !lhs->isSimple())\n    return EmitUnsupportedLValue(expr, \"conditional operator\");\n\n  lhsBlock = Builder.GetInsertBlock();\n  if (lhs)\n    Builder.CreateBr(contBlock);\n\n  // Any temporaries created here are conditional.\n  EmitBlock(rhsBlock);\n  eval.begin(*this);\n  Optional<LValue> rhs =\n      EmitLValueOrThrowExpression(*this, expr->getFalseExpr());\n  eval.end(*this);\n  if (rhs && !rhs->isSimple())\n    return EmitUnsupportedLValue(expr, \"conditional operator\");\n  rhsBlock = Builder.GetInsertBlock();\n\n  EmitBlock(contBlock);\n\n  if (lhs && rhs) {\n    llvm::PHINode *phi =\n        Builder.CreatePHI(lhs->getPointer(*this)->getType(), 2, \"cond-lvalue\");\n    phi->addIncoming(lhs->getPointer(*this), lhsBlock);\n    phi->addIncoming(rhs->getPointer(*this), rhsBlock);\n    Address result(phi, std::min(lhs->getAlignment(), rhs->getAlignment()));\n    AlignmentSource alignSource =\n      std::max(lhs->getBaseInfo().getAlignmentSource(),\n               rhs->getBaseInfo().getAlignmentSource());\n    TBAAAccessInfo TBAAInfo = CGM.mergeTBAAInfoForConditionalOperator(\n        lhs->getTBAAInfo(), rhs->getTBAAInfo());\n    return MakeAddrLValue(result, expr->getType(), LValueBaseInfo(alignSource),\n                          TBAAInfo);\n  } else {\n    assert((lhs || rhs) &&\n           \"both operands of glvalue conditional are throw-expressions?\");\n    return lhs ? *lhs : *rhs;\n  }\n}\n\n/// EmitCastLValue - Casts are never lvalues unless that cast is to a reference\n/// type. If the cast is to a reference, we can have the usual lvalue result,\n/// otherwise if a cast is needed by the code generator in an lvalue context,\n/// then it must mean that we need the address of an aggregate in order to\n/// access one of its members.  This can happen for all the reasons that casts\n/// are permitted with aggregate result, including noop aggregate casts, and\n/// cast from scalar to union.\nLValue CodeGenFunction::EmitCastLValue(const CastExpr *E) {\n  switch (E->getCastKind()) {\n  case CK_ToVoid:\n  case CK_BitCast:\n  case CK_LValueToRValueBitCast:\n  case CK_ArrayToPointerDecay:\n  case CK_FunctionToPointerDecay:\n  case CK_NullToMemberPointer:\n  case CK_NullToPointer:\n  case CK_IntegralToPointer:\n  case CK_PointerToIntegral:\n  case CK_PointerToBoolean:\n  case CK_VectorSplat:\n  case CK_IntegralCast:\n  case CK_BooleanToSignedIntegral:\n  case CK_IntegralToBoolean:\n  case CK_IntegralToFloating:\n  case CK_FloatingToIntegral:\n  case CK_FloatingToBoolean:\n  case CK_FloatingCast:\n  case CK_FloatingRealToComplex:\n  case CK_FloatingComplexToReal:\n  case CK_FloatingComplexToBoolean:\n  case CK_FloatingComplexCast:\n  case CK_FloatingComplexToIntegralComplex:\n  case CK_IntegralRealToComplex:\n  case CK_IntegralComplexToReal:\n  case CK_IntegralComplexToBoolean:\n  case CK_IntegralComplexCast:\n  case CK_IntegralComplexToFloatingComplex:\n  case CK_DerivedToBaseMemberPointer:\n  case CK_BaseToDerivedMemberPointer:\n  case CK_MemberPointerToBoolean:\n  case CK_ReinterpretMemberPointer:\n  case CK_AnyPointerToBlockPointerCast:\n  case CK_ARCProduceObject:\n  case CK_ARCConsumeObject:\n  case CK_ARCReclaimReturnedObject:\n  case CK_ARCExtendBlockObject:\n  case CK_CopyAndAutoreleaseBlockObject:\n  case CK_IntToOCLSampler:\n  case CK_FloatingToFixedPoint:\n  case CK_FixedPointToFloating:\n  case CK_FixedPointCast:\n  case CK_FixedPointToBoolean:\n  case CK_FixedPointToIntegral:\n  case CK_IntegralToFixedPoint:\n    return EmitUnsupportedLValue(E, \"unexpected cast lvalue\");\n\n  case CK_Dependent:\n    llvm_unreachable(\"dependent cast kind in IR gen!\");\n\n  case CK_BuiltinFnToFnPtr:\n    llvm_unreachable(\"builtin functions are handled elsewhere\");\n\n  // These are never l-values; just use the aggregate emission code.\n  case CK_NonAtomicToAtomic:\n  case CK_AtomicToNonAtomic:\n    return EmitAggExprToLValue(E);\n\n  case CK_Dynamic: {\n    LValue LV = EmitLValue(E->getSubExpr());\n    Address V = LV.getAddress(*this);\n    const auto *DCE = cast<CXXDynamicCastExpr>(E);\n    return MakeNaturalAlignAddrLValue(EmitDynamicCast(V, DCE), E->getType());\n  }\n\n  case CK_ConstructorConversion:\n  case CK_UserDefinedConversion:\n  case CK_CPointerToObjCPointerCast:\n  case CK_BlockPointerToObjCPointerCast:\n  case CK_NoOp:\n  case CK_LValueToRValue:\n    return EmitLValue(E->getSubExpr());\n\n  case CK_UncheckedDerivedToBase:\n  case CK_DerivedToBase: {\n    const auto *DerivedClassTy =\n        E->getSubExpr()->getType()->castAs<RecordType>();\n    auto *DerivedClassDecl = cast<CXXRecordDecl>(DerivedClassTy->getDecl());\n\n    LValue LV = EmitLValue(E->getSubExpr());\n    Address This = LV.getAddress(*this);\n\n    // Perform the derived-to-base conversion\n    Address Base = GetAddressOfBaseClass(\n        This, DerivedClassDecl, E->path_begin(), E->path_end(),\n        /*NullCheckValue=*/false, E->getExprLoc());\n\n    // TODO: Support accesses to members of base classes in TBAA. For now, we\n    // conservatively pretend that the complete object is of the base class\n    // type.\n    return MakeAddrLValue(Base, E->getType(), LV.getBaseInfo(),\n                          CGM.getTBAAInfoForSubobject(LV, E->getType()));\n  }\n  case CK_ToUnion:\n    return EmitAggExprToLValue(E);\n  case CK_BaseToDerived: {\n    const auto *DerivedClassTy = E->getType()->castAs<RecordType>();\n    auto *DerivedClassDecl = cast<CXXRecordDecl>(DerivedClassTy->getDecl());\n\n    LValue LV = EmitLValue(E->getSubExpr());\n\n    // Perform the base-to-derived conversion\n    Address Derived = GetAddressOfDerivedClass(\n        LV.getAddress(*this), DerivedClassDecl, E->path_begin(), E->path_end(),\n        /*NullCheckValue=*/false);\n\n    // C++11 [expr.static.cast]p2: Behavior is undefined if a downcast is\n    // performed and the object is not of the derived type.\n    if (sanitizePerformTypeCheck())\n      EmitTypeCheck(TCK_DowncastReference, E->getExprLoc(),\n                    Derived.getPointer(), E->getType());\n\n    if (SanOpts.has(SanitizerKind::CFIDerivedCast))\n      EmitVTablePtrCheckForCast(E->getType(), Derived.getPointer(),\n                                /*MayBeNull=*/false, CFITCK_DerivedCast,\n                                E->getBeginLoc());\n\n    return MakeAddrLValue(Derived, E->getType(), LV.getBaseInfo(),\n                          CGM.getTBAAInfoForSubobject(LV, E->getType()));\n  }\n  case CK_LValueBitCast: {\n    // This must be a reinterpret_cast (or c-style equivalent).\n    const auto *CE = cast<ExplicitCastExpr>(E);\n\n    CGM.EmitExplicitCastExprType(CE, this);\n    LValue LV = EmitLValue(E->getSubExpr());\n    Address V = Builder.CreateBitCast(LV.getAddress(*this),\n                                      ConvertType(CE->getTypeAsWritten()));\n\n    if (SanOpts.has(SanitizerKind::CFIUnrelatedCast))\n      EmitVTablePtrCheckForCast(E->getType(), V.getPointer(),\n                                /*MayBeNull=*/false, CFITCK_UnrelatedCast,\n                                E->getBeginLoc());\n\n    return MakeAddrLValue(V, E->getType(), LV.getBaseInfo(),\n                          CGM.getTBAAInfoForSubobject(LV, E->getType()));\n  }\n  case CK_AddressSpaceConversion: {\n    LValue LV = EmitLValue(E->getSubExpr());\n    QualType DestTy = getContext().getPointerType(E->getType());\n    llvm::Value *V = getTargetHooks().performAddrSpaceCast(\n        *this, LV.getPointer(*this),\n        E->getSubExpr()->getType().getAddressSpace(),\n        E->getType().getAddressSpace(), ConvertType(DestTy));\n    return MakeAddrLValue(Address(V, LV.getAddress(*this).getAlignment()),\n                          E->getType(), LV.getBaseInfo(), LV.getTBAAInfo());\n  }\n  case CK_ObjCObjectLValueCast: {\n    LValue LV = EmitLValue(E->getSubExpr());\n    Address V = Builder.CreateElementBitCast(LV.getAddress(*this),\n                                             ConvertType(E->getType()));\n    return MakeAddrLValue(V, E->getType(), LV.getBaseInfo(),\n                          CGM.getTBAAInfoForSubobject(LV, E->getType()));\n  }\n  case CK_ZeroToOCLOpaqueType:\n    llvm_unreachable(\"NULL to OpenCL opaque type lvalue cast is not valid\");\n  }\n\n  llvm_unreachable(\"Unhandled lvalue cast kind?\");\n}\n\nLValue CodeGenFunction::EmitOpaqueValueLValue(const OpaqueValueExpr *e) {\n  assert(OpaqueValueMappingData::shouldBindAsLValue(e));\n  return getOrCreateOpaqueLValueMapping(e);\n}\n\nLValue\nCodeGenFunction::getOrCreateOpaqueLValueMapping(const OpaqueValueExpr *e) {\n  assert(OpaqueValueMapping::shouldBindAsLValue(e));\n\n  llvm::DenseMap<const OpaqueValueExpr*,LValue>::iterator\n      it = OpaqueLValues.find(e);\n\n  if (it != OpaqueLValues.end())\n    return it->second;\n\n  assert(e->isUnique() && \"LValue for a nonunique OVE hasn't been emitted\");\n  return EmitLValue(e->getSourceExpr());\n}\n\nRValue\nCodeGenFunction::getOrCreateOpaqueRValueMapping(const OpaqueValueExpr *e) {\n  assert(!OpaqueValueMapping::shouldBindAsLValue(e));\n\n  llvm::DenseMap<const OpaqueValueExpr*,RValue>::iterator\n      it = OpaqueRValues.find(e);\n\n  if (it != OpaqueRValues.end())\n    return it->second;\n\n  assert(e->isUnique() && \"RValue for a nonunique OVE hasn't been emitted\");\n  return EmitAnyExpr(e->getSourceExpr());\n}\n\nRValue CodeGenFunction::EmitRValueForField(LValue LV,\n                                           const FieldDecl *FD,\n                                           SourceLocation Loc) {\n  QualType FT = FD->getType();\n  LValue FieldLV = EmitLValueForField(LV, FD);\n  switch (getEvaluationKind(FT)) {\n  case TEK_Complex:\n    return RValue::getComplex(EmitLoadOfComplex(FieldLV, Loc));\n  case TEK_Aggregate:\n    return FieldLV.asAggregateRValue(*this);\n  case TEK_Scalar:\n    // This routine is used to load fields one-by-one to perform a copy, so\n    // don't load reference fields.\n    if (FD->getType()->isReferenceType())\n      return RValue::get(FieldLV.getPointer(*this));\n    // Call EmitLoadOfScalar except when the lvalue is a bitfield to emit a\n    // primitive load.\n    if (FieldLV.isBitField())\n      return EmitLoadOfLValue(FieldLV, Loc);\n    return RValue::get(EmitLoadOfScalar(FieldLV, Loc));\n  }\n  llvm_unreachable(\"bad evaluation kind\");\n}\n\n//===--------------------------------------------------------------------===//\n//                             Expression Emission\n//===--------------------------------------------------------------------===//\n\nRValue CodeGenFunction::EmitCallExpr(const CallExpr *E,\n                                     ReturnValueSlot ReturnValue) {\n  // Builtins never have block type.\n  if (E->getCallee()->getType()->isBlockPointerType())\n    return EmitBlockCallExpr(E, ReturnValue);\n\n  if (const auto *CE = dyn_cast<CXXMemberCallExpr>(E))\n    return EmitCXXMemberCallExpr(CE, ReturnValue);\n\n  if (const auto *CE = dyn_cast<CUDAKernelCallExpr>(E))\n    return EmitCUDAKernelCallExpr(CE, ReturnValue);\n\n  if (const auto *CE = dyn_cast<CXXOperatorCallExpr>(E))\n    if (const CXXMethodDecl *MD =\n          dyn_cast_or_null<CXXMethodDecl>(CE->getCalleeDecl()))\n      return EmitCXXOperatorMemberCallExpr(CE, MD, ReturnValue);\n\n  CGCallee callee = EmitCallee(E->getCallee());\n\n  if (callee.isBuiltin()) {\n    return EmitBuiltinExpr(callee.getBuiltinDecl(), callee.getBuiltinID(),\n                           E, ReturnValue);\n  }\n\n  if (callee.isPseudoDestructor()) {\n    return EmitCXXPseudoDestructorExpr(callee.getPseudoDestructorExpr());\n  }\n\n  return EmitCall(E->getCallee()->getType(), callee, E, ReturnValue);\n}\n\n/// Emit a CallExpr without considering whether it might be a subclass.\nRValue CodeGenFunction::EmitSimpleCallExpr(const CallExpr *E,\n                                           ReturnValueSlot ReturnValue) {\n  CGCallee Callee = EmitCallee(E->getCallee());\n  return EmitCall(E->getCallee()->getType(), Callee, E, ReturnValue);\n}\n\nstatic CGCallee EmitDirectCallee(CodeGenFunction &CGF, GlobalDecl GD) {\n  const FunctionDecl *FD = cast<FunctionDecl>(GD.getDecl());\n\n  if (auto builtinID = FD->getBuiltinID()) {\n    // Replaceable builtin provide their own implementation of a builtin. Unless\n    // we are in the builtin implementation itself, don't call the actual\n    // builtin. If we are in the builtin implementation, avoid trivial infinite\n    // recursion.\n    if (!FD->isInlineBuiltinDeclaration() ||\n        CGF.CurFn->getName() == FD->getName())\n      return CGCallee::forBuiltin(builtinID, FD);\n  }\n\n  llvm::Constant *CalleePtr = EmitFunctionDeclPointer(CGF.CGM, GD);\n  if (CGF.CGM.getLangOpts().CUDA && !CGF.CGM.getLangOpts().CUDAIsDevice &&\n      FD->hasAttr<CUDAGlobalAttr>())\n    CalleePtr = CGF.CGM.getCUDARuntime().getKernelStub(\n        cast<llvm::GlobalValue>(CalleePtr->stripPointerCasts()));\n  return CGCallee::forDirect(CalleePtr, GD);\n}\n\nCGCallee CodeGenFunction::EmitCallee(const Expr *E) {\n  E = E->IgnoreParens();\n\n  // Look through function-to-pointer decay.\n  if (auto ICE = dyn_cast<ImplicitCastExpr>(E)) {\n    if (ICE->getCastKind() == CK_FunctionToPointerDecay ||\n        ICE->getCastKind() == CK_BuiltinFnToFnPtr) {\n      return EmitCallee(ICE->getSubExpr());\n    }\n\n  // Resolve direct calls.\n  } else if (auto DRE = dyn_cast<DeclRefExpr>(E)) {\n    if (auto FD = dyn_cast<FunctionDecl>(DRE->getDecl())) {\n      return EmitDirectCallee(*this, FD);\n    }\n  } else if (auto ME = dyn_cast<MemberExpr>(E)) {\n    if (auto FD = dyn_cast<FunctionDecl>(ME->getMemberDecl())) {\n      EmitIgnoredExpr(ME->getBase());\n      return EmitDirectCallee(*this, FD);\n    }\n\n  // Look through template substitutions.\n  } else if (auto NTTP = dyn_cast<SubstNonTypeTemplateParmExpr>(E)) {\n    return EmitCallee(NTTP->getReplacement());\n\n  // Treat pseudo-destructor calls differently.\n  } else if (auto PDE = dyn_cast<CXXPseudoDestructorExpr>(E)) {\n    return CGCallee::forPseudoDestructor(PDE);\n  }\n\n  // Otherwise, we have an indirect reference.\n  llvm::Value *calleePtr;\n  QualType functionType;\n  if (auto ptrType = E->getType()->getAs<PointerType>()) {\n    calleePtr = EmitScalarExpr(E);\n    functionType = ptrType->getPointeeType();\n  } else {\n    functionType = E->getType();\n    calleePtr = EmitLValue(E).getPointer(*this);\n  }\n  assert(functionType->isFunctionType());\n\n  GlobalDecl GD;\n  if (const auto *VD =\n          dyn_cast_or_null<VarDecl>(E->getReferencedDeclOfCallee()))\n    GD = GlobalDecl(VD);\n\n  CGCalleeInfo calleeInfo(functionType->getAs<FunctionProtoType>(), GD);\n  CGCallee callee(calleeInfo, calleePtr);\n  return callee;\n}\n\nLValue CodeGenFunction::EmitBinaryOperatorLValue(const BinaryOperator *E) {\n  // Comma expressions just emit their LHS then their RHS as an l-value.\n  if (E->getOpcode() == BO_Comma) {\n    EmitIgnoredExpr(E->getLHS());\n    EnsureInsertPoint();\n    return EmitLValue(E->getRHS());\n  }\n\n  if (E->getOpcode() == BO_PtrMemD ||\n      E->getOpcode() == BO_PtrMemI)\n    return EmitPointerToDataMemberBinaryExpr(E);\n\n  assert(E->getOpcode() == BO_Assign && \"unexpected binary l-value\");\n\n  // Note that in all of these cases, __block variables need the RHS\n  // evaluated first just in case the variable gets moved by the RHS.\n\n  switch (getEvaluationKind(E->getType())) {\n  case TEK_Scalar: {\n    switch (E->getLHS()->getType().getObjCLifetime()) {\n    case Qualifiers::OCL_Strong:\n      return EmitARCStoreStrong(E, /*ignored*/ false).first;\n\n    case Qualifiers::OCL_Autoreleasing:\n      return EmitARCStoreAutoreleasing(E).first;\n\n    // No reason to do any of these differently.\n    case Qualifiers::OCL_None:\n    case Qualifiers::OCL_ExplicitNone:\n    case Qualifiers::OCL_Weak:\n      break;\n    }\n\n    RValue RV = EmitAnyExpr(E->getRHS());\n    LValue LV = EmitCheckedLValue(E->getLHS(), TCK_Store);\n    if (RV.isScalar())\n      EmitNullabilityCheck(LV, RV.getScalarVal(), E->getExprLoc());\n    EmitStoreThroughLValue(RV, LV);\n    if (getLangOpts().OpenMP)\n      CGM.getOpenMPRuntime().checkAndEmitLastprivateConditional(*this,\n                                                                E->getLHS());\n    return LV;\n  }\n\n  case TEK_Complex:\n    return EmitComplexAssignmentLValue(E);\n\n  case TEK_Aggregate:\n    return EmitAggExprToLValue(E);\n  }\n  llvm_unreachable(\"bad evaluation kind\");\n}\n\nLValue CodeGenFunction::EmitCallExprLValue(const CallExpr *E) {\n  RValue RV = EmitCallExpr(E);\n\n  if (!RV.isScalar())\n    return MakeAddrLValue(RV.getAggregateAddress(), E->getType(),\n                          AlignmentSource::Decl);\n\n  assert(E->getCallReturnType(getContext())->isReferenceType() &&\n         \"Can't have a scalar return unless the return type is a \"\n         \"reference type!\");\n\n  return MakeNaturalAlignPointeeAddrLValue(RV.getScalarVal(), E->getType());\n}\n\nLValue CodeGenFunction::EmitVAArgExprLValue(const VAArgExpr *E) {\n  // FIXME: This shouldn't require another copy.\n  return EmitAggExprToLValue(E);\n}\n\nLValue CodeGenFunction::EmitCXXConstructLValue(const CXXConstructExpr *E) {\n  assert(E->getType()->getAsCXXRecordDecl()->hasTrivialDestructor()\n         && \"binding l-value to type which needs a temporary\");\n  AggValueSlot Slot = CreateAggTemp(E->getType());\n  EmitCXXConstructExpr(E, Slot);\n  return MakeAddrLValue(Slot.getAddress(), E->getType(), AlignmentSource::Decl);\n}\n\nLValue\nCodeGenFunction::EmitCXXTypeidLValue(const CXXTypeidExpr *E) {\n  return MakeNaturalAlignAddrLValue(EmitCXXTypeidExpr(E), E->getType());\n}\n\nAddress CodeGenFunction::EmitCXXUuidofExpr(const CXXUuidofExpr *E) {\n  return Builder.CreateElementBitCast(CGM.GetAddrOfMSGuidDecl(E->getGuidDecl()),\n                                      ConvertType(E->getType()));\n}\n\nLValue CodeGenFunction::EmitCXXUuidofLValue(const CXXUuidofExpr *E) {\n  return MakeAddrLValue(EmitCXXUuidofExpr(E), E->getType(),\n                        AlignmentSource::Decl);\n}\n\nLValue\nCodeGenFunction::EmitCXXBindTemporaryLValue(const CXXBindTemporaryExpr *E) {\n  AggValueSlot Slot = CreateAggTemp(E->getType(), \"temp.lvalue\");\n  Slot.setExternallyDestructed();\n  EmitAggExpr(E->getSubExpr(), Slot);\n  EmitCXXTemporary(E->getTemporary(), E->getType(), Slot.getAddress());\n  return MakeAddrLValue(Slot.getAddress(), E->getType(), AlignmentSource::Decl);\n}\n\nLValue CodeGenFunction::EmitObjCMessageExprLValue(const ObjCMessageExpr *E) {\n  RValue RV = EmitObjCMessageExpr(E);\n\n  if (!RV.isScalar())\n    return MakeAddrLValue(RV.getAggregateAddress(), E->getType(),\n                          AlignmentSource::Decl);\n\n  assert(E->getMethodDecl()->getReturnType()->isReferenceType() &&\n         \"Can't have a scalar return unless the return type is a \"\n         \"reference type!\");\n\n  return MakeNaturalAlignPointeeAddrLValue(RV.getScalarVal(), E->getType());\n}\n\nLValue CodeGenFunction::EmitObjCSelectorLValue(const ObjCSelectorExpr *E) {\n  Address V =\n    CGM.getObjCRuntime().GetAddrOfSelector(*this, E->getSelector());\n  return MakeAddrLValue(V, E->getType(), AlignmentSource::Decl);\n}\n\nllvm::Value *CodeGenFunction::EmitIvarOffset(const ObjCInterfaceDecl *Interface,\n                                             const ObjCIvarDecl *Ivar) {\n  return CGM.getObjCRuntime().EmitIvarOffset(*this, Interface, Ivar);\n}\n\nLValue CodeGenFunction::EmitLValueForIvar(QualType ObjectTy,\n                                          llvm::Value *BaseValue,\n                                          const ObjCIvarDecl *Ivar,\n                                          unsigned CVRQualifiers) {\n  return CGM.getObjCRuntime().EmitObjCValueForIvar(*this, ObjectTy, BaseValue,\n                                                   Ivar, CVRQualifiers);\n}\n\nLValue CodeGenFunction::EmitObjCIvarRefLValue(const ObjCIvarRefExpr *E) {\n  // FIXME: A lot of the code below could be shared with EmitMemberExpr.\n  llvm::Value *BaseValue = nullptr;\n  const Expr *BaseExpr = E->getBase();\n  Qualifiers BaseQuals;\n  QualType ObjectTy;\n  if (E->isArrow()) {\n    BaseValue = EmitScalarExpr(BaseExpr);\n    ObjectTy = BaseExpr->getType()->getPointeeType();\n    BaseQuals = ObjectTy.getQualifiers();\n  } else {\n    LValue BaseLV = EmitLValue(BaseExpr);\n    BaseValue = BaseLV.getPointer(*this);\n    ObjectTy = BaseExpr->getType();\n    BaseQuals = ObjectTy.getQualifiers();\n  }\n\n  LValue LV =\n    EmitLValueForIvar(ObjectTy, BaseValue, E->getDecl(),\n                      BaseQuals.getCVRQualifiers());\n  setObjCGCLValueClass(getContext(), E, LV);\n  return LV;\n}\n\nLValue CodeGenFunction::EmitStmtExprLValue(const StmtExpr *E) {\n  // Can only get l-value for message expression returning aggregate type\n  RValue RV = EmitAnyExprToTemp(E);\n  return MakeAddrLValue(RV.getAggregateAddress(), E->getType(),\n                        AlignmentSource::Decl);\n}\n\nRValue CodeGenFunction::EmitCall(QualType CalleeType, const CGCallee &OrigCallee,\n                                 const CallExpr *E, ReturnValueSlot ReturnValue,\n                                 llvm::Value *Chain) {\n  // Get the actual function type. The callee type will always be a pointer to\n  // function type or a block pointer type.\n  assert(CalleeType->isFunctionPointerType() &&\n         \"Call must have function pointer type!\");\n\n  const Decl *TargetDecl =\n      OrigCallee.getAbstractInfo().getCalleeDecl().getDecl();\n\n  CalleeType = getContext().getCanonicalType(CalleeType);\n\n  auto PointeeType = cast<PointerType>(CalleeType)->getPointeeType();\n\n  CGCallee Callee = OrigCallee;\n\n  if (getLangOpts().CPlusPlus && SanOpts.has(SanitizerKind::Function) &&\n      (!TargetDecl || !isa<FunctionDecl>(TargetDecl))) {\n    if (llvm::Constant *PrefixSig =\n            CGM.getTargetCodeGenInfo().getUBSanFunctionSignature(CGM)) {\n      SanitizerScope SanScope(this);\n      // Remove any (C++17) exception specifications, to allow calling e.g. a\n      // noexcept function through a non-noexcept pointer.\n      auto ProtoTy =\n        getContext().getFunctionTypeWithExceptionSpec(PointeeType, EST_None);\n      llvm::Constant *FTRTTIConst =\n          CGM.GetAddrOfRTTIDescriptor(ProtoTy, /*ForEH=*/true);\n      llvm::Type *PrefixSigType = PrefixSig->getType();\n      llvm::StructType *PrefixStructTy = llvm::StructType::get(\n          CGM.getLLVMContext(), {PrefixSigType, Int32Ty}, /*isPacked=*/true);\n\n      llvm::Value *CalleePtr = Callee.getFunctionPointer();\n\n      llvm::Value *CalleePrefixStruct = Builder.CreateBitCast(\n          CalleePtr, llvm::PointerType::getUnqual(PrefixStructTy));\n      llvm::Value *CalleeSigPtr =\n          Builder.CreateConstGEP2_32(PrefixStructTy, CalleePrefixStruct, 0, 0);\n      llvm::Value *CalleeSig =\n          Builder.CreateAlignedLoad(PrefixSigType, CalleeSigPtr, getIntAlign());\n      llvm::Value *CalleeSigMatch = Builder.CreateICmpEQ(CalleeSig, PrefixSig);\n\n      llvm::BasicBlock *Cont = createBasicBlock(\"cont\");\n      llvm::BasicBlock *TypeCheck = createBasicBlock(\"typecheck\");\n      Builder.CreateCondBr(CalleeSigMatch, TypeCheck, Cont);\n\n      EmitBlock(TypeCheck);\n      llvm::Value *CalleeRTTIPtr =\n          Builder.CreateConstGEP2_32(PrefixStructTy, CalleePrefixStruct, 0, 1);\n      llvm::Value *CalleeRTTIEncoded =\n          Builder.CreateAlignedLoad(Int32Ty, CalleeRTTIPtr, getPointerAlign());\n      llvm::Value *CalleeRTTI =\n          DecodeAddrUsedInPrologue(CalleePtr, CalleeRTTIEncoded);\n      llvm::Value *CalleeRTTIMatch =\n          Builder.CreateICmpEQ(CalleeRTTI, FTRTTIConst);\n      llvm::Constant *StaticData[] = {EmitCheckSourceLocation(E->getBeginLoc()),\n                                      EmitCheckTypeDescriptor(CalleeType)};\n      EmitCheck(std::make_pair(CalleeRTTIMatch, SanitizerKind::Function),\n                SanitizerHandler::FunctionTypeMismatch, StaticData,\n                {CalleePtr, CalleeRTTI, FTRTTIConst});\n\n      Builder.CreateBr(Cont);\n      EmitBlock(Cont);\n    }\n  }\n\n  const auto *FnType = cast<FunctionType>(PointeeType);\n\n  // If we are checking indirect calls and this call is indirect, check that the\n  // function pointer is a member of the bit set for the function type.\n  if (SanOpts.has(SanitizerKind::CFIICall) &&\n      (!TargetDecl || !isa<FunctionDecl>(TargetDecl))) {\n    SanitizerScope SanScope(this);\n    EmitSanitizerStatReport(llvm::SanStat_CFI_ICall);\n\n    llvm::Metadata *MD;\n    if (CGM.getCodeGenOpts().SanitizeCfiICallGeneralizePointers)\n      MD = CGM.CreateMetadataIdentifierGeneralized(QualType(FnType, 0));\n    else\n      MD = CGM.CreateMetadataIdentifierForType(QualType(FnType, 0));\n\n    llvm::Value *TypeId = llvm::MetadataAsValue::get(getLLVMContext(), MD);\n\n    llvm::Value *CalleePtr = Callee.getFunctionPointer();\n    llvm::Value *CastedCallee = Builder.CreateBitCast(CalleePtr, Int8PtrTy);\n    llvm::Value *TypeTest = Builder.CreateCall(\n        CGM.getIntrinsic(llvm::Intrinsic::type_test), {CastedCallee, TypeId});\n\n    auto CrossDsoTypeId = CGM.CreateCrossDsoCfiTypeId(MD);\n    llvm::Constant *StaticData[] = {\n        llvm::ConstantInt::get(Int8Ty, CFITCK_ICall),\n        EmitCheckSourceLocation(E->getBeginLoc()),\n        EmitCheckTypeDescriptor(QualType(FnType, 0)),\n    };\n    if (CGM.getCodeGenOpts().SanitizeCfiCrossDso && CrossDsoTypeId) {\n      EmitCfiSlowPathCheck(SanitizerKind::CFIICall, TypeTest, CrossDsoTypeId,\n                           CastedCallee, StaticData);\n    } else {\n      EmitCheck(std::make_pair(TypeTest, SanitizerKind::CFIICall),\n                SanitizerHandler::CFICheckFail, StaticData,\n                {CastedCallee, llvm::UndefValue::get(IntPtrTy)});\n    }\n  }\n\n  CallArgList Args;\n  if (Chain)\n    Args.add(RValue::get(Builder.CreateBitCast(Chain, CGM.VoidPtrTy)),\n             CGM.getContext().VoidPtrTy);\n\n  // C++17 requires that we evaluate arguments to a call using assignment syntax\n  // right-to-left, and that we evaluate arguments to certain other operators\n  // left-to-right. Note that we allow this to override the order dictated by\n  // the calling convention on the MS ABI, which means that parameter\n  // destruction order is not necessarily reverse construction order.\n  // FIXME: Revisit this based on C++ committee response to unimplementability.\n  EvaluationOrder Order = EvaluationOrder::Default;\n  if (auto *OCE = dyn_cast<CXXOperatorCallExpr>(E)) {\n    if (OCE->isAssignmentOp())\n      Order = EvaluationOrder::ForceRightToLeft;\n    else {\n      switch (OCE->getOperator()) {\n      case OO_LessLess:\n      case OO_GreaterGreater:\n      case OO_AmpAmp:\n      case OO_PipePipe:\n      case OO_Comma:\n      case OO_ArrowStar:\n        Order = EvaluationOrder::ForceLeftToRight;\n        break;\n      default:\n        break;\n      }\n    }\n  }\n\n  EmitCallArgs(Args, dyn_cast<FunctionProtoType>(FnType), E->arguments(),\n               E->getDirectCallee(), /*ParamsToSkip*/ 0, Order);\n\n  const CGFunctionInfo &FnInfo = CGM.getTypes().arrangeFreeFunctionCall(\n      Args, FnType, /*ChainCall=*/Chain);\n\n  // C99 6.5.2.2p6:\n  //   If the expression that denotes the called function has a type\n  //   that does not include a prototype, [the default argument\n  //   promotions are performed]. If the number of arguments does not\n  //   equal the number of parameters, the behavior is undefined. If\n  //   the function is defined with a type that includes a prototype,\n  //   and either the prototype ends with an ellipsis (, ...) or the\n  //   types of the arguments after promotion are not compatible with\n  //   the types of the parameters, the behavior is undefined. If the\n  //   function is defined with a type that does not include a\n  //   prototype, and the types of the arguments after promotion are\n  //   not compatible with those of the parameters after promotion,\n  //   the behavior is undefined [except in some trivial cases].\n  // That is, in the general case, we should assume that a call\n  // through an unprototyped function type works like a *non-variadic*\n  // call.  The way we make this work is to cast to the exact type\n  // of the promoted arguments.\n  //\n  // Chain calls use this same code path to add the invisible chain parameter\n  // to the function type.\n  if (isa<FunctionNoProtoType>(FnType) || Chain) {\n    llvm::Type *CalleeTy = getTypes().GetFunctionType(FnInfo);\n    int AS = Callee.getFunctionPointer()->getType()->getPointerAddressSpace();\n    CalleeTy = CalleeTy->getPointerTo(AS);\n\n    llvm::Value *CalleePtr = Callee.getFunctionPointer();\n    CalleePtr = Builder.CreateBitCast(CalleePtr, CalleeTy, \"callee.knr.cast\");\n    Callee.setFunctionPointer(CalleePtr);\n  }\n\n  // HIP function pointer contains kernel handle when it is used in triple\n  // chevron. The kernel stub needs to be loaded from kernel handle and used\n  // as callee.\n  if (CGM.getLangOpts().HIP && !CGM.getLangOpts().CUDAIsDevice &&\n      isa<CUDAKernelCallExpr>(E) &&\n      (!TargetDecl || !isa<FunctionDecl>(TargetDecl))) {\n    llvm::Value *Handle = Callee.getFunctionPointer();\n    auto *Cast =\n        Builder.CreateBitCast(Handle, Handle->getType()->getPointerTo());\n    auto *Stub = Builder.CreateLoad(Address(Cast, CGM.getPointerAlign()));\n    Callee.setFunctionPointer(Stub);\n  }\n  llvm::CallBase *CallOrInvoke = nullptr;\n  RValue Call = EmitCall(FnInfo, Callee, ReturnValue, Args, &CallOrInvoke,\n                         E->getExprLoc());\n\n  // Generate function declaration DISuprogram in order to be used\n  // in debug info about call sites.\n  if (CGDebugInfo *DI = getDebugInfo()) {\n    if (auto *CalleeDecl = dyn_cast_or_null<FunctionDecl>(TargetDecl))\n      DI->EmitFuncDeclForCallSite(CallOrInvoke, QualType(FnType, 0),\n                                  CalleeDecl);\n  }\n\n  return Call;\n}\n\nLValue CodeGenFunction::\nEmitPointerToDataMemberBinaryExpr(const BinaryOperator *E) {\n  Address BaseAddr = Address::invalid();\n  if (E->getOpcode() == BO_PtrMemI) {\n    BaseAddr = EmitPointerWithAlignment(E->getLHS());\n  } else {\n    BaseAddr = EmitLValue(E->getLHS()).getAddress(*this);\n  }\n\n  llvm::Value *OffsetV = EmitScalarExpr(E->getRHS());\n  const auto *MPT = E->getRHS()->getType()->castAs<MemberPointerType>();\n\n  LValueBaseInfo BaseInfo;\n  TBAAAccessInfo TBAAInfo;\n  Address MemberAddr =\n    EmitCXXMemberDataPointerAddress(E, BaseAddr, OffsetV, MPT, &BaseInfo,\n                                    &TBAAInfo);\n\n  return MakeAddrLValue(MemberAddr, MPT->getPointeeType(), BaseInfo, TBAAInfo);\n}\n\n/// Given the address of a temporary variable, produce an r-value of\n/// its type.\nRValue CodeGenFunction::convertTempToRValue(Address addr,\n                                            QualType type,\n                                            SourceLocation loc) {\n  LValue lvalue = MakeAddrLValue(addr, type, AlignmentSource::Decl);\n  switch (getEvaluationKind(type)) {\n  case TEK_Complex:\n    return RValue::getComplex(EmitLoadOfComplex(lvalue, loc));\n  case TEK_Aggregate:\n    return lvalue.asAggregateRValue(*this);\n  case TEK_Scalar:\n    return RValue::get(EmitLoadOfScalar(lvalue, loc));\n  }\n  llvm_unreachable(\"bad evaluation kind\");\n}\n\nvoid CodeGenFunction::SetFPAccuracy(llvm::Value *Val, float Accuracy) {\n  assert(Val->getType()->isFPOrFPVectorTy());\n  if (Accuracy == 0.0 || !isa<llvm::Instruction>(Val))\n    return;\n\n  llvm::MDBuilder MDHelper(getLLVMContext());\n  llvm::MDNode *Node = MDHelper.createFPMath(Accuracy);\n\n  cast<llvm::Instruction>(Val)->setMetadata(llvm::LLVMContext::MD_fpmath, Node);\n}\n\nnamespace {\n  struct LValueOrRValue {\n    LValue LV;\n    RValue RV;\n  };\n}\n\nstatic LValueOrRValue emitPseudoObjectExpr(CodeGenFunction &CGF,\n                                           const PseudoObjectExpr *E,\n                                           bool forLValue,\n                                           AggValueSlot slot) {\n  SmallVector<CodeGenFunction::OpaqueValueMappingData, 4> opaques;\n\n  // Find the result expression, if any.\n  const Expr *resultExpr = E->getResultExpr();\n  LValueOrRValue result;\n\n  for (PseudoObjectExpr::const_semantics_iterator\n         i = E->semantics_begin(), e = E->semantics_end(); i != e; ++i) {\n    const Expr *semantic = *i;\n\n    // If this semantic expression is an opaque value, bind it\n    // to the result of its source expression.\n    if (const auto *ov = dyn_cast<OpaqueValueExpr>(semantic)) {\n      // Skip unique OVEs.\n      if (ov->isUnique()) {\n        assert(ov != resultExpr &&\n               \"A unique OVE cannot be used as the result expression\");\n        continue;\n      }\n\n      // If this is the result expression, we may need to evaluate\n      // directly into the slot.\n      typedef CodeGenFunction::OpaqueValueMappingData OVMA;\n      OVMA opaqueData;\n      if (ov == resultExpr && ov->isRValue() && !forLValue &&\n          CodeGenFunction::hasAggregateEvaluationKind(ov->getType())) {\n        CGF.EmitAggExpr(ov->getSourceExpr(), slot);\n        LValue LV = CGF.MakeAddrLValue(slot.getAddress(), ov->getType(),\n                                       AlignmentSource::Decl);\n        opaqueData = OVMA::bind(CGF, ov, LV);\n        result.RV = slot.asRValue();\n\n      // Otherwise, emit as normal.\n      } else {\n        opaqueData = OVMA::bind(CGF, ov, ov->getSourceExpr());\n\n        // If this is the result, also evaluate the result now.\n        if (ov == resultExpr) {\n          if (forLValue)\n            result.LV = CGF.EmitLValue(ov);\n          else\n            result.RV = CGF.EmitAnyExpr(ov, slot);\n        }\n      }\n\n      opaques.push_back(opaqueData);\n\n    // Otherwise, if the expression is the result, evaluate it\n    // and remember the result.\n    } else if (semantic == resultExpr) {\n      if (forLValue)\n        result.LV = CGF.EmitLValue(semantic);\n      else\n        result.RV = CGF.EmitAnyExpr(semantic, slot);\n\n    // Otherwise, evaluate the expression in an ignored context.\n    } else {\n      CGF.EmitIgnoredExpr(semantic);\n    }\n  }\n\n  // Unbind all the opaques now.\n  for (unsigned i = 0, e = opaques.size(); i != e; ++i)\n    opaques[i].unbind(CGF);\n\n  return result;\n}\n\nRValue CodeGenFunction::EmitPseudoObjectRValue(const PseudoObjectExpr *E,\n                                               AggValueSlot slot) {\n  return emitPseudoObjectExpr(*this, E, false, slot).RV;\n}\n\nLValue CodeGenFunction::EmitPseudoObjectLValue(const PseudoObjectExpr *E) {\n  return emitPseudoObjectExpr(*this, E, true, AggValueSlot::ignored()).LV;\n}\n"}, "53": {"id": 53, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "content": "//===-- CGValue.h - LLVM CodeGen wrappers for llvm::Value* ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// These classes implement wrappers around llvm::Value in order to\n// fully represent the range of values for C L- and R- values.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CGVALUE_H\n#define LLVM_CLANG_LIB_CODEGEN_CGVALUE_H\n\n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Type.h\"\n#include \"llvm/IR/Value.h\"\n#include \"llvm/IR/Type.h\"\n#include \"Address.h\"\n#include \"CodeGenTBAA.h\"\n\nnamespace llvm {\n  class Constant;\n  class MDNode;\n}\n\nnamespace clang {\nnamespace CodeGen {\n  class AggValueSlot;\n  class CodeGenFunction;\n  struct CGBitFieldInfo;\n\n/// RValue - This trivial value class is used to represent the result of an\n/// expression that is evaluated.  It can be one of three things: either a\n/// simple LLVM SSA value, a pair of SSA values for complex numbers, or the\n/// address of an aggregate value in memory.\nclass RValue {\n  enum Flavor { Scalar, Complex, Aggregate };\n\n  // The shift to make to an aggregate's alignment to make it look\n  // like a pointer.\n  enum { AggAlignShift = 4 };\n\n  // Stores first value and flavor.\n  llvm::PointerIntPair<llvm::Value *, 2, Flavor> V1;\n  // Stores second value and volatility.\n  llvm::PointerIntPair<llvm::Value *, 1, bool> V2;\n\npublic:\n  bool isScalar() const { return V1.getInt() == Scalar; }\n  bool isComplex() const { return V1.getInt() == Complex; }\n  bool isAggregate() const { return V1.getInt() == Aggregate; }\n\n  bool isVolatileQualified() const { return V2.getInt(); }\n\n  /// getScalarVal() - Return the Value* of this scalar value.\n  llvm::Value *getScalarVal() const {\n    assert(isScalar() && \"Not a scalar!\");\n    return V1.getPointer();\n  }\n\n  /// getComplexVal - Return the real/imag components of this complex value.\n  ///\n  std::pair<llvm::Value *, llvm::Value *> getComplexVal() const {\n    return std::make_pair(V1.getPointer(), V2.getPointer());\n  }\n\n  /// getAggregateAddr() - Return the Value* of the address of the aggregate.\n  Address getAggregateAddress() const {\n    assert(isAggregate() && \"Not an aggregate!\");\n    auto align = reinterpret_cast<uintptr_t>(V2.getPointer()) >> AggAlignShift;\n    return Address(V1.getPointer(), CharUnits::fromQuantity(align));\n  }\n  llvm::Value *getAggregatePointer() const {\n    assert(isAggregate() && \"Not an aggregate!\");\n    return V1.getPointer();\n  }\n\n  static RValue getIgnored() {\n    // FIXME: should we make this a more explicit state?\n    return get(nullptr);\n  }\n\n  static RValue get(llvm::Value *V) {\n    RValue ER;\n    ER.V1.setPointer(V);\n    ER.V1.setInt(Scalar);\n    ER.V2.setInt(false);\n    return ER;\n  }\n  static RValue getComplex(llvm::Value *V1, llvm::Value *V2) {\n    RValue ER;\n    ER.V1.setPointer(V1);\n    ER.V2.setPointer(V2);\n    ER.V1.setInt(Complex);\n    ER.V2.setInt(false);\n    return ER;\n  }\n  static RValue getComplex(const std::pair<llvm::Value *, llvm::Value *> &C) {\n    return getComplex(C.first, C.second);\n  }\n  // FIXME: Aggregate rvalues need to retain information about whether they are\n  // volatile or not.  Remove default to find all places that probably get this\n  // wrong.\n  static RValue getAggregate(Address addr, bool isVolatile = false) {\n    RValue ER;\n    ER.V1.setPointer(addr.getPointer());\n    ER.V1.setInt(Aggregate);\n\n    auto align = static_cast<uintptr_t>(addr.getAlignment().getQuantity());\n    ER.V2.setPointer(reinterpret_cast<llvm::Value*>(align << AggAlignShift));\n    ER.V2.setInt(isVolatile);\n    return ER;\n  }\n};\n\n/// Does an ARC strong l-value have precise lifetime?\nenum ARCPreciseLifetime_t {\n  ARCImpreciseLifetime, ARCPreciseLifetime\n};\n\n/// The source of the alignment of an l-value; an expression of\n/// confidence in the alignment actually matching the estimate.\nenum class AlignmentSource {\n  /// The l-value was an access to a declared entity or something\n  /// equivalently strong, like the address of an array allocated by a\n  /// language runtime.\n  Decl,\n\n  /// The l-value was considered opaque, so the alignment was\n  /// determined from a type, but that type was an explicitly-aligned\n  /// typedef.\n  AttributedType,\n\n  /// The l-value was considered opaque, so the alignment was\n  /// determined from a type.\n  Type\n};\n\n/// Given that the base address has the given alignment source, what's\n/// our confidence in the alignment of the field?\nstatic inline AlignmentSource getFieldAlignmentSource(AlignmentSource Source) {\n  // For now, we don't distinguish fields of opaque pointers from\n  // top-level declarations, but maybe we should.\n  return AlignmentSource::Decl;\n}\n\nclass LValueBaseInfo {\n  AlignmentSource AlignSource;\n\npublic:\n  explicit LValueBaseInfo(AlignmentSource Source = AlignmentSource::Type)\n    : AlignSource(Source) {}\n  AlignmentSource getAlignmentSource() const { return AlignSource; }\n  void setAlignmentSource(AlignmentSource Source) { AlignSource = Source; }\n\n  void mergeForCast(const LValueBaseInfo &Info) {\n    setAlignmentSource(Info.getAlignmentSource());\n  }\n};\n\n/// LValue - This represents an lvalue references.  Because C/C++ allow\n/// bitfields, this is not a simple LLVM pointer, it may be a pointer plus a\n/// bitrange.\nclass LValue {\n  enum {\n    Simple,       // This is a normal l-value, use getAddress().\n    VectorElt,    // This is a vector element l-value (V[i]), use getVector*\n    BitField,     // This is a bitfield l-value, use getBitfield*.\n    ExtVectorElt, // This is an extended vector subset, use getExtVectorComp\n    GlobalReg,    // This is a register l-value, use getGlobalReg()\n    MatrixElt     // This is a matrix element, use getVector*\n  } LVType;\n\n  llvm::Value *V;\n\n  union {\n    // Index into a vector subscript: V[i]\n    llvm::Value *VectorIdx;\n\n    // ExtVector element subset: V.xyx\n    llvm::Constant *VectorElts;\n\n    // BitField start bit and size\n    const CGBitFieldInfo *BitFieldInfo;\n  };\n\n  QualType Type;\n\n  // 'const' is unused here\n  Qualifiers Quals;\n\n  // The alignment to use when accessing this lvalue.  (For vector elements,\n  // this is the alignment of the whole vector.)\n  unsigned Alignment;\n\n  // objective-c's ivar\n  bool Ivar:1;\n\n  // objective-c's ivar is an array\n  bool ObjIsArray:1;\n\n  // LValue is non-gc'able for any reason, including being a parameter or local\n  // variable.\n  bool NonGC: 1;\n\n  // Lvalue is a global reference of an objective-c object\n  bool GlobalObjCRef : 1;\n\n  // Lvalue is a thread local reference\n  bool ThreadLocalRef : 1;\n\n  // Lvalue has ARC imprecise lifetime.  We store this inverted to try\n  // to make the default bitfield pattern all-zeroes.\n  bool ImpreciseLifetime : 1;\n\n  // This flag shows if a nontemporal load/stores should be used when accessing\n  // this lvalue.\n  bool Nontemporal : 1;\n\n  LValueBaseInfo BaseInfo;\n  TBAAAccessInfo TBAAInfo;\n\n  Expr *BaseIvarExp;\n\nprivate:\n  void Initialize(QualType Type, Qualifiers Quals, CharUnits Alignment,\n                  LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo) {\n    assert((!Alignment.isZero() || Type->isIncompleteType()) &&\n           \"initializing l-value with zero alignment!\");\n    this->Type = Type;\n    this->Quals = Quals;\n    const unsigned MaxAlign = 1U << 31;\n    this->Alignment = Alignment.getQuantity() <= MaxAlign\n                          ? Alignment.getQuantity()\n                          : MaxAlign;\n    assert(this->Alignment == Alignment.getQuantity() &&\n           \"Alignment exceeds allowed max!\");\n    this->BaseInfo = BaseInfo;\n    this->TBAAInfo = TBAAInfo;\n\n    // Initialize Objective-C flags.\n    this->Ivar = this->ObjIsArray = this->NonGC = this->GlobalObjCRef = false;\n    this->ImpreciseLifetime = false;\n    this->Nontemporal = false;\n    this->ThreadLocalRef = false;\n    this->BaseIvarExp = nullptr;\n  }\n\npublic:\n  bool isSimple() const { return LVType == Simple; }\n  bool isVectorElt() const { return LVType == VectorElt; }\n  bool isBitField() const { return LVType == BitField; }\n  bool isExtVectorElt() const { return LVType == ExtVectorElt; }\n  bool isGlobalReg() const { return LVType == GlobalReg; }\n  bool isMatrixElt() const { return LVType == MatrixElt; }\n\n  bool isVolatileQualified() const { return Quals.hasVolatile(); }\n  bool isRestrictQualified() const { return Quals.hasRestrict(); }\n  unsigned getVRQualifiers() const {\n    return Quals.getCVRQualifiers() & ~Qualifiers::Const;\n  }\n\n  QualType getType() const { return Type; }\n\n  Qualifiers::ObjCLifetime getObjCLifetime() const {\n    return Quals.getObjCLifetime();\n  }\n\n  bool isObjCIvar() const { return Ivar; }\n  void setObjCIvar(bool Value) { Ivar = Value; }\n\n  bool isObjCArray() const { return ObjIsArray; }\n  void setObjCArray(bool Value) { ObjIsArray = Value; }\n\n  bool isNonGC () const { return NonGC; }\n  void setNonGC(bool Value) { NonGC = Value; }\n\n  bool isGlobalObjCRef() const { return GlobalObjCRef; }\n  void setGlobalObjCRef(bool Value) { GlobalObjCRef = Value; }\n\n  bool isThreadLocalRef() const { return ThreadLocalRef; }\n  void setThreadLocalRef(bool Value) { ThreadLocalRef = Value;}\n\n  ARCPreciseLifetime_t isARCPreciseLifetime() const {\n    return ARCPreciseLifetime_t(!ImpreciseLifetime);\n  }\n  void setARCPreciseLifetime(ARCPreciseLifetime_t value) {\n    ImpreciseLifetime = (value == ARCImpreciseLifetime);\n  }\n  bool isNontemporal() const { return Nontemporal; }\n  void setNontemporal(bool Value) { Nontemporal = Value; }\n\n  bool isObjCWeak() const {\n    return Quals.getObjCGCAttr() == Qualifiers::Weak;\n  }\n  bool isObjCStrong() const {\n    return Quals.getObjCGCAttr() == Qualifiers::Strong;\n  }\n\n  bool isVolatile() const {\n    return Quals.hasVolatile();\n  }\n\n  Expr *getBaseIvarExp() const { return BaseIvarExp; }\n  void setBaseIvarExp(Expr *V) { BaseIvarExp = V; }\n\n  TBAAAccessInfo getTBAAInfo() const { return TBAAInfo; }\n  void setTBAAInfo(TBAAAccessInfo Info) { TBAAInfo = Info; }\n\n  const Qualifiers &getQuals() const { return Quals; }\n  Qualifiers &getQuals() { return Quals; }\n\n  LangAS getAddressSpace() const { return Quals.getAddressSpace(); }\n\n  CharUnits getAlignment() const { return CharUnits::fromQuantity(Alignment); }\n  void setAlignment(CharUnits A) { Alignment = A.getQuantity(); }\n\n  LValueBaseInfo getBaseInfo() const { return BaseInfo; }\n  void setBaseInfo(LValueBaseInfo Info) { BaseInfo = Info; }\n\n  // simple lvalue\n  llvm::Value *getPointer(CodeGenFunction &CGF) const {\n    assert(isSimple());\n    return V;\n  }\n  Address getAddress(CodeGenFunction &CGF) const {\n    return Address(getPointer(CGF), getAlignment());\n  }\n  void setAddress(Address address) {\n    assert(isSimple());\n    V = address.getPointer();\n    Alignment = address.getAlignment().getQuantity();\n  }\n\n  // vector elt lvalue\n  Address getVectorAddress() const {\n    return Address(getVectorPointer(), getAlignment());\n  }\n  llvm::Value *getVectorPointer() const {\n    assert(isVectorElt());\n    return V;\n  }\n  llvm::Value *getVectorIdx() const {\n    assert(isVectorElt());\n    return VectorIdx;\n  }\n\n  Address getMatrixAddress() const {\n    return Address(getMatrixPointer(), getAlignment());\n  }\n  llvm::Value *getMatrixPointer() const {\n    assert(isMatrixElt());\n    return V;\n  }\n  llvm::Value *getMatrixIdx() const {\n    assert(isMatrixElt());\n    return VectorIdx;\n  }\n\n  // extended vector elements.\n  Address getExtVectorAddress() const {\n    return Address(getExtVectorPointer(), getAlignment());\n  }\n  llvm::Value *getExtVectorPointer() const {\n    assert(isExtVectorElt());\n    return V;\n  }\n  llvm::Constant *getExtVectorElts() const {\n    assert(isExtVectorElt());\n    return VectorElts;\n  }\n\n  // bitfield lvalue\n  Address getBitFieldAddress() const {\n    return Address(getBitFieldPointer(), getAlignment());\n  }\n  llvm::Value *getBitFieldPointer() const { assert(isBitField()); return V; }\n  const CGBitFieldInfo &getBitFieldInfo() const {\n    assert(isBitField());\n    return *BitFieldInfo;\n  }\n\n  // global register lvalue\n  llvm::Value *getGlobalReg() const { assert(isGlobalReg()); return V; }\n\n  static LValue MakeAddr(Address address, QualType type, ASTContext &Context,\n                         LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo) {\n    Qualifiers qs = type.getQualifiers();\n    qs.setObjCGCAttr(Context.getObjCGCAttrKind(type));\n\n    LValue R;\n    R.LVType = Simple;\n    assert(address.getPointer()->getType()->isPointerTy());\n    R.V = address.getPointer();\n    R.Initialize(type, qs, address.getAlignment(), BaseInfo, TBAAInfo);\n    return R;\n  }\n\n  static LValue MakeVectorElt(Address vecAddress, llvm::Value *Idx,\n                              QualType type, LValueBaseInfo BaseInfo,\n                              TBAAAccessInfo TBAAInfo) {\n    LValue R;\n    R.LVType = VectorElt;\n    R.V = vecAddress.getPointer();\n    R.VectorIdx = Idx;\n    R.Initialize(type, type.getQualifiers(), vecAddress.getAlignment(),\n                 BaseInfo, TBAAInfo);\n    return R;\n  }\n\n  static LValue MakeExtVectorElt(Address vecAddress, llvm::Constant *Elts,\n                                 QualType type, LValueBaseInfo BaseInfo,\n                                 TBAAAccessInfo TBAAInfo) {\n    LValue R;\n    R.LVType = ExtVectorElt;\n    R.V = vecAddress.getPointer();\n    R.VectorElts = Elts;\n    R.Initialize(type, type.getQualifiers(), vecAddress.getAlignment(),\n                 BaseInfo, TBAAInfo);\n    return R;\n  }\n\n  /// Create a new object to represent a bit-field access.\n  ///\n  /// \\param Addr - The base address of the bit-field sequence this\n  /// bit-field refers to.\n  /// \\param Info - The information describing how to perform the bit-field\n  /// access.\n  static LValue MakeBitfield(Address Addr, const CGBitFieldInfo &Info,\n                             QualType type, LValueBaseInfo BaseInfo,\n                             TBAAAccessInfo TBAAInfo) {\n    LValue R;\n    R.LVType = BitField;\n    R.V = Addr.getPointer();\n    R.BitFieldInfo = &Info;\n    R.Initialize(type, type.getQualifiers(), Addr.getAlignment(), BaseInfo,\n                 TBAAInfo);\n    return R;\n  }\n\n  static LValue MakeGlobalReg(Address Reg, QualType type) {\n    LValue R;\n    R.LVType = GlobalReg;\n    R.V = Reg.getPointer();\n    R.Initialize(type, type.getQualifiers(), Reg.getAlignment(),\n                 LValueBaseInfo(AlignmentSource::Decl), TBAAAccessInfo());\n    return R;\n  }\n\n  static LValue MakeMatrixElt(Address matAddress, llvm::Value *Idx,\n                              QualType type, LValueBaseInfo BaseInfo,\n                              TBAAAccessInfo TBAAInfo) {\n    LValue R;\n    R.LVType = MatrixElt;\n    R.V = matAddress.getPointer();\n    R.VectorIdx = Idx;\n    R.Initialize(type, type.getQualifiers(), matAddress.getAlignment(),\n                 BaseInfo, TBAAInfo);\n    return R;\n  }\n\n  RValue asAggregateRValue(CodeGenFunction &CGF) const {\n    return RValue::getAggregate(getAddress(CGF), isVolatileQualified());\n  }\n};\n\n/// An aggregate value slot.\nclass AggValueSlot {\n  /// The address.\n  llvm::Value *Addr;\n\n  // Qualifiers\n  Qualifiers Quals;\n\n  unsigned Alignment;\n\n  /// DestructedFlag - This is set to true if some external code is\n  /// responsible for setting up a destructor for the slot.  Otherwise\n  /// the code which constructs it should push the appropriate cleanup.\n  bool DestructedFlag : 1;\n\n  /// ObjCGCFlag - This is set to true if writing to the memory in the\n  /// slot might require calling an appropriate Objective-C GC\n  /// barrier.  The exact interaction here is unnecessarily mysterious.\n  bool ObjCGCFlag : 1;\n\n  /// ZeroedFlag - This is set to true if the memory in the slot is\n  /// known to be zero before the assignment into it.  This means that\n  /// zero fields don't need to be set.\n  bool ZeroedFlag : 1;\n\n  /// AliasedFlag - This is set to true if the slot might be aliased\n  /// and it's not undefined behavior to access it through such an\n  /// alias.  Note that it's always undefined behavior to access a C++\n  /// object that's under construction through an alias derived from\n  /// outside the construction process.\n  ///\n  /// This flag controls whether calls that produce the aggregate\n  /// value may be evaluated directly into the slot, or whether they\n  /// must be evaluated into an unaliased temporary and then memcpy'ed\n  /// over.  Since it's invalid in general to memcpy a non-POD C++\n  /// object, it's important that this flag never be set when\n  /// evaluating an expression which constructs such an object.\n  bool AliasedFlag : 1;\n\n  /// This is set to true if the tail padding of this slot might overlap\n  /// another object that may have already been initialized (and whose\n  /// value must be preserved by this initialization). If so, we may only\n  /// store up to the dsize of the type. Otherwise we can widen stores to\n  /// the size of the type.\n  bool OverlapFlag : 1;\n\n  /// If is set to true, sanitizer checks are already generated for this address\n  /// or not required. For instance, if this address represents an object\n  /// created in 'new' expression, sanitizer checks for memory is made as a part\n  /// of 'operator new' emission and object constructor should not generate\n  /// them.\n  bool SanitizerCheckedFlag : 1;\n\npublic:\n  enum IsAliased_t { IsNotAliased, IsAliased };\n  enum IsDestructed_t { IsNotDestructed, IsDestructed };\n  enum IsZeroed_t { IsNotZeroed, IsZeroed };\n  enum Overlap_t { DoesNotOverlap, MayOverlap };\n  enum NeedsGCBarriers_t { DoesNotNeedGCBarriers, NeedsGCBarriers };\n  enum IsSanitizerChecked_t { IsNotSanitizerChecked, IsSanitizerChecked };\n\n  /// ignored - Returns an aggregate value slot indicating that the\n  /// aggregate value is being ignored.\n  static AggValueSlot ignored() {\n    return forAddr(Address::invalid(), Qualifiers(), IsNotDestructed,\n                   DoesNotNeedGCBarriers, IsNotAliased, DoesNotOverlap);\n  }\n\n  /// forAddr - Make a slot for an aggregate value.\n  ///\n  /// \\param quals - The qualifiers that dictate how the slot should\n  /// be initialied. Only 'volatile' and the Objective-C lifetime\n  /// qualifiers matter.\n  ///\n  /// \\param isDestructed - true if something else is responsible\n  ///   for calling destructors on this object\n  /// \\param needsGC - true if the slot is potentially located\n  ///   somewhere that ObjC GC calls should be emitted for\n  static AggValueSlot forAddr(Address addr,\n                              Qualifiers quals,\n                              IsDestructed_t isDestructed,\n                              NeedsGCBarriers_t needsGC,\n                              IsAliased_t isAliased,\n                              Overlap_t mayOverlap,\n                              IsZeroed_t isZeroed = IsNotZeroed,\n                       IsSanitizerChecked_t isChecked = IsNotSanitizerChecked) {\n    AggValueSlot AV;\n    if (addr.isValid()) {\n      AV.Addr = addr.getPointer();\n      AV.Alignment = addr.getAlignment().getQuantity();\n    } else {\n      AV.Addr = nullptr;\n      AV.Alignment = 0;\n    }\n    AV.Quals = quals;\n    AV.DestructedFlag = isDestructed;\n    AV.ObjCGCFlag = needsGC;\n    AV.ZeroedFlag = isZeroed;\n    AV.AliasedFlag = isAliased;\n    AV.OverlapFlag = mayOverlap;\n    AV.SanitizerCheckedFlag = isChecked;\n    return AV;\n  }\n\n  static AggValueSlot\n  forLValue(const LValue &LV, CodeGenFunction &CGF, IsDestructed_t isDestructed,\n            NeedsGCBarriers_t needsGC, IsAliased_t isAliased,\n            Overlap_t mayOverlap, IsZeroed_t isZeroed = IsNotZeroed,\n            IsSanitizerChecked_t isChecked = IsNotSanitizerChecked) {\n    return forAddr(LV.getAddress(CGF), LV.getQuals(), isDestructed, needsGC,\n                   isAliased, mayOverlap, isZeroed, isChecked);\n  }\n\n  IsDestructed_t isExternallyDestructed() const {\n    return IsDestructed_t(DestructedFlag);\n  }\n  void setExternallyDestructed(bool destructed = true) {\n    DestructedFlag = destructed;\n  }\n\n  Qualifiers getQualifiers() const { return Quals; }\n\n  bool isVolatile() const {\n    return Quals.hasVolatile();\n  }\n\n  void setVolatile(bool flag) {\n    if (flag)\n      Quals.addVolatile();\n    else\n      Quals.removeVolatile();\n  }\n\n  Qualifiers::ObjCLifetime getObjCLifetime() const {\n    return Quals.getObjCLifetime();\n  }\n\n  NeedsGCBarriers_t requiresGCollection() const {\n    return NeedsGCBarriers_t(ObjCGCFlag);\n  }\n\n  llvm::Value *getPointer() const {\n    return Addr;\n  }\n\n  Address getAddress() const {\n    return Address(Addr, getAlignment());\n  }\n\n  bool isIgnored() const {\n    return Addr == nullptr;\n  }\n\n  CharUnits getAlignment() const {\n    return CharUnits::fromQuantity(Alignment);\n  }\n\n  IsAliased_t isPotentiallyAliased() const {\n    return IsAliased_t(AliasedFlag);\n  }\n\n  Overlap_t mayOverlap() const {\n    return Overlap_t(OverlapFlag);\n  }\n\n  bool isSanitizerChecked() const {\n    return SanitizerCheckedFlag;\n  }\n\n  RValue asRValue() const {\n    if (isIgnored()) {\n      return RValue::getIgnored();\n    } else {\n      return RValue::getAggregate(getAddress(), isVolatile());\n    }\n  }\n\n  void setZeroed(bool V = true) { ZeroedFlag = V; }\n  IsZeroed_t isZeroed() const {\n    return IsZeroed_t(ZeroedFlag);\n  }\n\n  /// Get the preferred size to use when storing a value to this slot. This\n  /// is the type size unless that might overlap another object, in which\n  /// case it's the dsize.\n  CharUnits getPreferredSize(ASTContext &Ctx, QualType Type) const {\n    return mayOverlap() ? Ctx.getTypeInfoDataSizeInChars(Type).Width\n                        : Ctx.getTypeSizeInChars(Type);\n  }\n};\n\n}  // end namespace CodeGen\n}  // end namespace clang\n\n#endif\n"}, "54": {"id": 54, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "content": "//===-- CodeGenFunction.h - Per-Function state for LLVM CodeGen -*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This is the internal per-function state used for llvm translation.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CODEGENFUNCTION_H\n#define LLVM_CLANG_LIB_CODEGEN_CODEGENFUNCTION_H\n\n#include \"CGBuilder.h\"\n#include \"CGDebugInfo.h\"\n#include \"CGLoopInfo.h\"\n#include \"CGValue.h\"\n#include \"CodeGenModule.h\"\n#include \"CodeGenPGO.h\"\n#include \"EHScopeStack.h\"\n#include \"VarBypassDetector.h\"\n#include \"clang/AST/CharUnits.h\"\n#include \"clang/AST/CurrentSourceLocExprScope.h\"\n#include \"clang/AST/ExprCXX.h\"\n#include \"clang/AST/ExprObjC.h\"\n#include \"clang/AST/ExprOpenMP.h\"\n#include \"clang/AST/StmtOpenMP.h\"\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/ABI.h\"\n#include \"clang/Basic/CapturedStmt.h\"\n#include \"clang/Basic/CodeGenOptions.h\"\n#include \"clang/Basic/OpenMPKinds.h\"\n#include \"clang/Basic/TargetInfo.h\"\n#include \"llvm/ADT/ArrayRef.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/ADT/MapVector.h\"\n#include \"llvm/ADT/SmallVector.h\"\n#include \"llvm/Frontend/OpenMP/OMPIRBuilder.h\"\n#include \"llvm/IR/ValueHandle.h\"\n#include \"llvm/Support/Debug.h\"\n#include \"llvm/Transforms/Utils/SanitizerStats.h\"\n\nnamespace llvm {\nclass BasicBlock;\nclass LLVMContext;\nclass MDNode;\nclass Module;\nclass SwitchInst;\nclass Twine;\nclass Value;\nclass CanonicalLoopInfo;\n}\n\nnamespace clang {\nclass ASTContext;\nclass BlockDecl;\nclass CXXDestructorDecl;\nclass CXXForRangeStmt;\nclass CXXTryStmt;\nclass Decl;\nclass LabelDecl;\nclass EnumConstantDecl;\nclass FunctionDecl;\nclass FunctionProtoType;\nclass LabelStmt;\nclass ObjCContainerDecl;\nclass ObjCInterfaceDecl;\nclass ObjCIvarDecl;\nclass ObjCMethodDecl;\nclass ObjCImplementationDecl;\nclass ObjCPropertyImplDecl;\nclass TargetInfo;\nclass VarDecl;\nclass ObjCForCollectionStmt;\nclass ObjCAtTryStmt;\nclass ObjCAtThrowStmt;\nclass ObjCAtSynchronizedStmt;\nclass ObjCAutoreleasePoolStmt;\nclass OMPUseDevicePtrClause;\nclass OMPUseDeviceAddrClause;\nclass ReturnsNonNullAttr;\nclass SVETypeFlags;\nclass OMPExecutableDirective;\n\nnamespace analyze_os_log {\nclass OSLogBufferLayout;\n}\n\nnamespace CodeGen {\nclass CodeGenTypes;\nclass CGCallee;\nclass CGFunctionInfo;\nclass CGRecordLayout;\nclass CGBlockInfo;\nclass CGCXXABI;\nclass BlockByrefHelpers;\nclass BlockByrefInfo;\nclass BlockFlags;\nclass BlockFieldFlags;\nclass RegionCodeGenTy;\nclass TargetCodeGenInfo;\nstruct OMPTaskDataTy;\nstruct CGCoroData;\n\n/// The kind of evaluation to perform on values of a particular\n/// type.  Basically, is the code in CGExprScalar, CGExprComplex, or\n/// CGExprAgg?\n///\n/// TODO: should vectors maybe be split out into their own thing?\nenum TypeEvaluationKind {\n  TEK_Scalar,\n  TEK_Complex,\n  TEK_Aggregate\n};\n\n#define LIST_SANITIZER_CHECKS                                                  \\\n  SANITIZER_CHECK(AddOverflow, add_overflow, 0)                                \\\n  SANITIZER_CHECK(BuiltinUnreachable, builtin_unreachable, 0)                  \\\n  SANITIZER_CHECK(CFICheckFail, cfi_check_fail, 0)                             \\\n  SANITIZER_CHECK(DivremOverflow, divrem_overflow, 0)                          \\\n  SANITIZER_CHECK(DynamicTypeCacheMiss, dynamic_type_cache_miss, 0)            \\\n  SANITIZER_CHECK(FloatCastOverflow, float_cast_overflow, 0)                   \\\n  SANITIZER_CHECK(FunctionTypeMismatch, function_type_mismatch, 1)             \\\n  SANITIZER_CHECK(ImplicitConversion, implicit_conversion, 0)                  \\\n  SANITIZER_CHECK(InvalidBuiltin, invalid_builtin, 0)                          \\\n  SANITIZER_CHECK(InvalidObjCCast, invalid_objc_cast, 0)                       \\\n  SANITIZER_CHECK(LoadInvalidValue, load_invalid_value, 0)                     \\\n  SANITIZER_CHECK(MissingReturn, missing_return, 0)                            \\\n  SANITIZER_CHECK(MulOverflow, mul_overflow, 0)                                \\\n  SANITIZER_CHECK(NegateOverflow, negate_overflow, 0)                          \\\n  SANITIZER_CHECK(NullabilityArg, nullability_arg, 0)                          \\\n  SANITIZER_CHECK(NullabilityReturn, nullability_return, 1)                    \\\n  SANITIZER_CHECK(NonnullArg, nonnull_arg, 0)                                  \\\n  SANITIZER_CHECK(NonnullReturn, nonnull_return, 1)                            \\\n  SANITIZER_CHECK(OutOfBounds, out_of_bounds, 0)                               \\\n  SANITIZER_CHECK(PointerOverflow, pointer_overflow, 0)                        \\\n  SANITIZER_CHECK(ShiftOutOfBounds, shift_out_of_bounds, 0)                    \\\n  SANITIZER_CHECK(SubOverflow, sub_overflow, 0)                                \\\n  SANITIZER_CHECK(TypeMismatch, type_mismatch, 1)                              \\\n  SANITIZER_CHECK(AlignmentAssumption, alignment_assumption, 0)                \\\n  SANITIZER_CHECK(VLABoundNotPositive, vla_bound_not_positive, 0)\n\nenum SanitizerHandler {\n#define SANITIZER_CHECK(Enum, Name, Version) Enum,\n  LIST_SANITIZER_CHECKS\n#undef SANITIZER_CHECK\n};\n\n/// Helper class with most of the code for saving a value for a\n/// conditional expression cleanup.\nstruct DominatingLLVMValue {\n  typedef llvm::PointerIntPair<llvm::Value*, 1, bool> saved_type;\n\n  /// Answer whether the given value needs extra work to be saved.\n  static bool needsSaving(llvm::Value *value) {\n    // If it's not an instruction, we don't need to save.\n    if (!isa<llvm::Instruction>(value)) return false;\n\n    // If it's an instruction in the entry block, we don't need to save.\n    llvm::BasicBlock *block = cast<llvm::Instruction>(value)->getParent();\n    return (block != &block->getParent()->getEntryBlock());\n  }\n\n  static saved_type save(CodeGenFunction &CGF, llvm::Value *value);\n  static llvm::Value *restore(CodeGenFunction &CGF, saved_type value);\n};\n\n/// A partial specialization of DominatingValue for llvm::Values that\n/// might be llvm::Instructions.\ntemplate <class T> struct DominatingPointer<T,true> : DominatingLLVMValue {\n  typedef T *type;\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return static_cast<T*>(DominatingLLVMValue::restore(CGF, value));\n  }\n};\n\n/// A specialization of DominatingValue for Address.\ntemplate <> struct DominatingValue<Address> {\n  typedef Address type;\n\n  struct saved_type {\n    DominatingLLVMValue::saved_type SavedValue;\n    CharUnits Alignment;\n  };\n\n  static bool needsSaving(type value) {\n    return DominatingLLVMValue::needsSaving(value.getPointer());\n  }\n  static saved_type save(CodeGenFunction &CGF, type value) {\n    return { DominatingLLVMValue::save(CGF, value.getPointer()),\n             value.getAlignment() };\n  }\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return Address(DominatingLLVMValue::restore(CGF, value.SavedValue),\n                   value.Alignment);\n  }\n};\n\n/// A specialization of DominatingValue for RValue.\ntemplate <> struct DominatingValue<RValue> {\n  typedef RValue type;\n  class saved_type {\n    enum Kind { ScalarLiteral, ScalarAddress, AggregateLiteral,\n                AggregateAddress, ComplexAddress };\n\n    llvm::Value *Value;\n    unsigned K : 3;\n    unsigned Align : 29;\n    saved_type(llvm::Value *v, Kind k, unsigned a = 0)\n      : Value(v), K(k), Align(a) {}\n\n  public:\n    static bool needsSaving(RValue value);\n    static saved_type save(CodeGenFunction &CGF, RValue value);\n    RValue restore(CodeGenFunction &CGF);\n\n    // implementations in CGCleanup.cpp\n  };\n\n  static bool needsSaving(type value) {\n    return saved_type::needsSaving(value);\n  }\n  static saved_type save(CodeGenFunction &CGF, type value) {\n    return saved_type::save(CGF, value);\n  }\n  static type restore(CodeGenFunction &CGF, saved_type value) {\n    return value.restore(CGF);\n  }\n};\n\n/// CodeGenFunction - This class organizes the per-function state that is used\n/// while generating LLVM code.\nclass CodeGenFunction : public CodeGenTypeCache {\n  CodeGenFunction(const CodeGenFunction &) = delete;\n  void operator=(const CodeGenFunction &) = delete;\n\n  friend class CGCXXABI;\npublic:\n  /// A jump destination is an abstract label, branching to which may\n  /// require a jump out through normal cleanups.\n  struct JumpDest {\n    JumpDest() : Block(nullptr), ScopeDepth(), Index(0) {}\n    JumpDest(llvm::BasicBlock *Block,\n             EHScopeStack::stable_iterator Depth,\n             unsigned Index)\n      : Block(Block), ScopeDepth(Depth), Index(Index) {}\n\n    bool isValid() const { return Block != nullptr; }\n    llvm::BasicBlock *getBlock() const { return Block; }\n    EHScopeStack::stable_iterator getScopeDepth() const { return ScopeDepth; }\n    unsigned getDestIndex() const { return Index; }\n\n    // This should be used cautiously.\n    void setScopeDepth(EHScopeStack::stable_iterator depth) {\n      ScopeDepth = depth;\n    }\n\n  private:\n    llvm::BasicBlock *Block;\n    EHScopeStack::stable_iterator ScopeDepth;\n    unsigned Index;\n  };\n\n  CodeGenModule &CGM;  // Per-module state.\n  const TargetInfo &Target;\n\n  // For EH/SEH outlined funclets, this field points to parent's CGF\n  CodeGenFunction *ParentCGF = nullptr;\n\n  typedef std::pair<llvm::Value *, llvm::Value *> ComplexPairTy;\n  LoopInfoStack LoopStack;\n  CGBuilderTy Builder;\n\n  // Stores variables for which we can't generate correct lifetime markers\n  // because of jumps.\n  VarBypassDetector Bypasses;\n\n  /// List of recently emitted OMPCanonicalLoops.\n  ///\n  /// Since OMPCanonicalLoops are nested inside other statements (in particular\n  /// CapturedStmt generated by OMPExecutableDirective and non-perfectly nested\n  /// loops), we cannot directly call OMPEmitOMPCanonicalLoop and receive its\n  /// llvm::CanonicalLoopInfo. Instead, we call EmitStmt and any\n  /// OMPEmitOMPCanonicalLoop called by it will add its CanonicalLoopInfo to\n  /// this stack when done. Entering a new loop requires clearing this list; it\n  /// either means we start parsing a new loop nest (in which case the previous\n  /// loop nest goes out of scope) or a second loop in the same level in which\n  /// case it would be ambiguous into which of the two (or more) loops the loop\n  /// nest would extend.\n  SmallVector<llvm::CanonicalLoopInfo *, 4> OMPLoopNestStack;\n\n  // CodeGen lambda for loops and support for ordered clause\n  typedef llvm::function_ref<void(CodeGenFunction &, const OMPLoopDirective &,\n                                  JumpDest)>\n      CodeGenLoopTy;\n  typedef llvm::function_ref<void(CodeGenFunction &, SourceLocation,\n                                  const unsigned, const bool)>\n      CodeGenOrderedTy;\n\n  // Codegen lambda for loop bounds in worksharing loop constructs\n  typedef llvm::function_ref<std::pair<LValue, LValue>(\n      CodeGenFunction &, const OMPExecutableDirective &S)>\n      CodeGenLoopBoundsTy;\n\n  // Codegen lambda for loop bounds in dispatch-based loop implementation\n  typedef llvm::function_ref<std::pair<llvm::Value *, llvm::Value *>(\n      CodeGenFunction &, const OMPExecutableDirective &S, Address LB,\n      Address UB)>\n      CodeGenDispatchBoundsTy;\n\n  /// CGBuilder insert helper. This function is called after an\n  /// instruction is created using Builder.\n  void InsertHelper(llvm::Instruction *I, const llvm::Twine &Name,\n                    llvm::BasicBlock *BB,\n                    llvm::BasicBlock::iterator InsertPt) const;\n\n  /// CurFuncDecl - Holds the Decl for the current outermost\n  /// non-closure context.\n  const Decl *CurFuncDecl;\n  /// CurCodeDecl - This is the inner-most code context, which includes blocks.\n  const Decl *CurCodeDecl;\n  const CGFunctionInfo *CurFnInfo;\n  QualType FnRetTy;\n  llvm::Function *CurFn = nullptr;\n\n  // Holds coroutine data if the current function is a coroutine. We use a\n  // wrapper to manage its lifetime, so that we don't have to define CGCoroData\n  // in this header.\n  struct CGCoroInfo {\n    std::unique_ptr<CGCoroData> Data;\n    CGCoroInfo();\n    ~CGCoroInfo();\n  };\n  CGCoroInfo CurCoro;\n\n  bool isCoroutine() const {\n    return CurCoro.Data != nullptr;\n  }\n\n  /// CurGD - The GlobalDecl for the current function being compiled.\n  GlobalDecl CurGD;\n\n  /// PrologueCleanupDepth - The cleanup depth enclosing all the\n  /// cleanups associated with the parameters.\n  EHScopeStack::stable_iterator PrologueCleanupDepth;\n\n  /// ReturnBlock - Unified return block.\n  JumpDest ReturnBlock;\n\n  /// ReturnValue - The temporary alloca to hold the return\n  /// value. This is invalid iff the function has no return value.\n  Address ReturnValue = Address::invalid();\n\n  /// ReturnValuePointer - The temporary alloca to hold a pointer to sret.\n  /// This is invalid if sret is not in use.\n  Address ReturnValuePointer = Address::invalid();\n\n  /// If a return statement is being visited, this holds the return statment's\n  /// result expression.\n  const Expr *RetExpr = nullptr;\n\n  /// Return true if a label was seen in the current scope.\n  bool hasLabelBeenSeenInCurrentScope() const {\n    if (CurLexicalScope)\n      return CurLexicalScope->hasLabels();\n    return !LabelMap.empty();\n  }\n\n  /// AllocaInsertPoint - This is an instruction in the entry block before which\n  /// we prefer to insert allocas.\n  llvm::AssertingVH<llvm::Instruction> AllocaInsertPt;\n\n  /// API for captured statement code generation.\n  class CGCapturedStmtInfo {\n  public:\n    explicit CGCapturedStmtInfo(CapturedRegionKind K = CR_Default)\n        : Kind(K), ThisValue(nullptr), CXXThisFieldDecl(nullptr) {}\n    explicit CGCapturedStmtInfo(const CapturedStmt &S,\n                                CapturedRegionKind K = CR_Default)\n      : Kind(K), ThisValue(nullptr), CXXThisFieldDecl(nullptr) {\n\n      RecordDecl::field_iterator Field =\n        S.getCapturedRecordDecl()->field_begin();\n      for (CapturedStmt::const_capture_iterator I = S.capture_begin(),\n                                                E = S.capture_end();\n           I != E; ++I, ++Field) {\n        if (I->capturesThis())\n          CXXThisFieldDecl = *Field;\n        else if (I->capturesVariable())\n          CaptureFields[I->getCapturedVar()->getCanonicalDecl()] = *Field;\n        else if (I->capturesVariableByCopy())\n          CaptureFields[I->getCapturedVar()->getCanonicalDecl()] = *Field;\n      }\n    }\n\n    virtual ~CGCapturedStmtInfo();\n\n    CapturedRegionKind getKind() const { return Kind; }\n\n    virtual void setContextValue(llvm::Value *V) { ThisValue = V; }\n    // Retrieve the value of the context parameter.\n    virtual llvm::Value *getContextValue() const { return ThisValue; }\n\n    /// Lookup the captured field decl for a variable.\n    virtual const FieldDecl *lookup(const VarDecl *VD) const {\n      return CaptureFields.lookup(VD->getCanonicalDecl());\n    }\n\n    bool isCXXThisExprCaptured() const { return getThisFieldDecl() != nullptr; }\n    virtual FieldDecl *getThisFieldDecl() const { return CXXThisFieldDecl; }\n\n    static bool classof(const CGCapturedStmtInfo *) {\n      return true;\n    }\n\n    /// Emit the captured statement body.\n    virtual void EmitBody(CodeGenFunction &CGF, const Stmt *S) {\n      CGF.incrementProfileCounter(S);\n      CGF.EmitStmt(S);\n    }\n\n    /// Get the name of the capture helper.\n    virtual StringRef getHelperName() const { return \"__captured_stmt\"; }\n\n  private:\n    /// The kind of captured statement being generated.\n    CapturedRegionKind Kind;\n\n    /// Keep the map between VarDecl and FieldDecl.\n    llvm::SmallDenseMap<const VarDecl *, FieldDecl *> CaptureFields;\n\n    /// The base address of the captured record, passed in as the first\n    /// argument of the parallel region function.\n    llvm::Value *ThisValue;\n\n    /// Captured 'this' type.\n    FieldDecl *CXXThisFieldDecl;\n  };\n  CGCapturedStmtInfo *CapturedStmtInfo = nullptr;\n\n  /// RAII for correct setting/restoring of CapturedStmtInfo.\n  class CGCapturedStmtRAII {\n  private:\n    CodeGenFunction &CGF;\n    CGCapturedStmtInfo *PrevCapturedStmtInfo;\n  public:\n    CGCapturedStmtRAII(CodeGenFunction &CGF,\n                       CGCapturedStmtInfo *NewCapturedStmtInfo)\n        : CGF(CGF), PrevCapturedStmtInfo(CGF.CapturedStmtInfo) {\n      CGF.CapturedStmtInfo = NewCapturedStmtInfo;\n    }\n    ~CGCapturedStmtRAII() { CGF.CapturedStmtInfo = PrevCapturedStmtInfo; }\n  };\n\n  /// An abstract representation of regular/ObjC call/message targets.\n  class AbstractCallee {\n    /// The function declaration of the callee.\n    const Decl *CalleeDecl;\n\n  public:\n    AbstractCallee() : CalleeDecl(nullptr) {}\n    AbstractCallee(const FunctionDecl *FD) : CalleeDecl(FD) {}\n    AbstractCallee(const ObjCMethodDecl *OMD) : CalleeDecl(OMD) {}\n    bool hasFunctionDecl() const {\n      return dyn_cast_or_null<FunctionDecl>(CalleeDecl);\n    }\n    const Decl *getDecl() const { return CalleeDecl; }\n    unsigned getNumParams() const {\n      if (const auto *FD = dyn_cast<FunctionDecl>(CalleeDecl))\n        return FD->getNumParams();\n      return cast<ObjCMethodDecl>(CalleeDecl)->param_size();\n    }\n    const ParmVarDecl *getParamDecl(unsigned I) const {\n      if (const auto *FD = dyn_cast<FunctionDecl>(CalleeDecl))\n        return FD->getParamDecl(I);\n      return *(cast<ObjCMethodDecl>(CalleeDecl)->param_begin() + I);\n    }\n  };\n\n  /// Sanitizers enabled for this function.\n  SanitizerSet SanOpts;\n\n  /// True if CodeGen currently emits code implementing sanitizer checks.\n  bool IsSanitizerScope = false;\n\n  /// RAII object to set/unset CodeGenFunction::IsSanitizerScope.\n  class SanitizerScope {\n    CodeGenFunction *CGF;\n  public:\n    SanitizerScope(CodeGenFunction *CGF);\n    ~SanitizerScope();\n  };\n\n  /// In C++, whether we are code generating a thunk.  This controls whether we\n  /// should emit cleanups.\n  bool CurFuncIsThunk = false;\n\n  /// In ARC, whether we should autorelease the return value.\n  bool AutoreleaseResult = false;\n\n  /// Whether we processed a Microsoft-style asm block during CodeGen. These can\n  /// potentially set the return value.\n  bool SawAsmBlock = false;\n\n  const NamedDecl *CurSEHParent = nullptr;\n\n  /// True if the current function is an outlined SEH helper. This can be a\n  /// finally block or filter expression.\n  bool IsOutlinedSEHHelper = false;\n\n  /// True if CodeGen currently emits code inside presereved access index\n  /// region.\n  bool IsInPreservedAIRegion = false;\n\n  /// True if the current statement has nomerge attribute.\n  bool InNoMergeAttributedStmt = false;\n\n  /// True if the current function should be marked mustprogress.\n  bool FnIsMustProgress = false;\n\n  /// True if the C++ Standard Requires Progress.\n  bool CPlusPlusWithProgress() {\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Never)\n      return false;\n\n    return getLangOpts().CPlusPlus11 || getLangOpts().CPlusPlus14 ||\n           getLangOpts().CPlusPlus17 || getLangOpts().CPlusPlus20;\n  }\n\n  /// True if the C Standard Requires Progress.\n  bool CWithProgress() {\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Always)\n      return true;\n    if (CGM.getCodeGenOpts().getFiniteLoops() ==\n        CodeGenOptions::FiniteLoopsKind::Never)\n      return false;\n\n    return getLangOpts().C11 || getLangOpts().C17 || getLangOpts().C2x;\n  }\n\n  /// True if the language standard requires progress in functions or\n  /// in infinite loops with non-constant conditionals.\n  bool LanguageRequiresProgress() {\n    return CWithProgress() || CPlusPlusWithProgress();\n  }\n\n  const CodeGen::CGBlockInfo *BlockInfo = nullptr;\n  llvm::Value *BlockPointer = nullptr;\n\n  llvm::DenseMap<const VarDecl *, FieldDecl *> LambdaCaptureFields;\n  FieldDecl *LambdaThisCaptureField = nullptr;\n\n  /// A mapping from NRVO variables to the flags used to indicate\n  /// when the NRVO has been applied to this variable.\n  llvm::DenseMap<const VarDecl *, llvm::Value *> NRVOFlags;\n\n  EHScopeStack EHStack;\n  llvm::SmallVector<char, 256> LifetimeExtendedCleanupStack;\n  llvm::SmallVector<const JumpDest *, 2> SEHTryEpilogueStack;\n\n  llvm::Instruction *CurrentFuncletPad = nullptr;\n\n  class CallLifetimeEnd final : public EHScopeStack::Cleanup {\n    llvm::Value *Addr;\n    llvm::Value *Size;\n\n  public:\n    CallLifetimeEnd(Address addr, llvm::Value *size)\n        : Addr(addr.getPointer()), Size(size) {}\n\n    void Emit(CodeGenFunction &CGF, Flags flags) override {\n      CGF.EmitLifetimeEnd(Size, Addr);\n    }\n  };\n\n  /// Header for data within LifetimeExtendedCleanupStack.\n  struct LifetimeExtendedCleanupHeader {\n    /// The size of the following cleanup object.\n    unsigned Size;\n    /// The kind of cleanup to push: a value from the CleanupKind enumeration.\n    unsigned Kind : 31;\n    /// Whether this is a conditional cleanup.\n    unsigned IsConditional : 1;\n\n    size_t getSize() const { return Size; }\n    CleanupKind getKind() const { return (CleanupKind)Kind; }\n    bool isConditional() const { return IsConditional; }\n  };\n\n  /// i32s containing the indexes of the cleanup destinations.\n  Address NormalCleanupDest = Address::invalid();\n\n  unsigned NextCleanupDestIndex = 1;\n\n  /// EHResumeBlock - Unified block containing a call to llvm.eh.resume.\n  llvm::BasicBlock *EHResumeBlock = nullptr;\n\n  /// The exception slot.  All landing pads write the current exception pointer\n  /// into this alloca.\n  llvm::Value *ExceptionSlot = nullptr;\n\n  /// The selector slot.  Under the MandatoryCleanup model, all landing pads\n  /// write the current selector value into this alloca.\n  llvm::AllocaInst *EHSelectorSlot = nullptr;\n\n  /// A stack of exception code slots. Entering an __except block pushes a slot\n  /// on the stack and leaving pops one. The __exception_code() intrinsic loads\n  /// a value from the top of the stack.\n  SmallVector<Address, 1> SEHCodeSlotStack;\n\n  /// Value returned by __exception_info intrinsic.\n  llvm::Value *SEHInfo = nullptr;\n\n  /// Emits a landing pad for the current EH stack.\n  llvm::BasicBlock *EmitLandingPad();\n\n  llvm::BasicBlock *getInvokeDestImpl();\n\n  /// Parent loop-based directive for scan directive.\n  const OMPExecutableDirective *OMPParentLoopDirectiveForScan = nullptr;\n  llvm::BasicBlock *OMPBeforeScanBlock = nullptr;\n  llvm::BasicBlock *OMPAfterScanBlock = nullptr;\n  llvm::BasicBlock *OMPScanExitBlock = nullptr;\n  llvm::BasicBlock *OMPScanDispatch = nullptr;\n  bool OMPFirstScanLoop = false;\n\n  /// Manages parent directive for scan directives.\n  class ParentLoopDirectiveForScanRegion {\n    CodeGenFunction &CGF;\n    const OMPExecutableDirective *ParentLoopDirectiveForScan;\n\n  public:\n    ParentLoopDirectiveForScanRegion(\n        CodeGenFunction &CGF,\n        const OMPExecutableDirective &ParentLoopDirectiveForScan)\n        : CGF(CGF),\n          ParentLoopDirectiveForScan(CGF.OMPParentLoopDirectiveForScan) {\n      CGF.OMPParentLoopDirectiveForScan = &ParentLoopDirectiveForScan;\n    }\n    ~ParentLoopDirectiveForScanRegion() {\n      CGF.OMPParentLoopDirectiveForScan = ParentLoopDirectiveForScan;\n    }\n  };\n\n  template <class T>\n  typename DominatingValue<T>::saved_type saveValueInCond(T value) {\n    return DominatingValue<T>::save(*this, value);\n  }\n\n  class CGFPOptionsRAII {\n  public:\n    CGFPOptionsRAII(CodeGenFunction &CGF, FPOptions FPFeatures);\n    CGFPOptionsRAII(CodeGenFunction &CGF, const Expr *E);\n    ~CGFPOptionsRAII();\n\n  private:\n    void ConstructorHelper(FPOptions FPFeatures);\n    CodeGenFunction &CGF;\n    FPOptions OldFPFeatures;\n    llvm::fp::ExceptionBehavior OldExcept;\n    llvm::RoundingMode OldRounding;\n    Optional<CGBuilderTy::FastMathFlagGuard> FMFGuard;\n  };\n  FPOptions CurFPFeatures;\n\npublic:\n  /// ObjCEHValueStack - Stack of Objective-C exception values, used for\n  /// rethrows.\n  SmallVector<llvm::Value*, 8> ObjCEHValueStack;\n\n  /// A class controlling the emission of a finally block.\n  class FinallyInfo {\n    /// Where the catchall's edge through the cleanup should go.\n    JumpDest RethrowDest;\n\n    /// A function to call to enter the catch.\n    llvm::FunctionCallee BeginCatchFn;\n\n    /// An i1 variable indicating whether or not the @finally is\n    /// running for an exception.\n    llvm::AllocaInst *ForEHVar;\n\n    /// An i8* variable into which the exception pointer to rethrow\n    /// has been saved.\n    llvm::AllocaInst *SavedExnVar;\n\n  public:\n    void enter(CodeGenFunction &CGF, const Stmt *Finally,\n               llvm::FunctionCallee beginCatchFn,\n               llvm::FunctionCallee endCatchFn, llvm::FunctionCallee rethrowFn);\n    void exit(CodeGenFunction &CGF);\n  };\n\n  /// Returns true inside SEH __try blocks.\n  bool isSEHTryScope() const { return !SEHTryEpilogueStack.empty(); }\n\n  /// Returns true while emitting a cleanuppad.\n  bool isCleanupPadScope() const {\n    return CurrentFuncletPad && isa<llvm::CleanupPadInst>(CurrentFuncletPad);\n  }\n\n  /// pushFullExprCleanup - Push a cleanup to be run at the end of the\n  /// current full-expression.  Safe against the possibility that\n  /// we're currently inside a conditionally-evaluated expression.\n  template <class T, class... As>\n  void pushFullExprCleanup(CleanupKind kind, As... A) {\n    // If we're not in a conditional branch, or if none of the\n    // arguments requires saving, then use the unconditional cleanup.\n    if (!isInConditionalBranch())\n      return EHStack.pushCleanup<T>(kind, A...);\n\n    // Stash values in a tuple so we can guarantee the order of saves.\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved{saveValueInCond(A)...};\n\n    typedef EHScopeStack::ConditionalCleanup<T, As...> CleanupType;\n    EHStack.pushCleanupTuple<CleanupType>(kind, Saved);\n    initFullExprCleanup();\n  }\n\n  /// Queue a cleanup to be pushed after finishing the current full-expression,\n  /// potentially with an active flag.\n  template <class T, class... As>\n  void pushCleanupAfterFullExpr(CleanupKind Kind, As... A) {\n    if (!isInConditionalBranch())\n      return pushCleanupAfterFullExprWithActiveFlag<T>(Kind, Address::invalid(),\n                                                       A...);\n\n    Address ActiveFlag = createCleanupActiveFlag();\n    assert(!DominatingValue<Address>::needsSaving(ActiveFlag) &&\n           \"cleanup active flag should never need saving\");\n\n    typedef std::tuple<typename DominatingValue<As>::saved_type...> SavedTuple;\n    SavedTuple Saved{saveValueInCond(A)...};\n\n    typedef EHScopeStack::ConditionalCleanup<T, As...> CleanupType;\n    pushCleanupAfterFullExprWithActiveFlag<CleanupType>(Kind, ActiveFlag, Saved);\n  }\n\n  template <class T, class... As>\n  void pushCleanupAfterFullExprWithActiveFlag(CleanupKind Kind,\n                                              Address ActiveFlag, As... A) {\n    LifetimeExtendedCleanupHeader Header = {sizeof(T), Kind,\n                                            ActiveFlag.isValid()};\n\n    size_t OldSize = LifetimeExtendedCleanupStack.size();\n    LifetimeExtendedCleanupStack.resize(\n        LifetimeExtendedCleanupStack.size() + sizeof(Header) + Header.Size +\n        (Header.IsConditional ? sizeof(ActiveFlag) : 0));\n\n    static_assert(sizeof(Header) % alignof(T) == 0,\n                  \"Cleanup will be allocated on misaligned address\");\n    char *Buffer = &LifetimeExtendedCleanupStack[OldSize];\n    new (Buffer) LifetimeExtendedCleanupHeader(Header);\n    new (Buffer + sizeof(Header)) T(A...);\n    if (Header.IsConditional)\n      new (Buffer + sizeof(Header) + sizeof(T)) Address(ActiveFlag);\n  }\n\n  /// Set up the last cleanup that was pushed as a conditional\n  /// full-expression cleanup.\n  void initFullExprCleanup() {\n    initFullExprCleanupWithFlag(createCleanupActiveFlag());\n  }\n\n  void initFullExprCleanupWithFlag(Address ActiveFlag);\n  Address createCleanupActiveFlag();\n\n  /// PushDestructorCleanup - Push a cleanup to call the\n  /// complete-object destructor of an object of the given type at the\n  /// given address.  Does nothing if T is not a C++ class type with a\n  /// non-trivial destructor.\n  void PushDestructorCleanup(QualType T, Address Addr);\n\n  /// PushDestructorCleanup - Push a cleanup to call the\n  /// complete-object variant of the given destructor on the object at\n  /// the given address.\n  void PushDestructorCleanup(const CXXDestructorDecl *Dtor, QualType T,\n                             Address Addr);\n\n  /// PopCleanupBlock - Will pop the cleanup entry on the stack and\n  /// process all branch fixups.\n  void PopCleanupBlock(bool FallThroughIsBranchThrough = false);\n\n  /// DeactivateCleanupBlock - Deactivates the given cleanup block.\n  /// The block cannot be reactivated.  Pops it if it's the top of the\n  /// stack.\n  ///\n  /// \\param DominatingIP - An instruction which is known to\n  ///   dominate the current IP (if set) and which lies along\n  ///   all paths of execution between the current IP and the\n  ///   the point at which the cleanup comes into scope.\n  void DeactivateCleanupBlock(EHScopeStack::stable_iterator Cleanup,\n                              llvm::Instruction *DominatingIP);\n\n  /// ActivateCleanupBlock - Activates an initially-inactive cleanup.\n  /// Cannot be used to resurrect a deactivated cleanup.\n  ///\n  /// \\param DominatingIP - An instruction which is known to\n  ///   dominate the current IP (if set) and which lies along\n  ///   all paths of execution between the current IP and the\n  ///   the point at which the cleanup comes into scope.\n  void ActivateCleanupBlock(EHScopeStack::stable_iterator Cleanup,\n                            llvm::Instruction *DominatingIP);\n\n  /// Enters a new scope for capturing cleanups, all of which\n  /// will be executed once the scope is exited.\n  class RunCleanupsScope {\n    EHScopeStack::stable_iterator CleanupStackDepth, OldCleanupScopeDepth;\n    size_t LifetimeExtendedCleanupStackSize;\n    bool OldDidCallStackSave;\n  protected:\n    bool PerformCleanup;\n  private:\n\n    RunCleanupsScope(const RunCleanupsScope &) = delete;\n    void operator=(const RunCleanupsScope &) = delete;\n\n  protected:\n    CodeGenFunction& CGF;\n\n  public:\n    /// Enter a new cleanup scope.\n    explicit RunCleanupsScope(CodeGenFunction &CGF)\n      : PerformCleanup(true), CGF(CGF)\n    {\n      CleanupStackDepth = CGF.EHStack.stable_begin();\n      LifetimeExtendedCleanupStackSize =\n          CGF.LifetimeExtendedCleanupStack.size();\n      OldDidCallStackSave = CGF.DidCallStackSave;\n      CGF.DidCallStackSave = false;\n      OldCleanupScopeDepth = CGF.CurrentCleanupScopeDepth;\n      CGF.CurrentCleanupScopeDepth = CleanupStackDepth;\n    }\n\n    /// Exit this cleanup scope, emitting any accumulated cleanups.\n    ~RunCleanupsScope() {\n      if (PerformCleanup)\n        ForceCleanup();\n    }\n\n    /// Determine whether this scope requires any cleanups.\n    bool requiresCleanups() const {\n      return CGF.EHStack.stable_begin() != CleanupStackDepth;\n    }\n\n    /// Force the emission of cleanups now, instead of waiting\n    /// until this object is destroyed.\n    /// \\param ValuesToReload - A list of values that need to be available at\n    /// the insertion point after cleanup emission. If cleanup emission created\n    /// a shared cleanup block, these value pointers will be rewritten.\n    /// Otherwise, they not will be modified.\n    void ForceCleanup(std::initializer_list<llvm::Value**> ValuesToReload = {}) {\n      assert(PerformCleanup && \"Already forced cleanup\");\n      CGF.DidCallStackSave = OldDidCallStackSave;\n      CGF.PopCleanupBlocks(CleanupStackDepth, LifetimeExtendedCleanupStackSize,\n                           ValuesToReload);\n      PerformCleanup = false;\n      CGF.CurrentCleanupScopeDepth = OldCleanupScopeDepth;\n    }\n  };\n\n  // Cleanup stack depth of the RunCleanupsScope that was pushed most recently.\n  EHScopeStack::stable_iterator CurrentCleanupScopeDepth =\n      EHScopeStack::stable_end();\n\n  class LexicalScope : public RunCleanupsScope {\n    SourceRange Range;\n    SmallVector<const LabelDecl*, 4> Labels;\n    LexicalScope *ParentScope;\n\n    LexicalScope(const LexicalScope &) = delete;\n    void operator=(const LexicalScope &) = delete;\n\n  public:\n    /// Enter a new cleanup scope.\n    explicit LexicalScope(CodeGenFunction &CGF, SourceRange Range)\n      : RunCleanupsScope(CGF), Range(Range), ParentScope(CGF.CurLexicalScope) {\n      CGF.CurLexicalScope = this;\n      if (CGDebugInfo *DI = CGF.getDebugInfo())\n        DI->EmitLexicalBlockStart(CGF.Builder, Range.getBegin());\n    }\n\n    void addLabel(const LabelDecl *label) {\n      assert(PerformCleanup && \"adding label to dead scope?\");\n      Labels.push_back(label);\n    }\n\n    /// Exit this cleanup scope, emitting any accumulated\n    /// cleanups.\n    ~LexicalScope() {\n      if (CGDebugInfo *DI = CGF.getDebugInfo())\n        DI->EmitLexicalBlockEnd(CGF.Builder, Range.getEnd());\n\n      // If we should perform a cleanup, force them now.  Note that\n      // this ends the cleanup scope before rescoping any labels.\n      if (PerformCleanup) {\n        ApplyDebugLocation DL(CGF, Range.getEnd());\n        ForceCleanup();\n      }\n    }\n\n    /// Force the emission of cleanups now, instead of waiting\n    /// until this object is destroyed.\n    void ForceCleanup() {\n      CGF.CurLexicalScope = ParentScope;\n      RunCleanupsScope::ForceCleanup();\n\n      if (!Labels.empty())\n        rescopeLabels();\n    }\n\n    bool hasLabels() const {\n      return !Labels.empty();\n    }\n\n    void rescopeLabels();\n  };\n\n  typedef llvm::DenseMap<const Decl *, Address> DeclMapTy;\n\n  /// The class used to assign some variables some temporarily addresses.\n  class OMPMapVars {\n    DeclMapTy SavedLocals;\n    DeclMapTy SavedTempAddresses;\n    OMPMapVars(const OMPMapVars &) = delete;\n    void operator=(const OMPMapVars &) = delete;\n\n  public:\n    explicit OMPMapVars() = default;\n    ~OMPMapVars() {\n      assert(SavedLocals.empty() && \"Did not restored original addresses.\");\n    };\n\n    /// Sets the address of the variable \\p LocalVD to be \\p TempAddr in\n    /// function \\p CGF.\n    /// \\return true if at least one variable was set already, false otherwise.\n    bool setVarAddr(CodeGenFunction &CGF, const VarDecl *LocalVD,\n                    Address TempAddr) {\n      LocalVD = LocalVD->getCanonicalDecl();\n      // Only save it once.\n      if (SavedLocals.count(LocalVD)) return false;\n\n      // Copy the existing local entry to SavedLocals.\n      auto it = CGF.LocalDeclMap.find(LocalVD);\n      if (it != CGF.LocalDeclMap.end())\n        SavedLocals.try_emplace(LocalVD, it->second);\n      else\n        SavedLocals.try_emplace(LocalVD, Address::invalid());\n\n      // Generate the private entry.\n      QualType VarTy = LocalVD->getType();\n      if (VarTy->isReferenceType()) {\n        Address Temp = CGF.CreateMemTemp(VarTy);\n        CGF.Builder.CreateStore(TempAddr.getPointer(), Temp);\n        TempAddr = Temp;\n      }\n      SavedTempAddresses.try_emplace(LocalVD, TempAddr);\n\n      return true;\n    }\n\n    /// Applies new addresses to the list of the variables.\n    /// \\return true if at least one variable is using new address, false\n    /// otherwise.\n    bool apply(CodeGenFunction &CGF) {\n      copyInto(SavedTempAddresses, CGF.LocalDeclMap);\n      SavedTempAddresses.clear();\n      return !SavedLocals.empty();\n    }\n\n    /// Restores original addresses of the variables.\n    void restore(CodeGenFunction &CGF) {\n      if (!SavedLocals.empty()) {\n        copyInto(SavedLocals, CGF.LocalDeclMap);\n        SavedLocals.clear();\n      }\n    }\n\n  private:\n    /// Copy all the entries in the source map over the corresponding\n    /// entries in the destination, which must exist.\n    static void copyInto(const DeclMapTy &Src, DeclMapTy &Dest) {\n      for (auto &Pair : Src) {\n        if (!Pair.second.isValid()) {\n          Dest.erase(Pair.first);\n          continue;\n        }\n\n        auto I = Dest.find(Pair.first);\n        if (I != Dest.end())\n          I->second = Pair.second;\n        else\n          Dest.insert(Pair);\n      }\n    }\n  };\n\n  /// The scope used to remap some variables as private in the OpenMP loop body\n  /// (or other captured region emitted without outlining), and to restore old\n  /// vars back on exit.\n  class OMPPrivateScope : public RunCleanupsScope {\n    OMPMapVars MappedVars;\n    OMPPrivateScope(const OMPPrivateScope &) = delete;\n    void operator=(const OMPPrivateScope &) = delete;\n\n  public:\n    /// Enter a new OpenMP private scope.\n    explicit OMPPrivateScope(CodeGenFunction &CGF) : RunCleanupsScope(CGF) {}\n\n    /// Registers \\p LocalVD variable as a private and apply \\p PrivateGen\n    /// function for it to generate corresponding private variable. \\p\n    /// PrivateGen returns an address of the generated private variable.\n    /// \\return true if the variable is registered as private, false if it has\n    /// been privatized already.\n    bool addPrivate(const VarDecl *LocalVD,\n                    const llvm::function_ref<Address()> PrivateGen) {\n      assert(PerformCleanup && \"adding private to dead scope\");\n      return MappedVars.setVarAddr(CGF, LocalVD, PrivateGen());\n    }\n\n    /// Privatizes local variables previously registered as private.\n    /// Registration is separate from the actual privatization to allow\n    /// initializers use values of the original variables, not the private one.\n    /// This is important, for example, if the private variable is a class\n    /// variable initialized by a constructor that references other private\n    /// variables. But at initialization original variables must be used, not\n    /// private copies.\n    /// \\return true if at least one variable was privatized, false otherwise.\n    bool Privatize() { return MappedVars.apply(CGF); }\n\n    void ForceCleanup() {\n      RunCleanupsScope::ForceCleanup();\n      MappedVars.restore(CGF);\n    }\n\n    /// Exit scope - all the mapped variables are restored.\n    ~OMPPrivateScope() {\n      if (PerformCleanup)\n        ForceCleanup();\n    }\n\n    /// Checks if the global variable is captured in current function.\n    bool isGlobalVarCaptured(const VarDecl *VD) const {\n      VD = VD->getCanonicalDecl();\n      return !VD->isLocalVarDeclOrParm() && CGF.LocalDeclMap.count(VD) > 0;\n    }\n  };\n\n  /// Save/restore original map of previously emitted local vars in case when we\n  /// need to duplicate emission of the same code several times in the same\n  /// function for OpenMP code.\n  class OMPLocalDeclMapRAII {\n    CodeGenFunction &CGF;\n    DeclMapTy SavedMap;\n\n  public:\n    OMPLocalDeclMapRAII(CodeGenFunction &CGF)\n        : CGF(CGF), SavedMap(CGF.LocalDeclMap) {}\n    ~OMPLocalDeclMapRAII() { SavedMap.swap(CGF.LocalDeclMap); }\n  };\n\n  /// Takes the old cleanup stack size and emits the cleanup blocks\n  /// that have been added.\n  void\n  PopCleanupBlocks(EHScopeStack::stable_iterator OldCleanupStackSize,\n                   std::initializer_list<llvm::Value **> ValuesToReload = {});\n\n  /// Takes the old cleanup stack size and emits the cleanup blocks\n  /// that have been added, then adds all lifetime-extended cleanups from\n  /// the given position to the stack.\n  void\n  PopCleanupBlocks(EHScopeStack::stable_iterator OldCleanupStackSize,\n                   size_t OldLifetimeExtendedStackSize,\n                   std::initializer_list<llvm::Value **> ValuesToReload = {});\n\n  void ResolveBranchFixups(llvm::BasicBlock *Target);\n\n  /// The given basic block lies in the current EH scope, but may be a\n  /// target of a potentially scope-crossing jump; get a stable handle\n  /// to which we can perform this jump later.\n  JumpDest getJumpDestInCurrentScope(llvm::BasicBlock *Target) {\n    return JumpDest(Target,\n                    EHStack.getInnermostNormalCleanup(),\n                    NextCleanupDestIndex++);\n  }\n\n  /// The given basic block lies in the current EH scope, but may be a\n  /// target of a potentially scope-crossing jump; get a stable handle\n  /// to which we can perform this jump later.\n  JumpDest getJumpDestInCurrentScope(StringRef Name = StringRef()) {\n    return getJumpDestInCurrentScope(createBasicBlock(Name));\n  }\n\n  /// EmitBranchThroughCleanup - Emit a branch from the current insert\n  /// block through the normal cleanup handling code (if any) and then\n  /// on to \\arg Dest.\n  void EmitBranchThroughCleanup(JumpDest Dest);\n\n  /// isObviouslyBranchWithoutCleanups - Return true if a branch to the\n  /// specified destination obviously has no cleanups to run.  'false' is always\n  /// a conservatively correct answer for this method.\n  bool isObviouslyBranchWithoutCleanups(JumpDest Dest) const;\n\n  /// popCatchScope - Pops the catch scope at the top of the EHScope\n  /// stack, emitting any required code (other than the catch handlers\n  /// themselves).\n  void popCatchScope();\n\n  llvm::BasicBlock *getEHResumeBlock(bool isCleanup);\n  llvm::BasicBlock *getEHDispatchBlock(EHScopeStack::stable_iterator scope);\n  llvm::BasicBlock *\n  getFuncletEHDispatchBlock(EHScopeStack::stable_iterator scope);\n\n  /// An object to manage conditionally-evaluated expressions.\n  class ConditionalEvaluation {\n    llvm::BasicBlock *StartBB;\n\n  public:\n    ConditionalEvaluation(CodeGenFunction &CGF)\n      : StartBB(CGF.Builder.GetInsertBlock()) {}\n\n    void begin(CodeGenFunction &CGF) {\n      assert(CGF.OutermostConditional != this);\n      if (!CGF.OutermostConditional)\n        CGF.OutermostConditional = this;\n    }\n\n    void end(CodeGenFunction &CGF) {\n      assert(CGF.OutermostConditional != nullptr);\n      if (CGF.OutermostConditional == this)\n        CGF.OutermostConditional = nullptr;\n    }\n\n    /// Returns a block which will be executed prior to each\n    /// evaluation of the conditional code.\n    llvm::BasicBlock *getStartingBlock() const {\n      return StartBB;\n    }\n  };\n\n  /// isInConditionalBranch - Return true if we're currently emitting\n  /// one branch or the other of a conditional expression.\n  bool isInConditionalBranch() const { return OutermostConditional != nullptr; }\n\n  void setBeforeOutermostConditional(llvm::Value *value, Address addr) {\n    assert(isInConditionalBranch());\n    llvm::BasicBlock *block = OutermostConditional->getStartingBlock();\n    auto store = new llvm::StoreInst(value, addr.getPointer(), &block->back());\n    store->setAlignment(addr.getAlignment().getAsAlign());\n  }\n\n  /// An RAII object to record that we're evaluating a statement\n  /// expression.\n  class StmtExprEvaluation {\n    CodeGenFunction &CGF;\n\n    /// We have to save the outermost conditional: cleanups in a\n    /// statement expression aren't conditional just because the\n    /// StmtExpr is.\n    ConditionalEvaluation *SavedOutermostConditional;\n\n  public:\n    StmtExprEvaluation(CodeGenFunction &CGF)\n      : CGF(CGF), SavedOutermostConditional(CGF.OutermostConditional) {\n      CGF.OutermostConditional = nullptr;\n    }\n\n    ~StmtExprEvaluation() {\n      CGF.OutermostConditional = SavedOutermostConditional;\n      CGF.EnsureInsertPoint();\n    }\n  };\n\n  /// An object which temporarily prevents a value from being\n  /// destroyed by aggressive peephole optimizations that assume that\n  /// all uses of a value have been realized in the IR.\n  class PeepholeProtection {\n    llvm::Instruction *Inst;\n    friend class CodeGenFunction;\n\n  public:\n    PeepholeProtection() : Inst(nullptr) {}\n  };\n\n  /// A non-RAII class containing all the information about a bound\n  /// opaque value.  OpaqueValueMapping, below, is a RAII wrapper for\n  /// this which makes individual mappings very simple; using this\n  /// class directly is useful when you have a variable number of\n  /// opaque values or don't want the RAII functionality for some\n  /// reason.\n  class OpaqueValueMappingData {\n    const OpaqueValueExpr *OpaqueValue;\n    bool BoundLValue;\n    CodeGenFunction::PeepholeProtection Protection;\n\n    OpaqueValueMappingData(const OpaqueValueExpr *ov,\n                           bool boundLValue)\n      : OpaqueValue(ov), BoundLValue(boundLValue) {}\n  public:\n    OpaqueValueMappingData() : OpaqueValue(nullptr) {}\n\n    static bool shouldBindAsLValue(const Expr *expr) {\n      // gl-values should be bound as l-values for obvious reasons.\n      // Records should be bound as l-values because IR generation\n      // always keeps them in memory.  Expressions of function type\n      // act exactly like l-values but are formally required to be\n      // r-values in C.\n      return expr->isGLValue() ||\n             expr->getType()->isFunctionType() ||\n             hasAggregateEvaluationKind(expr->getType());\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const Expr *e) {\n      if (shouldBindAsLValue(ov))\n        return bind(CGF, ov, CGF.EmitLValue(e));\n      return bind(CGF, ov, CGF.EmitAnyExpr(e));\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const LValue &lv) {\n      assert(shouldBindAsLValue(ov));\n      CGF.OpaqueLValues.insert(std::make_pair(ov, lv));\n      return OpaqueValueMappingData(ov, true);\n    }\n\n    static OpaqueValueMappingData bind(CodeGenFunction &CGF,\n                                       const OpaqueValueExpr *ov,\n                                       const RValue &rv) {\n      assert(!shouldBindAsLValue(ov));\n      CGF.OpaqueRValues.insert(std::make_pair(ov, rv));\n\n      OpaqueValueMappingData data(ov, false);\n\n      // Work around an extremely aggressive peephole optimization in\n      // EmitScalarConversion which assumes that all other uses of a\n      // value are extant.\n      data.Protection = CGF.protectFromPeepholes(rv);\n\n      return data;\n    }\n\n    bool isValid() const { return OpaqueValue != nullptr; }\n    void clear() { OpaqueValue = nullptr; }\n\n    void unbind(CodeGenFunction &CGF) {\n      assert(OpaqueValue && \"no data to unbind!\");\n\n      if (BoundLValue) {\n        CGF.OpaqueLValues.erase(OpaqueValue);\n      } else {\n        CGF.OpaqueRValues.erase(OpaqueValue);\n        CGF.unprotectFromPeepholes(Protection);\n      }\n    }\n  };\n\n  /// An RAII object to set (and then clear) a mapping for an OpaqueValueExpr.\n  class OpaqueValueMapping {\n    CodeGenFunction &CGF;\n    OpaqueValueMappingData Data;\n\n  public:\n    static bool shouldBindAsLValue(const Expr *expr) {\n      return OpaqueValueMappingData::shouldBindAsLValue(expr);\n    }\n\n    /// Build the opaque value mapping for the given conditional\n    /// operator if it's the GNU ?: extension.  This is a common\n    /// enough pattern that the convenience operator is really\n    /// helpful.\n    ///\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const AbstractConditionalOperator *op) : CGF(CGF) {\n      if (isa<ConditionalOperator>(op))\n        // Leave Data empty.\n        return;\n\n      const BinaryConditionalOperator *e = cast<BinaryConditionalOperator>(op);\n      Data = OpaqueValueMappingData::bind(CGF, e->getOpaqueValue(),\n                                          e->getCommon());\n    }\n\n    /// Build the opaque value mapping for an OpaqueValueExpr whose source\n    /// expression is set to the expression the OVE represents.\n    OpaqueValueMapping(CodeGenFunction &CGF, const OpaqueValueExpr *OV)\n        : CGF(CGF) {\n      if (OV) {\n        assert(OV->getSourceExpr() && \"wrong form of OpaqueValueMapping used \"\n                                      \"for OVE with no source expression\");\n        Data = OpaqueValueMappingData::bind(CGF, OV, OV->getSourceExpr());\n      }\n    }\n\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const OpaqueValueExpr *opaqueValue,\n                       LValue lvalue)\n      : CGF(CGF), Data(OpaqueValueMappingData::bind(CGF, opaqueValue, lvalue)) {\n    }\n\n    OpaqueValueMapping(CodeGenFunction &CGF,\n                       const OpaqueValueExpr *opaqueValue,\n                       RValue rvalue)\n      : CGF(CGF), Data(OpaqueValueMappingData::bind(CGF, opaqueValue, rvalue)) {\n    }\n\n    void pop() {\n      Data.unbind(CGF);\n      Data.clear();\n    }\n\n    ~OpaqueValueMapping() {\n      if (Data.isValid()) Data.unbind(CGF);\n    }\n  };\n\nprivate:\n  CGDebugInfo *DebugInfo;\n  /// Used to create unique names for artificial VLA size debug info variables.\n  unsigned VLAExprCounter = 0;\n  bool DisableDebugInfo = false;\n\n  /// DidCallStackSave - Whether llvm.stacksave has been called. Used to avoid\n  /// calling llvm.stacksave for multiple VLAs in the same scope.\n  bool DidCallStackSave = false;\n\n  /// IndirectBranch - The first time an indirect goto is seen we create a block\n  /// with an indirect branch.  Every time we see the address of a label taken,\n  /// we add the label to the indirect goto.  Every subsequent indirect goto is\n  /// codegen'd as a jump to the IndirectBranch's basic block.\n  llvm::IndirectBrInst *IndirectBranch = nullptr;\n\n  /// LocalDeclMap - This keeps track of the LLVM allocas or globals for local C\n  /// decls.\n  DeclMapTy LocalDeclMap;\n\n  // Keep track of the cleanups for callee-destructed parameters pushed to the\n  // cleanup stack so that they can be deactivated later.\n  llvm::DenseMap<const ParmVarDecl *, EHScopeStack::stable_iterator>\n      CalleeDestructedParamCleanups;\n\n  /// SizeArguments - If a ParmVarDecl had the pass_object_size attribute, this\n  /// will contain a mapping from said ParmVarDecl to its implicit \"object_size\"\n  /// parameter.\n  llvm::SmallDenseMap<const ParmVarDecl *, const ImplicitParamDecl *, 2>\n      SizeArguments;\n\n  /// Track escaped local variables with auto storage. Used during SEH\n  /// outlining to produce a call to llvm.localescape.\n  llvm::DenseMap<llvm::AllocaInst *, int> EscapedLocals;\n\n  /// LabelMap - This keeps track of the LLVM basic block for each C label.\n  llvm::DenseMap<const LabelDecl*, JumpDest> LabelMap;\n\n  // BreakContinueStack - This keeps track of where break and continue\n  // statements should jump to.\n  struct BreakContinue {\n    BreakContinue(JumpDest Break, JumpDest Continue)\n      : BreakBlock(Break), ContinueBlock(Continue) {}\n\n    JumpDest BreakBlock;\n    JumpDest ContinueBlock;\n  };\n  SmallVector<BreakContinue, 8> BreakContinueStack;\n\n  /// Handles cancellation exit points in OpenMP-related constructs.\n  class OpenMPCancelExitStack {\n    /// Tracks cancellation exit point and join point for cancel-related exit\n    /// and normal exit.\n    struct CancelExit {\n      CancelExit() = default;\n      CancelExit(OpenMPDirectiveKind Kind, JumpDest ExitBlock,\n                 JumpDest ContBlock)\n          : Kind(Kind), ExitBlock(ExitBlock), ContBlock(ContBlock) {}\n      OpenMPDirectiveKind Kind = llvm::omp::OMPD_unknown;\n      /// true if the exit block has been emitted already by the special\n      /// emitExit() call, false if the default codegen is used.\n      bool HasBeenEmitted = false;\n      JumpDest ExitBlock;\n      JumpDest ContBlock;\n    };\n\n    SmallVector<CancelExit, 8> Stack;\n\n  public:\n    OpenMPCancelExitStack() : Stack(1) {}\n    ~OpenMPCancelExitStack() = default;\n    /// Fetches the exit block for the current OpenMP construct.\n    JumpDest getExitBlock() const { return Stack.back().ExitBlock; }\n    /// Emits exit block with special codegen procedure specific for the related\n    /// OpenMP construct + emits code for normal construct cleanup.\n    void emitExit(CodeGenFunction &CGF, OpenMPDirectiveKind Kind,\n                  const llvm::function_ref<void(CodeGenFunction &)> CodeGen) {\n      if (Stack.back().Kind == Kind && getExitBlock().isValid()) {\n        assert(CGF.getOMPCancelDestination(Kind).isValid());\n        assert(CGF.HaveInsertPoint());\n        assert(!Stack.back().HasBeenEmitted);\n        auto IP = CGF.Builder.saveAndClearIP();\n        CGF.EmitBlock(Stack.back().ExitBlock.getBlock());\n        CodeGen(CGF);\n        CGF.EmitBranch(Stack.back().ContBlock.getBlock());\n        CGF.Builder.restoreIP(IP);\n        Stack.back().HasBeenEmitted = true;\n      }\n      CodeGen(CGF);\n    }\n    /// Enter the cancel supporting \\a Kind construct.\n    /// \\param Kind OpenMP directive that supports cancel constructs.\n    /// \\param HasCancel true, if the construct has inner cancel directive,\n    /// false otherwise.\n    void enter(CodeGenFunction &CGF, OpenMPDirectiveKind Kind, bool HasCancel) {\n      Stack.push_back({Kind,\n                       HasCancel ? CGF.getJumpDestInCurrentScope(\"cancel.exit\")\n                                 : JumpDest(),\n                       HasCancel ? CGF.getJumpDestInCurrentScope(\"cancel.cont\")\n                                 : JumpDest()});\n    }\n    /// Emits default exit point for the cancel construct (if the special one\n    /// has not be used) + join point for cancel/normal exits.\n    void exit(CodeGenFunction &CGF) {\n      if (getExitBlock().isValid()) {\n        assert(CGF.getOMPCancelDestination(Stack.back().Kind).isValid());\n        bool HaveIP = CGF.HaveInsertPoint();\n        if (!Stack.back().HasBeenEmitted) {\n          if (HaveIP)\n            CGF.EmitBranchThroughCleanup(Stack.back().ContBlock);\n          CGF.EmitBlock(Stack.back().ExitBlock.getBlock());\n          CGF.EmitBranchThroughCleanup(Stack.back().ContBlock);\n        }\n        CGF.EmitBlock(Stack.back().ContBlock.getBlock());\n        if (!HaveIP) {\n          CGF.Builder.CreateUnreachable();\n          CGF.Builder.ClearInsertionPoint();\n        }\n      }\n      Stack.pop_back();\n    }\n  };\n  OpenMPCancelExitStack OMPCancelStack;\n\n  /// Calculate branch weights for the likelihood attribute\n  llvm::MDNode *createBranchWeights(Stmt::Likelihood LH) const;\n\n  CodeGenPGO PGO;\n\n  /// Calculate branch weights appropriate for PGO data\n  llvm::MDNode *createProfileWeights(uint64_t TrueCount,\n                                     uint64_t FalseCount) const;\n  llvm::MDNode *createProfileWeights(ArrayRef<uint64_t> Weights) const;\n  llvm::MDNode *createProfileWeightsForLoop(const Stmt *Cond,\n                                            uint64_t LoopCount) const;\n\n  /// Calculate the branch weight for PGO data or the likelihood attribute.\n  /// The function tries to get the weight of \\ref createProfileWeightsForLoop.\n  /// If that fails it gets the weight of \\ref createBranchWeights.\n  llvm::MDNode *createProfileOrBranchWeightsForLoop(const Stmt *Cond,\n                                                    uint64_t LoopCount,\n                                                    const Stmt *Body) const;\n\npublic:\n  /// Increment the profiler's counter for the given statement by \\p StepV.\n  /// If \\p StepV is null, the default increment is 1.\n  void incrementProfileCounter(const Stmt *S, llvm::Value *StepV = nullptr) {\n    if (CGM.getCodeGenOpts().hasProfileClangInstr() &&\n        !CurFn->hasFnAttribute(llvm::Attribute::NoProfile))\n      PGO.emitCounterIncrement(Builder, S, StepV);\n    PGO.setCurrentStmt(S);\n  }\n\n  /// Get the profiler's count for the given statement.\n  uint64_t getProfileCount(const Stmt *S) {\n    Optional<uint64_t> Count = PGO.getStmtCount(S);\n    if (!Count.hasValue())\n      return 0;\n    return *Count;\n  }\n\n  /// Set the profiler's current count.\n  void setCurrentProfileCount(uint64_t Count) {\n    PGO.setCurrentRegionCount(Count);\n  }\n\n  /// Get the profiler's current count. This is generally the count for the most\n  /// recently incremented counter.\n  uint64_t getCurrentProfileCount() {\n    return PGO.getCurrentRegionCount();\n  }\n\nprivate:\n\n  /// SwitchInsn - This is nearest current switch instruction. It is null if\n  /// current context is not in a switch.\n  llvm::SwitchInst *SwitchInsn = nullptr;\n  /// The branch weights of SwitchInsn when doing instrumentation based PGO.\n  SmallVector<uint64_t, 16> *SwitchWeights = nullptr;\n\n  /// The likelihood attributes of the SwitchCase.\n  SmallVector<Stmt::Likelihood, 16> *SwitchLikelihood = nullptr;\n\n  /// CaseRangeBlock - This block holds if condition check for last case\n  /// statement range in current switch instruction.\n  llvm::BasicBlock *CaseRangeBlock = nullptr;\n\n  /// OpaqueLValues - Keeps track of the current set of opaque value\n  /// expressions.\n  llvm::DenseMap<const OpaqueValueExpr *, LValue> OpaqueLValues;\n  llvm::DenseMap<const OpaqueValueExpr *, RValue> OpaqueRValues;\n\n  // VLASizeMap - This keeps track of the associated size for each VLA type.\n  // We track this by the size expression rather than the type itself because\n  // in certain situations, like a const qualifier applied to an VLA typedef,\n  // multiple VLA types can share the same size expression.\n  // FIXME: Maybe this could be a stack of maps that is pushed/popped as we\n  // enter/leave scopes.\n  llvm::DenseMap<const Expr*, llvm::Value*> VLASizeMap;\n\n  /// A block containing a single 'unreachable' instruction.  Created\n  /// lazily by getUnreachableBlock().\n  llvm::BasicBlock *UnreachableBlock = nullptr;\n\n  /// Counts of the number return expressions in the function.\n  unsigned NumReturnExprs = 0;\n\n  /// Count the number of simple (constant) return expressions in the function.\n  unsigned NumSimpleReturnExprs = 0;\n\n  /// The last regular (non-return) debug location (breakpoint) in the function.\n  SourceLocation LastStopPoint;\n\npublic:\n  /// Source location information about the default argument or member\n  /// initializer expression we're evaluating, if any.\n  CurrentSourceLocExprScope CurSourceLocExprScope;\n  using SourceLocExprScopeGuard =\n      CurrentSourceLocExprScope::SourceLocExprScopeGuard;\n\n  /// A scope within which we are constructing the fields of an object which\n  /// might use a CXXDefaultInitExpr. This stashes away a 'this' value to use\n  /// if we need to evaluate a CXXDefaultInitExpr within the evaluation.\n  class FieldConstructionScope {\n  public:\n    FieldConstructionScope(CodeGenFunction &CGF, Address This)\n        : CGF(CGF), OldCXXDefaultInitExprThis(CGF.CXXDefaultInitExprThis) {\n      CGF.CXXDefaultInitExprThis = This;\n    }\n    ~FieldConstructionScope() {\n      CGF.CXXDefaultInitExprThis = OldCXXDefaultInitExprThis;\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    Address OldCXXDefaultInitExprThis;\n  };\n\n  /// The scope of a CXXDefaultInitExpr. Within this scope, the value of 'this'\n  /// is overridden to be the object under construction.\n  class CXXDefaultInitExprScope  {\n  public:\n    CXXDefaultInitExprScope(CodeGenFunction &CGF, const CXXDefaultInitExpr *E)\n        : CGF(CGF), OldCXXThisValue(CGF.CXXThisValue),\n          OldCXXThisAlignment(CGF.CXXThisAlignment),\n          SourceLocScope(E, CGF.CurSourceLocExprScope) {\n      CGF.CXXThisValue = CGF.CXXDefaultInitExprThis.getPointer();\n      CGF.CXXThisAlignment = CGF.CXXDefaultInitExprThis.getAlignment();\n    }\n    ~CXXDefaultInitExprScope() {\n      CGF.CXXThisValue = OldCXXThisValue;\n      CGF.CXXThisAlignment = OldCXXThisAlignment;\n    }\n\n  public:\n    CodeGenFunction &CGF;\n    llvm::Value *OldCXXThisValue;\n    CharUnits OldCXXThisAlignment;\n    SourceLocExprScopeGuard SourceLocScope;\n  };\n\n  struct CXXDefaultArgExprScope : SourceLocExprScopeGuard {\n    CXXDefaultArgExprScope(CodeGenFunction &CGF, const CXXDefaultArgExpr *E)\n        : SourceLocExprScopeGuard(E, CGF.CurSourceLocExprScope) {}\n  };\n\n  /// The scope of an ArrayInitLoopExpr. Within this scope, the value of the\n  /// current loop index is overridden.\n  class ArrayInitLoopExprScope {\n  public:\n    ArrayInitLoopExprScope(CodeGenFunction &CGF, llvm::Value *Index)\n      : CGF(CGF), OldArrayInitIndex(CGF.ArrayInitIndex) {\n      CGF.ArrayInitIndex = Index;\n    }\n    ~ArrayInitLoopExprScope() {\n      CGF.ArrayInitIndex = OldArrayInitIndex;\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    llvm::Value *OldArrayInitIndex;\n  };\n\n  class InlinedInheritingConstructorScope {\n  public:\n    InlinedInheritingConstructorScope(CodeGenFunction &CGF, GlobalDecl GD)\n        : CGF(CGF), OldCurGD(CGF.CurGD), OldCurFuncDecl(CGF.CurFuncDecl),\n          OldCurCodeDecl(CGF.CurCodeDecl),\n          OldCXXABIThisDecl(CGF.CXXABIThisDecl),\n          OldCXXABIThisValue(CGF.CXXABIThisValue),\n          OldCXXThisValue(CGF.CXXThisValue),\n          OldCXXABIThisAlignment(CGF.CXXABIThisAlignment),\n          OldCXXThisAlignment(CGF.CXXThisAlignment),\n          OldReturnValue(CGF.ReturnValue), OldFnRetTy(CGF.FnRetTy),\n          OldCXXInheritedCtorInitExprArgs(\n              std::move(CGF.CXXInheritedCtorInitExprArgs)) {\n      CGF.CurGD = GD;\n      CGF.CurFuncDecl = CGF.CurCodeDecl =\n          cast<CXXConstructorDecl>(GD.getDecl());\n      CGF.CXXABIThisDecl = nullptr;\n      CGF.CXXABIThisValue = nullptr;\n      CGF.CXXThisValue = nullptr;\n      CGF.CXXABIThisAlignment = CharUnits();\n      CGF.CXXThisAlignment = CharUnits();\n      CGF.ReturnValue = Address::invalid();\n      CGF.FnRetTy = QualType();\n      CGF.CXXInheritedCtorInitExprArgs.clear();\n    }\n    ~InlinedInheritingConstructorScope() {\n      CGF.CurGD = OldCurGD;\n      CGF.CurFuncDecl = OldCurFuncDecl;\n      CGF.CurCodeDecl = OldCurCodeDecl;\n      CGF.CXXABIThisDecl = OldCXXABIThisDecl;\n      CGF.CXXABIThisValue = OldCXXABIThisValue;\n      CGF.CXXThisValue = OldCXXThisValue;\n      CGF.CXXABIThisAlignment = OldCXXABIThisAlignment;\n      CGF.CXXThisAlignment = OldCXXThisAlignment;\n      CGF.ReturnValue = OldReturnValue;\n      CGF.FnRetTy = OldFnRetTy;\n      CGF.CXXInheritedCtorInitExprArgs =\n          std::move(OldCXXInheritedCtorInitExprArgs);\n    }\n\n  private:\n    CodeGenFunction &CGF;\n    GlobalDecl OldCurGD;\n    const Decl *OldCurFuncDecl;\n    const Decl *OldCurCodeDecl;\n    ImplicitParamDecl *OldCXXABIThisDecl;\n    llvm::Value *OldCXXABIThisValue;\n    llvm::Value *OldCXXThisValue;\n    CharUnits OldCXXABIThisAlignment;\n    CharUnits OldCXXThisAlignment;\n    Address OldReturnValue;\n    QualType OldFnRetTy;\n    CallArgList OldCXXInheritedCtorInitExprArgs;\n  };\n\n  // Helper class for the OpenMP IR Builder. Allows reusability of code used for\n  // region body, and finalization codegen callbacks. This will class will also\n  // contain privatization functions used by the privatization call backs\n  //\n  // TODO: this is temporary class for things that are being moved out of\n  // CGOpenMPRuntime, new versions of current CodeGenFunction methods, or\n  // utility function for use with the OMPBuilder. Once that move to use the\n  // OMPBuilder is done, everything here will either become part of CodeGenFunc.\n  // directly, or a new helper class that will contain functions used by both\n  // this and the OMPBuilder\n\n  struct OMPBuilderCBHelpers {\n\n    OMPBuilderCBHelpers() = delete;\n    OMPBuilderCBHelpers(const OMPBuilderCBHelpers &) = delete;\n    OMPBuilderCBHelpers &operator=(const OMPBuilderCBHelpers &) = delete;\n\n    using InsertPointTy = llvm::OpenMPIRBuilder::InsertPointTy;\n\n    /// Cleanup action for allocate support.\n    class OMPAllocateCleanupTy final : public EHScopeStack::Cleanup {\n\n    private:\n      llvm::CallInst *RTLFnCI;\n\n    public:\n      OMPAllocateCleanupTy(llvm::CallInst *RLFnCI) : RTLFnCI(RLFnCI) {\n        RLFnCI->removeFromParent();\n      }\n\n      void Emit(CodeGenFunction &CGF, Flags /*flags*/) override {\n        if (!CGF.HaveInsertPoint())\n          return;\n        CGF.Builder.Insert(RTLFnCI);\n      }\n    };\n\n    /// Returns address of the threadprivate variable for the current\n    /// thread. This Also create any necessary OMP runtime calls.\n    ///\n    /// \\param VD VarDecl for Threadprivate variable.\n    /// \\param VDAddr Address of the Vardecl\n    /// \\param Loc  The location where the barrier directive was encountered\n    static Address getAddrOfThreadPrivate(CodeGenFunction &CGF,\n                                          const VarDecl *VD, Address VDAddr,\n                                          SourceLocation Loc);\n\n    /// Gets the OpenMP-specific address of the local variable /p VD.\n    static Address getAddressOfLocalVariable(CodeGenFunction &CGF,\n                                             const VarDecl *VD);\n    /// Get the platform-specific name separator.\n    /// \\param Parts different parts of the final name that needs separation\n    /// \\param FirstSeparator First separator used between the initial two\n    ///        parts of the name.\n    /// \\param Separator separator used between all of the rest consecutinve\n    ///        parts of the name\n    static std::string getNameWithSeparators(ArrayRef<StringRef> Parts,\n                                             StringRef FirstSeparator = \".\",\n                                             StringRef Separator = \".\");\n    /// Emit the Finalization for an OMP region\n    /// \\param CGF\tThe Codegen function this belongs to\n    /// \\param IP\tInsertion point for generating the finalization code.\n    static void FinalizeOMPRegion(CodeGenFunction &CGF, InsertPointTy IP) {\n      CGBuilderTy::InsertPointGuard IPG(CGF.Builder);\n      assert(IP.getBlock()->end() != IP.getPoint() &&\n             \"OpenMP IR Builder should cause terminated block!\");\n\n      llvm::BasicBlock *IPBB = IP.getBlock();\n      llvm::BasicBlock *DestBB = IPBB->getUniqueSuccessor();\n      assert(DestBB && \"Finalization block should have one successor!\");\n\n      // erase and replace with cleanup branch.\n      IPBB->getTerminator()->eraseFromParent();\n      CGF.Builder.SetInsertPoint(IPBB);\n      CodeGenFunction::JumpDest Dest = CGF.getJumpDestInCurrentScope(DestBB);\n      CGF.EmitBranchThroughCleanup(Dest);\n    }\n\n    /// Emit the body of an OMP region\n    /// \\param CGF\tThe Codegen function this belongs to\n    /// \\param RegionBodyStmt\tThe body statement for the OpenMP region being\n    /// \t\t\t generated\n    /// \\param CodeGenIP\tInsertion point for generating the body code.\n    /// \\param FiniBB\tThe finalization basic block\n    static void EmitOMPRegionBody(CodeGenFunction &CGF,\n                                  const Stmt *RegionBodyStmt,\n                                  InsertPointTy CodeGenIP,\n                                  llvm::BasicBlock &FiniBB) {\n      llvm::BasicBlock *CodeGenIPBB = CodeGenIP.getBlock();\n      if (llvm::Instruction *CodeGenIPBBTI = CodeGenIPBB->getTerminator())\n        CodeGenIPBBTI->eraseFromParent();\n\n      CGF.Builder.SetInsertPoint(CodeGenIPBB);\n\n      CGF.EmitStmt(RegionBodyStmt);\n\n      if (CGF.Builder.saveIP().isSet())\n        CGF.Builder.CreateBr(&FiniBB);\n    }\n\n    /// RAII for preserving necessary info during Outlined region body codegen.\n    class OutlinedRegionBodyRAII {\n\n      llvm::AssertingVH<llvm::Instruction> OldAllocaIP;\n      CodeGenFunction::JumpDest OldReturnBlock;\n      CGBuilderTy::InsertPoint IP;\n      CodeGenFunction &CGF;\n\n    public:\n      OutlinedRegionBodyRAII(CodeGenFunction &cgf, InsertPointTy &AllocaIP,\n                             llvm::BasicBlock &RetBB)\n          : CGF(cgf) {\n        assert(AllocaIP.isSet() &&\n               \"Must specify Insertion point for allocas of outlined function\");\n        OldAllocaIP = CGF.AllocaInsertPt;\n        CGF.AllocaInsertPt = &*AllocaIP.getPoint();\n        IP = CGF.Builder.saveIP();\n\n        OldReturnBlock = CGF.ReturnBlock;\n        CGF.ReturnBlock = CGF.getJumpDestInCurrentScope(&RetBB);\n      }\n\n      ~OutlinedRegionBodyRAII() {\n        CGF.AllocaInsertPt = OldAllocaIP;\n        CGF.ReturnBlock = OldReturnBlock;\n        CGF.Builder.restoreIP(IP);\n      }\n    };\n\n    /// RAII for preserving necessary info during inlined region body codegen.\n    class InlinedRegionBodyRAII {\n\n      llvm::AssertingVH<llvm::Instruction> OldAllocaIP;\n      CodeGenFunction &CGF;\n\n    public:\n      InlinedRegionBodyRAII(CodeGenFunction &cgf, InsertPointTy &AllocaIP,\n                            llvm::BasicBlock &FiniBB)\n          : CGF(cgf) {\n        // Alloca insertion block should be in the entry block of the containing\n        // function so it expects an empty AllocaIP in which case will reuse the\n        // old alloca insertion point, or a new AllocaIP in the same block as\n        // the old one\n        assert((!AllocaIP.isSet() ||\n                CGF.AllocaInsertPt->getParent() == AllocaIP.getBlock()) &&\n               \"Insertion point should be in the entry block of containing \"\n               \"function!\");\n        OldAllocaIP = CGF.AllocaInsertPt;\n        if (AllocaIP.isSet())\n          CGF.AllocaInsertPt = &*AllocaIP.getPoint();\n\n        // TODO: Remove the call, after making sure the counter is not used by\n        //       the EHStack.\n        // Since this is an inlined region, it should not modify the\n        // ReturnBlock, and should reuse the one for the enclosing outlined\n        // region. So, the JumpDest being return by the function is discarded\n        (void)CGF.getJumpDestInCurrentScope(&FiniBB);\n      }\n\n      ~InlinedRegionBodyRAII() { CGF.AllocaInsertPt = OldAllocaIP; }\n    };\n  };\n\nprivate:\n  /// CXXThisDecl - When generating code for a C++ member function,\n  /// this will hold the implicit 'this' declaration.\n  ImplicitParamDecl *CXXABIThisDecl = nullptr;\n  llvm::Value *CXXABIThisValue = nullptr;\n  llvm::Value *CXXThisValue = nullptr;\n  CharUnits CXXABIThisAlignment;\n  CharUnits CXXThisAlignment;\n\n  /// The value of 'this' to use when evaluating CXXDefaultInitExprs within\n  /// this expression.\n  Address CXXDefaultInitExprThis = Address::invalid();\n\n  /// The current array initialization index when evaluating an\n  /// ArrayInitIndexExpr within an ArrayInitLoopExpr.\n  llvm::Value *ArrayInitIndex = nullptr;\n\n  /// The values of function arguments to use when evaluating\n  /// CXXInheritedCtorInitExprs within this context.\n  CallArgList CXXInheritedCtorInitExprArgs;\n\n  /// CXXStructorImplicitParamDecl - When generating code for a constructor or\n  /// destructor, this will hold the implicit argument (e.g. VTT).\n  ImplicitParamDecl *CXXStructorImplicitParamDecl = nullptr;\n  llvm::Value *CXXStructorImplicitParamValue = nullptr;\n\n  /// OutermostConditional - Points to the outermost active\n  /// conditional control.  This is used so that we know if a\n  /// temporary should be destroyed conditionally.\n  ConditionalEvaluation *OutermostConditional = nullptr;\n\n  /// The current lexical scope.\n  LexicalScope *CurLexicalScope = nullptr;\n\n  /// The current source location that should be used for exception\n  /// handling code.\n  SourceLocation CurEHLocation;\n\n  /// BlockByrefInfos - For each __block variable, contains\n  /// information about the layout of the variable.\n  llvm::DenseMap<const ValueDecl *, BlockByrefInfo> BlockByrefInfos;\n\n  /// Used by -fsanitize=nullability-return to determine whether the return\n  /// value can be checked.\n  llvm::Value *RetValNullabilityPrecondition = nullptr;\n\n  /// Check if -fsanitize=nullability-return instrumentation is required for\n  /// this function.\n  bool requiresReturnValueNullabilityCheck() const {\n    return RetValNullabilityPrecondition;\n  }\n\n  /// Used to store precise source locations for return statements by the\n  /// runtime return value checks.\n  Address ReturnLocation = Address::invalid();\n\n  /// Check if the return value of this function requires sanitization.\n  bool requiresReturnValueCheck() const;\n\n  llvm::BasicBlock *TerminateLandingPad = nullptr;\n  llvm::BasicBlock *TerminateHandler = nullptr;\n  llvm::SmallVector<llvm::BasicBlock *, 2> TrapBBs;\n\n  /// Terminate funclets keyed by parent funclet pad.\n  llvm::MapVector<llvm::Value *, llvm::BasicBlock *> TerminateFunclets;\n\n  /// Largest vector width used in ths function. Will be used to create a\n  /// function attribute.\n  unsigned LargestVectorWidth = 0;\n\n  /// True if we need emit the life-time markers.\n  const bool ShouldEmitLifetimeMarkers;\n\n  /// Add OpenCL kernel arg metadata and the kernel attribute metadata to\n  /// the function metadata.\n  void EmitOpenCLKernelMetadata(const FunctionDecl *FD,\n                                llvm::Function *Fn);\n\npublic:\n  CodeGenFunction(CodeGenModule &cgm, bool suppressNewContext=false);\n  ~CodeGenFunction();\n\n  CodeGenTypes &getTypes() const { return CGM.getTypes(); }\n  ASTContext &getContext() const { return CGM.getContext(); }\n  CGDebugInfo *getDebugInfo() {\n    if (DisableDebugInfo)\n      return nullptr;\n    return DebugInfo;\n  }\n  void disableDebugInfo() { DisableDebugInfo = true; }\n  void enableDebugInfo() { DisableDebugInfo = false; }\n\n  bool shouldUseFusedARCCalls() {\n    return CGM.getCodeGenOpts().OptimizationLevel == 0;\n  }\n\n  const LangOptions &getLangOpts() const { return CGM.getLangOpts(); }\n\n  /// Returns a pointer to the function's exception object and selector slot,\n  /// which is assigned in every landing pad.\n  Address getExceptionSlot();\n  Address getEHSelectorSlot();\n\n  /// Returns the contents of the function's exception object and selector\n  /// slots.\n  llvm::Value *getExceptionFromSlot();\n  llvm::Value *getSelectorFromSlot();\n\n  Address getNormalCleanupDestSlot();\n\n  llvm::BasicBlock *getUnreachableBlock() {\n    if (!UnreachableBlock) {\n      UnreachableBlock = createBasicBlock(\"unreachable\");\n      new llvm::UnreachableInst(getLLVMContext(), UnreachableBlock);\n    }\n    return UnreachableBlock;\n  }\n\n  llvm::BasicBlock *getInvokeDest() {\n    if (!EHStack.requiresLandingPad()) return nullptr;\n    return getInvokeDestImpl();\n  }\n\n  bool currentFunctionUsesSEHTry() const { return CurSEHParent != nullptr; }\n\n  const TargetInfo &getTarget() const { return Target; }\n  llvm::LLVMContext &getLLVMContext() { return CGM.getLLVMContext(); }\n  const TargetCodeGenInfo &getTargetHooks() const {\n    return CGM.getTargetCodeGenInfo();\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                                  Cleanups\n  //===--------------------------------------------------------------------===//\n\n  typedef void Destroyer(CodeGenFunction &CGF, Address addr, QualType ty);\n\n  void pushIrregularPartialArrayCleanup(llvm::Value *arrayBegin,\n                                        Address arrayEndPointer,\n                                        QualType elementType,\n                                        CharUnits elementAlignment,\n                                        Destroyer *destroyer);\n  void pushRegularPartialArrayCleanup(llvm::Value *arrayBegin,\n                                      llvm::Value *arrayEnd,\n                                      QualType elementType,\n                                      CharUnits elementAlignment,\n                                      Destroyer *destroyer);\n\n  void pushDestroy(QualType::DestructionKind dtorKind,\n                   Address addr, QualType type);\n  void pushEHDestroy(QualType::DestructionKind dtorKind,\n                     Address addr, QualType type);\n  void pushDestroy(CleanupKind kind, Address addr, QualType type,\n                   Destroyer *destroyer, bool useEHCleanupForArray);\n  void pushLifetimeExtendedDestroy(CleanupKind kind, Address addr,\n                                   QualType type, Destroyer *destroyer,\n                                   bool useEHCleanupForArray);\n  void pushCallObjectDeleteCleanup(const FunctionDecl *OperatorDelete,\n                                   llvm::Value *CompletePtr,\n                                   QualType ElementType);\n  void pushStackRestore(CleanupKind kind, Address SPMem);\n  void emitDestroy(Address addr, QualType type, Destroyer *destroyer,\n                   bool useEHCleanupForArray);\n  llvm::Function *generateDestroyHelper(Address addr, QualType type,\n                                        Destroyer *destroyer,\n                                        bool useEHCleanupForArray,\n                                        const VarDecl *VD);\n  void emitArrayDestroy(llvm::Value *begin, llvm::Value *end,\n                        QualType elementType, CharUnits elementAlign,\n                        Destroyer *destroyer,\n                        bool checkZeroLength, bool useEHCleanup);\n\n  Destroyer *getDestroyer(QualType::DestructionKind destructionKind);\n\n  /// Determines whether an EH cleanup is required to destroy a type\n  /// with the given destruction kind.\n  bool needsEHCleanup(QualType::DestructionKind kind) {\n    switch (kind) {\n    case QualType::DK_none:\n      return false;\n    case QualType::DK_cxx_destructor:\n    case QualType::DK_objc_weak_lifetime:\n    case QualType::DK_nontrivial_c_struct:\n      return getLangOpts().Exceptions;\n    case QualType::DK_objc_strong_lifetime:\n      return getLangOpts().Exceptions &&\n             CGM.getCodeGenOpts().ObjCAutoRefCountExceptions;\n    }\n    llvm_unreachable(\"bad destruction kind\");\n  }\n\n  CleanupKind getCleanupKind(QualType::DestructionKind kind) {\n    return (needsEHCleanup(kind) ? NormalAndEHCleanup : NormalCleanup);\n  }\n\n  //===--------------------------------------------------------------------===//\n  //                                  Objective-C\n  //===--------------------------------------------------------------------===//\n\n  void GenerateObjCMethod(const ObjCMethodDecl *OMD);\n\n  void StartObjCMethod(const ObjCMethodDecl *MD, const ObjCContainerDecl *CD);\n\n  /// GenerateObjCGetter - Synthesize an Objective-C property getter function.\n  void GenerateObjCGetter(ObjCImplementationDecl *IMP,\n                          const ObjCPropertyImplDecl *PID);\n  void generateObjCGetterBody(const ObjCImplementationDecl *classImpl,\n                              const ObjCPropertyImplDecl *propImpl,\n                              const ObjCMethodDecl *GetterMothodDecl,\n                              llvm::Constant *AtomicHelperFn);\n\n  void GenerateObjCCtorDtorMethod(ObjCImplementationDecl *IMP,\n                                  ObjCMethodDecl *MD, bool ctor);\n\n  /// GenerateObjCSetter - Synthesize an Objective-C property setter function\n  /// for the given property.\n  void GenerateObjCSetter(ObjCImplementationDecl *IMP,\n                          const ObjCPropertyImplDecl *PID);\n  void generateObjCSetterBody(const ObjCImplementationDecl *classImpl,\n                              const ObjCPropertyImplDecl *propImpl,\n                              llvm::Constant *AtomicHelperFn);\n\n  //===--------------------------------------------------------------------===//\n  //                                  Block Bits\n  //===--------------------------------------------------------------------===//\n\n  /// Emit block literal.\n  /// \\return an LLVM value which is a pointer to a struct which contains\n  /// information about the block, including the block invoke function, the\n  /// captured variables, etc.\n  llvm::Value *EmitBlockLiteral(const BlockExpr *);\n\n  llvm::Function *GenerateBlockFunction(GlobalDecl GD,\n                                        const CGBlockInfo &Info,\n                                        const DeclMapTy &ldm,\n                                        bool IsLambdaConversionToBlock,\n                                        bool BuildGlobalBlock);\n\n  /// Check if \\p T is a C++ class that has a destructor that can throw.\n  static bool cxxDestructorCanThrow(QualType T);\n\n  llvm::Constant *GenerateCopyHelperFunction(const CGBlockInfo &blockInfo);\n  llvm::Constant *GenerateDestroyHelperFunction(const CGBlockInfo &blockInfo);\n  llvm::Constant *GenerateObjCAtomicSetterCopyHelperFunction(\n                                             const ObjCPropertyImplDecl *PID);\n  llvm::Constant *GenerateObjCAtomicGetterCopyHelperFunction(\n                                             const ObjCPropertyImplDecl *PID);\n  llvm::Value *EmitBlockCopyAndAutorelease(llvm::Value *Block, QualType Ty);\n\n  void BuildBlockRelease(llvm::Value *DeclPtr, BlockFieldFlags flags,\n                         bool CanThrow);\n\n  class AutoVarEmission;\n\n  void emitByrefStructureInit(const AutoVarEmission &emission);\n\n  /// Enter a cleanup to destroy a __block variable.  Note that this\n  /// cleanup should be a no-op if the variable hasn't left the stack\n  /// yet; if a cleanup is required for the variable itself, that needs\n  /// to be done externally.\n  ///\n  /// \\param Kind Cleanup kind.\n  ///\n  /// \\param Addr When \\p LoadBlockVarAddr is false, the address of the __block\n  /// structure that will be passed to _Block_object_dispose. When\n  /// \\p LoadBlockVarAddr is true, the address of the field of the block\n  /// structure that holds the address of the __block structure.\n  ///\n  /// \\param Flags The flag that will be passed to _Block_object_dispose.\n  ///\n  /// \\param LoadBlockVarAddr Indicates whether we need to emit a load from\n  /// \\p Addr to get the address of the __block structure.\n  void enterByrefCleanup(CleanupKind Kind, Address Addr, BlockFieldFlags Flags,\n                         bool LoadBlockVarAddr, bool CanThrow);\n\n  void setBlockContextParameter(const ImplicitParamDecl *D, unsigned argNum,\n                                llvm::Value *ptr);\n\n  Address LoadBlockStruct();\n  Address GetAddrOfBlockDecl(const VarDecl *var);\n\n  /// BuildBlockByrefAddress - Computes the location of the\n  /// data in a variable which is declared as __block.\n  Address emitBlockByrefAddress(Address baseAddr, const VarDecl *V,\n                                bool followForward = true);\n  Address emitBlockByrefAddress(Address baseAddr,\n                                const BlockByrefInfo &info,\n                                bool followForward,\n                                const llvm::Twine &name);\n\n  const BlockByrefInfo &getBlockByrefInfo(const VarDecl *var);\n\n  QualType BuildFunctionArgList(GlobalDecl GD, FunctionArgList &Args);\n\n  void GenerateCode(GlobalDecl GD, llvm::Function *Fn,\n                    const CGFunctionInfo &FnInfo);\n\n  /// Annotate the function with an attribute that disables TSan checking at\n  /// runtime.\n  void markAsIgnoreThreadCheckingAtRuntime(llvm::Function *Fn);\n\n  /// Emit code for the start of a function.\n  /// \\param Loc       The location to be associated with the function.\n  /// \\param StartLoc  The location of the function body.\n  void StartFunction(GlobalDecl GD,\n                     QualType RetTy,\n                     llvm::Function *Fn,\n                     const CGFunctionInfo &FnInfo,\n                     const FunctionArgList &Args,\n                     SourceLocation Loc = SourceLocation(),\n                     SourceLocation StartLoc = SourceLocation());\n\n  static bool IsConstructorDelegationValid(const CXXConstructorDecl *Ctor);\n\n  void EmitConstructorBody(FunctionArgList &Args);\n  void EmitDestructorBody(FunctionArgList &Args);\n  void emitImplicitAssignmentOperatorBody(FunctionArgList &Args);\n  void EmitFunctionBody(const Stmt *Body);\n  void EmitBlockWithFallThrough(llvm::BasicBlock *BB, const Stmt *S);\n\n  void EmitForwardingCallToLambda(const CXXMethodDecl *LambdaCallOperator,\n                                  CallArgList &CallArgs);\n  void EmitLambdaBlockInvokeBody();\n  void EmitLambdaDelegatingInvokeBody(const CXXMethodDecl *MD);\n  void EmitLambdaStaticInvokeBody(const CXXMethodDecl *MD);\n  void EmitLambdaVLACapture(const VariableArrayType *VAT, LValue LV) {\n    EmitStoreThroughLValue(RValue::get(VLASizeMap[VAT->getSizeExpr()]), LV);\n  }\n  void EmitAsanPrologueOrEpilogue(bool Prologue);\n\n  /// Emit the unified return block, trying to avoid its emission when\n  /// possible.\n  /// \\return The debug location of the user written return statement if the\n  /// return block is is avoided.\n  llvm::DebugLoc EmitReturnBlock();\n\n  /// FinishFunction - Complete IR generation of the current function. It is\n  /// legal to call this function even if there is no current insertion point.\n  void FinishFunction(SourceLocation EndLoc=SourceLocation());\n\n  void StartThunk(llvm::Function *Fn, GlobalDecl GD,\n                  const CGFunctionInfo &FnInfo, bool IsUnprototyped);\n\n  void EmitCallAndReturnForThunk(llvm::FunctionCallee Callee,\n                                 const ThunkInfo *Thunk, bool IsUnprototyped);\n\n  void FinishThunk();\n\n  /// Emit a musttail call for a thunk with a potentially adjusted this pointer.\n  void EmitMustTailThunk(GlobalDecl GD, llvm::Value *AdjustedThisPtr,\n                         llvm::FunctionCallee Callee);\n\n  /// Generate a thunk for the given method.\n  void generateThunk(llvm::Function *Fn, const CGFunctionInfo &FnInfo,\n                     GlobalDecl GD, const ThunkInfo &Thunk,\n                     bool IsUnprototyped);\n\n  llvm::Function *GenerateVarArgsThunk(llvm::Function *Fn,\n                                       const CGFunctionInfo &FnInfo,\n                                       GlobalDecl GD, const ThunkInfo &Thunk);\n\n  void EmitCtorPrologue(const CXXConstructorDecl *CD, CXXCtorType Type,\n                        FunctionArgList &Args);\n\n  void EmitInitializerForField(FieldDecl *Field, LValue LHS, Expr *Init);\n\n  /// Struct with all information about dynamic [sub]class needed to set vptr.\n  struct VPtr {\n    BaseSubobject Base;\n    const CXXRecordDecl *NearestVBase;\n    CharUnits OffsetFromNearestVBase;\n    const CXXRecordDecl *VTableClass;\n  };\n\n  /// Initialize the vtable pointer of the given subobject.\n  void InitializeVTablePointer(const VPtr &vptr);\n\n  typedef llvm::SmallVector<VPtr, 4> VPtrsVector;\n\n  typedef llvm::SmallPtrSet<const CXXRecordDecl *, 4> VisitedVirtualBasesSetTy;\n  VPtrsVector getVTablePointers(const CXXRecordDecl *VTableClass);\n\n  void getVTablePointers(BaseSubobject Base, const CXXRecordDecl *NearestVBase,\n                         CharUnits OffsetFromNearestVBase,\n                         bool BaseIsNonVirtualPrimaryBase,\n                         const CXXRecordDecl *VTableClass,\n                         VisitedVirtualBasesSetTy &VBases, VPtrsVector &vptrs);\n\n  void InitializeVTablePointers(const CXXRecordDecl *ClassDecl);\n\n  /// GetVTablePtr - Return the Value of the vtable pointer member pointed\n  /// to by This.\n  llvm::Value *GetVTablePtr(Address This, llvm::Type *VTableTy,\n                            const CXXRecordDecl *VTableClass);\n\n  enum CFITypeCheckKind {\n    CFITCK_VCall,\n    CFITCK_NVCall,\n    CFITCK_DerivedCast,\n    CFITCK_UnrelatedCast,\n    CFITCK_ICall,\n    CFITCK_NVMFCall,\n    CFITCK_VMFCall,\n  };\n\n  /// Derived is the presumed address of an object of type T after a\n  /// cast. If T is a polymorphic class type, emit a check that the virtual\n  /// table for Derived belongs to a class derived from T.\n  void EmitVTablePtrCheckForCast(QualType T, llvm::Value *Derived,\n                                 bool MayBeNull, CFITypeCheckKind TCK,\n                                 SourceLocation Loc);\n\n  /// EmitVTablePtrCheckForCall - Virtual method MD is being called via VTable.\n  /// If vptr CFI is enabled, emit a check that VTable is valid.\n  void EmitVTablePtrCheckForCall(const CXXRecordDecl *RD, llvm::Value *VTable,\n                                 CFITypeCheckKind TCK, SourceLocation Loc);\n\n  /// EmitVTablePtrCheck - Emit a check that VTable is a valid virtual table for\n  /// RD using llvm.type.test.\n  void EmitVTablePtrCheck(const CXXRecordDecl *RD, llvm::Value *VTable,\n                          CFITypeCheckKind TCK, SourceLocation Loc);\n\n  /// If whole-program virtual table optimization is enabled, emit an assumption\n  /// that VTable is a member of RD's type identifier. Or, if vptr CFI is\n  /// enabled, emit a check that VTable is a member of RD's type identifier.\n  void EmitTypeMetadataCodeForVCall(const CXXRecordDecl *RD,\n                                    llvm::Value *VTable, SourceLocation Loc);\n\n  /// Returns whether we should perform a type checked load when loading a\n  /// virtual function for virtual calls to members of RD. This is generally\n  /// true when both vcall CFI and whole-program-vtables are enabled.\n  bool ShouldEmitVTableTypeCheckedLoad(const CXXRecordDecl *RD);\n\n  /// Emit a type checked load from the given vtable.\n  llvm::Value *EmitVTableTypeCheckedLoad(const CXXRecordDecl *RD, llvm::Value *VTable,\n                                         uint64_t VTableByteOffset);\n\n  /// EnterDtorCleanups - Enter the cleanups necessary to complete the\n  /// given phase of destruction for a destructor.  The end result\n  /// should call destructors on members and base classes in reverse\n  /// order of their construction.\n  void EnterDtorCleanups(const CXXDestructorDecl *Dtor, CXXDtorType Type);\n\n  /// ShouldInstrumentFunction - Return true if the current function should be\n  /// instrumented with __cyg_profile_func_* calls\n  bool ShouldInstrumentFunction();\n\n  /// ShouldXRayInstrument - Return true if the current function should be\n  /// instrumented with XRay nop sleds.\n  bool ShouldXRayInstrumentFunction() const;\n\n  /// AlwaysEmitXRayCustomEvents - Return true if we must unconditionally emit\n  /// XRay custom event handling calls.\n  bool AlwaysEmitXRayCustomEvents() const;\n\n  /// AlwaysEmitXRayTypedEvents - Return true if clang must unconditionally emit\n  /// XRay typed event handling calls.\n  bool AlwaysEmitXRayTypedEvents() const;\n\n  /// Encode an address into a form suitable for use in a function prologue.\n  llvm::Constant *EncodeAddrForUseInPrologue(llvm::Function *F,\n                                             llvm::Constant *Addr);\n\n  /// Decode an address used in a function prologue, encoded by \\c\n  /// EncodeAddrForUseInPrologue.\n  llvm::Value *DecodeAddrUsedInPrologue(llvm::Value *F,\n                                        llvm::Value *EncodedAddr);\n\n  /// EmitFunctionProlog - Emit the target specific LLVM code to load the\n  /// arguments for the given function. This is also responsible for naming the\n  /// LLVM function arguments.\n  void EmitFunctionProlog(const CGFunctionInfo &FI,\n                          llvm::Function *Fn,\n                          const FunctionArgList &Args);\n\n  /// EmitFunctionEpilog - Emit the target specific LLVM code to return the\n  /// given temporary.\n  void EmitFunctionEpilog(const CGFunctionInfo &FI, bool EmitRetDbgLoc,\n                          SourceLocation EndLoc);\n\n  /// Emit a test that checks if the return value \\p RV is nonnull.\n  void EmitReturnValueCheck(llvm::Value *RV);\n\n  /// EmitStartEHSpec - Emit the start of the exception spec.\n  void EmitStartEHSpec(const Decl *D);\n\n  /// EmitEndEHSpec - Emit the end of the exception spec.\n  void EmitEndEHSpec(const Decl *D);\n\n  /// getTerminateLandingPad - Return a landing pad that just calls terminate.\n  llvm::BasicBlock *getTerminateLandingPad();\n\n  /// getTerminateLandingPad - Return a cleanup funclet that just calls\n  /// terminate.\n  llvm::BasicBlock *getTerminateFunclet();\n\n  /// getTerminateHandler - Return a handler (not a landing pad, just\n  /// a catch handler) that just calls terminate.  This is used when\n  /// a terminate scope encloses a try.\n  llvm::BasicBlock *getTerminateHandler();\n\n  llvm::Type *ConvertTypeForMem(QualType T);\n  llvm::Type *ConvertType(QualType T);\n  llvm::Type *ConvertType(const TypeDecl *T) {\n    return ConvertType(getContext().getTypeDeclType(T));\n  }\n\n  /// LoadObjCSelf - Load the value of self. This function is only valid while\n  /// generating code for an Objective-C method.\n  llvm::Value *LoadObjCSelf();\n\n  /// TypeOfSelfObject - Return type of object that this self represents.\n  QualType TypeOfSelfObject();\n\n  /// getEvaluationKind - Return the TypeEvaluationKind of QualType \\c T.\n  static TypeEvaluationKind getEvaluationKind(QualType T);\n\n  static bool hasScalarEvaluationKind(QualType T) {\n    return getEvaluationKind(T) == TEK_Scalar;\n  }\n\n  static bool hasAggregateEvaluationKind(QualType T) {\n    return getEvaluationKind(T) == TEK_Aggregate;\n  }\n\n  /// createBasicBlock - Create an LLVM basic block.\n  llvm::BasicBlock *createBasicBlock(const Twine &name = \"\",\n                                     llvm::Function *parent = nullptr,\n                                     llvm::BasicBlock *before = nullptr) {\n    return llvm::BasicBlock::Create(getLLVMContext(), name, parent, before);\n  }\n\n  /// getBasicBlockForLabel - Return the LLVM basicblock that the specified\n  /// label maps to.\n  JumpDest getJumpDestForLabel(const LabelDecl *S);\n\n  /// SimplifyForwardingBlocks - If the given basic block is only a branch to\n  /// another basic block, simplify it. This assumes that no other code could\n  /// potentially reference the basic block.\n  void SimplifyForwardingBlocks(llvm::BasicBlock *BB);\n\n  /// EmitBlock - Emit the given block \\arg BB and set it as the insert point,\n  /// adding a fall-through branch from the current insert block if\n  /// necessary. It is legal to call this function even if there is no current\n  /// insertion point.\n  ///\n  /// IsFinished - If true, indicates that the caller has finished emitting\n  /// branches to the given block and does not expect to emit code into it. This\n  /// means the block can be ignored if it is unreachable.\n  void EmitBlock(llvm::BasicBlock *BB, bool IsFinished=false);\n\n  /// EmitBlockAfterUses - Emit the given block somewhere hopefully\n  /// near its uses, and leave the insertion point in it.\n  void EmitBlockAfterUses(llvm::BasicBlock *BB);\n\n  /// EmitBranch - Emit a branch to the specified basic block from the current\n  /// insert block, taking care to avoid creation of branches from dummy\n  /// blocks. It is legal to call this function even if there is no current\n  /// insertion point.\n  ///\n  /// This function clears the current insertion point. The caller should follow\n  /// calls to this function with calls to Emit*Block prior to generation new\n  /// code.\n  void EmitBranch(llvm::BasicBlock *Block);\n\n  /// HaveInsertPoint - True if an insertion point is defined. If not, this\n  /// indicates that the current code being emitted is unreachable.\n  bool HaveInsertPoint() const {\n    return Builder.GetInsertBlock() != nullptr;\n  }\n\n  /// EnsureInsertPoint - Ensure that an insertion point is defined so that\n  /// emitted IR has a place to go. Note that by definition, if this function\n  /// creates a block then that block is unreachable; callers may do better to\n  /// detect when no insertion point is defined and simply skip IR generation.\n  void EnsureInsertPoint() {\n    if (!HaveInsertPoint())\n      EmitBlock(createBasicBlock());\n  }\n\n  /// ErrorUnsupported - Print out an error that codegen doesn't support the\n  /// specified stmt yet.\n  void ErrorUnsupported(const Stmt *S, const char *Type);\n\n  //===--------------------------------------------------------------------===//\n  //                                  Helpers\n  //===--------------------------------------------------------------------===//\n\n  LValue MakeAddrLValue(Address Addr, QualType T,\n                        AlignmentSource Source = AlignmentSource::Type) {\n    return LValue::MakeAddr(Addr, T, getContext(), LValueBaseInfo(Source),\n                            CGM.getTBAAAccessInfo(T));\n  }\n\n  LValue MakeAddrLValue(Address Addr, QualType T, LValueBaseInfo BaseInfo,\n                        TBAAAccessInfo TBAAInfo) {\n    return LValue::MakeAddr(Addr, T, getContext(), BaseInfo, TBAAInfo);\n  }\n\n  LValue MakeAddrLValue(llvm::Value *V, QualType T, CharUnits Alignment,\n                        AlignmentSource Source = AlignmentSource::Type) {\n    return LValue::MakeAddr(Address(V, Alignment), T, getContext(),\n                            LValueBaseInfo(Source), CGM.getTBAAAccessInfo(T));\n  }\n\n  LValue MakeAddrLValue(llvm::Value *V, QualType T, CharUnits Alignment,\n                        LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo) {\n    return LValue::MakeAddr(Address(V, Alignment), T, getContext(),\n                            BaseInfo, TBAAInfo);\n  }\n\n  LValue MakeNaturalAlignPointeeAddrLValue(llvm::Value *V, QualType T);\n  LValue MakeNaturalAlignAddrLValue(llvm::Value *V, QualType T);\n\n  Address EmitLoadOfReference(LValue RefLVal,\n                              LValueBaseInfo *PointeeBaseInfo = nullptr,\n                              TBAAAccessInfo *PointeeTBAAInfo = nullptr);\n  LValue EmitLoadOfReferenceLValue(LValue RefLVal);\n  LValue EmitLoadOfReferenceLValue(Address RefAddr, QualType RefTy,\n                                   AlignmentSource Source =\n                                       AlignmentSource::Type) {\n    LValue RefLVal = MakeAddrLValue(RefAddr, RefTy, LValueBaseInfo(Source),\n                                    CGM.getTBAAAccessInfo(RefTy));\n    return EmitLoadOfReferenceLValue(RefLVal);\n  }\n\n  Address EmitLoadOfPointer(Address Ptr, const PointerType *PtrTy,\n                            LValueBaseInfo *BaseInfo = nullptr,\n                            TBAAAccessInfo *TBAAInfo = nullptr);\n  LValue EmitLoadOfPointerLValue(Address Ptr, const PointerType *PtrTy);\n\n  /// CreateTempAlloca - This creates an alloca and inserts it into the entry\n  /// block if \\p ArraySize is nullptr, otherwise inserts it at the current\n  /// insertion point of the builder. The caller is responsible for setting an\n  /// appropriate alignment on\n  /// the alloca.\n  ///\n  /// \\p ArraySize is the number of array elements to be allocated if it\n  ///    is not nullptr.\n  ///\n  /// LangAS::Default is the address space of pointers to local variables and\n  /// temporaries, as exposed in the source language. In certain\n  /// configurations, this is not the same as the alloca address space, and a\n  /// cast is needed to lift the pointer from the alloca AS into\n  /// LangAS::Default. This can happen when the target uses a restricted\n  /// address space for the stack but the source language requires\n  /// LangAS::Default to be a generic address space. The latter condition is\n  /// common for most programming languages; OpenCL is an exception in that\n  /// LangAS::Default is the private address space, which naturally maps\n  /// to the stack.\n  ///\n  /// Because the address of a temporary is often exposed to the program in\n  /// various ways, this function will perform the cast. The original alloca\n  /// instruction is returned through \\p Alloca if it is not nullptr.\n  ///\n  /// The cast is not performaed in CreateTempAllocaWithoutCast. This is\n  /// more efficient if the caller knows that the address will not be exposed.\n  llvm::AllocaInst *CreateTempAlloca(llvm::Type *Ty, const Twine &Name = \"tmp\",\n                                     llvm::Value *ArraySize = nullptr);\n  Address CreateTempAlloca(llvm::Type *Ty, CharUnits align,\n                           const Twine &Name = \"tmp\",\n                           llvm::Value *ArraySize = nullptr,\n                           Address *Alloca = nullptr);\n  Address CreateTempAllocaWithoutCast(llvm::Type *Ty, CharUnits align,\n                                      const Twine &Name = \"tmp\",\n                                      llvm::Value *ArraySize = nullptr);\n\n  /// CreateDefaultAlignedTempAlloca - This creates an alloca with the\n  /// default ABI alignment of the given LLVM type.\n  ///\n  /// IMPORTANT NOTE: This is *not* generally the right alignment for\n  /// any given AST type that happens to have been lowered to the\n  /// given IR type.  This should only ever be used for function-local,\n  /// IR-driven manipulations like saving and restoring a value.  Do\n  /// not hand this address off to arbitrary IRGen routines, and especially\n  /// do not pass it as an argument to a function that might expect a\n  /// properly ABI-aligned value.\n  Address CreateDefaultAlignTempAlloca(llvm::Type *Ty,\n                                       const Twine &Name = \"tmp\");\n\n  /// InitTempAlloca - Provide an initial value for the given alloca which\n  /// will be observable at all locations in the function.\n  ///\n  /// The address should be something that was returned from one of\n  /// the CreateTempAlloca or CreateMemTemp routines, and the\n  /// initializer must be valid in the entry block (i.e. it must\n  /// either be a constant or an argument value).\n  void InitTempAlloca(Address Alloca, llvm::Value *Value);\n\n  /// CreateIRTemp - Create a temporary IR object of the given type, with\n  /// appropriate alignment. This routine should only be used when an temporary\n  /// value needs to be stored into an alloca (for example, to avoid explicit\n  /// PHI construction), but the type is the IR type, not the type appropriate\n  /// for storing in memory.\n  ///\n  /// That is, this is exactly equivalent to CreateMemTemp, but calling\n  /// ConvertType instead of ConvertTypeForMem.\n  Address CreateIRTemp(QualType T, const Twine &Name = \"tmp\");\n\n  /// CreateMemTemp - Create a temporary memory object of the given type, with\n  /// appropriate alignmen and cast it to the default address space. Returns\n  /// the original alloca instruction by \\p Alloca if it is not nullptr.\n  Address CreateMemTemp(QualType T, const Twine &Name = \"tmp\",\n                        Address *Alloca = nullptr);\n  Address CreateMemTemp(QualType T, CharUnits Align, const Twine &Name = \"tmp\",\n                        Address *Alloca = nullptr);\n\n  /// CreateMemTemp - Create a temporary memory object of the given type, with\n  /// appropriate alignmen without casting it to the default address space.\n  Address CreateMemTempWithoutCast(QualType T, const Twine &Name = \"tmp\");\n  Address CreateMemTempWithoutCast(QualType T, CharUnits Align,\n                                   const Twine &Name = \"tmp\");\n\n  /// CreateAggTemp - Create a temporary memory object for the given\n  /// aggregate type.\n  AggValueSlot CreateAggTemp(QualType T, const Twine &Name = \"tmp\",\n                             Address *Alloca = nullptr) {\n    return AggValueSlot::forAddr(CreateMemTemp(T, Name, Alloca),\n                                 T.getQualifiers(),\n                                 AggValueSlot::IsNotDestructed,\n                                 AggValueSlot::DoesNotNeedGCBarriers,\n                                 AggValueSlot::IsNotAliased,\n                                 AggValueSlot::DoesNotOverlap);\n  }\n\n  /// Emit a cast to void* in the appropriate address space.\n  llvm::Value *EmitCastToVoidPtr(llvm::Value *value);\n\n  /// EvaluateExprAsBool - Perform the usual unary conversions on the specified\n  /// expression and compare the result against zero, returning an Int1Ty value.\n  llvm::Value *EvaluateExprAsBool(const Expr *E);\n\n  /// EmitIgnoredExpr - Emit an expression in a context which ignores the result.\n  void EmitIgnoredExpr(const Expr *E);\n\n  /// EmitAnyExpr - Emit code to compute the specified expression which can have\n  /// any type.  The result is returned as an RValue struct.  If this is an\n  /// aggregate expression, the aggloc/agglocvolatile arguments indicate where\n  /// the result should be returned.\n  ///\n  /// \\param ignoreResult True if the resulting value isn't used.\n  RValue EmitAnyExpr(const Expr *E,\n                     AggValueSlot aggSlot = AggValueSlot::ignored(),\n                     bool ignoreResult = false);\n\n  // EmitVAListRef - Emit a \"reference\" to a va_list; this is either the address\n  // or the value of the expression, depending on how va_list is defined.\n  Address EmitVAListRef(const Expr *E);\n\n  /// Emit a \"reference\" to a __builtin_ms_va_list; this is\n  /// always the value of the expression, because a __builtin_ms_va_list is a\n  /// pointer to a char.\n  Address EmitMSVAListRef(const Expr *E);\n\n  /// EmitAnyExprToTemp - Similarly to EmitAnyExpr(), however, the result will\n  /// always be accessible even if no aggregate location is provided.\n  RValue EmitAnyExprToTemp(const Expr *E);\n\n  /// EmitAnyExprToMem - Emits the code necessary to evaluate an\n  /// arbitrary expression into the given memory location.\n  void EmitAnyExprToMem(const Expr *E, Address Location,\n                        Qualifiers Quals, bool IsInitializer);\n\n  void EmitAnyExprToExn(const Expr *E, Address Addr);\n\n  /// EmitExprAsInit - Emits the code necessary to initialize a\n  /// location in memory with the given initializer.\n  void EmitExprAsInit(const Expr *init, const ValueDecl *D, LValue lvalue,\n                      bool capturedByInit);\n\n  /// hasVolatileMember - returns true if aggregate type has a volatile\n  /// member.\n  bool hasVolatileMember(QualType T) {\n    if (const RecordType *RT = T->getAs<RecordType>()) {\n      const RecordDecl *RD = cast<RecordDecl>(RT->getDecl());\n      return RD->hasVolatileMember();\n    }\n    return false;\n  }\n\n  /// Determine whether a return value slot may overlap some other object.\n  AggValueSlot::Overlap_t getOverlapForReturnValue() {\n    // FIXME: Assuming no overlap here breaks guaranteed copy elision for base\n    // class subobjects. These cases may need to be revisited depending on the\n    // resolution of the relevant core issue.\n    return AggValueSlot::DoesNotOverlap;\n  }\n\n  /// Determine whether a field initialization may overlap some other object.\n  AggValueSlot::Overlap_t getOverlapForFieldInit(const FieldDecl *FD);\n\n  /// Determine whether a base class initialization may overlap some other\n  /// object.\n  AggValueSlot::Overlap_t getOverlapForBaseInit(const CXXRecordDecl *RD,\n                                                const CXXRecordDecl *BaseRD,\n                                                bool IsVirtual);\n\n  /// Emit an aggregate assignment.\n  void EmitAggregateAssign(LValue Dest, LValue Src, QualType EltTy) {\n    bool IsVolatile = hasVolatileMember(EltTy);\n    EmitAggregateCopy(Dest, Src, EltTy, AggValueSlot::MayOverlap, IsVolatile);\n  }\n\n  void EmitAggregateCopyCtor(LValue Dest, LValue Src,\n                             AggValueSlot::Overlap_t MayOverlap) {\n    EmitAggregateCopy(Dest, Src, Src.getType(), MayOverlap);\n  }\n\n  /// EmitAggregateCopy - Emit an aggregate copy.\n  ///\n  /// \\param isVolatile \\c true iff either the source or the destination is\n  ///        volatile.\n  /// \\param MayOverlap Whether the tail padding of the destination might be\n  ///        occupied by some other object. More efficient code can often be\n  ///        generated if not.\n  void EmitAggregateCopy(LValue Dest, LValue Src, QualType EltTy,\n                         AggValueSlot::Overlap_t MayOverlap,\n                         bool isVolatile = false);\n\n  /// GetAddrOfLocalVar - Return the address of a local variable.\n  Address GetAddrOfLocalVar(const VarDecl *VD) {\n    auto it = LocalDeclMap.find(VD);\n    assert(it != LocalDeclMap.end() &&\n           \"Invalid argument to GetAddrOfLocalVar(), no decl!\");\n    return it->second;\n  }\n\n  /// Given an opaque value expression, return its LValue mapping if it exists,\n  /// otherwise create one.\n  LValue getOrCreateOpaqueLValueMapping(const OpaqueValueExpr *e);\n\n  /// Given an opaque value expression, return its RValue mapping if it exists,\n  /// otherwise create one.\n  RValue getOrCreateOpaqueRValueMapping(const OpaqueValueExpr *e);\n\n  /// Get the index of the current ArrayInitLoopExpr, if any.\n  llvm::Value *getArrayInitIndex() { return ArrayInitIndex; }\n\n  /// getAccessedFieldNo - Given an encoded value and a result number, return\n  /// the input field number being accessed.\n  static unsigned getAccessedFieldNo(unsigned Idx, const llvm::Constant *Elts);\n\n  llvm::BlockAddress *GetAddrOfLabel(const LabelDecl *L);\n  llvm::BasicBlock *GetIndirectGotoBlock();\n\n  /// Check if \\p E is a C++ \"this\" pointer wrapped in value-preserving casts.\n  static bool IsWrappedCXXThis(const Expr *E);\n\n  /// EmitNullInitialization - Generate code to set a value of the given type to\n  /// null, If the type contains data member pointers, they will be initialized\n  /// to -1 in accordance with the Itanium C++ ABI.\n  void EmitNullInitialization(Address DestPtr, QualType Ty);\n\n  /// Emits a call to an LLVM variable-argument intrinsic, either\n  /// \\c llvm.va_start or \\c llvm.va_end.\n  /// \\param ArgValue A reference to the \\c va_list as emitted by either\n  /// \\c EmitVAListRef or \\c EmitMSVAListRef.\n  /// \\param IsStart If \\c true, emits a call to \\c llvm.va_start; otherwise,\n  /// calls \\c llvm.va_end.\n  llvm::Value *EmitVAStartEnd(llvm::Value *ArgValue, bool IsStart);\n\n  /// Generate code to get an argument from the passed in pointer\n  /// and update it accordingly.\n  /// \\param VE The \\c VAArgExpr for which to generate code.\n  /// \\param VAListAddr Receives a reference to the \\c va_list as emitted by\n  /// either \\c EmitVAListRef or \\c EmitMSVAListRef.\n  /// \\returns A pointer to the argument.\n  // FIXME: We should be able to get rid of this method and use the va_arg\n  // instruction in LLVM instead once it works well enough.\n  Address EmitVAArg(VAArgExpr *VE, Address &VAListAddr);\n\n  /// emitArrayLength - Compute the length of an array, even if it's a\n  /// VLA, and drill down to the base element type.\n  llvm::Value *emitArrayLength(const ArrayType *arrayType,\n                               QualType &baseType,\n                               Address &addr);\n\n  /// EmitVLASize - Capture all the sizes for the VLA expressions in\n  /// the given variably-modified type and store them in the VLASizeMap.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitVariablyModifiedType(QualType Ty);\n\n  struct VlaSizePair {\n    llvm::Value *NumElts;\n    QualType Type;\n\n    VlaSizePair(llvm::Value *NE, QualType T) : NumElts(NE), Type(T) {}\n  };\n\n  /// Return the number of elements for a single dimension\n  /// for the given array type.\n  VlaSizePair getVLAElements1D(const VariableArrayType *vla);\n  VlaSizePair getVLAElements1D(QualType vla);\n\n  /// Returns an LLVM value that corresponds to the size,\n  /// in non-variably-sized elements, of a variable length array type,\n  /// plus that largest non-variably-sized element type.  Assumes that\n  /// the type has already been emitted with EmitVariablyModifiedType.\n  VlaSizePair getVLASize(const VariableArrayType *vla);\n  VlaSizePair getVLASize(QualType vla);\n\n  /// LoadCXXThis - Load the value of 'this'. This function is only valid while\n  /// generating code for an C++ member function.\n  llvm::Value *LoadCXXThis() {\n    assert(CXXThisValue && \"no 'this' value for this function\");\n    return CXXThisValue;\n  }\n  Address LoadCXXThisAddress();\n\n  /// LoadCXXVTT - Load the VTT parameter to base constructors/destructors have\n  /// virtual bases.\n  // FIXME: Every place that calls LoadCXXVTT is something\n  // that needs to be abstracted properly.\n  llvm::Value *LoadCXXVTT() {\n    assert(CXXStructorImplicitParamValue && \"no VTT value for this function\");\n    return CXXStructorImplicitParamValue;\n  }\n\n  /// GetAddressOfBaseOfCompleteClass - Convert the given pointer to a\n  /// complete class to the given direct base.\n  Address\n  GetAddressOfDirectBaseInCompleteClass(Address Value,\n                                        const CXXRecordDecl *Derived,\n                                        const CXXRecordDecl *Base,\n                                        bool BaseIsVirtual);\n\n  static bool ShouldNullCheckClassCastValue(const CastExpr *Cast);\n\n  /// GetAddressOfBaseClass - This function will add the necessary delta to the\n  /// load of 'this' and returns address of the base class.\n  Address GetAddressOfBaseClass(Address Value,\n                                const CXXRecordDecl *Derived,\n                                CastExpr::path_const_iterator PathBegin,\n                                CastExpr::path_const_iterator PathEnd,\n                                bool NullCheckValue, SourceLocation Loc);\n\n  Address GetAddressOfDerivedClass(Address Value,\n                                   const CXXRecordDecl *Derived,\n                                   CastExpr::path_const_iterator PathBegin,\n                                   CastExpr::path_const_iterator PathEnd,\n                                   bool NullCheckValue);\n\n  /// GetVTTParameter - Return the VTT parameter that should be passed to a\n  /// base constructor/destructor with virtual bases.\n  /// FIXME: VTTs are Itanium ABI-specific, so the definition should move\n  /// to ItaniumCXXABI.cpp together with all the references to VTT.\n  llvm::Value *GetVTTParameter(GlobalDecl GD, bool ForVirtualBase,\n                               bool Delegating);\n\n  void EmitDelegateCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                      CXXCtorType CtorType,\n                                      const FunctionArgList &Args,\n                                      SourceLocation Loc);\n  // It's important not to confuse this and the previous function. Delegating\n  // constructors are the C++0x feature. The constructor delegate optimization\n  // is used to reduce duplication in the base and complete consturctors where\n  // they are substantially the same.\n  void EmitDelegatingCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                        const FunctionArgList &Args);\n\n  /// Emit a call to an inheriting constructor (that is, one that invokes a\n  /// constructor inherited from a base class) by inlining its definition. This\n  /// is necessary if the ABI does not support forwarding the arguments to the\n  /// base class constructor (because they're variadic or similar).\n  void EmitInlinedInheritingCXXConstructorCall(const CXXConstructorDecl *Ctor,\n                                               CXXCtorType CtorType,\n                                               bool ForVirtualBase,\n                                               bool Delegating,\n                                               CallArgList &Args);\n\n  /// Emit a call to a constructor inherited from a base class, passing the\n  /// current constructor's arguments along unmodified (without even making\n  /// a copy).\n  void EmitInheritedCXXConstructorCall(const CXXConstructorDecl *D,\n                                       bool ForVirtualBase, Address This,\n                                       bool InheritedFromVBase,\n                                       const CXXInheritedCtorInitExpr *E);\n\n  void EmitCXXConstructorCall(const CXXConstructorDecl *D, CXXCtorType Type,\n                              bool ForVirtualBase, bool Delegating,\n                              AggValueSlot ThisAVS, const CXXConstructExpr *E);\n\n  void EmitCXXConstructorCall(const CXXConstructorDecl *D, CXXCtorType Type,\n                              bool ForVirtualBase, bool Delegating,\n                              Address This, CallArgList &Args,\n                              AggValueSlot::Overlap_t Overlap,\n                              SourceLocation Loc, bool NewPointerIsChecked);\n\n  /// Emit assumption load for all bases. Requires to be be called only on\n  /// most-derived class and not under construction of the object.\n  void EmitVTableAssumptionLoads(const CXXRecordDecl *ClassDecl, Address This);\n\n  /// Emit assumption that vptr load == global vtable.\n  void EmitVTableAssumptionLoad(const VPtr &vptr, Address This);\n\n  void EmitSynthesizedCXXCopyCtorCall(const CXXConstructorDecl *D,\n                                      Address This, Address Src,\n                                      const CXXConstructExpr *E);\n\n  void EmitCXXAggrConstructorCall(const CXXConstructorDecl *D,\n                                  const ArrayType *ArrayTy,\n                                  Address ArrayPtr,\n                                  const CXXConstructExpr *E,\n                                  bool NewPointerIsChecked,\n                                  bool ZeroInitialization = false);\n\n  void EmitCXXAggrConstructorCall(const CXXConstructorDecl *D,\n                                  llvm::Value *NumElements,\n                                  Address ArrayPtr,\n                                  const CXXConstructExpr *E,\n                                  bool NewPointerIsChecked,\n                                  bool ZeroInitialization = false);\n\n  static Destroyer destroyCXXObject;\n\n  void EmitCXXDestructorCall(const CXXDestructorDecl *D, CXXDtorType Type,\n                             bool ForVirtualBase, bool Delegating, Address This,\n                             QualType ThisTy);\n\n  void EmitNewArrayInitializer(const CXXNewExpr *E, QualType elementType,\n                               llvm::Type *ElementTy, Address NewPtr,\n                               llvm::Value *NumElements,\n                               llvm::Value *AllocSizeWithoutCookie);\n\n  void EmitCXXTemporary(const CXXTemporary *Temporary, QualType TempType,\n                        Address Ptr);\n\n  llvm::Value *EmitLifetimeStart(uint64_t Size, llvm::Value *Addr);\n  void EmitLifetimeEnd(llvm::Value *Size, llvm::Value *Addr);\n\n  llvm::Value *EmitCXXNewExpr(const CXXNewExpr *E);\n  void EmitCXXDeleteExpr(const CXXDeleteExpr *E);\n\n  void EmitDeleteCall(const FunctionDecl *DeleteFD, llvm::Value *Ptr,\n                      QualType DeleteTy, llvm::Value *NumElements = nullptr,\n                      CharUnits CookieSize = CharUnits());\n\n  RValue EmitBuiltinNewDeleteCall(const FunctionProtoType *Type,\n                                  const CallExpr *TheCallExpr, bool IsDelete);\n\n  llvm::Value *EmitCXXTypeidExpr(const CXXTypeidExpr *E);\n  llvm::Value *EmitDynamicCast(Address V, const CXXDynamicCastExpr *DCE);\n  Address EmitCXXUuidofExpr(const CXXUuidofExpr *E);\n\n  /// Situations in which we might emit a check for the suitability of a\n  /// pointer or glvalue. Needs to be kept in sync with ubsan_handlers.cpp in\n  /// compiler-rt.\n  enum TypeCheckKind {\n    /// Checking the operand of a load. Must be suitably sized and aligned.\n    TCK_Load,\n    /// Checking the destination of a store. Must be suitably sized and aligned.\n    TCK_Store,\n    /// Checking the bound value in a reference binding. Must be suitably sized\n    /// and aligned, but is not required to refer to an object (until the\n    /// reference is used), per core issue 453.\n    TCK_ReferenceBinding,\n    /// Checking the object expression in a non-static data member access. Must\n    /// be an object within its lifetime.\n    TCK_MemberAccess,\n    /// Checking the 'this' pointer for a call to a non-static member function.\n    /// Must be an object within its lifetime.\n    TCK_MemberCall,\n    /// Checking the 'this' pointer for a constructor call.\n    TCK_ConstructorCall,\n    /// Checking the operand of a static_cast to a derived pointer type. Must be\n    /// null or an object within its lifetime.\n    TCK_DowncastPointer,\n    /// Checking the operand of a static_cast to a derived reference type. Must\n    /// be an object within its lifetime.\n    TCK_DowncastReference,\n    /// Checking the operand of a cast to a base object. Must be suitably sized\n    /// and aligned.\n    TCK_Upcast,\n    /// Checking the operand of a cast to a virtual base object. Must be an\n    /// object within its lifetime.\n    TCK_UpcastToVirtualBase,\n    /// Checking the value assigned to a _Nonnull pointer. Must not be null.\n    TCK_NonnullAssign,\n    /// Checking the operand of a dynamic_cast or a typeid expression.  Must be\n    /// null or an object within its lifetime.\n    TCK_DynamicOperation\n  };\n\n  /// Determine whether the pointer type check \\p TCK permits null pointers.\n  static bool isNullPointerAllowed(TypeCheckKind TCK);\n\n  /// Determine whether the pointer type check \\p TCK requires a vptr check.\n  static bool isVptrCheckRequired(TypeCheckKind TCK, QualType Ty);\n\n  /// Whether any type-checking sanitizers are enabled. If \\c false,\n  /// calls to EmitTypeCheck can be skipped.\n  bool sanitizePerformTypeCheck() const;\n\n  /// Emit a check that \\p V is the address of storage of the\n  /// appropriate size and alignment for an object of type \\p Type\n  /// (or if ArraySize is provided, for an array of that bound).\n  void EmitTypeCheck(TypeCheckKind TCK, SourceLocation Loc, llvm::Value *V,\n                     QualType Type, CharUnits Alignment = CharUnits::Zero(),\n                     SanitizerSet SkippedChecks = SanitizerSet(),\n                     llvm::Value *ArraySize = nullptr);\n\n  /// Emit a check that \\p Base points into an array object, which\n  /// we can access at index \\p Index. \\p Accessed should be \\c false if we\n  /// this expression is used as an lvalue, for instance in \"&Arr[Idx]\".\n  void EmitBoundsCheck(const Expr *E, const Expr *Base, llvm::Value *Index,\n                       QualType IndexType, bool Accessed);\n\n  llvm::Value *EmitScalarPrePostIncDec(const UnaryOperator *E, LValue LV,\n                                       bool isInc, bool isPre);\n  ComplexPairTy EmitComplexPrePostIncDec(const UnaryOperator *E, LValue LV,\n                                         bool isInc, bool isPre);\n\n  /// Converts Location to a DebugLoc, if debug information is enabled.\n  llvm::DebugLoc SourceLocToDebugLoc(SourceLocation Location);\n\n  /// Get the record field index as represented in debug info.\n  unsigned getDebugInfoFIndex(const RecordDecl *Rec, unsigned FieldIndex);\n\n\n  //===--------------------------------------------------------------------===//\n  //                            Declaration Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitDecl - Emit a declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitDecl(const Decl &D);\n\n  /// EmitVarDecl - Emit a local variable declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitVarDecl(const VarDecl &D);\n\n  void EmitScalarInit(const Expr *init, const ValueDecl *D, LValue lvalue,\n                      bool capturedByInit);\n\n  typedef void SpecialInitFn(CodeGenFunction &Init, const VarDecl &D,\n                             llvm::Value *Address);\n\n  /// Determine whether the given initializer is trivial in the sense\n  /// that it requires no code to be generated.\n  bool isTrivialInitializer(const Expr *Init);\n\n  /// EmitAutoVarDecl - Emit an auto variable declaration.\n  ///\n  /// This function can be called with a null (unreachable) insert point.\n  void EmitAutoVarDecl(const VarDecl &D);\n\n  class AutoVarEmission {\n    friend class CodeGenFunction;\n\n    const VarDecl *Variable;\n\n    /// The address of the alloca for languages with explicit address space\n    /// (e.g. OpenCL) or alloca casted to generic pointer for address space\n    /// agnostic languages (e.g. C++). Invalid if the variable was emitted\n    /// as a global constant.\n    Address Addr;\n\n    llvm::Value *NRVOFlag;\n\n    /// True if the variable is a __block variable that is captured by an\n    /// escaping block.\n    bool IsEscapingByRef;\n\n    /// True if the variable is of aggregate type and has a constant\n    /// initializer.\n    bool IsConstantAggregate;\n\n    /// Non-null if we should use lifetime annotations.\n    llvm::Value *SizeForLifetimeMarkers;\n\n    /// Address with original alloca instruction. Invalid if the variable was\n    /// emitted as a global constant.\n    Address AllocaAddr;\n\n    struct Invalid {};\n    AutoVarEmission(Invalid)\n        : Variable(nullptr), Addr(Address::invalid()),\n          AllocaAddr(Address::invalid()) {}\n\n    AutoVarEmission(const VarDecl &variable)\n        : Variable(&variable), Addr(Address::invalid()), NRVOFlag(nullptr),\n          IsEscapingByRef(false), IsConstantAggregate(false),\n          SizeForLifetimeMarkers(nullptr), AllocaAddr(Address::invalid()) {}\n\n    bool wasEmittedAsGlobal() const { return !Addr.isValid(); }\n\n  public:\n    static AutoVarEmission invalid() { return AutoVarEmission(Invalid()); }\n\n    bool useLifetimeMarkers() const {\n      return SizeForLifetimeMarkers != nullptr;\n    }\n    llvm::Value *getSizeForLifetimeMarkers() const {\n      assert(useLifetimeMarkers());\n      return SizeForLifetimeMarkers;\n    }\n\n    /// Returns the raw, allocated address, which is not necessarily\n    /// the address of the object itself. It is casted to default\n    /// address space for address space agnostic languages.\n    Address getAllocatedAddress() const {\n      return Addr;\n    }\n\n    /// Returns the address for the original alloca instruction.\n    Address getOriginalAllocatedAddress() const { return AllocaAddr; }\n\n    /// Returns the address of the object within this declaration.\n    /// Note that this does not chase the forwarding pointer for\n    /// __block decls.\n    Address getObjectAddress(CodeGenFunction &CGF) const {\n      if (!IsEscapingByRef) return Addr;\n\n      return CGF.emitBlockByrefAddress(Addr, Variable, /*forward*/ false);\n    }\n  };\n  AutoVarEmission EmitAutoVarAlloca(const VarDecl &var);\n  void EmitAutoVarInit(const AutoVarEmission &emission);\n  void EmitAutoVarCleanups(const AutoVarEmission &emission);\n  void emitAutoVarTypeCleanup(const AutoVarEmission &emission,\n                              QualType::DestructionKind dtorKind);\n\n  /// Emits the alloca and debug information for the size expressions for each\n  /// dimension of an array. It registers the association of its (1-dimensional)\n  /// QualTypes and size expression's debug node, so that CGDebugInfo can\n  /// reference this node when creating the DISubrange object to describe the\n  /// array types.\n  void EmitAndRegisterVariableArrayDimensions(CGDebugInfo *DI,\n                                              const VarDecl &D,\n                                              bool EmitDebugInfo);\n\n  void EmitStaticVarDecl(const VarDecl &D,\n                         llvm::GlobalValue::LinkageTypes Linkage);\n\n  class ParamValue {\n    llvm::Value *Value;\n    unsigned Alignment;\n    ParamValue(llvm::Value *V, unsigned A) : Value(V), Alignment(A) {}\n  public:\n    static ParamValue forDirect(llvm::Value *value) {\n      return ParamValue(value, 0);\n    }\n    static ParamValue forIndirect(Address addr) {\n      assert(!addr.getAlignment().isZero());\n      return ParamValue(addr.getPointer(), addr.getAlignment().getQuantity());\n    }\n\n    bool isIndirect() const { return Alignment != 0; }\n    llvm::Value *getAnyValue() const { return Value; }\n\n    llvm::Value *getDirectValue() const {\n      assert(!isIndirect());\n      return Value;\n    }\n\n    Address getIndirectAddress() const {\n      assert(isIndirect());\n      return Address(Value, CharUnits::fromQuantity(Alignment));\n    }\n  };\n\n  /// EmitParmDecl - Emit a ParmVarDecl or an ImplicitParamDecl.\n  void EmitParmDecl(const VarDecl &D, ParamValue Arg, unsigned ArgNo);\n\n  /// protectFromPeepholes - Protect a value that we're intending to\n  /// store to the side, but which will probably be used later, from\n  /// aggressive peepholing optimizations that might delete it.\n  ///\n  /// Pass the result to unprotectFromPeepholes to declare that\n  /// protection is no longer required.\n  ///\n  /// There's no particular reason why this shouldn't apply to\n  /// l-values, it's just that no existing peepholes work on pointers.\n  PeepholeProtection protectFromPeepholes(RValue rvalue);\n  void unprotectFromPeepholes(PeepholeProtection protection);\n\n  void emitAlignmentAssumptionCheck(llvm::Value *Ptr, QualType Ty,\n                                    SourceLocation Loc,\n                                    SourceLocation AssumptionLoc,\n                                    llvm::Value *Alignment,\n                                    llvm::Value *OffsetValue,\n                                    llvm::Value *TheCheck,\n                                    llvm::Instruction *Assumption);\n\n  void emitAlignmentAssumption(llvm::Value *PtrValue, QualType Ty,\n                               SourceLocation Loc, SourceLocation AssumptionLoc,\n                               llvm::Value *Alignment,\n                               llvm::Value *OffsetValue = nullptr);\n\n  void emitAlignmentAssumption(llvm::Value *PtrValue, const Expr *E,\n                               SourceLocation AssumptionLoc,\n                               llvm::Value *Alignment,\n                               llvm::Value *OffsetValue = nullptr);\n\n  //===--------------------------------------------------------------------===//\n  //                             Statement Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitStopPoint - Emit a debug stoppoint if we are emitting debug info.\n  void EmitStopPoint(const Stmt *S);\n\n  /// EmitStmt - Emit the code for the statement \\arg S. It is legal to call\n  /// this function even if there is no current insertion point.\n  ///\n  /// This function may clear the current insertion point; callers should use\n  /// EnsureInsertPoint if they wish to subsequently generate code without first\n  /// calling EmitBlock, EmitBranch, or EmitStmt.\n  void EmitStmt(const Stmt *S, ArrayRef<const Attr *> Attrs = None);\n\n  /// EmitSimpleStmt - Try to emit a \"simple\" statement which does not\n  /// necessarily require an insertion point or debug information; typically\n  /// because the statement amounts to a jump or a container of other\n  /// statements.\n  ///\n  /// \\return True if the statement was handled.\n  bool EmitSimpleStmt(const Stmt *S, ArrayRef<const Attr *> Attrs);\n\n  Address EmitCompoundStmt(const CompoundStmt &S, bool GetLast = false,\n                           AggValueSlot AVS = AggValueSlot::ignored());\n  Address EmitCompoundStmtWithoutScope(const CompoundStmt &S,\n                                       bool GetLast = false,\n                                       AggValueSlot AVS =\n                                                AggValueSlot::ignored());\n\n  /// EmitLabel - Emit the block for the given label. It is legal to call this\n  /// function even if there is no current insertion point.\n  void EmitLabel(const LabelDecl *D); // helper for EmitLabelStmt.\n\n  void EmitLabelStmt(const LabelStmt &S);\n  void EmitAttributedStmt(const AttributedStmt &S);\n  void EmitGotoStmt(const GotoStmt &S);\n  void EmitIndirectGotoStmt(const IndirectGotoStmt &S);\n  void EmitIfStmt(const IfStmt &S);\n\n  void EmitWhileStmt(const WhileStmt &S,\n                     ArrayRef<const Attr *> Attrs = None);\n  void EmitDoStmt(const DoStmt &S, ArrayRef<const Attr *> Attrs = None);\n  void EmitForStmt(const ForStmt &S,\n                   ArrayRef<const Attr *> Attrs = None);\n  void EmitReturnStmt(const ReturnStmt &S);\n  void EmitDeclStmt(const DeclStmt &S);\n  void EmitBreakStmt(const BreakStmt &S);\n  void EmitContinueStmt(const ContinueStmt &S);\n  void EmitSwitchStmt(const SwitchStmt &S);\n  void EmitDefaultStmt(const DefaultStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitCaseStmt(const CaseStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitCaseStmtRange(const CaseStmt &S, ArrayRef<const Attr *> Attrs);\n  void EmitAsmStmt(const AsmStmt &S);\n\n  void EmitObjCForCollectionStmt(const ObjCForCollectionStmt &S);\n  void EmitObjCAtTryStmt(const ObjCAtTryStmt &S);\n  void EmitObjCAtThrowStmt(const ObjCAtThrowStmt &S);\n  void EmitObjCAtSynchronizedStmt(const ObjCAtSynchronizedStmt &S);\n  void EmitObjCAutoreleasePoolStmt(const ObjCAutoreleasePoolStmt &S);\n\n  void EmitCoroutineBody(const CoroutineBodyStmt &S);\n  void EmitCoreturnStmt(const CoreturnStmt &S);\n  RValue EmitCoawaitExpr(const CoawaitExpr &E,\n                         AggValueSlot aggSlot = AggValueSlot::ignored(),\n                         bool ignoreResult = false);\n  LValue EmitCoawaitLValue(const CoawaitExpr *E);\n  RValue EmitCoyieldExpr(const CoyieldExpr &E,\n                         AggValueSlot aggSlot = AggValueSlot::ignored(),\n                         bool ignoreResult = false);\n  LValue EmitCoyieldLValue(const CoyieldExpr *E);\n  RValue EmitCoroutineIntrinsic(const CallExpr *E, unsigned int IID);\n\n  void EnterCXXTryStmt(const CXXTryStmt &S, bool IsFnTryBlock = false);\n  void ExitCXXTryStmt(const CXXTryStmt &S, bool IsFnTryBlock = false);\n\n  void EmitCXXTryStmt(const CXXTryStmt &S);\n  void EmitSEHTryStmt(const SEHTryStmt &S);\n  void EmitSEHLeaveStmt(const SEHLeaveStmt &S);\n  void EnterSEHTryStmt(const SEHTryStmt &S);\n  void ExitSEHTryStmt(const SEHTryStmt &S);\n\n  void pushSEHCleanup(CleanupKind kind,\n                      llvm::Function *FinallyFunc);\n  void startOutlinedSEHHelper(CodeGenFunction &ParentCGF, bool IsFilter,\n                              const Stmt *OutlinedStmt);\n\n  llvm::Function *GenerateSEHFilterFunction(CodeGenFunction &ParentCGF,\n                                            const SEHExceptStmt &Except);\n\n  llvm::Function *GenerateSEHFinallyFunction(CodeGenFunction &ParentCGF,\n                                             const SEHFinallyStmt &Finally);\n\n  void EmitSEHExceptionCodeSave(CodeGenFunction &ParentCGF,\n                                llvm::Value *ParentFP,\n                                llvm::Value *EntryEBP);\n  llvm::Value *EmitSEHExceptionCode();\n  llvm::Value *EmitSEHExceptionInfo();\n  llvm::Value *EmitSEHAbnormalTermination();\n\n  /// Emit simple code for OpenMP directives in Simd-only mode.\n  void EmitSimpleOMPExecutableDirective(const OMPExecutableDirective &D);\n\n  /// Scan the outlined statement for captures from the parent function. For\n  /// each capture, mark the capture as escaped and emit a call to\n  /// llvm.localrecover. Insert the localrecover result into the LocalDeclMap.\n  void EmitCapturedLocals(CodeGenFunction &ParentCGF, const Stmt *OutlinedStmt,\n                          bool IsFilter);\n\n  /// Recovers the address of a local in a parent function. ParentVar is the\n  /// address of the variable used in the immediate parent function. It can\n  /// either be an alloca or a call to llvm.localrecover if there are nested\n  /// outlined functions. ParentFP is the frame pointer of the outermost parent\n  /// frame.\n  Address recoverAddrOfEscapedLocal(CodeGenFunction &ParentCGF,\n                                    Address ParentVar,\n                                    llvm::Value *ParentFP);\n\n  void EmitCXXForRangeStmt(const CXXForRangeStmt &S,\n                           ArrayRef<const Attr *> Attrs = None);\n\n  /// Controls insertion of cancellation exit blocks in worksharing constructs.\n  class OMPCancelStackRAII {\n    CodeGenFunction &CGF;\n\n  public:\n    OMPCancelStackRAII(CodeGenFunction &CGF, OpenMPDirectiveKind Kind,\n                       bool HasCancel)\n        : CGF(CGF) {\n      CGF.OMPCancelStack.enter(CGF, Kind, HasCancel);\n    }\n    ~OMPCancelStackRAII() { CGF.OMPCancelStack.exit(CGF); }\n  };\n\n  /// Returns calculated size of the specified type.\n  llvm::Value *getTypeSize(QualType Ty);\n  LValue InitCapturedStruct(const CapturedStmt &S);\n  llvm::Function *EmitCapturedStmt(const CapturedStmt &S, CapturedRegionKind K);\n  llvm::Function *GenerateCapturedStmtFunction(const CapturedStmt &S);\n  Address GenerateCapturedStmtArgument(const CapturedStmt &S);\n  llvm::Function *GenerateOpenMPCapturedStmtFunction(const CapturedStmt &S,\n                                                     SourceLocation Loc);\n  void GenerateOpenMPCapturedVars(const CapturedStmt &S,\n                                  SmallVectorImpl<llvm::Value *> &CapturedVars);\n  void emitOMPSimpleStore(LValue LVal, RValue RVal, QualType RValTy,\n                          SourceLocation Loc);\n  /// Perform element by element copying of arrays with type \\a\n  /// OriginalType from \\a SrcAddr to \\a DestAddr using copying procedure\n  /// generated by \\a CopyGen.\n  ///\n  /// \\param DestAddr Address of the destination array.\n  /// \\param SrcAddr Address of the source array.\n  /// \\param OriginalType Type of destination and source arrays.\n  /// \\param CopyGen Copying procedure that copies value of single array element\n  /// to another single array element.\n  void EmitOMPAggregateAssign(\n      Address DestAddr, Address SrcAddr, QualType OriginalType,\n      const llvm::function_ref<void(Address, Address)> CopyGen);\n  /// Emit proper copying of data from one variable to another.\n  ///\n  /// \\param OriginalType Original type of the copied variables.\n  /// \\param DestAddr Destination address.\n  /// \\param SrcAddr Source address.\n  /// \\param DestVD Destination variable used in \\a CopyExpr (for arrays, has\n  /// type of the base array element).\n  /// \\param SrcVD Source variable used in \\a CopyExpr (for arrays, has type of\n  /// the base array element).\n  /// \\param Copy Actual copygin expression for copying data from \\a SrcVD to \\a\n  /// DestVD.\n  void EmitOMPCopy(QualType OriginalType,\n                   Address DestAddr, Address SrcAddr,\n                   const VarDecl *DestVD, const VarDecl *SrcVD,\n                   const Expr *Copy);\n  /// Emit atomic update code for constructs: \\a X = \\a X \\a BO \\a E or\n  /// \\a X = \\a E \\a BO \\a E.\n  ///\n  /// \\param X Value to be updated.\n  /// \\param E Update value.\n  /// \\param BO Binary operation for update operation.\n  /// \\param IsXLHSInRHSPart true if \\a X is LHS in RHS part of the update\n  /// expression, false otherwise.\n  /// \\param AO Atomic ordering of the generated atomic instructions.\n  /// \\param CommonGen Code generator for complex expressions that cannot be\n  /// expressed through atomicrmw instruction.\n  /// \\returns <true, OldAtomicValue> if simple 'atomicrmw' instruction was\n  /// generated, <false, RValue::get(nullptr)> otherwise.\n  std::pair<bool, RValue> EmitOMPAtomicSimpleUpdateExpr(\n      LValue X, RValue E, BinaryOperatorKind BO, bool IsXLHSInRHSPart,\n      llvm::AtomicOrdering AO, SourceLocation Loc,\n      const llvm::function_ref<RValue(RValue)> CommonGen);\n  bool EmitOMPFirstprivateClause(const OMPExecutableDirective &D,\n                                 OMPPrivateScope &PrivateScope);\n  void EmitOMPPrivateClause(const OMPExecutableDirective &D,\n                            OMPPrivateScope &PrivateScope);\n  void EmitOMPUseDevicePtrClause(\n      const OMPUseDevicePtrClause &C, OMPPrivateScope &PrivateScope,\n      const llvm::DenseMap<const ValueDecl *, Address> &CaptureDeviceAddrMap);\n  void EmitOMPUseDeviceAddrClause(\n      const OMPUseDeviceAddrClause &C, OMPPrivateScope &PrivateScope,\n      const llvm::DenseMap<const ValueDecl *, Address> &CaptureDeviceAddrMap);\n  /// Emit code for copyin clause in \\a D directive. The next code is\n  /// generated at the start of outlined functions for directives:\n  /// \\code\n  /// threadprivate_var1 = master_threadprivate_var1;\n  /// operator=(threadprivate_var2, master_threadprivate_var2);\n  /// ...\n  /// __kmpc_barrier(&loc, global_tid);\n  /// \\endcode\n  ///\n  /// \\param D OpenMP directive possibly with 'copyin' clause(s).\n  /// \\returns true if at least one copyin variable is found, false otherwise.\n  bool EmitOMPCopyinClause(const OMPExecutableDirective &D);\n  /// Emit initial code for lastprivate variables. If some variable is\n  /// not also firstprivate, then the default initialization is used. Otherwise\n  /// initialization of this variable is performed by EmitOMPFirstprivateClause\n  /// method.\n  ///\n  /// \\param D Directive that may have 'lastprivate' directives.\n  /// \\param PrivateScope Private scope for capturing lastprivate variables for\n  /// proper codegen in internal captured statement.\n  ///\n  /// \\returns true if there is at least one lastprivate variable, false\n  /// otherwise.\n  bool EmitOMPLastprivateClauseInit(const OMPExecutableDirective &D,\n                                    OMPPrivateScope &PrivateScope);\n  /// Emit final copying of lastprivate values to original variables at\n  /// the end of the worksharing or simd directive.\n  ///\n  /// \\param D Directive that has at least one 'lastprivate' directives.\n  /// \\param IsLastIterCond Boolean condition that must be set to 'i1 true' if\n  /// it is the last iteration of the loop code in associated directive, or to\n  /// 'i1 false' otherwise. If this item is nullptr, no final check is required.\n  void EmitOMPLastprivateClauseFinal(const OMPExecutableDirective &D,\n                                     bool NoFinals,\n                                     llvm::Value *IsLastIterCond = nullptr);\n  /// Emit initial code for linear clauses.\n  void EmitOMPLinearClause(const OMPLoopDirective &D,\n                           CodeGenFunction::OMPPrivateScope &PrivateScope);\n  /// Emit final code for linear clauses.\n  /// \\param CondGen Optional conditional code for final part of codegen for\n  /// linear clause.\n  void EmitOMPLinearClauseFinal(\n      const OMPLoopDirective &D,\n      const llvm::function_ref<llvm::Value *(CodeGenFunction &)> CondGen);\n  /// Emit initial code for reduction variables. Creates reduction copies\n  /// and initializes them with the values according to OpenMP standard.\n  ///\n  /// \\param D Directive (possibly) with the 'reduction' clause.\n  /// \\param PrivateScope Private scope for capturing reduction variables for\n  /// proper codegen in internal captured statement.\n  ///\n  void EmitOMPReductionClauseInit(const OMPExecutableDirective &D,\n                                  OMPPrivateScope &PrivateScope,\n                                  bool ForInscan = false);\n  /// Emit final update of reduction values to original variables at\n  /// the end of the directive.\n  ///\n  /// \\param D Directive that has at least one 'reduction' directives.\n  /// \\param ReductionKind The kind of reduction to perform.\n  void EmitOMPReductionClauseFinal(const OMPExecutableDirective &D,\n                                   const OpenMPDirectiveKind ReductionKind);\n  /// Emit initial code for linear variables. Creates private copies\n  /// and initializes them with the values according to OpenMP standard.\n  ///\n  /// \\param D Directive (possibly) with the 'linear' clause.\n  /// \\return true if at least one linear variable is found that should be\n  /// initialized with the value of the original variable, false otherwise.\n  bool EmitOMPLinearClauseInit(const OMPLoopDirective &D);\n\n  typedef const llvm::function_ref<void(CodeGenFunction & /*CGF*/,\n                                        llvm::Function * /*OutlinedFn*/,\n                                        const OMPTaskDataTy & /*Data*/)>\n      TaskGenTy;\n  void EmitOMPTaskBasedDirective(const OMPExecutableDirective &S,\n                                 const OpenMPDirectiveKind CapturedRegion,\n                                 const RegionCodeGenTy &BodyGen,\n                                 const TaskGenTy &TaskGen, OMPTaskDataTy &Data);\n  struct OMPTargetDataInfo {\n    Address BasePointersArray = Address::invalid();\n    Address PointersArray = Address::invalid();\n    Address SizesArray = Address::invalid();\n    Address MappersArray = Address::invalid();\n    unsigned NumberOfTargetItems = 0;\n    explicit OMPTargetDataInfo() = default;\n    OMPTargetDataInfo(Address BasePointersArray, Address PointersArray,\n                      Address SizesArray, Address MappersArray,\n                      unsigned NumberOfTargetItems)\n        : BasePointersArray(BasePointersArray), PointersArray(PointersArray),\n          SizesArray(SizesArray), MappersArray(MappersArray),\n          NumberOfTargetItems(NumberOfTargetItems) {}\n  };\n  void EmitOMPTargetTaskBasedDirective(const OMPExecutableDirective &S,\n                                       const RegionCodeGenTy &BodyGen,\n                                       OMPTargetDataInfo &InputInfo);\n\n  void EmitOMPParallelDirective(const OMPParallelDirective &S);\n  void EmitOMPSimdDirective(const OMPSimdDirective &S);\n  void EmitOMPTileDirective(const OMPTileDirective &S);\n  void EmitOMPForDirective(const OMPForDirective &S);\n  void EmitOMPForSimdDirective(const OMPForSimdDirective &S);\n  void EmitOMPSectionsDirective(const OMPSectionsDirective &S);\n  void EmitOMPSectionDirective(const OMPSectionDirective &S);\n  void EmitOMPSingleDirective(const OMPSingleDirective &S);\n  void EmitOMPMasterDirective(const OMPMasterDirective &S);\n  void EmitOMPCriticalDirective(const OMPCriticalDirective &S);\n  void EmitOMPParallelForDirective(const OMPParallelForDirective &S);\n  void EmitOMPParallelForSimdDirective(const OMPParallelForSimdDirective &S);\n  void EmitOMPParallelSectionsDirective(const OMPParallelSectionsDirective &S);\n  void EmitOMPParallelMasterDirective(const OMPParallelMasterDirective &S);\n  void EmitOMPTaskDirective(const OMPTaskDirective &S);\n  void EmitOMPTaskyieldDirective(const OMPTaskyieldDirective &S);\n  void EmitOMPBarrierDirective(const OMPBarrierDirective &S);\n  void EmitOMPTaskwaitDirective(const OMPTaskwaitDirective &S);\n  void EmitOMPTaskgroupDirective(const OMPTaskgroupDirective &S);\n  void EmitOMPFlushDirective(const OMPFlushDirective &S);\n  void EmitOMPDepobjDirective(const OMPDepobjDirective &S);\n  void EmitOMPScanDirective(const OMPScanDirective &S);\n  void EmitOMPOrderedDirective(const OMPOrderedDirective &S);\n  void EmitOMPAtomicDirective(const OMPAtomicDirective &S);\n  void EmitOMPTargetDirective(const OMPTargetDirective &S);\n  void EmitOMPTargetDataDirective(const OMPTargetDataDirective &S);\n  void EmitOMPTargetEnterDataDirective(const OMPTargetEnterDataDirective &S);\n  void EmitOMPTargetExitDataDirective(const OMPTargetExitDataDirective &S);\n  void EmitOMPTargetUpdateDirective(const OMPTargetUpdateDirective &S);\n  void EmitOMPTargetParallelDirective(const OMPTargetParallelDirective &S);\n  void\n  EmitOMPTargetParallelForDirective(const OMPTargetParallelForDirective &S);\n  void EmitOMPTeamsDirective(const OMPTeamsDirective &S);\n  void\n  EmitOMPCancellationPointDirective(const OMPCancellationPointDirective &S);\n  void EmitOMPCancelDirective(const OMPCancelDirective &S);\n  void EmitOMPTaskLoopBasedDirective(const OMPLoopDirective &S);\n  void EmitOMPTaskLoopDirective(const OMPTaskLoopDirective &S);\n  void EmitOMPTaskLoopSimdDirective(const OMPTaskLoopSimdDirective &S);\n  void EmitOMPMasterTaskLoopDirective(const OMPMasterTaskLoopDirective &S);\n  void\n  EmitOMPMasterTaskLoopSimdDirective(const OMPMasterTaskLoopSimdDirective &S);\n  void EmitOMPParallelMasterTaskLoopDirective(\n      const OMPParallelMasterTaskLoopDirective &S);\n  void EmitOMPParallelMasterTaskLoopSimdDirective(\n      const OMPParallelMasterTaskLoopSimdDirective &S);\n  void EmitOMPDistributeDirective(const OMPDistributeDirective &S);\n  void EmitOMPDistributeParallelForDirective(\n      const OMPDistributeParallelForDirective &S);\n  void EmitOMPDistributeParallelForSimdDirective(\n      const OMPDistributeParallelForSimdDirective &S);\n  void EmitOMPDistributeSimdDirective(const OMPDistributeSimdDirective &S);\n  void EmitOMPTargetParallelForSimdDirective(\n      const OMPTargetParallelForSimdDirective &S);\n  void EmitOMPTargetSimdDirective(const OMPTargetSimdDirective &S);\n  void EmitOMPTeamsDistributeDirective(const OMPTeamsDistributeDirective &S);\n  void\n  EmitOMPTeamsDistributeSimdDirective(const OMPTeamsDistributeSimdDirective &S);\n  void EmitOMPTeamsDistributeParallelForSimdDirective(\n      const OMPTeamsDistributeParallelForSimdDirective &S);\n  void EmitOMPTeamsDistributeParallelForDirective(\n      const OMPTeamsDistributeParallelForDirective &S);\n  void EmitOMPTargetTeamsDirective(const OMPTargetTeamsDirective &S);\n  void EmitOMPTargetTeamsDistributeDirective(\n      const OMPTargetTeamsDistributeDirective &S);\n  void EmitOMPTargetTeamsDistributeParallelForDirective(\n      const OMPTargetTeamsDistributeParallelForDirective &S);\n  void EmitOMPTargetTeamsDistributeParallelForSimdDirective(\n      const OMPTargetTeamsDistributeParallelForSimdDirective &S);\n  void EmitOMPTargetTeamsDistributeSimdDirective(\n      const OMPTargetTeamsDistributeSimdDirective &S);\n\n  /// Emit device code for the target directive.\n  static void EmitOMPTargetDeviceFunction(CodeGenModule &CGM,\n                                          StringRef ParentName,\n                                          const OMPTargetDirective &S);\n  static void\n  EmitOMPTargetParallelDeviceFunction(CodeGenModule &CGM, StringRef ParentName,\n                                      const OMPTargetParallelDirective &S);\n  /// Emit device code for the target parallel for directive.\n  static void EmitOMPTargetParallelForDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetParallelForDirective &S);\n  /// Emit device code for the target parallel for simd directive.\n  static void EmitOMPTargetParallelForSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetParallelForSimdDirective &S);\n  /// Emit device code for the target teams directive.\n  static void\n  EmitOMPTargetTeamsDeviceFunction(CodeGenModule &CGM, StringRef ParentName,\n                                   const OMPTargetTeamsDirective &S);\n  /// Emit device code for the target teams distribute directive.\n  static void EmitOMPTargetTeamsDistributeDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeDirective &S);\n  /// Emit device code for the target teams distribute simd directive.\n  static void EmitOMPTargetTeamsDistributeSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeSimdDirective &S);\n  /// Emit device code for the target simd directive.\n  static void EmitOMPTargetSimdDeviceFunction(CodeGenModule &CGM,\n                                              StringRef ParentName,\n                                              const OMPTargetSimdDirective &S);\n  /// Emit device code for the target teams distribute parallel for simd\n  /// directive.\n  static void EmitOMPTargetTeamsDistributeParallelForSimdDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeParallelForSimdDirective &S);\n\n  static void EmitOMPTargetTeamsDistributeParallelForDeviceFunction(\n      CodeGenModule &CGM, StringRef ParentName,\n      const OMPTargetTeamsDistributeParallelForDirective &S);\n\n  /// Emit the Stmt \\p S and return its topmost canonical loop, if any.\n  /// TODO: The \\p Depth paramter is not yet implemented and must be 1. In the\n  /// future it is meant to be the number of loops expected in the loop nests\n  /// (usually specified by the \"collapse\" clause) that are collapsed to a\n  /// single loop by this function.\n  llvm::CanonicalLoopInfo *EmitOMPCollapsedCanonicalLoopNest(const Stmt *S,\n                                                             int Depth);\n\n  /// Emit an OMPCanonicalLoop using the OpenMPIRBuilder.\n  void EmitOMPCanonicalLoop(const OMPCanonicalLoop *S);\n\n  /// Emit inner loop of the worksharing/simd construct.\n  ///\n  /// \\param S Directive, for which the inner loop must be emitted.\n  /// \\param RequiresCleanup true, if directive has some associated private\n  /// variables.\n  /// \\param LoopCond Bollean condition for loop continuation.\n  /// \\param IncExpr Increment expression for loop control variable.\n  /// \\param BodyGen Generator for the inner body of the inner loop.\n  /// \\param PostIncGen Genrator for post-increment code (required for ordered\n  /// loop directvies).\n  void EmitOMPInnerLoop(\n      const OMPExecutableDirective &S, bool RequiresCleanup,\n      const Expr *LoopCond, const Expr *IncExpr,\n      const llvm::function_ref<void(CodeGenFunction &)> BodyGen,\n      const llvm::function_ref<void(CodeGenFunction &)> PostIncGen);\n\n  JumpDest getOMPCancelDestination(OpenMPDirectiveKind Kind);\n  /// Emit initial code for loop counters of loop-based directives.\n  void EmitOMPPrivateLoopCounters(const OMPLoopDirective &S,\n                                  OMPPrivateScope &LoopScope);\n\n  /// Helper for the OpenMP loop directives.\n  void EmitOMPLoopBody(const OMPLoopDirective &D, JumpDest LoopExit);\n\n  /// Emit code for the worksharing loop-based directive.\n  /// \\return true, if this construct has any lastprivate clause, false -\n  /// otherwise.\n  bool EmitOMPWorksharingLoop(const OMPLoopDirective &S, Expr *EUB,\n                              const CodeGenLoopBoundsTy &CodeGenLoopBounds,\n                              const CodeGenDispatchBoundsTy &CGDispatchBounds);\n\n  /// Emit code for the distribute loop-based directive.\n  void EmitOMPDistributeLoop(const OMPLoopDirective &S,\n                             const CodeGenLoopTy &CodeGenLoop, Expr *IncExpr);\n\n  /// Helpers for the OpenMP loop directives.\n  void EmitOMPSimdInit(const OMPLoopDirective &D, bool IsMonotonic = false);\n  void EmitOMPSimdFinal(\n      const OMPLoopDirective &D,\n      const llvm::function_ref<llvm::Value *(CodeGenFunction &)> CondGen);\n\n  /// Emits the lvalue for the expression with possibly captured variable.\n  LValue EmitOMPSharedLValue(const Expr *E);\n\nprivate:\n  /// Helpers for blocks.\n  llvm::Value *EmitBlockLiteral(const CGBlockInfo &Info);\n\n  /// struct with the values to be passed to the OpenMP loop-related functions\n  struct OMPLoopArguments {\n    /// loop lower bound\n    Address LB = Address::invalid();\n    /// loop upper bound\n    Address UB = Address::invalid();\n    /// loop stride\n    Address ST = Address::invalid();\n    /// isLastIteration argument for runtime functions\n    Address IL = Address::invalid();\n    /// Chunk value generated by sema\n    llvm::Value *Chunk = nullptr;\n    /// EnsureUpperBound\n    Expr *EUB = nullptr;\n    /// IncrementExpression\n    Expr *IncExpr = nullptr;\n    /// Loop initialization\n    Expr *Init = nullptr;\n    /// Loop exit condition\n    Expr *Cond = nullptr;\n    /// Update of LB after a whole chunk has been executed\n    Expr *NextLB = nullptr;\n    /// Update of UB after a whole chunk has been executed\n    Expr *NextUB = nullptr;\n    OMPLoopArguments() = default;\n    OMPLoopArguments(Address LB, Address UB, Address ST, Address IL,\n                     llvm::Value *Chunk = nullptr, Expr *EUB = nullptr,\n                     Expr *IncExpr = nullptr, Expr *Init = nullptr,\n                     Expr *Cond = nullptr, Expr *NextLB = nullptr,\n                     Expr *NextUB = nullptr)\n        : LB(LB), UB(UB), ST(ST), IL(IL), Chunk(Chunk), EUB(EUB),\n          IncExpr(IncExpr), Init(Init), Cond(Cond), NextLB(NextLB),\n          NextUB(NextUB) {}\n  };\n  void EmitOMPOuterLoop(bool DynamicOrOrdered, bool IsMonotonic,\n                        const OMPLoopDirective &S, OMPPrivateScope &LoopScope,\n                        const OMPLoopArguments &LoopArgs,\n                        const CodeGenLoopTy &CodeGenLoop,\n                        const CodeGenOrderedTy &CodeGenOrdered);\n  void EmitOMPForOuterLoop(const OpenMPScheduleTy &ScheduleKind,\n                           bool IsMonotonic, const OMPLoopDirective &S,\n                           OMPPrivateScope &LoopScope, bool Ordered,\n                           const OMPLoopArguments &LoopArgs,\n                           const CodeGenDispatchBoundsTy &CGDispatchBounds);\n  void EmitOMPDistributeOuterLoop(OpenMPDistScheduleClauseKind ScheduleKind,\n                                  const OMPLoopDirective &S,\n                                  OMPPrivateScope &LoopScope,\n                                  const OMPLoopArguments &LoopArgs,\n                                  const CodeGenLoopTy &CodeGenLoopContent);\n  /// Emit code for sections directive.\n  void EmitSections(const OMPExecutableDirective &S);\n\npublic:\n\n  //===--------------------------------------------------------------------===//\n  //                         LValue Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  /// Create a check that a scalar RValue is non-null.\n  llvm::Value *EmitNonNullRValueCheck(RValue RV, QualType T);\n\n  /// GetUndefRValue - Get an appropriate 'undef' rvalue for the given type.\n  RValue GetUndefRValue(QualType Ty);\n\n  /// EmitUnsupportedRValue - Emit a dummy r-value using the type of E\n  /// and issue an ErrorUnsupported style diagnostic (using the\n  /// provided Name).\n  RValue EmitUnsupportedRValue(const Expr *E,\n                               const char *Name);\n\n  /// EmitUnsupportedLValue - Emit a dummy l-value using the type of E and issue\n  /// an ErrorUnsupported style diagnostic (using the provided Name).\n  LValue EmitUnsupportedLValue(const Expr *E,\n                               const char *Name);\n\n  /// EmitLValue - Emit code to compute a designator that specifies the location\n  /// of the expression.\n  ///\n  /// This can return one of two things: a simple address or a bitfield\n  /// reference.  In either case, the LLVM Value* in the LValue structure is\n  /// guaranteed to be an LLVM pointer type.\n  ///\n  /// If this returns a bitfield reference, nothing about the pointee type of\n  /// the LLVM value is known: For example, it may not be a pointer to an\n  /// integer.\n  ///\n  /// If this returns a normal address, and if the lvalue's C type is fixed\n  /// size, this method guarantees that the returned pointer type will point to\n  /// an LLVM type of the same size of the lvalue's type.  If the lvalue has a\n  /// variable length type, this is not possible.\n  ///\n  LValue EmitLValue(const Expr *E);\n\n  /// Same as EmitLValue but additionally we generate checking code to\n  /// guard against undefined behavior.  This is only suitable when we know\n  /// that the address will be used to access the object.\n  LValue EmitCheckedLValue(const Expr *E, TypeCheckKind TCK);\n\n  RValue convertTempToRValue(Address addr, QualType type,\n                             SourceLocation Loc);\n\n  void EmitAtomicInit(Expr *E, LValue lvalue);\n\n  bool LValueIsSuitableForInlineAtomic(LValue Src);\n\n  RValue EmitAtomicLoad(LValue LV, SourceLocation SL,\n                        AggValueSlot Slot = AggValueSlot::ignored());\n\n  RValue EmitAtomicLoad(LValue lvalue, SourceLocation loc,\n                        llvm::AtomicOrdering AO, bool IsVolatile = false,\n                        AggValueSlot slot = AggValueSlot::ignored());\n\n  void EmitAtomicStore(RValue rvalue, LValue lvalue, bool isInit);\n\n  void EmitAtomicStore(RValue rvalue, LValue lvalue, llvm::AtomicOrdering AO,\n                       bool IsVolatile, bool isInit);\n\n  std::pair<RValue, llvm::Value *> EmitAtomicCompareExchange(\n      LValue Obj, RValue Expected, RValue Desired, SourceLocation Loc,\n      llvm::AtomicOrdering Success =\n          llvm::AtomicOrdering::SequentiallyConsistent,\n      llvm::AtomicOrdering Failure =\n          llvm::AtomicOrdering::SequentiallyConsistent,\n      bool IsWeak = false, AggValueSlot Slot = AggValueSlot::ignored());\n\n  void EmitAtomicUpdate(LValue LVal, llvm::AtomicOrdering AO,\n                        const llvm::function_ref<RValue(RValue)> &UpdateOp,\n                        bool IsVolatile);\n\n  /// EmitToMemory - Change a scalar value from its value\n  /// representation to its in-memory representation.\n  llvm::Value *EmitToMemory(llvm::Value *Value, QualType Ty);\n\n  /// EmitFromMemory - Change a scalar value from its memory\n  /// representation to its value representation.\n  llvm::Value *EmitFromMemory(llvm::Value *Value, QualType Ty);\n\n  /// Check if the scalar \\p Value is within the valid range for the given\n  /// type \\p Ty.\n  ///\n  /// Returns true if a check is needed (even if the range is unknown).\n  bool EmitScalarRangeCheck(llvm::Value *Value, QualType Ty,\n                            SourceLocation Loc);\n\n  /// EmitLoadOfScalar - Load a scalar value from an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.\n  llvm::Value *EmitLoadOfScalar(Address Addr, bool Volatile, QualType Ty,\n                                SourceLocation Loc,\n                                AlignmentSource Source = AlignmentSource::Type,\n                                bool isNontemporal = false) {\n    return EmitLoadOfScalar(Addr, Volatile, Ty, Loc, LValueBaseInfo(Source),\n                            CGM.getTBAAAccessInfo(Ty), isNontemporal);\n  }\n\n  llvm::Value *EmitLoadOfScalar(Address Addr, bool Volatile, QualType Ty,\n                                SourceLocation Loc, LValueBaseInfo BaseInfo,\n                                TBAAAccessInfo TBAAInfo,\n                                bool isNontemporal = false);\n\n  /// EmitLoadOfScalar - Load a scalar value from an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.  The l-value must be a simple\n  /// l-value.\n  llvm::Value *EmitLoadOfScalar(LValue lvalue, SourceLocation Loc);\n\n  /// EmitStoreOfScalar - Store a scalar value to an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.\n  void EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                         bool Volatile, QualType Ty,\n                         AlignmentSource Source = AlignmentSource::Type,\n                         bool isInit = false, bool isNontemporal = false) {\n    EmitStoreOfScalar(Value, Addr, Volatile, Ty, LValueBaseInfo(Source),\n                      CGM.getTBAAAccessInfo(Ty), isInit, isNontemporal);\n  }\n\n  void EmitStoreOfScalar(llvm::Value *Value, Address Addr,\n                         bool Volatile, QualType Ty,\n                         LValueBaseInfo BaseInfo, TBAAAccessInfo TBAAInfo,\n                         bool isInit = false, bool isNontemporal = false);\n\n  /// EmitStoreOfScalar - Store a scalar value to an address, taking\n  /// care to appropriately convert from the memory representation to\n  /// the LLVM value representation.  The l-value must be a simple\n  /// l-value.  The isInit flag indicates whether this is an initialization.\n  /// If so, atomic qualifiers are ignored and the store is always non-atomic.\n  void EmitStoreOfScalar(llvm::Value *value, LValue lvalue, bool isInit=false);\n\n  /// EmitLoadOfLValue - Given an expression that represents a value lvalue,\n  /// this method emits the address of the lvalue, then loads the result as an\n  /// rvalue, returning the rvalue.\n  RValue EmitLoadOfLValue(LValue V, SourceLocation Loc);\n  RValue EmitLoadOfExtVectorElementLValue(LValue V);\n  RValue EmitLoadOfBitfieldLValue(LValue LV, SourceLocation Loc);\n  RValue EmitLoadOfGlobalRegLValue(LValue LV);\n\n  /// EmitStoreThroughLValue - Store the specified rvalue into the specified\n  /// lvalue, where both are guaranteed to the have the same type, and that type\n  /// is 'Ty'.\n  void EmitStoreThroughLValue(RValue Src, LValue Dst, bool isInit = false);\n  void EmitStoreThroughExtVectorComponentLValue(RValue Src, LValue Dst);\n  void EmitStoreThroughGlobalRegLValue(RValue Src, LValue Dst);\n\n  /// EmitStoreThroughBitfieldLValue - Store Src into Dst with same constraints\n  /// as EmitStoreThroughLValue.\n  ///\n  /// \\param Result [out] - If non-null, this will be set to a Value* for the\n  /// bit-field contents after the store, appropriate for use as the result of\n  /// an assignment to the bit-field.\n  void EmitStoreThroughBitfieldLValue(RValue Src, LValue Dst,\n                                      llvm::Value **Result=nullptr);\n\n  /// Emit an l-value for an assignment (simple or compound) of complex type.\n  LValue EmitComplexAssignmentLValue(const BinaryOperator *E);\n  LValue EmitComplexCompoundAssignmentLValue(const CompoundAssignOperator *E);\n  LValue EmitScalarCompoundAssignWithComplex(const CompoundAssignOperator *E,\n                                             llvm::Value *&Result);\n\n  // Note: only available for agg return types\n  LValue EmitBinaryOperatorLValue(const BinaryOperator *E);\n  LValue EmitCompoundAssignmentLValue(const CompoundAssignOperator *E);\n  // Note: only available for agg return types\n  LValue EmitCallExprLValue(const CallExpr *E);\n  // Note: only available for agg return types\n  LValue EmitVAArgExprLValue(const VAArgExpr *E);\n  LValue EmitDeclRefLValue(const DeclRefExpr *E);\n  LValue EmitStringLiteralLValue(const StringLiteral *E);\n  LValue EmitObjCEncodeExprLValue(const ObjCEncodeExpr *E);\n  LValue EmitPredefinedLValue(const PredefinedExpr *E);\n  LValue EmitUnaryOpLValue(const UnaryOperator *E);\n  LValue EmitArraySubscriptExpr(const ArraySubscriptExpr *E,\n                                bool Accessed = false);\n  LValue EmitMatrixSubscriptExpr(const MatrixSubscriptExpr *E);\n  LValue EmitOMPArraySectionExpr(const OMPArraySectionExpr *E,\n                                 bool IsLowerBound = true);\n  LValue EmitExtVectorElementExpr(const ExtVectorElementExpr *E);\n  LValue EmitMemberExpr(const MemberExpr *E);\n  LValue EmitObjCIsaExpr(const ObjCIsaExpr *E);\n  LValue EmitCompoundLiteralLValue(const CompoundLiteralExpr *E);\n  LValue EmitInitListLValue(const InitListExpr *E);\n  LValue EmitConditionalOperatorLValue(const AbstractConditionalOperator *E);\n  LValue EmitCastLValue(const CastExpr *E);\n  LValue EmitMaterializeTemporaryExpr(const MaterializeTemporaryExpr *E);\n  LValue EmitOpaqueValueLValue(const OpaqueValueExpr *e);\n\n  Address EmitExtVectorElementLValue(LValue V);\n\n  RValue EmitRValueForField(LValue LV, const FieldDecl *FD, SourceLocation Loc);\n\n  Address EmitArrayToPointerDecay(const Expr *Array,\n                                  LValueBaseInfo *BaseInfo = nullptr,\n                                  TBAAAccessInfo *TBAAInfo = nullptr);\n\n  class ConstantEmission {\n    llvm::PointerIntPair<llvm::Constant*, 1, bool> ValueAndIsReference;\n    ConstantEmission(llvm::Constant *C, bool isReference)\n      : ValueAndIsReference(C, isReference) {}\n  public:\n    ConstantEmission() {}\n    static ConstantEmission forReference(llvm::Constant *C) {\n      return ConstantEmission(C, true);\n    }\n    static ConstantEmission forValue(llvm::Constant *C) {\n      return ConstantEmission(C, false);\n    }\n\n    explicit operator bool() const {\n      return ValueAndIsReference.getOpaqueValue() != nullptr;\n    }\n\n    bool isReference() const { return ValueAndIsReference.getInt(); }\n    LValue getReferenceLValue(CodeGenFunction &CGF, Expr *refExpr) const {\n      assert(isReference());\n      return CGF.MakeNaturalAlignAddrLValue(ValueAndIsReference.getPointer(),\n                                            refExpr->getType());\n    }\n\n    llvm::Constant *getValue() const {\n      assert(!isReference());\n      return ValueAndIsReference.getPointer();\n    }\n  };\n\n  ConstantEmission tryEmitAsConstant(DeclRefExpr *refExpr);\n  ConstantEmission tryEmitAsConstant(const MemberExpr *ME);\n  llvm::Value *emitScalarConstant(const ConstantEmission &Constant, Expr *E);\n\n  RValue EmitPseudoObjectRValue(const PseudoObjectExpr *e,\n                                AggValueSlot slot = AggValueSlot::ignored());\n  LValue EmitPseudoObjectLValue(const PseudoObjectExpr *e);\n\n  llvm::Value *EmitIvarOffset(const ObjCInterfaceDecl *Interface,\n                              const ObjCIvarDecl *Ivar);\n  LValue EmitLValueForField(LValue Base, const FieldDecl* Field);\n  LValue EmitLValueForLambdaField(const FieldDecl *Field);\n\n  /// EmitLValueForFieldInitialization - Like EmitLValueForField, except that\n  /// if the Field is a reference, this will return the address of the reference\n  /// and not the address of the value stored in the reference.\n  LValue EmitLValueForFieldInitialization(LValue Base,\n                                          const FieldDecl* Field);\n\n  LValue EmitLValueForIvar(QualType ObjectTy,\n                           llvm::Value* Base, const ObjCIvarDecl *Ivar,\n                           unsigned CVRQualifiers);\n\n  LValue EmitCXXConstructLValue(const CXXConstructExpr *E);\n  LValue EmitCXXBindTemporaryLValue(const CXXBindTemporaryExpr *E);\n  LValue EmitCXXTypeidLValue(const CXXTypeidExpr *E);\n  LValue EmitCXXUuidofLValue(const CXXUuidofExpr *E);\n\n  LValue EmitObjCMessageExprLValue(const ObjCMessageExpr *E);\n  LValue EmitObjCIvarRefLValue(const ObjCIvarRefExpr *E);\n  LValue EmitStmtExprLValue(const StmtExpr *E);\n  LValue EmitPointerToDataMemberBinaryExpr(const BinaryOperator *E);\n  LValue EmitObjCSelectorLValue(const ObjCSelectorExpr *E);\n  void   EmitDeclRefExprDbgValue(const DeclRefExpr *E, const APValue &Init);\n\n  //===--------------------------------------------------------------------===//\n  //                         Scalar Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  /// EmitCall - Generate a call of the given function, expecting the given\n  /// result type, and using the given argument list which specifies both the\n  /// LLVM arguments and the types they were derived from.\n  RValue EmitCall(const CGFunctionInfo &CallInfo, const CGCallee &Callee,\n                  ReturnValueSlot ReturnValue, const CallArgList &Args,\n                  llvm::CallBase **callOrInvoke, SourceLocation Loc);\n  RValue EmitCall(const CGFunctionInfo &CallInfo, const CGCallee &Callee,\n                  ReturnValueSlot ReturnValue, const CallArgList &Args,\n                  llvm::CallBase **callOrInvoke = nullptr) {\n    return EmitCall(CallInfo, Callee, ReturnValue, Args, callOrInvoke,\n                    SourceLocation());\n  }\n  RValue EmitCall(QualType FnType, const CGCallee &Callee, const CallExpr *E,\n                  ReturnValueSlot ReturnValue, llvm::Value *Chain = nullptr);\n  RValue EmitCallExpr(const CallExpr *E,\n                      ReturnValueSlot ReturnValue = ReturnValueSlot());\n  RValue EmitSimpleCallExpr(const CallExpr *E, ReturnValueSlot ReturnValue);\n  CGCallee EmitCallee(const Expr *E);\n\n  void checkTargetFeatures(const CallExpr *E, const FunctionDecl *TargetDecl);\n  void checkTargetFeatures(SourceLocation Loc, const FunctionDecl *TargetDecl);\n\n  llvm::CallInst *EmitRuntimeCall(llvm::FunctionCallee callee,\n                                  const Twine &name = \"\");\n  llvm::CallInst *EmitRuntimeCall(llvm::FunctionCallee callee,\n                                  ArrayRef<llvm::Value *> args,\n                                  const Twine &name = \"\");\n  llvm::CallInst *EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                          const Twine &name = \"\");\n  llvm::CallInst *EmitNounwindRuntimeCall(llvm::FunctionCallee callee,\n                                          ArrayRef<llvm::Value *> args,\n                                          const Twine &name = \"\");\n\n  SmallVector<llvm::OperandBundleDef, 1>\n  getBundlesForFunclet(llvm::Value *Callee);\n\n  llvm::CallBase *EmitCallOrInvoke(llvm::FunctionCallee Callee,\n                                   ArrayRef<llvm::Value *> Args,\n                                   const Twine &Name = \"\");\n  llvm::CallBase *EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                          ArrayRef<llvm::Value *> args,\n                                          const Twine &name = \"\");\n  llvm::CallBase *EmitRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                          const Twine &name = \"\");\n  void EmitNoreturnRuntimeCallOrInvoke(llvm::FunctionCallee callee,\n                                       ArrayRef<llvm::Value *> args);\n\n  CGCallee BuildAppleKextVirtualCall(const CXXMethodDecl *MD,\n                                     NestedNameSpecifier *Qual,\n                                     llvm::Type *Ty);\n\n  CGCallee BuildAppleKextVirtualDestructorCall(const CXXDestructorDecl *DD,\n                                               CXXDtorType Type,\n                                               const CXXRecordDecl *RD);\n\n  // Return the copy constructor name with the prefix \"__copy_constructor_\"\n  // removed.\n  static std::string getNonTrivialCopyConstructorStr(QualType QT,\n                                                     CharUnits Alignment,\n                                                     bool IsVolatile,\n                                                     ASTContext &Ctx);\n\n  // Return the destructor name with the prefix \"__destructor_\" removed.\n  static std::string getNonTrivialDestructorStr(QualType QT,\n                                                CharUnits Alignment,\n                                                bool IsVolatile,\n                                                ASTContext &Ctx);\n\n  // These functions emit calls to the special functions of non-trivial C\n  // structs.\n  void defaultInitNonTrivialCStructVar(LValue Dst);\n  void callCStructDefaultConstructor(LValue Dst);\n  void callCStructDestructor(LValue Dst);\n  void callCStructCopyConstructor(LValue Dst, LValue Src);\n  void callCStructMoveConstructor(LValue Dst, LValue Src);\n  void callCStructCopyAssignmentOperator(LValue Dst, LValue Src);\n  void callCStructMoveAssignmentOperator(LValue Dst, LValue Src);\n\n  RValue\n  EmitCXXMemberOrOperatorCall(const CXXMethodDecl *Method,\n                              const CGCallee &Callee,\n                              ReturnValueSlot ReturnValue, llvm::Value *This,\n                              llvm::Value *ImplicitParam,\n                              QualType ImplicitParamTy, const CallExpr *E,\n                              CallArgList *RtlArgs);\n  RValue EmitCXXDestructorCall(GlobalDecl Dtor, const CGCallee &Callee,\n                               llvm::Value *This, QualType ThisTy,\n                               llvm::Value *ImplicitParam,\n                               QualType ImplicitParamTy, const CallExpr *E);\n  RValue EmitCXXMemberCallExpr(const CXXMemberCallExpr *E,\n                               ReturnValueSlot ReturnValue);\n  RValue EmitCXXMemberOrOperatorMemberCallExpr(const CallExpr *CE,\n                                               const CXXMethodDecl *MD,\n                                               ReturnValueSlot ReturnValue,\n                                               bool HasQualifier,\n                                               NestedNameSpecifier *Qualifier,\n                                               bool IsArrow, const Expr *Base);\n  // Compute the object pointer.\n  Address EmitCXXMemberDataPointerAddress(const Expr *E, Address base,\n                                          llvm::Value *memberPtr,\n                                          const MemberPointerType *memberPtrType,\n                                          LValueBaseInfo *BaseInfo = nullptr,\n                                          TBAAAccessInfo *TBAAInfo = nullptr);\n  RValue EmitCXXMemberPointerCallExpr(const CXXMemberCallExpr *E,\n                                      ReturnValueSlot ReturnValue);\n\n  RValue EmitCXXOperatorMemberCallExpr(const CXXOperatorCallExpr *E,\n                                       const CXXMethodDecl *MD,\n                                       ReturnValueSlot ReturnValue);\n  RValue EmitCXXPseudoDestructorExpr(const CXXPseudoDestructorExpr *E);\n\n  RValue EmitCUDAKernelCallExpr(const CUDAKernelCallExpr *E,\n                                ReturnValueSlot ReturnValue);\n\n  RValue EmitNVPTXDevicePrintfCallExpr(const CallExpr *E,\n                                       ReturnValueSlot ReturnValue);\n  RValue EmitAMDGPUDevicePrintfCallExpr(const CallExpr *E,\n                                        ReturnValueSlot ReturnValue);\n\n  RValue EmitBuiltinExpr(const GlobalDecl GD, unsigned BuiltinID,\n                         const CallExpr *E, ReturnValueSlot ReturnValue);\n\n  RValue emitRotate(const CallExpr *E, bool IsRotateRight);\n\n  /// Emit IR for __builtin_os_log_format.\n  RValue emitBuiltinOSLogFormat(const CallExpr &E);\n\n  /// Emit IR for __builtin_is_aligned.\n  RValue EmitBuiltinIsAligned(const CallExpr *E);\n  /// Emit IR for __builtin_align_up/__builtin_align_down.\n  RValue EmitBuiltinAlignTo(const CallExpr *E, bool AlignUp);\n\n  llvm::Function *generateBuiltinOSLogHelperFunction(\n      const analyze_os_log::OSLogBufferLayout &Layout,\n      CharUnits BufferAlignment);\n\n  RValue EmitBlockCallExpr(const CallExpr *E, ReturnValueSlot ReturnValue);\n\n  /// EmitTargetBuiltinExpr - Emit the given builtin call. Returns 0 if the call\n  /// is unhandled by the current target.\n  llvm::Value *EmitTargetBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue);\n\n  llvm::Value *EmitAArch64CompareBuiltinExpr(llvm::Value *Op, llvm::Type *Ty,\n                                             const llvm::CmpInst::Predicate Fp,\n                                             const llvm::CmpInst::Predicate Ip,\n                                             const llvm::Twine &Name = \"\");\n  llvm::Value *EmitARMBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                  ReturnValueSlot ReturnValue,\n                                  llvm::Triple::ArchType Arch);\n  llvm::Value *EmitARMMVEBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue,\n                                     llvm::Triple::ArchType Arch);\n  llvm::Value *EmitARMCDEBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                     ReturnValueSlot ReturnValue,\n                                     llvm::Triple::ArchType Arch);\n  llvm::Value *EmitCMSEClearRecord(llvm::Value *V, llvm::IntegerType *ITy,\n                                   QualType RTy);\n  llvm::Value *EmitCMSEClearRecord(llvm::Value *V, llvm::ArrayType *ATy,\n                                   QualType RTy);\n\n  llvm::Value *EmitCommonNeonBuiltinExpr(unsigned BuiltinID,\n                                         unsigned LLVMIntrinsic,\n                                         unsigned AltLLVMIntrinsic,\n                                         const char *NameHint,\n                                         unsigned Modifier,\n                                         const CallExpr *E,\n                                         SmallVectorImpl<llvm::Value *> &Ops,\n                                         Address PtrOp0, Address PtrOp1,\n                                         llvm::Triple::ArchType Arch);\n\n  llvm::Function *LookupNeonLLVMIntrinsic(unsigned IntrinsicID,\n                                          unsigned Modifier, llvm::Type *ArgTy,\n                                          const CallExpr *E);\n  llvm::Value *EmitNeonCall(llvm::Function *F,\n                            SmallVectorImpl<llvm::Value*> &O,\n                            const char *name,\n                            unsigned shift = 0, bool rightshift = false);\n  llvm::Value *EmitNeonSplat(llvm::Value *V, llvm::Constant *Idx,\n                             const llvm::ElementCount &Count);\n  llvm::Value *EmitNeonSplat(llvm::Value *V, llvm::Constant *Idx);\n  llvm::Value *EmitNeonShiftVector(llvm::Value *V, llvm::Type *Ty,\n                                   bool negateForRightShift);\n  llvm::Value *EmitNeonRShiftImm(llvm::Value *Vec, llvm::Value *Amt,\n                                 llvm::Type *Ty, bool usgn, const char *name);\n  llvm::Value *vectorWrapScalar16(llvm::Value *Op);\n  /// SVEBuiltinMemEltTy - Returns the memory element type for this memory\n  /// access builtin.  Only required if it can't be inferred from the base\n  /// pointer operand.\n  llvm::Type *SVEBuiltinMemEltTy(SVETypeFlags TypeFlags);\n\n  SmallVector<llvm::Type *, 2> getSVEOverloadTypes(SVETypeFlags TypeFlags,\n                                                   llvm::Type *ReturnType,\n                                                   ArrayRef<llvm::Value *> Ops);\n  llvm::Type *getEltType(SVETypeFlags TypeFlags);\n  llvm::ScalableVectorType *getSVEType(const SVETypeFlags &TypeFlags);\n  llvm::ScalableVectorType *getSVEPredType(SVETypeFlags TypeFlags);\n  llvm::Value *EmitSVEAllTruePred(SVETypeFlags TypeFlags);\n  llvm::Value *EmitSVEDupX(llvm::Value *Scalar);\n  llvm::Value *EmitSVEDupX(llvm::Value *Scalar, llvm::Type *Ty);\n  llvm::Value *EmitSVEReinterpret(llvm::Value *Val, llvm::Type *Ty);\n  llvm::Value *EmitSVEPMull(SVETypeFlags TypeFlags,\n                            llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                            unsigned BuiltinID);\n  llvm::Value *EmitSVEMovl(SVETypeFlags TypeFlags,\n                           llvm::ArrayRef<llvm::Value *> Ops,\n                           unsigned BuiltinID);\n  llvm::Value *EmitSVEPredicateCast(llvm::Value *Pred,\n                                    llvm::ScalableVectorType *VTy);\n  llvm::Value *EmitSVEGatherLoad(SVETypeFlags TypeFlags,\n                                 llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                                 unsigned IntID);\n  llvm::Value *EmitSVEScatterStore(SVETypeFlags TypeFlags,\n                                   llvm::SmallVectorImpl<llvm::Value *> &Ops,\n                                   unsigned IntID);\n  llvm::Value *EmitSVEMaskedLoad(const CallExpr *, llvm::Type *ReturnTy,\n                                 SmallVectorImpl<llvm::Value *> &Ops,\n                                 unsigned BuiltinID, bool IsZExtReturn);\n  llvm::Value *EmitSVEMaskedStore(const CallExpr *,\n                                  SmallVectorImpl<llvm::Value *> &Ops,\n                                  unsigned BuiltinID);\n  llvm::Value *EmitSVEPrefetchLoad(SVETypeFlags TypeFlags,\n                                   SmallVectorImpl<llvm::Value *> &Ops,\n                                   unsigned BuiltinID);\n  llvm::Value *EmitSVEGatherPrefetch(SVETypeFlags TypeFlags,\n                                     SmallVectorImpl<llvm::Value *> &Ops,\n                                     unsigned IntID);\n  llvm::Value *EmitSVEStructLoad(SVETypeFlags TypeFlags,\n                                 SmallVectorImpl<llvm::Value *> &Ops, unsigned IntID);\n  llvm::Value *EmitSVEStructStore(SVETypeFlags TypeFlags,\n                                  SmallVectorImpl<llvm::Value *> &Ops,\n                                  unsigned IntID);\n  llvm::Value *EmitAArch64SVEBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n\n  llvm::Value *EmitAArch64BuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                      llvm::Triple::ArchType Arch);\n  llvm::Value *EmitBPFBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n\n  llvm::Value *BuildVector(ArrayRef<llvm::Value*> Ops);\n  llvm::Value *EmitX86BuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitPPCBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitAMDGPUBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitSystemZBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitNVPTXBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitWebAssemblyBuiltinExpr(unsigned BuiltinID,\n                                          const CallExpr *E);\n  llvm::Value *EmitHexagonBuiltinExpr(unsigned BuiltinID, const CallExpr *E);\n  llvm::Value *EmitRISCVBuiltinExpr(unsigned BuiltinID, const CallExpr *E,\n                                    ReturnValueSlot ReturnValue);\n  bool ProcessOrderScopeAMDGCN(llvm::Value *Order, llvm::Value *Scope,\n                               llvm::AtomicOrdering &AO,\n                               llvm::SyncScope::ID &SSID);\n\n  enum class MSVCIntrin;\n  llvm::Value *EmitMSVCBuiltinExpr(MSVCIntrin BuiltinID, const CallExpr *E);\n\n  llvm::Value *EmitBuiltinAvailable(const VersionTuple &Version);\n\n  llvm::Value *EmitObjCProtocolExpr(const ObjCProtocolExpr *E);\n  llvm::Value *EmitObjCStringLiteral(const ObjCStringLiteral *E);\n  llvm::Value *EmitObjCBoxedExpr(const ObjCBoxedExpr *E);\n  llvm::Value *EmitObjCArrayLiteral(const ObjCArrayLiteral *E);\n  llvm::Value *EmitObjCDictionaryLiteral(const ObjCDictionaryLiteral *E);\n  llvm::Value *EmitObjCCollectionLiteral(const Expr *E,\n                                const ObjCMethodDecl *MethodWithObjects);\n  llvm::Value *EmitObjCSelectorExpr(const ObjCSelectorExpr *E);\n  RValue EmitObjCMessageExpr(const ObjCMessageExpr *E,\n                             ReturnValueSlot Return = ReturnValueSlot());\n\n  /// Retrieves the default cleanup kind for an ARC cleanup.\n  /// Except under -fobjc-arc-eh, ARC cleanups are normal-only.\n  CleanupKind getARCCleanupKind() {\n    return CGM.getCodeGenOpts().ObjCAutoRefCountExceptions\n             ? NormalAndEHCleanup : NormalCleanup;\n  }\n\n  // ARC primitives.\n  void EmitARCInitWeak(Address addr, llvm::Value *value);\n  void EmitARCDestroyWeak(Address addr);\n  llvm::Value *EmitARCLoadWeak(Address addr);\n  llvm::Value *EmitARCLoadWeakRetained(Address addr);\n  llvm::Value *EmitARCStoreWeak(Address addr, llvm::Value *value, bool ignored);\n  void emitARCCopyAssignWeak(QualType Ty, Address DstAddr, Address SrcAddr);\n  void emitARCMoveAssignWeak(QualType Ty, Address DstAddr, Address SrcAddr);\n  void EmitARCCopyWeak(Address dst, Address src);\n  void EmitARCMoveWeak(Address dst, Address src);\n  llvm::Value *EmitARCRetainAutorelease(QualType type, llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleaseNonBlock(llvm::Value *value);\n  llvm::Value *EmitARCStoreStrong(LValue lvalue, llvm::Value *value,\n                                  bool resultIgnored);\n  llvm::Value *EmitARCStoreStrongCall(Address addr, llvm::Value *value,\n                                      bool resultIgnored);\n  llvm::Value *EmitARCRetain(QualType type, llvm::Value *value);\n  llvm::Value *EmitARCRetainNonBlock(llvm::Value *value);\n  llvm::Value *EmitARCRetainBlock(llvm::Value *value, bool mandatory);\n  void EmitARCDestroyStrong(Address addr, ARCPreciseLifetime_t precise);\n  void EmitARCRelease(llvm::Value *value, ARCPreciseLifetime_t precise);\n  llvm::Value *EmitARCAutorelease(llvm::Value *value);\n  llvm::Value *EmitARCAutoreleaseReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleaseReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCRetainAutoreleasedReturnValue(llvm::Value *value);\n  llvm::Value *EmitARCUnsafeClaimAutoreleasedReturnValue(llvm::Value *value);\n\n  llvm::Value *EmitObjCAutorelease(llvm::Value *value, llvm::Type *returnType);\n  llvm::Value *EmitObjCRetainNonBlock(llvm::Value *value,\n                                      llvm::Type *returnType);\n  void EmitObjCRelease(llvm::Value *value, ARCPreciseLifetime_t precise);\n\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreAutoreleasing(const BinaryOperator *e);\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreStrong(const BinaryOperator *e, bool ignored);\n  std::pair<LValue,llvm::Value*>\n  EmitARCStoreUnsafeUnretained(const BinaryOperator *e, bool ignored);\n\n  llvm::Value *EmitObjCAlloc(llvm::Value *value,\n                             llvm::Type *returnType);\n  llvm::Value *EmitObjCAllocWithZone(llvm::Value *value,\n                                     llvm::Type *returnType);\n  llvm::Value *EmitObjCAllocInit(llvm::Value *value, llvm::Type *resultType);\n\n  llvm::Value *EmitObjCThrowOperand(const Expr *expr);\n  llvm::Value *EmitObjCConsumeObject(QualType T, llvm::Value *Ptr);\n  llvm::Value *EmitObjCExtendObjectLifetime(QualType T, llvm::Value *Ptr);\n\n  llvm::Value *EmitARCExtendBlockObject(const Expr *expr);\n  llvm::Value *EmitARCReclaimReturnedObject(const Expr *e,\n                                            bool allowUnsafeClaim);\n  llvm::Value *EmitARCRetainScalarExpr(const Expr *expr);\n  llvm::Value *EmitARCRetainAutoreleaseScalarExpr(const Expr *expr);\n  llvm::Value *EmitARCUnsafeUnretainedScalarExpr(const Expr *expr);\n\n  void EmitARCIntrinsicUse(ArrayRef<llvm::Value*> values);\n\n  void EmitARCNoopIntrinsicUse(ArrayRef<llvm::Value *> values);\n\n  static Destroyer destroyARCStrongImprecise;\n  static Destroyer destroyARCStrongPrecise;\n  static Destroyer destroyARCWeak;\n  static Destroyer emitARCIntrinsicUse;\n  static Destroyer destroyNonTrivialCStruct;\n\n  void EmitObjCAutoreleasePoolPop(llvm::Value *Ptr);\n  llvm::Value *EmitObjCAutoreleasePoolPush();\n  llvm::Value *EmitObjCMRRAutoreleasePoolPush();\n  void EmitObjCAutoreleasePoolCleanup(llvm::Value *Ptr);\n  void EmitObjCMRRAutoreleasePoolPop(llvm::Value *Ptr);\n\n  /// Emits a reference binding to the passed in expression.\n  RValue EmitReferenceBindingToExpr(const Expr *E);\n\n  //===--------------------------------------------------------------------===//\n  //                           Expression Emission\n  //===--------------------------------------------------------------------===//\n\n  // Expressions are broken into three classes: scalar, complex, aggregate.\n\n  /// EmitScalarExpr - Emit the computation of the specified expression of LLVM\n  /// scalar type, returning the result.\n  llvm::Value *EmitScalarExpr(const Expr *E , bool IgnoreResultAssign = false);\n\n  /// Emit a conversion from the specified type to the specified destination\n  /// type, both of which are LLVM scalar types.\n  llvm::Value *EmitScalarConversion(llvm::Value *Src, QualType SrcTy,\n                                    QualType DstTy, SourceLocation Loc);\n\n  /// Emit a conversion from the specified complex type to the specified\n  /// destination type, where the destination type is an LLVM scalar type.\n  llvm::Value *EmitComplexToScalarConversion(ComplexPairTy Src, QualType SrcTy,\n                                             QualType DstTy,\n                                             SourceLocation Loc);\n\n  /// EmitAggExpr - Emit the computation of the specified expression\n  /// of aggregate type.  The result is computed into the given slot,\n  /// which may be null to indicate that the value is not needed.\n  void EmitAggExpr(const Expr *E, AggValueSlot AS);\n\n  /// EmitAggExprToLValue - Emit the computation of the specified expression of\n  /// aggregate type into a temporary LValue.\n  LValue EmitAggExprToLValue(const Expr *E);\n\n  /// Build all the stores needed to initialize an aggregate at Dest with the\n  /// value Val.\n  void EmitAggregateStore(llvm::Value *Val, Address Dest, bool DestIsVolatile);\n\n  /// EmitExtendGCLifetime - Given a pointer to an Objective-C object,\n  /// make sure it survives garbage collection until this point.\n  void EmitExtendGCLifetime(llvm::Value *object);\n\n  /// EmitComplexExpr - Emit the computation of the specified expression of\n  /// complex type, returning the result.\n  ComplexPairTy EmitComplexExpr(const Expr *E,\n                                bool IgnoreReal = false,\n                                bool IgnoreImag = false);\n\n  /// EmitComplexExprIntoLValue - Emit the given expression of complex\n  /// type and place its result into the specified l-value.\n  void EmitComplexExprIntoLValue(const Expr *E, LValue dest, bool isInit);\n\n  /// EmitStoreOfComplex - Store a complex number into the specified l-value.\n  void EmitStoreOfComplex(ComplexPairTy V, LValue dest, bool isInit);\n\n  /// EmitLoadOfComplex - Load a complex number from the specified l-value.\n  ComplexPairTy EmitLoadOfComplex(LValue src, SourceLocation loc);\n\n  Address emitAddrOfRealComponent(Address complex, QualType complexType);\n  Address emitAddrOfImagComponent(Address complex, QualType complexType);\n\n  /// AddInitializerToStaticVarDecl - Add the initializer for 'D' to the\n  /// global variable that has already been created for it.  If the initializer\n  /// has a different type than GV does, this may free GV and return a different\n  /// one.  Otherwise it just returns GV.\n  llvm::GlobalVariable *\n  AddInitializerToStaticVarDecl(const VarDecl &D,\n                                llvm::GlobalVariable *GV);\n\n  // Emit an @llvm.invariant.start call for the given memory region.\n  void EmitInvariantStart(llvm::Constant *Addr, CharUnits Size);\n\n  /// EmitCXXGlobalVarDeclInit - Create the initializer for a C++\n  /// variable with global storage.\n  void EmitCXXGlobalVarDeclInit(const VarDecl &D, llvm::Constant *DeclPtr,\n                                bool PerformInit);\n\n  llvm::Function *createAtExitStub(const VarDecl &VD, llvm::FunctionCallee Dtor,\n                                   llvm::Constant *Addr);\n\n  /// Call atexit() with a function that passes the given argument to\n  /// the given function.\n  void registerGlobalDtorWithAtExit(const VarDecl &D, llvm::FunctionCallee fn,\n                                    llvm::Constant *addr);\n\n  /// Call atexit() with function dtorStub.\n  void registerGlobalDtorWithAtExit(llvm::Constant *dtorStub);\n\n  /// Call unatexit() with function dtorStub.\n  llvm::Value *unregisterGlobalDtorWithUnAtExit(llvm::Constant *dtorStub);\n\n  /// Emit code in this function to perform a guarded variable\n  /// initialization.  Guarded initializations are used when it's not\n  /// possible to prove that an initialization will be done exactly\n  /// once, e.g. with a static local variable or a static data member\n  /// of a class template.\n  void EmitCXXGuardedInit(const VarDecl &D, llvm::GlobalVariable *DeclPtr,\n                          bool PerformInit);\n\n  enum class GuardKind { VariableGuard, TlsGuard };\n\n  /// Emit a branch to select whether or not to perform guarded initialization.\n  void EmitCXXGuardedInitBranch(llvm::Value *NeedsInit,\n                                llvm::BasicBlock *InitBlock,\n                                llvm::BasicBlock *NoInitBlock,\n                                GuardKind Kind, const VarDecl *D);\n\n  /// GenerateCXXGlobalInitFunc - Generates code for initializing global\n  /// variables.\n  void\n  GenerateCXXGlobalInitFunc(llvm::Function *Fn,\n                            ArrayRef<llvm::Function *> CXXThreadLocals,\n                            ConstantAddress Guard = ConstantAddress::invalid());\n\n  /// GenerateCXXGlobalCleanUpFunc - Generates code for cleaning up global\n  /// variables.\n  void GenerateCXXGlobalCleanUpFunc(\n      llvm::Function *Fn,\n      const std::vector<std::tuple<llvm::FunctionType *, llvm::WeakTrackingVH,\n                                   llvm::Constant *>> &DtorsOrStermFinalizers);\n\n  void GenerateCXXGlobalVarDeclInitFunc(llvm::Function *Fn,\n                                        const VarDecl *D,\n                                        llvm::GlobalVariable *Addr,\n                                        bool PerformInit);\n\n  void EmitCXXConstructExpr(const CXXConstructExpr *E, AggValueSlot Dest);\n\n  void EmitSynthesizedCXXCopyCtor(Address Dest, Address Src, const Expr *Exp);\n\n  void EmitCXXThrowExpr(const CXXThrowExpr *E, bool KeepInsertionPoint = true);\n\n  RValue EmitAtomicExpr(AtomicExpr *E);\n\n  //===--------------------------------------------------------------------===//\n  //                         Annotations Emission\n  //===--------------------------------------------------------------------===//\n\n  /// Emit an annotation call (intrinsic).\n  llvm::Value *EmitAnnotationCall(llvm::Function *AnnotationFn,\n                                  llvm::Value *AnnotatedVal,\n                                  StringRef AnnotationStr,\n                                  SourceLocation Location,\n                                  const AnnotateAttr *Attr);\n\n  /// Emit local annotations for the local variable V, declared by D.\n  void EmitVarAnnotations(const VarDecl *D, llvm::Value *V);\n\n  /// Emit field annotations for the given field & value. Returns the\n  /// annotation result.\n  Address EmitFieldAnnotations(const FieldDecl *D, Address V);\n\n  //===--------------------------------------------------------------------===//\n  //                             Internal Helpers\n  //===--------------------------------------------------------------------===//\n\n  /// ContainsLabel - Return true if the statement contains a label in it.  If\n  /// this statement is not executed normally, it not containing a label means\n  /// that we can just remove the code.\n  static bool ContainsLabel(const Stmt *S, bool IgnoreCaseStmts = false);\n\n  /// containsBreak - Return true if the statement contains a break out of it.\n  /// If the statement (recursively) contains a switch or loop with a break\n  /// inside of it, this is fine.\n  static bool containsBreak(const Stmt *S);\n\n  /// Determine if the given statement might introduce a declaration into the\n  /// current scope, by being a (possibly-labelled) DeclStmt.\n  static bool mightAddDeclToScope(const Stmt *S);\n\n  /// ConstantFoldsToSimpleInteger - If the specified expression does not fold\n  /// to a constant, or if it does but contains a label, return false.  If it\n  /// constant folds return true and set the boolean result in Result.\n  bool ConstantFoldsToSimpleInteger(const Expr *Cond, bool &Result,\n                                    bool AllowLabels = false);\n\n  /// ConstantFoldsToSimpleInteger - If the specified expression does not fold\n  /// to a constant, or if it does but contains a label, return false.  If it\n  /// constant folds return true and set the folded value.\n  bool ConstantFoldsToSimpleInteger(const Expr *Cond, llvm::APSInt &Result,\n                                    bool AllowLabels = false);\n\n  /// isInstrumentedCondition - Determine whether the given condition is an\n  /// instrumentable condition (i.e. no \"&&\" or \"||\").\n  static bool isInstrumentedCondition(const Expr *C);\n\n  /// EmitBranchToCounterBlock - Emit a conditional branch to a new block that\n  /// increments a profile counter based on the semantics of the given logical\n  /// operator opcode.  This is used to instrument branch condition coverage\n  /// for logical operators.\n  void EmitBranchToCounterBlock(const Expr *Cond, BinaryOperator::Opcode LOp,\n                                llvm::BasicBlock *TrueBlock,\n                                llvm::BasicBlock *FalseBlock,\n                                uint64_t TrueCount = 0,\n                                Stmt::Likelihood LH = Stmt::LH_None,\n                                const Expr *CntrIdx = nullptr);\n\n  /// EmitBranchOnBoolExpr - Emit a branch on a boolean condition (e.g. for an\n  /// if statement) to the specified blocks.  Based on the condition, this might\n  /// try to simplify the codegen of the conditional based on the branch.\n  /// TrueCount should be the number of times we expect the condition to\n  /// evaluate to true based on PGO data.\n  void EmitBranchOnBoolExpr(const Expr *Cond, llvm::BasicBlock *TrueBlock,\n                            llvm::BasicBlock *FalseBlock, uint64_t TrueCount,\n                            Stmt::Likelihood LH = Stmt::LH_None);\n\n  /// Given an assignment `*LHS = RHS`, emit a test that checks if \\p RHS is\n  /// nonnull, if \\p LHS is marked _Nonnull.\n  void EmitNullabilityCheck(LValue LHS, llvm::Value *RHS, SourceLocation Loc);\n\n  /// An enumeration which makes it easier to specify whether or not an\n  /// operation is a subtraction.\n  enum { NotSubtraction = false, IsSubtraction = true };\n\n  /// Same as IRBuilder::CreateInBoundsGEP, but additionally emits a check to\n  /// detect undefined behavior when the pointer overflow sanitizer is enabled.\n  /// \\p SignedIndices indicates whether any of the GEP indices are signed.\n  /// \\p IsSubtraction indicates whether the expression used to form the GEP\n  /// is a subtraction.\n  llvm::Value *EmitCheckedInBoundsGEP(llvm::Value *Ptr,\n                                      ArrayRef<llvm::Value *> IdxList,\n                                      bool SignedIndices,\n                                      bool IsSubtraction,\n                                      SourceLocation Loc,\n                                      const Twine &Name = \"\");\n\n  /// Specifies which type of sanitizer check to apply when handling a\n  /// particular builtin.\n  enum BuiltinCheckKind {\n    BCK_CTZPassedZero,\n    BCK_CLZPassedZero,\n  };\n\n  /// Emits an argument for a call to a builtin. If the builtin sanitizer is\n  /// enabled, a runtime check specified by \\p Kind is also emitted.\n  llvm::Value *EmitCheckedArgForBuiltin(const Expr *E, BuiltinCheckKind Kind);\n\n  /// Emit a description of a type in a format suitable for passing to\n  /// a runtime sanitizer handler.\n  llvm::Constant *EmitCheckTypeDescriptor(QualType T);\n\n  /// Convert a value into a format suitable for passing to a runtime\n  /// sanitizer handler.\n  llvm::Value *EmitCheckValue(llvm::Value *V);\n\n  /// Emit a description of a source location in a format suitable for\n  /// passing to a runtime sanitizer handler.\n  llvm::Constant *EmitCheckSourceLocation(SourceLocation Loc);\n\n  /// Create a basic block that will either trap or call a handler function in\n  /// the UBSan runtime with the provided arguments, and create a conditional\n  /// branch to it.\n  void EmitCheck(ArrayRef<std::pair<llvm::Value *, SanitizerMask>> Checked,\n                 SanitizerHandler Check, ArrayRef<llvm::Constant *> StaticArgs,\n                 ArrayRef<llvm::Value *> DynamicArgs);\n\n  /// Emit a slow path cross-DSO CFI check which calls __cfi_slowpath\n  /// if Cond if false.\n  void EmitCfiSlowPathCheck(SanitizerMask Kind, llvm::Value *Cond,\n                            llvm::ConstantInt *TypeId, llvm::Value *Ptr,\n                            ArrayRef<llvm::Constant *> StaticArgs);\n\n  /// Emit a reached-unreachable diagnostic if \\p Loc is valid and runtime\n  /// checking is enabled. Otherwise, just emit an unreachable instruction.\n  void EmitUnreachable(SourceLocation Loc);\n\n  /// Create a basic block that will call the trap intrinsic, and emit a\n  /// conditional branch to it, for the -ftrapv checks.\n  void EmitTrapCheck(llvm::Value *Checked, SanitizerHandler CheckHandlerID);\n\n  /// Emit a call to trap or debugtrap and attach function attribute\n  /// \"trap-func-name\" if specified.\n  llvm::CallInst *EmitTrapCall(llvm::Intrinsic::ID IntrID);\n\n  /// Emit a stub for the cross-DSO CFI check function.\n  void EmitCfiCheckStub();\n\n  /// Emit a cross-DSO CFI failure handling function.\n  void EmitCfiCheckFail();\n\n  /// Create a check for a function parameter that may potentially be\n  /// declared as non-null.\n  void EmitNonNullArgCheck(RValue RV, QualType ArgType, SourceLocation ArgLoc,\n                           AbstractCallee AC, unsigned ParmNum);\n\n  /// EmitCallArg - Emit a single call argument.\n  void EmitCallArg(CallArgList &args, const Expr *E, QualType ArgType);\n\n  /// EmitDelegateCallArg - We are performing a delegate call; that\n  /// is, the current function is delegating to another one.  Produce\n  /// a r-value suitable for passing the given parameter.\n  void EmitDelegateCallArg(CallArgList &args, const VarDecl *param,\n                           SourceLocation loc);\n\n  /// SetFPAccuracy - Set the minimum required accuracy of the given floating\n  /// point operation, expressed as the maximum relative error in ulp.\n  void SetFPAccuracy(llvm::Value *Val, float Accuracy);\n\n  /// SetFPModel - Control floating point behavior via fp-model settings.\n  void SetFPModel();\n\n  /// Set the codegen fast-math flags.\n  void SetFastMathFlags(FPOptions FPFeatures);\n\nprivate:\n  llvm::MDNode *getRangeForLoadFromType(QualType Ty);\n  void EmitReturnOfRValue(RValue RV, QualType Ty);\n\n  void deferPlaceholderReplacement(llvm::Instruction *Old, llvm::Value *New);\n\n  llvm::SmallVector<std::pair<llvm::WeakTrackingVH, llvm::Value *>, 4>\n      DeferredReplacements;\n\n  /// Set the address of a local variable.\n  void setAddrOfLocalVar(const VarDecl *VD, Address Addr) {\n    assert(!LocalDeclMap.count(VD) && \"Decl already exists in LocalDeclMap!\");\n    LocalDeclMap.insert({VD, Addr});\n  }\n\n  /// ExpandTypeFromArgs - Reconstruct a structure of type \\arg Ty\n  /// from function arguments into \\arg Dst. See ABIArgInfo::Expand.\n  ///\n  /// \\param AI - The first function argument of the expansion.\n  void ExpandTypeFromArgs(QualType Ty, LValue Dst,\n                          llvm::Function::arg_iterator &AI);\n\n  /// ExpandTypeToArgs - Expand an CallArg \\arg Arg, with the LLVM type for \\arg\n  /// Ty, into individual arguments on the provided vector \\arg IRCallArgs,\n  /// starting at index \\arg IRCallArgPos. See ABIArgInfo::Expand.\n  void ExpandTypeToArgs(QualType Ty, CallArg Arg, llvm::FunctionType *IRFuncTy,\n                        SmallVectorImpl<llvm::Value *> &IRCallArgs,\n                        unsigned &IRCallArgPos);\n\n  llvm::Value* EmitAsmInput(const TargetInfo::ConstraintInfo &Info,\n                            const Expr *InputExpr, std::string &ConstraintStr);\n\n  llvm::Value* EmitAsmInputLValue(const TargetInfo::ConstraintInfo &Info,\n                                  LValue InputValue, QualType InputType,\n                                  std::string &ConstraintStr,\n                                  SourceLocation Loc);\n\n  /// Attempts to statically evaluate the object size of E. If that\n  /// fails, emits code to figure the size of E out for us. This is\n  /// pass_object_size aware.\n  ///\n  /// If EmittedExpr is non-null, this will use that instead of re-emitting E.\n  llvm::Value *evaluateOrEmitBuiltinObjectSize(const Expr *E, unsigned Type,\n                                               llvm::IntegerType *ResType,\n                                               llvm::Value *EmittedE,\n                                               bool IsDynamic);\n\n  /// Emits the size of E, as required by __builtin_object_size. This\n  /// function is aware of pass_object_size parameters, and will act accordingly\n  /// if E is a parameter with the pass_object_size attribute.\n  llvm::Value *emitBuiltinObjectSize(const Expr *E, unsigned Type,\n                                     llvm::IntegerType *ResType,\n                                     llvm::Value *EmittedE,\n                                     bool IsDynamic);\n\n  void emitZeroOrPatternForAutoVarInit(QualType type, const VarDecl &D,\n                                       Address Loc);\n\npublic:\n  enum class EvaluationOrder {\n    ///! No language constraints on evaluation order.\n    Default,\n    ///! Language semantics require left-to-right evaluation.\n    ForceLeftToRight,\n    ///! Language semantics require right-to-left evaluation.\n    ForceRightToLeft\n  };\n\n  // Wrapper for function prototype sources. Wraps either a FunctionProtoType or\n  // an ObjCMethodDecl.\n  struct PrototypeWrapper {\n    llvm::PointerUnion<const FunctionProtoType *, const ObjCMethodDecl *> P;\n\n    PrototypeWrapper(const FunctionProtoType *FT) : P(FT) {}\n    PrototypeWrapper(const ObjCMethodDecl *MD) : P(MD) {}\n  };\n\n  void EmitCallArgs(CallArgList &Args, PrototypeWrapper Prototype,\n                    llvm::iterator_range<CallExpr::const_arg_iterator> ArgRange,\n                    AbstractCallee AC = AbstractCallee(),\n                    unsigned ParamsToSkip = 0,\n                    EvaluationOrder Order = EvaluationOrder::Default);\n\n  /// EmitPointerWithAlignment - Given an expression with a pointer type,\n  /// emit the value and compute our best estimate of the alignment of the\n  /// pointee.\n  ///\n  /// \\param BaseInfo - If non-null, this will be initialized with\n  /// information about the source of the alignment and the may-alias\n  /// attribute.  Note that this function will conservatively fall back on\n  /// the type when it doesn't recognize the expression and may-alias will\n  /// be set to false.\n  ///\n  /// One reasonable way to use this information is when there's a language\n  /// guarantee that the pointer must be aligned to some stricter value, and\n  /// we're simply trying to ensure that sufficiently obvious uses of under-\n  /// aligned objects don't get miscompiled; for example, a placement new\n  /// into the address of a local variable.  In such a case, it's quite\n  /// reasonable to just ignore the returned alignment when it isn't from an\n  /// explicit source.\n  Address EmitPointerWithAlignment(const Expr *Addr,\n                                   LValueBaseInfo *BaseInfo = nullptr,\n                                   TBAAAccessInfo *TBAAInfo = nullptr);\n\n  /// If \\p E references a parameter with pass_object_size info or a constant\n  /// array size modifier, emit the object size divided by the size of \\p EltTy.\n  /// Otherwise return null.\n  llvm::Value *LoadPassedObjectSize(const Expr *E, QualType EltTy);\n\n  void EmitSanitizerStatReport(llvm::SanitizerStatKind SSK);\n\n  struct MultiVersionResolverOption {\n    llvm::Function *Function;\n    FunctionDecl *FD;\n    struct Conds {\n      StringRef Architecture;\n      llvm::SmallVector<StringRef, 8> Features;\n\n      Conds(StringRef Arch, ArrayRef<StringRef> Feats)\n          : Architecture(Arch), Features(Feats.begin(), Feats.end()) {}\n    } Conditions;\n\n    MultiVersionResolverOption(llvm::Function *F, StringRef Arch,\n                               ArrayRef<StringRef> Feats)\n        : Function(F), Conditions(Arch, Feats) {}\n  };\n\n  // Emits the body of a multiversion function's resolver. Assumes that the\n  // options are already sorted in the proper order, with the 'default' option\n  // last (if it exists).\n  void EmitMultiVersionResolver(llvm::Function *Resolver,\n                                ArrayRef<MultiVersionResolverOption> Options);\n\n  static uint64_t GetX86CpuSupportsMask(ArrayRef<StringRef> FeatureStrs);\n\nprivate:\n  QualType getVarArgType(const Expr *Arg);\n\n  void EmitDeclMetadata();\n\n  BlockByrefHelpers *buildByrefHelpers(llvm::StructType &byrefType,\n                                  const AutoVarEmission &emission);\n\n  void AddObjCARCExceptionMetadata(llvm::Instruction *Inst);\n\n  llvm::Value *GetValueForARMHint(unsigned BuiltinID);\n  llvm::Value *EmitX86CpuIs(const CallExpr *E);\n  llvm::Value *EmitX86CpuIs(StringRef CPUStr);\n  llvm::Value *EmitX86CpuSupports(const CallExpr *E);\n  llvm::Value *EmitX86CpuSupports(ArrayRef<StringRef> FeatureStrs);\n  llvm::Value *EmitX86CpuSupports(uint64_t Mask);\n  llvm::Value *EmitX86CpuInit();\n  llvm::Value *FormResolverCondition(const MultiVersionResolverOption &RO);\n};\n\n/// TargetFeatures - This class is used to check whether the builtin function\n/// has the required tagert specific features. It is able to support the\n/// combination of ','(and), '|'(or), and '()'. By default, the priority of\n/// ',' is higher than that of '|' .\n/// E.g:\n/// A,B|C means the builtin function requires both A and B, or C.\n/// If we want the builtin function requires both A and B, or both A and C,\n/// there are two ways: A,B|A,C or A,(B|C).\n/// The FeaturesList should not contain spaces, and brackets must appear in\n/// pairs.\nclass TargetFeatures {\n  struct FeatureListStatus {\n    bool HasFeatures;\n    StringRef CurFeaturesList;\n  };\n\n  const llvm::StringMap<bool> &CallerFeatureMap;\n\n  FeatureListStatus getAndFeatures(StringRef FeatureList) {\n    int InParentheses = 0;\n    bool HasFeatures = true;\n    size_t SubexpressionStart = 0;\n    for (size_t i = 0, e = FeatureList.size(); i < e; ++i) {\n      char CurrentToken = FeatureList[i];\n      switch (CurrentToken) {\n      default:\n        break;\n      case '(':\n        if (InParentheses == 0)\n          SubexpressionStart = i + 1;\n        ++InParentheses;\n        break;\n      case ')':\n        --InParentheses;\n        assert(InParentheses >= 0 && \"Parentheses are not in pair\");\n        LLVM_FALLTHROUGH;\n      case '|':\n      case ',':\n        if (InParentheses == 0) {\n          if (HasFeatures && i != SubexpressionStart) {\n            StringRef F = FeatureList.slice(SubexpressionStart, i);\n            HasFeatures = CurrentToken == ')' ? hasRequiredFeatures(F)\n                                              : CallerFeatureMap.lookup(F);\n          }\n          SubexpressionStart = i + 1;\n          if (CurrentToken == '|') {\n            return {HasFeatures, FeatureList.substr(SubexpressionStart)};\n          }\n        }\n        break;\n      }\n    }\n    assert(InParentheses == 0 && \"Parentheses are not in pair\");\n    if (HasFeatures && SubexpressionStart != FeatureList.size())\n      HasFeatures =\n          CallerFeatureMap.lookup(FeatureList.substr(SubexpressionStart));\n    return {HasFeatures, StringRef()};\n  }\n\npublic:\n  bool hasRequiredFeatures(StringRef FeatureList) {\n    FeatureListStatus FS = {false, FeatureList};\n    while (!FS.HasFeatures && !FS.CurFeaturesList.empty())\n      FS = getAndFeatures(FS.CurFeaturesList);\n    return FS.HasFeatures;\n  }\n\n  TargetFeatures(const llvm::StringMap<bool> &CallerFeatureMap)\n      : CallerFeatureMap(CallerFeatureMap) {}\n};\n\ninline DominatingLLVMValue::saved_type\nDominatingLLVMValue::save(CodeGenFunction &CGF, llvm::Value *value) {\n  if (!needsSaving(value)) return saved_type(value, false);\n\n  // Otherwise, we need an alloca.\n  auto align = CharUnits::fromQuantity(\n            CGF.CGM.getDataLayout().getPrefTypeAlignment(value->getType()));\n  Address alloca =\n    CGF.CreateTempAlloca(value->getType(), align, \"cond-cleanup.save\");\n  CGF.Builder.CreateStore(value, alloca);\n\n  return saved_type(alloca.getPointer(), true);\n}\n\ninline llvm::Value *DominatingLLVMValue::restore(CodeGenFunction &CGF,\n                                                 saved_type value) {\n  // If the value says it wasn't saved, trust that it's still dominating.\n  if (!value.getInt()) return value.getPointer();\n\n  // Otherwise, it should be an alloca instruction, as set up in save().\n  auto alloca = cast<llvm::AllocaInst>(value.getPointer());\n  return CGF.Builder.CreateAlignedLoad(alloca, alloca->getAlign());\n}\n\n}  // end namespace CodeGen\n\n// Map the LangOption for floating point exception behavior into\n// the corresponding enum in the IR.\nllvm::fp::ExceptionBehavior\nToConstrainedExceptMD(LangOptions::FPExceptionModeKind Kind);\n}  // end namespace clang\n\n#endif\n"}, "55": {"id": 55, "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenTBAA.h", "content": "//===--- CodeGenTBAA.h - TBAA information for LLVM CodeGen ------*- C++ -*-===//\n//\n// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n// See https://llvm.org/LICENSE.txt for license information.\n// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n//\n//===----------------------------------------------------------------------===//\n//\n// This is the code that manages TBAA information and defines the TBAA policy\n// for the optimizer to use.\n//\n//===----------------------------------------------------------------------===//\n\n#ifndef LLVM_CLANG_LIB_CODEGEN_CODEGENTBAA_H\n#define LLVM_CLANG_LIB_CODEGEN_CODEGENTBAA_H\n\n#include \"clang/AST/Type.h\"\n#include \"clang/Basic/LLVM.h\"\n#include \"llvm/ADT/DenseMap.h\"\n#include \"llvm/IR/MDBuilder.h\"\n#include \"llvm/IR/Metadata.h\"\n\nnamespace clang {\n  class ASTContext;\n  class CodeGenOptions;\n  class LangOptions;\n  class MangleContext;\n  class QualType;\n  class Type;\n\nnamespace CodeGen {\nclass CGRecordLayout;\n\n// TBAAAccessKind - A kind of TBAA memory access descriptor.\nenum class TBAAAccessKind : unsigned {\n  Ordinary,\n  MayAlias,\n  Incomplete,\n};\n\n// TBAAAccessInfo - Describes a memory access in terms of TBAA.\nstruct TBAAAccessInfo {\n  TBAAAccessInfo(TBAAAccessKind Kind, llvm::MDNode *BaseType,\n                 llvm::MDNode *AccessType, uint64_t Offset, uint64_t Size)\n    : Kind(Kind), BaseType(BaseType), AccessType(AccessType),\n      Offset(Offset), Size(Size)\n  {}\n\n  TBAAAccessInfo(llvm::MDNode *BaseType, llvm::MDNode *AccessType,\n                 uint64_t Offset, uint64_t Size)\n    : TBAAAccessInfo(TBAAAccessKind::Ordinary, BaseType, AccessType,\n                     Offset, Size)\n  {}\n\n  explicit TBAAAccessInfo(llvm::MDNode *AccessType, uint64_t Size)\n    : TBAAAccessInfo(/* BaseType= */ nullptr, AccessType, /* Offset= */ 0, Size)\n  {}\n\n  TBAAAccessInfo()\n    : TBAAAccessInfo(/* AccessType= */ nullptr, /* Size= */ 0)\n  {}\n\n  static TBAAAccessInfo getMayAliasInfo() {\n    return TBAAAccessInfo(TBAAAccessKind::MayAlias,\n                          /* BaseType= */ nullptr, /* AccessType= */ nullptr,\n                          /* Offset= */ 0, /* Size= */ 0);\n  }\n\n  bool isMayAlias() const { return Kind == TBAAAccessKind::MayAlias; }\n\n  static TBAAAccessInfo getIncompleteInfo() {\n    return TBAAAccessInfo(TBAAAccessKind::Incomplete,\n                          /* BaseType= */ nullptr, /* AccessType= */ nullptr,\n                          /* Offset= */ 0, /* Size= */ 0);\n  }\n\n  bool isIncomplete() const { return Kind == TBAAAccessKind::Incomplete; }\n\n  bool operator==(const TBAAAccessInfo &Other) const {\n    return Kind == Other.Kind &&\n           BaseType == Other.BaseType &&\n           AccessType == Other.AccessType &&\n           Offset == Other.Offset &&\n           Size == Other.Size;\n  }\n\n  bool operator!=(const TBAAAccessInfo &Other) const {\n    return !(*this == Other);\n  }\n\n  explicit operator bool() const {\n    return *this != TBAAAccessInfo();\n  }\n\n  /// Kind - The kind of the access descriptor.\n  TBAAAccessKind Kind;\n\n  /// BaseType - The base/leading access type. May be null if this access\n  /// descriptor represents an access that is not considered to be an access\n  /// to an aggregate or union member.\n  llvm::MDNode *BaseType;\n\n  /// AccessType - The final access type. May be null if there is no TBAA\n  /// information available about this access.\n  llvm::MDNode *AccessType;\n\n  /// Offset - The byte offset of the final access within the base one. Must be\n  /// zero if the base access type is not specified.\n  uint64_t Offset;\n\n  /// Size - The size of access, in bytes.\n  uint64_t Size;\n};\n\n/// CodeGenTBAA - This class organizes the cross-module state that is used\n/// while lowering AST types to LLVM types.\nclass CodeGenTBAA {\n  ASTContext &Context;\n  llvm::Module &Module;\n  const CodeGenOptions &CodeGenOpts;\n  const LangOptions &Features;\n  MangleContext &MContext;\n\n  // MDHelper - Helper for creating metadata.\n  llvm::MDBuilder MDHelper;\n\n  /// MetadataCache - This maps clang::Types to scalar llvm::MDNodes describing\n  /// them.\n  llvm::DenseMap<const Type *, llvm::MDNode *> MetadataCache;\n  /// This maps clang::Types to a base access type in the type DAG.\n  llvm::DenseMap<const Type *, llvm::MDNode *> BaseTypeMetadataCache;\n  /// This maps TBAA access descriptors to tag nodes.\n  llvm::DenseMap<TBAAAccessInfo, llvm::MDNode *> AccessTagMetadataCache;\n\n  /// StructMetadataCache - This maps clang::Types to llvm::MDNodes describing\n  /// them for struct assignments.\n  llvm::DenseMap<const Type *, llvm::MDNode *> StructMetadataCache;\n\n  llvm::MDNode *Root;\n  llvm::MDNode *Char;\n\n  /// getRoot - This is the mdnode for the root of the metadata type graph\n  /// for this translation unit.\n  llvm::MDNode *getRoot();\n\n  /// getChar - This is the mdnode for \"char\", which is special, and any types\n  /// considered to be equivalent to it.\n  llvm::MDNode *getChar();\n\n  /// CollectFields - Collect information about the fields of a type for\n  /// !tbaa.struct metadata formation. Return false for an unsupported type.\n  bool CollectFields(uint64_t BaseOffset,\n                     QualType Ty,\n                     SmallVectorImpl<llvm::MDBuilder::TBAAStructField> &Fields,\n                     bool MayAlias);\n\n  /// createScalarTypeNode - A wrapper function to create a metadata node\n  /// describing a scalar type.\n  llvm::MDNode *createScalarTypeNode(StringRef Name, llvm::MDNode *Parent,\n                                     uint64_t Size);\n\n  /// getTypeInfoHelper - An internal helper function to generate metadata used\n  /// to describe accesses to objects of the given type.\n  llvm::MDNode *getTypeInfoHelper(const Type *Ty);\n\n  /// getBaseTypeInfoHelper - An internal helper function to generate metadata\n  /// used to describe accesses to objects of the given base type.\n  llvm::MDNode *getBaseTypeInfoHelper(const Type *Ty);\n\npublic:\n  CodeGenTBAA(ASTContext &Ctx, llvm::Module &M, const CodeGenOptions &CGO,\n              const LangOptions &Features, MangleContext &MContext);\n  ~CodeGenTBAA();\n\n  /// getTypeInfo - Get metadata used to describe accesses to objects of the\n  /// given type.\n  llvm::MDNode *getTypeInfo(QualType QTy);\n\n  /// getAccessInfo - Get TBAA information that describes an access to\n  /// an object of the given type.\n  TBAAAccessInfo getAccessInfo(QualType AccessType);\n\n  /// getVTablePtrAccessInfo - Get the TBAA information that describes an\n  /// access to a virtual table pointer.\n  TBAAAccessInfo getVTablePtrAccessInfo(llvm::Type *VTablePtrType);\n\n  /// getTBAAStructInfo - Get the TBAAStruct MDNode to be used for a memcpy of\n  /// the given type.\n  llvm::MDNode *getTBAAStructInfo(QualType QTy);\n\n  /// getBaseTypeInfo - Get metadata that describes the given base access type.\n  /// Return null if the type is not suitable for use in TBAA access tags.\n  llvm::MDNode *getBaseTypeInfo(QualType QTy);\n\n  /// getAccessTagInfo - Get TBAA tag for a given memory access.\n  llvm::MDNode *getAccessTagInfo(TBAAAccessInfo Info);\n\n  /// mergeTBAAInfoForCast - Get merged TBAA information for the purpose of\n  /// type casts.\n  TBAAAccessInfo mergeTBAAInfoForCast(TBAAAccessInfo SourceInfo,\n                                      TBAAAccessInfo TargetInfo);\n\n  /// mergeTBAAInfoForConditionalOperator - Get merged TBAA information for the\n  /// purpose of conditional operator.\n  TBAAAccessInfo mergeTBAAInfoForConditionalOperator(TBAAAccessInfo InfoA,\n                                                     TBAAAccessInfo InfoB);\n\n  /// mergeTBAAInfoForMemoryTransfer - Get merged TBAA information for the\n  /// purpose of memory transfer calls.\n  TBAAAccessInfo mergeTBAAInfoForMemoryTransfer(TBAAAccessInfo DestInfo,\n                                                TBAAAccessInfo SrcInfo);\n};\n\n}  // end namespace CodeGen\n}  // end namespace clang\n\nnamespace llvm {\n\ntemplate<> struct DenseMapInfo<clang::CodeGen::TBAAAccessInfo> {\n  static clang::CodeGen::TBAAAccessInfo getEmptyKey() {\n    unsigned UnsignedKey = DenseMapInfo<unsigned>::getEmptyKey();\n    return clang::CodeGen::TBAAAccessInfo(\n      static_cast<clang::CodeGen::TBAAAccessKind>(UnsignedKey),\n      DenseMapInfo<MDNode *>::getEmptyKey(),\n      DenseMapInfo<MDNode *>::getEmptyKey(),\n      DenseMapInfo<uint64_t>::getEmptyKey(),\n      DenseMapInfo<uint64_t>::getEmptyKey());\n  }\n\n  static clang::CodeGen::TBAAAccessInfo getTombstoneKey() {\n    unsigned UnsignedKey = DenseMapInfo<unsigned>::getTombstoneKey();\n    return clang::CodeGen::TBAAAccessInfo(\n      static_cast<clang::CodeGen::TBAAAccessKind>(UnsignedKey),\n      DenseMapInfo<MDNode *>::getTombstoneKey(),\n      DenseMapInfo<MDNode *>::getTombstoneKey(),\n      DenseMapInfo<uint64_t>::getTombstoneKey(),\n      DenseMapInfo<uint64_t>::getTombstoneKey());\n  }\n\n  static unsigned getHashValue(const clang::CodeGen::TBAAAccessInfo &Val) {\n    auto KindValue = static_cast<unsigned>(Val.Kind);\n    return DenseMapInfo<unsigned>::getHashValue(KindValue) ^\n           DenseMapInfo<MDNode *>::getHashValue(Val.BaseType) ^\n           DenseMapInfo<MDNode *>::getHashValue(Val.AccessType) ^\n           DenseMapInfo<uint64_t>::getHashValue(Val.Offset) ^\n           DenseMapInfo<uint64_t>::getHashValue(Val.Size);\n  }\n\n  static bool isEqual(const clang::CodeGen::TBAAAccessInfo &LHS,\n                      const clang::CodeGen::TBAAAccessInfo &RHS) {\n    return LHS == RHS;\n  }\n};\n\n}  // end namespace llvm\n\n#endif\n"}}, "reports": [{"events": [{"location": {"col": 8, "file": 1, "line": 175}, "message": "destructor '~TypeInfoChars' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/ASTContext.h", "reportHash": "eb03ae2d5f4afaef760c9f14f8fd3f35", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 21, "line": 23}, "message": "destructor '~NSAPI' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/include/clang/AST/NSAPI.h", "reportHash": "f6e3d76fa2a2cec5cabddfa076ac1b2b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 50, "line": 67}, "message": "destructor '~CGCallee' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "reportHash": "ad59412b77ce6f664ef6d60640ffd565", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 50, "line": 358}, "message": "default constructor 'FunctionArgList' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "reportHash": "e8fcff47eac79d77a272905d74398aba", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 50, "line": 362}, "message": "destructor '~ReturnValueSlot' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCall.h", "reportHash": "156586d1584bec0635a75e95fa1809f1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 21, "file": 51, "line": 491}, "message": "destructor '~iterator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCleanup.h", "reportHash": "7c28a9452d7c5de55dc97be404db92c1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 21, "file": 51, "line": 491}, "message": "move constructor 'iterator' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGCleanup.h", "reportHash": "aa55a463bfc78dceeed87fd2cbadf6ce", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 52, "line": 3128}, "message": "destructor '~SanitizerHandlerInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGExpr.cpp", "reportHash": "1165e5404ff447a7824a41456d5b34fd", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 27, "file": 52, "line": 3701}, "message": "destructor '~' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGExpr.cpp", "reportHash": "ce710b20d532fc28374ab33d6ee7baed", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 27, "file": 52, "line": 3701}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGExpr.cpp", "reportHash": "70079dbd7fa267a56d2281fa5a07baaa", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 52, "line": 5352}, "message": "default constructor 'LValueOrRValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGExpr.cpp", "reportHash": "c4d38cc27d95ae0cd0ea9acceeddd0d6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 10, "file": 52, "line": 5352}, "message": "move constructor 'LValueOrRValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGExpr.cpp", "reportHash": "c96f8ae5c43775a0517938e4774ab8cf", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 39}, "message": "default constructor 'RValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "b8af3da991199d8f82356be947de823c", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 39}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "040d457894f0aea492410365203dbed6", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 39}, "message": "move constructor 'RValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "be7f69bf7a62113af3534e12989ead53", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 150}, "message": "destructor '~LValueBaseInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "1c99ccb7ee99fa9b727d8dfa8d4964c0", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 150}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "e9c37dcb126a24617b641e7880bf3afb", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 150}, "message": "move constructor 'LValueBaseInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "0a6a9200d000148916cc09b0c5345ddc", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 167}, "message": "default constructor 'LValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "94a0bfcbe5ef487d90daa18d34700865", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 167}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "040539004fb95c35fbc74c37dcdee3f7", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 167}, "message": "move constructor 'LValue' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "a81482c7b7f49bc9bfd712bc44a92048", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 3, "file": 53, "line": 179}, "message": "move constructor '' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "9775656210d033127e4cc25b92b02a59", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 471}, "message": "default constructor 'AggValueSlot' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "e54e059b1ed9751ce4c071ec35172039", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 471}, "message": "destructor '~AggValueSlot' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "f49cebee88543ccf5323adc26bf20454", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 471}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "52c668819ae96e81b3df19e2a6e8c1c1", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 7, "file": 53, "line": 471}, "message": "move constructor 'AggValueSlot' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CGValue.h", "reportHash": "02b2c7f7225fdb1008bb9a9c29f45b7b", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 54, "line": 204}, "message": "destructor '~saved_type' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "011b72109964b6ee834743358ad2eb98", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 9, "file": 54, "line": 204}, "message": "move constructor 'saved_type' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenFunction.h", "reportHash": "5a0b184b1b0b8baf1cff5e40ded472a4", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 55, "line": 42}, "message": "destructor '~TBAAAccessInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenTBAA.h", "reportHash": "477b5fd3425e800c7967c3f6eb50e982", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 55, "line": 42}, "message": "move assignment operator 'operator=' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenTBAA.h", "reportHash": "d255650d14ba2c1d0e758876ae1e604f", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}, {"events": [{"location": {"col": 8, "file": 55, "line": 42}, "message": "move constructor 'TBAAAccessInfo' should be marked noexcept"}], "macros": [], "notes": [], "path": "/home/vsts/work/1/llvm-project/clang/lib/CodeGen/CodeGenTBAA.h", "reportHash": "3552f6682b0d44c23e43abda1d2c0a69", "checkerName": "cppcoreguidelines-noexcept", "reviewStatus": null, "severity": "UNSPECIFIED"}]};
      window.onload = function() {
        if (!browserCompatible) {
          setNonCompatibleBrowserMessage();
        } else {
          BugViewer.init(data.files, data.reports);
          BugViewer.create();
          BugViewer.initByUrl();
        }
      };
    </script>
  </head>
  <body>
  <div class="container">
    <div id="content">
      <div id="side-bar">
        <div class="header">
          <a href="index.html" class="button">&#8249; Return to List</a>
        </div>
        <div id="report-nav">
          <div class="header">Reports</div>
        </div>
      </div>
      <div id="editor-wrapper">
        <div class="header">
          <div id="file">
            <span class="label">File:</span>
            <span id="file-path"></span>
          </div>
          <div id="checker">
            <span class="label">Checker name:</span>
            <span id="checker-name"></span>
          </div>
          <div id="review-status-wrapper">
            <span class="label">Review status:</span>
            <span id="review-status"></span>
          </div>
        </div>
        <div id="editor"></div>
      </div>
    </div>
  </div>
  </body>
</html>
